---
layout: default
title: Object Detection--的一个好的对比总结文章
---

{{ "%3Cdiv+id%3D%22article_content%22+class%3D%22article_content+clearfix+csdn-tracking-statistics%22+data-pid%3D%22blog%22+data-mod%3D%22popu_307%22+data-dsm%3D%22post%22%3E+%0A+%3Clink+rel%3D%22stylesheet%22+href%3D%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fphoenix%2Ftemplate%2Fcss%2Fck_htmledit_views-e2445db1a8.css%22%3E+%0A+%3Cdiv+class%3D%22htmledit_views%22%3E+%0A++%3Cp%3E%3Cbr%3E+https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%3Cbr%3E+%3C%2Fp%3E+%0A++%3Cp%3E%3Cbr%3E+%3C%2Fp%3E+%0A++%3Cp%3E%3Cbr%3E+%3C%2Fp%3E+%0A++%3Cp%3E%3C%2Fp%3E+%0A++%3Cdiv+id%3D%22toc%22+style%3D%22margin%3A0px%3B+padding%3A10px%3B+border%3A1px+solid+rgb%28170%2C170%2C170%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EJump+to...%3C%2Fspan%3E+%0A+++%3Col+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+list-style-type%3Adisc%22%3E+%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23leaderboard%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ELeaderboard%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23papers%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EPapers%3C%2Fa%3E+%0A+++++%3Col+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+list-style-type%3Adisc%22%3E+%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23r-cnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ER-CNN%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23fast-r-cnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EFast+R-CNN%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23faster-r-cnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EFaster+R-CNN%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23multibox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EMultiBox%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23spp-net%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ESPP-Net%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23deepid-net%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EDeepID-Net%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23noc%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ENoC%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23deepbox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EDeepBox%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23mr-cnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EMR-CNN%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23yolo%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EYOLO%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23yolov2%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EYOLOv2%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23attentionnet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EAttentionNet%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23densebox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EDenseBox%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23ssd%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ESSD%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23dssd%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EDSSD%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23inside-outside-net-ion%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EInside-Outside+Net+%28ION%29%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23g-cnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EG-CNN%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23hypernet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EHyperNet%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23multipathnet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EMultiPathNet%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23craft%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ECRAFT%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23ohem%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EOHEM%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23r-fcn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ER-FCN%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23ms-cnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EMS-CNN%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23pvanet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EPVANET%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23gbd-net%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EGBD-Net%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23stuffnet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EStuffNet%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23feature-pyramid-network-fpn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EFeature+Pyramid+Network+%28FPN%29%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23cc-net%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ECC-Net%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23dsod%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EDSOD%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23nms%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ENMS%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23weakly-supervised-object-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EWeakly+Supervised+Object+Detection%3C%2Fa%3E%3C%2Fli%3E%0A+++++%3C%2Fol%3E+%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23detection-from-video%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EDetection+From+Video%3C%2Fa%3E+%0A+++++%3Col+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+list-style-type%3Adisc%22%3E+%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23t-cnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ET-CNN%3C%2Fa%3E%3C%2Fli%3E%0A+++++%3C%2Fol%3E+%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23object-detection-in-3d%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EObject+Detection+in+3D%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23object-detection-on-rgb-d%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EObject+Detection+on+RGB-D%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23salient-object-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ESalient+Object+Detection%3C%2Fa%3E+%0A+++++%3Col+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+list-style-type%3Adisc%22%3E+%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23saliency-detection-in-video%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ESaliency+Detection+in+Video%3C%2Fa%3E%3C%2Fli%3E%0A+++++%3C%2Fol%3E+%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23visual-relationship-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EVisual+Relationship+Detection%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23specific-object-deteciton%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ESpecific+Object+Deteciton%3C%2Fa%3E+%0A+++++%3Col+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+list-style-type%3Adisc%22%3E+%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23face-deteciton%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EFace+Deteciton%3C%2Fa%3E+%0A+++++++%3Col+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+list-style-type%3Adisc%22%3E+%0A++++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23unitbox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EUnitBox%3C%2Fa%3E%3C%2Fli%3E%0A++++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23mtcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EMTCNN%3C%2Fa%3E%3C%2Fli%3E%0A+++++++%3C%2Fol%3E+%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23facial-point--landmark-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EFacial+Point+%2F+Landmark+Detection%3C%2Fa%3E%3C%2Fli%3E%0A+++++%3C%2Fol%3E+%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23people-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EPeople+Detection%3C%2Fa%3E+%0A+++++%3Col+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+list-style-type%3Adisc%22%3E+%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23person-head-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EPerson+Head+Detection%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23pedestrian-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EPedestrian+Detection%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23vehicle-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EVehicle+Detection%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23traffic-sign-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ETraffic-Sign+Detection%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23boundary--edge--contour-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EBoundary+%2F+Edge+%2F+Contour+Detection%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23skeleton-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ESkeleton+Detection%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23fruit-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EFruit+Detection%3C%2Fa%3E%3C%2Fli%3E%0A++++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23part-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EPart+Detection%3C%2Fa%3E%3C%2Fli%3E%0A+++++%3C%2Fol%3E+%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23object-proposal%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EObject+Proposal%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23localization%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ELocalization%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23tutorials--talks%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ETutorials+%2F+Talks%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23projects%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EProjects%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23tools%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3ETools%3C%2Fa%3E%3C%2Fli%3E%0A++++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3E%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%23blogs%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EBlogs%3C%2Fa%3E%3C%2Fli%3E%0A+++%3C%2Fol%3E+%0A++%3C%2Fdiv%3E+%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Ctable+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+position%3Arelative%3B+width%3A600px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cthead+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Cth+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-align%3Acenter%22%3EMethod%3C%2Fth%3E+%0A+++++%3Cth+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-align%3Acenter%22%3EVOC2007%3C%2Fth%3E+%0A+++++%3Cth+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-align%3Acenter%22%3EVOC2010%3C%2Fth%3E+%0A+++++%3Cth+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-align%3Acenter%22%3EVOC2012%3C%2Fth%3E+%0A+++++%3Cth+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-align%3Acenter%22%3EILSVRC+2013%3C%2Fth%3E+%0A+++++%3Cth+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-align%3Acenter%22%3EMSCOCO+2015%3C%2Fth%3E+%0A+++++%3Cth+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-align%3Acenter%22%3ESpeed%3C%2Fth%3E+%0A++++%3C%2Ftr%3E+%0A+++%3C%2Fthead%3E+%0A+++%3Ctbody+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EOverFeat%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E24.3%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ER-CNN+%28AlexNet%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E58.5%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E53.7%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E53.3%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E31.4%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ER-CNN+%28VGG16%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E66.0%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ESPP_net%28ZF-5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E54.2%25%281-model%29%2C+60.9%25%282-model%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E31.84%25%281-model%29%2C+35.11%25%286-model%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EDeepID-Net%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E64.1%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E50.3%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ENoC%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E73.3%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E68.8%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EFast-RCNN+%28VGG16%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E70.0%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E68.8%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E68.4%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E19.7%25%28%40%5B0.5-0.95%5D%29%2C+35.9%25%28%400.5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EMR-CNN%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E78.2%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E73.9%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EFaster-RCNN+%28VGG16%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E78.8%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E75.9%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E21.9%25%28%40%5B0.5-0.95%5D%29%2C+42.7%25%28%400.5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E198ms%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EFaster-RCNN+%28ResNet-101%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E85.6%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E83.8%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E37.4%25%28%40%5B0.5-0.95%5D%29%2C+59.0%25%28%400.5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EYOLO%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E63.4%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E57.9%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E45+fps%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EYOLO+VGG-16%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E66.4%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E21+fps%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EYOLOv2+544+%C3%97+544%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E78.6%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E73.4%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E21.6%25%28%40%5B0.5-0.95%5D%29%2C+44.0%25%28%400.5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E40+fps%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ESSD300+%28VGG16%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E77.2%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E75.8%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E25.1%25%28%40%5B0.5-0.95%5D%29%2C+43.1%25%28%400.5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E46+fps%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ESSD512+%28VGG16%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E79.8%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E78.5%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E28.8%25%28%40%5B0.5-0.95%5D%29%2C+48.5%25%28%400.5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E19+fps%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EION%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E79.2%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E76.4%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ECRAFT%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E75.7%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E71.3%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E48.5%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EOHEM%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E78.9%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E76.3%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E25.5%25%28%40%5B0.5-0.95%5D%29%2C+45.9%25%28%400.5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ER-FCN+%28ResNet-50%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E77.4%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E0.12sec%28K40%29%2C+0.09sec%28TitianX%29%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ER-FCN+%28ResNet-101%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E79.5%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E0.17sec%28K40%29%2C+0.12sec%28TitianX%29%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3ER-FCN+%28ResNet-101%29%2Cmulti+sc+train%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E83.6%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E82.0%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E31.5%25%28%40%5B0.5-0.95%5D%29%2C+53.2%25%28%400.5%29%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A++++%3Ctr+style%3D%22margin%3A0px%3B+padding%3A0px%22%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3EPVANet+9.0%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E89.8%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E84.2%25%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E%26nbsp%3B%3C%2Ftd%3E+%0A+++++%3Ctd+style%3D%22margin%3A0px%3B+padding%3A4px+0px%3B+text-indent%3A6px%3B+text-align%3Acenter%22%3E750ms%28CPU%29%2C+46ms%28TitianX%29%3C%2Ftd%3E+%0A++++%3C%2Ftr%3E+%0A+++%3C%2Ftbody%3E+%0A++%3C%2Ftable%3E+%0A++%3Ch1+id%3D%22leaderboard%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Leaderboard%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDetection+Results%3A+VOC2012%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Competition+%E2%80%9Ccomp4%E2%80%9D+%28train+on+additional+data%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ehomepage%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fhost.robots.ox.ac.uk%3A8080%2Fleaderboard%2Fdisplaylb.php%3Fchallengeid%3D11%26amp%3Bcompid%3D4%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fhost.robots.ox.ac.uk%3A8080%2Fleaderboard%2Fdisplaylb.php%3Fchallengeid%3D11%26amp%3Bcompid%3D4%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22papers%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Papers%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Neural+Networks+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5207-deep-neural-networks-for-object-detection.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpapers.nips.cc%2Fpaper%2F5207-deep-neural-networks-for-object-detection.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EOverFeat%3A+Integrated+Recognition%2C+Localization+and+Detection+using+Convolutional+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1312.6229%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1312.6229%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fsermanet%2FOverFeat%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fsermanet%2FOverFeat%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ecode%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcilvr.nyu.edu%2Fdoku.php%3Fid%3Dsoftware%3Aoverfeat%3Astart%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcilvr.nyu.edu%2Fdoku.php%3Fid%3Dsoftware%3Aoverfeat%3Astart%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22r-cnn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+R-CNN%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ERich+feature+hierarchies+for+accurate+object+detection+and+semantic+segmentation%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+R-CNN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1311.2524%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1311.2524%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Esupp%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpeople.eecs.berkeley.edu%2F%7Erbg%2Fpapers%2Fr-cnn-cvpr-supp.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpeople.eecs.berkeley.edu%2F%7Erbg%2Fpapers%2Fr-cnn-cvpr-supp.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.image-net.org%2Fchallenges%2FLSVRC%2F2013%2Fslides%2Fr-cnn-ilsvrc2013-workshop.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.image-net.org%2Fchallenges%2FLSVRC%2F2013%2Fslides%2Fr-cnn-ilsvrc2013-workshop.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cs.berkeley.edu%2F%7Erbg%2Fslides%2Frcnn-cvpr14-slides.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cs.berkeley.edu%2F%7Erbg%2Fslides%2Frcnn-cvpr14-slides.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Frcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Frcnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Enotes%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fzhangliliang.com%2F2014%2F07%2F23%2Fpaper-note-rcnn%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fzhangliliang.com%2F2014%2F07%2F23%2Fpaper-note-rcnn%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ecaffe-pr%28%E2%80%9CMake+R-CNN+the+Caffe+detection+example%E2%80%9D%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FBVLC%2Fcaffe%2Fpull%2F482%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FBVLC%2Fcaffe%2Fpull%2F482%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22fast-r-cnn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Fast+R-CNN%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFast+R-CNN%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1504.08083%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1504.08083%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Ftutorial.caffe.berkeleyvision.org%2Fcaffe-cvpr15-detection.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Ftutorial.caffe.berkeleyvision.org%2Fcaffe-cvpr15-detection.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28COCO-branch%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%2Ftree%2Fcoco%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%2Ftree%2Fcoco%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ewebcam+demo%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%2Fpull%2F29%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%2Fpull%2F29%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Enotes%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fzhangliliang.com%2F2015%2F05%2F17%2Fpaper-note-fast-rcnn%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fzhangliliang.com%2F2015%2F05%2F17%2Fpaper-note-fast-rcnn%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Enotes%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fblog.csdn.net%2Flinj_m%2Farticle%2Fdetails%2F48930179%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fblog.csdn.net%2Flinj_m%2Farticle%2Fdetails%2F48930179%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28%E2%80%9CFast+R-CNN+in+MXNet%E2%80%9D%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fprecedenceguo%2Fmx-rcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fprecedenceguo%2Fmx-rcnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fmahyarnajibi%2Ffast-rcnn-torch%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fmahyarnajibi%2Ffast-rcnn-torch%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fapple2373%2Fchainer-simple-fast-rnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fapple2373%2Fchainer-simple-fast-rnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fzplizzi%2Ftensorflow-fast-rcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fzplizzi%2Ftensorflow-fast-rcnn%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA-Fast-RCNN%3A+Hard+Positive+Generation+via+Adversary+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.03414%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.03414%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fabhinavsh.info%2Fpapers%2Fpdfs%2Fadversarial_object_detection.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fabhinavsh.info%2Fpapers%2Fpdfs%2Fadversarial_object_detection.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Caffe%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fxiaolonw%2Fadversarial-frcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fxiaolonw%2Fadversarial-frcnn%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22faster-r-cnn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Faster+R-CNN%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFaster+R-CNN%3A+Towards+Real-Time+Object+Detection+with+Region+Proposal+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+NIPS+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1506.01497%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1506.01497%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egitxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.gitxiv.com%2Fposts%2F8pfpcvefDYn2gSgXk%2Ffaster-r-cnn-towards-real-time-object-detection-with-region%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.gitxiv.com%2Fposts%2F8pfpcvefDYn2gSgXk%2Ffaster-r-cnn-towards-real-time-object-detection-with-region%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fweb.cs.hacettepe.edu.tr%2F%7Eaykut%2Fclasses%2Fspring2016%2Fbil722%2Fslides%2Fw05-FasterR-CNN.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fweb.cs.hacettepe.edu.tr%2F%7Eaykut%2Fclasses%2Fspring2016%2Fbil722%2Fslides%2Fw05-FasterR-CNN.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28official%2C+Matlab%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FShaoqingRen%2Ffaster_rcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FShaoqingRen%2Ffaster_rcnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Fpy-faster-rcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Fpy-faster-rcnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fmitmul%2Fchainer-faster-rcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fmitmul%2Fchainer-faster-rcnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fandreaskoepf%2Ffaster-rcnn.torch%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fandreaskoepf%2Ffaster-rcnn.torch%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fruotianluo%2FFaster-RCNN-Densecap-torch%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fruotianluo%2FFaster-RCNN-Densecap-torch%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fsmallcorgi%2FFaster-RCNN_TF%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fsmallcorgi%2FFaster-RCNN_TF%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FCharlesShang%2FTFFRCNN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FCharlesShang%2FTFFRCNN%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28C%2B%2B+demo%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FYihangLou%2FFasterRCNN-Encapsulation-Cplusplus%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FYihangLou%2FFasterRCNN-Encapsulation-Cplusplus%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fyhenon%2Fkeras-frcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fyhenon%2Fkeras-frcnn%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFaster+R-CNN+in+MXNet+with+distributed+implementation+and+data+parallelization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fdmlc%2Fmxnet%2Ftree%2Fmaster%2Fexample%2Frcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fdmlc%2Fmxnet%2Ftree%2Fmaster%2Fexample%2Frcnn%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EContextual+Priming+and+Feedback+for+Faster+R-CNN%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016.+Carnegie+Mellon+University%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fabhinavsh.info%2Fcontext_priming_feedback.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fabhinavsh.info%2Fcontext_priming_feedback.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eposter%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.eccv2016.org%2Ffiles%2Fposters%2FP-1A-20.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.eccv2016.org%2Ffiles%2Fposters%2FP-1A-20.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAn+Implementation+of+Faster+RCNN+with+Study+for+Region+Sampling%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Technical+Report%2C+3+pages.+CMU%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.02138%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.02138%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fendernewton%2Ftf-faster-rcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fendernewton%2Ftf-faster-rcnn%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Chr+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A++%3Ch2+id%3D%22multibox%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+MultiBox%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EScalable+Object+Detection+using+Deep+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+first+MultiBox.+Train+a+CNN+to+predict+Region+of+Interest.%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1312.2249%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1312.2249%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fgoogle%2Fmultibox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fgoogle%2Fmultibox%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fresearch.googleblog.com%2F2014%2F12%2Fhigh-quality-object-detection-at-scale.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fresearch.googleblog.com%2F2014%2F12%2Fhigh-quality-object-detection-at-scale.html%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EScalable%2C+High-Quality+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+second+MultiBox%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1412.1441%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1412.1441%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fgoogle%2Fmultibox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fgoogle%2Fmultibox%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22spp-net%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+SPP-Net%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESpatial+Pyramid+Pooling+in+Deep+Convolutional+Networks+for+Visual+Recognition%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2014+%2F+TPAMI+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1406.4729%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1406.4729%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FShaoqingRen%2FSPP_net%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FShaoqingRen%2FSPP_net%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Enotes%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fzhangliliang.com%2F2014%2F09%2F13%2Fpaper-note-sppnet%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fzhangliliang.com%2F2014%2F09%2F13%2Fpaper-note-sppnet%2F%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22deepid-net%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+DeepID-Net%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeepID-Net%3A+Deformable+Deep+Convolutional+Neural+Networks+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+PAMI+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+an+extension+of+R-CNN.+box+pre-training%2C+cascade+on+region+proposals%2C+deformation+layers+and+context+representations%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%25CB%259Cwlouyang%2Fprojects%2FimagenetDeepId%2Findex.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%25CB%259Cwlouyang%2Fprojects%2FimagenetDeepId%2Findex.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1412.5661%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1412.5661%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+Detectors+Emerge+in+Deep+Scene+CNNs%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICLR+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1412.6856%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1412.6856%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fwww.robots.ox.ac.uk%2F%7Evgg%2Frg%2Fpapers%2Fzhou_iclr15.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fwww.robots.ox.ac.uk%2F%7Evgg%2Frg%2Fpapers%2Fzhou_iclr15.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fpeople.csail.mit.edu%2Fkhosla%2Fpapers%2Ficlr2015_zhou.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fpeople.csail.mit.edu%2Fkhosla%2Fpapers%2Ficlr2015_zhou.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fplaces.csail.mit.edu%2Fslide_iclr2015.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fplaces.csail.mit.edu%2Fslide_iclr2015.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EsegDeepM%3A+Exploiting+Segmentation+and+Context+in+Deep+Neural+Networks+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject%28code%2Bdata%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fwww.cs.toronto.edu%2F%7Eyukun%2Fsegdeepm.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fwww.cs.toronto.edu%2F%7Eyukun%2Fsegdeepm.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1502.04275%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1502.04275%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FYknZhu%2FsegDeepM%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FYknZhu%2FsegDeepM%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22noc%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+NoC%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+Detection+Networks+on+Convolutional+Feature+Maps%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+TPAMI+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1504.06066%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1504.06066%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EImproving+Object+Detection+with+Deep+Convolutional+Networks+via+Bayesian+Optimization+and+Structured+Prediction%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1504.03293%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1504.03293%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.ytzhang.net%2Ffiles%2Fpublications%2F2015-cvpr-det-slides.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.ytzhang.net%2Ffiles%2Fpublications%2F2015-cvpr-det-slides.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FYutingZhang%2Ffgs-obj%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FYutingZhang%2Ffgs-obj%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22deepbox%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+DeepBox%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeepBox%3A+Learning+Objectness+with+Convolutional+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1505.02146%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1505.02146%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fweichengkuo%2FDeepBox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fweichengkuo%2FDeepBox%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22mr-cnn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+MR-CNN%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+detection+via+a+multi-region+%26amp%3B+semantic+segmentation-aware+CNN+model%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015.+MR-CNN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1505.01749%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1505.01749%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fgidariss%2Fmrcnn-object-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fgidariss%2Fmrcnn-object-detection%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Enotes%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fzhangliliang.com%2F2015%2F05%2F17%2Fpaper-note-ms-cnn%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fzhangliliang.com%2F2015%2F05%2F17%2Fpaper-note-ms-cnn%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Enotes%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fblog.cvmarcher.com%2Fposts%2F2015%2F05%2F17%2Fmulti-region-semantic-segmentation-aware-cnn%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fblog.cvmarcher.com%2Fposts%2F2015%2F05%2F17%2Fmulti-region-semantic-segmentation-aware-cnn%2F%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22yolo%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+YOLO%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EYou+Only+Look+Once%3A+Unified%2C+Real-Time+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2Fe69d4118b20a42de4e23b9549f9a6ec6dbbb0814%2F687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1506.02640%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1506.02640%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ecode%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolo%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolo%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fpjreddie%2Fdarknet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fpjreddie%2Fdarknet%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fpjreddie.com%2Fpublications%2Fyolo%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fpjreddie.com%2Fpublications%2Fyolo%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA%2Fpub%3Fstart%3Dfalse%26amp%3Bloop%3Dfalse%26amp%3Bdelayms%3D3000%26amp%3Bslide%3Did.p%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA%2Fpub%3Fstart%3Dfalse%26amp%3Bloop%3Dfalse%26amp%3Bdelayms%3D3000%26amp%3Bslide%3Did.p%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ereddit%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fwww.reddit.com%2Fr%2FMachineLearning%2Fcomments%2F3a3m0o%2Frealtime_object_detection_with_yolo%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fwww.reddit.com%2Fr%2FMachineLearning%2Fcomments%2F3a3m0o%2Frealtime_object_detection_with_yolo%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fgliese581gg%2FYOLO_tensorflow%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fgliese581gg%2FYOLO_tensorflow%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fxingwangsfu%2Fcaffe-yolo%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fxingwangsfu%2Fcaffe-yolo%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ffrankzhangrui%2FDarknet-Yolo%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ffrankzhangrui%2FDarknet-Yolo%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FBriSkyHekun%2Fpy-darknet-yolo%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FBriSkyHekun%2Fpy-darknet-yolo%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ftommy-qichang%2Fyolo.torch%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ftommy-qichang%2Fyolo.torch%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ffrischzenger%2Fyolo-windows%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ffrischzenger%2Fyolo-windows%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FAlexeyAB%2Fyolo-windows%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FAlexeyAB%2Fyolo-windows%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fnilboy%2Ftensorflow-yolo%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fnilboy%2Ftensorflow-yolo%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3Edarkflow+-+translate+darknet+to+tensorflow.+Load+trained+weights%2C+retrain%2Ffine-tune+them+using+tensorflow%2C+export+constant+graph+def+to+C%2B%2B%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fthtrieu.github.io%2Fnotes%2Fyolo-tensorflow-graph-buffer-cpp%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fthtrieu.github.io%2Fnotes%2Fyolo-tensorflow-graph-buffer-cpp%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fthtrieu%2Fdarkflow%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fthtrieu%2Fdarkflow%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EStart+Training+YOLO+with+Our+Own+Data%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22http%3A%2F%2Fguanghan.info%2Fblog%2Fen%2Fwp-content%2Fuploads%2F2015%2F12%2Fimages-40.jpg%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+train+with+customized+data+and+class+numbers%2Flabels.+Linux+%2F+Windows+version+for+darknet.%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fguanghan.info%2Fblog%2Fen%2Fmy-works%2Ftrain-yolo%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fguanghan.info%2Fblog%2Fen%2Fmy-works%2Ftrain-yolo%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FGuanghan%2Fdarknet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FGuanghan%2Fdarknet%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EYOLO%3A+Core+ML+versus+MPSNNGraph%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Tiny+YOLO+for+iOS+implemented+using+CoreML+but+also+using+the+new+MPS+graph+API.%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fmachinethink.net%2Fblog%2Fyolo-coreml-versus-mps-graph%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fmachinethink.net%2Fblog%2Fyolo-coreml-versus-mps-graph%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fhollance%2FYOLO-CoreML-MPSNNGraph%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fhollance%2FYOLO-CoreML-MPSNNGraph%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETensorFlow+YOLO+object+detection+on+Android%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Real-time+object+detection+on+Android+using+the+YOLO+network+with+TensorFlow%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fnatanielruiz%2Fandroid-yolo%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fnatanielruiz%2Fandroid-yolo%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EComputer+Vision+in+iOS+%E2%80%93+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fsriraghu.com%2F2017%2F07%2F12%2Fcomputer-vision-in-ios-object-detection%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fsriraghu.com%2F2017%2F07%2F12%2Fcomputer-vision-in-ios-object-detection%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fr4ghu%2FiOS-CoreML-Yolo%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fr4ghu%2FiOS-CoreML-Yolo%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22yolov2%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+YOLOv2%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EYOLO9000%3A+Better%2C+Faster%2C+Stronger%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.08242%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.08242%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ecode%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpjreddie.com%2Fyolo9000%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpjreddie.com%2Fyolo9000%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Chainer%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fleetenki%2FYOLOv2%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fleetenki%2FYOLOv2%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Keras%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fallanzelener%2FYAD2K%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fallanzelener%2FYAD2K%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28PyTorch%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Flongcw%2Fyolo2-pytorch%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Flongcw%2Fyolo2-pytorch%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Tensorflow%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fhizhangp%2Fyolo_tensorflow%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fhizhangp%2Fyolo_tensorflow%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Windows%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FAlexeyAB%2Fdarknet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FAlexeyAB%2Fdarknet%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FchoasUp%2Fcaffe-yolo9000%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FchoasUp%2Fcaffe-yolo9000%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fphilipperemy%2Fyolo-9000%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fphilipperemy%2Fyolo-9000%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EYolo_mark%3A+GUI+for+marking+bounded+boxes+of+objects+in+images+for+training+Yolo+v2%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FAlexeyAB%2FYolo_mark%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FAlexeyAB%2FYolo_mark%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Chr+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ER-CNN+minus+R%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1506.06981%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1506.06981%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22attentionnet%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+AttentionNet%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAttentionNet%3A+Aggregating+Weak+Directions+for+Accurate+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+state-of-the-art+performance+of+65%25+%28AP%29+on+PASCAL+VOC+2007%2F2012+human+detection+task%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1506.07704%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1506.07704%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fwww.robots.ox.ac.uk%2F%7Evgg%2Frg%2Fslides%2FAttentionNet.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fwww.robots.ox.ac.uk%2F%7Evgg%2Frg%2Fslides%2FAttentionNet.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks%2Flunit-kaist-slide.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks%2Flunit-kaist-slide.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22densebox%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+DenseBox%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDenseBox%3A+Unifying+Landmark+Localization+with+End+to+End+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1509.04874%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1509.04874%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Edemo%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpan.baidu.com%2Fs%2F1mgoWWsS%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpan.baidu.com%2Fs%2F1mgoWWsS%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3EKITTI+result%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cvlibs.net%2Fdatasets%2Fkitti%2Feval_object.php%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cvlibs.net%2Fdatasets%2Fkitti%2Feval_object.php%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22ssd%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+SSD%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESSD%3A+Single+Shot+MultiBox+Detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2Fad9b147ed3a5f48ffb7c3540711c15aa04ce49c6%2F687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016+Oral%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1512.02325%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1512.02325%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cs.unc.edu%2F%7Ewliu%2Fpapers%2Fssd.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cs.unc.edu%2F%7Ewliu%2Fpapers%2Fssd.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cs.unc.edu%2F%7Ewliu%2Fpapers%2Fssd_eccv2016_slide.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cs.unc.edu%2F%257Ewliu%2Fpapers%2Fssd_eccv2016_slide.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Official%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fweiliu89%2Fcaffe%2Ftree%2Fssd%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fweiliu89%2Fcaffe%2Ftree%2Fssd%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Evideo%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fweibo.com%2Fp%2F2304447a2326da963254c963c97fb05dd3a973%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fweibo.com%2Fp%2F2304447a2326da963254c963c97fb05dd3a973%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fzhreshold%2Fmxnet-ssd%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fzhreshold%2Fmxnet-ssd%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fzhreshold%2Fmxnet-ssd.cpp%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fzhreshold%2Fmxnet-ssd.cpp%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Frykov8%2Fssd_keras%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Frykov8%2Fssd_keras%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fbalancap%2FSSD-Tensorflow%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fbalancap%2FSSD-Tensorflow%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Famdegroot%2Fssd.pytorch%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Famdegroot%2Fssd.pytorch%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Caffe%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fchuanqi305%2FMobileNet-SSD%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fchuanqi305%2FMobileNet-SSD%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EWhat%E2%80%99s+the+diffience+in+performance+between+this+new+code+you+pushed+and+the+previous+code%3F+%23327%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fweiliu89%2Fcaffe%2Fissues%2F327%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fweiliu89%2Fcaffe%2Fissues%2F327%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEnhancement+of+SSD+by+concatenating+feature+maps+for+object+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+rainbow+SSD+%28R-SSD%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.09587%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.09587%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22dssd%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+DSSD%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDSSD+%3A+Deconvolutional+Single+Shot+Detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+UNC+Chapel+Hill+%26amp%3B+Amazon+Inc%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1701.06659%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1701.06659%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Edemo%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2F120.52.72.53%2Fwww.cs.unc.edu%2Fc3pr90ntc0td%2F%7Ecyfu%2Fdssd_lalaland.mp4%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2F120.52.72.53%2Fwww.cs.unc.edu%2Fc3pr90ntc0td%2F%7Ecyfu%2Fdssd_lalaland.mp4%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EContext-aware+Single-Shot+Detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+CSSD%2C+DiCSSD%2C+DeCSSD%2C+effective+receptive+fields+%28ERFs%29%2C+theoretical+receptive+fields+%28TRFs%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.08682%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.08682%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFeature-Fused+SSD%3A+Fast+Detection+for+Small+Objects%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.05054%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.05054%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Chr+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A++%3Ch2+id%3D%22inside-outside-net-ion%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Inside-Outside+Net+%28ION%29%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EInside-Outside+Net%3A+Detecting+Objects+in+Context+with+Skip+Pooling+and+Recurrent+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+%E2%80%9C0.8s+per+image+on+a+Titan+X+GPU+%28excluding+proposal+generation%29+without+two-stage+bounding-box+regression+and+1.15s+per+image+with+it%E2%80%9D.%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1512.04143%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1512.04143%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.seanbell.ca%2Ftmp%2Fion-coco-talk-bell2015.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.seanbell.ca%2Ftmp%2Fion-coco-talk-bell2015.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ecoco-leaderboard%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fmscoco.org%2Fdataset%2F%23detections-leaderboard%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fmscoco.org%2Fdataset%2F%23detections-leaderboard%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAdaptive+Object+Detection+Using+Adjacency+and+Zoom+Prediction%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016.+AZ-Net%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1512.07711%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1512.07711%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fluyongxi%2Faz-net%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fluyongxi%2Faz-net%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eyoutube%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYmFtuNwxaNM%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYmFtuNwxaNM%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22g-cnn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+G-CNN%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EG-CNN%3A+an+Iterative+Grid+Based+Object+Detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1512.07729%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1512.07729%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFactors+in+Finetuning+Deep+Model+for+object+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFactors+in+Finetuning+Deep+Model+for+Object+Detection+with+Long-tail+Distribution%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016.rank+3rd+for+provided+data+and+2nd+for+external+data+on+ILSVRC+2015+object+detection%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%7Ewlouyang%2Fprojects%2FImageNetFactors%2FCVPR16.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%7Ewlouyang%2Fprojects%2FImageNetFactors%2FCVPR16.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1601.05150%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1601.05150%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EWe+don%E2%80%99t+need+no+bounding-boxes%3A+Training+object+class+detectors+using+only+human+verification%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1602.08405%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1602.08405%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22hypernet%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+HyperNet%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EHyperNet%3A+Towards+Accurate+Region+Proposal+Generation+and+Joint+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1604.00600%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1604.00600%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22multipathnet%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+MultiPathNet%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+MultiPath+Network+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+BMVC+2016.+Facebook+AI+Research+%28FAIR%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1604.02135%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1604.02135%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ffacebookresearch%2Fmultipathnet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ffacebookresearch%2Fmultipathnet%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22craft%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+CRAFT%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ECRAFT+Objects+from+Images%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016.+Cascade+Region-proposal-network+And+FasT-rcnn.+an+extension+of+Faster+R-CNN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fbyangderek.github.io%2Fprojects%2Fcraft.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fbyangderek.github.io%2Fprojects%2Fcraft.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1604.03239%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1604.03239%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FYang_CRAFT_Objects_From_CVPR_2016_paper.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FYang_CRAFT_Objects_From_CVPR_2016_paper.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fbyangderek%2FCRAFT%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fbyangderek%2FCRAFT%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22ohem%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+OHEM%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETraining+Region-based+Object+Detectors+with+Online+Hard+Example+Mining%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016+Oral.+Online+hard+example+mining+%28OHEM%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1604.03540%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1604.03540%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FShrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FShrivastava_Training_Region-Based_Object_CVPR_2016_paper.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Official%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fabhi2610%2Fohem%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fabhi2610%2Fohem%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eauthor+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fabhinav-shrivastava.info%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fabhinav-shrivastava.info%2F%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EExploit+All+the+Layers%3A+Fast+and+Accurate+CNN+Object+Detector+with+Scale+Dependent+Pooling+and+Cascaded+Rejection+Classifiers%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+scale-dependent+pooling+%28SDP%29%2C+cascaded+rejection+classifiers+%28CRC%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww-personal.umich.edu%2F%7Ewgchoi%2FSDP-CRC_camready.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww-personal.umich.edu%2F%7Ewgchoi%2FSDP-CRC_camready.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22r-fcn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+R-FCN%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ER-FCN%3A+Object+Detection+via+Region-based+Fully+Convolutional+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1605.06409%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1605.06409%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fdaijifeng001%2FR-FCN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fdaijifeng001%2FR-FCN%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FOrpine%2Fpy-R-FCN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FOrpine%2Fpy-R-FCN%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FPureDiors%2Fpytorch_RFCN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FPureDiors%2Fpytorch_RFCN%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fbharatsingh430%2Fpy-R-FCN-multiGPU%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fbharatsingh430%2Fpy-R-FCN-multiGPU%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fxdever%2FRFCN-tensorflow%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fxdever%2FRFCN-tensorflow%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ERecycle+deep+features+for+better+object+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.05066%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.05066%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22ms-cnn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+MS-CNN%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Unified+Multi-scale+Deep+Convolutional+Neural+Network+for+Fast+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+640%C3%97480%3A+15+fps%2C+960%C3%97720%3A+8+fps%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.07155%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.07155%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fzhaoweicai%2Fmscnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fzhaoweicai%2Fmscnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eposter%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.eccv2016.org%2Ffiles%2Fposters%2FP-2B-38.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.eccv2016.org%2Ffiles%2Fposters%2FP-2B-38.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EMulti-stage+Object+Detection+with+Group+Recursive+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+VOC2007%3A+78.6%25%2C+VOC2012%3A+74.9%25%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.05159%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.05159%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESubcategory-aware+Convolutional+Neural+Networks+for+Object+Proposals+and+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+WACV+2017.+SubCNN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1604.04693%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1604.04693%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ftanshen%2FSubCNN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ftanshen%2FSubCNN%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22pvanet%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+PVANET%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPVANET%3A+Deep+but+Lightweight+Neural+Networks+for+Real-time+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+%E2%80%9Cless+channels+with+more+layers%E2%80%9D%2C+concatenated+ReLU%2C+Inception%2C+and+HyperNet%2C+batch+normalization%2C+residual+connections%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.08021%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.08021%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fsanghoon%2Fpva-faster-rcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fsanghoon%2Fpva-faster-rcnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eleaderboard%28PVANet+9.0%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fhost.robots.ox.ac.uk%3A8080%2Fleaderboard%2Fdisplaylb.php%3Fchallengeid%3D11%26amp%3Bcompid%3D4%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fhost.robots.ox.ac.uk%3A8080%2Fleaderboard%2Fdisplaylb.php%3Fchallengeid%3D11%26amp%3Bcompid%3D4%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPVANet%3A+Lightweight+Deep+Neural+Networks+for+Real-time+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Presented+at+NIPS+2016+Workshop+on+Efficient+Methods+for+Deep+Neural+Networks+%28EMDNN%29.+Continuation+of%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1608.08021%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EarXiv%3A1608.08021%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.08588%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.08588%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22gbd-net%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+GBD-Net%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EGated+Bi-directional+CNN+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+The+Chinese+University+of+Hong+Kong+%26amp%3B+Sensetime+Group+Limited%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-319-46478-7_22%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-319-46478-7_22%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Emirror%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fpan.baidu.com%2Fs%2F1dFohO7v%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fpan.baidu.com%2Fs%2F1dFohO7v%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ECrafting+GBD-Net+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+winner+of+the+ImageNet+object+detection+challenge+of+2016.+CUImage+and+CUVideo%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+gated+bi-directional+CNN+%28GBD-Net%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1610.02579%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1610.02579%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FcraftGBD%2FcraftGBD%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FcraftGBD%2FcraftGBD%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22stuffnet%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+StuffNet%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EStuffNet%3A+Using+%E2%80%98Stuff%E2%80%99+to+Improve+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1610.05861%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1610.05861%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EGeneralized+Haar+Filter+based+Deep+Networks+for+Real-Time+Object+Detection+in+Traffic+Scene%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1610.09609%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1610.09609%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EHierarchical+Object+Detection+with+Deep+Reinforcement+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Deep+Reinforcement+Learning+Workshop+%28NIPS+2016%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fimatge-upc.github.io%2Fdetection-2016-nipsws%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fimatge-upc.github.io%2Fdetection-2016-nipsws%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.03718%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.03718%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.slideshare.net%2Fxavigiro%2Fhierarchical-object-detection-with-deep-reinforcement-learning%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.slideshare.net%2Fxavigiro%2Fhierarchical-object-detection-with-deep-reinforcement-learning%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fimatge-upc%2Fdetection-2016-nipsws%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fimatge-upc%2Fdetection-2016-nipsws%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fjorditorres.org%2Fnips%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fjorditorres.org%2Fnips%2F%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+to+detect+and+localize+many+objects+from+few+examples%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.05664%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.05664%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESpeed%2Faccuracy+trade-offs+for+modern+convolutional+object+detectors%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Google+Research%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.10012%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.10012%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESqueezeDet%3A+Unified%2C+Small%2C+Low+Power+Fully+Convolutional+Neural+Networks+for+Real-Time+Object+Detection+for+Autonomous+Driving%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.01051%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.01051%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FBichenWuUCB%2FsqueezeDet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FBichenWuUCB%2FsqueezeDet%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ffregu856%2F2D_detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ffregu856%2F2D_detection%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22feature-pyramid-network-fpn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Feature+Pyramid+Network+%28FPN%29%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFeature+Pyramid+Networks+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Facebook+AI+Research%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.03144%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.03144%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAction-Driven+Object+Detection+with+Top-Down+Visual+Attentions%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.06704%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.06704%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EBeyond+Skip+Connections%3A+Top-Down+Modulation+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CMU+%26amp%3B+UC+Berkeley+%26amp%3B+Google+Research%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.06851%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.06851%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EWide-Residual-Inception+Networks+for+Real-time+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Inha+University%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.01243%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.01243%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAttentional+Network+for+Visual+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+University+of+Maryland+%26amp%3B+Mitsubishi+Electric+Research+Laboratories%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.01478%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.01478%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22cc-net%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+CC-Net%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+Chained+Deep+Features+and+Classifiers+for+Cascade+in+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+chained+cascade+network+%28CC-Net%29.+81.1%25+mAP+on+PASCAL+VOC+2007%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.07054%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.07054%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeNet%3A+Scalable+Real-time+Object+Detection+with+Directed+Sparse+Sampling%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.10295%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.10295%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDiscriminative+Bimodal+Networks+for+Visual+Localization+and+Detection+with+Natural+Language+Queries%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.03944%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.03944%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESpatial+Memory+for+Context+Reasoning+in+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.04224%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.04224%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAccurate+Single+Stage+Detector+Using+Recurrent+Rolling+Convolution%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017.+SenseTime%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+Recurrent+Rolling+Convolution+%28RRC%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.05776%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.05776%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FxiaohaoChen%2Frrc_detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FxiaohaoChen%2Frrc_detection%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Occlusion+Reasoning+for+Multi-Camera+Multi-Target+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.05775%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.05775%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ES-OHEM%3A+Stratified+Online+Hard+Example+Mining+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.02233%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.02233%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELCDet%3A+Low-Complexity+Fully-Convolutional+Neural+Networks+for+Object+Detection+in+Embedded+Systems%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Embedded+Vision+Workshop+in+CVPR.+UC+San+Diego+%26amp%3B+Qualcomm+Inc%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.05922%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.05922%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPoint+Linking+Network+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Point+Linking+Network+%28PLN%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.03646%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.03646%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPerceptual+Generative+Adversarial+Networks+for+Small+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.05274%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.05274%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFew-shot+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.08249%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.08249%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EYes-Net%3A+An+effective+Detector+Based+on+Global+Information%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.09180%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.09180%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESMC+Faster+R-CNN%3A+Toward+a+scene-specialized+multi-object+detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.10217%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.10217%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETowards+lightweight+convolutional+neural+networks+for+object+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.01395%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.01395%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ERON%3A+Reverse+Connection+with+Objectness+Prior+Networks+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.01691%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.01691%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ftaokong%2FRON%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ftaokong%2FRON%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EResidual+Features+and+Unified+Prediction+Network+for+Single+Stage+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.05031%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.05031%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeformable+Part-based+Fully+Convolutional+Network+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+BMVC+2017+%28oral%29.+Sorbonne+Universit%C3%A9s+%26amp%3B+CEDRIC%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.06175%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.06175%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAdaptive+Feeding%3A+Achieving+Fast+and+Accurate+Detections+by+Adaptively+Combining+Object+Detectors%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.06399%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.06399%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ERecurrent+Scale+Approximation+for+Object+Detection+in+CNN%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+Recurrent+Scale+Approximation+%28RSA%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.09531%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.09531%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fsciencefans%2FRSA-for-object-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fsciencefans%2FRSA-for-object-detection%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22dsod%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+DSOD%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDSOD%3A+Learning+Deeply+Supervised+Object+Detectors+from+Scratch%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22https%3A%2F%2Fuser-images.githubusercontent.com%2F3794909%2F28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017.+Fudan+University+%26amp%3B+Tsinghua+University+%26amp%3B+Intel+Labs+China%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.01241%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.01241%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fszq0214%2FDSOD%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fszq0214%2FDSOD%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFocal+Loss+for+Dense+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017+Best+student+paper+award.+Facebook+AI+Research%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+RetinaNet%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.02002%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.02002%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ECoupleNet%3A+Coupling+Global+Structure+with+Local+Parts+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.02863%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.02863%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EZoom+Out-and-In+Network+with+Map+Attention+Decision+for+Region+Proposal+and+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.04347%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.04347%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EStairNet%3A+Top-Down+Semantic+Aggregation+for+Accurate+One+Shot+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.05788%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.05788%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22nms%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+NMS%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEnd-to-End+Integration+of+a+Convolutional+Network%2C+Deformable+Parts+Model+and+Non-Maximum+Suppression%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1411.5309%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1411.5309%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2015%2Fpapers%2FWan_End-to-End_Integration_of_2015_CVPR_paper.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2015%2Fpapers%2FWan_End-to-End_Integration_of_2015_CVPR_paper.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+convnet+for+non-maximum+suppression%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1511.06437%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1511.06437%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EImproving+Object+Detection+With+One+Line+of+Code%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESoft-NMS+%E2%80%93+Improving+Object+Detection+With+One+Line+of+Code%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017.+University+of+Maryland%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+Soft-NMS%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.04503%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.04503%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fbharatsingh430%2Fsoft-nms%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fbharatsingh430%2Fsoft-nms%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+non-maximum+suppression%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.02950%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.02950%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22weakly-supervised-object-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Weakly+Supervised+Object+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETrack+and+Transfer%3A+Watching+Videos+to+Simulate+Strong+Human+Supervision+for+Weakly-Supervised+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1604.05766%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1604.05766%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EWeakly+supervised+object+detection+using+pseudo-strong+labels%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.04731%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.04731%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESaliency+Guided+End-to-End+Learning+for+Weakly+Supervised+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+IJCAI+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.06768%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.06768%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22detection-from-video%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Detection+From+Video%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+Object+Class+Detectors+from+Weakly+Annotated+Video%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2012%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fwww.vision.ee.ethz.ch%2Fpublications%2Fpapers%2Fproceedings%2Feth_biwi_00905.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fwww.vision.ee.ethz.ch%2Fpublications%2Fpapers%2Fproceedings%2Feth_biwi_00905.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAnalysing+domain+shift+factors+between+videos+and+images+for+object+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1501.01186%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1501.01186%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EVideo+Object+Recognition%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fvision.princeton.edu%2Fcourses%2FCOS598%2F2015sp%2Fslides%2FVideoRecog%2FVideo%2520Object%2520Recognition.pptx%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fvision.princeton.edu%2Fcourses%2FCOS598%2F2015sp%2Fslides%2FVideoRecog%2FVideo%2520Object%2520Recognition.pptx%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Learning+for+Saliency+Prediction+in+Natural+Video%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Submitted+on+12+Jan+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+Deep+learning%2C+saliency+map%2C+optical+flow%2C+convolution+network%2C+contrast+features%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhal.archives-ouvertes.fr%2Fhal-01251614%2Fdocument%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fhal.archives-ouvertes.fr%2Fhal-01251614%2Fdocument%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22t-cnn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+T-CNN%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ET-CNN%3A+Tubelets+with+Convolutional+Neural+Networks+for+Object+Detection+from+Videos%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Winning+solution+in+ILSVRC2015+Object+Detection+from+Video%28VID%29+Task%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1604.02532%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1604.02532%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fmyfavouritekk%2FT-CNN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fmyfavouritekk%2FT-CNN%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+Detection+from+Video+Tubelets+with+Convolutional+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016+Spotlight+paper%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1604.04053%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1604.04053%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%7Ewlouyang%2FPapers%2FKangVideoDet_CVPR16.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%7Ewlouyang%2FPapers%2FKangVideoDet_CVPR16.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egihtub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fmyfavouritekk%2Fvdetlib%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fmyfavouritekk%2Fvdetlib%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+Detection+in+Videos+with+Tubelets+and+Multi-context+Cues%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+SenseTime+Group%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%7Exgwang%2FCUvideo.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%7Exgwang%2FCUvideo.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks%2FObject%2520Detection%2520in%2520Videos%2520with%2520Tubelets%2520and%2520Multi-context%2520Cues%2520-%2520Final.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks%2FObject%2520Detection%2520in%2520Videos%2520with%2520Tubelets%2520and%2520Multi-context%2520Cues%2520-%2520Final.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EContext+Matters%3A+Refining+Object+Detection+in+Video+with+Recurrent+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+BMVC+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+pseudo-labeler%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.04648%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.04648%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fvision.cornell.edu%2Fse3%2Fwp-content%2Fuploads%2F2016%2F07%2Fvideo_object_detection_BMVC.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fvision.cornell.edu%2Fse3%2Fwp-content%2Fuploads%2F2016%2F07%2Fvideo_object_detection_BMVC.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ECNN+Based+Object+Detection+in+Large+Video+Images%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+WangTao+%40+%E7%88%B1%E5%A5%87%E8%89%BA%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+object+retrieval%2C+object+detection%2C+scene+classification%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fon-demand.gputechconf.com%2Fgtc%2F2016%2Fpresentation%2Fs6362-wang-tao-cnn-based-object-detection-large-video-images.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fon-demand.gputechconf.com%2Fgtc%2F2016%2Fpresentation%2Fs6362-wang-tao-cnn-based-object-detection-large-video-images.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+Detection+in+Videos+with+Tubelet+Proposal+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.06355%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.06355%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFlow-Guided+Feature+Aggregation+for+Video+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+MSRA%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.10025%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.10025%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EVideo+Object+Detection+using+Faster+R-CNN%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fandrewliao11.github.io%2Fobject_detection%2Ffaster_rcnn%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fandrewliao11.github.io%2Fobject_detection%2Ffaster_rcnn%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fandrewliao11%2Fpy-faster-rcnn-imagenet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fandrewliao11%2Fpy-faster-rcnn-imagenet%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EImproving+Context+Modeling+for+Video+Object+Detection+and+Tracking%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks_2017%2Filsvrc2017_short%28poster%29.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks_2017%2Filsvrc2017_short%28poster%29.pdf%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETemporal+Dynamic+Graph+LSTM+for+Action-driven+Video+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.00666%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.00666%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22object-detection-in-3d%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Object+Detection+in+3D%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EVote3Deep%3A+Fast+Object+Detection+in+3D+Point+Clouds+Using+Efficient+Convolutional+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1609.06666%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1609.06666%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22object-detection-on-rgb-d%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Object+Detection+on+RGB-D%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+Rich+Features+from+RGB-D+Images+for+Object+Detection+and+Segmentation%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1407.5736%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1407.5736%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDifferential+Geometry+Boosts+Convolutional+Neural+Networks+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016_workshops%2Fw23%2Fhtml%2FWang_Differential_Geometry_Boosts_CVPR_2016_paper.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016_workshops%2Fw23%2Fhtml%2FWang_Differential_Geometry_Boosts_CVPR_2016_paper.html%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Self-supervised+Learning+System+for+Object+Detection+using+Physics+Simulation+and+Multi-view+Pose+Estimation%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.03347%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.03347%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch1+id%3D%22salient-object-detection%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Salient+Object+Detection%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+This+task+involves+predicting+the+salient+regions+of+an+image+given+by+human+eye+fixations.%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EBest+Deep+Saliency+Detection+Models+%28CVPR+2016+%26amp%3B+2015%29%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fi.cs.hku.hk%2F%7Eyzyu%2Fvision.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fi.cs.hku.hk%2F%7Eyzyu%2Fvision.html%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELarge-scale+optimization+of+hierarchical+features+for+saliency+prediction+in+natural+images%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcoxlab.org%2Fpdfs%2Fcvpr2014_vig_saliency.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcoxlab.org%2Fpdfs%2Fcvpr2014_vig_saliency.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPredicting+Eye+Fixations+using+Convolutional+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.escience.cn%2Fsystem%2Ffile%3FfileId%3D72648%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.escience.cn%2Fsystem%2Ffile%3FfileId%3D72648%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESaliency+Detection+by+Multi-Context+Deep+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2015%2Fpapers%2FZhao_Saliency_Detection_by_2015_CVPR_paper.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2015%2Fpapers%2FZhao_Saliency_Detection_by_2015_CVPR_paper.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeepSaliency%3A+Multi-Task+Deep+Neural+Network+Model+for+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1510.05484%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1510.05484%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESuperCNN%3A+A+Superpixelwise+Convolutional+Neural+Network+for+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fwww.shengfenghe.com%2Fsupercnn-a-superpixelwise-convolutional-neural-network-for-salient-object-detection.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ewww.shengfenghe.com%2Fsupercnn-a-superpixelwise-convolutional-neural-network-for-salient-object-detection.html%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EShallow+and+Deep+Convolutional+Networks+for+Saliency+Prediction%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1603.00845%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1603.00845%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fimatge-upc%2Fsaliency-2016-cvpr%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fimatge-upc%2Fsaliency-2016-cvpr%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ERecurrent+Attentional+Networks+for+Saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016.+recurrent+attentional+convolutional-deconvolution+network+%28RACDNN%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1604.03227%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1604.03227%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETwo-Stream+Convolutional+Networks+for+Dynamic+Saliency+Prediction%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.04730%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.04730%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EUnconstrained+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EUnconstrained+Salient+Object+Detection+via+Proposal+Subset+Optimization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22http%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2Fimages%2Fpasted%2520image%25201465x373.jpg%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2Fsod.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2Fsod.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2FSOD%2FCVPR16SOD_camera_ready.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2FSOD%2FCVPR16SOD_camera_ready.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fjimmie33%2FSOD%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fjimmie33%2FSOD%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ecaffe+model+zoo%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FBVLC%2Fcaffe%2Fwiki%2FModel-Zoo%23cnn-object-proposal-models-for-salient-object-detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FBVLC%2Fcaffe%2Fwiki%2FModel-Zoo%23cnn-object-proposal-models-for-salient-object-detection%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDHSNet%3A+Deep+Hierarchical+Saliency+Network+for+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FLiu_DHSNet_Deep_Hierarchical_CVPR_2016_paper.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FLiu_DHSNet_Deep_Hierarchical_CVPR_2016_paper.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESalient+Object+Subitizing%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22http%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2Fimages%2Ffrontpage.png%3Fcrc%3D123070793%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+predicting+the+existence+and+the+number+of+salient+objects+in+an+image+using+holistic+cues%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2Fsos.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2Fsos.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.07525%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.07525%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2FSOS%2FSOS_preprint.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcs-people.bu.edu%2Fjmzhang%2FSOS%2FSOS_preprint.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ecaffe+model+zoo%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FBVLC%2Fcaffe%2Fwiki%2FModel-Zoo%23cnn-models-for-salient-object-subitizing%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FBVLC%2Fcaffe%2Fwiki%2FModel-Zoo%23cnn-models-for-salient-object-subitizing%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeeply-Supervised+Recurrent+Convolutional+Neural+Network+for+Saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ACMMM+2016.+deeply-supervised+recurrent+convolutional+neural+network+%28DSRCNN%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.05177%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.05177%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESaliency+Detection+via+Combining+Region-Level+and+Pixel-Level+Predictions+with+CNNs%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.05186%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.05186%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEdge+Preserving+and+Multi-Scale+Contextual+Neural+Network+for+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.08029%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.08029%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Deep+Multi-Level+Network+for+Saliency+Prediction%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1609.01064%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1609.01064%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EVisual+Saliency+Detection+Based+on+Multiscale+Deep+CNN+Features%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+IEEE+Transactions+on+Image+Processing%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1609.02077%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1609.02077%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Deep+Spatial+Contextual+Long-term+Recurrent+Convolutional+Network+for+Saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+DSCLRCN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1610.01708%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1610.01708%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeeply+supervised+salient+object+detection+with+short+connections%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.04849%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.04849%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EWeakly+Supervised+Top-down+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Nanyang+Technological+University%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.05345%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.05345%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESalGAN%3A+Visual+Saliency+Prediction+with+Generative+Adversarial+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fimatge-upc.github.io%2Fsaliency-salgan-2017%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fimatge-upc.github.io%2Fsaliency-salgan-2017%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1701.01081%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1701.01081%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EVisual+Saliency+Prediction+Using+a+Mixture+of+Deep+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.00372%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.00372%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Fast+and+Compact+Salient+Score+Regression+Network+Based+on+Fully+Convolutional+Network%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.00615%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.00615%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESaliency+Detection+by+Forward+and+Backward+Cues+in+Deep-CNNs%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.00152%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.00152%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESupervised+Adversarial+Networks+for+Image+Saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.07242%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.07242%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EGroup-wise+Deep+Co-saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.07381%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.07381%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETowards+the+Success+Rate+of+One%3A+Real-time+Unconstrained+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+University+of+Maryland+College+Park+%26amp%3B+eBay+Inc%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.00079%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.00079%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAmulet%3A+Aggregating+Multi-level+Convolutional+Features+for+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earixv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.02001%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.02001%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+Uncertain+Convolutional+Features+for+Accurate+Saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Accepted+as+a+poster+in+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.02031%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.02031%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Edge-Aware+Saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.04366%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.04366%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESelf-explanatory+Deep+Salient+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+National+University+of+Defense+Technology%2C+China+%26amp%3B+National+University+of+Singapore%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.05595%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.05595%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPiCANet%3A+Learning+Pixel-wise+Contextual+Attention+in+ConvNets+and+Its+Application+in+Saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.06433%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.06433%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeepFeat%3A+A+Bottom+Up+and+Top+Down+Saliency+Model+Based+on+Deep+Features+of+Convolutional+Neural+Nets%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.02495%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.02495%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22saliency-detection-in-video%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Saliency+Detection+in+Video%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Learning+For+Video+Saliency+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.00871%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.00871%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EVideo+Salient+Object+Detection+Using+Spatiotemporal+Deep+Features%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.01447%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.01447%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPredicting+Video+Saliency+with+Object-to-Motion+CNN+and+Two-layer+Convolutional+LSTM%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.06316%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.06316%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch1+id%3D%22visual-relationship-detection%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Visual+Relationship+Detection%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EVisual+Relationship+Detection+with+Language+Priors%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016+oral%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fcs.stanford.edu%2Fpeople%2Franjaykrishna%2Fvrd%2Fvrd.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fcs.stanford.edu%2Fpeople%2Franjaykrishna%2Fvrd%2Fvrd.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FProf-Lu-Cewu%2FVisual-Relationship-Detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FProf-Lu-Cewu%2FVisual-Relationship-Detection%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EViP-CNN%3A+A+Visual+Phrase+Reasoning+Convolutional+Neural+Network+for+Visual+Relationship+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Visual+Phrase+reasoning+Convolutional+Neural+Network+%28ViP-CNN%29%2C+Visual+Phrase+Reasoning+Structure+%28VPRS%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.07191%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.07191%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EVisual+Translation+Embedding+Network+for+Visual+Relation+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fwww.arxiv.org%2Fabs%2F1702.08319%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fwww.arxiv.org%2Fabs%2F1702.08319%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Variation-structured+Reinforcement+Learning+for+Visual+Relationship+and+Attribute+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017+spotlight+paper%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.03054%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.03054%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDetecting+Visual+Relationships+with+Deep+Relational+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017+oral.+The+Chinese+University+of+Hong+Kong%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.03114%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.03114%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EIdentifying+Spatial+Relations+in+Images+using+Convolutional+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.04215%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.04215%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPPR-FCN%3A+Weakly+Supervised+Visual+Relation+Detection+via+Parallel+Pairwise+R-FCN%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.01956%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.01956%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22specific-object-deteciton%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Specific+Object+Deteciton%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Deformation+Network+for+Object+Landmark+Localization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1605.01014%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1605.01014%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFashion+Landmark+Detection+in+the+Wild%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Elz013%2Fprojects%2FFashionLandmarks.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Elz013%2Fprojects%2FFashionLandmarks.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.03049%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.03049%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Caffe%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fliuziwei7%2Ffashion-landmarks%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fliuziwei7%2Ffashion-landmarks%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Learning+for+Fast+and+Accurate+Fashion+Item+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Kuznech+Inc.%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+MultiBox+and+Fast+R-CNN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fkddfashion2016.mybluemix.net%2Fkddfashion_finalSubmissions%2FDeep%2520Learning%2520for%2520Fast%2520and%2520Accurate%2520Fashion%2520Item%2520Detection.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fkddfashion2016.mybluemix.net%2Fkddfashion_finalSubmissions%2FDeep%2520Learning%2520for%2520Fast%2520and%2520Accurate%2520Fashion%2520Item%2520Detection.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EOSMDeepOD+-+OSM+and+Deep+Learning+based+Object+Detection+from+Aerial+Imagery+%28formerly+known+as+%E2%80%9COSM-Crosswalk-Detection%E2%80%9D%29%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22https%3A%2F%2Fraw.githubusercontent.com%2Fgeometalab%2FOSMDeepOD%2Fmaster%2Fimgs%2Fprocess.png%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fgeometalab%2FOSMDeepOD%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fgeometalab%2FOSMDeepOD%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESelfie+Detection+by+Synergy-Constraint+Based+Convolutional+Neural+Network%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+IEEE+SITIS+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.04357%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.04357%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAssociative+Embedding%3AEnd-to-End+Learning+for+Joint+Detection+and+Grouping%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.05424%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.05424%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Cuboid+Detection%3A+Beyond+2D+Bounding+Boxes%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CMU+%26amp%3B+Magic+Leap%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.10010%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.10010%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAutomatic+Model+Based+Dataset+Generation+for+Fast+and+Accurate+Crop+and+Weeds+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.03019%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.03019%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Learning+Logo+Detection+with+Data+Expansion+by+Synthesising+Context%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.09322%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.09322%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPixel-wise+Ear+Detection+with+Convolutional+Encoder-Decoder+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.00307%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.00307%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAutomatic+Handgun+Detection+Alarm+in+Videos+Using+Deep+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.05147%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.05147%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eresults%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FSihamTabik%2FPistol-Detection-in-Videos%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FSihamTabik%2FPistol-Detection-in-Videos%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EUsing+Deep+Networks+for+Drone+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+AVSS+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.05726%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.05726%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ECut%2C+Paste+and+Learn%3A+Surprisingly+Easy+Synthesis+for+Instance+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.01642%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.01642%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeepVoting%3A+An+Explainable+Framework+for+Semantic+Part+Detection+under+Partial+Occlusion%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.04577%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.04577%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFast+Shadow+Detection+from+a+Single+Image+Using+a+Patched+Convolutional+Neural+Network%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.09283%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.09283%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22face-deteciton%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Face+Deteciton%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EMulti-view+Face+Detection+Using+Deep+Convolutional+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Yahoo%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1502.02766%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1502.02766%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fguoyilin%2FFaceDetection_CNN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fguoyilin%2FFaceDetection_CNN%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFrom+Facial+Parts+Responses+to+Face+Detection%3A+A+Deep+Learning+Approach%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22http%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Eys014%2Fprojects%2FFaceness%2Fsupport%2Findex.png%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015.+CUHK%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Eys014%2Fprojects%2FFaceness%2FFaceness.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Eys014%2Fprojects%2FFaceness%2FFaceness.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1509.06451%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1509.06451%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_iccv_2015%2Fpapers%2FYang_From_Facial_Parts_ICCV_2015_paper.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_iccv_2015%2Fpapers%2FYang_From_Facial_Parts_ICCV_2015_paper.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ECompact+Convolutional+Neural+Network+Cascade+for+Face+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1508.01292%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1508.01292%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FBkmz21%2FFD-Evaluation%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FBkmz21%2FFD-Evaluation%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FBkmz21%2FCompactCNNCascade%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FBkmz21%2FCompactCNNCascade%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFace+Detection+with+End-to-End+Integration+of+a+ConvNet+and+a+3D+Model%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1606.00850%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1606.00850%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28MXNet%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ftfwu%2FFaceDetection-ConvNet-3D%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ftfwu%2FFaceDetection-ConvNet-3D%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ECMS-RCNN%3A+Contextual+Multi-Scale+Region-based+CNN+for+Unconstrained+Face+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CMU%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1606.05413%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1606.05413%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFinding+Tiny+Faces%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017.+CMU%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cs.cmu.edu%2F%7Epeiyunh%2Ftiny%2Findex.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cs.cmu.edu%2F%7Epeiyunh%2Ftiny%2Findex.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.04402%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.04402%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fpeiyunh%2Ftiny%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fpeiyunh%2Ftiny%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28inference-only%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fchinakook%2Fhr101_mxnet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fchinakook%2Fhr101_mxnet%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETowards+a+Deep+Learning+Framework+for+Unconstrained+Face+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+overlap+with+CMS-RCNN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.05322%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.05322%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESupervised+Transformer+Network+for+Efficient+Face+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.05477%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.05477%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch3+id%3D%22unitbox%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A18px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+UnitBox%3C%2Fh3%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EUnitBox%3A+An+Advanced+Object+Detection+Network%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ACM+MM+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.01471%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.01471%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EBootstrapping+Face+Detection+with+Hard+Negative+Examples%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eauthor%3A+%E4%B8%87%E9%9F%B6%E5%8D%8E+%40+%E5%B0%8F%E7%B1%B3.%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Faster+R-CNN%2C+hard+negative+mining.+state-of-the-art+on+the+FDDB+dataset%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.02236%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.02236%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EGrid+Loss%3A+Detecting+Occluded+Faces%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1609.00129%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1609.00129%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Flrs.icg.tugraz.at%2Fpubs%2Fopitz_eccv_16.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Flrs.icg.tugraz.at%2Fpubs%2Fopitz_eccv_16.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eposter%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.eccv2016.org%2Ffiles%2Fposters%2FP-2A-34.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.eccv2016.org%2Ffiles%2Fposters%2FP-2A-34.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Multi-Scale+Cascade+Fully+Convolutional+Network+Face+Detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICPR+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1609.03536%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1609.03536%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch3+id%3D%22mtcnn%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A18px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+MTCNN%3C%2Fh3%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EJoint+Face+Detection+and+Alignment+using+Multi-task+Cascaded+Convolutional+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EJoint+Face+Detection+and+Alignment+using+Multi-task+Cascaded+Convolutional+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22https%3A%2F%2Fkpzhang93.github.io%2FMTCNN_face_detection_alignment%2Fsupport%2Findex.png%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fkpzhang93.github.io%2FMTCNN_face_detection_alignment%2Findex.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fkpzhang93.github.io%2FMTCNN_face_detection_alignment%2Findex.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1604.02878%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1604.02878%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Matlab%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fkpzhang93%2FMTCNN_face_detection_alignment%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fkpzhang93%2FMTCNN_face_detection_alignment%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fpangyupo%2Fmxnet_mtcnn_face_detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fpangyupo%2Fmxnet_mtcnn_face_detection%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FDaFuCoding%2FMTCNN_Caffe%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FDaFuCoding%2FMTCNN_Caffe%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28MXNet%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FSeanlinx%2Fmtcnn%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FSeanlinx%2Fmtcnn%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FPi-DeepLearning%2FRaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FPi-DeepLearning%2FRaspberryPi-FaceDetection-MTCNN-Caffe-With-Motion%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Caffe%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FforeverYoungGitHub%2FMTCNN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FforeverYoungGitHub%2FMTCNN%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FCongWeilin%2Fmtcnn-caffe%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FCongWeilin%2Fmtcnn-caffe%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FAlphaQi%2FMTCNN-light%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FAlphaQi%2FMTCNN-light%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFace+Detection+using+Deep+Learning%3A+An+Improved+Faster+RCNN+Approach%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+DeepIR+Inc%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1701.08289%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1701.08289%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFaceness-Net%3A+Face+Detection+through+Deep+Facial+Part+Responses%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+An+extended+version+of+ICCV+2015+paper%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1701.08393%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1701.08393%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EMulti-Path+Region-Based+Convolutional+Neural+Network+for+Accurate+Detection+of+Unconstrained+%E2%80%9CHard+Faces%E2%80%9D%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017.+MP-RCNN%2C+MP-RPN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.09145%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.09145%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEnd-To-End+Face+Detection+and+Recognition%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.10818%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.10818%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFace+R-CNN%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.01061%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.01061%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFace+Detection+through+Scale-Friendly+Deep+Convolutional+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.02863%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.02863%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EScale-Aware+Face+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017.+SenseTime+%26amp%3B+Tsinghua+University%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.09876%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.09876%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EMulti-Branch+Fully+Convolutional+Network+for+Face+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.06330%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.06330%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESSH%3A+Single+Stage+Headless+Face+Detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.03979%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.03979%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDockerface%3A+an+easy+to+install+and+use+Faster+R-CNN+face+detector+in+a+Docker+container%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.04370%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.04370%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFaceBoxes%3A+A+CPU+Real-time+Face+Detector+with+High+Accuracy%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+IJCB+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+Rapidly+Digested+Convolutional+Layers+%28RDCL%29%2C+Multiple+Scale+Convolutional+Layers+%28MSCL%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+the+proposed+detector+runs+at+20+FPS+on+a+single+CPU+core+and+125+FPS+using+a+GPU+for+VGA-resolution+images%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.05234%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.05234%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ES3FD%3A+Single+Shot+Scale-invariant+Face+Detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+can+run+at+36+FPS+on+a+Nvidia+Titan+X+%28Pascal%29+for+VGA-resolution+images%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.05237%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.05237%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDetecting+Faces+Using+Region-based+Fully+Convolutional+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.05256%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.05256%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAffordanceNet%3A+An+End-to-End+Deep+Learning+Approach+for+Object+Affordance+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.07326%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.07326%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22facial-point--landmark-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Facial+Point+%2F+Landmark+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Convolutional+Network+Cascade+for+Facial+Point+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22http%3A%2F%2Fmmlab.ie.cuhk.edu.hk%2Farchive%2FCNN%2Fdata%2FPicture1.png%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ehomepage%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fmmlab.ie.cuhk.edu.hk%2Farchive%2FCNN_FacePoint.htm%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fmmlab.ie.cuhk.edu.hk%2Farchive%2FCNN_FacePoint.htm%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%7Exgwang%2Fpapers%2FsunWTcvpr13.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%7Exgwang%2Fpapers%2FsunWTcvpr13.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fluoyetx%2Fdeep-landmark%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fluoyetx%2Fdeep-landmark%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFacial+Landmark+Detection+by+Deep+Multi-task+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2014%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fmmlab.ie.cuhk.edu.hk%2Fprojects%2FTCDCN.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fmmlab.ie.cuhk.edu.hk%2Fprojects%2FTCDCN.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Eccloy%2Ffiles%2Feccv_2014_deepfacealign.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Eccloy%2Ffiles%2Feccv_2014_deepfacealign.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Matlab%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fzhzhanp%2FTCDCN-face-alignment%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fzhzhanp%2FTCDCN-face-alignment%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Recurrent+Encoder-Decoder+Network+for+Sequential+Face+Alignment%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1608.05477%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1608.05477%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDetecting+facial+landmarks+in+the+video+based+on+a+hybrid+framework%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1609.06441%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1609.06441%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Constrained+Local+Models+for+Facial+Landmark+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.08657%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.08657%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEffective+face+landmark+localization+via+single+deep+network%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.02719%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.02719%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Convolution+Tree+with+Deconvolution+Branches%3A+Exploiting+Geometric+Relationships+for+Single+Shot+Keypoint+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.01880%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.01880%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Alignment+Network%3A+A+convolutional+neural+network+for+robust+face+alignment%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPRW+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.01789%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.01789%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egihtub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FMarekKowalski%2FDeepAlignmentNetwork%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FMarekKowalski%2FDeepAlignmentNetwork%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EJoint+Multi-view+Face+Alignment+in+the+Wild%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.06023%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.06023%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFacePoseNet%3A+Making+a+Case+for+Landmark-Free+Face+Alignment%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.07517%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.07517%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch1+id%3D%22people-detection%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+People+Detection%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEnd-to-end+people+detection+in+crowded+scenes%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22https%3A%2F%2Fhandong1587.github.io%2Fassets%2Fobject-detection-materials%2Fend_to_end_people_detection_in_crowded_scenes.jpg%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1506.04878%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1506.04878%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FRussell91%2Freinspect%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FRussell91%2Freinspect%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eipn%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fnbviewer.ipython.org%2Fgithub%2FRussell91%2FReInspect%2Fblob%2Fmaster%2Fevaluation_reinspect.ipynb%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fnbviewer.ipython.org%2Fgithub%2FRussell91%2FReInspect%2Fblob%2Fmaster%2Fevaluation_reinspect.ipynb%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eyoutube%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DQeWl0h3kQ24%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DQeWl0h3kQ24%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDetecting+People+in+Artwork+with+CNNs%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016+Workshops%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1610.08871%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1610.08871%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Multi-camera+People+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.04593%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.04593%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22person-head-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Person+Head+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EContext-aware+CNNs+for+person+head+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.di.ens.fr%2Fwillow%2Fresearch%2Fheaddetection%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.di.ens.fr%2Fwillow%2Fresearch%2Fheaddetection%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1511.07917%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1511.07917%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Faosokin%2Fcnn_head_detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Faosokin%2Fcnn_head_detection%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22pedestrian-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Pedestrian+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPedestrian+Detection+aided+by+Deep+Learning+Semantic+Tasks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fmmlab.ie.cuhk.edu.hk%2Fprojects%2FTA-CNN%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fmmlab.ie.cuhk.edu.hk%2Fprojects%2FTA-CNN%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1412.0069%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1412.0069%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Learning+Strong+Parts+for+Pedestrian+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015.+CUHK.+DeepParts%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Achieving+11.89%25+average+miss+rate+on+Caltech+Pedestrian+Dataset%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Epluo%2Fpdf%2FtianLWTiccv15.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fpersonal.ie.cuhk.edu.hk%2F%7Epluo%2Fpdf%2FtianLWTiccv15.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETaking+a+Deeper+Look+at+Pedestrians%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1501.05790%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1501.05790%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EConvolutional+Channel+Features%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1504.07339%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1504.07339%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fbyangderek%2FCCF%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fbyangderek%2FCCF%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+Complexity-Aware+Cascades+for+Deep+Pedestrian+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1507.05348%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1507.05348%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+convolutional+neural+networks+for+pedestrian+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1510.03608%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1510.03608%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FDenisTome%2FDeepPed%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FDenisTome%2FDeepPed%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EScale-aware+Fast+R-CNN+for+Pedestrian+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1510.08160%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1510.08160%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ENew+algorithm+improves+speed+and+accuracy+of+pedestrian+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.eurekalert.org%2Fpub_releases%2F2016-02%2Fuoc--nai020516.php%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.eurekalert.org%2Fpub_releases%2F2016-02%2Fuoc%E2%80%93nai020516.php%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPushing+the+Limits+of+Deep+CNNs+for+Pedestrian+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+%E2%80%9Cset+a+new+record+on+the+Caltech+pedestrian+dataset%2C+lowering+the+log-average+miss+rate+from+11.7%25+to+8.9%25%E2%80%9D%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1603.04525%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1603.04525%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Real-Time+Deep+Learning+Pedestrian+Detector+for+Robot+Navigation%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.04436%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.04436%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EA+Real-Time+Pedestrian+Detector+using+Deep+Learning+for+Human-Aware+Navigation%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.04441%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.04441%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EIs+Faster+R-CNN+Doing+Well+for+Pedestrian+Detection%3F%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.07032%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.07032%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fzhangliliang%2FRPN_BF%2Ftree%2FRPN-pedestrian%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fzhangliliang%2FRPN_BF%2Ftree%2FRPN-pedestrian%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EReduced+Memory+Region+Based+Deep+Convolutional+Neural+Network+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+IEEE+2016+ICCE-Berlin%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1609.02500%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1609.02500%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFused+DNN%3A+A+deep+neural+network+fusion+approach+to+fast+and+robust+pedestrian+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1610.03466%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1610.03466%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EMultispectral+Deep+Neural+Networks+for+Pedestrian+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+BMVC+2016+oral%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1611.02644%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1611.02644%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EExpecting+the+Unexpected%3A+Training+Detectors+for+Unusual+Pedestrians+with+Adversarial+Imposters%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fml.cs.tsinghua.edu.cn%3A5000%2Fpublications%2Fsynunity%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fml.cs.tsinghua.edu.cn%3A5000%2Fpublications%2Fsynunity%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.06283%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.06283%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Tensorflow%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fhuangshiyu13%2FRPNplus%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fhuangshiyu13%2FRPNplus%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EIlluminating+Pedestrians+via+Simultaneous+Detection+%26amp%3B+Segmentation%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%5Bhttps%3A%2F%2Farxiv.org%2Fabs%2F1706.08564%5D%28https%3A%2F%2Farxiv.org%2Fabs%2F1706.08564%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ERotational+Rectification+Network+for+Robust+Pedestrian+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CMU+%26amp%3B+Volvo+Construction%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.08917%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.08917%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESTD-PD%3A+Generating+Synthetic+Training+Data+for+Pedestrian+Detection+in+Unannotated+Videos%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+The+University+of+North+Carolina+at+Chapel+Hill%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.09100%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.09100%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EToo+Far+to+See%3F+Not+Really%21+%E2%80%94+Pedestrian+Detection+with+Scale-aware+Localization+Policy%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.00235%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.00235%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22vehicle-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Vehicle+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDAVE%3A+A+Unified+Framework+for+Fast+Vehicle+Detection+and+Annotation%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.04564%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.04564%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEvolving+Boxes+for+fast+Vehicle+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.00254%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.00254%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFine-Grained+Car+Detection+for+Visual+Census+Estimation%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+AAAI+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.02480%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.02480%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22traffic-sign-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Traffic-Sign+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETraffic-Sign+Detection+and+Classification+in+the+Wild%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%28code%2Bdataset%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcg.cs.tsinghua.edu.cn%2Ftraffic-sign%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcg.cs.tsinghua.edu.cn%2Ftraffic-sign%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FZhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_cvpr_2016%2Fpapers%2FZhu_Traffic-Sign_Detection_and_CVPR_2016_paper.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ecode+%26amp%3B+model%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcg.cs.tsinghua.edu.cn%2Ftraffic-sign%2Fdata_model_code%2Fnewdata0411.zip%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcg.cs.tsinghua.edu.cn%2Ftraffic-sign%2Fdata_model_code%2Fnewdata0411.zip%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDetecting+Small+Signs+from+Large+Images%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+IEEE+Conference+on+Information+Reuse+and+Integration+%28IRI%29+2017+oral%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.08574%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.08574%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22boundary--edge--contour-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Boundary+%2F+Edge+%2F+Contour+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EHolistically-Nested+Edge+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2Fda32e7e3275c2a9693dd2a6925b03a1151e2b098%2F687474703a2f2f70616765732e756373642e6564752f7e7a74752f6865642e6a7067%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015%2C+Marr+Prize%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_iccv_2015%2Fpapers%2FXie_Holistically-Nested_Edge_Detection_ICCV_2015_paper.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.cv-foundation.org%2Fopenaccess%2Fcontent_iccv_2015%2Fpapers%2FXie_Holistically-Nested_Edge_Detection_ICCV_2015_paper.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1504.06375%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1504.06375%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fs9xie%2Fhed%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fs9xie%2Fhed%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EUnsupervised+Learning+of+Edges%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016.+Facebook+AI+Research%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1511.04166%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1511.04166%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ezn-blog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.leiphone.com%2Fnews%2F201607%2Fb1trsg9j6GSMnjOP.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.leiphone.com%2Fnews%2F201607%2Fb1trsg9j6GSMnjOP.html%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EPushing+the+Boundaries+of+Boundary+Detection+using+Deep+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1511.07386%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1511.07386%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EConvolutional+Oriented+Boundaries%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.02755%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.02755%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EConvolutional+Oriented+Boundaries%3A+From+Image+Segmentation+to+High-Level+Tasks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.vision.ee.ethz.ch%2F%7Ecvlsegmentation%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.vision.ee.ethz.ch%2F%7Ecvlsegmentation%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1701.04658%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1701.04658%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fkmaninis%2FCOB%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fkmaninis%2FCOB%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ERicher+Convolutional+Features+for+Edge+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+richer+convolutional+features+%28RCF%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.02103%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.02103%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fyun-liu%2Frcf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fyun-liu%2Frcf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EContour+Detection+from+Deep+Patch-level+Boundary+Prediction%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.03159%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.03159%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ECASENet%3A+Deep+Category-Aware+Semantic+Edge+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.09759%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.09759%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22skeleton-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Skeleton+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+Skeleton+Extraction+in+Natural+Images+by+Fusing+Scale-associated+Deep+Side+Outputs%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2F88a65f132aa4ae4b0477e3ad02c13cdc498377d9%2F687474703a2f2f37786e37777a2e636f6d312e7a302e676c622e636c6f7564646e2e636f6d2f44656570536b656c65746f6e2e706e673f696d61676556696577322f322f772f353030%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1603.09446%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1603.09446%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fzeakey%2FDeepSkeleton%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fzeakey%2FDeepSkeleton%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeepSkeleton%3A+Learning+Multi-task+Scale-associated+Deep+Side+Outputs+for+Object+Skeleton+Extraction+in+Natural+Images%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1609.03659%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1609.03659%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESRN%3A+Side-output+Residual+Network+for+Object+Symmetry+Detection+in+the+Wild%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.02243%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.02243%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FKevinKecc%2FSRN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FKevinKecc%2FSRN%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22fruit-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Fruit+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Fruit+Detection+in+Orchards%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1610.03677%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1610.03677%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EImage+Segmentation+for+Fruit+Detection+and+Yield+Estimation+in+Apple+Orchards%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+The+Journal+of+Field+Robotics+in+May+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fconfluence.acfr.usyd.edu.au%2Fdisplay%2FAGPub%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fconfluence.acfr.usyd.edu.au%2Fdisplay%2FAGPub%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1610.08120%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1610.08120%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22part-detection%22+class%3D%22clickable-header%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+font-size%3A20px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Part+Detection%3C%2Fh2%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObjects+as+context+for+part+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.09529%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.09529%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch1+id%3D%22object-proposal%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Object+Proposal%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeepProposal%3A+Hunting+Objects+by+Cascading+Deep+Convolutional+Layers%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1510.04445%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1510.04445%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Faghodrati%2Fdeepproposal%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Faghodrati%2Fdeepproposal%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EScale-aware+Pixel-wise+Object+Proposal+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+IEEE+Transactions+on+Image+Processing%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1601.04798%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1601.04798%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAttend+Refine+Repeat%3A+Active+Box+Proposal+Generation+via+In-Out+Localization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+BMVC+2016.+AttractioNet%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1606.04446%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1606.04446%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fgidariss%2FAttractioNet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fgidariss%2FAttractioNet%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+to+Segment+Object+Proposals+via+Recursive+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.01057%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.01057%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+Detection+with+Diverse+Proposals%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+differentiable+Determinantal+Point+Process+%28DPP%29+layer%2C+Learning+Detection+with+Diverse+Proposals+%28LDDP%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.03533%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.03533%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EScaleNet%3A+Guiding+Object+Proposal+Generation+in+Supermarkets+and+Beyond%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+product+detection%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.06752%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.06752%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EImproving+Small+Object+Proposals+for+Company+Logo+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICMR+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.08881%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.08881%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22localization%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Localization%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EBeyond+Bounding+Boxes%3A+Precise+Localization+of+Objects+in+Images%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+PhD+Thesis%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ehomepage%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.eecs.berkeley.edu%2FPubs%2FTechRpts%2F2015%2FEECS-2015-193.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.eecs.berkeley.edu%2FPubs%2FTechRpts%2F2015%2FEECS-2015-193.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ephd-thesis%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.eecs.berkeley.edu%2FPubs%2FTechRpts%2F2015%2FEECS-2015-193.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.eecs.berkeley.edu%2FPubs%2FTechRpts%2F2015%2FEECS-2015-193.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28%E2%80%9CSDS+using+hypercolumns%E2%80%9D%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fbharath272%2Fsds%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fbharath272%2Fsds%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EWeakly+Supervised+Object+Localization+with+Multi-fold+Multiple+Instance+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1503.00949%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1503.00949%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EWeakly+Supervised+Object+Localization+Using+Size+Estimates%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1608.04314%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1608.04314%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EActive+Object+Localization+with+Deep+Reinforcement+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2015%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+Markov+Decision+Process%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1511.06015%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1511.06015%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELocalizing+objects+using+referring+expressions%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+LSTM%2C+multiple+instance+learning+%28MIL%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epaper%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.umiacs.umd.edu%2F%7Evarun%2Ffiles%2Frefexp-ECCV16.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.umiacs.umd.edu%2F%7Evarun%2Ffiles%2Frefexp-ECCV16.pdf%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fvarun-nagaraja%2Freferring-expressions%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fvarun-nagaraja%2Freferring-expressions%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELocNet%3A+Improving+Localization+Accuracy+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+CVPR+2016+oral%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1511.07763%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1511.07763%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fgidariss%2FLocNet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fgidariss%2FLocNet%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ELearning+Deep+Features+for+Discriminative+Localization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22http%3A%2F%2Fcnnlocalization.csail.mit.edu%2Fframework.jpg%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ehomepage%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fcnnlocalization.csail.mit.edu%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fcnnlocalization.csail.mit.edu%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1512.04150%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1512.04150%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%28Tensorflow%29%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fjazzsaxmafia%2FWeakly_detector%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fjazzsaxmafia%2FWeakly_detector%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fmetalbubble%2FCAM%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fmetalbubble%2FCAM%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ftdeboissiere%2FVGG16CAM-keras%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ftdeboissiere%2FVGG16CAM-keras%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EContextLocNet%3A+Context-Aware+Deep+Network+Models+for+Weakly+Supervised+Localization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cimg+src%3D%22http%3A%2F%2Fwww.di.ens.fr%2Fwillow%2Fresearch%2Fcontextlocnet%2Fmodel.png%22+alt%3D%22%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+position%3Arelative%3B+max-width%3A100%25%22%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ECCV+2016%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eproject+page%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fwww.di.ens.fr%2Fwillow%2Fresearch%2Fcontextlocnet%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fwww.di.ens.fr%2Fwillow%2Fresearch%2Fcontextlocnet%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1609.04331%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1609.04331%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fvadimkantorov%2Fcontextlocnet%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fvadimkantorov%2Fcontextlocnet%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEnsemble+of+Part+Detectors+for+Simultaneous+Classification+and+Localization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.10034%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.10034%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESTNet%3A+Selective+Tuning+of+Convolutional+Networks+for+Object+Localization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.06418%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.06418%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESoft+Proposal+Networks+for+Weakly+Supervised+Object+Localization%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ICCV+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.01829%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.01829%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFine-grained+Discriminative+Localization+via+Saliency-guided+Faster+R-CNN%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+ACM+MM+2017%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Earxiv%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.08295%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.08295%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22tutorials--talks%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Tutorials+%2F+Talks%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EConvolutional+Feature+Maps%3A+Elements+of+efficient+%28and+accurate%29+CNN-based+object+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Fkahe%2Ficcv15tutorial%2Ficcv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Fkahe%2Ficcv15tutorial%2Ficcv2015_tutorial_convolutional_feature_maps_kaiminghe.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETowards+Good+Practices+for+Recognition+%26amp%3B+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Hikvision+Research+Institute.+Supervised+Data+Augmentation+%28SDA%29%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eslides%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks%2F2016%2FHikvision_at_ImageNet_2016.pdf%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fimage-net.org%2Fchallenges%2Ftalks%2F2016%2FHikvision_at_ImageNet_2016.pdf%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22projects%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Projects%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ETensorBox%3A+a+simple+framework+for+training+neural+networks+to+detect+objects+in+images%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+%E2%80%9CThe+basic+model+implements+the+simple+and+robust+GoogLeNet-OverFeat+algorithm.+We+additionally+provide+an+implementation+of+the%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FRussell91%2FReInspect%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3EReInspect%3C%2Fa%3E%26nbsp%3Balgorithm%E2%80%9D%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FRussell91%2FTensorBox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FRussell91%2FTensorBox%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+detection+in+torch%3A+Implementation+of+some+object+detection+frameworks+in+torch%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ffmassa%2Fobject-detection.torch%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ffmassa%2Fobject-detection.torch%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EUsing+DIGITS+to+train+an+Object+Detection+network%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FNVIDIA%2FDIGITS%2Fblob%2Fmaster%2Fexamples%2Fobject-detection%2FREADME.md%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FNVIDIA%2FDIGITS%2Fblob%2Fmaster%2Fexamples%2Fobject-detection%2FREADME.md%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFCN-MultiBox+Detector%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+Full+convolution+MultiBox+Detector+%28like+SSD%29+implemented+in+Torch.%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fteaonly%2FFMD.torch%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fteaonly%2FFMD.torch%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EKittiBox%3A+A+car+detection+model+implemented+in+Tensorflow.%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+MultiNet%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+KittiBox+is+a+collection+of+scripts+to+train+out+model+FastBox+on+the+Kitti+Object+Detection+Dataset%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FMarvinTeichmann%2FKittiBox%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FMarvinTeichmann%2FKittiBox%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeformable+Convolutional+Networks+%2B+MST+%2B+Soft-NMS%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fbharatsingh430%2FDeformable-ConvNets%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fbharatsingh430%2FDeformable-ConvNets%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Ch1+id%3D%22tools%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Tools%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EBeaverDam%3A+Video+annotation+tool+for+deep+learning+training+labels%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fantingshen%2FBeaverDam%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fantingshen%2FBeaverDam%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch1+id%3D%22blogs%22+class%3D%22clickable-header+top-level-header%22+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px%3B+font-size%3A22px%3B+color%3Argb%2877%2C77%2C77%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+Blogs%3C%2Fh1%3E+%0A++%3Cspan+class%3D%22icon-arrow-up+back-to-top%22+style%3D%22%22%3E%3C%2Fspan%3E%0A++%3Cspan+style%3D%22font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E%3C%2Fspan%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EConvolutional+Neural+Networks+for+Object+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Frnd.azoft.com%2Fconvolutional-neural-networks-object-detection%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Frnd.azoft.com%2Fconvolutional-neural-networks-object-detection%2F%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EIntroducing+automatic+object+detection+to+visual+search+%28Pinterest%29%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+Faster+R-CNN%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fengineering.pinterest.com%2Fblog%2Fintroducing-automatic-object-detection-visual-search%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fengineering.pinterest.com%2Fblog%2Fintroducing-automatic-object-detection-visual-search%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Edemo%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fengineering.pinterest.com%2Fsites%2Fengineering%2Ffiles%2FVisual%2520Search%2520V1%2520-%2520Video.mp4%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fengineering.pinterest.com%2Fsites%2Fengineering%2Ffiles%2FVisual%2520Search%2520V1%2520-%2520Video.mp4%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ereview%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fnews.developer.nvidia.com%2Fpinterest-introduces-the-future-of-visual-search%2F%3Fmkt_tok%3DeyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%253D%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fnews.developer.nvidia.com%2Fpinterest-introduces-the-future-of-visual-search%2F%3Fmkt_tok%3DeyJpIjoiTnpaa01UWXpPRE0xTURFMiIsInQiOiJJRjcybjkwTmtmallORUhLOFFFODBDclFqUlB3SWlRVXJXb1MrQ013TDRIMGxLQWlBczFIeWg0TFRUdnN2UHY2ZWFiXC9QQVwvQzBHM3B0UzBZblpOSmUyU1FcLzNPWXI4cml2VERwTTJsOFwvOEk9In0%253D%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EDeep+Learning+for+Object+Detection+with+DIGITS%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fdevblogs.nvidia.com%2Fparallelforall%2Fdeep-learning-object-detection-digits%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fdevblogs.nvidia.com%2Fparallelforall%2Fdeep-learning-object-detection-digits%2F%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EAnalyzing+The+Papers+Behind+Facebook%E2%80%99s+Computer+Vision+Approach%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Ekeywords%3A+DeepMask%2C+SharpMask%2C+MultiPathNet%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fadeshpande3.github.io%2Fadeshpande3.github.io%2FAnalyzing-the-Papers-Behind-Facebook%27+rel%3D%22+nofollow%22s-computer-vision-approach+%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fadeshpande3.github.io%2Fadeshpande3.github.io%2FAnalyzing-the-Papers-Behind-Facebook%E2%80%99s-Computer-Vision-Approach%2F%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EEasily+Create+High+Quality+Object+Detectors+with+Deep+Learning%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eintro%3A+dlib+v19.2%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22http%3A%2F%2Fblog.dlib.net%2F2016%2F10%2Feasily-create-high-quality-object.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttp%3A%2F%2Fblog.dlib.net%2F2016%2F10%2Feasily-create-high-quality-object.html%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EHow+to+Train+a+Deep-Learned+Object+Detection+Model+in+the+Microsoft+Cognitive+Toolkit%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fblogs.technet.microsoft.com%2Fmachinelearning%2F2016%2F10%2F25%2Fhow-to-train-a-deep-learned-object-detection-model-in-cntk%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fblogs.technet.microsoft.com%2Fmachinelearning%2F2016%2F10%2F25%2Fhow-to-train-a-deep-learned-object-detection-model-in-cntk%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2FMicrosoft%2FCNTK%2Ftree%2Fmaster%2FExamples%2FImage%2FDetection%2FFastRCNN%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2FMicrosoft%2FCNTK%2Ftree%2Fmaster%2FExamples%2FImage%2FDetection%2FFastRCNN%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EObject+Detection+in+Satellite+Imagery%2C+a+Low+Overhead+Approach%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epart+1%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fmedium.com%2Fthe-downlinq%2Fobject-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7%23.2csh4iwx9%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fmedium.com%2Fthe-downlinq%2Fobject-detection-in-satellite-imagery-a-low-overhead-approach-part-i-cbd96154a1b7%23.2csh4iwx9%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epart+2%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fmedium.com%2Fthe-downlinq%2Fobject-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92%23.f9b7dgf64%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fmedium.com%2Fthe-downlinq%2Fobject-detection-in-satellite-imagery-a-low-overhead-approach-part-ii-893f40122f92%23.f9b7dgf64%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EYou+Only+Look+Twice%E2%80%8A%E2%80%94%E2%80%8AMulti-Scale+Object+Detection+in+Satellite+Imagery+With+Convolutional+Neural+Networks%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epart+1%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fmedium.com%2Fthe-downlinq%2Fyou-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571%23.fmmi2o3of%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fmedium.com%2Fthe-downlinq%2Fyou-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-38dad1cf7571%23.fmmi2o3of%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Epart+2%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fmedium.com%2Fthe-downlinq%2Fyou-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588%23.nwzarsz1t%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fmedium.com%2Fthe-downlinq%2Fyou-only-look-twice-multi-scale-object-detection-in-satellite-imagery-with-convolutional-neural-34f72f659588%23.nwzarsz1t%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3EFaster+R-CNN+Pedestrian+and+Car+Detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fbigsnarf.wordpress.com%2F2016%2F11%2F07%2Ffaster-r-cnn-pedestrian-and-car-detection%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fbigsnarf.wordpress.com%2F2016%2F11%2F07%2Ffaster-r-cnn-pedestrian-and-car-detection%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eipn%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgist.github.com%2Fbigsnarfdude%2F2f7b2144065f6056892a98495644d3e0%23file-demo_faster_rcnn_notebook-ipynb%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgist.github.com%2Fbigsnarfdude%2F2f7b2144065f6056892a98495644d3e0%23file-demo_faster_rcnn_notebook-ipynb%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fbigsnarfdude%2FFaster-RCNN_TF%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fbigsnarfdude%2FFaster-RCNN_TF%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESmall+U-Net+for+vehicle+detection%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fmedium.com%2F%40vivek.yadav%2Fsmall-u-net-for-vehicle-detection-9eec216f9fd6%23.md4u80kad%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fmedium.com%2F%40vivek.yadav%2Fsmall-u-net-for-vehicle-detection-9eec216f9fd6%23.md4u80kad%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ERegion+of+interest+pooling+explained%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fdeepsense.io%2Fregion-of-interest-pooling-explained%2F%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fdeepsense.io%2Fregion-of-interest-pooling-explained%2F%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Fdeepsense-io%2Froi-pooling%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Fdeepsense-io%2Froi-pooling%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cp+style%3D%22margin-top%3A1em%3B+margin-bottom%3A1em%3B+padding-top%3A0px%3B+padding-bottom%3A0px%3B+line-height%3A1.6%3B+color%3Argb%2886%2C86%2C86%29%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%3Cspan+style%3D%22margin%3A0px%3B+padding%3A0px%22%3ESupercharge+your+Computer+Vision+models+with+the+TensorFlow+Object+Detection+API%3C%2Fspan%3E%3C%2Fp%3E+%0A++%3Cul+style%3D%22margin%3A0px+0px+1em%3B+padding%3A0px+0px+0px+20px%3B+font-family%3AGeorgia%2C%26quot%3BHiragino+Sans+GB%26quot%3B%2C%E5%AE%8B%E4%BD%93%3B+font-size%3A14px%3B+background-color%3Argb%28227%2C222%2C216%29%22%3E+%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Eblog%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fresearch.googleblog.com%2F2017%2F06%2Fsupercharge-your-computer-vision-models.html%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fresearch.googleblog.com%2F2017%2F06%2Fsupercharge-your-computer-vision-models.html%3C%2Fa%3E%3C%2Fli%3E%0A+++%3Cli+style%3D%22margin%3A0px%3B+padding%3A0px%3B+line-height%3A24px%22%3Egithub%3A%26nbsp%3B%3Ca+target%3D%22_blank%22+href%3D%22https%3A%2F%2Fgithub.com%2Ftensorflow%2Fmodels%2Ftree%2Fmaster%2Fobject_detection%22+rel%3D%22nofollow%22+style%3D%22margin%3A0px%3B+padding%3A0px%3B+color%3Argb%28145%2C115%2C107%29%22%3Ehttps%3A%2F%2Fgithub.com%2Ftensorflow%2Fmodels%2Ftree%2Fmaster%2Fobject_detection%3C%2Fa%3E%3C%2Fli%3E%0A++%3C%2Ful%3E+%0A++%3Cbr%3E+%0A++%3Cp%3E%3Cbr%3E+%3C%2Fp%3E+%0A++%3Cp%3E%3Cbr%3E+%3C%2Fp%3E+%0A+%3C%2Fdiv%3E+%0A%3C%2Fdiv%3E+%0A%3Cdiv+class%3D%22hide-article-box+text-center%22%3E+%0A+%3Ca+class%3D%22btn+btn-red-hollow%22+id%3D%22btn-readmore%22+data-track-view%3D%22%7B%26quot%3Bmod%26quot%3B%3A%26quot%3Bpopu_376%26quot%3B%2C%26quot%3Bcon%26quot%3B%3A%26quot%3B%2Chttps%3A%2F%2Fblog.csdn.net%2Fleoking01%2Farticle%2Fdetails%2F78531902%2C%26quot%3B%7D%22+data-track-click%3D%22%7B%26quot%3Bmod%26quot%3B%3A%26quot%3Bpopu_376%26quot%3B%2C%26quot%3Bcon%26quot%3B%3A%26quot%3B%2Chttps%3A%2F%2Fblog.csdn.net%2Fleoking01%2Farticle%2Fdetails%2F78531902%2C%26quot%3B%7D%22%3E%E9%98%85%E8%AF%BB%E6%9B%B4%E5%A4%9A%3C%2Fa%3E+%0A%3C%2Fdiv%3E" | url_decode}}