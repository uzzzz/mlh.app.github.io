---
layout: default
title: 资源|17类对抗网络经典论文及开源代码（附源码）
---

{{ "%3Cdiv+id%3D%22article_content%22+class%3D%22article_content+clearfix+csdn-tracking-statistics%22+data-pid%3D%22blog%22+data-mod%3D%22popu_307%22+data-dsm%3D%22post%22%3E+%0A+%3Cdiv+id%3D%22content_views%22+class%3D%22markdown_views+prism-atom-one-dark%22%3E+%0A++%3C%21--+flowchart+%E7%AE%AD%E5%A4%B4%E5%9B%BE%E6%A0%87+%E5%8B%BF%E5%88%A0+--%3E+%0A++%3Csvg+xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22+style%3D%22display%3A+none%3B%22%3E%0A+++%3Cpath+stroke-linecap%3D%22round%22+d%3D%22M5%2C0+0%2C2.5+5%2C5z%22+id%3D%22raphael-marker-block%22+style%3D%22-webkit-tap-highlight-color%3A+rgba%280%2C+0%2C+0%2C+0%29%3B%22%3E%3C%2Fpath%3E%0A++%3C%2Fsvg%3E+%0A++%3Cp%3E%3Cstrong%3E%E5%88%86%E4%BA%AB%E4%B8%80%E4%B8%8B%E6%88%91%E8%80%81%E5%B8%88%E5%A4%A7%E7%A5%9E%E7%9A%84%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E6%95%99%E7%A8%8B%EF%BC%81%E9%9B%B6%E5%9F%BA%E7%A1%80%EF%BC%8C%E9%80%9A%E4%BF%97%E6%98%93%E6%87%82%EF%BC%81%3Ca+href%3D%22https%3A%2F%2Fblog.csdn.net%2Fjiangjunshow%2Farticle%2Fdetails%2F77338485%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fblog.csdn.net%2Fjiangjunshow%3C%2Fa%3E%3C%2Fstrong%3E%3C%2Fp%3E%0A++%3Cp%3E%3C%2Fp%3E%0A++%3Cp%3E%3Cstrong%3E%E4%B9%9F%E6%AC%A2%E8%BF%8E%E5%A4%A7%E5%AE%B6%E8%BD%AC%E8%BD%BD%E6%9C%AC%E7%AF%87%E6%96%87%E7%AB%A0%E3%80%82%E5%88%86%E4%BA%AB%E7%9F%A5%E8%AF%86%EF%BC%8C%E9%80%A0%E7%A6%8F%E4%BA%BA%E6%B0%91%EF%BC%8C%E5%AE%9E%E7%8E%B0%E6%88%91%E4%BB%AC%E4%B8%AD%E5%8D%8E%E6%B0%91%E6%97%8F%E4%BC%9F%E5%A4%A7%E5%A4%8D%E5%85%B4%EF%BC%81%3C%2Fstrong%3E%3C%2Fp%3E%0A++%3Cp%3E%3C%2Fp%3E%0A++%3Cdiv+class%3D%22htmledit_views%22%3E%0A+++%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B%26nbsp%3B+%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cbr%3E%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C%E4%B8%93%E9%A2%98%E6%96%87%E7%8C%AE%E9%9B%86%3Cbr%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%E7%AC%AC%E4%B8%80%E7%AF%87%E8%AE%BA%E6%96%87%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan+lang%3D%22zh-CN%22%3E%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BGenerative+Adversarial+Nets%5D%28the+first+paper+about+it%29%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cblockquote%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5D%EF%BC%9Ahttps%3A%2F%2Farxiv.org%2Fabs%2F1406.2661%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5D%EF%BC%9Ahttps%3A%2F%2Fgithub.com%2Fgoodfeli%2Fadversarial%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3C%2Fblockquote%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%E6%9C%AA%E5%88%86%E7%B1%BB%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BDeep+Generative+Image+Models+using+a+Laplacian+Pyramid+of+Adversarial+Networks%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cblockquote%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1506.05751%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Ffacebook%2Feyescream%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3C%2Fblockquote%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BUnsupervised+Representation+Learning+with+Deep+Convolutional+Generative+Adversarial+Networks%5D%3Cspan%3E%28Gan%26nbsp%3Bwith+convolutional+networks%29%28ICLR%29%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cblockquote%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1511.06434%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fjacobgil%2Fkeras-dcgan%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3C%2Fblockquote%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BAdversarial+Autoencoders%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cblockquote%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttp%3A%2F%2Farxiv.org%2Fabs%2F1511.05644%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fmusyoku%2Fadversarial-autoencoder%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3C%2Fblockquote%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BGenerating+Images+with+Perceptual+Similarity+Metrics+based+on+Deep+Networks%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cblockquote%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fpdf%2F1602.02644v2.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3C%2Fblockquote%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BGenerating+images+with+recurrent+adversarial+networks%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cblockquote%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1602.05110%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A++++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fofirnachum%2Fsequence_gan%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3C%2Fblockquote%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BGenerative+Visual+Manipulation+on+the+Natural+Image+Manifold%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Fpeople.eecs.berkeley.edu%2F%257Ejunyanz%2Fprojects%2Fgvm%2Feccv16_gvm.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fjunyanz%2FiGAN%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BGenerative+Adversarial+Text+to+Image+Synthesis%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1605.05396%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Freedscot%2Ficml2016%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5Bcode%5Dhttps%3A%2F%2Fgithub.com%2Fpaarthneekhara%2Ftext-to-image%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BLearning+What+and+Where+to+Draw%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttp%3A%2F%2Fwww.scottreed.info%2Ffiles%2Fnips2016.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Freedscot%2Fnips2016%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BAdversarial+Training+for+Sketch+Retrieval%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttp%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-319-46604-0_55%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BGenerative+Image+Modeling+using+Style+and+Structure+Adversarial+Networks%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fpdf%2F1603.05631.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fxiaolonw%2Fss-gan%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BGenerative+Adversarial+Networks+as+Variational+Training+of+Energy+Based+Models%5D%3Cspan%3E%28ICLR%26nbsp%3B2017%29%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttp%3A%2F%2Fwww.mathpubs.com%2Fdetail%2F1611.01799v1%2FGenerative-Adversarial-Networks-as-Variational-Training-of-Energy-Based-Models%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BAdversarial+Training+Methods+for+Semi-Supervised+Text+Classification%5D%3Cspan%3E%28%26nbsp%3BIan+Goodfellow+Paper%29%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1605.07725%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BNote%5Dhttps%3A%2F%2Fgithub.com%2Fdennybritz%2Fdeeplearning-papernotes%2Fblob%2Fmaster%2Fnotes%2Fadversarial-text-classification.md%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BLearning+from+Simulated+and+Unsupervised+Images+through+Adversarial+Training%5D%3Cspan%3E%EF%BC%88Apple%26nbsp%3Bpaper%EF%BC%89%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1612.07828%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5Bcode%5Dhttps%3A%2F%2Fgithub.com%2Fcarpedm20%2Fsimulated-unsupervised-tensorflow%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BSynthesizing+the+preferred+inputs+for+neurons+in+neural+networks+via+deep+generator+networks%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fpdf%2F1605.09304v5.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2FEvolving-AI-Lab%2Fsynthesizing%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BSalGAN%3A+Visual+Saliency+Prediction+with+Generative+Adversarial+Networks%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1701.01081%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fimatge-upc%2Fsaliency-salgan-2017%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BAdversarial+Feature+Learning%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1605.09782%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BUnpaired+Image-to-Image+Translation+using+Cycle-Consistent+Adversarial+Networks%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Fjunyanz.github.io%2FCycleGAN%2F%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fjunyanz%2FCycleGAN%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3EEnsemble%3C%2Fspan%3E%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BAdaGAN%3A+Boosting+Generative+Models%5D+%EF%BC%88Google+Brain%EF%BC%89%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1701.02386%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%E8%81%9A%E7%B1%BB%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cbr%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BUnsupervised+Learning+Using+Generative+Adversarial+Training+And+Clustering%5D%28ICLR%29%3Cspan%3E%3Cbr%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%3C%2Fspan%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Fopenreview.net%2Fforum%3Fid%3DSJ8BZTjeg%26amp%3BnoteId%3DSJ8BZTjeg%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2FVittalP%2FUnsupGAN%3C%2Fspan%3E%3C%2Fspan%3E%3Cspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cbr%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BUnsupervised+and+Semi-supervised+Learning+with+Categorical+Generative+Adversarial+Networks%5D+%28ICLR%29%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1511.06390%3C%2Fspan%3E%3C%2Fspan%3E%3Cspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cbr%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3EImage+Inpainting%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BSemantic+Image+Inpainting+with+Perceptual+and%26nbsp%3BContextual+Losses%5D%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1607.07539%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fbamos%2Fdcgan-completion.tensorflow%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BContext+Encoders%3A+Feature+Learning+by+Inpainting%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1604.07379%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fjazzsaxmafia%2FInpainting%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BSemi-Supervised+Learning+with+Context-Conditional+Generative+Adversarial+Networks%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1611.06430v1%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Cbr%3E%3C%2Fh2%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3E%3Cspan%3EJoint+Probability%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BAdversarially+Learned+Inference%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1606.00704%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2FIshmaelBelghazi%2FALI%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3E%3Cspan%3ESuper-Resolution%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BImage+super-resolution+through+deep+learning+%5D%28Just+for+face+dataset%29%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fdavid-gpu%2Fsrez%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BPhoto-Realistic+Single+Image+Super-Resolution+Using+a+Generative+Adversarial+Network%5D+%EF%BC%88Using+Deep+residual+network%EF%BC%89%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1609.04802%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fleehomyc%2FPhoto-Realistic-Super-Resoluton%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BEnhanceGAN%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BDocs%5Dhttps%3A%2F%2Fmedium.com%2F%40richardherbert%2Ffaces-from-noise-super-enhancing-8x8-images-with-enhancegan-ebda015bb5e0%23.io6pskvin%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3E%3Cspan%3EDisocclusion%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BRobust+LSTM-Autoencoders+for+Face+De-Occlusion+in+the+Wild%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1612.08534%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Cbr%3E%3C%2Fh2%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3E%3Cspan%3ESemantic+Segmentation%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BSemantic+Segmentation+using+Adversarial+Networks%5D+%EF%BC%88soumith%27s+paper%EF%BC%89%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1611.08408%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Cbr%3E%3C%2Fh2%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3E%3Cspan%3EObject+Detection%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BPerceptual+generative+adversarial+networks+for+small+object+detection%5D%EF%BC%88Submitted%EF%BC%89%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BA-Fast-RCNN%3A+Hard+Positive+Generation+via+Adversary+for+Object+Detection%5D%28CVPR2017%29%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttp%3A%2F%2Fabhinavsh.info%2Fpapers%2Fpdfs%2Fadversarial_object_detection.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3E%3Cspan%3ERNN%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BC-RNN-GAN%3A+Continuous+recurrent+neural+networks+with+adversarial+training%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1611.09904%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Folofmogren%2Fc-rnn-gan%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Ch2%3E%3Ca%3E%3C%2Fa%3E%3Cspan%3E%3Cspan%3EConditional+adversarial%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fh2%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BConditional+Generative+Adversarial+Nets%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1411.1784%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fzhangqianhui%2FConditional-Gans%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BInfoGAN%3A+Interpretable+Representation+Learning+by+Information+Maximizing+Generative+Adversarial+Nets%5D%26nbsp%3B%3Cbr%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1606.03657%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fburiburisuri%2Fsupervised_infogan%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BImage-to-image+translation+using+conditional+adversarial+nets%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fpdf%2F1611.07004v1.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fphillipi%2Fpix2pix%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fyenchenlin%2Fpix2pix-tensorflow%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BConditional+Image+Synthesis+With+Auxiliary+Classifier+GANs%5D%28GoogleBrain+ICLR+2017%29%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1610.09585%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fburiburisuri%2Fac-gan%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BPixel-Level+Domain+Transfer%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fpdf%2F1603.07442v2.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Ffxia22%2Fpldtgan%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BInvertible+Conditional+GANs+for+image+editing%5D%26nbsp%3B%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1611.06355%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2FGuim3%2FIcGAN%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BPlug+%26amp%3B+Play+Generative+Networks%3A+Conditional+Iterative+Generation+of+Images+in+Latent+Space%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fabs%2F1612.00005v1%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2FEvolving-AI-Lab%2Fppgn%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%5BStackGAN%3A+Text+to+Photo-realistic+Image+Synthesis+with+Stacked+Generative+Adversarial+Networks%5D%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BPaper%5Dhttps%3A%2F%2Farxiv.org%2Fpdf%2F1612.03242v1.pdf%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cspan%3E%3Cspan%3E%5BCode%5Dhttps%3A%2F%2Fgithub.com%2Fhanzhanggit%2FStackGAN%3C%2Fspan%3E%3C%2Fspan%3E%3C%2Fp%3E%0A+++%3Cp%3E%3Cbr%3E%3C%2Fp%3E%0A+++%3Cp%3E%3C%2Fp%3E%0A++%3C%2Fdiv%3E+%0A+%3C%2Fdiv%3E+%0A+%3Clink+href%3D%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fphoenix%2Fmdeditor%2Fmarkdown_views-a47e74522c.css%22+rel%3D%22stylesheet%22%3E+%0A%3C%2Fdiv%3E+%0A%3Cdiv+class%3D%22hide-article-box+text-center%22%3E+%0A+%3Ca+class%3D%22btn%22+id%3D%22btn-readmore%22+data-track-view%3D%22%7B%26quot%3Bmod%26quot%3B%3A%26quot%3Bpopu_376%26quot%3B%2C%26quot%3Bcon%26quot%3B%3A%26quot%3B%2Chttps%3A%2F%2Fblog.csdn.net%2Fggjttfc%2Farticle%2Fdetails%2F83956471%2C%26quot%3B%7D%22+data-track-click%3D%22%7B%26quot%3Bmod%26quot%3B%3A%26quot%3Bpopu_376%26quot%3B%2C%26quot%3Bcon%26quot%3B%3A%26quot%3B%2Chttps%3A%2F%2Fblog.csdn.net%2Fggjttfc%2Farticle%2Fdetails%2F83956471%2C%26quot%3B%7D%22%3E%E9%98%85%E8%AF%BB%E6%9B%B4%E5%A4%9A%3C%2Fa%3E+%0A%3C%2Fdiv%3E+%0A%3Cscript%3E%0A%09%09%09%09%09%09%28function%28%29%7B%0A%09%09%09%09%09%09%09function+setArticleH%28btnReadmore%2Cposi%29%7B%0A%09%09%09%09%09%09%09%09var+winH+%3D+%24%28window%29.height%28%29%3B%0A%09%09%09%09%09%09%09%09var+articleBox+%3D+%24%28%22div.article_content%22%29%3B%0A%09%09%09%09%09%09%09%09var+artH+%3D+articleBox.height%28%29%3B%0A%09%09%09%09%09%09%09%09if%28artH+%3E+winH*posi%29%7B%0A%09%09%09%09%09%09%09%09%09articleBox.css%28%7B%0A%09%09%09%09%09%09%09%09%09%09%27height%27%3AwinH*posi%2B%27px%27%2C%0A%09%09%09%09%09%09%09%09%09%09%27overflow%27%3A%27hidden%27%0A%09%09%09%09%09%09%09%09%09%7D%29%0A%09%09%09%09%09%09%09%09%09btnReadmore.click%28function%28%29%7B%0A%09%09%09%09%09%09%09%09%09%09if%28typeof+window.localStorage+%3D%3D%3D+%22object%22+%26%26+typeof+window.csdn.anonymousUserLimit+%3D%3D%3D+%22object%22%29%7B%0A%09%09%09%09%09%09%09%09%09%09%09if%28%21window.csdn.anonymousUserLimit.judgment%28%29%29%7B%0A%09%09%09%09%09%09%09%09%09%09%09%09window.csdn.anonymousUserLimit.Jumplogin%28%29%3B%0A%09%09%09%09%09%09%09%09%09%09%09%09return+false%3B%0A%09%09%09%09%09%09%09%09%09%09%09%7Delse+if%28%21currentUserName%29%7B%0A%09%09%09%09%09%09%09%09%09%09%09%09window.csdn.anonymousUserLimit.updata%28%29%3B%0A%09%09%09%09%09%09%09%09%09%09%09%7D%0A%09%09%09%09%09%09%09%09%09%09%7D%0A%09%09%09%09%09%09%09%09%09%09%0A%09%09%09%09%09%09%09%09%09%09articleBox.removeAttr%28%22style%22%29%3B%0A%09%09%09%09%09%09%09%09%09%09%24%28this%29.parent%28%29.remove%28%29%3B%0A%09%09%09%09%09%09%09%09%09%7D%29%0A%09%09%09%09%09%09%09%09%7Delse%7B%0A%09%09%09%09%09%09%09%09%09btnReadmore.parent%28%29.remove%28%29%3B%0A%09%09%09%09%09%09%09%09%7D%0A%09%09%09%09%09%09%09%7D%0A%09%09%09%09%09%09%09var+btnReadmore+%3D+%24%28%22%23btn-readmore%22%29%3B%0A%09%09%09%09%09%09%09if%28btnReadmore.length%3E0%29%7B%0A%09%09%09%09%09%09%09%09if%28currentUserName%29%7B%0A%09%09%09%09%09%09%09%09%09setArticleH%28btnReadmore%2C3%29%3B%0A%09%09%09%09%09%09%09%09%7Delse%7B%0A%09%09%09%09%09%09%09%09%09setArticleH%28btnReadmore%2C1.2%29%3B%0A%09%09%09%09%09%09%09%09%7D%0A%09%09%09%09%09%09%09%7D%0A%09%09%09%09%09%09%7D%29%28%29%0A%09%09%09%09%09%3C%2Fscript%3E" | url_decode}}