---
layout: default
title: 目标检测(Object Detection)算法合集（持续更新ing）
---

{{ "%3Cdiv+id%3D%22article_content%22+class%3D%22article_content+clearfix+csdn-tracking-statistics%22+data-pid%3D%22blog%22+data-mod%3D%22popu_307%22+data-dsm%3D%22post%22%3E+%0A+%3Cdiv+class%3D%22article-copyright%22%3E%0A+++%E7%89%88%E6%9D%83%E5%A3%B0%E6%98%8E%EF%BC%9A%E6%9C%AC%E6%96%87%E4%B8%BA%E9%98%BF%E6%9C%A8%E5%AF%BA%E7%9A%84%E5%8E%9F%E5%88%9B%E6%96%87%E7%AB%A0%EF%BC%8C%E6%9C%AA%E7%BB%8F%E6%9C%AC%E4%BA%BA%E5%85%81%E8%AE%B8%E4%B8%8D%E5%BE%97%E8%BD%AC%E8%BD%BD%E3%80%82+https%3A%2F%2Fblog.csdn.net%2Famusi1994%2Farticle%2Fdetails%2F81042923+%0A+%3C%2Fdiv%3E+%0A+%3Cdiv+class%3D%22markdown_views+prism-atom-one-dark%22%3E+%0A++%3C%21--+flowchart+%E7%AE%AD%E5%A4%B4%E5%9B%BE%E6%A0%87+%E5%8B%BF%E5%88%A0+--%3E+%0A++%3Csvg+xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22+style%3D%22display%3A+none%3B%22%3E%0A+++%3Cpath+stroke-linecap%3D%22round%22+d%3D%22M5%2C0+0%2C2.5+5%2C5z%22+id%3D%22raphael-marker-block%22+style%3D%22-webkit-tap-highlight-color%3A+rgba%280%2C+0%2C+0%2C+0%29%3B%22%3E%3C%2Fpath%3E%0A++%3C%2Fsvg%3E+%0A++%3Cp%3E%3Cstrong%3E%E6%83%B3%E4%BA%86%E8%A7%A3%E6%9C%80%E6%96%B0%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%EF%BC%8C%E8%AF%A6%E8%A7%81+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Famusi%2Fawesome-object-detection%22+rel%3D%22nofollow%22%3Eawesome-object-detection%3C%2Fa%3E%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3C%2Fp%3E%0A++%3Cdiv+class%3D%22toc%22%3E+%0A+++%3Cul%3E+%0A++++%3Cli%3E%3Ca+href%3D%22%23object-detection%22+rel%3D%22nofollow%22%3EObject+Detection%3C%2Fa%3E%3C%2Fli%3E+%0A++++%3Cli%3E%3Ca+href%3D%22%23paperscodes%22+rel%3D%22nofollow%22%3EPapers%26amp%3BCodes%3C%2Fa%3E%0A+++++%3Cul%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23r-cnn%22+rel%3D%22nofollow%22%3ER-CNN%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23fast-r-cnn%22+rel%3D%22nofollow%22%3EFast+R-CNN%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23faster-r-cnn%22+rel%3D%22nofollow%22%3EFaster+R-CNN%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23light-head-r-cnn%22+rel%3D%22nofollow%22%3ELight-Head+R-CNN%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23cascade-r-cnn%22+rel%3D%22nofollow%22%3ECascade+R-CNN%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23spp-net%22+rel%3D%22nofollow%22%3ESPP-Net%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23yolo%22+rel%3D%22nofollow%22%3EYOLO%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23yolov2%22+rel%3D%22nofollow%22%3EYOLOv2%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23yolov3%22+rel%3D%22nofollow%22%3EYOLOv3%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23yolt%22+rel%3D%22nofollow%22%3EYOLT%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23ssd%22+rel%3D%22nofollow%22%3ESSD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23dssd%22+rel%3D%22nofollow%22%3EDSSD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23fssd%22+rel%3D%22nofollow%22%3EFSSD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23essd%22+rel%3D%22nofollow%22%3EESSD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23mdssd%22+rel%3D%22nofollow%22%3EMDSSD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23pelee%22+rel%3D%22nofollow%22%3EPelee%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23fire-ssd%22+rel%3D%22nofollow%22%3EFire+SSD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23r-fcn%22+rel%3D%22nofollow%22%3ER-FCN%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23fpn%22+rel%3D%22nofollow%22%3EFPN%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23dsod%22+rel%3D%22nofollow%22%3EDSOD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23retinanet%22+rel%3D%22nofollow%22%3ERetinaNet%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23megdet%22+rel%3D%22nofollow%22%3EMegDet%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23refinenet%22+rel%3D%22nofollow%22%3ERefineNet%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23detnet%22+rel%3D%22nofollow%22%3EDetNet%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23ssod%22+rel%3D%22nofollow%22%3ESSOD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%233d-object-detection%22+rel%3D%22nofollow%22%3E3D+Object+Detection%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23zsd%22+rel%3D%22nofollow%22%3EZSD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%23osd%22+rel%3D%22nofollow%22%3EOSD%3C%2Fa%3E%3C%2Fli%3E+%0A++++++%3Cli%3E%3Ca+href%3D%22%232018%22+rel%3D%22nofollow%22%3E2018%3C%2Fa%3E%3C%2Fli%3E+%0A+++++%3C%2Ful%3E+%3C%2Fli%3E+%0A+++%3C%2Ful%3E+%0A++%3C%2Fdiv%3E+%0A++%3Cp%3E%3C%2Fp%3E+%0A++%3Ch1+id%3D%22object-detection%22%3EObject+Detection%3C%2Fh1%3E+%0A++%3Cp%3E%E6%83%B3%E4%BA%86%E8%A7%A3%E6%9C%80%E6%96%B0%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%EF%BC%8C%E8%AF%A6%E8%A7%81+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Famusi%2Fawesome-object-detection%22+rel%3D%22nofollow%22%3Eawesome-object-detection%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3EThis+is+a+list+of+awesome+articles+about+object+detection.%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3ER-CNN%3C%2Fli%3E+%0A+++%3Cli%3EFast+R-CNN%3C%2Fli%3E+%0A+++%3Cli%3EFaster+R-CNN%3C%2Fli%3E+%0A+++%3Cli%3ELight-Head+R-CNN%3C%2Fli%3E+%0A+++%3Cli%3ECascade+R-CNN%3C%2Fli%3E+%0A+++%3Cli%3ESPP-Net%3C%2Fli%3E+%0A+++%3Cli%3EYOLO%3C%2Fli%3E+%0A+++%3Cli%3EYOLOv2%3C%2Fli%3E+%0A+++%3Cli%3EYOLOv3%3C%2Fli%3E+%0A+++%3Cli%3EYOLT%3C%2Fli%3E+%0A+++%3Cli%3ESSD%3C%2Fli%3E+%0A+++%3Cli%3EDSSD%3C%2Fli%3E+%0A+++%3Cli%3EFSSD%3C%2Fli%3E+%0A+++%3Cli%3EESSD%3C%2Fli%3E+%0A+++%3Cli%3EMDSSD%3C%2Fli%3E+%0A+++%3Cli%3EPelee%3C%2Fli%3E+%0A+++%3Cli%3EFire+SSD%3C%2Fli%3E+%0A+++%3Cli%3ER-FCN%3C%2Fli%3E+%0A+++%3Cli%3EFPN%3C%2Fli%3E+%0A+++%3Cli%3EDSOD%3C%2Fli%3E+%0A+++%3Cli%3ERetinaNet%3C%2Fli%3E+%0A+++%3Cli%3EMegNet%3C%2Fli%3E+%0A+++%3Cli%3ERefineNet%3C%2Fli%3E+%0A+++%3Cli%3EDetNet%3C%2Fli%3E+%0A+++%3Cli%3ESSOD%3C%2Fli%3E+%0A+++%3Cli%3E3D+Object+Detection%3C%2Fli%3E+%0A+++%3Cli%3EZSD%EF%BC%88Zero-Shot+Object+Detection%EF%BC%89%3C%2Fli%3E+%0A+++%3Cli%3EOSD%EF%BC%88One-Shot+object+Detection%EF%BC%89%3C%2Fli%3E+%0A+++%3Cli%3EOther%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3EBased+on+handong1587%E2%80%99s+github%EF%BC%88%3Ca+href%3D%22https%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fhandong1587.github.io%2Fdeep_learning%2F2015%2F10%2F09%2Fobject-detection.html%3C%2Fa%3E%EF%BC%89%3C%2Fp%3E+%0A++%3Ch1+id%3D%22paperscodes%22%3EPapers%26amp%3BCodes%3C%2Fh1%3E+%0A++%3Ch2+id%3D%22r-cnn%22%3ER-CNN%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ERich+feature+hierarchies+for+accurate+object+detection+and+semantic+segmentation%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+R-CNN%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1311.2524%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1311.2524%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Esupp%3A+%3Ca+href%3D%22http%3A%2F%2Fpeople.eecs.berkeley.edu%2F%7Erbg%2Fpapers%2Fr-cnn-cvpr-supp.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fpeople.eecs.berkeley.edu%2F%7Erbg%2Fpapers%2Fr-cnn-cvpr-supp.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eslides%3A+%3Ca+href%3D%22http%3A%2F%2Fwww.image-net.org%2Fchallenges%2FLSVRC%2F2013%2Fslides%2Fr-cnn-ilsvrc2013-workshop.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fwww.image-net.org%2Fchallenges%2FLSVRC%2F2013%2Fslides%2Fr-cnn-ilsvrc2013-workshop.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eslides%3A+%3Ca+href%3D%22http%3A%2F%2Fwww.cs.berkeley.edu%2F%7Erbg%2Fslides%2Frcnn-cvpr14-slides.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fwww.cs.berkeley.edu%2F%7Erbg%2Fslides%2Frcnn-cvpr14-slides.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Frcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Frcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Enotes%3A+%3Ca+href%3D%22http%3A%2F%2Fzhangliliang.com%2F2014%2F07%2F23%2Fpaper-note-rcnn%2F%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fzhangliliang.com%2F2014%2F07%2F23%2Fpaper-note-rcnn%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Ecaffe-pr%28%E2%80%9CMake+R-CNN+the+Caffe+detection+example%E2%80%9D%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FBVLC%2Fcaffe%2Fpull%2F482%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FBVLC%2Fcaffe%2Fpull%2F482%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22fast-r-cnn%22%3EFast+R-CNN%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EFast+R-CNN%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1504.08083%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1504.08083%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eslides%3A+%3Ca+href%3D%22http%3A%2F%2Ftutorial.caffe.berkeleyvision.org%2Fcaffe-cvpr15-detection.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Ftutorial.caffe.berkeleyvision.org%2Fcaffe-cvpr15-detection.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28COCO-branch%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%2Ftree%2Fcoco%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%2Ftree%2Fcoco%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Ewebcam+demo%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%2Fpull%2F29%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Ffast-rcnn%2Fpull%2F29%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Enotes%3A+%3Ca+href%3D%22http%3A%2F%2Fzhangliliang.com%2F2015%2F05%2F17%2Fpaper-note-fast-rcnn%2F%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fzhangliliang.com%2F2015%2F05%2F17%2Fpaper-note-fast-rcnn%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Enotes%3A+%3Ca+href%3D%22http%3A%2F%2Fblog.csdn.net%2Flinj_m%2Farticle%2Fdetails%2F48930179%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fblog.csdn.net%2Flinj_m%2Farticle%2Fdetails%2F48930179%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28%E2%80%9CFast+R-CNN+in+MXNet%E2%80%9D%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fprecedenceguo%2Fmx-rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fprecedenceguo%2Fmx-rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fmahyarnajibi%2Ffast-rcnn-torch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fmahyarnajibi%2Ffast-rcnn-torch%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fapple2373%2Fchainer-simple-fast-rnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fapple2373%2Fchainer-simple-fast-rnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fzplizzi%2Ftensorflow-fast-rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fzplizzi%2Ftensorflow-fast-rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EA-Fast-RCNN%3A+Hard+Positive+Generation+via+Adversary+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2017%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.03414%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.03414%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Epaper%3A+%3Ca+href%3D%22http%3A%2F%2Fabhinavsh.info%2Fpapers%2Fpdfs%2Fadversarial_object_detection.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fabhinavsh.info%2Fpapers%2Fpdfs%2Fadversarial_object_detection.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Caffe%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fxiaolonw%2Fadversarial-frcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fxiaolonw%2Fadversarial-frcnn%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22faster-r-cnn%22%3EFaster+R-CNN%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EFaster+R-CNN%3A+Towards+Real-Time+Object+Detection+with+Region+Proposal+Networks%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+NIPS+2015%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1506.01497%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1506.01497%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egitxiv%3A+%3Ca+href%3D%22http%3A%2F%2Fwww.gitxiv.com%2Fposts%2F8pfpcvefDYn2gSgXk%2Ffaster-r-cnn-towards-real-time-object-detection-with-region%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fwww.gitxiv.com%2Fposts%2F8pfpcvefDYn2gSgXk%2Ffaster-r-cnn-towards-real-time-object-detection-with-region%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eslides%3A+%3Ca+href%3D%22http%3A%2F%2Fweb.cs.hacettepe.edu.tr%2F%7Eaykut%2Fclasses%2Fspring2016%2Fbil722%2Fslides%2Fw05-FasterR-CNN.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fweb.cs.hacettepe.edu.tr%2F%7Eaykut%2Fclasses%2Fspring2016%2Fbil722%2Fslides%2Fw05-FasterR-CNN.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28official%2C+Matlab%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FShaoqingRen%2Ffaster_rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FShaoqingRen%2Ffaster_rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Caffe%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Frbgirshick%2Fpy-faster-rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Frbgirshick%2Fpy-faster-rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28MXNet%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fmsracver%2FDeformable-ConvNets%2Ftree%2Fmaster%2Ffaster_rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fmsracver%2FDeformable-ConvNets%2Ftree%2Fmaster%2Ffaster_rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28PyTorch%E2%80%93recommend%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2F%2Fjwyang%2Ffaster-rcnn.pytorch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2F%2Fjwyang%2Ffaster-rcnn.pytorch%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fmitmul%2Fchainer-faster-rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fmitmul%2Fchainer-faster-rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Torch%29%3A%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fandreaskoepf%2Ffaster-rcnn.torch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fandreaskoepf%2Ffaster-rcnn.torch%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Torch%29%3A%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fruotianluo%2FFaster-RCNN-Densecap-torch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fruotianluo%2FFaster-RCNN-Densecap-torch%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28TensorFlow%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fsmallcorgi%2FFaster-RCNN_TF%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fsmallcorgi%2FFaster-RCNN_TF%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28TensorFlow%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FCharlesShang%2FTFFRCNN%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FCharlesShang%2FTFFRCNN%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28C%2B%2B+demo%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FYihangLou%2FFasterRCNN-Encapsulation-Cplusplus%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FYihangLou%2FFasterRCNN-Encapsulation-Cplusplus%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Keras%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fyhenon%2Fkeras-frcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fyhenon%2Fkeras-frcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FEniac-Xie%2Ffaster-rcnn-resnet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FEniac-Xie%2Ffaster-rcnn-resnet%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28C%2B%2B%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FD-X-Y%2Fcaffe-faster-rcnn%2Ftree%2Fdev%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FD-X-Y%2Fcaffe-faster-rcnn%2Ftree%2Fdev%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ER-CNN+minus+R%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+BMVC+2015%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1506.06981%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1506.06981%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EFaster+R-CNN+in+MXNet+with+distributed+implementation+and+data+parallelization%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fdmlc%2Fmxnet%2Ftree%2Fmaster%2Fexample%2Frcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fdmlc%2Fmxnet%2Ftree%2Fmaster%2Fexample%2Frcnn%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EContextual+Priming+and+Feedback+for+Faster+R-CNN%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ECCV+2016.+Carnegie+Mellon+University%3C%2Fli%3E+%0A+++%3Cli%3Epaper%3A+%3Ca+href%3D%22http%3A%2F%2Fabhinavsh.info%2Fcontext_priming_feedback.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fabhinavsh.info%2Fcontext_priming_feedback.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eposter%3A+%3Ca+href%3D%22http%3A%2F%2Fwww.eccv2016.org%2Ffiles%2Fposters%2FP-1A-20.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fwww.eccv2016.org%2Ffiles%2Fposters%2FP-1A-20.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EAn+Implementation+of+Faster+RCNN+with+Study+for+Region+Sampling%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Technical+Report%2C+3+pages.+CMU%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.02138%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.02138%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fendernewton%2Ftf-faster-rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fendernewton%2Ftf-faster-rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EInterpretable+R-CNN%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+North+Carolina+State+University+%26amp%3B+Alibaba%3C%2Fli%3E+%0A+++%3Cli%3Ekeywords%3A+AND-OR+Graph+%28AOG%29%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.05226%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.05226%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22light-head-r-cnn%22%3ELight-Head+R-CNN%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ELight-Head+R-CNN%3A+In+Defense+of+Two-Stage+Object+Detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Tsinghua+University+%26amp%3B+Megvii+Inc%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.07264%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.07264%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28offical%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fzengarden%2Flight_head_rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fzengarden%2Flight_head_rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fterrychenism%2FDeformable-ConvNets%2Fblob%2Fmaster%2Frfcn%2Fsymbols%2Fresnet_v1_101_rfcn_light.py%23L784%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fterrychenism%2FDeformable-ConvNets%2Fblob%2Fmaster%2Frfcn%2Fsymbols%2Fresnet_v1_101_rfcn_light.py%23L784%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22cascade-r-cnn%22%3ECascade+R-CNN%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ECascade+R-CNN%3A+Delving+into+High+Quality+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.00726%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.00726%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fzhaoweicai%2Fcascade-rcnn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fzhaoweicai%2Fcascade-rcnn%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22spp-net%22%3ESPP-Net%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ESpatial+Pyramid+Pooling+in+Deep+Convolutional+Networks+for+Visual+Recognition%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ECCV+2014+%2F+TPAMI+2015%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1406.4729%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1406.4729%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FShaoqingRen%2FSPP_net%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FShaoqingRen%2FSPP_net%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Enotes%3A+%3Ca+href%3D%22http%3A%2F%2Fzhangliliang.com%2F2014%2F09%2F13%2Fpaper-note-sppnet%2F%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fzhangliliang.com%2F2014%2F09%2F13%2Fpaper-note-sppnet%2F%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EDeepID-Net%3A+Deformable+Deep+Convolutional+Neural+Networks+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+PAMI+2016%3C%2Fli%3E+%0A+++%3Cli%3Eintro%3A+an+extension+of+R-CNN.+box+pre-training%2C+cascade+on+region+proposals%2C+deformation+layers+and+context+representations%3C%2Fli%3E+%0A+++%3Cli%3Eproject+page%3A+%3Ca+href%3D%22http%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%25CB%259Cwlouyang%2Fprojects%2FimagenetDeepId%2Findex.html%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fwww.ee.cuhk.edu.hk%2F%25CB%259Cwlouyang%2Fprojects%2FimagenetDeepId%2Findex.html%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1412.5661%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1412.5661%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EObject+Detectors+Emerge+in+Deep+Scene+CNNs%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ICLR+2015%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1412.6856%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1412.6856%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Epaper%3A+%3Ca+href%3D%22https%3A%2F%2Fwww.robots.ox.ac.uk%2F%7Evgg%2Frg%2Fpapers%2Fzhou_iclr15.pdf%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fwww.robots.ox.ac.uk%2F%7Evgg%2Frg%2Fpapers%2Fzhou_iclr15.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Epaper%3A+%3Ca+href%3D%22https%3A%2F%2Fpeople.csail.mit.edu%2Fkhosla%2Fpapers%2Ficlr2015_zhou.pdf%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fpeople.csail.mit.edu%2Fkhosla%2Fpapers%2Ficlr2015_zhou.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eslides%3A+%3Ca+href%3D%22http%3A%2F%2Fplaces.csail.mit.edu%2Fslide_iclr2015.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fplaces.csail.mit.edu%2Fslide_iclr2015.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EsegDeepM%3A+Exploiting+Segmentation+and+Context+in+Deep+Neural+Networks+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2015%3C%2Fli%3E+%0A+++%3Cli%3Eproject%28code%2Bdata%29%3A+%3Ca+href%3D%22https%3A%2F%2Fwww.cs.toronto.edu%2F%7Eyukun%2Fsegdeepm.html%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fwww.cs.toronto.edu%2F%7Eyukun%2Fsegdeepm.html%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1502.04275%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1502.04275%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FYknZhu%2FsegDeepM%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FYknZhu%2FsegDeepM%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EObject+Detection+Networks+on+Convolutional+Feature+Maps%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+TPAMI+2015%3C%2Fli%3E+%0A+++%3Cli%3Ekeywords%3A+NoC%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1504.06066%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1504.06066%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EImproving+Object+Detection+with+Deep+Convolutional+Networks+via+Bayesian+Optimization+and+Structured+Prediction%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1504.03293%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1504.03293%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eslides%3A+%3Ca+href%3D%22http%3A%2F%2Fwww.ytzhang.net%2Ffiles%2Fpublications%2F2015-cvpr-det-slides.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fwww.ytzhang.net%2Ffiles%2Fpublications%2F2015-cvpr-det-slides.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FYutingZhang%2Ffgs-obj%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FYutingZhang%2Ffgs-obj%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EDeepBox%3A+Learning+Objectness+with+Convolutional+Networks%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Ekeywords%3A+DeepBox%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1505.02146%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1505.02146%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fweichengkuo%2FDeepBox%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fweichengkuo%2FDeepBox%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22yolo%22%3EYOLO%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EYou+Only+Look+Once%3A+Unified%2C+Real-Time+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2Fe69d4118b20a42de4e23b9549f9a6ec6dbbb0814%2F687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67%22+rel%3D%22nofollow%22%3E%3Cimg+src%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2Fe69d4118b20a42de4e23b9549f9a6ec6dbbb0814%2F687474703a2f2f706a7265646469652e636f6d2f6d656469612f66696c65732f6461726b6e65742d626c61636b2d736d616c6c2e706e67%22+alt%3D%22img%22+title%3D%22%22%3E%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1506.02640%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1506.02640%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Ecode%3A+%3Ca+href%3D%22https%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolov1%2F%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolov1%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fpjreddie%2Fdarknet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fpjreddie%2Fdarknet%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eblog%3A+%3Ca+href%3D%22https%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolov1%2F%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolov1%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eslides%3A+%3Ca+href%3D%22https%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA%2Fpub%3Fstart%3Dfalse%26amp%3Bloop%3Dfalse%26amp%3Bdelayms%3D3000%26amp%3Bslide%3Did.p%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fdocs.google.com%2Fpresentation%2Fd%2F1aeRvtKG21KHdD5lg6Hgyhx5rPq_ZOsGjG5rJ1HP7BbA%2Fpub%3Fstart%3Dfalse%26amp%3Bloop%3Dfalse%26amp%3Bdelayms%3D3000%26amp%3Bslide%3Did.p%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Ereddit%3A+%3Ca+href%3D%22https%3A%2F%2Fwww.reddit.com%2Fr%2FMachineLearning%2Fcomments%2F3a3m0o%2Frealtime_object_detection_with_yolo%2F%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fwww.reddit.com%2Fr%2FMachineLearning%2Fcomments%2F3a3m0o%2Frealtime_object_detection_with_yolo%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fgliese581gg%2FYOLO_tensorflow%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fgliese581gg%2FYOLO_tensorflow%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fxingwangsfu%2Fcaffe-yolo%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fxingwangsfu%2Fcaffe-yolo%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Ffrankzhangrui%2FDarknet-Yolo%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Ffrankzhangrui%2FDarknet-Yolo%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FBriSkyHekun%2Fpy-darknet-yolo%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FBriSkyHekun%2Fpy-darknet-yolo%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Ftommy-qichang%2Fyolo.torch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Ftommy-qichang%2Fyolo.torch%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Ffrischzenger%2Fyolo-windows%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Ffrischzenger%2Fyolo-windows%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FAlexeyAB%2Fyolo-windows%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FAlexeyAB%2Fyolo-windows%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fnilboy%2Ftensorflow-yolo%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fnilboy%2Ftensorflow-yolo%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3Edarkflow+-+translate+darknet+to+tensorflow.+Load+trained+weights%2C+retrain%2Ffine-tune+them+using+tensorflow%2C+export+constant+graph+def+to+C%2B%2B%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eblog%3A+%3Ca+href%3D%22https%3A%2F%2Fthtrieu.github.io%2Fnotes%2Fyolo-tensorflow-graph-buffer-cpp%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fthtrieu.github.io%2Fnotes%2Fyolo-tensorflow-graph-buffer-cpp%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fthtrieu%2Fdarkflow%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fthtrieu%2Fdarkflow%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EStart+Training+YOLO+with+Our+Own+Data%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2F2f99b692dd7ce47d7832385f3e8a6654e680d92a%2F687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067%22+rel%3D%22nofollow%22%3E%3Cimg+src%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2F2f99b692dd7ce47d7832385f3e8a6654e680d92a%2F687474703a2f2f6775616e6768616e2e696e666f2f626c6f672f656e2f77702d636f6e74656e742f75706c6f6164732f323031352f31322f696d616765732d34302e6a7067%22+alt%3D%22img%22+title%3D%22%22%3E%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+train+with+customized+data+and+class+numbers%2Flabels.+Linux+%2F+Windows+version+for+darknet.%3C%2Fli%3E+%0A+++%3Cli%3Eblog%3A+%3Ca+href%3D%22http%3A%2F%2Fguanghan.info%2Fblog%2Fen%2Fmy-works%2Ftrain-yolo%2F%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fguanghan.info%2Fblog%2Fen%2Fmy-works%2Ftrain-yolo%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FGuanghan%2Fdarknet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FGuanghan%2Fdarknet%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EYOLO%3A+Core+ML+versus+MPSNNGraph%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Tiny+YOLO+for+iOS+implemented+using+CoreML+but+also+using+the+new+MPS+graph+API.%3C%2Fli%3E+%0A+++%3Cli%3Eblog%3A+%3Ca+href%3D%22http%3A%2F%2Fmachinethink.net%2Fblog%2Fyolo-coreml-versus-mps-graph%2F%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fmachinethink.net%2Fblog%2Fyolo-coreml-versus-mps-graph%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fhollance%2FYOLO-CoreML-MPSNNGraph%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fhollance%2FYOLO-CoreML-MPSNNGraph%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ETensorFlow+YOLO+object+detection+on+Android%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Real-time+object+detection+on+Android+using+the+YOLO+network+with+TensorFlow%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fnatanielruiz%2Fandroid-yolo%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fnatanielruiz%2Fandroid-yolo%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EComputer+Vision+in+iOS+%E2%80%93+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eblog%3A+%3Ca+href%3D%22https%3A%2F%2Fsriraghu.com%2F2017%2F07%2F12%2Fcomputer-vision-in-ios-object-detection%2F%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fsriraghu.com%2F2017%2F07%2F12%2Fcomputer-vision-in-ios-object-detection%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fr4ghu%2FiOS-CoreML-Yolo%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fr4ghu%2FiOS-CoreML-Yolo%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22yolov2%22%3EYOLOv2%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EYOLO9000%3A+Better%2C+Faster%2C+Stronger%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.08242%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.08242%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Ecode%3A+%3Ca+href%3D%22http%3A%2F%2Fpjreddie.com%2Fyolo9000%2F%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fpjreddie.com%2Fyolo9000%2F%3C%2Fa%3E+%3Ca+href%3D%22https%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolov2%2F%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolov2%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Chainer%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fleetenki%2FYOLOv2%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fleetenki%2FYOLOv2%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Keras%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fallanzelener%2FYAD2K%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fallanzelener%2FYAD2K%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28PyTorch%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Flongcw%2Fyolo2-pytorch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Flongcw%2Fyolo2-pytorch%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Tensorflow%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fhizhangp%2Fyolo_tensorflow%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fhizhangp%2Fyolo_tensorflow%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Windows%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FAlexeyAB%2Fdarknet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FAlexeyAB%2Fdarknet%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FchoasUp%2Fcaffe-yolo9000%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FchoasUp%2Fcaffe-yolo9000%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fphilipperemy%2Fyolo-9000%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fphilipperemy%2Fyolo-9000%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28TensorFlow%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FKOD-Chen%2FYOLOv2-Tensorflow%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FKOD-Chen%2FYOLOv2-Tensorflow%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Keras%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fyhcc%2Fyolo2%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fyhcc%2Fyolo2%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Keras%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fexperiencor%2Fkeras-yolo2%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fexperiencor%2Fkeras-yolo2%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28TensorFlow%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FWojciechMormul%2Fyolo2%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FWojciechMormul%2Fyolo2%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3Edarknet_scripts%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Auxilary+scripts+to+work+with+%28YOLO%29+darknet+deep+learning+famework.+AKA+-%26gt%3B+How+to+generate+YOLO+anchors%3F%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FJumabek%2Fdarknet_scripts%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FJumabek%2Fdarknet_scripts%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EYolo_mark%3A+GUI+for+marking+bounded+boxes+of+objects+in+images+for+training+Yolo+v2%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FAlexeyAB%2FYolo_mark%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FAlexeyAB%2FYolo_mark%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELightNet%3A+Bringing+pjreddie%E2%80%99s+DarkNet+out+of+the+shadows%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2F%2Fexplosion%2Flightnet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2F%2Fexplosion%2Flightnet%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EYOLO+v2+Bounding+Box+Tool%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Bounding+box+labeler+tool+to+generate+the+training+data+in+the+format+YOLO+v2+requires.%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FCartucho%2Fyolo-boundingbox-labeler-GUI%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FCartucho%2Fyolo-boundingbox-labeler-GUI%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELoss+Rank+Mining%3A+A+General+Hard+Example+Mining+Method+for+Real-time+Detectors%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+%3Cstrong%3ELRM%3C%2Fstrong%3E+is+the+first+hard+example+mining+strategy+which+could+fit+YOLOv2+perfectly+and+make+it+better+applied+in+series+of+real+scenarios+where+both+real-time+rates+and+accurate+detection+are+strongly+demanded.%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.04606%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.04606%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EObject+detection+at+200+Frames+Per+Second%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+faster+than+Tiny-Yolo-v2%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.06361%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.06361%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EEvent-based+Convolutional+Networks+for+Object+Detection+in+Neuromorphic+Cameras%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+YOLE%E2%80%93Object+Detection+in+Neuromorphic+Cameras%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.07931%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.07931%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EOmniDetector%3A+With+Neural+Networks+to+Bounding+Boxes%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+a+person+detector+on+n+fish-eye+images+of+indoor+scenes%EF%BC%88NIPS+2018%EF%BC%89%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.08503%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.08503%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Edatasets%3A%3Ca+href%3D%22https%3A%2F%2Fgitlab.com%2Fomnidetector%2Fomnidetector%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgitlab.com%2Fomnidetector%2Fomnidetector%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22yolov3%22%3EYOLOv3%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EYOLOv3%3A+An+Incremental+Improvement%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.02767%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.02767%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Epaper%3A%3Ca+href%3D%22https%3A%2F%2Fpjreddie.com%2Fmedia%2Ffiles%2Fpapers%2FYOLOv3.pdf%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fpjreddie.com%2Fmedia%2Ffiles%2Fpapers%2FYOLOv3.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Ecode%3A+%3Ca+href%3D%22https%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolo%2F%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fpjreddie.com%2Fdarknet%2Fyolo%2F%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Official%29%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fpjreddie%2Fdarknet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fpjreddie%2Fdarknet%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fexperiencor%2Fkeras-yolo3%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fexperiencor%2Fkeras-yolo3%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fqqwweee%2Fkeras-yolo3%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fqqwweee%2Fkeras-yolo3%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fmarvis%2Fpytorch-yolo3%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fmarvis%2Fpytorch-yolo3%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fayooshkathuria%2Fpytorch-yolo-v3%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fayooshkathuria%2Fpytorch-yolo-v3%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fayooshkathuria%2FYOLO_v3_tutorial_from_scratch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fayooshkathuria%2FYOLO_v3_tutorial_from_scratch%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Feriklindernoren%2FPyTorch-YOLOv3%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Feriklindernoren%2FPyTorch-YOLOv3%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22yolt%22%3EYOLT%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EYou+Only+Look+Twice%3A+Rapid+Multi-Scale+Object+Detection+In+Satellite+Imagery%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3Eintro%3A+Small+Object+Detection%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.09512%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.09512%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Favanetten%2Fyolt%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Favanetten%2Fyolt%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22ssd%22%3ESSD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ESSD%3A+Single+Shot+MultiBox+Detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2Fad9b147ed3a5f48ffb7c3540711c15aa04ce49c6%2F687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67%22+rel%3D%22nofollow%22%3E%3Cimg+src%3D%22https%3A%2F%2Fcamo.githubusercontent.com%2Fad9b147ed3a5f48ffb7c3540711c15aa04ce49c6%2F687474703a2f2f7777772e63732e756e632e6564752f7e776c69752f7061706572732f7373642e706e67%22+alt%3D%22img%22+title%3D%22%22%3E%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ECCV+2016+Oral%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1512.02325%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1512.02325%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Epaper%3A+%3Ca+href%3D%22http%3A%2F%2Fwww.cs.unc.edu%2F%7Ewliu%2Fpapers%2Fssd.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fwww.cs.unc.edu%2F%7Ewliu%2Fpapers%2Fssd.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Eslides%3A+%3Ca+href%3D%22http%3A%2F%2Fwww.cs.unc.edu%2F%7Ewliu%2Fpapers%2Fssd_eccv2016_slide.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fwww.cs.unc.edu%2F%257Ewliu%2Fpapers%2Fssd_eccv2016_slide.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Official%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fweiliu89%2Fcaffe%2Ftree%2Fssd%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fweiliu89%2Fcaffe%2Ftree%2Fssd%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Evideo%3A+%3Ca+href%3D%22http%3A%2F%2Fweibo.com%2Fp%2F2304447a2326da963254c963c97fb05dd3a973%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fweibo.com%2Fp%2F2304447a2326da963254c963c97fb05dd3a973%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fzhreshold%2Fmxnet-ssd%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fzhreshold%2Fmxnet-ssd%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fzhreshold%2Fmxnet-ssd.cpp%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fzhreshold%2Fmxnet-ssd.cpp%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Frykov8%2Fssd_keras%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Frykov8%2Fssd_keras%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fbalancap%2FSSD-Tensorflow%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fbalancap%2FSSD-Tensorflow%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Famdegroot%2Fssd.pytorch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Famdegroot%2Fssd.pytorch%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28Caffe%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fchuanqi305%2FMobileNet-SSD%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fchuanqi305%2FMobileNet-SSD%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EWhat%E2%80%99s+the+diffience+in+performance+between+this+new+code+you+pushed+and+the+previous+code%3F+%23327%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fweiliu89%2Fcaffe%2Fissues%2F327%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fweiliu89%2Fcaffe%2Fissues%2F327%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22dssd%22%3EDSSD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EDSSD+%3A+Deconvolutional+Single+Shot+Detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+UNC+Chapel+Hill+%26amp%3B+Amazon+Inc%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1701.06659%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1701.06659%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fchengyangfu%2Fcaffe%2Ftree%2Fdssd%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fchengyangfu%2Fcaffe%2Ftree%2Fdssd%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FMTCloudVision%2Fmxnet-dssd%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FMTCloudVision%2Fmxnet-dssd%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Edemo%3A+%3Ca+href%3D%22http%3A%2F%2F120.52.72.53%2Fwww.cs.unc.edu%2Fc3pr90ntc0td%2F%7Ecyfu%2Fdssd_lalaland.mp4%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2F120.52.72.53%2Fwww.cs.unc.edu%2Fc3pr90ntc0td%2F%7Ecyfu%2Fdssd_lalaland.mp4%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EEnhancement+of+SSD+by+concatenating+feature+maps+for+object+detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+rainbow+SSD+%28R-SSD%29%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.09587%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.09587%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EContext-aware+Single-Shot+Detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Ekeywords%3A+CSSD%2C+DiCSSD%2C+DeCSSD%2C+effective+receptive+fields+%28ERFs%29%2C+theoretical+receptive+fields+%28TRFs%29%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.08682%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.08682%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EFeature-Fused+SSD%3A+Fast+Detection+for+Small+Objects%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.05054%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.05054%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22fssd%22%3EFSSD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EFSSD%3A+Feature+Fusion+Single+Shot+Multibox+Detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.00960%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.00960%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EWeaving+Multi-scale+Context+for+Single+Shot+Detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+WeaveNet%3C%2Fli%3E+%0A+++%3Cli%3Ekeywords%3A+fuse+multi-scale+information%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.03149%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.03149%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22essd%22%3EESSD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EExtend+the+shallow+part+of+Single+Shot+MultiBox+Detector+via+Convolutional+Neural+Network%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1801.05918%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1801.05918%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ETiny+SSD%3A+A+Tiny+Single-shot+Detection+Deep+Convolutional+Neural+Network+for+Real-time+Embedded+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1802.06488%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1802.06488%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22mdssd%22%3EMDSSD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EMDSSD%3A+Multi-scale+Deconvolutional+Single+Shot+Detector+for+small+objects%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.07009%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.07009%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22pelee%22%3EPelee%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EPelee%3A+A+Real-Time+Object+Detection+System+on+Mobile+Devices%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FRobert-JunWang%2FPelee%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FRobert-JunWang%2FPelee%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3Eintro%3A+%28ICLR+2018+workshop+track%29%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.06882%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.06882%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FRobert-JunWang%2FPelee%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FRobert-JunWang%2FPelee%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22fire-ssd%22%3EFire+SSD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EFire+SSD%3A+Wide+Fire+Modules+based+Single+Shot+Detector+on+Edge+Device%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3Eintro%3Alow+cost%2C+fast+speed+and+high+mAP+on+factor+edge+computing+devices%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1806.05363%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1806.05363%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22r-fcn%22%3ER-FCN%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ER-FCN%3A+Object+Detection+via+Region-based+Fully+Convolutional+Networks%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1605.06409%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1605.06409%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fdaijifeng001%2FR-FCN%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fdaijifeng001%2FR-FCN%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%28MXNet%29%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fmsracver%2FDeformable-ConvNets%2Ftree%2Fmaster%2Frfcn%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fmsracver%2FDeformable-ConvNets%2Ftree%2Fmaster%2Frfcn%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FOrpine%2Fpy-R-FCN%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FOrpine%2Fpy-R-FCN%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FPureDiors%2Fpytorch_RFCN%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FPureDiors%2Fpytorch_RFCN%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fbharatsingh430%2Fpy-R-FCN-multiGPU%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fbharatsingh430%2Fpy-R-FCN-multiGPU%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fxdever%2FRFCN-tensorflow%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fxdever%2FRFCN-tensorflow%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ER-FCN-3000+at+30fps%3A+Decoupling+Detection+and+Classification%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.01802%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.01802%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ERecycle+deep+features+for+better+object+detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22http%3A%2F%2Farxiv.org%2Fabs%2F1607.05066%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Farxiv.org%2Fabs%2F1607.05066%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22fpn%22%3EFPN%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EFeature+Pyramid+Networks+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Facebook+AI+Research%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.03144%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.03144%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EAction-Driven+Object+Detection+with+Top-Down+Visual+Attentions%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.06704%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.06704%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EBeyond+Skip+Connections%3A+Top-Down+Modulation+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CMU+%26amp%3B+UC+Berkeley+%26amp%3B+Google+Research%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1612.06851%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1612.06851%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EWide-Residual-Inception+Networks+for+Real-time+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Inha+University%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.01243%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.01243%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EAttentional+Network+for+Visual+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+University+of+Maryland+%26amp%3B+Mitsubishi+Electric+Research+Laboratories%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.01478%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.01478%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELearning+Chained+Deep+Features+and+Classifiers+for+Cascade+in+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Ekeykwords%3A+CC-Net%3C%2Fli%3E+%0A+++%3Cli%3Eintro%3A+chained+cascade+network+%28CC-Net%29.+81.1%25+mAP+on+PASCAL+VOC+2007%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1702.07054%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1702.07054%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EDeNet%3A+Scalable+Real-time+Object+Detection+with+Directed+Sparse+Sampling%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ICCV+2017+%28poster%29%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1703.10295%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1703.10295%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EDiscriminative+Bimodal+Networks+for+Visual+Localization+and+Detection+with+Natural+Language+Queries%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2017%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.03944%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.03944%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ESpatial+Memory+for+Context+Reasoning+in+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.04224%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.04224%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EAccurate+Single+Stage+Detector+Using+Recurrent+Rolling+Convolution%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2017.+SenseTime%3C%2Fli%3E+%0A+++%3Cli%3Ekeywords%3A+Recurrent+Rolling+Convolution+%28RRC%29%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.05776%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.05776%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FxiaohaoChen%2Frrc_detection%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FxiaohaoChen%2Frrc_detection%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EDeep+Occlusion+Reasoning+for+Multi-Camera+Multi-Target+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1704.05775%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1704.05775%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ELCDet%3A+Low-Complexity+Fully-Convolutional+Neural+Networks+for+Object+Detection+in+Embedded+Systems%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Embedded+Vision+Workshop+in+CVPR.+UC+San+Diego+%26amp%3B+Qualcomm+Inc%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1705.05922%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1705.05922%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EPoint+Linking+Network+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Point+Linking+Network+%28PLN%29%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.03646%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.03646%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EPerceptual+Generative+Adversarial+Networks+for+Small+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.05274%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.05274%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EFew-shot+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.08249%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.08249%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EYes-Net%3A+An+effective+Detector+Based+on+Global+Information%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.09180%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.09180%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ESMC+Faster+R-CNN%3A+Toward+a+scene-specialized+multi-object+detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1706.10217%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1706.10217%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ETowards+lightweight+convolutional+neural+networks+for+object+detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.01395%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.01395%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ERON%3A+Reverse+Connection+with+Objectness+Prior+Networks+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2017%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.01691%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.01691%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Ftaokong%2FRON%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Ftaokong%2FRON%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EMimicking+Very+Efficient+Network+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2017.+SenseTime+%26amp%3B+Beihang+University%3C%2Fli%3E+%0A+++%3Cli%3Epaper%3A+%3Ca+href%3D%22http%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_cvpr_2017%2Fpapers%2FLi_Mimicking_Very_Efficient_CVPR_2017_paper.pdf%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fopenaccess.thecvf.com%2Fcontent_cvpr_2017%2Fpapers%2FLi_Mimicking_Very_Efficient_CVPR_2017_paper.pdf%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EResidual+Features+and+Unified+Prediction+Network+for+Single+Stage+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.05031%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.05031%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EDeformable+Part-based+Fully+Convolutional+Network+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+BMVC+2017+%28oral%29.+Sorbonne+Universit%C3%A9s+%26amp%3B+CEDRIC%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.06175%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.06175%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EAdaptive+Feeding%3A+Achieving+Fast+and+Accurate+Detections+by+Adaptively+Combining+Object+Detectors%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ICCV+2017%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.06399%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.06399%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ERecurrent+Scale+Approximation+for+Object+Detection+in+CNN%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ICCV+2017%3C%2Fli%3E+%0A+++%3Cli%3Ekeywords%3A+Recurrent+Scale+Approximation+%28RSA%29%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1707.09531%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1707.09531%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fsciencefans%2FRSA-for-object-detection%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fsciencefans%2FRSA-for-object-detection%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22dsod%22%3EDSOD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EDSOD%3A+Learning+Deeply+Supervised+Object+Detectors+from+Scratch%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cimg+src%3D%22https%3A%2F%2Fuser-images.githubusercontent.com%2F3794909%2F28934967-718c9302-78b5-11e7-89ee-8b514e53e23c.png%22+alt%3D%22img%22+title%3D%22%22%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ICCV+2017.+Fudan+University+%26amp%3B+Tsinghua+University+%26amp%3B+Intel+Labs+China%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.01241%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.01241%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fszq0214%2FDSOD%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fszq0214%2FDSOD%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FWindaway%2FDSOD-Tensorflow%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FWindaway%2FDSOD-Tensorflow%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fchenyuntc%2Fdsod.pytorch%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fchenyuntc%2Fdsod.pytorch%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELearning+Object+Detectors+from+Scratch+with+Gated+Recurrent+Feature+Pyramids%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.00886%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.00886%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fszq0214%2FGRP-DSOD%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fszq0214%2FGRP-DSOD%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22retinanet%22%3ERetinaNet%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EFocal+Loss+for+Dense+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ICCV+2017+Best+student+paper+award.+Facebook+AI+Research%3C%2Fli%3E+%0A+++%3Cli%3Ekeywords%3A+RetinaNet%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.02002%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.02002%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ECoupleNet%3A+Coupling+Global+Structure+with+Local+Parts+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ICCV+2017%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.02863%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.02863%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EIncremental+Learning+of+Object+Detectors+without+Catastrophic+Forgetting%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+ICCV+2017.+Inria%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1708.06977%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1708.06977%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EZoom+Out-and-In+Network+with+Map+Attention+Decision+for+Region+Proposal+and+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.04347%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.04347%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EStairNet%3A+Top-Down+Semantic+Aggregation+for+Accurate+One+Shot+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1709.05788%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1709.05788%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EDynamic+Zoom-in+Network+for+Fast+Object+Detection+in+Large+Images%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.05187%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.05187%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EZero-Annotation+Object+Detection+with+Web+Knowledge+Transfer%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+NTU%2C+Singapore+%26amp%3B+Amazon%3C%2Fli%3E+%0A+++%3Cli%3Ekeywords%3A+multi-instance+multi-label+domain+adaption+learning+framework%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.05954%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.05954%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22megdet%22%3EMegDet%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EMegDet%3A+A+Large+Mini-Batch+Object+Detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Peking+University+%26amp%3B+Tsinghua+University+%26amp%3B+Megvii+Inc%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.07240%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.07240%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EReceptive+Field+Block+Net+for+Accurate+and+Fast+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+RFBNet%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.07767%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.07767%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2F%2Fruinmessi%2FRFBNet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2F%2Fruinmessi%2FRFBNet%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EAn+Analysis+of+Scale+Invariance+in+Object+Detection+-+SNIP%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.08189%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.08189%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fbharatsingh430%2Fsnip%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fbharatsingh430%2Fsnip%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EFeature+Selective+Networks+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.08879%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.08879%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ELearning+a+Rotation+Invariant+Detector+with+Rotatable+Bounding+Box%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.09405%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.09405%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fliulei01%2FDRBox%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fliulei01%2FDRBox%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EScalable+Object+Detection+for+Stylized+Objects%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Microsoft+AI+%26amp%3B+Research+Munich%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.09822%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.09822%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELearning+Object+Detectors+from+Scratch+with+Gated+Recurrent+Feature+Pyramids%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.00886%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.00886%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fszq0214%2FGRP-DSOD%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fszq0214%2FGRP-DSOD%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EDeep+Regionlets+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Ekeywords%3A+region+selection+network%2C+gating+network%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.02408%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.02408%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ETraining+and+Testing+Object+Detectors+with+Virtual+Images%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+IEEE%2FCAA+Journal+of+Automatica+Sinica%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.08470%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.08470%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELarge-Scale+Object+Discovery+and+Detector+Adaptation+from+Unlabeled+Video%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Ekeywords%3A+object+mining%2C+object+tracking%2C+unsupervised+object+discovery+by+appearance-based+clustering%2C+self-supervised+detector+adaptation%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1712.08832%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1712.08832%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ESpot+the+Difference+by+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Tsinghua+University+%26amp%3B+JD+Group%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1801.01051%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1801.01051%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELocalization-Aware+Active+Learning+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1801.05124%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1801.05124%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EObject+Detection+with+Mask-based+Feature+Encoding%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1802.03934%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1802.03934%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ELSTD%3A+A+Low-Shot+Transfer+Detector+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+AAAI+2018%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.01529%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.01529%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EDomain+Adaptive+Faster+R-CNN+for+Object+Detection+in+the+Wild%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2018.+ETH+Zurich+%26amp%3B+ESAT%2FPSI%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.03243%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.03243%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EPseudo+Mask+Augmented+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.05858%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.05858%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ERevisiting+RCNN%3A+On+Awakening+the+Classification+Power+of+Faster+RCNN%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.06799%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.06799%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ELearning+Region+Features+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Peking+University+%26amp%3B+MSRA%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.07066%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.07066%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ESingle-Shot+Bidirectional+Pyramid+Networks+for+High-Quality+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Singapore+Management+University+%26amp%3B+Zhejiang+University%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.08208%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.08208%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EObject+Detection+for+Comics+using+Manga109+Annotations%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+University+of+Tokyo+%26amp%3B+National+Institute+of+Informatics%2C+Japan%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.08670%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.08670%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ETask-Driven+Super+Resolution%3A+Object+Detection+in+Low-resolution+Images%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.11316%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.11316%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ETransferring+Common-Sense+Knowledge+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.01077%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.01077%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3EMulti-scale+Location-aware+Kernel+Representation+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2018%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.00428%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.00428%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FHwang64%2FMLKP%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FHwang64%2FMLKP%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELoss+Rank+Mining%3A+A+General+Hard+Example+Mining+Method+for+Real-time+Detectors%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+National+University+of+Defense+Technology%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.04606%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.04606%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ERobust+Physical+Adversarial+Attack+on+Faster+R-CNN+Object+Detector%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.05810%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.05810%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Ch2+id%3D%22refinenet%22%3ERefineNet%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ESingle-Shot+Refinement+Neural+Network+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3Eintro%3A+CVPR+2018%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.06897%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.06897%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fsfzhang15%2FRefineDet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fsfzhang15%2FRefineDet%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Flzx1413%2FPytorchSSD%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Flzx1413%2FPytorchSSD%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fddlee96%2FRefineDet_mxnet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fddlee96%2FRefineDet_mxnet%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FMTCloudVision%2FRefineDet-Mxnet%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FMTCloudVision%2FRefineDet-Mxnet%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22detnet%22%3EDetNet%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EDetNet%3A+A+Backbone+network+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3Eintro%3A+Tsinghua+University+%26amp%3B+Face%2B%2B%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.06215%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.06215%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22ssod%22%3ESSOD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ESelf-supervisory+Signals+for+Object+Discovery+and+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3EGoogle+Brain%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1806.03370%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1806.03370%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%223d-object-detection%22%3E3D+Object+Detection%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3ELMNet%3A+Real-time+Multiclass+Object+Detection+on+CPU+using+3D+LiDARs%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.04902%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.04902%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2FCPFL%2FAutoware%2Ftree%2Ffeature%2Fcnn_lidar_detection%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2FCPFL%2FAutoware%2Ftree%2Ffeature%2Fcnn_lidar_detection%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22zsd%22%3EZSD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EZero-Shot+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+Australian+National+University%3C%2Fli%3E+%0A+++%3Cli%3Ekeywords%3A+YOLO%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.07113%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.07113%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EZero-Shot+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1804.04340%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1804.04340%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EZero-Shot+Object+Detection%3A+Learning+to+Simultaneously+Recognize+and+Localize+Novel+Concepts%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1803.06049%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1803.06049%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EZero-Shot+Object+Detection+by+Hybrid+Region+Embedding%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.06157%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.06157%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%22osd%22%3EOSD%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EOne-Shot+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3ERepMet%3A+Representative-based+metric+learning+for+classification+and+one-shot+object+detection%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3Eintro%3A+IBM+Research+AI%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1806.04728%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1806.04728%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A+TODO%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Ch2+id%3D%222018%22%3E2018%3C%2Fh2%3E+%0A++%3Cp%3E%3Cstrong%3EMetaAnchor%3A+Learning+to+Detect+Objects+with+Customized+Anchors%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cp%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1807.00980%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1807.00980%3C%2Fa%3E%3C%2Fp%3E+%0A++%3Cp%3E%3Cstrong%3ERelation+Network+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2018%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1711.11575%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1711.11575%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fmsracver%2FRelation-Networks-for-Object-Detection%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fmsracver%2FRelation-Networks-for-Object-Detection%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3EQuantization+Mimic%3A+Towards+Very+Tiny+CNN+for+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3ETsinghua+University1+%26amp%3B+The+Chinese+University+of+Hong+Kong2+%26amp%3BSenseTime3%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.02152%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.02152%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ELearning+Rich+Features+for+Image+Manipulation+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+CVPR+2018+Camera+Ready%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A+%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.04953%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.04953%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ESNIPER%3A+Efficient+Multi-Scale+Training%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1805.09300%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1805.09300%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Egithub%3A%3Ca+href%3D%22https%3A%2F%2Fgithub.com%2Fmahyarnajibi%2FSNIPER%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Fgithub.com%2Fmahyarnajibi%2FSNIPER%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ESoft+Sampling+for+Robust+Object+Detection%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3E%3Cp%3Eintro%3A+the+robustness+of+object+detection+under+the+presence+of+missing+annotations%3C%2Fp%3E%3C%2Fli%3E+%0A+++%3Cli%3E%3Cp%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1806.06986%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1806.06986%3C%2Fa%3E%3C%2Fp%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A++%3Cp%3E%3Cstrong%3ECost-effective+Object+Detection%3A+Active+Sample+Mining+with+Switchable+Selection+Criteria%3C%2Fstrong%3E%3C%2Fp%3E+%0A++%3Cul%3E+%0A+++%3Cli%3Eintro%3A+TNNLS+2018%3C%2Fli%3E+%0A+++%3Cli%3Earxiv%3A%3Ca+href%3D%22https%3A%2F%2Farxiv.org%2Fabs%2F1807.00147%22+rel%3D%22nofollow%22%3Ehttps%3A%2F%2Farxiv.org%2Fabs%2F1807.00147%3C%2Fa%3E%3C%2Fli%3E+%0A+++%3Cli%3Ecode%3A+%3Ca+href%3D%22http%3A%2F%2Fkezewang.com%2Fcodes%2FASM_ver1.zip%22+rel%3D%22nofollow%22%3Ehttp%3A%2F%2Fkezewang.com%2Fcodes%2FASM_ver1.zip%3C%2Fa%3E%3C%2Fli%3E+%0A++%3C%2Ful%3E+%0A+%3C%2Fdiv%3E+%0A+%3Clink+href%3D%22https%3A%2F%2Fcsdnimg.cn%2Frelease%2Fphoenix%2Fmdeditor%2Fmarkdown_views-8cccb36679.css%22+rel%3D%22stylesheet%22%3E+%0A%3C%2Fdiv%3E+%0A%3Cdiv+class%3D%22hide-article-box+text-center%22%3E+%0A+%3Ca+class%3D%22btn%22+id%3D%22btn-readmore%22+data-track-view%3D%22%7B%26quot%3Bmod%26quot%3B%3A%26quot%3Bpopu_376%26quot%3B%2C%26quot%3Bcon%26quot%3B%3A%26quot%3B%2Chttps%3A%2F%2Fblog.csdn.net%2Famusi1994%2Farticle%2Fdetails%2F81042923%2C%26quot%3B%7D%22+data-track-click%3D%22%7B%26quot%3Bmod%26quot%3B%3A%26quot%3Bpopu_376%26quot%3B%2C%26quot%3Bcon%26quot%3B%3A%26quot%3B%2Chttps%3A%2F%2Fblog.csdn.net%2Famusi1994%2Farticle%2Fdetails%2F81042923%2C%26quot%3B%7D%22%3E%E9%98%85%E8%AF%BB%E6%9B%B4%E5%A4%9A%3C%2Fa%3E+%0A+%3C%21--+%3Ca+class%3D%22btn%22+href%3D%22https%3A%2F%2Fpassport.csdn.net%2Faccount%2Flogin%3Futm_source%3Dcsdn_blog_pc_more_login%22+target%3D%22_self%22+id%3D%22btn-lobinreadmore%22+data-track-view%3D%27%7B%22mod%22%3A%22popu_557%22%2C%22con%22%3A%22%2Chttps%3A%2F%2Fblog.csdn.net%2Famusi1994%2Farticle%2Fdetails%2F81042923%2C%22%7D%27+data-track-click%3D%27%7B%22mod%22%3A%22popu_557%22%2C%22con%22%3A%22%2Chttps%3A%2F%2Fblog.csdn.net%2Famusi1994%2Farticle%2Fdetails%2F81042923%2C%22%7D%27%3E%E7%99%BB%E5%BD%95%E5%90%8E%E8%87%AA%E5%8A%A8%E5%B1%95%E5%BC%80%3C%2Fa%3E+--%3E+%0A%3C%2Fdiv%3E" | url_decode}}