<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>ETH-Pow算法分析 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="ETH-Pow算法分析" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1. Ethash&nbsp;算法 1.1 Ethash Ethash是以太坊1.0中使用的PoW(工作量证明)算法,它是Hashimoto算法结合Dagger之后产生的一个变种。它的特点是计算的效率基本与CPU无关，却和内存大小和内存带宽正相关。因此通过共享内存的方式大规模部署的矿机芯片并不能在挖矿效率上有线性或者超线性的增长。 该算法的一般流程如下： 首先根据块信息计算一个种子(seed, c++代码中为seedhash) 使用这个种子，计算出一个16MB的cache数据。轻客户端需要存储这份cache. 通过cache，计算出一个1GB(初始大小)的数据集(DAG)，DAG可以理解为是一个完整的搜索空间，全客户端和矿工需要存储完整的DAG，挖矿过程中需要从DAG中重复的随机抽取数据拿去和其他数据计算mixhash，DAG中每个元素的生成只依赖于cache中的少量数据。每到一个新的纪元DAG会完全不一样，并且它的大小也随时间线性增长。 由于仅根据cache就可以使用少量内存快速的计算出DAG中指定位置的数据，所以轻客户端只需要存储cache就可以高效的进行校验。 1.2 内存难解 由于比特币将hash算法作为pow工作量证明的重要手段，后续的各种采用pow的数字货币也延续了这个设计，以SHA256、MD5（MD5后来被证明不具备强碰撞性数字货币一般不用）为代表算法。在设计之初都是算力敏感型，意味着计算资源是瓶颈，主频越高的 CPU 进行 Hash 的速度也越快。这个设计直接导致后来的矿机出现，采用ASIC芯片的矿机更是将这种运算能力成倍提升，更多矿场的出现使得当时的比特币面临算力中心化的威胁。为了限制计算能力的依赖，人们开始寻求新的算法，既然要限制CPU的能力，目光自然投向存储依赖，也就是内存依赖。 ​ Hashimoto算法采用IO饱和的策略来对抗ASIC，使内存读取成为采矿过程中的限制因素。 ​ Dagger算法使用DAG(directed acyclic graphs 有向无环图)来同时实现内存难解和内存易验证两个特点。 主要原理是，计算每个nonce需要DAG中的一小部分，采矿过程需要存储完整的DAG，禁止每次计算DAG的相应子集，而验证过程是允许的。 1.3 参数定义 &nbsp; WORD_BYTES&nbsp; 4&nbsp; Word的字节数&nbsp; &nbsp; DATASET_BYTES_INIT&nbsp; 2**30 1GB&nbsp; Dataset的初始大小 | &nbsp; DATASET_BYTES_GROWTH&nbsp; 2**23 8MB&nbsp; 每个纪元dataset的增长量 | &nbsp; CACHE_BYTES_INIT&nbsp; 2**24 16MB&nbsp; Cache的初始大小 | &nbsp; CHCHE_BYTES_GROWTH&nbsp; 2**17 128KB&nbsp; 每个纪元cache的增长量 | &nbsp; CACHE_MULTIPLIER&nbsp; 1024&nbsp; Size of the DAG relative to the cache | &nbsp; EPOCH_LENGTH&nbsp; 30000&nbsp; 每个epoch的块数 | &nbsp; MIX_BYTES&nbsp; 128&nbsp; Mix的宽度 | &nbsp; HASH_BYTES&nbsp; 64&nbsp; Hash的长度 | &nbsp; DATASET_PARENTS&nbsp; 256&nbsp; 每个数据集元素的parents数量 | &nbsp; CACHE_ROUNDS&nbsp; 3&nbsp; 计算cache时的轮数 | &nbsp; ACCESSES&nbsp; 64&nbsp; Hashimoto循环的次数 | &nbsp; 2 DAG DAG是ethash算法中需要频繁访问的数据集，这个为每个epoch生成的。DAG要花很长时间生成，如果客户端至少按照需要生成它，那么在找到新epoch第一个区块之前，每个epoch过渡都要等待很长时间。然而，DAG的生成只取决于区块数量，所以可以预先计算出DAG来避免在每个epoch过渡过长的等待时间。 DAG的生成流程如下： 2.1 Dag_size 和Cache_size 每个epoch的dagsize和cachesize都不同，上面已经定义了创世时的初始值，以太坊还提供了一个表来存储接下来2048个纪元(大约20年)的各个值。详见官网或源码cpp-ethereum/libethash/data_sizes.h. 获取datasize 和cachesize的方法如下: 2.2 Seedhash 算法中需要一个seedhash，由下面程序生成，从程序可见每个epoch的seed是不变的。 2.3 Cache 使用seedhash计算cache。 2.4 DAG 最后使用cache计算DAG，light参数中保存的是cache数据. 2.5 DAG文件 DAG每次生成都需要很长时间，因此生成时候需要存在文件中，再使用mmap映射到内存中。DAG文件路径一般如下 Mac/Linux : $HOME/.ethash/full-R– Windows: $HOME/Appdata/Local/Ethash/full-R– 是ethash算法的版本号，在libethash/ethash.h 中REVISION定义。 是上面计算出来的seedhash 路径下可能会有多个DAG文件，这取决于用户或者客户端是否删除过时的DAG文件。 格式： DAG文件以8字节的幻数开头，值为0xfee1deadbaddcafe, 以小端格式写入。接下来是小端格式写入的dataset数据。 &nbsp; 3 Ethash实现 3.1 Ethash 图1 算法流程图 参数说明： Header_hash: 是当前块头部数据的hash值，在矿机调用get_ethwork时从任务参数中获取。 Nonce: 是每次计算ethash使用不同的数，不能重复。可以取时间戳或随机数作为起始值，然后递增。 对于矿工来说，如果result的值小于或等于target，那么就完成了挖矿过程，将当前的nonce和mix_hash作为工作量证明提交工作；如果result的值大于target，那么就需要改变nonce的值，再次调用ethash算法. Ethash算法程序如下： 从图中看，每次ethash从DAG随机取64128=8192Bytes, 以GTX1070显卡为例，带宽为256GB/s, 那么每秒能承受256102410241024/8192=33554432次ethash运算，即33MH/s的算力。可见，该算法对内存带宽的要求很高。 3.2 快速验证 当验证一个工作提交是否有效时，速度很快。 下面是快速验证程序： &nbsp; &nbsp; 原文链接：http://wangxiaoming.com/blog/2018/06/26/HPB-47-ETH-Pow/ &nbsp; 关于我：蓝莲花（汪晓明），微信/QQ：86606813，公众号：xm123798。HPB芯链（http://www.hpb.io)创始人。致力于推动区块链应用落地。 &nbsp; 阅读更多" />
<meta property="og:description" content="1. Ethash&nbsp;算法 1.1 Ethash Ethash是以太坊1.0中使用的PoW(工作量证明)算法,它是Hashimoto算法结合Dagger之后产生的一个变种。它的特点是计算的效率基本与CPU无关，却和内存大小和内存带宽正相关。因此通过共享内存的方式大规模部署的矿机芯片并不能在挖矿效率上有线性或者超线性的增长。 该算法的一般流程如下： 首先根据块信息计算一个种子(seed, c++代码中为seedhash) 使用这个种子，计算出一个16MB的cache数据。轻客户端需要存储这份cache. 通过cache，计算出一个1GB(初始大小)的数据集(DAG)，DAG可以理解为是一个完整的搜索空间，全客户端和矿工需要存储完整的DAG，挖矿过程中需要从DAG中重复的随机抽取数据拿去和其他数据计算mixhash，DAG中每个元素的生成只依赖于cache中的少量数据。每到一个新的纪元DAG会完全不一样，并且它的大小也随时间线性增长。 由于仅根据cache就可以使用少量内存快速的计算出DAG中指定位置的数据，所以轻客户端只需要存储cache就可以高效的进行校验。 1.2 内存难解 由于比特币将hash算法作为pow工作量证明的重要手段，后续的各种采用pow的数字货币也延续了这个设计，以SHA256、MD5（MD5后来被证明不具备强碰撞性数字货币一般不用）为代表算法。在设计之初都是算力敏感型，意味着计算资源是瓶颈，主频越高的 CPU 进行 Hash 的速度也越快。这个设计直接导致后来的矿机出现，采用ASIC芯片的矿机更是将这种运算能力成倍提升，更多矿场的出现使得当时的比特币面临算力中心化的威胁。为了限制计算能力的依赖，人们开始寻求新的算法，既然要限制CPU的能力，目光自然投向存储依赖，也就是内存依赖。 ​ Hashimoto算法采用IO饱和的策略来对抗ASIC，使内存读取成为采矿过程中的限制因素。 ​ Dagger算法使用DAG(directed acyclic graphs 有向无环图)来同时实现内存难解和内存易验证两个特点。 主要原理是，计算每个nonce需要DAG中的一小部分，采矿过程需要存储完整的DAG，禁止每次计算DAG的相应子集，而验证过程是允许的。 1.3 参数定义 &nbsp; WORD_BYTES&nbsp; 4&nbsp; Word的字节数&nbsp; &nbsp; DATASET_BYTES_INIT&nbsp; 2**30 1GB&nbsp; Dataset的初始大小 | &nbsp; DATASET_BYTES_GROWTH&nbsp; 2**23 8MB&nbsp; 每个纪元dataset的增长量 | &nbsp; CACHE_BYTES_INIT&nbsp; 2**24 16MB&nbsp; Cache的初始大小 | &nbsp; CHCHE_BYTES_GROWTH&nbsp; 2**17 128KB&nbsp; 每个纪元cache的增长量 | &nbsp; CACHE_MULTIPLIER&nbsp; 1024&nbsp; Size of the DAG relative to the cache | &nbsp; EPOCH_LENGTH&nbsp; 30000&nbsp; 每个epoch的块数 | &nbsp; MIX_BYTES&nbsp; 128&nbsp; Mix的宽度 | &nbsp; HASH_BYTES&nbsp; 64&nbsp; Hash的长度 | &nbsp; DATASET_PARENTS&nbsp; 256&nbsp; 每个数据集元素的parents数量 | &nbsp; CACHE_ROUNDS&nbsp; 3&nbsp; 计算cache时的轮数 | &nbsp; ACCESSES&nbsp; 64&nbsp; Hashimoto循环的次数 | &nbsp; 2 DAG DAG是ethash算法中需要频繁访问的数据集，这个为每个epoch生成的。DAG要花很长时间生成，如果客户端至少按照需要生成它，那么在找到新epoch第一个区块之前，每个epoch过渡都要等待很长时间。然而，DAG的生成只取决于区块数量，所以可以预先计算出DAG来避免在每个epoch过渡过长的等待时间。 DAG的生成流程如下： 2.1 Dag_size 和Cache_size 每个epoch的dagsize和cachesize都不同，上面已经定义了创世时的初始值，以太坊还提供了一个表来存储接下来2048个纪元(大约20年)的各个值。详见官网或源码cpp-ethereum/libethash/data_sizes.h. 获取datasize 和cachesize的方法如下: 2.2 Seedhash 算法中需要一个seedhash，由下面程序生成，从程序可见每个epoch的seed是不变的。 2.3 Cache 使用seedhash计算cache。 2.4 DAG 最后使用cache计算DAG，light参数中保存的是cache数据. 2.5 DAG文件 DAG每次生成都需要很长时间，因此生成时候需要存在文件中，再使用mmap映射到内存中。DAG文件路径一般如下 Mac/Linux : $HOME/.ethash/full-R– Windows: $HOME/Appdata/Local/Ethash/full-R– 是ethash算法的版本号，在libethash/ethash.h 中REVISION定义。 是上面计算出来的seedhash 路径下可能会有多个DAG文件，这取决于用户或者客户端是否删除过时的DAG文件。 格式： DAG文件以8字节的幻数开头，值为0xfee1deadbaddcafe, 以小端格式写入。接下来是小端格式写入的dataset数据。 &nbsp; 3 Ethash实现 3.1 Ethash 图1 算法流程图 参数说明： Header_hash: 是当前块头部数据的hash值，在矿机调用get_ethwork时从任务参数中获取。 Nonce: 是每次计算ethash使用不同的数，不能重复。可以取时间戳或随机数作为起始值，然后递增。 对于矿工来说，如果result的值小于或等于target，那么就完成了挖矿过程，将当前的nonce和mix_hash作为工作量证明提交工作；如果result的值大于target，那么就需要改变nonce的值，再次调用ethash算法. Ethash算法程序如下： 从图中看，每次ethash从DAG随机取64128=8192Bytes, 以GTX1070显卡为例，带宽为256GB/s, 那么每秒能承受256102410241024/8192=33554432次ethash运算，即33MH/s的算力。可见，该算法对内存带宽的要求很高。 3.2 快速验证 当验证一个工作提交是否有效时，速度很快。 下面是快速验证程序： &nbsp; &nbsp; 原文链接：http://wangxiaoming.com/blog/2018/06/26/HPB-47-ETH-Pow/ &nbsp; 关于我：蓝莲花（汪晓明），微信/QQ：86606813，公众号：xm123798。HPB芯链（http://www.hpb.io)创始人。致力于推动区块链应用落地。 &nbsp; 阅读更多" />
<link rel="canonical" href="https://mlh.app/2018/08/21/53bf887e19d7849a42bbb5b62ac0b303.html" />
<meta property="og:url" content="https://mlh.app/2018/08/21/53bf887e19d7849a42bbb5b62ac0b303.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-08-21T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"1. Ethash&nbsp;算法 1.1 Ethash Ethash是以太坊1.0中使用的PoW(工作量证明)算法,它是Hashimoto算法结合Dagger之后产生的一个变种。它的特点是计算的效率基本与CPU无关，却和内存大小和内存带宽正相关。因此通过共享内存的方式大规模部署的矿机芯片并不能在挖矿效率上有线性或者超线性的增长。 该算法的一般流程如下： 首先根据块信息计算一个种子(seed, c++代码中为seedhash) 使用这个种子，计算出一个16MB的cache数据。轻客户端需要存储这份cache. 通过cache，计算出一个1GB(初始大小)的数据集(DAG)，DAG可以理解为是一个完整的搜索空间，全客户端和矿工需要存储完整的DAG，挖矿过程中需要从DAG中重复的随机抽取数据拿去和其他数据计算mixhash，DAG中每个元素的生成只依赖于cache中的少量数据。每到一个新的纪元DAG会完全不一样，并且它的大小也随时间线性增长。 由于仅根据cache就可以使用少量内存快速的计算出DAG中指定位置的数据，所以轻客户端只需要存储cache就可以高效的进行校验。 1.2 内存难解 由于比特币将hash算法作为pow工作量证明的重要手段，后续的各种采用pow的数字货币也延续了这个设计，以SHA256、MD5（MD5后来被证明不具备强碰撞性数字货币一般不用）为代表算法。在设计之初都是算力敏感型，意味着计算资源是瓶颈，主频越高的 CPU 进行 Hash 的速度也越快。这个设计直接导致后来的矿机出现，采用ASIC芯片的矿机更是将这种运算能力成倍提升，更多矿场的出现使得当时的比特币面临算力中心化的威胁。为了限制计算能力的依赖，人们开始寻求新的算法，既然要限制CPU的能力，目光自然投向存储依赖，也就是内存依赖。 ​ Hashimoto算法采用IO饱和的策略来对抗ASIC，使内存读取成为采矿过程中的限制因素。 ​ Dagger算法使用DAG(directed acyclic graphs 有向无环图)来同时实现内存难解和内存易验证两个特点。 主要原理是，计算每个nonce需要DAG中的一小部分，采矿过程需要存储完整的DAG，禁止每次计算DAG的相应子集，而验证过程是允许的。 1.3 参数定义 &nbsp; WORD_BYTES&nbsp; 4&nbsp; Word的字节数&nbsp; &nbsp; DATASET_BYTES_INIT&nbsp; 2**30 1GB&nbsp; Dataset的初始大小 | &nbsp; DATASET_BYTES_GROWTH&nbsp; 2**23 8MB&nbsp; 每个纪元dataset的增长量 | &nbsp; CACHE_BYTES_INIT&nbsp; 2**24 16MB&nbsp; Cache的初始大小 | &nbsp; CHCHE_BYTES_GROWTH&nbsp; 2**17 128KB&nbsp; 每个纪元cache的增长量 | &nbsp; CACHE_MULTIPLIER&nbsp; 1024&nbsp; Size of the DAG relative to the cache | &nbsp; EPOCH_LENGTH&nbsp; 30000&nbsp; 每个epoch的块数 | &nbsp; MIX_BYTES&nbsp; 128&nbsp; Mix的宽度 | &nbsp; HASH_BYTES&nbsp; 64&nbsp; Hash的长度 | &nbsp; DATASET_PARENTS&nbsp; 256&nbsp; 每个数据集元素的parents数量 | &nbsp; CACHE_ROUNDS&nbsp; 3&nbsp; 计算cache时的轮数 | &nbsp; ACCESSES&nbsp; 64&nbsp; Hashimoto循环的次数 | &nbsp; 2 DAG DAG是ethash算法中需要频繁访问的数据集，这个为每个epoch生成的。DAG要花很长时间生成，如果客户端至少按照需要生成它，那么在找到新epoch第一个区块之前，每个epoch过渡都要等待很长时间。然而，DAG的生成只取决于区块数量，所以可以预先计算出DAG来避免在每个epoch过渡过长的等待时间。 DAG的生成流程如下： 2.1 Dag_size 和Cache_size 每个epoch的dagsize和cachesize都不同，上面已经定义了创世时的初始值，以太坊还提供了一个表来存储接下来2048个纪元(大约20年)的各个值。详见官网或源码cpp-ethereum/libethash/data_sizes.h. 获取datasize 和cachesize的方法如下: 2.2 Seedhash 算法中需要一个seedhash，由下面程序生成，从程序可见每个epoch的seed是不变的。 2.3 Cache 使用seedhash计算cache。 2.4 DAG 最后使用cache计算DAG，light参数中保存的是cache数据. 2.5 DAG文件 DAG每次生成都需要很长时间，因此生成时候需要存在文件中，再使用mmap映射到内存中。DAG文件路径一般如下 Mac/Linux : $HOME/.ethash/full-R– Windows: $HOME/Appdata/Local/Ethash/full-R– 是ethash算法的版本号，在libethash/ethash.h 中REVISION定义。 是上面计算出来的seedhash 路径下可能会有多个DAG文件，这取决于用户或者客户端是否删除过时的DAG文件。 格式： DAG文件以8字节的幻数开头，值为0xfee1deadbaddcafe, 以小端格式写入。接下来是小端格式写入的dataset数据。 &nbsp; 3 Ethash实现 3.1 Ethash 图1 算法流程图 参数说明： Header_hash: 是当前块头部数据的hash值，在矿机调用get_ethwork时从任务参数中获取。 Nonce: 是每次计算ethash使用不同的数，不能重复。可以取时间戳或随机数作为起始值，然后递增。 对于矿工来说，如果result的值小于或等于target，那么就完成了挖矿过程，将当前的nonce和mix_hash作为工作量证明提交工作；如果result的值大于target，那么就需要改变nonce的值，再次调用ethash算法. Ethash算法程序如下： 从图中看，每次ethash从DAG随机取64128=8192Bytes, 以GTX1070显卡为例，带宽为256GB/s, 那么每秒能承受256102410241024/8192=33554432次ethash运算，即33MH/s的算力。可见，该算法对内存带宽的要求很高。 3.2 快速验证 当验证一个工作提交是否有效时，速度很快。 下面是快速验证程序： &nbsp; &nbsp; 原文链接：http://wangxiaoming.com/blog/2018/06/26/HPB-47-ETH-Pow/ &nbsp; 关于我：蓝莲花（汪晓明），微信/QQ：86606813，公众号：xm123798。HPB芯链（http://www.hpb.io)创始人。致力于推动区块链应用落地。 &nbsp; 阅读更多","@type":"BlogPosting","url":"https://mlh.app/2018/08/21/53bf887e19d7849a42bbb5b62ac0b303.html","headline":"ETH-Pow算法分析","dateModified":"2018-08-21T00:00:00+08:00","datePublished":"2018-08-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2018/08/21/53bf887e19d7849a42bbb5b62ac0b303.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>ETH-Pow算法分析</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-e2445db1a8.css"> 
 <div class="htmledit_views"> 
  <p><strong>1. Ethash</strong>&nbsp;<strong>算法</strong></p> 
  <p><strong>1.1 Ethash</strong></p> 
  <p>Ethash是以太坊1.0中使用的PoW(工作量证明)算法,它是Hashimoto算法结合Dagger之后产生的一个变种。它的特点是计算的效率基本与CPU无关，却和内存大小和内存带宽正相关。因此通过共享内存的方式大规模部署的矿机芯片并不能在挖矿效率上有线性或者超线性的增长。</p> 
  <p>该算法的一般流程如下：</p> 
  <ul>
   <li>首先根据块信息计算一个种子(seed, c++代码中为seedhash)</li> 
   <li>使用这个种子，计算出一个16MB的cache数据。轻客户端需要存储这份cache.</li> 
   <li>通过cache，计算出一个1GB(初始大小)的数据集(DAG)，DAG可以理解为是一个完整的搜索空间，全客户端和矿工需要存储完整的DAG，挖矿过程中需要从DAG中重复的随机抽取数据拿去和其他数据计算mixhash，DAG中每个元素的生成只依赖于cache中的少量数据。每到一个新的纪元DAG会完全不一样，并且它的大小也随时间线性增长。</li> 
   <li>由于仅根据cache就可以使用少量内存快速的计算出DAG中指定位置的数据，所以轻客户端只需要存储cache就可以高效的进行校验。</li> 
  </ul>
  <p><strong>1.2 内存难解</strong></p> 
  <p>由于比特币将hash算法作为pow工作量证明的重要手段，后续的各种采用pow的数字货币也延续了这个设计，以SHA256、MD5（MD5后来被证明不具备强碰撞性数字货币一般不用）为代表算法。在设计之初都是算力敏感型，意味着计算资源是瓶颈，主频越高的 CPU 进行 Hash 的速度也越快。这个设计直接导致后来的矿机出现，采用ASIC芯片的矿机更是将这种运算能力成倍提升，更多矿场的出现使得当时的比特币面临算力中心化的威胁。为了限制计算能力的依赖，人们开始寻求新的算法，既然要限制CPU的能力，目光自然投向存储依赖，也就是内存依赖。</p> 
  <p>​ Hashimoto算法采用IO饱和的策略来对抗ASIC，使内存读取成为采矿过程中的限制因素。</p> 
  <p>​ Dagger算法使用DAG(directed acyclic graphs 有向无环图)来同时实现内存难解和内存易验证两个特点。 主要原理是，计算每个nonce需要DAG中的一小部分，采矿过程需要存储完整的DAG，禁止每次计算DAG的相应子集，而验证过程是允许的。</p> 
  <p><strong>1.3 参数定义</strong></p> 
  <table>
   <thead>
    <tr>
     <th>&nbsp;</th> 
     <th>WORD_BYTES&nbsp;</th> 
     <th>4&nbsp;</th> 
     <th>Word的字节数&nbsp;</th> 
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>&nbsp;</td> 
     <td>DATASET_BYTES_INIT&nbsp;</td> 
     <td>2**30 1GB&nbsp;</td> 
     <td>Dataset的初始大小 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>DATASET_BYTES_GROWTH&nbsp;</td> 
     <td>2**23 8MB&nbsp;</td> 
     <td>每个纪元dataset的增长量 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>CACHE_BYTES_INIT&nbsp;</td> 
     <td>2**24 16MB&nbsp;</td> 
     <td>Cache的初始大小 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>CHCHE_BYTES_GROWTH&nbsp;</td> 
     <td>2**17 128KB&nbsp;</td> 
     <td>每个纪元cache的增长量 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>CACHE_MULTIPLIER&nbsp;</td> 
     <td>1024&nbsp;</td> 
     <td>Size of the DAG relative to the cache |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>EPOCH_LENGTH&nbsp;</td> 
     <td>30000&nbsp;</td> 
     <td>每个epoch的块数 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>MIX_BYTES&nbsp;</td> 
     <td>128&nbsp;</td> 
     <td>Mix的宽度 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>HASH_BYTES&nbsp;</td> 
     <td>64&nbsp;</td> 
     <td>Hash的长度 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>DATASET_PARENTS&nbsp;</td> 
     <td>256&nbsp;</td> 
     <td>每个数据集元素的parents数量 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>CACHE_ROUNDS&nbsp;</td> 
     <td>3&nbsp;</td> 
     <td>计算cache时的轮数 |</td> 
    </tr>
    <tr>
     <td>&nbsp;</td> 
     <td>ACCESSES&nbsp;</td> 
     <td>64&nbsp;</td> 
     <td>Hashimoto循环的次数 |</td> 
    </tr>
   </tbody>
  </table>
  <p>&nbsp;</p> 
  <p><strong>2 DAG</strong></p> 
  <p>DAG是ethash算法中需要频繁访问的数据集，这个为每个epoch生成的。DAG要花很长时间生成，如果客户端至少按照需要生成它，那么在找到新epoch第一个区块之前，每个epoch过渡都要等待很长时间。然而，DAG的生成只取决于区块数量，所以可以预先计算出DAG来避免在每个epoch过渡过长的等待时间。</p> 
  <p>DAG的生成流程如下：</p> 
  <p><strong>2.1 Dag_size 和Cache_size</strong></p> 
  <p>每个epoch的dagsize和cachesize都不同，上面已经定义了创世时的初始值，以太坊还提供了一个表来存储接下来2048个纪元(大约20年)的各个值。详见<a href="https://github.com/ethereum/wiki/wiki/Ethash#data-sizes" rel="nofollow">官网</a>或源码cpp-ethereum/libethash/data_sizes.h.</p> 
  <p>获取datasize 和cachesize的方法如下:</p> 
  <p><img alt="" class="has" src="http://assets.wangxiaoming.com/image/pow1.png"></p> 
  <p><strong>2.2 Seedhash</strong></p> 
  <p>算法中需要一个seedhash，由下面程序生成，从程序可见每个epoch的seed是不变的。</p> 
  <p><img alt="" class="has" src="http://assets.wangxiaoming.com/image/pow2.png"></p> 
  <p><strong>2.3 Cache</strong></p> 
  <p>使用seedhash计算cache。</p> 
  <p><img alt="" class="has" src="http://assets.wangxiaoming.com/image/pow3.png"></p> 
  <p><strong>2.4 DAG</strong></p> 
  <p>最后使用cache计算DAG，light参数中保存的是cache数据.</p> 
  <p><img alt="" class="has" src="http://assets.wangxiaoming.com/image/pow4.png"></p> 
  <p><strong>2.5 DAG文件</strong></p> 
  <p>DAG每次生成都需要很长时间，因此生成时候需要存在文件中，再使用mmap映射到内存中。DAG文件路径一般如下</p> 
  <p>Mac/Linux : $HOME/.ethash/full-R–</p> 
  <p>Windows: $HOME/Appdata/Local/Ethash/full-R–</p> 
  <p>是ethash算法的版本号，在libethash/ethash.h 中REVISION定义。</p> 
  <p>是上面计算出来的seedhash</p> 
  <p>路径下可能会有多个DAG文件，这取决于用户或者客户端是否删除过时的DAG文件。</p> 
  <p>格式：</p> 
  <p>DAG文件以8字节的幻数开头，值为0xfee1deadbaddcafe, 以小端格式写入。接下来是小端格式写入的dataset数据。</p> 
  <p>&nbsp;</p> 
  <p><strong>3 Ethash实现</strong></p> 
  <p><strong>3.1 Ethash</strong></p> 
  <p><img alt="" class="has" src="http://assets.wangxiaoming.com/image/pow5.png"></p> 
  <p>图1 算法流程图</p> 
  <p>参数说明：</p> 
  <p>Header_hash: 是当前块头部数据的hash值，在矿机调用get_ethwork时从任务参数中获取。</p> 
  <p>Nonce: 是每次计算ethash使用不同的数，不能重复。可以取时间戳或随机数作为起始值，然后递增。</p> 
  <p>对于矿工来说，如果result的值小于或等于target，那么就完成了挖矿过程，将当前的nonce和mix_hash作为工作量证明提交工作；如果result的值大于target，那么就需要改变nonce的值，再次调用ethash算法.</p> 
  <p>Ethash算法程序如下：</p> 
  <p><img alt="" class="has" src="http://assets.wangxiaoming.com/image/pow6.png"></p> 
  <p>从图中看，每次ethash从DAG随机取64<em>128=8192Bytes, 以GTX1070显卡为例，带宽为256GB/s, 那么每秒能承受256</em>1024<em>1024</em>1024/8192=33554432次ethash运算，即33MH/s的算力。可见，该算法对内存带宽的要求很高。</p> 
  <p><strong>3.2 快速验证</strong></p> 
  <p>当验证一个工作提交是否有效时，速度很快。</p> 
  <p>下面是快速验证程序：</p> 
  <p>&nbsp;<img alt="" class="has" src="http://assets.wangxiaoming.com/image/pow7.png"></p> 
  <p>&nbsp;</p> 
  <p><strong>原文链接：</strong><a href="http://wangxiaoming.com/blog/2018/06/26/HPB-47-ETH-Pow/" rel="nofollow">http://wangxiaoming.com/blog/2018/06/26/HPB-47-ETH-Pow/</a></p> 
  <p>&nbsp;</p> 
  <p><strong>关于我：</strong>蓝莲花（汪晓明），微信/QQ：86606813，公众号：xm123798。HPB芯链（<a href="http://www.hpb.io/" rel="nofollow">http://www.hpb.io</a>)创始人。致力于推动区块链应用落地。</p> 
  <p>&nbsp;</p> 
 </div> 
</div> 
<div class="hide-article-box text-center"> 
 <a class="btn btn-red-hollow" id="btn-readmore" data-track-view="{&quot;mod&quot;:&quot;popu_376&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/qukuai/article/details/81912377,&quot;}" data-track-click="{&quot;mod&quot;:&quot;popu_376&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/qukuai/article/details/81912377,&quot;}">阅读更多</a> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
