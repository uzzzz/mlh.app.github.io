<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>区块链基础知识系列 第二课 区块链共识算法 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="区块链基础知识系列 第二课 区块链共识算法" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="共识算法解决的是对某个提案(proposal)大家达成一致意见的过程。 PBFT&nbsp;(拜占庭容错)算法 -Fabric 0.6采用 五个阶段：request，预准备（pre-prepare）、准备（prepare）、和确认（commit），reply 步骤：&nbsp; &nbsp; 1.从全网节点选举出一个主节点（Leader），新区块由主节点负责生成&nbsp; &nbsp; 2.Pre-Prepare：每个节点把客户端发来的交易向全网广播，主节点0将从网络收集到需放在新区块内的多个交易排序后存入列表，并将该列表向全网广播，扩散至123&nbsp; &nbsp; 3.Prepare：每个节点接收到交易列表后，根据排序模拟执行这些交易。所有交易执行完后，基于交易结果计算新区块的哈希摘要，并向全网广播，1-&gt;023，2-&gt;013，3因为宕机无法广播&nbsp; &nbsp; 4.Commit：如果一个节点收到的2f（f为可容忍的拜占庭节点数）个其它节点发来的摘要都和自己相等，就向全网广播一条commit消息&nbsp; &nbsp; 5.Reply：如果一个节点收到2f+1条commit消息，即可提交新区块及其交易到本地的区块链和状态数据库。拜占庭容错能够容纳将近1/3的错误节点误差，IBM创建的Hyperledger 0.6版本就是使用了该算法作为共识算法（1.0版本已弃用，使用kafka）。 Fabric1.0采用共识算法为Solo、Kafka 1.Solo Orderer:&nbsp;The solo orderer is intended to be an extremely easy to deploy, non-production orderer. It consists of a single process which serves all clients, so no `consensus&#39; is required as there is a single central authority. There is correspondingly no high availability or scalability. This makes solo ideal for development and testing, but not deployment. The Solo orderer depends on a backing orderer ledge order-solo模式作为单节点通信模式，所有从peer收到的消息都在本节点进行排序与生成数据块，详细流程见下图：（用于开发模式下） order-solo过程分析：Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息。Orderer通过Recv接口接收Peer发送过来的消息，Orderer将接收到的消息生成数据块，并将数据块存入ledger，peer通过deliver接口从orderer中的ledger获取数据块。 2.Kafka Orderer :&nbsp;The Kafka orderer leverages the Kafka pubsub system to perform the ordering, but wraps this in the familiar ab.proto definition so that the peer orderer client code does not to be written specifically for Kafka. In real world deployments, it would be expected that the Kafka proto service would bound locally in process, as Kafka has its own robust wire protocol. However, for testing or novel deployment scenarios, the Kafka orderer may be deployed as a network service. Kafka is anticipated to be the preferred choice production deployments which demand high throughput and high availability but do not require byzantine fault tolerance. The Kafka orderer does not utilize a backing orderer ledger because this is handled by the Kafka brokers. Orderer-Kafka分析&nbsp;（用于正式环境下） BroadCast ：Broadcast主要接收Peer的数据并在Orderer里面生成一系列数据块，主要流程见下图： Broadcast过程分析：Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息。Orderer通过Recv接口接收Peer发送过来的消息，并将消息推送到Kafka。同时与Kafka相连接的Orderer通过Consumer实例消费Kafka上的消息，将消费的消息进行同一排序（Order），排序完成后，当达到生成数据块（Block）的条件（条件有两个1：下一数据块定时器到期，定时器通过向Orderer向Kafka发送定时器消息，再通过Kafka消费来达到定时效果。2：每消费一条真实数据，就触发判断是否达到生成一个新的数据块条件，该条件由当前待生成数据块的数据总的大小以及记录数决定），并创建新的数据块（CreateNextBlock），创建成功则将数据块写入ledger（WriteBlock）Deliver过程分析：Peer通过GRPC与orderer建立通信，连接成功以后，通过deliver接口发起获取数据请求。Orderer通过recv接口接收到数据获取请求，分析请求参数（SeekInfo_Start:1、SeekPosition_Oldest：从第一条数据块开始获取。2、SeekPosition_Newest：从最新一个数据块开始获取 3、SeekPosition_Specified：从指定数据块数获取）。Orderer从ledger中获取数据块迭代器入口，循环迭代器获取所有的数据块，每获取一个数据块同时就获取到的数据块返回给peer，知道所有数据块获取完，最后向peer返回获取成功状态。 参考内容：https://zhuanlan.zhihu.com/p/25358777 阅读更多" />
<meta property="og:description" content="共识算法解决的是对某个提案(proposal)大家达成一致意见的过程。 PBFT&nbsp;(拜占庭容错)算法 -Fabric 0.6采用 五个阶段：request，预准备（pre-prepare）、准备（prepare）、和确认（commit），reply 步骤：&nbsp; &nbsp; 1.从全网节点选举出一个主节点（Leader），新区块由主节点负责生成&nbsp; &nbsp; 2.Pre-Prepare：每个节点把客户端发来的交易向全网广播，主节点0将从网络收集到需放在新区块内的多个交易排序后存入列表，并将该列表向全网广播，扩散至123&nbsp; &nbsp; 3.Prepare：每个节点接收到交易列表后，根据排序模拟执行这些交易。所有交易执行完后，基于交易结果计算新区块的哈希摘要，并向全网广播，1-&gt;023，2-&gt;013，3因为宕机无法广播&nbsp; &nbsp; 4.Commit：如果一个节点收到的2f（f为可容忍的拜占庭节点数）个其它节点发来的摘要都和自己相等，就向全网广播一条commit消息&nbsp; &nbsp; 5.Reply：如果一个节点收到2f+1条commit消息，即可提交新区块及其交易到本地的区块链和状态数据库。拜占庭容错能够容纳将近1/3的错误节点误差，IBM创建的Hyperledger 0.6版本就是使用了该算法作为共识算法（1.0版本已弃用，使用kafka）。 Fabric1.0采用共识算法为Solo、Kafka 1.Solo Orderer:&nbsp;The solo orderer is intended to be an extremely easy to deploy, non-production orderer. It consists of a single process which serves all clients, so no `consensus&#39; is required as there is a single central authority. There is correspondingly no high availability or scalability. This makes solo ideal for development and testing, but not deployment. The Solo orderer depends on a backing orderer ledge order-solo模式作为单节点通信模式，所有从peer收到的消息都在本节点进行排序与生成数据块，详细流程见下图：（用于开发模式下） order-solo过程分析：Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息。Orderer通过Recv接口接收Peer发送过来的消息，Orderer将接收到的消息生成数据块，并将数据块存入ledger，peer通过deliver接口从orderer中的ledger获取数据块。 2.Kafka Orderer :&nbsp;The Kafka orderer leverages the Kafka pubsub system to perform the ordering, but wraps this in the familiar ab.proto definition so that the peer orderer client code does not to be written specifically for Kafka. In real world deployments, it would be expected that the Kafka proto service would bound locally in process, as Kafka has its own robust wire protocol. However, for testing or novel deployment scenarios, the Kafka orderer may be deployed as a network service. Kafka is anticipated to be the preferred choice production deployments which demand high throughput and high availability but do not require byzantine fault tolerance. The Kafka orderer does not utilize a backing orderer ledger because this is handled by the Kafka brokers. Orderer-Kafka分析&nbsp;（用于正式环境下） BroadCast ：Broadcast主要接收Peer的数据并在Orderer里面生成一系列数据块，主要流程见下图： Broadcast过程分析：Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息。Orderer通过Recv接口接收Peer发送过来的消息，并将消息推送到Kafka。同时与Kafka相连接的Orderer通过Consumer实例消费Kafka上的消息，将消费的消息进行同一排序（Order），排序完成后，当达到生成数据块（Block）的条件（条件有两个1：下一数据块定时器到期，定时器通过向Orderer向Kafka发送定时器消息，再通过Kafka消费来达到定时效果。2：每消费一条真实数据，就触发判断是否达到生成一个新的数据块条件，该条件由当前待生成数据块的数据总的大小以及记录数决定），并创建新的数据块（CreateNextBlock），创建成功则将数据块写入ledger（WriteBlock）Deliver过程分析：Peer通过GRPC与orderer建立通信，连接成功以后，通过deliver接口发起获取数据请求。Orderer通过recv接口接收到数据获取请求，分析请求参数（SeekInfo_Start:1、SeekPosition_Oldest：从第一条数据块开始获取。2、SeekPosition_Newest：从最新一个数据块开始获取 3、SeekPosition_Specified：从指定数据块数获取）。Orderer从ledger中获取数据块迭代器入口，循环迭代器获取所有的数据块，每获取一个数据块同时就获取到的数据块返回给peer，知道所有数据块获取完，最后向peer返回获取成功状态。 参考内容：https://zhuanlan.zhihu.com/p/25358777 阅读更多" />
<link rel="canonical" href="https://mlh.app/2018/02/26/1883d872d21ca25b471dcf40e045f54d.html" />
<meta property="og:url" content="https://mlh.app/2018/02/26/1883d872d21ca25b471dcf40e045f54d.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-02-26T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"共识算法解决的是对某个提案(proposal)大家达成一致意见的过程。 PBFT&nbsp;(拜占庭容错)算法 -Fabric 0.6采用 五个阶段：request，预准备（pre-prepare）、准备（prepare）、和确认（commit），reply 步骤：&nbsp; &nbsp; 1.从全网节点选举出一个主节点（Leader），新区块由主节点负责生成&nbsp; &nbsp; 2.Pre-Prepare：每个节点把客户端发来的交易向全网广播，主节点0将从网络收集到需放在新区块内的多个交易排序后存入列表，并将该列表向全网广播，扩散至123&nbsp; &nbsp; 3.Prepare：每个节点接收到交易列表后，根据排序模拟执行这些交易。所有交易执行完后，基于交易结果计算新区块的哈希摘要，并向全网广播，1-&gt;023，2-&gt;013，3因为宕机无法广播&nbsp; &nbsp; 4.Commit：如果一个节点收到的2f（f为可容忍的拜占庭节点数）个其它节点发来的摘要都和自己相等，就向全网广播一条commit消息&nbsp; &nbsp; 5.Reply：如果一个节点收到2f+1条commit消息，即可提交新区块及其交易到本地的区块链和状态数据库。拜占庭容错能够容纳将近1/3的错误节点误差，IBM创建的Hyperledger 0.6版本就是使用了该算法作为共识算法（1.0版本已弃用，使用kafka）。 Fabric1.0采用共识算法为Solo、Kafka 1.Solo Orderer:&nbsp;The solo orderer is intended to be an extremely easy to deploy, non-production orderer. It consists of a single process which serves all clients, so no `consensus&#39; is required as there is a single central authority. There is correspondingly no high availability or scalability. This makes solo ideal for development and testing, but not deployment. The Solo orderer depends on a backing orderer ledge order-solo模式作为单节点通信模式，所有从peer收到的消息都在本节点进行排序与生成数据块，详细流程见下图：（用于开发模式下） order-solo过程分析：Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息。Orderer通过Recv接口接收Peer发送过来的消息，Orderer将接收到的消息生成数据块，并将数据块存入ledger，peer通过deliver接口从orderer中的ledger获取数据块。 2.Kafka Orderer :&nbsp;The Kafka orderer leverages the Kafka pubsub system to perform the ordering, but wraps this in the familiar ab.proto definition so that the peer orderer client code does not to be written specifically for Kafka. In real world deployments, it would be expected that the Kafka proto service would bound locally in process, as Kafka has its own robust wire protocol. However, for testing or novel deployment scenarios, the Kafka orderer may be deployed as a network service. Kafka is anticipated to be the preferred choice production deployments which demand high throughput and high availability but do not require byzantine fault tolerance. The Kafka orderer does not utilize a backing orderer ledger because this is handled by the Kafka brokers. Orderer-Kafka分析&nbsp;（用于正式环境下） BroadCast ：Broadcast主要接收Peer的数据并在Orderer里面生成一系列数据块，主要流程见下图： Broadcast过程分析：Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息。Orderer通过Recv接口接收Peer发送过来的消息，并将消息推送到Kafka。同时与Kafka相连接的Orderer通过Consumer实例消费Kafka上的消息，将消费的消息进行同一排序（Order），排序完成后，当达到生成数据块（Block）的条件（条件有两个1：下一数据块定时器到期，定时器通过向Orderer向Kafka发送定时器消息，再通过Kafka消费来达到定时效果。2：每消费一条真实数据，就触发判断是否达到生成一个新的数据块条件，该条件由当前待生成数据块的数据总的大小以及记录数决定），并创建新的数据块（CreateNextBlock），创建成功则将数据块写入ledger（WriteBlock）Deliver过程分析：Peer通过GRPC与orderer建立通信，连接成功以后，通过deliver接口发起获取数据请求。Orderer通过recv接口接收到数据获取请求，分析请求参数（SeekInfo_Start:1、SeekPosition_Oldest：从第一条数据块开始获取。2、SeekPosition_Newest：从最新一个数据块开始获取 3、SeekPosition_Specified：从指定数据块数获取）。Orderer从ledger中获取数据块迭代器入口，循环迭代器获取所有的数据块，每获取一个数据块同时就获取到的数据块返回给peer，知道所有数据块获取完，最后向peer返回获取成功状态。 参考内容：https://zhuanlan.zhihu.com/p/25358777 阅读更多","@type":"BlogPosting","url":"https://mlh.app/2018/02/26/1883d872d21ca25b471dcf40e045f54d.html","headline":"区块链基础知识系列 第二课 区块链共识算法","dateModified":"2018-02-26T00:00:00+08:00","datePublished":"2018-02-26T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2018/02/26/1883d872d21ca25b471dcf40e045f54d.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>区块链基础知识系列 第二课 区块链共识算法</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-e2445db1a8.css"> 
 <div class="htmledit_views"> 
  <h1 class="title" style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-size:18px;">共识算法解决的是对某个提案(proposal)大家达成一致意见的过程。</span></h1>
  <div>
   <span style="font-size:18px;">PBFT&nbsp;<span style="color:rgb(85,85,85);font-family:'microsoft yahei';">(拜占庭容错)算法 -Fabric 0.6采用</span></span>
  </div>
  <div>
   <div class="image-package">
    <div class="image-container" style="background-color:transparent;">
     <div class="image-container-fill">
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-size:18px;">五个阶段：request，预准备（pre-prepare）、准备（prepare）、和确认（commit），reply<br></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-size:18px;"><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180126111648573" alt="" style="border:none;"></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-family:SimSun;"><span style="font-size:18px;">步骤：<br><br>&nbsp; &nbsp; 1.从全网节点选举出一个主节点（Leader），新区块由主节点负责生成<br>&nbsp; &nbsp; 2.Pre-Prepare：每个节点把客户端发来的交易向全网广播，主节点0将从网络收集到需放在新区块内的多个交易排序后存入列表，并将该列表向全网广播，扩散至123<br>&nbsp; &nbsp; 3.Prepare：每个节点接收到交易列表后，根据排序模拟执行这些交易。所有交易执行完后，基于交易结果计算新区块的哈希摘要，并向全网广播，1-&gt;023，2-&gt;013，3因为宕机无法广播<br>&nbsp; &nbsp; 4.Commit：如果一个节点收到的2f（f为可容忍的拜占庭节点数）个其它节点发来的摘要都和自己相等，就向全网广播一条commit消息<br>&nbsp; &nbsp; 5.Reply：如果一个节点收到2f+1条commit消息，即可提交新区块及其交易到本地的区块链和状态数据库。<br><br>拜占庭容错能够容纳将近1/3的错误节点误差，IBM创建的Hyperledger 0.6版本就是使用了该算法作为共识算法（1.0版本已弃用，使用kafka）。</span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-family:SimSun;"><span style="font-size:18px;"><br></span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-family:SimSun;"><span style="font-size:18px;">Fabric1.0采用共识算法为<span style="color:rgb(51,51,51);">Solo、Kafka</span></span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-family:SimSun;"><span style="color:rgb(51,51,51);"><span style="font-size:18px;"><br></span></span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-size:18px;"><span style="color:rgb(51,51,51);background-color:transparent;font-weight:600;">1.Solo Orderer:</span><span style="color:rgb(51,51,51);background-color:transparent;">&nbsp;The solo orderer is intended to be an extremely easy to deploy, non-production orderer. It consists of a single process which serves all clients, so no `consensus' is required as there is a single central authority. There is correspondingly no high availability or scalability. This makes solo ideal for development and testing, but not deployment. The Solo orderer depends on a backing orderer ledge</span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="color:rgb(51,51,51);background-color:transparent;"><span style="font-size:18px;"><br></span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="color:rgb(51,51,51);background-color:transparent;"><span style="font-size:18px;">order-solo模式作为单节点通信模式，所有从peer收到的消息都在本节点进行排序与生成数据块，详细流程见下图：（用于开发模式下）</span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="color:rgb(51,51,51);background-color:transparent;"><span style="font-size:18px;"><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180315102523147" alt=""><br></span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-size:18px;"><span style="color:rgb(51,51,51);background-color:transparent;">order-solo过程分析：</span><span style="color:rgb(51,51,51);background-color:transparent;">Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息。Orderer通过Recv接口接收Peer发送过来的消息，Orderer将接收到的消息生成数据块，并将数据块存入ledger，peer通过deliver接口从orderer中的ledger获取数据块。</span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="color:rgb(51,51,51);background-color:transparent;font-weight:600;"><span style="font-size:18px;"><br></span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-size:18px;"><span style="color:rgb(51,51,51);background-color:transparent;">2.</span><span style="color:rgb(51,51,51);background-color:transparent;font-weight:600;">Kafka Orderer :&nbsp;</span><span style="color:rgb(51,51,51);background-color:transparent;">The Kafka orderer leverages the Kafka pubsub system to perform the ordering, but wraps this in the familiar ab.proto definition so that the peer orderer client code does not to be written specifically for Kafka. In real world deployments, it would be expected that the Kafka proto service would bound locally in process, as Kafka has its own robust wire protocol. However, for testing or novel deployment scenarios, the Kafka orderer may be deployed as a network service. Kafka is anticipated to be the preferred choice production deployments which demand high throughput and high availability but do not require byzantine fault tolerance. The Kafka orderer does not utilize a backing orderer ledger because this is handled by the Kafka brokers.</span></span></p>
      <p style="color:rgb(85,85,85);font-family:'microsoft yahei';"><span style="font-size:18px;"><span style="color:rgb(51,51,51);background-color:transparent;">Orderer-Kafka分析</span><span style="color:rgb(51,51,51);background-color:transparent;">&nbsp;（用于正式环境下）</span></span></p>
      <ol style="color:rgb(51,51,51);">
       <li style="list-style-type:decimal;list-style-position:outside;"><span style="font-size:18px;"><span style="background-color:transparent;">BroadCast ：</span><span style="background-color:transparent;">Broadcast主要接收Peer的数据并在Orderer里面生成一系列数据块，主要流程见下图：<img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180315102718704" alt=""></span></span></li>
       <li style="list-style-type:decimal;list-style-position:outside;"><span style="background-color:transparent;"><span style="font-size:18px;"><span style="background-color:transparent;">Broadcast过程分析：Peer（客户端）通过GRPC发起通信，与Orderer连接成功之后，便可以向Orderer发送消息。Orderer通过Recv接口接收Peer发送过来的消息，并将消息推送到Kafka。同时与Kafka相连接的Orderer通过Consumer实例消费Kafka上的消息，将消费的消息进行同一排序（Order），排序完成后，当达到生成数据块（Block）的条件（条件有两个1：下一数据块定时器到期，定时器通过向Orderer向Kafka发送定时器消息，再通过Kafka消费来达到定时效果。2：每消费一条真实数据，就触发判断是否达到生成一个新的数据块条件，该条件由当前待生成数据块的数据总的大小以及记录数决定），并创建新的数据块（CreateNextBlock），创建成功则将数据块写入ledger（WriteBlock）<img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180315102734859" alt=""></span></span></span>Deliver过程分析：<p style="color:rgb(51,51,51);">Peer通过GRPC与orderer建立通信，连接成功以后，通过deliver接口发起获取数据请求。Orderer通过recv接口接收到数据获取请求，分析请求参数（SeekInfo_Start:1、SeekPosition_Oldest：从第一条数据块开始获取。2、SeekPosition_Newest：从最新一个数据块开始获取 3、SeekPosition_Specified：从指定数据块数获取）。Orderer从ledger中获取数据块迭代器入口，循环迭代器获取所有的数据块，每获取一个数据块同时就获取到的数据块返回给peer，知道所有数据块获取完，最后向peer返回获取成功状态。</p></li>
      </ol>
      <div>
       <span style="font-size:18px;color:#333333;"><br></span>
      </div>
      <div>
       <span style="font-size:18px;color:#333333;"><br></span>
      </div>
      <div>
       <span style="font-size:18px;color:#333333;">参考内容：https://zhuanlan.zhihu.com/p/25358777</span>
      </div>
     </div>
    </div>
   </div>
  </div> 
 </div> 
</div> 
<div class="hide-article-box text-center"> 
 <a class="btn btn-red-hollow" id="btn-readmore" data-track-view="{&quot;mod&quot;:&quot;popu_376&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/tiandiwuya/article/details/79382509,&quot;}" data-track-click="{&quot;mod&quot;:&quot;popu_376&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/tiandiwuya/article/details/79382509,&quot;}">阅读更多</a> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
