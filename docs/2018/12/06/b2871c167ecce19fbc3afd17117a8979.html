<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>16 SVM - 代码案例三 - 不同SVM核函数效果比较 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="16 SVM - 代码案例三 - 不同SVM核函数效果比较" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="SVM的章节已经讲完，具体内容请参考：《01 SVM - 大纲》 《14 SVM - 代码案例一 - 鸢尾花数据SVM分类》 《15 SVM - 代码案例二 - 鸢尾花数据不同分类器效果比较》 常规操作： 1、头文件引入SVM相关的包 2、防止中文乱码 3、读取数据 4、数据分割训练集和测试集 6:4 import time import numpy as np import pandas as pd import matplotlib as mpl import matplotlib.pyplot as plt from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score ## 设置属性防止中文乱码 mpl.rcParams[&#39;font.sans-serif&#39;] = [u&#39;SimHei&#39;] mpl.rcParams[&#39;axes.unicode_minus&#39;] = False ## 读取数据 # &#39;sepal length&#39;, &#39;sepal width&#39;, &#39;petal length&#39;, &#39;petal width&#39; iris_feature = u&#39;花萼长度&#39;, u&#39;花萼宽度&#39;, u&#39;花瓣长度&#39;, u&#39;花瓣宽度&#39; path = &#39;./datas/iris.data&#39; # 数据文件路径 data = pd.read_csv(path, header=None) x, y = data[list(range(4))], data[4] y = pd.Categorical(y).codes x = x[[0, 1]] ## 数据分割 x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=28, train_size=0.6) 数据SVM分类器构建： 1、线性核；2、高斯核；3、多项式核；4、Sigmoid核函数；10 SVM - 核函数 - 文末对四种核函数进行了介绍，尤其是高斯核。 svm1 = SVC(C=1, kernel=&#39;linear&#39;) svm2 = SVC(C=1, kernel=&#39;rbf&#39;) svm3 = SVC(C=1, kernel=&#39;poly&#39;) svm4 = SVC(C=1, kernel=&#39;sigmoid&#39;) ## 模型训练 t0=time.time() svm1.fit(x_train, y_train) t1=time.time() svm2.fit(x_train, y_train) t2=time.time() svm3.fit(x_train, y_train) t3=time.time() svm4.fit(x_train, y_train) t4=time.time() 效果评估： svm1_score1 = accuracy_score(y_train, svm1.predict(x_train)) svm1_score2 = accuracy_score(y_test, svm1.predict(x_test)) svm2_score1 = accuracy_score(y_train, svm2.predict(x_train)) svm2_score2 = accuracy_score(y_test, svm2.predict(x_test)) svm3_score1 = accuracy_score(y_train, svm3.predict(x_train)) svm3_score2 = accuracy_score(y_test, svm3.predict(x_test)) svm4_score1 = accuracy_score(y_train, svm4.predict(x_train)) svm4_score2 = accuracy_score(y_test, svm4.predict(x_test)) 画图 - 鸢尾花数据SVM分类器不同内核函数模型比较： x_tmp = [0,1,2,3] t_score = [t1 - t0, t2-t1, t3-t2, t4-t3] y_score1 = [svm1_score1, svm2_score1, svm3_score1, svm4_score1] y_score2 = [svm1_score2, svm2_score2, svm3_score2, svm4_score2] plt.figure(facecolor=&#39;w&#39;, figsize=(12,6)) 模型预测准确率比较： plt.subplot(121) plt.plot(x_tmp, y_score1, &#39;r-&#39;, lw=2, label=u&#39;训练集准确率&#39;) plt.plot(x_tmp, y_score2, &#39;g-&#39;, lw=2, label=u&#39;测试集准确率&#39;) plt.xlim(-0.3, 3.3) plt.ylim(np.min((np.min(y_score1), np.min(y_score2)))*0.9, np.max((np.max(y_score1), np.max(y_score2)))*1.1) plt.legend(loc = &#39;lower left&#39;) plt.title(u&#39;模型预测准确率&#39;, fontsize=13) plt.xticks(x_tmp, [u&#39;linear-SVM&#39;, u&#39;rbf-SVM&#39;, u&#39;poly-SVM&#39;, u&#39;sigmoid-SVM&#39;], rotation=0) plt.grid(b=True) 模型训练耗时比较: plt.subplot(122) plt.plot(x_tmp, t_score, &#39;b-&#39;, lw=2, label=u&#39;模型训练时间&#39;) plt.title(u&#39;模型训练耗时&#39;, fontsize=13) plt.xticks(x_tmp, [u&#39;linear-SVM&#39;, u&#39;rbf-SVM&#39;, u&#39;poly-SVM&#39;, u&#39;sigmoid-SVM&#39;], rotation=0) plt.xlim(-0.3, 3.3) plt.grid(b=True) plt.suptitle(u&#39;鸢尾花数据SVM分类器不同内核函数模型比较&#39;, fontsize=16) plt.show() 预测结果画图 画图比较： N = 500 x1_min, x2_min = x.min() x1_max, x2_max = x.max() t1 = np.linspace(x1_min, x1_max, N) t2 = np.linspace(x2_min, x2_max, N) x1, x2 = np.meshgrid(t1, t2) # 生成网格采样点 grid_show = np.dstack((x1.flat, x2.flat))[0] # 测试点 获取各个不同算法的测试值: svm1_grid_hat = svm1.predict(grid_show) svm1_grid_hat = svm1_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm2_grid_hat = svm2.predict(grid_show) svm2_grid_hat = svm2_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm3_grid_hat = svm3.predict(grid_show) svm3_grid_hat = svm3_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm4_grid_hat = svm4.predict(grid_show) svm4_grid_hat = svm4_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 画图: cm_light = mpl.colors.ListedColormap([&#39;#A0FFA0&#39;, &#39;#FFA0A0&#39;, &#39;#A0A0FF&#39;]) cm_dark = mpl.colors.ListedColormap([&#39;g&#39;, &#39;r&#39;, &#39;b&#39;]) plt.figure(facecolor=&#39;w&#39;, figsize=(14,7)) 1、鸢尾花Linear-SVM特征分类 (线性核) plt.subplot(221) ## 区域图 plt.pcolormesh(x1, x2, svm1_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花Linear-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 2、鸢尾花rbf-SVM特征分类 (高斯核) plt.subplot(222) ## 区域图 plt.pcolormesh(x1, x2, svm2_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花rbf-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 3、鸢尾花poly-SVM特征分类 (多项式核) plt.subplot(223) ## 区域图 plt.pcolormesh(x1, x2, svm3_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花poly-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 4、鸢尾花sigmoid-SVM特征分类: plt.subplot(224) ## 区域图 plt.pcolormesh(x1, x2, svm4_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花sigmoid-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) plt.show() PS: 还记得讲核函数时候说过的话么？高斯核 可以近似表示无穷维的扩展，效果最好。sigmoid核 一塌糊涂，不要去用。 17 SVM - 代码案例四 - 不同SVM惩罚参数C值不同效果比较" />
<meta property="og:description" content="SVM的章节已经讲完，具体内容请参考：《01 SVM - 大纲》 《14 SVM - 代码案例一 - 鸢尾花数据SVM分类》 《15 SVM - 代码案例二 - 鸢尾花数据不同分类器效果比较》 常规操作： 1、头文件引入SVM相关的包 2、防止中文乱码 3、读取数据 4、数据分割训练集和测试集 6:4 import time import numpy as np import pandas as pd import matplotlib as mpl import matplotlib.pyplot as plt from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score ## 设置属性防止中文乱码 mpl.rcParams[&#39;font.sans-serif&#39;] = [u&#39;SimHei&#39;] mpl.rcParams[&#39;axes.unicode_minus&#39;] = False ## 读取数据 # &#39;sepal length&#39;, &#39;sepal width&#39;, &#39;petal length&#39;, &#39;petal width&#39; iris_feature = u&#39;花萼长度&#39;, u&#39;花萼宽度&#39;, u&#39;花瓣长度&#39;, u&#39;花瓣宽度&#39; path = &#39;./datas/iris.data&#39; # 数据文件路径 data = pd.read_csv(path, header=None) x, y = data[list(range(4))], data[4] y = pd.Categorical(y).codes x = x[[0, 1]] ## 数据分割 x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=28, train_size=0.6) 数据SVM分类器构建： 1、线性核；2、高斯核；3、多项式核；4、Sigmoid核函数；10 SVM - 核函数 - 文末对四种核函数进行了介绍，尤其是高斯核。 svm1 = SVC(C=1, kernel=&#39;linear&#39;) svm2 = SVC(C=1, kernel=&#39;rbf&#39;) svm3 = SVC(C=1, kernel=&#39;poly&#39;) svm4 = SVC(C=1, kernel=&#39;sigmoid&#39;) ## 模型训练 t0=time.time() svm1.fit(x_train, y_train) t1=time.time() svm2.fit(x_train, y_train) t2=time.time() svm3.fit(x_train, y_train) t3=time.time() svm4.fit(x_train, y_train) t4=time.time() 效果评估： svm1_score1 = accuracy_score(y_train, svm1.predict(x_train)) svm1_score2 = accuracy_score(y_test, svm1.predict(x_test)) svm2_score1 = accuracy_score(y_train, svm2.predict(x_train)) svm2_score2 = accuracy_score(y_test, svm2.predict(x_test)) svm3_score1 = accuracy_score(y_train, svm3.predict(x_train)) svm3_score2 = accuracy_score(y_test, svm3.predict(x_test)) svm4_score1 = accuracy_score(y_train, svm4.predict(x_train)) svm4_score2 = accuracy_score(y_test, svm4.predict(x_test)) 画图 - 鸢尾花数据SVM分类器不同内核函数模型比较： x_tmp = [0,1,2,3] t_score = [t1 - t0, t2-t1, t3-t2, t4-t3] y_score1 = [svm1_score1, svm2_score1, svm3_score1, svm4_score1] y_score2 = [svm1_score2, svm2_score2, svm3_score2, svm4_score2] plt.figure(facecolor=&#39;w&#39;, figsize=(12,6)) 模型预测准确率比较： plt.subplot(121) plt.plot(x_tmp, y_score1, &#39;r-&#39;, lw=2, label=u&#39;训练集准确率&#39;) plt.plot(x_tmp, y_score2, &#39;g-&#39;, lw=2, label=u&#39;测试集准确率&#39;) plt.xlim(-0.3, 3.3) plt.ylim(np.min((np.min(y_score1), np.min(y_score2)))*0.9, np.max((np.max(y_score1), np.max(y_score2)))*1.1) plt.legend(loc = &#39;lower left&#39;) plt.title(u&#39;模型预测准确率&#39;, fontsize=13) plt.xticks(x_tmp, [u&#39;linear-SVM&#39;, u&#39;rbf-SVM&#39;, u&#39;poly-SVM&#39;, u&#39;sigmoid-SVM&#39;], rotation=0) plt.grid(b=True) 模型训练耗时比较: plt.subplot(122) plt.plot(x_tmp, t_score, &#39;b-&#39;, lw=2, label=u&#39;模型训练时间&#39;) plt.title(u&#39;模型训练耗时&#39;, fontsize=13) plt.xticks(x_tmp, [u&#39;linear-SVM&#39;, u&#39;rbf-SVM&#39;, u&#39;poly-SVM&#39;, u&#39;sigmoid-SVM&#39;], rotation=0) plt.xlim(-0.3, 3.3) plt.grid(b=True) plt.suptitle(u&#39;鸢尾花数据SVM分类器不同内核函数模型比较&#39;, fontsize=16) plt.show() 预测结果画图 画图比较： N = 500 x1_min, x2_min = x.min() x1_max, x2_max = x.max() t1 = np.linspace(x1_min, x1_max, N) t2 = np.linspace(x2_min, x2_max, N) x1, x2 = np.meshgrid(t1, t2) # 生成网格采样点 grid_show = np.dstack((x1.flat, x2.flat))[0] # 测试点 获取各个不同算法的测试值: svm1_grid_hat = svm1.predict(grid_show) svm1_grid_hat = svm1_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm2_grid_hat = svm2.predict(grid_show) svm2_grid_hat = svm2_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm3_grid_hat = svm3.predict(grid_show) svm3_grid_hat = svm3_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm4_grid_hat = svm4.predict(grid_show) svm4_grid_hat = svm4_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 画图: cm_light = mpl.colors.ListedColormap([&#39;#A0FFA0&#39;, &#39;#FFA0A0&#39;, &#39;#A0A0FF&#39;]) cm_dark = mpl.colors.ListedColormap([&#39;g&#39;, &#39;r&#39;, &#39;b&#39;]) plt.figure(facecolor=&#39;w&#39;, figsize=(14,7)) 1、鸢尾花Linear-SVM特征分类 (线性核) plt.subplot(221) ## 区域图 plt.pcolormesh(x1, x2, svm1_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花Linear-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 2、鸢尾花rbf-SVM特征分类 (高斯核) plt.subplot(222) ## 区域图 plt.pcolormesh(x1, x2, svm2_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花rbf-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 3、鸢尾花poly-SVM特征分类 (多项式核) plt.subplot(223) ## 区域图 plt.pcolormesh(x1, x2, svm3_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花poly-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 4、鸢尾花sigmoid-SVM特征分类: plt.subplot(224) ## 区域图 plt.pcolormesh(x1, x2, svm4_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花sigmoid-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) plt.show() PS: 还记得讲核函数时候说过的话么？高斯核 可以近似表示无穷维的扩展，效果最好。sigmoid核 一塌糊涂，不要去用。 17 SVM - 代码案例四 - 不同SVM惩罚参数C值不同效果比较" />
<link rel="canonical" href="https://mlh.app/2018/12/06/b2871c167ecce19fbc3afd17117a8979.html" />
<meta property="og:url" content="https://mlh.app/2018/12/06/b2871c167ecce19fbc3afd17117a8979.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-12-06T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"SVM的章节已经讲完，具体内容请参考：《01 SVM - 大纲》 《14 SVM - 代码案例一 - 鸢尾花数据SVM分类》 《15 SVM - 代码案例二 - 鸢尾花数据不同分类器效果比较》 常规操作： 1、头文件引入SVM相关的包 2、防止中文乱码 3、读取数据 4、数据分割训练集和测试集 6:4 import time import numpy as np import pandas as pd import matplotlib as mpl import matplotlib.pyplot as plt from sklearn.svm import SVC from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score ## 设置属性防止中文乱码 mpl.rcParams[&#39;font.sans-serif&#39;] = [u&#39;SimHei&#39;] mpl.rcParams[&#39;axes.unicode_minus&#39;] = False ## 读取数据 # &#39;sepal length&#39;, &#39;sepal width&#39;, &#39;petal length&#39;, &#39;petal width&#39; iris_feature = u&#39;花萼长度&#39;, u&#39;花萼宽度&#39;, u&#39;花瓣长度&#39;, u&#39;花瓣宽度&#39; path = &#39;./datas/iris.data&#39; # 数据文件路径 data = pd.read_csv(path, header=None) x, y = data[list(range(4))], data[4] y = pd.Categorical(y).codes x = x[[0, 1]] ## 数据分割 x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=28, train_size=0.6) 数据SVM分类器构建： 1、线性核；2、高斯核；3、多项式核；4、Sigmoid核函数；10 SVM - 核函数 - 文末对四种核函数进行了介绍，尤其是高斯核。 svm1 = SVC(C=1, kernel=&#39;linear&#39;) svm2 = SVC(C=1, kernel=&#39;rbf&#39;) svm3 = SVC(C=1, kernel=&#39;poly&#39;) svm4 = SVC(C=1, kernel=&#39;sigmoid&#39;) ## 模型训练 t0=time.time() svm1.fit(x_train, y_train) t1=time.time() svm2.fit(x_train, y_train) t2=time.time() svm3.fit(x_train, y_train) t3=time.time() svm4.fit(x_train, y_train) t4=time.time() 效果评估： svm1_score1 = accuracy_score(y_train, svm1.predict(x_train)) svm1_score2 = accuracy_score(y_test, svm1.predict(x_test)) svm2_score1 = accuracy_score(y_train, svm2.predict(x_train)) svm2_score2 = accuracy_score(y_test, svm2.predict(x_test)) svm3_score1 = accuracy_score(y_train, svm3.predict(x_train)) svm3_score2 = accuracy_score(y_test, svm3.predict(x_test)) svm4_score1 = accuracy_score(y_train, svm4.predict(x_train)) svm4_score2 = accuracy_score(y_test, svm4.predict(x_test)) 画图 - 鸢尾花数据SVM分类器不同内核函数模型比较： x_tmp = [0,1,2,3] t_score = [t1 - t0, t2-t1, t3-t2, t4-t3] y_score1 = [svm1_score1, svm2_score1, svm3_score1, svm4_score1] y_score2 = [svm1_score2, svm2_score2, svm3_score2, svm4_score2] plt.figure(facecolor=&#39;w&#39;, figsize=(12,6)) 模型预测准确率比较： plt.subplot(121) plt.plot(x_tmp, y_score1, &#39;r-&#39;, lw=2, label=u&#39;训练集准确率&#39;) plt.plot(x_tmp, y_score2, &#39;g-&#39;, lw=2, label=u&#39;测试集准确率&#39;) plt.xlim(-0.3, 3.3) plt.ylim(np.min((np.min(y_score1), np.min(y_score2)))*0.9, np.max((np.max(y_score1), np.max(y_score2)))*1.1) plt.legend(loc = &#39;lower left&#39;) plt.title(u&#39;模型预测准确率&#39;, fontsize=13) plt.xticks(x_tmp, [u&#39;linear-SVM&#39;, u&#39;rbf-SVM&#39;, u&#39;poly-SVM&#39;, u&#39;sigmoid-SVM&#39;], rotation=0) plt.grid(b=True) 模型训练耗时比较: plt.subplot(122) plt.plot(x_tmp, t_score, &#39;b-&#39;, lw=2, label=u&#39;模型训练时间&#39;) plt.title(u&#39;模型训练耗时&#39;, fontsize=13) plt.xticks(x_tmp, [u&#39;linear-SVM&#39;, u&#39;rbf-SVM&#39;, u&#39;poly-SVM&#39;, u&#39;sigmoid-SVM&#39;], rotation=0) plt.xlim(-0.3, 3.3) plt.grid(b=True) plt.suptitle(u&#39;鸢尾花数据SVM分类器不同内核函数模型比较&#39;, fontsize=16) plt.show() 预测结果画图 画图比较： N = 500 x1_min, x2_min = x.min() x1_max, x2_max = x.max() t1 = np.linspace(x1_min, x1_max, N) t2 = np.linspace(x2_min, x2_max, N) x1, x2 = np.meshgrid(t1, t2) # 生成网格采样点 grid_show = np.dstack((x1.flat, x2.flat))[0] # 测试点 获取各个不同算法的测试值: svm1_grid_hat = svm1.predict(grid_show) svm1_grid_hat = svm1_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm2_grid_hat = svm2.predict(grid_show) svm2_grid_hat = svm2_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm3_grid_hat = svm3.predict(grid_show) svm3_grid_hat = svm3_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 svm4_grid_hat = svm4.predict(grid_show) svm4_grid_hat = svm4_grid_hat.reshape(x1.shape) # 使之与输入的形状相同 画图: cm_light = mpl.colors.ListedColormap([&#39;#A0FFA0&#39;, &#39;#FFA0A0&#39;, &#39;#A0A0FF&#39;]) cm_dark = mpl.colors.ListedColormap([&#39;g&#39;, &#39;r&#39;, &#39;b&#39;]) plt.figure(facecolor=&#39;w&#39;, figsize=(14,7)) 1、鸢尾花Linear-SVM特征分类 (线性核) plt.subplot(221) ## 区域图 plt.pcolormesh(x1, x2, svm1_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花Linear-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 2、鸢尾花rbf-SVM特征分类 (高斯核) plt.subplot(222) ## 区域图 plt.pcolormesh(x1, x2, svm2_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花rbf-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 3、鸢尾花poly-SVM特征分类 (多项式核) plt.subplot(223) ## 区域图 plt.pcolormesh(x1, x2, svm3_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花poly-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) 4、鸢尾花sigmoid-SVM特征分类: plt.subplot(224) ## 区域图 plt.pcolormesh(x1, x2, svm4_grid_hat, cmap=cm_light) ## 所以样本点 plt.scatter(x[0], x[1], c=y, edgecolors=&#39;k&#39;, s=50, cmap=cm_dark) # 样本 ## 测试数据集 plt.scatter(x_test[0], x_test[1], s=120, facecolors=&#39;none&#39;, zorder=10) # 圈中测试集样本 ## lable列表 plt.xlabel(iris_feature[0], fontsize=13) plt.ylabel(iris_feature[1], fontsize=13) plt.xlim(x1_min, x1_max) plt.ylim(x2_min, x2_max) plt.title(u&#39;鸢尾花sigmoid-SVM特征分类&#39;, fontsize=16) plt.grid(b=True, ls=&#39;:&#39;) plt.tight_layout(pad=1.5) plt.show() PS: 还记得讲核函数时候说过的话么？高斯核 可以近似表示无穷维的扩展，效果最好。sigmoid核 一塌糊涂，不要去用。 17 SVM - 代码案例四 - 不同SVM惩罚参数C值不同效果比较","@type":"BlogPosting","url":"https://mlh.app/2018/12/06/b2871c167ecce19fbc3afd17117a8979.html","headline":"16 SVM - 代码案例三 - 不同SVM核函数效果比较","dateModified":"2018-12-06T00:00:00+08:00","datePublished":"2018-12-06T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2018/12/06/b2871c167ecce19fbc3afd17117a8979.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>16 SVM - 代码案例三 - 不同SVM核函数效果比较</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="show-content-free"> 
   <p>SVM的章节已经讲完，具体内容请参考：《<a href="https://www.jianshu.com/p/1f6915285226" rel="nofollow">01 SVM - 大纲</a>》</p> 
   <p>《<a href="https://www.jianshu.com/p/cd94efc78b6b" rel="nofollow">14 SVM - 代码案例一 - 鸢尾花数据SVM分类</a>》<br> 《<a href="https://www.jianshu.com/p/30f7f2db4a40" rel="nofollow">15 SVM - 代码案例二 - 鸢尾花数据不同分类器效果比较</a>》</p> 
   <h5>常规操作：</h5> 
   <p>1、头文件引入SVM相关的包<br> 2、防止中文乱码<br> 3、读取数据<br> 4、数据分割训练集和测试集 6:4</p> 
   <pre><code>import time
import numpy as np
import pandas as pd
import matplotlib as mpl
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

## 设置属性防止中文乱码
mpl.rcParams['font.sans-serif'] = [u'SimHei']
mpl.rcParams['axes.unicode_minus'] = False

## 读取数据
# 'sepal length', 'sepal width', 'petal length', 'petal width'
iris_feature = u'花萼长度', u'花萼宽度', u'花瓣长度', u'花瓣宽度'
path = './datas/iris.data'  # 数据文件路径
data = pd.read_csv(path, header=None)
x, y = data[list(range(4))], data[4]
y = pd.Categorical(y).codes
x = x[[0, 1]]

## 数据分割
x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=28, train_size=0.6)
</code></pre> 
   <hr>
   <h5>数据SVM分类器构建：</h5> 
   <p>1、线性核；2、高斯核；3、多项式核；4、Sigmoid核函数；<br><a href="https://www.jianshu.com/p/028d1883ad93" rel="nofollow">10 SVM - 核函数</a> - 文末对四种核函数进行了介绍，尤其是高斯核。</p> 
   <pre><code>svm1 = SVC(C=1, kernel='linear')
svm2 = SVC(C=1, kernel='rbf')
svm3 = SVC(C=1, kernel='poly')
svm4 = SVC(C=1, kernel='sigmoid')

## 模型训练
t0=time.time()
svm1.fit(x_train, y_train)
t1=time.time()
svm2.fit(x_train, y_train)
t2=time.time()
svm3.fit(x_train, y_train)
t3=time.time()
svm4.fit(x_train, y_train)
t4=time.time()
</code></pre> 
   <hr>
   <h4>效果评估：</h4> 
   <pre><code>svm1_score1 = accuracy_score(y_train, svm1.predict(x_train))
svm1_score2 = accuracy_score(y_test, svm1.predict(x_test))

svm2_score1 = accuracy_score(y_train, svm2.predict(x_train))
svm2_score2 = accuracy_score(y_test, svm2.predict(x_test))

svm3_score1 = accuracy_score(y_train, svm3.predict(x_train))
svm3_score2 = accuracy_score(y_test, svm3.predict(x_test))

svm4_score1 = accuracy_score(y_train, svm4.predict(x_train))
svm4_score2 = accuracy_score(y_test, svm4.predict(x_test))
</code></pre> 
   <h5>画图 - 鸢尾花数据SVM分类器不同内核函数模型比较：</h5> 
   <pre><code>x_tmp = [0,1,2,3]
t_score = [t1 - t0, t2-t1, t3-t2, t4-t3]
y_score1 = [svm1_score1, svm2_score1, svm3_score1, svm4_score1]
y_score2 = [svm1_score2, svm2_score2, svm3_score2, svm4_score2]

plt.figure(facecolor='w', figsize=(12,6))
</code></pre> 
   <h5>模型预测准确率比较：</h5> 
   <pre><code>plt.subplot(121)
plt.plot(x_tmp, y_score1, 'r-', lw=2, label=u'训练集准确率')
plt.plot(x_tmp, y_score2, 'g-', lw=2, label=u'测试集准确率')
plt.xlim(-0.3, 3.3)
plt.ylim(np.min((np.min(y_score1), np.min(y_score2)))*0.9, 
    np.max((np.max(y_score1), np.max(y_score2)))*1.1)
plt.legend(loc = 'lower left')
plt.title(u'模型预测准确率', fontsize=13)
plt.xticks(x_tmp, [u'linear-SVM', u'rbf-SVM', u'poly-SVM', u'sigmoid-SVM'], rotation=0)
plt.grid(b=True)
</code></pre> 
   <h5>模型训练耗时比较:</h5> 
   <pre><code>plt.subplot(122)
plt.plot(x_tmp, t_score, 'b-', lw=2, label=u'模型训练时间')
plt.title(u'模型训练耗时', fontsize=13)
plt.xticks(x_tmp, [u'linear-SVM', u'rbf-SVM', u'poly-SVM', u'sigmoid-SVM'], rotation=0)
plt.xlim(-0.3, 3.3)
plt.grid(b=True)
</code></pre> 
   <pre><code>plt.suptitle(u'鸢尾花数据SVM分类器不同内核函数模型比较', fontsize=16)
plt.show()
</code></pre> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/3153092-3c90cd0b01bf5613.png" alt="3153092-3c90cd0b01bf5613.png">
     </div> 
    </div> 
    <div class="image-caption"></div> 
   </div> 
   <hr>
   <h3>预测结果画图</h3> 
   <h5>画图比较：</h5> 
   <pre><code>N = 500
x1_min, x2_min = x.min()
x1_max, x2_max = x.max()

t1 = np.linspace(x1_min, x1_max, N)
t2 = np.linspace(x2_min, x2_max, N)
x1, x2 = np.meshgrid(t1, t2)  # 生成网格采样点
grid_show = np.dstack((x1.flat, x2.flat))[0] # 测试点
</code></pre> 
   <h5>获取各个不同算法的测试值:</h5> 
   <pre><code>svm1_grid_hat = svm1.predict(grid_show)
svm1_grid_hat = svm1_grid_hat.reshape(x1.shape)  # 使之与输入的形状相同

svm2_grid_hat = svm2.predict(grid_show)
svm2_grid_hat = svm2_grid_hat.reshape(x1.shape)  # 使之与输入的形状相同

svm3_grid_hat = svm3.predict(grid_show)
svm3_grid_hat = svm3_grid_hat.reshape(x1.shape)  # 使之与输入的形状相同

svm4_grid_hat = svm4.predict(grid_show)
svm4_grid_hat = svm4_grid_hat.reshape(x1.shape)  # 使之与输入的形状相同
</code></pre> 
   <h5>画图:</h5> 
   <pre><code>cm_light = mpl.colors.ListedColormap(['#A0FFA0', '#FFA0A0', '#A0A0FF'])
cm_dark = mpl.colors.ListedColormap(['g', 'r', 'b'])
plt.figure(facecolor='w', figsize=(14,7))
</code></pre> 
   <h5>1、鸢尾花Linear-SVM特征分类 (线性核)</h5> 
   <pre><code>plt.subplot(221)
## 区域图
plt.pcolormesh(x1, x2, svm1_grid_hat, cmap=cm_light)
## 所以样本点
plt.scatter(x[0], x[1], c=y, edgecolors='k', s=50, cmap=cm_dark)      # 样本
## 测试数据集
plt.scatter(x_test[0], x_test[1], s=120, facecolors='none', zorder=10)     # 圈中测试集样本
## lable列表
plt.xlabel(iris_feature[0], fontsize=13)
plt.ylabel(iris_feature[1], fontsize=13)
plt.xlim(x1_min, x1_max)
plt.ylim(x2_min, x2_max)
plt.title(u'鸢尾花Linear-SVM特征分类', fontsize=16)
plt.grid(b=True, ls=':')
plt.tight_layout(pad=1.5)
</code></pre> 
   <h5>2、鸢尾花rbf-SVM特征分类 (高斯核)</h5> 
   <pre><code>plt.subplot(222)
## 区域图
plt.pcolormesh(x1, x2, svm2_grid_hat, cmap=cm_light)
## 所以样本点
plt.scatter(x[0], x[1], c=y, edgecolors='k', s=50, cmap=cm_dark)      # 样本
## 测试数据集
plt.scatter(x_test[0], x_test[1], s=120, facecolors='none', zorder=10)     # 圈中测试集样本
## lable列表
plt.xlabel(iris_feature[0], fontsize=13)
plt.ylabel(iris_feature[1], fontsize=13)
plt.xlim(x1_min, x1_max)
plt.ylim(x2_min, x2_max)
plt.title(u'鸢尾花rbf-SVM特征分类', fontsize=16)
plt.grid(b=True, ls=':')
plt.tight_layout(pad=1.5)
</code></pre> 
   <h5>3、鸢尾花poly-SVM特征分类 (多项式核)</h5> 
   <pre><code>plt.subplot(223)
## 区域图
plt.pcolormesh(x1, x2, svm3_grid_hat, cmap=cm_light)
## 所以样本点
plt.scatter(x[0], x[1], c=y, edgecolors='k', s=50, cmap=cm_dark)      # 样本
## 测试数据集
plt.scatter(x_test[0], x_test[1], s=120, facecolors='none', zorder=10)     # 圈中测试集样本
## lable列表
plt.xlabel(iris_feature[0], fontsize=13)
plt.ylabel(iris_feature[1], fontsize=13)
plt.xlim(x1_min, x1_max)
plt.ylim(x2_min, x2_max)
plt.title(u'鸢尾花poly-SVM特征分类', fontsize=16)
plt.grid(b=True, ls=':')
plt.tight_layout(pad=1.5)
</code></pre> 
   <h5>4、鸢尾花sigmoid-SVM特征分类:</h5> 
   <pre><code>plt.subplot(224)
## 区域图
plt.pcolormesh(x1, x2, svm4_grid_hat, cmap=cm_light)
## 所以样本点
plt.scatter(x[0], x[1], c=y, edgecolors='k', s=50, cmap=cm_dark)      # 样本
## 测试数据集
plt.scatter(x_test[0], x_test[1], s=120, facecolors='none', zorder=10)     # 圈中测试集样本
## lable列表
plt.xlabel(iris_feature[0], fontsize=13)
plt.ylabel(iris_feature[1], fontsize=13)
plt.xlim(x1_min, x1_max)
plt.ylim(x2_min, x2_max)
plt.title(u'鸢尾花sigmoid-SVM特征分类', fontsize=16)
plt.grid(b=True, ls=':')
plt.tight_layout(pad=1.5)
</code></pre> 
   <pre><code>plt.show()
</code></pre> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/3153092-1743ec8c8b983991.png" alt="3153092-1743ec8c8b983991.png">
     </div> 
    </div> 
    <div class="image-caption"></div> 
   </div> 
   <p><strong>PS:</strong> 还记得讲核函数时候说过的话么？<br><strong>高斯核</strong> 可以近似表示无穷维的扩展，效果最好。<br><strong>sigmoid核</strong> 一塌糊涂，不要去用。</p> 
   <p><a href="https://www.jianshu.com/p/19c0aaf582f6" rel="nofollow">17 SVM - 代码案例四 - 不同SVM惩罚参数C值不同效果比较</a></p> 
  </div> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
