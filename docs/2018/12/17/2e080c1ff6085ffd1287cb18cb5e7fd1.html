<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>深度学习目标检测系列：faster RCNN实现 附python源码 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="深度学习目标检测系列：faster RCNN实现 附python源码" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="摘要： 本文在讲述RCNN系列算法基本原理基础上，使用keras实现faster RCNN算法，在细胞检测任务上表现优异，可动手操作一下。 目标检测一直是计算机视觉中比较热门的研究领域，有一些常用且成熟的算法得到业内公认水平，比如RCNN系列算法、SSD以及YOLO等。如果你是从事这一行业的话，你会使用哪种算法进行目标检测任务呢？在我寻求在最短的时间内构建最精确的模型时，我尝试了其中的R-CNN系列算法，如果读者们对这方面的算法还不太了解的话，建议阅读《目标检测算法图解：一文看懂RCNN系列算法》。在掌握基本原理后，下面进入实战部分。 本文将使用一个非常酷且有用的数据集来实现faster R-CNN，这些数据集具有潜在的真实应用场景。 问题陈述 数据来源于医疗相关数据集，目的是解决血细胞检测问题。任务是通过显微图像读数来检测每张图像中的所有红细胞（RBC）、白细胞（WBC）以及血小板。最终预测效果应如下所示： 选择该数据集的原因是我们血液中RBC、WBC和血小板的密度提供了大量关于免疫系统和血红蛋白的信息，这些信息可以帮助我们初步地识别一个人是否健康，如果在其血液中发现了任何差异，我们就可以迅速采取行动来进行下一步的诊断。 通过显微镜手动查看样品是一个繁琐的过程，这也是深度学习模式能够发挥重要作用的地方，一些算法可以从显微图像中分类和检测血细胞，并且达到很高的精确度。 本文采用的血细胞检测数据集可以从这里下载，本文稍微修改了一些数据： 边界框已从给定的.xml格式转换为.csv格式； 随机划分数据集，得到训练集和测试集； 这里使用流行的Keras框架构建本文模型。 系统设置 在真正进入模型构建阶段之前，需要确保系统已安装正确的库和相应的框架。运行此项目需要以下库： pandas matplotlib tensorflow keras – 2.0.3 numpy opencv-python sklearn h5py 对于已经安装了Anaconda和Jupyter的电脑而言，上述这些库大多数已经安装好了。建议从此链接下载requirements.txt文件，并使用它来安装剩余的库。在终端中键入以下命令来执行此操作： pip install -r requirement.txt 系统设置好后，下一步是进行数据处理。 数据探索 首先探索所拥有的数据总是一个好开始（坦率地说，这是一个强制性的步骤）。对数据熟悉有助于挖掘隐藏的模式，还可以获得对整体的洞察力。本文从整个数据集中创建了三个文件，分别是： train_images：用于训练模型的图像，包含每个图像的类别和实际边界框； test_images：用于模型预测的图像，该集合缺少对应的标签； train.csv：包含每个图像的名称、类别和边界框坐标。一张图像可以有多行数据，因为单张图像可能包含多个对象； 读取.csv文件并打印出前几行： # importing required libraries import pandas as pd import matplotlib.pyplot as plt %matplotlib inline from matplotlib import patches # read the csv file using read_csv function of pandas train = pd.read_csv(‘train.csv’) train.head() 训练文件中总共有6列，其中每列代表的内容如下： image_names：图像的名称； cell_type：表示单元的类型； xmin：图像左下角的x坐标； xmax：图像右上角的x坐标； ymin：图像左下角的y坐标； ymax：图像右上角的y坐标； 下面打印出一张图片来展示正在处理的图像： # reading single image using imread function of matplotlib image = plt.imread(&#39;images/1.jpg&#39;) plt.imshow(image) 上图就是血细胞图像的样子，其中，蓝色部分代表WBC，略带红色的部分代表RBC。下面看看整个训练集中总共有多少张图像和不同类型的数量。 # Number of classes train[&#39;cell_type&#39;].value_counts() 结果显示训练集有254张图像。 # Number of classes train[&#39;cell_type&#39;].value_counts() 结果显示有三种不同类型的细胞，即RBC，WBC和血小板。最后，看一下检测到的对象的图像是怎样的： fig = plt.figure() #add axes to the image ax = fig.add_axes([0,0,1,1]) # read and plot the image image = plt.imread(&#39;images/1.jpg&#39;) plt.imshow(image) # iterating over the image for different objects for _,row in train[train.image_names == &quot;1.jpg&quot;].iterrows(): xmin = row.xmin xmax = row.xmax ymin = row.ymin ymax = row.ymax width = xmax - xmin height = ymax - ymin # assign different color to different classes of objects if row.cell_type == &#39;RBC&#39;: edgecolor = &#39;r&#39; ax.annotate(&#39;RBC&#39;, xy=(xmax-40,ymin+20)) elif row.cell_type == &#39;WBC&#39;: edgecolor = &#39;b&#39; ax.annotate(&#39;WBC&#39;, xy=(xmax-40,ymin+20)) elif row.cell_type == &#39;Platelets&#39;: edgecolor = &#39;g&#39; ax.annotate(&#39;Platelets&#39;, xy=(xmax-40,ymin+20)) # add bounding boxes to the image rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = &#39;none&#39;) ax.add_patch(rect) 上图就是训练样本示例，从中可以看到，细胞有不同的类及其相应的边界框。下面进行模型训练，本文使用keras_frcnn库来训练搭建的模型以及对测试图像进行预测。 faster R-CNN实现 为了实现 faster R-CNN算法，本文遵循此Github存储库中提到的步骤。因此，首先请确保克隆好此存储库。打开一个新的终端窗口并键入以下内容以执行此操作： git clone https://github.com/kbardool/keras-frcnn.git 并将train_images和test_images文件夹以及train.csv文件移动到该存储库目录下。为了在新数据集上训练模型，输入的格式应为： filepath,x1,y1,x2,y2,class_name 其中： filepath是训练图像的路径； x1是边界框的xmin坐标； y1是边界框的ymin坐标； x2是边界框的xmax坐标； y2是边界框的ymax坐标； class_name是该边界框中类的名称； 这里需要将.csv格式转换为.txt文件，该文件具有与上述相同的格式。创建一个新的数据帧，按照格式将所有值填入该数据帧，然后将其另存为.txt文件。 data = pd.DataFrame() data[&#39;format&#39;] = train[&#39;image_names&#39;] # as the images are in train_images folder, add train_images before the image name for i in range(data.shape[0]): data[&#39;format&#39;][i] = &#39;train_images/&#39; + data[&#39;format&#39;][i] # add xmin, ymin, xmax, ymax and class as per the format required for i in range(data.shape[0]): data[&#39;format&#39;][i] = data[&#39;format&#39;][i] + &#39;,&#39; + str(train[&#39;xmin&#39;][i]) + &#39;,&#39; + str(train[&#39;ymin&#39;][i]) + &#39;,&#39; + str(train[&#39;xmax&#39;][i]) + &#39;,&#39; + str(train[&#39;ymax&#39;][i]) + &#39;,&#39; + train[&#39;cell_type&#39;][i] data.to_csv(&#39;annotate.txt&#39;, header=None, index=None, sep=&#39; &#39;) 下一步进行模型训练，使用train_frcnn.py文件来训练模型。 cd keras-frcnn python train_frcnn.py -o simple -p annotate.txt 由于数据集较大，需要一段时间来训练模型。如果条件满足的话，可以使用GPU来加快训练过程。同样也可以尝试减少num_epochs参数来加快训练过程。 模型每训练好一次（有改进时），该特定时刻的权重将保存在与“model_frcnn.hdf5”相同的目录中。当对测试集进行预测时，将使用到这些权重。 根据机器的配置，可能需要花费大量时间来训练模型并获得权重。建议使用本文训练大约500个时期的权重作为初始化。可以从这里下载这些权重，并设置好相应的路径。 因此，当模型训练好并保存好权重后，下面进行预测。Keras_frcnn对新图像进行预测并将其保存在新文件夹中，这里只需在test_frcnn.py文件中进行两处更改即可保存图像： 从该文件的最后一行删除注释： cv2.imwrite（&#39;./ results_imgs / {}。png&#39;.format（idx），img）； 在此文件的倒数第二行和第三行添加注释： ＃cv2.imshow（&#39;img&#39;，img） ； ＃cv2.waitKey（0）； 使用下面的代码进行图像预测： python test_frcnn.py -p test_images 最后，检测到对象的图像将保存在“results_imgs”文件夹中。以下是本文实现faster R-CNN后预测几个样本获得的结果： 结果1 结果2 结果3 结果4 总结 R-CNN算法确实是用于对象检测任务的变革者，改变了传统的做法，并开创了深度学习算法。近年来，计算机视觉应用的数量突然出现飙升，而R-CNN系列算法仍然是其中大多数应用的核心。 Keras_frcnn也被证明是一个很好的对象检测工具库，在本系列的下一篇文章中，将专注于更先进的技术，如YOLO，SSD等。 本文作者：【方向】 阅读原文 本文为云栖社区原创内容，未经允许不得转载。" />
<meta property="og:description" content="摘要： 本文在讲述RCNN系列算法基本原理基础上，使用keras实现faster RCNN算法，在细胞检测任务上表现优异，可动手操作一下。 目标检测一直是计算机视觉中比较热门的研究领域，有一些常用且成熟的算法得到业内公认水平，比如RCNN系列算法、SSD以及YOLO等。如果你是从事这一行业的话，你会使用哪种算法进行目标检测任务呢？在我寻求在最短的时间内构建最精确的模型时，我尝试了其中的R-CNN系列算法，如果读者们对这方面的算法还不太了解的话，建议阅读《目标检测算法图解：一文看懂RCNN系列算法》。在掌握基本原理后，下面进入实战部分。 本文将使用一个非常酷且有用的数据集来实现faster R-CNN，这些数据集具有潜在的真实应用场景。 问题陈述 数据来源于医疗相关数据集，目的是解决血细胞检测问题。任务是通过显微图像读数来检测每张图像中的所有红细胞（RBC）、白细胞（WBC）以及血小板。最终预测效果应如下所示： 选择该数据集的原因是我们血液中RBC、WBC和血小板的密度提供了大量关于免疫系统和血红蛋白的信息，这些信息可以帮助我们初步地识别一个人是否健康，如果在其血液中发现了任何差异，我们就可以迅速采取行动来进行下一步的诊断。 通过显微镜手动查看样品是一个繁琐的过程，这也是深度学习模式能够发挥重要作用的地方，一些算法可以从显微图像中分类和检测血细胞，并且达到很高的精确度。 本文采用的血细胞检测数据集可以从这里下载，本文稍微修改了一些数据： 边界框已从给定的.xml格式转换为.csv格式； 随机划分数据集，得到训练集和测试集； 这里使用流行的Keras框架构建本文模型。 系统设置 在真正进入模型构建阶段之前，需要确保系统已安装正确的库和相应的框架。运行此项目需要以下库： pandas matplotlib tensorflow keras – 2.0.3 numpy opencv-python sklearn h5py 对于已经安装了Anaconda和Jupyter的电脑而言，上述这些库大多数已经安装好了。建议从此链接下载requirements.txt文件，并使用它来安装剩余的库。在终端中键入以下命令来执行此操作： pip install -r requirement.txt 系统设置好后，下一步是进行数据处理。 数据探索 首先探索所拥有的数据总是一个好开始（坦率地说，这是一个强制性的步骤）。对数据熟悉有助于挖掘隐藏的模式，还可以获得对整体的洞察力。本文从整个数据集中创建了三个文件，分别是： train_images：用于训练模型的图像，包含每个图像的类别和实际边界框； test_images：用于模型预测的图像，该集合缺少对应的标签； train.csv：包含每个图像的名称、类别和边界框坐标。一张图像可以有多行数据，因为单张图像可能包含多个对象； 读取.csv文件并打印出前几行： # importing required libraries import pandas as pd import matplotlib.pyplot as plt %matplotlib inline from matplotlib import patches # read the csv file using read_csv function of pandas train = pd.read_csv(‘train.csv’) train.head() 训练文件中总共有6列，其中每列代表的内容如下： image_names：图像的名称； cell_type：表示单元的类型； xmin：图像左下角的x坐标； xmax：图像右上角的x坐标； ymin：图像左下角的y坐标； ymax：图像右上角的y坐标； 下面打印出一张图片来展示正在处理的图像： # reading single image using imread function of matplotlib image = plt.imread(&#39;images/1.jpg&#39;) plt.imshow(image) 上图就是血细胞图像的样子，其中，蓝色部分代表WBC，略带红色的部分代表RBC。下面看看整个训练集中总共有多少张图像和不同类型的数量。 # Number of classes train[&#39;cell_type&#39;].value_counts() 结果显示训练集有254张图像。 # Number of classes train[&#39;cell_type&#39;].value_counts() 结果显示有三种不同类型的细胞，即RBC，WBC和血小板。最后，看一下检测到的对象的图像是怎样的： fig = plt.figure() #add axes to the image ax = fig.add_axes([0,0,1,1]) # read and plot the image image = plt.imread(&#39;images/1.jpg&#39;) plt.imshow(image) # iterating over the image for different objects for _,row in train[train.image_names == &quot;1.jpg&quot;].iterrows(): xmin = row.xmin xmax = row.xmax ymin = row.ymin ymax = row.ymax width = xmax - xmin height = ymax - ymin # assign different color to different classes of objects if row.cell_type == &#39;RBC&#39;: edgecolor = &#39;r&#39; ax.annotate(&#39;RBC&#39;, xy=(xmax-40,ymin+20)) elif row.cell_type == &#39;WBC&#39;: edgecolor = &#39;b&#39; ax.annotate(&#39;WBC&#39;, xy=(xmax-40,ymin+20)) elif row.cell_type == &#39;Platelets&#39;: edgecolor = &#39;g&#39; ax.annotate(&#39;Platelets&#39;, xy=(xmax-40,ymin+20)) # add bounding boxes to the image rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = &#39;none&#39;) ax.add_patch(rect) 上图就是训练样本示例，从中可以看到，细胞有不同的类及其相应的边界框。下面进行模型训练，本文使用keras_frcnn库来训练搭建的模型以及对测试图像进行预测。 faster R-CNN实现 为了实现 faster R-CNN算法，本文遵循此Github存储库中提到的步骤。因此，首先请确保克隆好此存储库。打开一个新的终端窗口并键入以下内容以执行此操作： git clone https://github.com/kbardool/keras-frcnn.git 并将train_images和test_images文件夹以及train.csv文件移动到该存储库目录下。为了在新数据集上训练模型，输入的格式应为： filepath,x1,y1,x2,y2,class_name 其中： filepath是训练图像的路径； x1是边界框的xmin坐标； y1是边界框的ymin坐标； x2是边界框的xmax坐标； y2是边界框的ymax坐标； class_name是该边界框中类的名称； 这里需要将.csv格式转换为.txt文件，该文件具有与上述相同的格式。创建一个新的数据帧，按照格式将所有值填入该数据帧，然后将其另存为.txt文件。 data = pd.DataFrame() data[&#39;format&#39;] = train[&#39;image_names&#39;] # as the images are in train_images folder, add train_images before the image name for i in range(data.shape[0]): data[&#39;format&#39;][i] = &#39;train_images/&#39; + data[&#39;format&#39;][i] # add xmin, ymin, xmax, ymax and class as per the format required for i in range(data.shape[0]): data[&#39;format&#39;][i] = data[&#39;format&#39;][i] + &#39;,&#39; + str(train[&#39;xmin&#39;][i]) + &#39;,&#39; + str(train[&#39;ymin&#39;][i]) + &#39;,&#39; + str(train[&#39;xmax&#39;][i]) + &#39;,&#39; + str(train[&#39;ymax&#39;][i]) + &#39;,&#39; + train[&#39;cell_type&#39;][i] data.to_csv(&#39;annotate.txt&#39;, header=None, index=None, sep=&#39; &#39;) 下一步进行模型训练，使用train_frcnn.py文件来训练模型。 cd keras-frcnn python train_frcnn.py -o simple -p annotate.txt 由于数据集较大，需要一段时间来训练模型。如果条件满足的话，可以使用GPU来加快训练过程。同样也可以尝试减少num_epochs参数来加快训练过程。 模型每训练好一次（有改进时），该特定时刻的权重将保存在与“model_frcnn.hdf5”相同的目录中。当对测试集进行预测时，将使用到这些权重。 根据机器的配置，可能需要花费大量时间来训练模型并获得权重。建议使用本文训练大约500个时期的权重作为初始化。可以从这里下载这些权重，并设置好相应的路径。 因此，当模型训练好并保存好权重后，下面进行预测。Keras_frcnn对新图像进行预测并将其保存在新文件夹中，这里只需在test_frcnn.py文件中进行两处更改即可保存图像： 从该文件的最后一行删除注释： cv2.imwrite（&#39;./ results_imgs / {}。png&#39;.format（idx），img）； 在此文件的倒数第二行和第三行添加注释： ＃cv2.imshow（&#39;img&#39;，img） ； ＃cv2.waitKey（0）； 使用下面的代码进行图像预测： python test_frcnn.py -p test_images 最后，检测到对象的图像将保存在“results_imgs”文件夹中。以下是本文实现faster R-CNN后预测几个样本获得的结果： 结果1 结果2 结果3 结果4 总结 R-CNN算法确实是用于对象检测任务的变革者，改变了传统的做法，并开创了深度学习算法。近年来，计算机视觉应用的数量突然出现飙升，而R-CNN系列算法仍然是其中大多数应用的核心。 Keras_frcnn也被证明是一个很好的对象检测工具库，在本系列的下一篇文章中，将专注于更先进的技术，如YOLO，SSD等。 本文作者：【方向】 阅读原文 本文为云栖社区原创内容，未经允许不得转载。" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-12-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"摘要： 本文在讲述RCNN系列算法基本原理基础上，使用keras实现faster RCNN算法，在细胞检测任务上表现优异，可动手操作一下。 目标检测一直是计算机视觉中比较热门的研究领域，有一些常用且成熟的算法得到业内公认水平，比如RCNN系列算法、SSD以及YOLO等。如果你是从事这一行业的话，你会使用哪种算法进行目标检测任务呢？在我寻求在最短的时间内构建最精确的模型时，我尝试了其中的R-CNN系列算法，如果读者们对这方面的算法还不太了解的话，建议阅读《目标检测算法图解：一文看懂RCNN系列算法》。在掌握基本原理后，下面进入实战部分。 本文将使用一个非常酷且有用的数据集来实现faster R-CNN，这些数据集具有潜在的真实应用场景。 问题陈述 数据来源于医疗相关数据集，目的是解决血细胞检测问题。任务是通过显微图像读数来检测每张图像中的所有红细胞（RBC）、白细胞（WBC）以及血小板。最终预测效果应如下所示： 选择该数据集的原因是我们血液中RBC、WBC和血小板的密度提供了大量关于免疫系统和血红蛋白的信息，这些信息可以帮助我们初步地识别一个人是否健康，如果在其血液中发现了任何差异，我们就可以迅速采取行动来进行下一步的诊断。 通过显微镜手动查看样品是一个繁琐的过程，这也是深度学习模式能够发挥重要作用的地方，一些算法可以从显微图像中分类和检测血细胞，并且达到很高的精确度。 本文采用的血细胞检测数据集可以从这里下载，本文稍微修改了一些数据： 边界框已从给定的.xml格式转换为.csv格式； 随机划分数据集，得到训练集和测试集； 这里使用流行的Keras框架构建本文模型。 系统设置 在真正进入模型构建阶段之前，需要确保系统已安装正确的库和相应的框架。运行此项目需要以下库： pandas matplotlib tensorflow keras – 2.0.3 numpy opencv-python sklearn h5py 对于已经安装了Anaconda和Jupyter的电脑而言，上述这些库大多数已经安装好了。建议从此链接下载requirements.txt文件，并使用它来安装剩余的库。在终端中键入以下命令来执行此操作： pip install -r requirement.txt 系统设置好后，下一步是进行数据处理。 数据探索 首先探索所拥有的数据总是一个好开始（坦率地说，这是一个强制性的步骤）。对数据熟悉有助于挖掘隐藏的模式，还可以获得对整体的洞察力。本文从整个数据集中创建了三个文件，分别是： train_images：用于训练模型的图像，包含每个图像的类别和实际边界框； test_images：用于模型预测的图像，该集合缺少对应的标签； train.csv：包含每个图像的名称、类别和边界框坐标。一张图像可以有多行数据，因为单张图像可能包含多个对象； 读取.csv文件并打印出前几行： # importing required libraries import pandas as pd import matplotlib.pyplot as plt %matplotlib inline from matplotlib import patches # read the csv file using read_csv function of pandas train = pd.read_csv(‘train.csv’) train.head() 训练文件中总共有6列，其中每列代表的内容如下： image_names：图像的名称； cell_type：表示单元的类型； xmin：图像左下角的x坐标； xmax：图像右上角的x坐标； ymin：图像左下角的y坐标； ymax：图像右上角的y坐标； 下面打印出一张图片来展示正在处理的图像： # reading single image using imread function of matplotlib image = plt.imread(&#39;images/1.jpg&#39;) plt.imshow(image) 上图就是血细胞图像的样子，其中，蓝色部分代表WBC，略带红色的部分代表RBC。下面看看整个训练集中总共有多少张图像和不同类型的数量。 # Number of classes train[&#39;cell_type&#39;].value_counts() 结果显示训练集有254张图像。 # Number of classes train[&#39;cell_type&#39;].value_counts() 结果显示有三种不同类型的细胞，即RBC，WBC和血小板。最后，看一下检测到的对象的图像是怎样的： fig = plt.figure() #add axes to the image ax = fig.add_axes([0,0,1,1]) # read and plot the image image = plt.imread(&#39;images/1.jpg&#39;) plt.imshow(image) # iterating over the image for different objects for _,row in train[train.image_names == &quot;1.jpg&quot;].iterrows(): xmin = row.xmin xmax = row.xmax ymin = row.ymin ymax = row.ymax width = xmax - xmin height = ymax - ymin # assign different color to different classes of objects if row.cell_type == &#39;RBC&#39;: edgecolor = &#39;r&#39; ax.annotate(&#39;RBC&#39;, xy=(xmax-40,ymin+20)) elif row.cell_type == &#39;WBC&#39;: edgecolor = &#39;b&#39; ax.annotate(&#39;WBC&#39;, xy=(xmax-40,ymin+20)) elif row.cell_type == &#39;Platelets&#39;: edgecolor = &#39;g&#39; ax.annotate(&#39;Platelets&#39;, xy=(xmax-40,ymin+20)) # add bounding boxes to the image rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = &#39;none&#39;) ax.add_patch(rect) 上图就是训练样本示例，从中可以看到，细胞有不同的类及其相应的边界框。下面进行模型训练，本文使用keras_frcnn库来训练搭建的模型以及对测试图像进行预测。 faster R-CNN实现 为了实现 faster R-CNN算法，本文遵循此Github存储库中提到的步骤。因此，首先请确保克隆好此存储库。打开一个新的终端窗口并键入以下内容以执行此操作： git clone https://github.com/kbardool/keras-frcnn.git 并将train_images和test_images文件夹以及train.csv文件移动到该存储库目录下。为了在新数据集上训练模型，输入的格式应为： filepath,x1,y1,x2,y2,class_name 其中： filepath是训练图像的路径； x1是边界框的xmin坐标； y1是边界框的ymin坐标； x2是边界框的xmax坐标； y2是边界框的ymax坐标； class_name是该边界框中类的名称； 这里需要将.csv格式转换为.txt文件，该文件具有与上述相同的格式。创建一个新的数据帧，按照格式将所有值填入该数据帧，然后将其另存为.txt文件。 data = pd.DataFrame() data[&#39;format&#39;] = train[&#39;image_names&#39;] # as the images are in train_images folder, add train_images before the image name for i in range(data.shape[0]): data[&#39;format&#39;][i] = &#39;train_images/&#39; + data[&#39;format&#39;][i] # add xmin, ymin, xmax, ymax and class as per the format required for i in range(data.shape[0]): data[&#39;format&#39;][i] = data[&#39;format&#39;][i] + &#39;,&#39; + str(train[&#39;xmin&#39;][i]) + &#39;,&#39; + str(train[&#39;ymin&#39;][i]) + &#39;,&#39; + str(train[&#39;xmax&#39;][i]) + &#39;,&#39; + str(train[&#39;ymax&#39;][i]) + &#39;,&#39; + train[&#39;cell_type&#39;][i] data.to_csv(&#39;annotate.txt&#39;, header=None, index=None, sep=&#39; &#39;) 下一步进行模型训练，使用train_frcnn.py文件来训练模型。 cd keras-frcnn python train_frcnn.py -o simple -p annotate.txt 由于数据集较大，需要一段时间来训练模型。如果条件满足的话，可以使用GPU来加快训练过程。同样也可以尝试减少num_epochs参数来加快训练过程。 模型每训练好一次（有改进时），该特定时刻的权重将保存在与“model_frcnn.hdf5”相同的目录中。当对测试集进行预测时，将使用到这些权重。 根据机器的配置，可能需要花费大量时间来训练模型并获得权重。建议使用本文训练大约500个时期的权重作为初始化。可以从这里下载这些权重，并设置好相应的路径。 因此，当模型训练好并保存好权重后，下面进行预测。Keras_frcnn对新图像进行预测并将其保存在新文件夹中，这里只需在test_frcnn.py文件中进行两处更改即可保存图像： 从该文件的最后一行删除注释： cv2.imwrite（&#39;./ results_imgs / {}。png&#39;.format（idx），img）； 在此文件的倒数第二行和第三行添加注释： ＃cv2.imshow（&#39;img&#39;，img） ； ＃cv2.waitKey（0）； 使用下面的代码进行图像预测： python test_frcnn.py -p test_images 最后，检测到对象的图像将保存在“results_imgs”文件夹中。以下是本文实现faster R-CNN后预测几个样本获得的结果： 结果1 结果2 结果3 结果4 总结 R-CNN算法确实是用于对象检测任务的变革者，改变了传统的做法，并开创了深度学习算法。近年来，计算机视觉应用的数量突然出现飙升，而R-CNN系列算法仍然是其中大多数应用的核心。 Keras_frcnn也被证明是一个很好的对象检测工具库，在本系列的下一篇文章中，将专注于更先进的技术，如YOLO，SSD等。 本文作者：【方向】 阅读原文 本文为云栖社区原创内容，未经允许不得转载。","@type":"BlogPosting","url":"/2018/12/17/2e080c1ff6085ffd1287cb18cb5e7fd1.html","headline":"深度学习目标检测系列：faster RCNN实现 附python源码","dateModified":"2018-12-17T00:00:00+08:00","datePublished":"2018-12-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2018/12/17/2e080c1ff6085ffd1287cb18cb5e7fd1.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>深度学习目标检测系列：faster RCNN实现|附python源码</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="show-content-free"> 
   <blockquote> 
    <p><strong>摘要：</strong> 本文在讲述RCNN系列算法基本原理基础上，使用keras实现faster RCNN算法，在细胞检测任务上表现优异，可动手操作一下。</p> 
   </blockquote> 
   <p>目标检测一直是计算机视觉中比较热门的研究领域，有一些常用且成熟的算法得到业内公认水平，比如RCNN系列算法、SSD以及YOLO等。如果你是从事这一行业的话，你会使用哪种算法进行目标检测任务呢？在我寻求在最短的时间内构建最精确的模型时，我尝试了其中的R-CNN系列算法，如果读者们对这方面的算法还不太了解的话，建议阅读<a href="https://yq.aliyun.com/articles/676148?spm=a2c4e.11155435.0.0.64ba3312lzxSbs" rel="nofollow">《目标检测算法图解：一文看懂RCNN系列算法》</a>。在掌握基本原理后，下面进入实战部分。</p> 
   <p>本文将使用一个非常酷且有用的数据集来实现faster R-CNN，这些数据集具有潜在的真实应用场景。</p> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/2509688-88a8bf715abe317d.png" alt="2509688-88a8bf715abe317d.png">
     </div> 
    </div> 
    <div class="image-caption"></div> 
   </div> 
   <h2>问题陈述</h2> 
   <p>数据来源于医疗相关数据集，目的是解决血细胞检测问题。任务是通过显微图像读数来检测每张图像中的所有红细胞（RBC）、白细胞（WBC）以及血小板。最终预测效果应如下所示：</p> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/2509688-21a7ce849dfee836.png" alt="2509688-21a7ce849dfee836.png">
     </div> 
    </div> 
    <div class="image-caption"></div> 
   </div> 
   <p>选择该数据集的原因是我们血液中RBC、WBC和血小板的密度提供了大量关于免疫系统和血红蛋白的信息，这些信息可以帮助我们初步地识别一个人是否健康，如果在其血液中发现了任何差异，我们就可以迅速采取行动来进行下一步的诊断。</p> 
   <p>通过显微镜手动查看样品是一个繁琐的过程，这也是深度学习模式能够发挥重要作用的地方，一些算法可以从显微图像中分类和检测血细胞，并且达到很高的精确度。</p> 
   <p>本文采用的血细胞检测数据集可以从<a href="https://github.com/Shenggan/BCCD_Dataset" rel="nofollow">这里</a>下载，本文稍微修改了一些数据：</p> 
   <ul>
    <li>边界框已从给定的.xml格式转换为.csv格式；</li> 
    <li>随机划分数据集，得到训练集和测试集；</li> 
   </ul>
   <p>这里使用流行的Keras框架构建本文模型。</p> 
   <h4>系统设置</h4> 
   <p>在真正进入模型构建阶段之前，需要确保系统已安装正确的库和相应的框架。运行此项目需要以下库：</p> 
   <ul>
    <li>pandas</li> 
    <li>matplotlib</li> 
    <li>tensorflow</li> 
    <li>keras – 2.0.3</li> 
    <li>numpy</li> 
    <li>opencv-python</li> 
    <li>sklearn</li> 
    <li>h5py</li> 
   </ul>
   <p>对于已经安装了Anaconda和Jupyter的电脑而言，上述这些库大多数已经安装好了。建议从<a href="https://drive.google.com/file/d/1R4O0stMW9Wjksg-o7c54svntDiyask1B/view?usp=sharing" rel="nofollow">此链接下载</a>requirements.txt文件，并使用它来安装剩余的库。在终端中键入以下命令来执行此操作：</p> 
   <pre><code>pip install -r requirement.txt
</code></pre> 
   <p>系统设置好后，下一步是进行数据处理。</p> 
   <h4>数据探索</h4> 
   <p>首先探索所拥有的数据总是一个好开始（坦率地说，这是一个强制性的步骤）。对数据熟悉有助于挖掘隐藏的模式，还可以获得对整体的洞察力。本文从整个数据集中创建了三个文件，分别是：</p> 
   <ul>
    <li> <code>train_images</code>：用于训练模型的图像，包含每个图像的类别和实际边界框；</li> 
    <li> <code>test_images</code>：用于模型预测的图像，该集合缺少对应的标签；</li> 
    <li> <code>train.csv</code>：包含每个图像的名称、类别和边界框坐标。一张图像可以有多行数据，因为单张图像可能包含多个对象；</li> 
   </ul>
   <p>读取<code>.csv</code>文件并打印出前几行：</p> 
   <pre><code># importing required libraries
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from matplotlib import patches

# read the csv file using read_csv function of pandas
train = pd.read_csv(‘train.csv’)
train.head()
</code></pre> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/2509688-f74433a29f6c39b7.png" alt="2509688-f74433a29f6c39b7.png">
     </div> 
    </div> 
    <div class="image-caption"></div> 
   </div> 
   <p>训练文件中总共有6列，其中每列代表的内容如下：</p> 
   <ul>
    <li> <code>image_names</code>：图像的名称；</li> 
    <li> <code>cell_type</code>：表示单元的类型；</li> 
    <li> <code>xmin</code>：图像左下角的x坐标；</li> 
    <li> <code>xmax</code>：图像右上角的x坐标；</li> 
    <li> <code>ymin</code>：图像左下角的y坐标；</li> 
    <li> <code>ymax</code>：图像右上角的y坐标；</li> 
   </ul>
   <p>下面打印出一张图片来展示正在处理的图像：</p> 
   <pre><code># reading single image using imread function of matplotlib
image = plt.imread('images/1.jpg')
plt.imshow(image)
</code></pre> 
   <p>上图就是血细胞图像的样子，其中，蓝色部分代表WBC，略带红色的部分代表RBC。下面看看整个训练集中总共有多少张图像和不同类型的数量。</p> 
   <pre><code># Number of classes
train['cell_type'].value_counts()
</code></pre> 
   <p>结果显示训练集有254张图像。</p> 
   <pre><code># Number of classes
train['cell_type'].value_counts()
</code></pre> 
   <p>结果显示有三种不同类型的细胞，即RBC，WBC和血小板。最后，看一下检测到的对象的图像是怎样的：</p> 
   <pre><code>fig = plt.figure()

#add axes to the image
ax = fig.add_axes([0,0,1,1])

# read and plot the image
image = plt.imread('images/1.jpg')
plt.imshow(image)

# iterating over the image for different objects
for _,row in train[train.image_names == "1.jpg"].iterrows():
    xmin = row.xmin
    xmax = row.xmax
    ymin = row.ymin
    ymax = row.ymax

    width = xmax - xmin
    height = ymax - ymin

    # assign different color to different classes of objects
    if row.cell_type == 'RBC':
        edgecolor = 'r'
        ax.annotate('RBC', xy=(xmax-40,ymin+20))
    elif row.cell_type == 'WBC':
        edgecolor = 'b'
        ax.annotate('WBC', xy=(xmax-40,ymin+20))
    elif row.cell_type == 'Platelets':
        edgecolor = 'g'
        ax.annotate('Platelets', xy=(xmax-40,ymin+20))

    # add bounding boxes to the image
    rect = patches.Rectangle((xmin,ymin), width, height, edgecolor = edgecolor, facecolor = 'none')

    ax.add_patch(rect)
</code></pre> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/2509688-318f4e301374407d.png" alt="2509688-318f4e301374407d.png">
     </div> 
    </div> 
    <div class="image-caption"></div> 
   </div> 
   <p>上图就是训练样本示例，从中可以看到，细胞有不同的类及其相应的边界框。下面进行模型训练，本文使用<code>keras_frcnn</code>库来训练搭建的模型以及对测试图像进行预测。</p> 
   <h4>faster R-CNN实现</h4> 
   <p>为了实现 faster R-CNN算法，本文遵循<a href="https://github.com/kbardool/keras-frcnn" rel="nofollow">此Github存储库</a>中提到的步骤。因此，首先请确保克隆好此存储库。打开一个新的终端窗口并键入以下内容以执行此操作：</p> 
   <pre><code>git clone https://github.com/kbardool/keras-frcnn.git
</code></pre> 
   <p>并将<code>train_images</code>和<code>test_images</code>文件夹以及<code>train.csv</code>文件移动到该存储库目录下。为了在新数据集上训练模型，输入的格式应为：</p> 
   <pre><code>filepath,x1,y1,x2,y2,class_name
</code></pre> 
   <p>其中：</p> 
   <ul>
    <li>filepath是训练图像的路径；</li> 
    <li>x1是边界框的xmin坐标；</li> 
    <li>y1是边界框的ymin坐标；</li> 
    <li>x2是边界框的xmax坐标；</li> 
    <li>y2是边界框的ymax坐标；</li> 
    <li>class_name是该边界框中类的名称；</li> 
   </ul>
   <p>这里需要将<code>.csv</code>格式转换为<code>.txt</code>文件，该文件具有与上述相同的格式。创建一个新的数据帧，按照格式将所有值填入该数据帧，然后将其另存为<code>.txt</code>文件。</p> 
   <pre><code>data = pd.DataFrame()
data['format'] = train['image_names']

# as the images are in train_images folder, add train_images before the image name
for i in range(data.shape[0]):
    data['format'][i] = 'train_images/' + data['format'][i]

# add xmin, ymin, xmax, ymax and class as per the format required
for i in range(data.shape[0]):
    data['format'][i] = data['format'][i] + ',' + str(train['xmin'][i]) + ',' + str(train['ymin'][i]) + ',' + str(train['xmax'][i]) + ',' + str(train['ymax'][i]) + ',' + train['cell_type'][i]

data.to_csv('annotate.txt', header=None, index=None, sep=' ')
</code></pre> 
   <p>下一步进行模型训练，使用<code>train_frcnn.py</code>文件来训练模型。</p> 
   <pre><code>cd keras-frcnn
python train_frcnn.py -o simple -p annotate.txt
</code></pre> 
   <p>由于数据集较大，需要一段时间来训练模型。如果条件满足的话，可以使用GPU来加快训练过程。同样也可以尝试减少<code>num_epochs</code>参数来加快训练过程。</p> 
   <p>模型每训练好一次（有改进时），该特定时刻的权重将保存在与“model_frcnn.hdf5”相同的目录中。当对测试集进行预测时，将使用到这些权重。</p> 
   <p>根据机器的配置，可能需要花费大量时间来训练模型并获得权重。建议使用本文训练大约500个时期的权重作为初始化。可以从<a href="https://drive.google.com/file/d/1OmCKlUEYmTjg_jaaN-IQm81eHROU-Gyl/view?usp=sharing" rel="nofollow">这里</a>下载这些权重，并设置好相应的路径。</p> 
   <p>因此，当模型训练好并保存好权重后，下面进行预测。<code>Keras_frcnn</code>对新图像进行预测并将其保存在新文件夹中，这里只需在<code>test_frcnn.py</code>文件中进行两处更改即可保存图像：</p> 
   <ul>
    <li> <p>从该文件的最后一行删除注释：</p> 
     <ul>
      <li>cv2.imwrite（'./ results_imgs / {}。png'.format（idx），img）；</li> 
     </ul></li> 
    <li> <p>在此文件的倒数第二行和第三行添加注释：</p> 
     <ul>
      <li>＃cv2.imshow（'img'，img） ；</li> 
      <li>＃cv2.waitKey（0）；</li> 
     </ul></li> 
   </ul>
   <p>使用下面的代码进行图像预测：</p> 
   <pre><code>python test_frcnn.py -p test_images
</code></pre> 
   <p>最后，检测到对象的图像将保存在“results_imgs”文件夹中。以下是本文实现faster R-CNN后预测几个样本获得的结果：</p> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/2509688-a7ac08c23e6adb97.png" alt="2509688-a7ac08c23e6adb97.png">
     </div> 
    </div> 
    <div class="image-caption">
     结果1
    </div> 
   </div> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/2509688-d6e6146ea0f7725d.png" alt="2509688-d6e6146ea0f7725d.png">
     </div> 
    </div> 
    <div class="image-caption">
     结果2
    </div> 
   </div> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/2509688-22423526c76b5922.png" alt="2509688-22423526c76b5922.png">
     </div> 
    </div> 
    <div class="image-caption">
     结果3
    </div> 
   </div> 
   <div class="image-package"> 
    <div class="image-container"> 
     <div class="image-container-fill"></div> 
     <div class="image-view">
      <img src="https://upload-images.jianshu.io/upload_images/2509688-e289d69cf5e7fa29.png" alt="2509688-e289d69cf5e7fa29.png">
     </div> 
    </div> 
    <div class="image-caption">
     结果4
    </div> 
   </div> 
   <h4>总结</h4> 
   <p>R-CNN算法确实是用于对象检测任务的变革者，改变了传统的做法，并开创了深度学习算法。近年来，计算机视觉应用的数量突然出现飙升，而R-CNN系列算法仍然是其中大多数应用的核心。</p> 
   <p><code>Keras_frcnn</code>也被证明是一个很好的对象检测工具库，在本系列的下一篇文章中，将专注于更先进的技术，如YOLO，SSD等。<br></p>
   <hr>
   <br> 本文作者：【方向】
   <p></p> 
   <p><a href="https://yq.aliyun.com/articles/679245?utm_content=g_1000031076" rel="nofollow">阅读原文</a></p> 
   <p>本文为云栖社区原创内容，未经允许不得转载。</p> 
  </div> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
