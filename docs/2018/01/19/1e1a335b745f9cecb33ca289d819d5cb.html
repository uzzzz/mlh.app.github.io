<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>如何一夜暴富？这里有一份比特币价格预测指南 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="如何一夜暴富？这里有一份比特币价格预测指南" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="翻译 | AI科技大本营（rgznai100） 参与 | 王赫 编辑 | Donna 近年来，以比特币为代表的加密数字货币一直是社交媒体和搜索引擎上的热门。但是，比特币价格浮动也使各位看官们经历了过山车般的体验。 随着本周各大权威机构纷纷表示看好区块链的未来，从1月17日到18日凌晨，比特币成功止住前一日暴跌的颓势，涨幅接近20%（18.46%）。 如果我们能够智能化的制定投资策略的话，就能发现这些反复无常的波动背后潜藏着巨大的利润。 与传统金融工具相比，加密货币由于缺乏指标数据，预测变得非常困难。 本文以当下最火的比特币为例，来探讨如何用深度学习预测加密数字货币的价格，并了解它们未来的发展趋势。 免责声明：比特币等数字货币的交易属于投资行为。交易有风险，买币须谨慎。由此带来的收益和亏损，和营长无关。若要打赏，猛戳“转发”与“点赞”即可。 第一步 要运行本文中的代码，请确保已经安装了以下环境和代码库： Python 2.7 Tensorflow=1.2.0 Keras=2.1.1 Pandas=0.20.3 Numpy=1.13.3 h5py=2.7.0 sklearn=0.19.1 数据采集 用于分析预测的数据可以从Kaggle或者Poloniex上收集到。 为确保在不同数据集之间代码适用的一致性，从Poloniex上收集数据的列名都会更改为与Kaggle相匹配的列名。 数据准备 从数据源收集而来的数据需要先被解析一下才能送到模型中进行预测。下面代码中，PastSampler类是参考这个博客上的方法将数据分成一列子数据集和相应的标签数据集。模型输入数据大小（N）为256个，输出大小（K）为16个。 值得注意的是，从Poloniex收集来的数据是以5分钟为基础间隔时序数据。 这表明输入模型的数据跨度为1280分钟，而输出的数据跨度超过了80分钟。 在创建完PastSampler类之后，我将利用此类来收集数据。 由于原始数据的取值范围从0到10000以上，因此需要对数据进行缩放操作来使神经网络更容易理解数据。 模型构建 CNN 一维卷积神经网络可以通过核窗口在输入数据上滑动的情况下很好地捕捉数据的局部特征。 如下图所示。 CNN 图例 来自 http://cs231n.github.io/convolutional-networks/ 上述代码是我建立的第一个卷积神经网络模型。 以下代码将我的GPU编号为“1”（这是因为我有4个GPU，您可以将其设置为您任何一个GPU）。 由于Tensorflow在多GPU上运行似乎不尽人意，因此把它限制在一个GPU上运行很合适的。 如果您没有GPU也请不要担心，尽管忽略下面的代码就好。 构建CNN模型的代码是非常简单的。加入dropout层是为了避免过拟合问题。 损失函数的定义为均方误差（MSE），而优化器选用最先进的Adam自适应优化。 唯一需要担心的是每层之间的输入数据和输出数据的维度。 计算某个卷积层输出数据维度的公式是： 输出时间步长=（输入时间步长 - 核窗口大小）/步幅+ 1 在下面代码的末尾，我添加了两个回调函数CSVLogger和ModelCheckpoint。 前者可以帮助我跟踪所有的训练和验证过程，而后者则可以存储每个周期的模型权重参数。 LSTM 长期短期记忆（LSTM）网络是递归神经网络（RNN）的一种变体，发明它的目的是为了解决在普通RNN中存在的梯度消失问题。 据称LSTM能够记住更长的时序输入步长。 LSTM 图例 (来自 http://colah.github.io/posts/2015-08-Understanding-LSTMs/&gt;) LSTM比CNN更容易通过代码实现，这是因为你根本不需要关心核窗口的大小，步长，输入和输出的数据维度大小之间的关系等。 只需要确保输入网络数据和输出网络的数据维度就可以了。 GRU 门控循环单元（GRU）是RNN的另一种变体。 它的网络结构不如LSTM那么复杂，只有一个复位门和忘记门，而不是记忆单元。 据称GRU的性能与LSTM是相当的，但效率可以更高。 （在本文中也是如此的，因为LSTM大约需要跑45秒/周期，而GRU则不到40秒/周期） 来自http://www.jackdermody.net/brightwire/article/GRU_Recurrent_Neural_Networks) 只需将LSTM模型中的第二行 替换为 绘图结果 由于三个模型的计算结果图像很相似，所以我只会查看CNN模型的图像。 首先，我们需要重建模型并将训练权重加载到模型中。 然后，我们需要对预测后的数据进行反向缩放，因为之前使用了MinMaxScaler，因此此时预测的数据范围是在[0,1]。 如上所示的两个Dataframes分别构造了真实值（实际价格）以及比特币的预测价格。 为了更好的可视化，绘制的图像只显示了2017年8月之后的数据。 我们使用pyplot绘制图形。 由于预测出的价格是以16分钟为间隔的，所以为了让我们更方便的查看结果，我就不把它们全部链接起来了。 结果，这里预测的数据被绘制成红点，如第三行中的“ro”所示。 下图中的蓝线表示真实值（实际价格数据），而红点表示预测的比特币价格。 使用2层CNN模型预测的最佳比特币价格 从上图可以看出，预测价格与比特币的实际价格是非常相似的。 为了得到最佳模型效果，我决定测试集中配置下的神经网络，如下表所示。 不同模型下的预测结果 上表中的每一行都是从100个训练周期中得到的最佳验证损失的模型。 从以上结果可以看出，LeakyReLU似乎总是比通常的ReLU产生更好的损失效果。 但是，使用Leaky ReLU作为激活函数的4层CNN模型会得到较大的验证损失值，这可能是由于重新验证的模型所导致的问题。 CNN模型可以训练得非常快（使用GPU时，2秒/周期），在性能上要比LSTM和GRU稍差一点。 虽然3层CNN似乎可以更好地捕捉数据的局部时间依赖性，但最好的模型似乎是用 tanh和Leaky ReLU作为激活函数的LSTM模型。 用Tanh和Leaky ReLu作为激活函数的LSTM模型 用Leaky ReLu作为激活函数的3层CNN模型 虽然预测看起来都相当不错，但是过度拟合还是很值得留意的。 当用LeakyReLU训练LSTM时，训练损失和验证损失之间存在差距（5.97E-06 vs 3.92E-05），应该使用正则化来最小化这个差异。 正则化 为了找到最佳的正则化方案，我用L1和L2在不同的几个值中实验。 首先，我们需要定义一个新的函数来使得数据能够拟合到LSTM中。 在这里，我将使用在偏置正规化方法对偏差向量进行正则化。 通过重复训练模型30次，每次30个周期为标准进行实验。 如果你使用的是Jupyter notebook，则可以直接从输出数据中查看如下表格。 使用偏置正则化的结果 为了可视化比较，我们可以使用boxplot绘图： 通过比较可知，L2正则化中偏差向量的系数为0.01时可以似乎得到了最好的结果。 为了找出所有超参数正则化之间的最佳组合，包括激活，偏置，核窗口，循环矩阵等等，有必要逐一测试所有正则化方案，但这对我目前的硬件配置来说并不现实。 因此，我将搁置下来以后再议。 结论 从本文，你已经了解到： 如何收集时序的比特币数据。 如何使用深度学习技术预测比特币的价格。 如何可视化预测的结果。 如何在模型上应用正则化技术。 作者：黃功詳 Steeve Huang 原文链接: https://github.com/khuangaf 阅读更多" />
<meta property="og:description" content="翻译 | AI科技大本营（rgznai100） 参与 | 王赫 编辑 | Donna 近年来，以比特币为代表的加密数字货币一直是社交媒体和搜索引擎上的热门。但是，比特币价格浮动也使各位看官们经历了过山车般的体验。 随着本周各大权威机构纷纷表示看好区块链的未来，从1月17日到18日凌晨，比特币成功止住前一日暴跌的颓势，涨幅接近20%（18.46%）。 如果我们能够智能化的制定投资策略的话，就能发现这些反复无常的波动背后潜藏着巨大的利润。 与传统金融工具相比，加密货币由于缺乏指标数据，预测变得非常困难。 本文以当下最火的比特币为例，来探讨如何用深度学习预测加密数字货币的价格，并了解它们未来的发展趋势。 免责声明：比特币等数字货币的交易属于投资行为。交易有风险，买币须谨慎。由此带来的收益和亏损，和营长无关。若要打赏，猛戳“转发”与“点赞”即可。 第一步 要运行本文中的代码，请确保已经安装了以下环境和代码库： Python 2.7 Tensorflow=1.2.0 Keras=2.1.1 Pandas=0.20.3 Numpy=1.13.3 h5py=2.7.0 sklearn=0.19.1 数据采集 用于分析预测的数据可以从Kaggle或者Poloniex上收集到。 为确保在不同数据集之间代码适用的一致性，从Poloniex上收集数据的列名都会更改为与Kaggle相匹配的列名。 数据准备 从数据源收集而来的数据需要先被解析一下才能送到模型中进行预测。下面代码中，PastSampler类是参考这个博客上的方法将数据分成一列子数据集和相应的标签数据集。模型输入数据大小（N）为256个，输出大小（K）为16个。 值得注意的是，从Poloniex收集来的数据是以5分钟为基础间隔时序数据。 这表明输入模型的数据跨度为1280分钟，而输出的数据跨度超过了80分钟。 在创建完PastSampler类之后，我将利用此类来收集数据。 由于原始数据的取值范围从0到10000以上，因此需要对数据进行缩放操作来使神经网络更容易理解数据。 模型构建 CNN 一维卷积神经网络可以通过核窗口在输入数据上滑动的情况下很好地捕捉数据的局部特征。 如下图所示。 CNN 图例 来自 http://cs231n.github.io/convolutional-networks/ 上述代码是我建立的第一个卷积神经网络模型。 以下代码将我的GPU编号为“1”（这是因为我有4个GPU，您可以将其设置为您任何一个GPU）。 由于Tensorflow在多GPU上运行似乎不尽人意，因此把它限制在一个GPU上运行很合适的。 如果您没有GPU也请不要担心，尽管忽略下面的代码就好。 构建CNN模型的代码是非常简单的。加入dropout层是为了避免过拟合问题。 损失函数的定义为均方误差（MSE），而优化器选用最先进的Adam自适应优化。 唯一需要担心的是每层之间的输入数据和输出数据的维度。 计算某个卷积层输出数据维度的公式是： 输出时间步长=（输入时间步长 - 核窗口大小）/步幅+ 1 在下面代码的末尾，我添加了两个回调函数CSVLogger和ModelCheckpoint。 前者可以帮助我跟踪所有的训练和验证过程，而后者则可以存储每个周期的模型权重参数。 LSTM 长期短期记忆（LSTM）网络是递归神经网络（RNN）的一种变体，发明它的目的是为了解决在普通RNN中存在的梯度消失问题。 据称LSTM能够记住更长的时序输入步长。 LSTM 图例 (来自 http://colah.github.io/posts/2015-08-Understanding-LSTMs/&gt;) LSTM比CNN更容易通过代码实现，这是因为你根本不需要关心核窗口的大小，步长，输入和输出的数据维度大小之间的关系等。 只需要确保输入网络数据和输出网络的数据维度就可以了。 GRU 门控循环单元（GRU）是RNN的另一种变体。 它的网络结构不如LSTM那么复杂，只有一个复位门和忘记门，而不是记忆单元。 据称GRU的性能与LSTM是相当的，但效率可以更高。 （在本文中也是如此的，因为LSTM大约需要跑45秒/周期，而GRU则不到40秒/周期） 来自http://www.jackdermody.net/brightwire/article/GRU_Recurrent_Neural_Networks) 只需将LSTM模型中的第二行 替换为 绘图结果 由于三个模型的计算结果图像很相似，所以我只会查看CNN模型的图像。 首先，我们需要重建模型并将训练权重加载到模型中。 然后，我们需要对预测后的数据进行反向缩放，因为之前使用了MinMaxScaler，因此此时预测的数据范围是在[0,1]。 如上所示的两个Dataframes分别构造了真实值（实际价格）以及比特币的预测价格。 为了更好的可视化，绘制的图像只显示了2017年8月之后的数据。 我们使用pyplot绘制图形。 由于预测出的价格是以16分钟为间隔的，所以为了让我们更方便的查看结果，我就不把它们全部链接起来了。 结果，这里预测的数据被绘制成红点，如第三行中的“ro”所示。 下图中的蓝线表示真实值（实际价格数据），而红点表示预测的比特币价格。 使用2层CNN模型预测的最佳比特币价格 从上图可以看出，预测价格与比特币的实际价格是非常相似的。 为了得到最佳模型效果，我决定测试集中配置下的神经网络，如下表所示。 不同模型下的预测结果 上表中的每一行都是从100个训练周期中得到的最佳验证损失的模型。 从以上结果可以看出，LeakyReLU似乎总是比通常的ReLU产生更好的损失效果。 但是，使用Leaky ReLU作为激活函数的4层CNN模型会得到较大的验证损失值，这可能是由于重新验证的模型所导致的问题。 CNN模型可以训练得非常快（使用GPU时，2秒/周期），在性能上要比LSTM和GRU稍差一点。 虽然3层CNN似乎可以更好地捕捉数据的局部时间依赖性，但最好的模型似乎是用 tanh和Leaky ReLU作为激活函数的LSTM模型。 用Tanh和Leaky ReLu作为激活函数的LSTM模型 用Leaky ReLu作为激活函数的3层CNN模型 虽然预测看起来都相当不错，但是过度拟合还是很值得留意的。 当用LeakyReLU训练LSTM时，训练损失和验证损失之间存在差距（5.97E-06 vs 3.92E-05），应该使用正则化来最小化这个差异。 正则化 为了找到最佳的正则化方案，我用L1和L2在不同的几个值中实验。 首先，我们需要定义一个新的函数来使得数据能够拟合到LSTM中。 在这里，我将使用在偏置正规化方法对偏差向量进行正则化。 通过重复训练模型30次，每次30个周期为标准进行实验。 如果你使用的是Jupyter notebook，则可以直接从输出数据中查看如下表格。 使用偏置正则化的结果 为了可视化比较，我们可以使用boxplot绘图： 通过比较可知，L2正则化中偏差向量的系数为0.01时可以似乎得到了最好的结果。 为了找出所有超参数正则化之间的最佳组合，包括激活，偏置，核窗口，循环矩阵等等，有必要逐一测试所有正则化方案，但这对我目前的硬件配置来说并不现实。 因此，我将搁置下来以后再议。 结论 从本文，你已经了解到： 如何收集时序的比特币数据。 如何使用深度学习技术预测比特币的价格。 如何可视化预测的结果。 如何在模型上应用正则化技术。 作者：黃功詳 Steeve Huang 原文链接: https://github.com/khuangaf 阅读更多" />
<link rel="canonical" href="https://mlh.app/2018/01/19/1e1a335b745f9cecb33ca289d819d5cb.html" />
<meta property="og:url" content="https://mlh.app/2018/01/19/1e1a335b745f9cecb33ca289d819d5cb.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-01-19T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"翻译 | AI科技大本营（rgznai100） 参与 | 王赫 编辑 | Donna 近年来，以比特币为代表的加密数字货币一直是社交媒体和搜索引擎上的热门。但是，比特币价格浮动也使各位看官们经历了过山车般的体验。 随着本周各大权威机构纷纷表示看好区块链的未来，从1月17日到18日凌晨，比特币成功止住前一日暴跌的颓势，涨幅接近20%（18.46%）。 如果我们能够智能化的制定投资策略的话，就能发现这些反复无常的波动背后潜藏着巨大的利润。 与传统金融工具相比，加密货币由于缺乏指标数据，预测变得非常困难。 本文以当下最火的比特币为例，来探讨如何用深度学习预测加密数字货币的价格，并了解它们未来的发展趋势。 免责声明：比特币等数字货币的交易属于投资行为。交易有风险，买币须谨慎。由此带来的收益和亏损，和营长无关。若要打赏，猛戳“转发”与“点赞”即可。 第一步 要运行本文中的代码，请确保已经安装了以下环境和代码库： Python 2.7 Tensorflow=1.2.0 Keras=2.1.1 Pandas=0.20.3 Numpy=1.13.3 h5py=2.7.0 sklearn=0.19.1 数据采集 用于分析预测的数据可以从Kaggle或者Poloniex上收集到。 为确保在不同数据集之间代码适用的一致性，从Poloniex上收集数据的列名都会更改为与Kaggle相匹配的列名。 数据准备 从数据源收集而来的数据需要先被解析一下才能送到模型中进行预测。下面代码中，PastSampler类是参考这个博客上的方法将数据分成一列子数据集和相应的标签数据集。模型输入数据大小（N）为256个，输出大小（K）为16个。 值得注意的是，从Poloniex收集来的数据是以5分钟为基础间隔时序数据。 这表明输入模型的数据跨度为1280分钟，而输出的数据跨度超过了80分钟。 在创建完PastSampler类之后，我将利用此类来收集数据。 由于原始数据的取值范围从0到10000以上，因此需要对数据进行缩放操作来使神经网络更容易理解数据。 模型构建 CNN 一维卷积神经网络可以通过核窗口在输入数据上滑动的情况下很好地捕捉数据的局部特征。 如下图所示。 CNN 图例 来自 http://cs231n.github.io/convolutional-networks/ 上述代码是我建立的第一个卷积神经网络模型。 以下代码将我的GPU编号为“1”（这是因为我有4个GPU，您可以将其设置为您任何一个GPU）。 由于Tensorflow在多GPU上运行似乎不尽人意，因此把它限制在一个GPU上运行很合适的。 如果您没有GPU也请不要担心，尽管忽略下面的代码就好。 构建CNN模型的代码是非常简单的。加入dropout层是为了避免过拟合问题。 损失函数的定义为均方误差（MSE），而优化器选用最先进的Adam自适应优化。 唯一需要担心的是每层之间的输入数据和输出数据的维度。 计算某个卷积层输出数据维度的公式是： 输出时间步长=（输入时间步长 - 核窗口大小）/步幅+ 1 在下面代码的末尾，我添加了两个回调函数CSVLogger和ModelCheckpoint。 前者可以帮助我跟踪所有的训练和验证过程，而后者则可以存储每个周期的模型权重参数。 LSTM 长期短期记忆（LSTM）网络是递归神经网络（RNN）的一种变体，发明它的目的是为了解决在普通RNN中存在的梯度消失问题。 据称LSTM能够记住更长的时序输入步长。 LSTM 图例 (来自 http://colah.github.io/posts/2015-08-Understanding-LSTMs/&gt;) LSTM比CNN更容易通过代码实现，这是因为你根本不需要关心核窗口的大小，步长，输入和输出的数据维度大小之间的关系等。 只需要确保输入网络数据和输出网络的数据维度就可以了。 GRU 门控循环单元（GRU）是RNN的另一种变体。 它的网络结构不如LSTM那么复杂，只有一个复位门和忘记门，而不是记忆单元。 据称GRU的性能与LSTM是相当的，但效率可以更高。 （在本文中也是如此的，因为LSTM大约需要跑45秒/周期，而GRU则不到40秒/周期） 来自http://www.jackdermody.net/brightwire/article/GRU_Recurrent_Neural_Networks) 只需将LSTM模型中的第二行 替换为 绘图结果 由于三个模型的计算结果图像很相似，所以我只会查看CNN模型的图像。 首先，我们需要重建模型并将训练权重加载到模型中。 然后，我们需要对预测后的数据进行反向缩放，因为之前使用了MinMaxScaler，因此此时预测的数据范围是在[0,1]。 如上所示的两个Dataframes分别构造了真实值（实际价格）以及比特币的预测价格。 为了更好的可视化，绘制的图像只显示了2017年8月之后的数据。 我们使用pyplot绘制图形。 由于预测出的价格是以16分钟为间隔的，所以为了让我们更方便的查看结果，我就不把它们全部链接起来了。 结果，这里预测的数据被绘制成红点，如第三行中的“ro”所示。 下图中的蓝线表示真实值（实际价格数据），而红点表示预测的比特币价格。 使用2层CNN模型预测的最佳比特币价格 从上图可以看出，预测价格与比特币的实际价格是非常相似的。 为了得到最佳模型效果，我决定测试集中配置下的神经网络，如下表所示。 不同模型下的预测结果 上表中的每一行都是从100个训练周期中得到的最佳验证损失的模型。 从以上结果可以看出，LeakyReLU似乎总是比通常的ReLU产生更好的损失效果。 但是，使用Leaky ReLU作为激活函数的4层CNN模型会得到较大的验证损失值，这可能是由于重新验证的模型所导致的问题。 CNN模型可以训练得非常快（使用GPU时，2秒/周期），在性能上要比LSTM和GRU稍差一点。 虽然3层CNN似乎可以更好地捕捉数据的局部时间依赖性，但最好的模型似乎是用 tanh和Leaky ReLU作为激活函数的LSTM模型。 用Tanh和Leaky ReLu作为激活函数的LSTM模型 用Leaky ReLu作为激活函数的3层CNN模型 虽然预测看起来都相当不错，但是过度拟合还是很值得留意的。 当用LeakyReLU训练LSTM时，训练损失和验证损失之间存在差距（5.97E-06 vs 3.92E-05），应该使用正则化来最小化这个差异。 正则化 为了找到最佳的正则化方案，我用L1和L2在不同的几个值中实验。 首先，我们需要定义一个新的函数来使得数据能够拟合到LSTM中。 在这里，我将使用在偏置正规化方法对偏差向量进行正则化。 通过重复训练模型30次，每次30个周期为标准进行实验。 如果你使用的是Jupyter notebook，则可以直接从输出数据中查看如下表格。 使用偏置正则化的结果 为了可视化比较，我们可以使用boxplot绘图： 通过比较可知，L2正则化中偏差向量的系数为0.01时可以似乎得到了最好的结果。 为了找出所有超参数正则化之间的最佳组合，包括激活，偏置，核窗口，循环矩阵等等，有必要逐一测试所有正则化方案，但这对我目前的硬件配置来说并不现实。 因此，我将搁置下来以后再议。 结论 从本文，你已经了解到： 如何收集时序的比特币数据。 如何使用深度学习技术预测比特币的价格。 如何可视化预测的结果。 如何在模型上应用正则化技术。 作者：黃功詳 Steeve Huang 原文链接: https://github.com/khuangaf 阅读更多","@type":"BlogPosting","url":"https://mlh.app/2018/01/19/1e1a335b745f9cecb33ca289d819d5cb.html","headline":"如何一夜暴富？这里有一份比特币价格预测指南","dateModified":"2018-01-19T00:00:00+08:00","datePublished":"2018-01-19T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2018/01/19/1e1a335b745f9cecb33ca289d819d5cb.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>如何一夜暴富？这里有一份比特币价格预测指南</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="markdown_views"> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119140452962?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>翻译 | AI科技大本营（rgznai100） <br> 参与 | 王赫 <br> 编辑 | Donna</p> 
  <p>近年来，以比特币为代表的加密数字货币一直是社交媒体和搜索引擎上的热门。但是，比特币价格浮动也使各位看官们经历了过山车般的体验。</p> 
  <p>随着本周各大权威机构纷纷表示看好区块链的未来，从1月17日到18日凌晨，比特币成功止住前一日暴跌的颓势，涨幅接近20%（18.46%）。</p> 
  <p>如果我们能够智能化的制定投资策略的话，就能发现这些反复无常的波动背后潜藏着巨大的利润。</p> 
  <p>与传统金融工具相比，加密货币由于缺乏指标数据，预测变得非常困难。 本文以当下最火的比特币为例，来探讨如何用深度学习预测加密数字货币的价格，并了解它们未来的发展趋势。</p> 
  <p>免责声明：比特币等数字货币的交易属于投资行为。交易有风险，买币须谨慎。由此带来的收益和亏损，和营长无关。若要打赏，猛戳“转发”与“点赞”即可。</p> 
  <h3 id="第一步">第一步</h3> 
  <p>要运行本文中的代码，请确保已经安装了以下环境和代码库：</p> 
  <pre class="prettyprint"><code class=" hljs makefile">
Python 2.7
<span class="hljs-constant">Tensorflow</span>=1.2.0
<span class="hljs-constant">Keras</span>=2.1.1
<span class="hljs-constant">Pandas</span>=0.20.3
<span class="hljs-constant">Numpy</span>=1.13.3
<span class="hljs-constant">h5py</span>=2.7.0
<span class="hljs-constant">sklearn</span>=0.19.1</code></pre> 
  <h3 id="数据采集">数据采集</h3> 
  <p>用于分析预测的数据可以从Kaggle或者Poloniex上收集到。 为确保在不同数据集之间代码适用的一致性，从Poloniex上收集数据的列名都会更改为与Kaggle相匹配的列名。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119140937633?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <h3 id="数据准备">数据准备</h3> 
  <p>从数据源收集而来的数据需要先被解析一下才能送到模型中进行预测。下面代码中，PastSampler类是参考这个博客上的方法将数据分成一列子数据集和相应的标签数据集。模型输入数据大小（N）为256个，输出大小（K）为16个。</p> 
  <p>值得注意的是，从Poloniex收集来的数据是以5分钟为基础间隔时序数据。 这表明输入模型的数据跨度为1280分钟，而输出的数据跨度超过了80分钟。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141003902?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>在创建完PastSampler类之后，我将利用此类来收集数据。 由于原始数据的取值范围从0到10000以上，因此需要对数据进行缩放操作来使神经网络更容易理解数据。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141011285?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <h3 id="模型构建">模型构建</h3> 
  <p><strong>CNN</strong></p> 
  <p>一维卷积神经网络可以通过核窗口在输入数据上滑动的情况下很好地捕捉数据的局部特征。 如下图所示。 <br> <img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141112881?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>CNN 图例 来自 <a href="http://cs231n.github.io/convolutional-networks/" rel="nofollow" target="_blank">http://cs231n.github.io/convolutional-networks/</a></p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141142838?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>上述代码是我建立的第一个卷积神经网络模型。 以下代码将我的GPU编号为“1”（这是因为我有4个GPU，您可以将其设置为您任何一个GPU）。 由于Tensorflow在多GPU上运行似乎不尽人意，因此把它限制在一个GPU上运行很合适的。 如果您没有GPU也请不要担心，尽管忽略下面的代码就好。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141312700?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>构建CNN模型的代码是非常简单的。加入dropout层是为了避免过拟合问题。 损失函数的定义为均方误差（MSE），而优化器选用最先进的Adam自适应优化。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141324604?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>唯一需要担心的是每层之间的输入数据和输出数据的维度。 计算某个卷积层输出数据维度的公式是：</p> 
  <p>输出时间步长=（输入时间步长 - 核窗口大小）/步幅+ 1</p> 
  <p>在下面代码的末尾，我添加了两个回调函数CSVLogger和ModelCheckpoint。 前者可以帮助我跟踪所有的训练和验证过程，而后者则可以存储每个周期的模型权重参数。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141341997?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p><strong>LSTM</strong></p> 
  <p>长期短期记忆（LSTM）网络是递归神经网络（RNN）的一种变体，发明它的目的是为了解决在普通RNN中存在的梯度消失问题。 据称LSTM能够记住更长的时序输入步长。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141407658?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br> LSTM 图例 (来自 <a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" rel="nofollow" target="_blank">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</a>&gt;)</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141507901?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br> LSTM比CNN更容易通过代码实现，这是因为你根本不需要关心核窗口的大小，步长，输入和输出的数据维度大小之间的关系等。 只需要确保输入网络数据和输出网络的数据维度就可以了。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141546208?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p><strong>GRU</strong></p> 
  <p>门控循环单元（GRU）是RNN的另一种变体。 它的网络结构不如LSTM那么复杂，只有一个复位门和忘记门，而不是记忆单元。 据称GRU的性能与LSTM是相当的，但效率可以更高。 （在本文中也是如此的，因为LSTM大约需要跑45秒/周期，而GRU则不到40秒/周期）</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141555191?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br> 来自<a href="http://www.jackdermody.net/brightwire/article/GRU_Recurrent_Neural_Networks" rel="nofollow" target="_blank">http://www.jackdermody.net/brightwire/article/GRU_Recurrent_Neural_Networks</a>) <br> <img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141708618?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>只需将LSTM模型中的第二行</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141718153?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>替换为 <br> <img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141751125?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <h3 id="绘图结果">绘图结果</h3> 
  <p>由于三个模型的计算结果图像很相似，所以我只会查看CNN模型的图像。 首先，我们需要重建模型并将训练权重加载到模型中。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141832422?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>然后，我们需要对预测后的数据进行反向缩放，因为之前使用了MinMaxScaler，因此此时预测的数据范围是在[0,1]。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141909985?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>如上所示的两个Dataframes分别构造了真实值（实际价格）以及比特币的预测价格。 为了更好的可视化，绘制的图像只显示了2017年8月之后的数据。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119141954816?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>我们使用pyplot绘制图形。 由于预测出的价格是以16分钟为间隔的，所以为了让我们更方便的查看结果，我就不把它们全部链接起来了。 结果，这里预测的数据被绘制成红点，如第三行中的“ro”所示。</p> 
  <p>下图中的蓝线表示真实值（实际价格数据），而红点表示预测的比特币价格。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142016794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <h3 id="使用2层cnn模型预测的最佳比特币价格">使用2层CNN模型预测的最佳比特币价格</h3> 
  <p>从上图可以看出，预测价格与比特币的实际价格是非常相似的。 为了得到最佳模型效果，我决定测试集中配置下的神经网络，如下表所示。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142053705?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>不同模型下的预测结果</p> 
  <p>上表中的每一行都是从100个训练周期中得到的最佳验证损失的模型。 从以上结果可以看出，LeakyReLU似乎总是比通常的ReLU产生更好的损失效果。 但是，使用Leaky ReLU作为激活函数的4层CNN模型会得到较大的验证损失值，这可能是由于重新验证的模型所导致的问题。 CNN模型可以训练得非常快（使用GPU时，2秒/周期），在性能上要比LSTM和GRU稍差一点。 虽然3层CNN似乎可以更好地捕捉数据的局部时间依赖性，但最好的模型似乎是用 tanh和Leaky ReLU作为激活函数的LSTM模型。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142242844?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br> 用Tanh和Leaky ReLu作为激活函数的LSTM模型</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142346863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> <br> 用Leaky ReLu作为激活函数的3层CNN模型</p> 
  <p>虽然预测看起来都相当不错，但是过度拟合还是很值得留意的。 当用LeakyReLU训练LSTM时，训练损失和验证损失之间存在差距（5.97E-06 vs 3.92E-05），应该使用正则化来最小化这个差异。</p> 
  <h3 id="正则化">正则化</h3> 
  <p>为了找到最佳的正则化方案，我用L1和L2在不同的几个值中实验。 首先，我们需要定义一个新的函数来使得数据能够拟合到LSTM中。 在这里，我将使用在偏置正规化方法对偏差向量进行正则化。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142503339?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>通过重复训练模型30次，每次30个周期为标准进行实验。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142625000?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>如果你使用的是Jupyter notebook，则可以直接从输出数据中查看如下表格。</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142717510?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>使用偏置正则化的结果 <br> <img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142804299?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>为了可视化比较，我们可以使用boxplot绘图：</p> 
  <p><img src="https://blog.uzzz.org/_p?https://img-blog.csdn.net/20180119142811923?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvZFFDRkt5UURYWW0zRjhyQjA=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""></p> 
  <p>通过比较可知，L2正则化中偏差向量的系数为0.01时可以似乎得到了最好的结果。</p> 
  <p>为了找出所有超参数正则化之间的最佳组合，包括激活，偏置，核窗口，循环矩阵等等，有必要逐一测试所有正则化方案，但这对我目前的硬件配置来说并不现实。 因此，我将搁置下来以后再议。</p> 
  <h3 id="结论">结论</h3> 
  <p>从本文，你已经了解到：</p> 
  <ul> 
   <li>如何收集时序的比特币数据。 </li> 
   <li>如何使用深度学习技术预测比特币的价格。 </li> 
   <li>如何可视化预测的结果。</li> 
   <li>如何在模型上应用正则化技术。</li> 
  </ul> 
  <p>作者：黃功詳 Steeve Huang <br> 原文链接: <a href="https://github.com/khuangaf" rel="nofollow" target="_blank">https://github.com/khuangaf</a></p> 
 </div> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/markdown_views-ea0013b516.css"> 
</div> 
<div class="hide-article-box text-center"> 
 <a class="btn btn-red-hollow" id="btn-readmore" data-track-view="{&quot;mod&quot;:&quot;popu_376&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/79106387,&quot;}" data-track-click="{&quot;mod&quot;:&quot;popu_376&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/79106387,&quot;}">阅读更多</a> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
