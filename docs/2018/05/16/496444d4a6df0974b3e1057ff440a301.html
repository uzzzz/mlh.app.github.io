<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>LevelDB介绍-随笔 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="LevelDB介绍-随笔" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="最近在看区块链代码的时候对LevelDB有点兴趣，所以了解了一下，这篇文章写的挺好的，可以看看 https://blog.csdn.net/linuxheik/article/details/52768223 刚刚看到这篇文章，介绍的比上一篇详细： https://blog.csdn.net/charles1e/article/details/52966776 LevelDB是google开源的KV（key-value，存储的数据都是kv的形式）单机数据库，官方版本是C++，比特币使用的是c++版本： &nbsp; &nbsp; https://github.com/google/leveldb 以太坊使用的是go语言版本： &nbsp; &nbsp; https://github.com/syndtr/goleveldb 性能方面：号称顺序写、随机写速度快，顺序读快，随机读性能一般， 所以想了解下为什么性能是这样的。读了上面的博客和其他一些文章，大致有了答案。 LevelDB写数据的流程，写数据的时候依次写入 1 Log文件（用来系统崩溃后恢复数据，防止丢失数据），存储的数据是Key无序的，写入的时候顺序写入 2 memtable文件（内存，使用Skiplist实现），Key有序 当memtable满足一定条件（写满了之后，默认是4M大小，以太坊设置的是192M）改变为immutable memtable同时触发执行minor compaction（leveldb实现了minor compaction和major compaction）写文件到level 0的文件（Key有序，但是不同的level 0文件可能存在key重叠，level 0 之上的level 1...N不会存在key重叠） 有另外一个线程监测是否需要major compaction，当level i（0-N)的文件满足一定条件（会计算一个score，level 0达到4个文件限制、level 0以上根据文件的总大小）会触发major compaction，选出level i的某个文件与level i+1的某些文件进行合并生成新的level i+1文件（这里有几个问题待回答： 1 是合并成一个level i+1的文件还是根据文件大小限制切分成几个文件 2 。。。怎么忽然忘记了什么问题） 每层文件的数据量大小限制是上一层文件的10倍，这种分层的结构也是leveldb的由来 所以我们知道了顺序写和随机写为什么性能高了： 因为随机写和顺序写是一样的，都只是顺序写入log文件和memtable，所以性能就是写log文件的性能， 因为写log文件对磁盘来说是顺序写入，所以性能还是很高的。 LevelDB的读数据流程，读数据的时候依次查询： 1 memtable和immutable memtable 2 cache（有table cache和block cache） 3 根据bloom filter依次从level 0开始查找（bloom filter怎么使用的需要再看下代码，是每个db文件查还是每个level的db一起查） 4 如果是从level中查找到了，会将block读入cache供后续读取 所以我们也知道了为什么顺序读性能高，随机读性能一般 顺序读的时候除了第一次需要查找到key的位置，后续读的时候依赖于key有序和cache，读取性能很高 但是随机读需要每次都查找然后从磁盘中读取数据，所以性能相对一般 答案有了，下一步是看代码查看具体实现 可查看这篇文章： https://blog.csdn.net/csds319/article/details/80361450 阅读更多" />
<meta property="og:description" content="最近在看区块链代码的时候对LevelDB有点兴趣，所以了解了一下，这篇文章写的挺好的，可以看看 https://blog.csdn.net/linuxheik/article/details/52768223 刚刚看到这篇文章，介绍的比上一篇详细： https://blog.csdn.net/charles1e/article/details/52966776 LevelDB是google开源的KV（key-value，存储的数据都是kv的形式）单机数据库，官方版本是C++，比特币使用的是c++版本： &nbsp; &nbsp; https://github.com/google/leveldb 以太坊使用的是go语言版本： &nbsp; &nbsp; https://github.com/syndtr/goleveldb 性能方面：号称顺序写、随机写速度快，顺序读快，随机读性能一般， 所以想了解下为什么性能是这样的。读了上面的博客和其他一些文章，大致有了答案。 LevelDB写数据的流程，写数据的时候依次写入 1 Log文件（用来系统崩溃后恢复数据，防止丢失数据），存储的数据是Key无序的，写入的时候顺序写入 2 memtable文件（内存，使用Skiplist实现），Key有序 当memtable满足一定条件（写满了之后，默认是4M大小，以太坊设置的是192M）改变为immutable memtable同时触发执行minor compaction（leveldb实现了minor compaction和major compaction）写文件到level 0的文件（Key有序，但是不同的level 0文件可能存在key重叠，level 0 之上的level 1...N不会存在key重叠） 有另外一个线程监测是否需要major compaction，当level i（0-N)的文件满足一定条件（会计算一个score，level 0达到4个文件限制、level 0以上根据文件的总大小）会触发major compaction，选出level i的某个文件与level i+1的某些文件进行合并生成新的level i+1文件（这里有几个问题待回答： 1 是合并成一个level i+1的文件还是根据文件大小限制切分成几个文件 2 。。。怎么忽然忘记了什么问题） 每层文件的数据量大小限制是上一层文件的10倍，这种分层的结构也是leveldb的由来 所以我们知道了顺序写和随机写为什么性能高了： 因为随机写和顺序写是一样的，都只是顺序写入log文件和memtable，所以性能就是写log文件的性能， 因为写log文件对磁盘来说是顺序写入，所以性能还是很高的。 LevelDB的读数据流程，读数据的时候依次查询： 1 memtable和immutable memtable 2 cache（有table cache和block cache） 3 根据bloom filter依次从level 0开始查找（bloom filter怎么使用的需要再看下代码，是每个db文件查还是每个level的db一起查） 4 如果是从level中查找到了，会将block读入cache供后续读取 所以我们也知道了为什么顺序读性能高，随机读性能一般 顺序读的时候除了第一次需要查找到key的位置，后续读的时候依赖于key有序和cache，读取性能很高 但是随机读需要每次都查找然后从磁盘中读取数据，所以性能相对一般 答案有了，下一步是看代码查看具体实现 可查看这篇文章： https://blog.csdn.net/csds319/article/details/80361450 阅读更多" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-05-16T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"最近在看区块链代码的时候对LevelDB有点兴趣，所以了解了一下，这篇文章写的挺好的，可以看看 https://blog.csdn.net/linuxheik/article/details/52768223 刚刚看到这篇文章，介绍的比上一篇详细： https://blog.csdn.net/charles1e/article/details/52966776 LevelDB是google开源的KV（key-value，存储的数据都是kv的形式）单机数据库，官方版本是C++，比特币使用的是c++版本： &nbsp; &nbsp; https://github.com/google/leveldb 以太坊使用的是go语言版本： &nbsp; &nbsp; https://github.com/syndtr/goleveldb 性能方面：号称顺序写、随机写速度快，顺序读快，随机读性能一般， 所以想了解下为什么性能是这样的。读了上面的博客和其他一些文章，大致有了答案。 LevelDB写数据的流程，写数据的时候依次写入 1 Log文件（用来系统崩溃后恢复数据，防止丢失数据），存储的数据是Key无序的，写入的时候顺序写入 2 memtable文件（内存，使用Skiplist实现），Key有序 当memtable满足一定条件（写满了之后，默认是4M大小，以太坊设置的是192M）改变为immutable memtable同时触发执行minor compaction（leveldb实现了minor compaction和major compaction）写文件到level 0的文件（Key有序，但是不同的level 0文件可能存在key重叠，level 0 之上的level 1...N不会存在key重叠） 有另外一个线程监测是否需要major compaction，当level i（0-N)的文件满足一定条件（会计算一个score，level 0达到4个文件限制、level 0以上根据文件的总大小）会触发major compaction，选出level i的某个文件与level i+1的某些文件进行合并生成新的level i+1文件（这里有几个问题待回答： 1 是合并成一个level i+1的文件还是根据文件大小限制切分成几个文件 2 。。。怎么忽然忘记了什么问题） 每层文件的数据量大小限制是上一层文件的10倍，这种分层的结构也是leveldb的由来 所以我们知道了顺序写和随机写为什么性能高了： 因为随机写和顺序写是一样的，都只是顺序写入log文件和memtable，所以性能就是写log文件的性能， 因为写log文件对磁盘来说是顺序写入，所以性能还是很高的。 LevelDB的读数据流程，读数据的时候依次查询： 1 memtable和immutable memtable 2 cache（有table cache和block cache） 3 根据bloom filter依次从level 0开始查找（bloom filter怎么使用的需要再看下代码，是每个db文件查还是每个level的db一起查） 4 如果是从level中查找到了，会将block读入cache供后续读取 所以我们也知道了为什么顺序读性能高，随机读性能一般 顺序读的时候除了第一次需要查找到key的位置，后续读的时候依赖于key有序和cache，读取性能很高 但是随机读需要每次都查找然后从磁盘中读取数据，所以性能相对一般 答案有了，下一步是看代码查看具体实现 可查看这篇文章： https://blog.csdn.net/csds319/article/details/80361450 阅读更多","@type":"BlogPosting","url":"/2018/05/16/496444d4a6df0974b3e1057ff440a301.html","headline":"LevelDB介绍-随笔","dateModified":"2018-05-16T00:00:00+08:00","datePublished":"2018-05-16T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2018/05/16/496444d4a6df0974b3e1057ff440a301.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>LevelDB介绍-随笔</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-e2445db1a8.css"> 
 <div class="htmledit_views">
   最近在看区块链代码的时候对LevelDB有点兴趣，所以了解了一下，这篇文章写的挺好的，可以看看
  <br>
  <p>https://blog.csdn.net/linuxheik/article/details/52768223</p>
  <p>刚刚看到这篇文章，介绍的比上一篇详细：</p>
  <p>https://blog.csdn.net/charles1e/article/details/52966776<br></p>
  <p>LevelDB是google开源的KV（key-value，存储的数据都是kv的形式）单机数据库，官方版本是C++，比特币使用的是c++版本：</p>
  <p>&nbsp; &nbsp; https://github.com/google/leveldb<br></p>
  <p>以太坊使用的是go语言版本：</p>
  <p>&nbsp; &nbsp; https://github.com/syndtr/goleveldb<br></p>
  <p>性能方面：号称顺序写、随机写速度快，顺序读快，随机读性能一般，</p>
  <p>所以想了解下为什么性能是这样的。读了上面的博客和其他一些文章，大致有了答案。</p>
  <h3><strong>LevelDB写数据的流程，写数据的时候依次写入</strong></h3>
  <p>1 Log文件（用来系统崩溃后恢复数据，防止丢失数据），存储的数据是Key无序的，写入的时候顺序写入</p>
  <p>2 memtable文件（内存，使用Skiplist实现），Key有序</p>
  <p>当memtable满足一定条件（写满了之后，默认是4M大小，以太坊设置的是192M）改变为immutable memtable同时触发执行minor compaction（leveldb实现了minor compaction和major compaction）写文件到level 0的文件（Key有序，但是不同的level 0文件可能存在key重叠，level 0 之上的level 1...N不会存在key重叠）</p>
  <p>有另外一个线程监测是否需要major compaction，当level i（0-N)的文件满足一定条件（会计算一个score，level 0达到4个文件限制、level 0以上根据文件的总大小）会触发major compaction，选出level i的某个文件与level i+1的某些文件进行合并生成新的level i+1文件（这里有几个问题待回答：</p>
  <p>1 是合并成一个level i+1的文件还是根据文件大小限制切分成几个文件</p>
  <p>2 。。。怎么忽然忘记了什么问题）</p>
  <p>每层文件的数据量大小限制是上一层文件的10倍，这种分层的结构也是leveldb的由来</p>
  <h5>所以我们知道了顺序写和随机写为什么性能高了：</h5>
  <p>因为随机写和顺序写是一样的，都只是顺序写入log文件和memtable，所以性能就是写log文件的性能，</p>
  <p>因为写log文件对磁盘来说是顺序写入，所以性能还是很高的。</p>
  <p><br></p>
  <h3>LevelDB的读数据流程，读数据的时候依次查询：</h3>
  <p>1 memtable和immutable memtable</p>
  <p>2 cache（有table cache和block cache）</p>
  <p>3 根据bloom filter依次从level 0开始查找（bloom filter怎么使用的需要再看下代码，是每个db文件查还是每个level的db一起查）</p>
  <p>4 如果是从level中查找到了，会将block读入cache供后续读取</p>
  <h5>所以我们也知道了为什么顺序读性能高，随机读性能一般</h5>
  <p>顺序读的时候除了第一次需要查找到key的位置，后续读的时候依赖于key有序和cache，读取性能很高</p>
  <p>但是随机读需要每次都查找然后从磁盘中读取数据，所以性能相对一般</p>
  <p>答案有了，下一步是看代码查看具体实现</p>
  <p>可查看这篇文章：</p>
  <p>https://blog.csdn.net/csds319/article/details/80361450<br></p>
  <p><br></p>
  <p><br></p>
  <p><br></p> 
 </div> 
</div> 
<div class="hide-article-box text-center"> 
 <a class="btn btn-red-hollow" id="btn-readmore" data-track-view="{&quot;mod&quot;:&quot;popu_376&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/csds319/article/details/80333187,&quot;}" data-track-click="{&quot;mod&quot;:&quot;popu_376&quot;,&quot;con&quot;:&quot;,https://blog.csdn.net/csds319/article/details/80333187,&quot;}">阅读更多</a> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
