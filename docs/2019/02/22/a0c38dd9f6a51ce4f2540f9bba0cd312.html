<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>语音识别CTC模型的output delay问题及其解决办法 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="语音识别CTC模型的output delay问题及其解决办法" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="本篇博客主要是参考谷歌2015年的一篇文章《ACOUSTIC MODELLING WITH CD-CTC-SMBR LSTM RNNS》。 什么叫output delay(输出延迟) 在训练传统的HMM-DNN声学模型时，为了利用上下文信息，我们通常会做拼帧的操作，也就是除了考虑当前帧，还会考虑前面的N帧，未来的M帧。因为我们要等到未来的M帧说完才能输出当前帧的预测值，就会有输出延迟。比如考虑未来的5帧，帧移是10ms，那么输出延迟就是50ms。 CTC也会产生输出延迟，但它的延迟时间是不确定的。为什么会产生不确定的输出延迟呢？论文原话是： With CTC, there is no time alignment supervision since the network is constantly integrating over all possible alignments. This means that the LSTM can vary the delay between acoustics and outputs, using an arbitrarily large future context if that helps optimizing the total sequence probability。 个人理解：因为训练CTC的时候我们不需要每一帧都要输出某个确定的label(比如可以输出blank)。也就是说不需要强制对齐，只要对最大化目标函数有利，延迟可以是任意的。 这种不确定的延迟如下图所示： 首先解释下这张图： 横坐标下的区间表示用DNN进行强制对齐的结果。比如我在下图手动画的两红竖，表示在这个区间内对应的输出应该是m。 图中的尖峰表示CTC的输出结果。从图中可以看出，第一个m的输出(从左开始的第一个蓝色尖峰)比实际(DNN的对齐结果)延迟了25ms。 解决方法 输出延迟会影响我们的解码速度，所以需要对延迟做限制。具体怎么做呢，论文原话是： Delay can be limited by restricting the set of search paths used in the forward-backward algorithm to those in which the delay between CTC labels and the “ground truth” alignment does not exceed some threshold。 个人理解：就是以对齐的label作为标准，在前后向变量计算的过程中只选择延时在一定范围内的路径。比如我们限制输出延迟在60ms以内，当前帧的对齐label是m，那么前后向计算的时候我们就不会考虑&lt;b&gt;, &lt;b&gt;,&lt;b&gt;,&lt;b&gt;,&lt;b&gt;,&lt;b&gt;,m这样的路径，因为m出现在了当前帧往后的第7帧，超过了60ms的时间限制。(这里&lt;b&gt;表示blank) 那么限制延迟时间会对wer产生什么样的影响呢，作者做了下面几组实验： 实验结果如下图第二列所示，基本上限制得越狠，wer下降得越多。但加上区分性训练准则sMBR之后，这种影响几乎可以消除了(如红圈所示)：" />
<meta property="og:description" content="本篇博客主要是参考谷歌2015年的一篇文章《ACOUSTIC MODELLING WITH CD-CTC-SMBR LSTM RNNS》。 什么叫output delay(输出延迟) 在训练传统的HMM-DNN声学模型时，为了利用上下文信息，我们通常会做拼帧的操作，也就是除了考虑当前帧，还会考虑前面的N帧，未来的M帧。因为我们要等到未来的M帧说完才能输出当前帧的预测值，就会有输出延迟。比如考虑未来的5帧，帧移是10ms，那么输出延迟就是50ms。 CTC也会产生输出延迟，但它的延迟时间是不确定的。为什么会产生不确定的输出延迟呢？论文原话是： With CTC, there is no time alignment supervision since the network is constantly integrating over all possible alignments. This means that the LSTM can vary the delay between acoustics and outputs, using an arbitrarily large future context if that helps optimizing the total sequence probability。 个人理解：因为训练CTC的时候我们不需要每一帧都要输出某个确定的label(比如可以输出blank)。也就是说不需要强制对齐，只要对最大化目标函数有利，延迟可以是任意的。 这种不确定的延迟如下图所示： 首先解释下这张图： 横坐标下的区间表示用DNN进行强制对齐的结果。比如我在下图手动画的两红竖，表示在这个区间内对应的输出应该是m。 图中的尖峰表示CTC的输出结果。从图中可以看出，第一个m的输出(从左开始的第一个蓝色尖峰)比实际(DNN的对齐结果)延迟了25ms。 解决方法 输出延迟会影响我们的解码速度，所以需要对延迟做限制。具体怎么做呢，论文原话是： Delay can be limited by restricting the set of search paths used in the forward-backward algorithm to those in which the delay between CTC labels and the “ground truth” alignment does not exceed some threshold。 个人理解：就是以对齐的label作为标准，在前后向变量计算的过程中只选择延时在一定范围内的路径。比如我们限制输出延迟在60ms以内，当前帧的对齐label是m，那么前后向计算的时候我们就不会考虑&lt;b&gt;, &lt;b&gt;,&lt;b&gt;,&lt;b&gt;,&lt;b&gt;,&lt;b&gt;,m这样的路径，因为m出现在了当前帧往后的第7帧，超过了60ms的时间限制。(这里&lt;b&gt;表示blank) 那么限制延迟时间会对wer产生什么样的影响呢，作者做了下面几组实验： 实验结果如下图第二列所示，基本上限制得越狠，wer下降得越多。但加上区分性训练准则sMBR之后，这种影响几乎可以消除了(如红圈所示)：" />
<link rel="canonical" href="https://mlh.app/2019/02/22/a0c38dd9f6a51ce4f2540f9bba0cd312.html" />
<meta property="og:url" content="https://mlh.app/2019/02/22/a0c38dd9f6a51ce4f2540f9bba0cd312.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-22T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"本篇博客主要是参考谷歌2015年的一篇文章《ACOUSTIC MODELLING WITH CD-CTC-SMBR LSTM RNNS》。 什么叫output delay(输出延迟) 在训练传统的HMM-DNN声学模型时，为了利用上下文信息，我们通常会做拼帧的操作，也就是除了考虑当前帧，还会考虑前面的N帧，未来的M帧。因为我们要等到未来的M帧说完才能输出当前帧的预测值，就会有输出延迟。比如考虑未来的5帧，帧移是10ms，那么输出延迟就是50ms。 CTC也会产生输出延迟，但它的延迟时间是不确定的。为什么会产生不确定的输出延迟呢？论文原话是： With CTC, there is no time alignment supervision since the network is constantly integrating over all possible alignments. This means that the LSTM can vary the delay between acoustics and outputs, using an arbitrarily large future context if that helps optimizing the total sequence probability。 个人理解：因为训练CTC的时候我们不需要每一帧都要输出某个确定的label(比如可以输出blank)。也就是说不需要强制对齐，只要对最大化目标函数有利，延迟可以是任意的。 这种不确定的延迟如下图所示： 首先解释下这张图： 横坐标下的区间表示用DNN进行强制对齐的结果。比如我在下图手动画的两红竖，表示在这个区间内对应的输出应该是m。 图中的尖峰表示CTC的输出结果。从图中可以看出，第一个m的输出(从左开始的第一个蓝色尖峰)比实际(DNN的对齐结果)延迟了25ms。 解决方法 输出延迟会影响我们的解码速度，所以需要对延迟做限制。具体怎么做呢，论文原话是： Delay can be limited by restricting the set of search paths used in the forward-backward algorithm to those in which the delay between CTC labels and the “ground truth” alignment does not exceed some threshold。 个人理解：就是以对齐的label作为标准，在前后向变量计算的过程中只选择延时在一定范围内的路径。比如我们限制输出延迟在60ms以内，当前帧的对齐label是m，那么前后向计算的时候我们就不会考虑&lt;b&gt;, &lt;b&gt;,&lt;b&gt;,&lt;b&gt;,&lt;b&gt;,&lt;b&gt;,m这样的路径，因为m出现在了当前帧往后的第7帧，超过了60ms的时间限制。(这里&lt;b&gt;表示blank) 那么限制延迟时间会对wer产生什么样的影响呢，作者做了下面几组实验： 实验结果如下图第二列所示，基本上限制得越狠，wer下降得越多。但加上区分性训练准则sMBR之后，这种影响几乎可以消除了(如红圈所示)：","@type":"BlogPosting","url":"https://mlh.app/2019/02/22/a0c38dd9f6a51ce4f2540f9bba0cd312.html","headline":"语音识别CTC模型的output delay问题及其解决办法","dateModified":"2019-02-22T00:00:00+08:00","datePublished":"2019-02-22T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/02/22/a0c38dd9f6a51ce4f2540f9bba0cd312.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>语音识别CTC模型的output delay问题及其解决办法</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p>本篇博客主要是参考谷歌2015年的一篇文章《ACOUSTIC MODELLING WITH CD-CTC-SMBR LSTM RNNS》。</p> 
  <h4><a id="output_delay_2"></a>什么叫output delay(输出延迟)</h4> 
  <p>在训练<strong>传统的HMM-DNN声学模型</strong>时，为了利用上下文信息，我们通常会做拼帧的操作，也就是除了考虑当前帧，还会考虑前面的N帧，未来的M帧。因为我们要等到未来的M帧说完才能输出当前帧的预测值，就会有输出延迟。比如考虑未来的5帧，帧移是10ms，那么输出延迟就是50ms。<br> CTC也会产生输出延迟，<strong>但它的延迟时间是不确定的</strong>。为什么会产生不确定的输出延迟呢？论文原话是：</p> 
  <blockquote> 
   <p>With CTC, there is no time alignment supervision since the network is constantly integrating over all possible alignments. This means that the LSTM can vary the delay between acoustics and outputs, using an arbitrarily large future context if that helps optimizing the total sequence probability。</p> 
  </blockquote> 
  <p>个人理解：因为训练CTC的时候我们不需要每一帧都要输出某个确定的label(比如可以输出blank)。也就是说不需要强制对齐，只要对最大化目标函数有利，延迟可以是任意的。</p> 
  <p>这种不确定的延迟如下图所示：<br> 首先解释下这张图：</p> 
  <ul> 
   <li>横坐标下的区间表示用DNN进行强制对齐的结果。比如我在下图手动画的两红竖，表示在这个区间内对应的输出应该是m。</li> 
   <li>图中的尖峰表示CTC的输出结果。从图中可以看出，第一个m的输出(从左开始的第一个蓝色尖峰)比实际(DNN的对齐结果)延迟了25ms。<img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190224151935798.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FzcmdyZWVr,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li> 
  </ul> 
  <h4><a id="_16"></a>解决方法</h4> 
  <p>输出延迟会影响我们的解码速度，所以需要对延迟做限制。具体怎么做呢，论文原话是：</p> 
  <blockquote> 
   <p>Delay can be limited by restricting the set of search paths used in the forward-backward algorithm to those in which the delay between CTC labels and the “ground truth” alignment does not exceed some threshold。</p> 
  </blockquote> 
  <p>个人理解：就是以对齐的label作为标准，在前后向变量计算的过程中只选择延时在一定范围内的路径。比如我们限制输出延迟在60ms以内，当前帧的对齐label是m，那么前后向计算的时候我们就不会考虑&lt;b&gt;, &lt;b&gt;,&lt;b&gt;,&lt;b&gt;,&lt;b&gt;,&lt;b&gt;,m这样的路径，因为m出现在了当前帧往后的第7帧，超过了60ms的时间限制。(这里&lt;b&gt;表示blank)</p> 
  <p>那么限制延迟时间会对wer产生什么样的影响呢，作者做了下面几组实验：<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222201755591.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FzcmdyZWVr,size_16,color_FFFFFF,t_70" alt="Label posteriors estimated by CD-CTC LSTM RNN models trained with different delay constraints plotted against fixed DNN frame level alignments shown only for labels in the alignment on a held out utterance ‘museums in Chicago’.  refers to the blank label."><br> 实验结果如下图第二列所示，基本上限制得越狠，wer下降得越多。但加上<strong>区分性训练准则sMBR</strong>之后，这种影响几乎可以消除了(如红圈所示)：<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190224144206729.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2FzcmdyZWVr,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
