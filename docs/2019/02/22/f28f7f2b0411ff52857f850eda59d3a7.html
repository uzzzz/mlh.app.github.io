<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>TensorFlow-一种改进的inception-v3迁移学习(图文） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="TensorFlow-一种改进的inception-v3迁移学习(图文）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="本文是关于如何用谷歌提供的训练好的Inception-v3进行水果图片分类，涉及以下几个内容：下载inception-v3（谷歌训练好的模型）图片数据的下载图片数据的清洗将模型用于图片分类-------------------------------------------------------------------详解：【创建文件】 &nbsp;|--baidu_search.py &nbsp; &nbsp; #通过百度爬取图片 &nbsp;|--ulibs.py &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#用于存放数据清洗等功能函数 &nbsp;|--inception-v3.py &nbsp; &nbsp; &nbsp; # 模型训练函数 &nbsp;|--data/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #存放数据 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--model/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#存放已训练好的模型 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--fruit_photos/ &nbsp; #存放爬取的图片 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--tmp/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #存放临时文件【下载inception-v3】https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip解压后放在./data/model/目录下【下载水果图片】：通过关键字从百度爬取baidu_search.py:# -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Tue Feb 27 11:10:45 2018 @author: mc.meng &quot;&quot;&quot; import re, os import requests from urllib.request import urlretrieve def download1(url, filename, filepath): &nbsp; &nbsp; full_name = os.path.join(filepath, filename) &nbsp; &nbsp; if os.path.exists(full_name): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】文件已经存在：&quot;, full_name) &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; pic = requests.get(url, timeout=5) &nbsp; &nbsp; except: &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;【错误】当前图片无法下载&#39;) &nbsp; &nbsp; &nbsp; &nbsp; return &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; with open(filepath + &quot;/&quot; + filename, &#39;wb&#39;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wf.write(pic.content) &nbsp; &nbsp; except : &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】写入失败&quot;) def download2(url, filename, filepath): &nbsp; &nbsp; full_name = os.path.join(filepath, filename) &nbsp; &nbsp; if os.path.exists(full_name): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】文件已经存在：&quot;, full_name) &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; urlretrieve(url, full_name) &nbsp; &nbsp; except: &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;【错误】当前图片无法下载&#39;) def search(word=&quot;美女&quot;, local_path=&quot;./data/down/&quot;, page=None, keep_original_name=True): &nbsp; &nbsp; local_path += word &nbsp; &nbsp; os.makedirs(local_path, exist_ok=True) &nbsp; &nbsp; url = &#39;http://image.baidu.com/search/flip?tn=baiduimage&amp;ie=utf-8&amp;word={word}&amp;pn={pn}&amp;gsm={gsm:x}&amp;ct=&amp;ic=0&amp;lm=-1&amp;width=0&amp;height=0&#39;.format(word=word, pn=20 * page, gsm=40 + 20 * page) &nbsp; &nbsp; print(&quot;HHHC:0====&gt;page=%d,url=\&quot;%s\&quot;&quot; % (page,url)) &nbsp; &nbsp; html = requests.get(url).text &nbsp; &nbsp; pic_url = re.findall(&#39;&quot;objURL&quot;:&quot;(.*?)&quot;,&#39;, html, re.S) &nbsp; &nbsp; i = 0 &nbsp; &nbsp; for url in pic_url: &nbsp; &nbsp; &nbsp; &nbsp; print(url) &nbsp; &nbsp; &nbsp; &nbsp; i = i + 1 &nbsp; &nbsp; &nbsp; &nbsp; filename = os.path.split(url)[1].split(&#39;?&#39;)[0] &nbsp; &nbsp; &nbsp; &nbsp; filename_split = filename.split(&#39;.&#39;) &nbsp; &nbsp; &nbsp; &nbsp; if len(filename_split) != 2: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】文件名异常:&quot; + filename) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; #print(&quot;HHHA:0====&gt;&quot;, filename_split[1]) &nbsp; &nbsp; &nbsp; &nbsp; if filename_split[1] != &#39;jpg&#39; and filename_split[1] != &#39;JPG&#39; \ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; and filename_split[1] != &#39;png&#39; and filename_split[1] != &#39;PNG&#39;: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】类型异常:&quot; + filename) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; if not keep_original_name: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; filename = filename.split(&#39;.&#39;)[0].strip() + &quot;-&quot; + str(page) + &quot;-&quot; + str(i) + &quot;.&quot; + filename.split(&#39;.&#39;)[1].strip() &nbsp; &nbsp; &nbsp; &nbsp; download1(url, filename, local_path) &nbsp; &nbsp; return def search_50_page(word, local_path=&quot;./data/down/&quot;): &nbsp; &nbsp; for i in range(1, 50): &nbsp; &nbsp; &nbsp; &nbsp; search(word, local_path, i) def search_50_page_test(): &nbsp; &nbsp; search_50_page(&quot;美女&quot;) def search_list_test(): &nbsp; &nbsp; obj_list = [&quot;苹果&quot;, &quot;香蕉&quot;, &quot;桔子&quot;, &quot;桃子&quot;, &quot;樱桃&quot;, &quot;龙眼&quot;, &quot;荔枝&quot;] &nbsp; &nbsp; #obj_list = [&quot;苹果&quot;, &quot;香蕉&quot;, &quot;桔子&quot;, &quot;橙子&quot;, &quot;桃子&quot;, &quot;樱桃&quot;, &quot;龙眼&quot;, &quot;荔枝&quot;, &quot;雪梨&quot;, &quot;草莓&quot;, &quot;葡萄&quot;, &quot;猕猴桃&quot;, &quot;菠萝&quot;, &quot;番石榴&quot;, &quot;青梅&quot;] &nbsp; &nbsp; #obj_list = [&quot;菊花&quot;, &quot;蒲公英&quot;, &quot;玫瑰&quot;, &quot;向日葵&quot;, &quot;郁金香&quot;] &nbsp; &nbsp; for obj in obj_list: &nbsp; &nbsp; &nbsp; &nbsp; search_50_page(obj, &quot;./data/fruit_photos/&quot;) if __name__ == &#39;__main__&#39;: &nbsp; &nbsp; search_list_test() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; （PS：源码暗藏福利，但是我不说^V^）等效于按下图步骤把百度图片切换到”传统翻页版“，然后手动把前面50页都下载下来了如果你尝试过手动下载，你就会发现图片中有很多是相同的——文件名和URL都一样。此爬虫在文件保存的时候用原始文件名保存，并在在保存新文件前先判断文件是否存在，这就避免了重复的文件。如果把“苹果”换成“apple&quot;你将看到：这显然不是我们想要的效果——我们今天需要的是水果图片，因此我们先用中文关键字爬取，完了之后再手动把文件夹名改成英文的：【图片统一转成jpg】从百度爬取的图片文件有png、jpg、gpeg等格式，为了方便处理，先把它们统一成jpg(创建ulibs.py用于存放我们的清洗函数):def png_to_jpg(path): &nbsp; &nbsp; &quot;&quot;&quot;convert images into jpg format under the path&quot;&quot;&quot; &nbsp; &nbsp; print(&quot;【消息】将图片转换成jpg&quot;, path) &nbsp; &nbsp; for root, sub_dir, files in os.walk(path): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】进入目录：%s&quot; % root) &nbsp; &nbsp; &nbsp; &nbsp; if root == path or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; for file in files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if file.split(&#39;.&#39;)[1] != &#39;jpg&#39;: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】不是jpg:&quot;, file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; old_file = os.path.join(root, file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.imread(old_file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_file = os.path.join(root, file.split(&#39;.&#39;)[0] + &quot;.jpg&quot;) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;转换成:&quot;, new_file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.imwrite(new_file, img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.remove(old_file) &nbsp; &nbsp; print(&quot;【消息】转换完毕&quot;) def png_to_jpg_test(): &nbsp; &nbsp; png_to_jpg(&quot;./data/fruit_photos/&quot;)【手动删除无法预览及明显错误的图片】：【统一命名】：从百度爬取的图片的文件名不统一，很多“%”，长度也参差不齐，为了美观起见我们也把文件名处理一下：类型+编号：def rename_files(path): &nbsp; &nbsp; &quot;&quot;&quot;rename files under path&quot;&quot;&quot; &nbsp; &nbsp; for root, sub_dir, files in os.walk(path): &nbsp; &nbsp; &nbsp; &nbsp; if root == path or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;will rename files under[%s]&quot; % root) &nbsp; &nbsp; &nbsp; &nbsp; count = 1 &nbsp; &nbsp; &nbsp; &nbsp; for file in files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.rename(os.path.join(root, file), os.path.join(root, os.path.basename(root) + &quot;-&quot; + str(count) + &quot;.jpg&quot;)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; count += 1 def rename_files_test(): &nbsp; &nbsp; rename_files(&quot;./data/fruit_photos/&quot;)效果：【将inception-v3用于水果分类】重头戏终于开始了，先上完整代码，然后看效果，然后再详解代码：&#39;&#39;&#39; data: http://download.tensorflow.org/example_images/flower_photos.tgz model: https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip inception-v4: http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz &#39;&#39;&#39; import glob import os.path import random import cv2 import numpy as np import tensorflow as tf from tensorflow.python.platform import gfile from tensorflow.python.framework import graph_util os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; BOTTLENECK_TENSOR_SIZE = 2048 BOTTLENECK_TENSOR_NAME = &#39;pool_3/_reshape:0&#39; JPEG_DATA_TENSOR_NAME = &#39;DecodeJpeg/contents:0&#39; MODEL_DIR = &#39;./data/model/inception_dec_2015&#39; MODEL_FILE = &#39;tensorflow_inception_graph.pb&#39; THIS_MODEL_DIR = &quot;./data/model/inception/&quot; THIS_MODEL_FILE = &quot;inception.pb&quot; CACHE_DIR = &#39;./data/tmp/bottleneck/inception&#39; #INPUT_DATA = &#39;./data/flower_photos&#39; INPUT_DATA = &#39;./data/fruit_photos&#39; INPUT_DATA = &#39;./data/animal_photos&#39; VALIDATION_PERCENTAGE = 10 TEST_PERCENTAGE = 10 LEARNING_RATE = 0.01 STEPS = 1000 BATCH = 100 def create_image_lists(file_dir): &nbsp; &nbsp; training = {} &nbsp; &nbsp; validation = {} &nbsp; &nbsp; testing = {} &nbsp; &nbsp; if not os.path.exists(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Not such path:&quot;, file_dir) &nbsp; &nbsp; &nbsp; &nbsp; return None, None, None &nbsp; &nbsp; for this_dir, sub_dirs, files in os.walk(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; if this_dir == file_dir or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(files) &nbsp; &nbsp; &nbsp; &nbsp; percent10 = int(len(files) * 0.1) &nbsp; &nbsp; &nbsp; &nbsp; this_dir = os.path.basename(this_dir.lower()) &nbsp; &nbsp; &nbsp; &nbsp; training[this_dir] = files[:percent10 * 8] &nbsp; &nbsp; &nbsp; &nbsp; validation[this_dir] = files[percent10 * 8:percent10 * 9] &nbsp; &nbsp; &nbsp; &nbsp; testing[this_dir] = files[percent10 * 9:] &nbsp; &nbsp; return training, validation, testing def get_or_create_bottleneck(sess_mod, image_path): &nbsp; &nbsp; path_seg = image_path.split(&#39;\\&#39;) &nbsp; &nbsp; label_name = path_seg[-2] &nbsp; &nbsp; os.makedirs(os.path.join(CACHE_DIR, label_name), exist_ok=True) &nbsp; &nbsp; bottleneck_path = os.path.join(CACHE_DIR, path_seg[-2], path_seg[-1]) + &quot;.txt&quot; &nbsp; &nbsp; if not os.path.exists(bottleneck_path): &nbsp; &nbsp; &nbsp; &nbsp; image_data = gfile.FastGFile(image_path, &#39;rb&#39;).read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data}) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = np.squeeze(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;HHHA:0====&gt;&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; print(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = &#39;,&#39;.join(str(x &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;) for x in bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;w&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_file.write(bottleneck_string) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;r&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = bottleneck_file.read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = [float(x) for x in bottleneck_string.split(&#39;,&#39;)] &nbsp; &nbsp; return bottleneck_values def get_cached_bottleneck(sess_mod, images, label=None, index=None): &nbsp; &nbsp; label_list = list(images.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; if label is None: &nbsp; &nbsp; &nbsp; &nbsp; label = label_list[random.randrange(len(label_list))] &nbsp; &nbsp; if index is None: &nbsp; &nbsp; &nbsp; &nbsp; index = random.randrange(len(images[label])) &nbsp; &nbsp; image_path = os.path.join(INPUT_DATA, label, images[label][index]) &nbsp; &nbsp; bottleneck = get_or_create_bottleneck(sess_mod, image_path) &nbsp; &nbsp; ground_truth = np.zeros(len(label_list), dtype=np.float32) &nbsp; &nbsp; ground_truth[label_list.index(label)] = 1.0 &nbsp; &nbsp; return bottleneck, ground_truth, image_path def fill_feed_dict(sess_mod, image_lists, amount=None): &nbsp; &nbsp; bottlenecks = [] &nbsp; &nbsp; ground_truths = [] &nbsp; &nbsp; this_paths = [] &nbsp; &nbsp; if amount is None: &nbsp; &nbsp; &nbsp; &nbsp; for label in list(image_lists.keys()): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for index, file in enumerate(image_lists[label]): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists, label, index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(amount): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_labels&#39;]: ground_truths, &nbsp; &nbsp; } &nbsp; &nbsp; return feed_dict, this_paths def inference(inputs, n_classes): &nbsp; &nbsp; this_input = tf.reshape(inputs, [-1, BOTTLENECK_TENSOR_SIZE], name=&#39;input_images&#39;) &nbsp; &nbsp; weights = tf.get_variable(&quot;weights&quot;, [BOTTLENECK_TENSOR_SIZE, n_classes], initializer=tf.truncated_normal_initializer(stddev=0.001)) &nbsp; &nbsp; biases = tf.get_variable(&quot;biases&quot;, [n_classes], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; logits = tf.add(tf.matmul(this_input, weights), biases, &quot;logits&quot;) &nbsp; &nbsp; return logits def loss(logits, labels): &nbsp; &nbsp; labels = tf.to_int64(labels) &nbsp; &nbsp; cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels) &nbsp; &nbsp; return tf.reduce_mean(cross_entropy) def training(loss, learning_rate): &nbsp; &nbsp; tf.summary.scalar(&#39;loss&#39;, loss) &nbsp; &nbsp; optimizer = tf.train.GradientDescentOptimizer(learning_rate) &nbsp; &nbsp; global_step = tf.Variable(0, name=&#39;global_step&#39;, trainable=False) &nbsp; &nbsp; train_op = optimizer.minimize(loss, global_step=global_step) &nbsp; &nbsp; return train_op def evaluation(logits, labels): &nbsp; &nbsp; with tf.name_scope(&#39;evaluation&#39;): &nbsp; &nbsp; &nbsp; &nbsp; correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)) &nbsp; &nbsp; &nbsp; &nbsp; evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) &nbsp; &nbsp; &nbsp; &nbsp; return evaluation_step def model_save(sess, model_path, input_tensor_name, bottleneck_tensor_name): &nbsp; &nbsp; graph_def = tf.get_default_graph().as_graph_def() &nbsp; &nbsp; outpput_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, [input_tensor_name, bottleneck_tensor_name]) &nbsp; &nbsp; with tf.gfile.GFile(model_path, &quot;wb&quot;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; wf.write(outpput_graph_def.SerializeToString()) def model_restore(model_path, input_tensor_name, bottleneck_tensor_name): &nbsp; &nbsp; with gfile.FastGFile(model_path, &#39;rb&#39;) as rf: &nbsp; &nbsp; &nbsp; &nbsp; graph_def = tf.GraphDef() &nbsp; &nbsp; &nbsp; &nbsp; graph_def.ParseFromString(rf.read()) &nbsp; &nbsp; in_tensor, out_tensor, &nbsp;= tf.import_graph_def(graph_def, return_elements=[input_tensor_name, bottleneck_tensor_name]) &nbsp; &nbsp; return in_tensor, out_tensor def run_training(epoch=STEPS): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; n_classes = len(imgs_training.keys()) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; placeholder_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name=&#39;in_images&#39;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, n_classes]) &nbsp; &nbsp; logits = inference(placeholder_input, n_classes) &nbsp; &nbsp; this_loss = loss(logits, placeholder_labels) &nbsp; &nbsp; train_step = training(this_loss, LEARNING_RATE) &nbsp; &nbsp; evaluation_step = evaluation(logits, placeholder_labels) &nbsp; &nbsp; init = tf.global_variables_initializer() &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(init) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: placeholder_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; for step in range(epoch): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_training, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sess.run(train_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if step % 100 == 0 or step + 1 == STEPS: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_validation, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Step %d: Validation accuracy on random sampled %d examples = %.2f%%&quot; % (step, BATCH, accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=fill_feed_dict(sess_mod, imgs_testing)[0]) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; model_save(sess, os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images&quot;, &#39;logits&#39;) def predict_test(): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; m2_input, m2_bottleneck = model_restore(os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images:0&quot;, &quot;logits:0&quot;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, len(imgs_training.keys())]) &nbsp; &nbsp; evaluation_step = evaluation(m2_bottleneck, placeholder_labels) &nbsp; &nbsp; placeholder_logits = tf.placeholder(tf.float32, [None, len(imgs_training.keys())]) &nbsp; &nbsp; final_tensor = tf.nn.softmax(placeholder_logits) &nbsp; &nbsp; final_index = tf.argmax(final_tensor, 1) &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(tf.global_variables_initializer()) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: m2_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_testing) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; while True: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_testing, 1) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_logits = sess.run(m2_bottleneck, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_tensor, f_index = sess.run([final_tensor, final_index], feed_dict={placeholder_logits: this_logits}) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image_path = image_path[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_tensor = f_tensor[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_index = f_index[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;image_path:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_tensor:&quot;, f_tensor) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_index&quot;, f_index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; label_list = list(imgs_testing.keys()) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_predict = label_list[f_index] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_predict:&quot;, f_predict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.imread(image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if img is None: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;File not found:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.resize(img, (500, 500)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.putText(img, os.path.basename(image_path), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.putText(img, f_predict, (50, 150), cv2.FONT_HERSHEY_COMPLEX, 3, (255, 0, 255), 5) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.imshow(&quot;predict&quot;, img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; key = cv2.waitKey() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if key &amp; 0xFF == ord(&#39;q&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elif key &amp; 0xFF == ord(&#39;d&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;removing:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.remove(image_path) def main(argv=None): &nbsp; &nbsp; #run_training(STEPS) &nbsp; &nbsp; predict_test() if __name__ == &quot;__main__&quot;: &nbsp; &nbsp; tf.app.run() 运行过程中如果出现错误，一般是图片文件无法打开（文件损坏、原图是gif文件等），直接将其删除就好了。输出：94.2%的准确率，还算不错。【可视化预测结果】主函数修改如下再运行：def main(argv=None): &nbsp; &nbsp; #run_training(500) &nbsp; &nbsp; predict_test()按q键退出，按d键删除当前文件，按其它何意键切换到下一张：【代码详解】：主函数开始：def main(argv=None): &nbsp; &nbsp; run_training(STEPS) &nbsp; &nbsp; #predict_test()可以看出，我们的模型分训练和预测两个阶段： &nbsp; &nbsp;run_training()是将inception-3迁移到我们的水果分类，训练并将保存新模型； &nbsp; &nbsp;predict_test()是使用新模型进行预测，并可视化展示预测结果；【模型保存及恢复】：model_save()、model_restore()分别是保存和恢复模型def model_save(sess, model_path, input_tensor_name, bottelneck_tensor_name): &nbsp; &nbsp; graph_def = tf.get_default_graph().as_graph_def() &nbsp; &nbsp; outpput_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, [input_tensor_name, bottelneck_tensor_name]) &nbsp; &nbsp; with tf.gfile.GFile(model_path, &quot;wb&quot;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; wf.write(outpput_graph_def.SerializeToString()) def model_restore(model_path, input_tensor_name, bottelneck_tensor_name): &nbsp; &nbsp; with gfile.FastGFile(model_path, &#39;rb&#39;) as rf: &nbsp; &nbsp; &nbsp; &nbsp; graph_def = tf.GraphDef() &nbsp; &nbsp; &nbsp; &nbsp; graph_def.ParseFromString(rf.read()) &nbsp; &nbsp; in_tensor, out_tensor, &nbsp;= tf.import_graph_def(graph_def, return_elements=[input_tensor_name, bottelneck_tensor_name]) &nbsp; &nbsp; return in_tensor, out_tensor参数： &nbsp; &nbsp;model_path：指定了模型文件所在的路径； &nbsp; &nbsp;input_tensor_name: &nbsp;模型的输入张量名称； &nbsp; &nbsp;bottelneck_tensor_name: 模型的瓶颈张量； &nbsp; &nbsp;sess: 保存模型时需要传入当前的会话；model_restore()在run_training()和predict_test()中都有使用：在run_training()中是恢复inception-v3模型；而在predict_test()中不仅要恢复inception-v3模型，还要恢复我们刚刚训练好的新模型，因此调用了两次。【四大金刚】：模型、损失、训练、评估def inference(inputs, n_classes): &nbsp; &nbsp; this_input = tf.reshape(inputs, [-1, BOTTLENECK_TENSOR_SIZE], name=&#39;input_images&#39;) &nbsp; &nbsp; weights = tf.get_variable(&quot;weights&quot;, [BOTTLENECK_TENSOR_SIZE, n_classes], initializer=tf.truncated_normal_initializer(stddev=0.001)) &nbsp; &nbsp; biases = tf.get_variable(&quot;biases&quot;, [n_classes], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; logits = tf.add(tf.matmul(this_input, weights), biases, &quot;logits&quot;) &nbsp; &nbsp; return logits def loss(logits, labels): &nbsp; &nbsp; labels = tf.to_int64(labels) &nbsp; &nbsp; cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels) &nbsp; &nbsp; return tf.reduce_mean(cross_entropy) def training(loss, learning_rate): &nbsp; &nbsp; tf.summary.scalar(&#39;loss&#39;, loss) &nbsp; &nbsp; optimizer = tf.train.GradientDescentOptimizer(learning_rate) &nbsp; &nbsp; global_step = tf.Variable(0, name=&#39;global_step&#39;, trainable=False) &nbsp; &nbsp; train_op = optimizer.minimize(loss, global_step=global_step) &nbsp; &nbsp; return train_op def evaluation(logits, labels): &nbsp; &nbsp; with tf.name_scope(&#39;evaluation&#39;): &nbsp; &nbsp; &nbsp; &nbsp; correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)) &nbsp; &nbsp; &nbsp; &nbsp; evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) &nbsp; &nbsp; &nbsp; &nbsp; return evaluation_step这四个函数都是针对我们的新模型而言： &nbsp; &nbsp;inference: &nbsp;向前传播模型； &nbsp; &nbsp;loss: 损失的计算； &nbsp; &nbsp;training: 通过最小化损失训练模型参数； &nbsp; &nbsp;evaluation: 计算预测的精确度；【瓶颈张量的计算】def create_image_lists(file_dir): &nbsp; &nbsp; training = {} &nbsp; &nbsp; validation = {} &nbsp; &nbsp; testing = {} &nbsp; &nbsp; if not os.path.exists(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Not such path:&quot;, file_dir) &nbsp; &nbsp; &nbsp; &nbsp; return None, None, None &nbsp; &nbsp; for this_dir, sub_dirs, files in os.walk(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; if this_dir == file_dir or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(files) &nbsp; &nbsp; &nbsp; &nbsp; percent10 = int(len(files) * 0.1) &nbsp; &nbsp; &nbsp; &nbsp; this_dir = os.path.basename(this_dir.lower()) &nbsp; &nbsp; &nbsp; &nbsp; training[this_dir] = files[:percent10 * 8] &nbsp; &nbsp; &nbsp; &nbsp; validation[this_dir] = files[percent10 * 8:percent10 * 9] &nbsp; &nbsp; &nbsp; &nbsp; testing[this_dir] = files[percent10 * 9:] &nbsp; &nbsp; return training, validation, testing def get_or_create_bottleneck(sess_mod, image_path): &nbsp; &nbsp; path_seg = image_path.split(&#39;\\&#39;) &nbsp; &nbsp; label_name = path_seg[-2] &nbsp; &nbsp; os.makedirs(os.path.join(CACHE_DIR, label_name), exist_ok=True) &nbsp; &nbsp; bottleneck_path = os.path.join(CACHE_DIR, path_seg[-2], path_seg[-1]) + &quot;.txt&quot; &nbsp; &nbsp; if not os.path.exists(bottleneck_path): &nbsp; &nbsp; &nbsp; &nbsp; image_data = gfile.FastGFile(image_path, &#39;rb&#39;).read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data}) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = np.squeeze(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;HHHA:0====&gt;&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; print(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = &#39;,&#39;.join(str(x &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;) for x in bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;w&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_file.write(bottleneck_string) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;r&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = bottleneck_file.read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = [float(x) for x in bottleneck_string.split(&#39;,&#39;)] &nbsp; &nbsp; return bottleneck_values def get_cached_bottleneck(sess_mod, images, label=None, index=None): &nbsp; &nbsp; label_list = list(images.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; if label is None: &nbsp; &nbsp; &nbsp; &nbsp; label = label_list[random.randrange(len(label_list))] &nbsp; &nbsp; if index is None: &nbsp; &nbsp; &nbsp; &nbsp; index = random.randrange(len(images[label])) &nbsp; &nbsp; image_path = os.path.join(INPUT_DATA, label, images[label][index]) &nbsp; &nbsp; bottleneck = get_or_create_bottleneck(sess_mod, image_path) &nbsp; &nbsp; ground_truth = np.zeros(len(label_list), dtype=np.float32) &nbsp; &nbsp; ground_truth[label_list.index(label)] = 1.0 &nbsp; &nbsp; return bottleneck, ground_truth, image_pathcreate_image_lists()：理解这个函数需要结合我们的目录结构：fruit_photos下面每种水果的图片放在一个以该水果命名的小目录中：参数file_dir传入的将是fruit_photos所在路径。用os.walk遍历这个目录，并按1：1：8的比例把所有图片分割成训练、验证、测试三个数据集，每个数据集都是一个字典：以水果名称为键，以图片名称列表为值。get_or_create_bottleneck():获取或创建瓶颈向量：用指定的模型计算指定图片的瓶颈向量。什么意思呢？具体就是获取图片A经过inception-v3这个模型之后的输出。参数sess_mod是封装了inception-v3的输入、输出、和用于计算的sess：bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data})可对比tensorflow的经典方式进行理解：sess.run(z, feed_dict={x:a, y:b})计算瓶颈向量比较耗时，为了避免重复计算，把计算结果存放在CACHE_DIR/水果名/中，以图片名.txt命名。每次获取时先尝试从该目录中获取，如果文件不存在，则用模型进行计算并保存。参数image_path指明了给获取哪张图片的瓶颈向量。get_cached_bottleneck():基于get_or_create_bottleneck()的封装，参数： &nbsp; images: 图片列表，也就是create_image_list中分割出来的training, validation, testing三个数据集中的一个； &nbsp; label: 水果名称，如果没有指定，则随机选择一种水果 &nbsp; index: 文件下标，如果没有指定，则随机选择一个下标如：get_cached_bottleneck(sess_mod, training, &quot;apple&quot;, 0)的意思是获取训练集中的苹果的下标为0的图片的瓶颈向量；又如：get_cached_bottleneck(sess_mod, training)的意思是从训练集中随机获取一张图片的瓶颈向量。【训练字典的生成】def fill_feed_dict(sess_mod, image_lists, amount=None): &nbsp; &nbsp; bottlenecks = [] &nbsp; &nbsp; ground_truths = [] &nbsp; &nbsp; this_paths = [] &nbsp; &nbsp; if amount is None: &nbsp; &nbsp; &nbsp; &nbsp; for label in list(image_lists.keys()): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for index, file in enumerate(image_lists[label]): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists, label, index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(amount): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_labels&#39;]: ground_truths, &nbsp; &nbsp; } &nbsp; &nbsp; return feed_dict, this_paths这个函数最终输出一个字典，用于新模型的计算。 &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp;sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp;sess_mod[&#39;placeholder_labels&#39;]: ground_truths,}bottlenecks是图片经过inception-v3的输出，它将作为新模型的输入。sess_mod[&#39;placeholder_input&#39;]是新模型的输出占位张量；sess_mod[&#39;placeholder_labels&#39;]是图片的正确标签——计算瓶颈向量的时候“顺便”生成的。再看amount这个参数：训练的时候用BATCH，评估的时候未指定——等效于None，predict_test()的时候用1，这是为什么呢？原来amount是指明要随机填充的图片数量，当为空时候将填充传入的整个图片列表。predict_test()阶段由于要向用户展示图片，因此每次只填充一张。【运行训练】def run_training(epoch=STEPS): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; n_classes = len(imgs_training.keys()) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; placeholder_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name=&#39;in_images&#39;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, n_classes]) &nbsp; &nbsp; logits = inference(placeholder_input, n_classes) &nbsp; &nbsp; this_loss = loss(logits, placeholder_labels) &nbsp; &nbsp; train_step = training(this_loss, LEARNING_RATE) &nbsp; &nbsp; evaluation_step = evaluation(logits, placeholder_labels) &nbsp; &nbsp; init = tf.global_variables_initializer() &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(init) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: placeholder_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; for step in range(epoch): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_training, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sess.run(train_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if step % 100 == 0 or step + 1 == STEPS: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_validation, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Step %d: Validation accuracy on random sampled %d examples = %.2f%%&quot; % (step, BATCH, accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=fill_feed_dict(sess_mod, imgs_testing)[0]) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; model_save(sess, os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images&quot;, &#39;logits&#39;)这是训练的主干过程，解释完前面的小函数之后，这个函数似乎没有太多需要解释的了，它就是把前介绍的函数调用了一遍！sess_mod的这样封装的原因是sess、m1_input，m1_bottelneck这几个参数经过多层传递最终执行，把它们入在字典中可减少中间函数的参数数量，增加代码的可读性。【图片展示函数片段】while True: &nbsp; &nbsp; this_logits = sess.run(m2_bottleneck, feed_dict=feed_dict) &nbsp; &nbsp; f_tensor, f_index = sess.run([final_tensor, final_index], feed_dict={placeholder_logits: this_logits}) &nbsp; &nbsp; image_path = image_path[0] &nbsp; &nbsp; f_tensor = f_tensor[0] &nbsp; &nbsp; f_index = f_index[0] &nbsp; &nbsp; print(&quot;image_path:&quot;, image_path) &nbsp; &nbsp; print(&quot;f_tensor:&quot;, f_tensor) &nbsp; &nbsp; print(&quot;f_index&quot;, f_index) &nbsp; &nbsp; label_list = list(imgs_testing.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; f_predict = label_list[f_index] &nbsp; &nbsp; print(&quot;f_predict:&quot;, f_predict) &nbsp; &nbsp; img = cv2.imread(image_path) &nbsp; &nbsp; if img is None: &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;File not found:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; img = cv2.resize(img, (500, 500)) &nbsp; &nbsp; cv2.putText(img, os.path.basename(image_path), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1) &nbsp; &nbsp; cv2.putText(img, f_predict, (50, 150), cv2.FONT_HERSHEY_COMPLEX, 3, (255, 0, 255), 5) &nbsp; &nbsp; cv2.imshow(&quot;predict&quot;, img) &nbsp; &nbsp; key = cv2.waitKey() &nbsp; &nbsp; if key &amp; 0xFF == ord(&#39;q&#39;): &nbsp; &nbsp; &nbsp; &nbsp; break &nbsp; &nbsp; elif key &amp; 0xFF == ord(&#39;d&#39;): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;removing:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; os.remove(image_path)用opencv，cv2.imread(): 读取图片；cv2.resize(): 将图片大小调整为500*500，这是因为原图的大小并非统一的，建议读者试试去掉的效果；cv2.putText(): 在图上显示文字；cv2.imshow(): 显示图片；cv2.waitKey(): 等待用户输入: &nbsp; &nbsp;如果用户输入q: 退出循环； &nbsp; &nbsp;如果用户输入d: 删除当前图片，这在剔除错误图片时相当方便【扩展】将model_save()/model_restore()收入ulibs.py中，然后通过以下方式调用:import ulibs ulibs.model_save() &nbsp;ulibs.model_restore()参考：《TensorFlow实战Google尝试学习框架》--郑泽宇 顾思宇 &nbsp;" />
<meta property="og:description" content="本文是关于如何用谷歌提供的训练好的Inception-v3进行水果图片分类，涉及以下几个内容：下载inception-v3（谷歌训练好的模型）图片数据的下载图片数据的清洗将模型用于图片分类-------------------------------------------------------------------详解：【创建文件】 &nbsp;|--baidu_search.py &nbsp; &nbsp; #通过百度爬取图片 &nbsp;|--ulibs.py &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#用于存放数据清洗等功能函数 &nbsp;|--inception-v3.py &nbsp; &nbsp; &nbsp; # 模型训练函数 &nbsp;|--data/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #存放数据 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--model/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#存放已训练好的模型 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--fruit_photos/ &nbsp; #存放爬取的图片 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--tmp/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #存放临时文件【下载inception-v3】https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip解压后放在./data/model/目录下【下载水果图片】：通过关键字从百度爬取baidu_search.py:# -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Tue Feb 27 11:10:45 2018 @author: mc.meng &quot;&quot;&quot; import re, os import requests from urllib.request import urlretrieve def download1(url, filename, filepath): &nbsp; &nbsp; full_name = os.path.join(filepath, filename) &nbsp; &nbsp; if os.path.exists(full_name): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】文件已经存在：&quot;, full_name) &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; pic = requests.get(url, timeout=5) &nbsp; &nbsp; except: &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;【错误】当前图片无法下载&#39;) &nbsp; &nbsp; &nbsp; &nbsp; return &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; with open(filepath + &quot;/&quot; + filename, &#39;wb&#39;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wf.write(pic.content) &nbsp; &nbsp; except : &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】写入失败&quot;) def download2(url, filename, filepath): &nbsp; &nbsp; full_name = os.path.join(filepath, filename) &nbsp; &nbsp; if os.path.exists(full_name): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】文件已经存在：&quot;, full_name) &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; urlretrieve(url, full_name) &nbsp; &nbsp; except: &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;【错误】当前图片无法下载&#39;) def search(word=&quot;美女&quot;, local_path=&quot;./data/down/&quot;, page=None, keep_original_name=True): &nbsp; &nbsp; local_path += word &nbsp; &nbsp; os.makedirs(local_path, exist_ok=True) &nbsp; &nbsp; url = &#39;http://image.baidu.com/search/flip?tn=baiduimage&amp;ie=utf-8&amp;word={word}&amp;pn={pn}&amp;gsm={gsm:x}&amp;ct=&amp;ic=0&amp;lm=-1&amp;width=0&amp;height=0&#39;.format(word=word, pn=20 * page, gsm=40 + 20 * page) &nbsp; &nbsp; print(&quot;HHHC:0====&gt;page=%d,url=\&quot;%s\&quot;&quot; % (page,url)) &nbsp; &nbsp; html = requests.get(url).text &nbsp; &nbsp; pic_url = re.findall(&#39;&quot;objURL&quot;:&quot;(.*?)&quot;,&#39;, html, re.S) &nbsp; &nbsp; i = 0 &nbsp; &nbsp; for url in pic_url: &nbsp; &nbsp; &nbsp; &nbsp; print(url) &nbsp; &nbsp; &nbsp; &nbsp; i = i + 1 &nbsp; &nbsp; &nbsp; &nbsp; filename = os.path.split(url)[1].split(&#39;?&#39;)[0] &nbsp; &nbsp; &nbsp; &nbsp; filename_split = filename.split(&#39;.&#39;) &nbsp; &nbsp; &nbsp; &nbsp; if len(filename_split) != 2: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】文件名异常:&quot; + filename) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; #print(&quot;HHHA:0====&gt;&quot;, filename_split[1]) &nbsp; &nbsp; &nbsp; &nbsp; if filename_split[1] != &#39;jpg&#39; and filename_split[1] != &#39;JPG&#39; \ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; and filename_split[1] != &#39;png&#39; and filename_split[1] != &#39;PNG&#39;: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】类型异常:&quot; + filename) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; if not keep_original_name: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; filename = filename.split(&#39;.&#39;)[0].strip() + &quot;-&quot; + str(page) + &quot;-&quot; + str(i) + &quot;.&quot; + filename.split(&#39;.&#39;)[1].strip() &nbsp; &nbsp; &nbsp; &nbsp; download1(url, filename, local_path) &nbsp; &nbsp; return def search_50_page(word, local_path=&quot;./data/down/&quot;): &nbsp; &nbsp; for i in range(1, 50): &nbsp; &nbsp; &nbsp; &nbsp; search(word, local_path, i) def search_50_page_test(): &nbsp; &nbsp; search_50_page(&quot;美女&quot;) def search_list_test(): &nbsp; &nbsp; obj_list = [&quot;苹果&quot;, &quot;香蕉&quot;, &quot;桔子&quot;, &quot;桃子&quot;, &quot;樱桃&quot;, &quot;龙眼&quot;, &quot;荔枝&quot;] &nbsp; &nbsp; #obj_list = [&quot;苹果&quot;, &quot;香蕉&quot;, &quot;桔子&quot;, &quot;橙子&quot;, &quot;桃子&quot;, &quot;樱桃&quot;, &quot;龙眼&quot;, &quot;荔枝&quot;, &quot;雪梨&quot;, &quot;草莓&quot;, &quot;葡萄&quot;, &quot;猕猴桃&quot;, &quot;菠萝&quot;, &quot;番石榴&quot;, &quot;青梅&quot;] &nbsp; &nbsp; #obj_list = [&quot;菊花&quot;, &quot;蒲公英&quot;, &quot;玫瑰&quot;, &quot;向日葵&quot;, &quot;郁金香&quot;] &nbsp; &nbsp; for obj in obj_list: &nbsp; &nbsp; &nbsp; &nbsp; search_50_page(obj, &quot;./data/fruit_photos/&quot;) if __name__ == &#39;__main__&#39;: &nbsp; &nbsp; search_list_test() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; （PS：源码暗藏福利，但是我不说^V^）等效于按下图步骤把百度图片切换到”传统翻页版“，然后手动把前面50页都下载下来了如果你尝试过手动下载，你就会发现图片中有很多是相同的——文件名和URL都一样。此爬虫在文件保存的时候用原始文件名保存，并在在保存新文件前先判断文件是否存在，这就避免了重复的文件。如果把“苹果”换成“apple&quot;你将看到：这显然不是我们想要的效果——我们今天需要的是水果图片，因此我们先用中文关键字爬取，完了之后再手动把文件夹名改成英文的：【图片统一转成jpg】从百度爬取的图片文件有png、jpg、gpeg等格式，为了方便处理，先把它们统一成jpg(创建ulibs.py用于存放我们的清洗函数):def png_to_jpg(path): &nbsp; &nbsp; &quot;&quot;&quot;convert images into jpg format under the path&quot;&quot;&quot; &nbsp; &nbsp; print(&quot;【消息】将图片转换成jpg&quot;, path) &nbsp; &nbsp; for root, sub_dir, files in os.walk(path): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】进入目录：%s&quot; % root) &nbsp; &nbsp; &nbsp; &nbsp; if root == path or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; for file in files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if file.split(&#39;.&#39;)[1] != &#39;jpg&#39;: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】不是jpg:&quot;, file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; old_file = os.path.join(root, file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.imread(old_file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_file = os.path.join(root, file.split(&#39;.&#39;)[0] + &quot;.jpg&quot;) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;转换成:&quot;, new_file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.imwrite(new_file, img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.remove(old_file) &nbsp; &nbsp; print(&quot;【消息】转换完毕&quot;) def png_to_jpg_test(): &nbsp; &nbsp; png_to_jpg(&quot;./data/fruit_photos/&quot;)【手动删除无法预览及明显错误的图片】：【统一命名】：从百度爬取的图片的文件名不统一，很多“%”，长度也参差不齐，为了美观起见我们也把文件名处理一下：类型+编号：def rename_files(path): &nbsp; &nbsp; &quot;&quot;&quot;rename files under path&quot;&quot;&quot; &nbsp; &nbsp; for root, sub_dir, files in os.walk(path): &nbsp; &nbsp; &nbsp; &nbsp; if root == path or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;will rename files under[%s]&quot; % root) &nbsp; &nbsp; &nbsp; &nbsp; count = 1 &nbsp; &nbsp; &nbsp; &nbsp; for file in files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.rename(os.path.join(root, file), os.path.join(root, os.path.basename(root) + &quot;-&quot; + str(count) + &quot;.jpg&quot;)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; count += 1 def rename_files_test(): &nbsp; &nbsp; rename_files(&quot;./data/fruit_photos/&quot;)效果：【将inception-v3用于水果分类】重头戏终于开始了，先上完整代码，然后看效果，然后再详解代码：&#39;&#39;&#39; data: http://download.tensorflow.org/example_images/flower_photos.tgz model: https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip inception-v4: http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz &#39;&#39;&#39; import glob import os.path import random import cv2 import numpy as np import tensorflow as tf from tensorflow.python.platform import gfile from tensorflow.python.framework import graph_util os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; BOTTLENECK_TENSOR_SIZE = 2048 BOTTLENECK_TENSOR_NAME = &#39;pool_3/_reshape:0&#39; JPEG_DATA_TENSOR_NAME = &#39;DecodeJpeg/contents:0&#39; MODEL_DIR = &#39;./data/model/inception_dec_2015&#39; MODEL_FILE = &#39;tensorflow_inception_graph.pb&#39; THIS_MODEL_DIR = &quot;./data/model/inception/&quot; THIS_MODEL_FILE = &quot;inception.pb&quot; CACHE_DIR = &#39;./data/tmp/bottleneck/inception&#39; #INPUT_DATA = &#39;./data/flower_photos&#39; INPUT_DATA = &#39;./data/fruit_photos&#39; INPUT_DATA = &#39;./data/animal_photos&#39; VALIDATION_PERCENTAGE = 10 TEST_PERCENTAGE = 10 LEARNING_RATE = 0.01 STEPS = 1000 BATCH = 100 def create_image_lists(file_dir): &nbsp; &nbsp; training = {} &nbsp; &nbsp; validation = {} &nbsp; &nbsp; testing = {} &nbsp; &nbsp; if not os.path.exists(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Not such path:&quot;, file_dir) &nbsp; &nbsp; &nbsp; &nbsp; return None, None, None &nbsp; &nbsp; for this_dir, sub_dirs, files in os.walk(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; if this_dir == file_dir or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(files) &nbsp; &nbsp; &nbsp; &nbsp; percent10 = int(len(files) * 0.1) &nbsp; &nbsp; &nbsp; &nbsp; this_dir = os.path.basename(this_dir.lower()) &nbsp; &nbsp; &nbsp; &nbsp; training[this_dir] = files[:percent10 * 8] &nbsp; &nbsp; &nbsp; &nbsp; validation[this_dir] = files[percent10 * 8:percent10 * 9] &nbsp; &nbsp; &nbsp; &nbsp; testing[this_dir] = files[percent10 * 9:] &nbsp; &nbsp; return training, validation, testing def get_or_create_bottleneck(sess_mod, image_path): &nbsp; &nbsp; path_seg = image_path.split(&#39;\\&#39;) &nbsp; &nbsp; label_name = path_seg[-2] &nbsp; &nbsp; os.makedirs(os.path.join(CACHE_DIR, label_name), exist_ok=True) &nbsp; &nbsp; bottleneck_path = os.path.join(CACHE_DIR, path_seg[-2], path_seg[-1]) + &quot;.txt&quot; &nbsp; &nbsp; if not os.path.exists(bottleneck_path): &nbsp; &nbsp; &nbsp; &nbsp; image_data = gfile.FastGFile(image_path, &#39;rb&#39;).read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data}) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = np.squeeze(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;HHHA:0====&gt;&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; print(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = &#39;,&#39;.join(str(x &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;) for x in bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;w&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_file.write(bottleneck_string) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;r&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = bottleneck_file.read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = [float(x) for x in bottleneck_string.split(&#39;,&#39;)] &nbsp; &nbsp; return bottleneck_values def get_cached_bottleneck(sess_mod, images, label=None, index=None): &nbsp; &nbsp; label_list = list(images.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; if label is None: &nbsp; &nbsp; &nbsp; &nbsp; label = label_list[random.randrange(len(label_list))] &nbsp; &nbsp; if index is None: &nbsp; &nbsp; &nbsp; &nbsp; index = random.randrange(len(images[label])) &nbsp; &nbsp; image_path = os.path.join(INPUT_DATA, label, images[label][index]) &nbsp; &nbsp; bottleneck = get_or_create_bottleneck(sess_mod, image_path) &nbsp; &nbsp; ground_truth = np.zeros(len(label_list), dtype=np.float32) &nbsp; &nbsp; ground_truth[label_list.index(label)] = 1.0 &nbsp; &nbsp; return bottleneck, ground_truth, image_path def fill_feed_dict(sess_mod, image_lists, amount=None): &nbsp; &nbsp; bottlenecks = [] &nbsp; &nbsp; ground_truths = [] &nbsp; &nbsp; this_paths = [] &nbsp; &nbsp; if amount is None: &nbsp; &nbsp; &nbsp; &nbsp; for label in list(image_lists.keys()): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for index, file in enumerate(image_lists[label]): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists, label, index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(amount): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_labels&#39;]: ground_truths, &nbsp; &nbsp; } &nbsp; &nbsp; return feed_dict, this_paths def inference(inputs, n_classes): &nbsp; &nbsp; this_input = tf.reshape(inputs, [-1, BOTTLENECK_TENSOR_SIZE], name=&#39;input_images&#39;) &nbsp; &nbsp; weights = tf.get_variable(&quot;weights&quot;, [BOTTLENECK_TENSOR_SIZE, n_classes], initializer=tf.truncated_normal_initializer(stddev=0.001)) &nbsp; &nbsp; biases = tf.get_variable(&quot;biases&quot;, [n_classes], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; logits = tf.add(tf.matmul(this_input, weights), biases, &quot;logits&quot;) &nbsp; &nbsp; return logits def loss(logits, labels): &nbsp; &nbsp; labels = tf.to_int64(labels) &nbsp; &nbsp; cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels) &nbsp; &nbsp; return tf.reduce_mean(cross_entropy) def training(loss, learning_rate): &nbsp; &nbsp; tf.summary.scalar(&#39;loss&#39;, loss) &nbsp; &nbsp; optimizer = tf.train.GradientDescentOptimizer(learning_rate) &nbsp; &nbsp; global_step = tf.Variable(0, name=&#39;global_step&#39;, trainable=False) &nbsp; &nbsp; train_op = optimizer.minimize(loss, global_step=global_step) &nbsp; &nbsp; return train_op def evaluation(logits, labels): &nbsp; &nbsp; with tf.name_scope(&#39;evaluation&#39;): &nbsp; &nbsp; &nbsp; &nbsp; correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)) &nbsp; &nbsp; &nbsp; &nbsp; evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) &nbsp; &nbsp; &nbsp; &nbsp; return evaluation_step def model_save(sess, model_path, input_tensor_name, bottleneck_tensor_name): &nbsp; &nbsp; graph_def = tf.get_default_graph().as_graph_def() &nbsp; &nbsp; outpput_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, [input_tensor_name, bottleneck_tensor_name]) &nbsp; &nbsp; with tf.gfile.GFile(model_path, &quot;wb&quot;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; wf.write(outpput_graph_def.SerializeToString()) def model_restore(model_path, input_tensor_name, bottleneck_tensor_name): &nbsp; &nbsp; with gfile.FastGFile(model_path, &#39;rb&#39;) as rf: &nbsp; &nbsp; &nbsp; &nbsp; graph_def = tf.GraphDef() &nbsp; &nbsp; &nbsp; &nbsp; graph_def.ParseFromString(rf.read()) &nbsp; &nbsp; in_tensor, out_tensor, &nbsp;= tf.import_graph_def(graph_def, return_elements=[input_tensor_name, bottleneck_tensor_name]) &nbsp; &nbsp; return in_tensor, out_tensor def run_training(epoch=STEPS): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; n_classes = len(imgs_training.keys()) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; placeholder_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name=&#39;in_images&#39;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, n_classes]) &nbsp; &nbsp; logits = inference(placeholder_input, n_classes) &nbsp; &nbsp; this_loss = loss(logits, placeholder_labels) &nbsp; &nbsp; train_step = training(this_loss, LEARNING_RATE) &nbsp; &nbsp; evaluation_step = evaluation(logits, placeholder_labels) &nbsp; &nbsp; init = tf.global_variables_initializer() &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(init) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: placeholder_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; for step in range(epoch): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_training, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sess.run(train_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if step % 100 == 0 or step + 1 == STEPS: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_validation, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Step %d: Validation accuracy on random sampled %d examples = %.2f%%&quot; % (step, BATCH, accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=fill_feed_dict(sess_mod, imgs_testing)[0]) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; model_save(sess, os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images&quot;, &#39;logits&#39;) def predict_test(): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; m2_input, m2_bottleneck = model_restore(os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images:0&quot;, &quot;logits:0&quot;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, len(imgs_training.keys())]) &nbsp; &nbsp; evaluation_step = evaluation(m2_bottleneck, placeholder_labels) &nbsp; &nbsp; placeholder_logits = tf.placeholder(tf.float32, [None, len(imgs_training.keys())]) &nbsp; &nbsp; final_tensor = tf.nn.softmax(placeholder_logits) &nbsp; &nbsp; final_index = tf.argmax(final_tensor, 1) &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(tf.global_variables_initializer()) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: m2_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_testing) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; while True: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_testing, 1) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_logits = sess.run(m2_bottleneck, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_tensor, f_index = sess.run([final_tensor, final_index], feed_dict={placeholder_logits: this_logits}) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image_path = image_path[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_tensor = f_tensor[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_index = f_index[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;image_path:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_tensor:&quot;, f_tensor) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_index&quot;, f_index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; label_list = list(imgs_testing.keys()) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_predict = label_list[f_index] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_predict:&quot;, f_predict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.imread(image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if img is None: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;File not found:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.resize(img, (500, 500)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.putText(img, os.path.basename(image_path), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.putText(img, f_predict, (50, 150), cv2.FONT_HERSHEY_COMPLEX, 3, (255, 0, 255), 5) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.imshow(&quot;predict&quot;, img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; key = cv2.waitKey() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if key &amp; 0xFF == ord(&#39;q&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elif key &amp; 0xFF == ord(&#39;d&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;removing:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.remove(image_path) def main(argv=None): &nbsp; &nbsp; #run_training(STEPS) &nbsp; &nbsp; predict_test() if __name__ == &quot;__main__&quot;: &nbsp; &nbsp; tf.app.run() 运行过程中如果出现错误，一般是图片文件无法打开（文件损坏、原图是gif文件等），直接将其删除就好了。输出：94.2%的准确率，还算不错。【可视化预测结果】主函数修改如下再运行：def main(argv=None): &nbsp; &nbsp; #run_training(500) &nbsp; &nbsp; predict_test()按q键退出，按d键删除当前文件，按其它何意键切换到下一张：【代码详解】：主函数开始：def main(argv=None): &nbsp; &nbsp; run_training(STEPS) &nbsp; &nbsp; #predict_test()可以看出，我们的模型分训练和预测两个阶段： &nbsp; &nbsp;run_training()是将inception-3迁移到我们的水果分类，训练并将保存新模型； &nbsp; &nbsp;predict_test()是使用新模型进行预测，并可视化展示预测结果；【模型保存及恢复】：model_save()、model_restore()分别是保存和恢复模型def model_save(sess, model_path, input_tensor_name, bottelneck_tensor_name): &nbsp; &nbsp; graph_def = tf.get_default_graph().as_graph_def() &nbsp; &nbsp; outpput_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, [input_tensor_name, bottelneck_tensor_name]) &nbsp; &nbsp; with tf.gfile.GFile(model_path, &quot;wb&quot;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; wf.write(outpput_graph_def.SerializeToString()) def model_restore(model_path, input_tensor_name, bottelneck_tensor_name): &nbsp; &nbsp; with gfile.FastGFile(model_path, &#39;rb&#39;) as rf: &nbsp; &nbsp; &nbsp; &nbsp; graph_def = tf.GraphDef() &nbsp; &nbsp; &nbsp; &nbsp; graph_def.ParseFromString(rf.read()) &nbsp; &nbsp; in_tensor, out_tensor, &nbsp;= tf.import_graph_def(graph_def, return_elements=[input_tensor_name, bottelneck_tensor_name]) &nbsp; &nbsp; return in_tensor, out_tensor参数： &nbsp; &nbsp;model_path：指定了模型文件所在的路径； &nbsp; &nbsp;input_tensor_name: &nbsp;模型的输入张量名称； &nbsp; &nbsp;bottelneck_tensor_name: 模型的瓶颈张量； &nbsp; &nbsp;sess: 保存模型时需要传入当前的会话；model_restore()在run_training()和predict_test()中都有使用：在run_training()中是恢复inception-v3模型；而在predict_test()中不仅要恢复inception-v3模型，还要恢复我们刚刚训练好的新模型，因此调用了两次。【四大金刚】：模型、损失、训练、评估def inference(inputs, n_classes): &nbsp; &nbsp; this_input = tf.reshape(inputs, [-1, BOTTLENECK_TENSOR_SIZE], name=&#39;input_images&#39;) &nbsp; &nbsp; weights = tf.get_variable(&quot;weights&quot;, [BOTTLENECK_TENSOR_SIZE, n_classes], initializer=tf.truncated_normal_initializer(stddev=0.001)) &nbsp; &nbsp; biases = tf.get_variable(&quot;biases&quot;, [n_classes], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; logits = tf.add(tf.matmul(this_input, weights), biases, &quot;logits&quot;) &nbsp; &nbsp; return logits def loss(logits, labels): &nbsp; &nbsp; labels = tf.to_int64(labels) &nbsp; &nbsp; cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels) &nbsp; &nbsp; return tf.reduce_mean(cross_entropy) def training(loss, learning_rate): &nbsp; &nbsp; tf.summary.scalar(&#39;loss&#39;, loss) &nbsp; &nbsp; optimizer = tf.train.GradientDescentOptimizer(learning_rate) &nbsp; &nbsp; global_step = tf.Variable(0, name=&#39;global_step&#39;, trainable=False) &nbsp; &nbsp; train_op = optimizer.minimize(loss, global_step=global_step) &nbsp; &nbsp; return train_op def evaluation(logits, labels): &nbsp; &nbsp; with tf.name_scope(&#39;evaluation&#39;): &nbsp; &nbsp; &nbsp; &nbsp; correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)) &nbsp; &nbsp; &nbsp; &nbsp; evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) &nbsp; &nbsp; &nbsp; &nbsp; return evaluation_step这四个函数都是针对我们的新模型而言： &nbsp; &nbsp;inference: &nbsp;向前传播模型； &nbsp; &nbsp;loss: 损失的计算； &nbsp; &nbsp;training: 通过最小化损失训练模型参数； &nbsp; &nbsp;evaluation: 计算预测的精确度；【瓶颈张量的计算】def create_image_lists(file_dir): &nbsp; &nbsp; training = {} &nbsp; &nbsp; validation = {} &nbsp; &nbsp; testing = {} &nbsp; &nbsp; if not os.path.exists(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Not such path:&quot;, file_dir) &nbsp; &nbsp; &nbsp; &nbsp; return None, None, None &nbsp; &nbsp; for this_dir, sub_dirs, files in os.walk(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; if this_dir == file_dir or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(files) &nbsp; &nbsp; &nbsp; &nbsp; percent10 = int(len(files) * 0.1) &nbsp; &nbsp; &nbsp; &nbsp; this_dir = os.path.basename(this_dir.lower()) &nbsp; &nbsp; &nbsp; &nbsp; training[this_dir] = files[:percent10 * 8] &nbsp; &nbsp; &nbsp; &nbsp; validation[this_dir] = files[percent10 * 8:percent10 * 9] &nbsp; &nbsp; &nbsp; &nbsp; testing[this_dir] = files[percent10 * 9:] &nbsp; &nbsp; return training, validation, testing def get_or_create_bottleneck(sess_mod, image_path): &nbsp; &nbsp; path_seg = image_path.split(&#39;\\&#39;) &nbsp; &nbsp; label_name = path_seg[-2] &nbsp; &nbsp; os.makedirs(os.path.join(CACHE_DIR, label_name), exist_ok=True) &nbsp; &nbsp; bottleneck_path = os.path.join(CACHE_DIR, path_seg[-2], path_seg[-1]) + &quot;.txt&quot; &nbsp; &nbsp; if not os.path.exists(bottleneck_path): &nbsp; &nbsp; &nbsp; &nbsp; image_data = gfile.FastGFile(image_path, &#39;rb&#39;).read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data}) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = np.squeeze(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;HHHA:0====&gt;&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; print(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = &#39;,&#39;.join(str(x &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;) for x in bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;w&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_file.write(bottleneck_string) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;r&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = bottleneck_file.read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = [float(x) for x in bottleneck_string.split(&#39;,&#39;)] &nbsp; &nbsp; return bottleneck_values def get_cached_bottleneck(sess_mod, images, label=None, index=None): &nbsp; &nbsp; label_list = list(images.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; if label is None: &nbsp; &nbsp; &nbsp; &nbsp; label = label_list[random.randrange(len(label_list))] &nbsp; &nbsp; if index is None: &nbsp; &nbsp; &nbsp; &nbsp; index = random.randrange(len(images[label])) &nbsp; &nbsp; image_path = os.path.join(INPUT_DATA, label, images[label][index]) &nbsp; &nbsp; bottleneck = get_or_create_bottleneck(sess_mod, image_path) &nbsp; &nbsp; ground_truth = np.zeros(len(label_list), dtype=np.float32) &nbsp; &nbsp; ground_truth[label_list.index(label)] = 1.0 &nbsp; &nbsp; return bottleneck, ground_truth, image_pathcreate_image_lists()：理解这个函数需要结合我们的目录结构：fruit_photos下面每种水果的图片放在一个以该水果命名的小目录中：参数file_dir传入的将是fruit_photos所在路径。用os.walk遍历这个目录，并按1：1：8的比例把所有图片分割成训练、验证、测试三个数据集，每个数据集都是一个字典：以水果名称为键，以图片名称列表为值。get_or_create_bottleneck():获取或创建瓶颈向量：用指定的模型计算指定图片的瓶颈向量。什么意思呢？具体就是获取图片A经过inception-v3这个模型之后的输出。参数sess_mod是封装了inception-v3的输入、输出、和用于计算的sess：bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data})可对比tensorflow的经典方式进行理解：sess.run(z, feed_dict={x:a, y:b})计算瓶颈向量比较耗时，为了避免重复计算，把计算结果存放在CACHE_DIR/水果名/中，以图片名.txt命名。每次获取时先尝试从该目录中获取，如果文件不存在，则用模型进行计算并保存。参数image_path指明了给获取哪张图片的瓶颈向量。get_cached_bottleneck():基于get_or_create_bottleneck()的封装，参数： &nbsp; images: 图片列表，也就是create_image_list中分割出来的training, validation, testing三个数据集中的一个； &nbsp; label: 水果名称，如果没有指定，则随机选择一种水果 &nbsp; index: 文件下标，如果没有指定，则随机选择一个下标如：get_cached_bottleneck(sess_mod, training, &quot;apple&quot;, 0)的意思是获取训练集中的苹果的下标为0的图片的瓶颈向量；又如：get_cached_bottleneck(sess_mod, training)的意思是从训练集中随机获取一张图片的瓶颈向量。【训练字典的生成】def fill_feed_dict(sess_mod, image_lists, amount=None): &nbsp; &nbsp; bottlenecks = [] &nbsp; &nbsp; ground_truths = [] &nbsp; &nbsp; this_paths = [] &nbsp; &nbsp; if amount is None: &nbsp; &nbsp; &nbsp; &nbsp; for label in list(image_lists.keys()): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for index, file in enumerate(image_lists[label]): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists, label, index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(amount): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_labels&#39;]: ground_truths, &nbsp; &nbsp; } &nbsp; &nbsp; return feed_dict, this_paths这个函数最终输出一个字典，用于新模型的计算。 &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp;sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp;sess_mod[&#39;placeholder_labels&#39;]: ground_truths,}bottlenecks是图片经过inception-v3的输出，它将作为新模型的输入。sess_mod[&#39;placeholder_input&#39;]是新模型的输出占位张量；sess_mod[&#39;placeholder_labels&#39;]是图片的正确标签——计算瓶颈向量的时候“顺便”生成的。再看amount这个参数：训练的时候用BATCH，评估的时候未指定——等效于None，predict_test()的时候用1，这是为什么呢？原来amount是指明要随机填充的图片数量，当为空时候将填充传入的整个图片列表。predict_test()阶段由于要向用户展示图片，因此每次只填充一张。【运行训练】def run_training(epoch=STEPS): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; n_classes = len(imgs_training.keys()) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; placeholder_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name=&#39;in_images&#39;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, n_classes]) &nbsp; &nbsp; logits = inference(placeholder_input, n_classes) &nbsp; &nbsp; this_loss = loss(logits, placeholder_labels) &nbsp; &nbsp; train_step = training(this_loss, LEARNING_RATE) &nbsp; &nbsp; evaluation_step = evaluation(logits, placeholder_labels) &nbsp; &nbsp; init = tf.global_variables_initializer() &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(init) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: placeholder_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; for step in range(epoch): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_training, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sess.run(train_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if step % 100 == 0 or step + 1 == STEPS: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_validation, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Step %d: Validation accuracy on random sampled %d examples = %.2f%%&quot; % (step, BATCH, accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=fill_feed_dict(sess_mod, imgs_testing)[0]) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; model_save(sess, os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images&quot;, &#39;logits&#39;)这是训练的主干过程，解释完前面的小函数之后，这个函数似乎没有太多需要解释的了，它就是把前介绍的函数调用了一遍！sess_mod的这样封装的原因是sess、m1_input，m1_bottelneck这几个参数经过多层传递最终执行，把它们入在字典中可减少中间函数的参数数量，增加代码的可读性。【图片展示函数片段】while True: &nbsp; &nbsp; this_logits = sess.run(m2_bottleneck, feed_dict=feed_dict) &nbsp; &nbsp; f_tensor, f_index = sess.run([final_tensor, final_index], feed_dict={placeholder_logits: this_logits}) &nbsp; &nbsp; image_path = image_path[0] &nbsp; &nbsp; f_tensor = f_tensor[0] &nbsp; &nbsp; f_index = f_index[0] &nbsp; &nbsp; print(&quot;image_path:&quot;, image_path) &nbsp; &nbsp; print(&quot;f_tensor:&quot;, f_tensor) &nbsp; &nbsp; print(&quot;f_index&quot;, f_index) &nbsp; &nbsp; label_list = list(imgs_testing.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; f_predict = label_list[f_index] &nbsp; &nbsp; print(&quot;f_predict:&quot;, f_predict) &nbsp; &nbsp; img = cv2.imread(image_path) &nbsp; &nbsp; if img is None: &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;File not found:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; img = cv2.resize(img, (500, 500)) &nbsp; &nbsp; cv2.putText(img, os.path.basename(image_path), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1) &nbsp; &nbsp; cv2.putText(img, f_predict, (50, 150), cv2.FONT_HERSHEY_COMPLEX, 3, (255, 0, 255), 5) &nbsp; &nbsp; cv2.imshow(&quot;predict&quot;, img) &nbsp; &nbsp; key = cv2.waitKey() &nbsp; &nbsp; if key &amp; 0xFF == ord(&#39;q&#39;): &nbsp; &nbsp; &nbsp; &nbsp; break &nbsp; &nbsp; elif key &amp; 0xFF == ord(&#39;d&#39;): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;removing:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; os.remove(image_path)用opencv，cv2.imread(): 读取图片；cv2.resize(): 将图片大小调整为500*500，这是因为原图的大小并非统一的，建议读者试试去掉的效果；cv2.putText(): 在图上显示文字；cv2.imshow(): 显示图片；cv2.waitKey(): 等待用户输入: &nbsp; &nbsp;如果用户输入q: 退出循环； &nbsp; &nbsp;如果用户输入d: 删除当前图片，这在剔除错误图片时相当方便【扩展】将model_save()/model_restore()收入ulibs.py中，然后通过以下方式调用:import ulibs ulibs.model_save() &nbsp;ulibs.model_restore()参考：《TensorFlow实战Google尝试学习框架》--郑泽宇 顾思宇 &nbsp;" />
<link rel="canonical" href="https://mlh.app/2019/02/22/f28f7f2b0411ff52857f850eda59d3a7.html" />
<meta property="og:url" content="https://mlh.app/2019/02/22/f28f7f2b0411ff52857f850eda59d3a7.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-22T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"本文是关于如何用谷歌提供的训练好的Inception-v3进行水果图片分类，涉及以下几个内容：下载inception-v3（谷歌训练好的模型）图片数据的下载图片数据的清洗将模型用于图片分类-------------------------------------------------------------------详解：【创建文件】 &nbsp;|--baidu_search.py &nbsp; &nbsp; #通过百度爬取图片 &nbsp;|--ulibs.py &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#用于存放数据清洗等功能函数 &nbsp;|--inception-v3.py &nbsp; &nbsp; &nbsp; # 模型训练函数 &nbsp;|--data/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #存放数据 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--model/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#存放已训练好的模型 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--fruit_photos/ &nbsp; #存放爬取的图片 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--tmp/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #存放临时文件【下载inception-v3】https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip解压后放在./data/model/目录下【下载水果图片】：通过关键字从百度爬取baidu_search.py:# -*- coding: utf-8 -*- &quot;&quot;&quot; Created on Tue Feb 27 11:10:45 2018 @author: mc.meng &quot;&quot;&quot; import re, os import requests from urllib.request import urlretrieve def download1(url, filename, filepath): &nbsp; &nbsp; full_name = os.path.join(filepath, filename) &nbsp; &nbsp; if os.path.exists(full_name): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】文件已经存在：&quot;, full_name) &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; pic = requests.get(url, timeout=5) &nbsp; &nbsp; except: &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;【错误】当前图片无法下载&#39;) &nbsp; &nbsp; &nbsp; &nbsp; return &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; with open(filepath + &quot;/&quot; + filename, &#39;wb&#39;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wf.write(pic.content) &nbsp; &nbsp; except : &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】写入失败&quot;) def download2(url, filename, filepath): &nbsp; &nbsp; full_name = os.path.join(filepath, filename) &nbsp; &nbsp; if os.path.exists(full_name): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】文件已经存在：&quot;, full_name) &nbsp; &nbsp; try: &nbsp; &nbsp; &nbsp; &nbsp; urlretrieve(url, full_name) &nbsp; &nbsp; except: &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;【错误】当前图片无法下载&#39;) def search(word=&quot;美女&quot;, local_path=&quot;./data/down/&quot;, page=None, keep_original_name=True): &nbsp; &nbsp; local_path += word &nbsp; &nbsp; os.makedirs(local_path, exist_ok=True) &nbsp; &nbsp; url = &#39;http://image.baidu.com/search/flip?tn=baiduimage&amp;ie=utf-8&amp;word={word}&amp;pn={pn}&amp;gsm={gsm:x}&amp;ct=&amp;ic=0&amp;lm=-1&amp;width=0&amp;height=0&#39;.format(word=word, pn=20 * page, gsm=40 + 20 * page) &nbsp; &nbsp; print(&quot;HHHC:0====&gt;page=%d,url=\\&quot;%s\\&quot;&quot; % (page,url)) &nbsp; &nbsp; html = requests.get(url).text &nbsp; &nbsp; pic_url = re.findall(&#39;&quot;objURL&quot;:&quot;(.*?)&quot;,&#39;, html, re.S) &nbsp; &nbsp; i = 0 &nbsp; &nbsp; for url in pic_url: &nbsp; &nbsp; &nbsp; &nbsp; print(url) &nbsp; &nbsp; &nbsp; &nbsp; i = i + 1 &nbsp; &nbsp; &nbsp; &nbsp; filename = os.path.split(url)[1].split(&#39;?&#39;)[0] &nbsp; &nbsp; &nbsp; &nbsp; filename_split = filename.split(&#39;.&#39;) &nbsp; &nbsp; &nbsp; &nbsp; if len(filename_split) != 2: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】文件名异常:&quot; + filename) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; #print(&quot;HHHA:0====&gt;&quot;, filename_split[1]) &nbsp; &nbsp; &nbsp; &nbsp; if filename_split[1] != &#39;jpg&#39; and filename_split[1] != &#39;JPG&#39; \\ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; and filename_split[1] != &#39;png&#39; and filename_split[1] != &#39;PNG&#39;: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【错误】类型异常:&quot; + filename) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; if not keep_original_name: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; filename = filename.split(&#39;.&#39;)[0].strip() + &quot;-&quot; + str(page) + &quot;-&quot; + str(i) + &quot;.&quot; + filename.split(&#39;.&#39;)[1].strip() &nbsp; &nbsp; &nbsp; &nbsp; download1(url, filename, local_path) &nbsp; &nbsp; return def search_50_page(word, local_path=&quot;./data/down/&quot;): &nbsp; &nbsp; for i in range(1, 50): &nbsp; &nbsp; &nbsp; &nbsp; search(word, local_path, i) def search_50_page_test(): &nbsp; &nbsp; search_50_page(&quot;美女&quot;) def search_list_test(): &nbsp; &nbsp; obj_list = [&quot;苹果&quot;, &quot;香蕉&quot;, &quot;桔子&quot;, &quot;桃子&quot;, &quot;樱桃&quot;, &quot;龙眼&quot;, &quot;荔枝&quot;] &nbsp; &nbsp; #obj_list = [&quot;苹果&quot;, &quot;香蕉&quot;, &quot;桔子&quot;, &quot;橙子&quot;, &quot;桃子&quot;, &quot;樱桃&quot;, &quot;龙眼&quot;, &quot;荔枝&quot;, &quot;雪梨&quot;, &quot;草莓&quot;, &quot;葡萄&quot;, &quot;猕猴桃&quot;, &quot;菠萝&quot;, &quot;番石榴&quot;, &quot;青梅&quot;] &nbsp; &nbsp; #obj_list = [&quot;菊花&quot;, &quot;蒲公英&quot;, &quot;玫瑰&quot;, &quot;向日葵&quot;, &quot;郁金香&quot;] &nbsp; &nbsp; for obj in obj_list: &nbsp; &nbsp; &nbsp; &nbsp; search_50_page(obj, &quot;./data/fruit_photos/&quot;) if __name__ == &#39;__main__&#39;: &nbsp; &nbsp; search_list_test() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; （PS：源码暗藏福利，但是我不说^V^）等效于按下图步骤把百度图片切换到”传统翻页版“，然后手动把前面50页都下载下来了如果你尝试过手动下载，你就会发现图片中有很多是相同的——文件名和URL都一样。此爬虫在文件保存的时候用原始文件名保存，并在在保存新文件前先判断文件是否存在，这就避免了重复的文件。如果把“苹果”换成“apple&quot;你将看到：这显然不是我们想要的效果——我们今天需要的是水果图片，因此我们先用中文关键字爬取，完了之后再手动把文件夹名改成英文的：【图片统一转成jpg】从百度爬取的图片文件有png、jpg、gpeg等格式，为了方便处理，先把它们统一成jpg(创建ulibs.py用于存放我们的清洗函数):def png_to_jpg(path): &nbsp; &nbsp; &quot;&quot;&quot;convert images into jpg format under the path&quot;&quot;&quot; &nbsp; &nbsp; print(&quot;【消息】将图片转换成jpg&quot;, path) &nbsp; &nbsp; for root, sub_dir, files in os.walk(path): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】进入目录：%s&quot; % root) &nbsp; &nbsp; &nbsp; &nbsp; if root == path or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; for file in files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if file.split(&#39;.&#39;)[1] != &#39;jpg&#39;: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;【消息】不是jpg:&quot;, file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; old_file = os.path.join(root, file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.imread(old_file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_file = os.path.join(root, file.split(&#39;.&#39;)[0] + &quot;.jpg&quot;) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;转换成:&quot;, new_file) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.imwrite(new_file, img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.remove(old_file) &nbsp; &nbsp; print(&quot;【消息】转换完毕&quot;) def png_to_jpg_test(): &nbsp; &nbsp; png_to_jpg(&quot;./data/fruit_photos/&quot;)【手动删除无法预览及明显错误的图片】：【统一命名】：从百度爬取的图片的文件名不统一，很多“%”，长度也参差不齐，为了美观起见我们也把文件名处理一下：类型+编号：def rename_files(path): &nbsp; &nbsp; &quot;&quot;&quot;rename files under path&quot;&quot;&quot; &nbsp; &nbsp; for root, sub_dir, files in os.walk(path): &nbsp; &nbsp; &nbsp; &nbsp; if root == path or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;will rename files under[%s]&quot; % root) &nbsp; &nbsp; &nbsp; &nbsp; count = 1 &nbsp; &nbsp; &nbsp; &nbsp; for file in files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.rename(os.path.join(root, file), os.path.join(root, os.path.basename(root) + &quot;-&quot; + str(count) + &quot;.jpg&quot;)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; count += 1 def rename_files_test(): &nbsp; &nbsp; rename_files(&quot;./data/fruit_photos/&quot;)效果：【将inception-v3用于水果分类】重头戏终于开始了，先上完整代码，然后看效果，然后再详解代码：&#39;&#39;&#39; data: http://download.tensorflow.org/example_images/flower_photos.tgz model: https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip inception-v4: http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz &#39;&#39;&#39; import glob import os.path import random import cv2 import numpy as np import tensorflow as tf from tensorflow.python.platform import gfile from tensorflow.python.framework import graph_util os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; BOTTLENECK_TENSOR_SIZE = 2048 BOTTLENECK_TENSOR_NAME = &#39;pool_3/_reshape:0&#39; JPEG_DATA_TENSOR_NAME = &#39;DecodeJpeg/contents:0&#39; MODEL_DIR = &#39;./data/model/inception_dec_2015&#39; MODEL_FILE = &#39;tensorflow_inception_graph.pb&#39; THIS_MODEL_DIR = &quot;./data/model/inception/&quot; THIS_MODEL_FILE = &quot;inception.pb&quot; CACHE_DIR = &#39;./data/tmp/bottleneck/inception&#39; #INPUT_DATA = &#39;./data/flower_photos&#39; INPUT_DATA = &#39;./data/fruit_photos&#39; INPUT_DATA = &#39;./data/animal_photos&#39; VALIDATION_PERCENTAGE = 10 TEST_PERCENTAGE = 10 LEARNING_RATE = 0.01 STEPS = 1000 BATCH = 100 def create_image_lists(file_dir): &nbsp; &nbsp; training = {} &nbsp; &nbsp; validation = {} &nbsp; &nbsp; testing = {} &nbsp; &nbsp; if not os.path.exists(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Not such path:&quot;, file_dir) &nbsp; &nbsp; &nbsp; &nbsp; return None, None, None &nbsp; &nbsp; for this_dir, sub_dirs, files in os.walk(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; if this_dir == file_dir or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(files) &nbsp; &nbsp; &nbsp; &nbsp; percent10 = int(len(files) * 0.1) &nbsp; &nbsp; &nbsp; &nbsp; this_dir = os.path.basename(this_dir.lower()) &nbsp; &nbsp; &nbsp; &nbsp; training[this_dir] = files[:percent10 * 8] &nbsp; &nbsp; &nbsp; &nbsp; validation[this_dir] = files[percent10 * 8:percent10 * 9] &nbsp; &nbsp; &nbsp; &nbsp; testing[this_dir] = files[percent10 * 9:] &nbsp; &nbsp; return training, validation, testing def get_or_create_bottleneck(sess_mod, image_path): &nbsp; &nbsp; path_seg = image_path.split(&#39;\\\\&#39;) &nbsp; &nbsp; label_name = path_seg[-2] &nbsp; &nbsp; os.makedirs(os.path.join(CACHE_DIR, label_name), exist_ok=True) &nbsp; &nbsp; bottleneck_path = os.path.join(CACHE_DIR, path_seg[-2], path_seg[-1]) + &quot;.txt&quot; &nbsp; &nbsp; if not os.path.exists(bottleneck_path): &nbsp; &nbsp; &nbsp; &nbsp; image_data = gfile.FastGFile(image_path, &#39;rb&#39;).read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data}) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = np.squeeze(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;HHHA:0====&gt;&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; print(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = &#39;,&#39;.join(str(x &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;) for x in bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;w&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_file.write(bottleneck_string) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;r&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = bottleneck_file.read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = [float(x) for x in bottleneck_string.split(&#39;,&#39;)] &nbsp; &nbsp; return bottleneck_values def get_cached_bottleneck(sess_mod, images, label=None, index=None): &nbsp; &nbsp; label_list = list(images.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; if label is None: &nbsp; &nbsp; &nbsp; &nbsp; label = label_list[random.randrange(len(label_list))] &nbsp; &nbsp; if index is None: &nbsp; &nbsp; &nbsp; &nbsp; index = random.randrange(len(images[label])) &nbsp; &nbsp; image_path = os.path.join(INPUT_DATA, label, images[label][index]) &nbsp; &nbsp; bottleneck = get_or_create_bottleneck(sess_mod, image_path) &nbsp; &nbsp; ground_truth = np.zeros(len(label_list), dtype=np.float32) &nbsp; &nbsp; ground_truth[label_list.index(label)] = 1.0 &nbsp; &nbsp; return bottleneck, ground_truth, image_path def fill_feed_dict(sess_mod, image_lists, amount=None): &nbsp; &nbsp; bottlenecks = [] &nbsp; &nbsp; ground_truths = [] &nbsp; &nbsp; this_paths = [] &nbsp; &nbsp; if amount is None: &nbsp; &nbsp; &nbsp; &nbsp; for label in list(image_lists.keys()): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for index, file in enumerate(image_lists[label]): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists, label, index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(amount): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_labels&#39;]: ground_truths, &nbsp; &nbsp; } &nbsp; &nbsp; return feed_dict, this_paths def inference(inputs, n_classes): &nbsp; &nbsp; this_input = tf.reshape(inputs, [-1, BOTTLENECK_TENSOR_SIZE], name=&#39;input_images&#39;) &nbsp; &nbsp; weights = tf.get_variable(&quot;weights&quot;, [BOTTLENECK_TENSOR_SIZE, n_classes], initializer=tf.truncated_normal_initializer(stddev=0.001)) &nbsp; &nbsp; biases = tf.get_variable(&quot;biases&quot;, [n_classes], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; logits = tf.add(tf.matmul(this_input, weights), biases, &quot;logits&quot;) &nbsp; &nbsp; return logits def loss(logits, labels): &nbsp; &nbsp; labels = tf.to_int64(labels) &nbsp; &nbsp; cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels) &nbsp; &nbsp; return tf.reduce_mean(cross_entropy) def training(loss, learning_rate): &nbsp; &nbsp; tf.summary.scalar(&#39;loss&#39;, loss) &nbsp; &nbsp; optimizer = tf.train.GradientDescentOptimizer(learning_rate) &nbsp; &nbsp; global_step = tf.Variable(0, name=&#39;global_step&#39;, trainable=False) &nbsp; &nbsp; train_op = optimizer.minimize(loss, global_step=global_step) &nbsp; &nbsp; return train_op def evaluation(logits, labels): &nbsp; &nbsp; with tf.name_scope(&#39;evaluation&#39;): &nbsp; &nbsp; &nbsp; &nbsp; correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)) &nbsp; &nbsp; &nbsp; &nbsp; evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) &nbsp; &nbsp; &nbsp; &nbsp; return evaluation_step def model_save(sess, model_path, input_tensor_name, bottleneck_tensor_name): &nbsp; &nbsp; graph_def = tf.get_default_graph().as_graph_def() &nbsp; &nbsp; outpput_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, [input_tensor_name, bottleneck_tensor_name]) &nbsp; &nbsp; with tf.gfile.GFile(model_path, &quot;wb&quot;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; wf.write(outpput_graph_def.SerializeToString()) def model_restore(model_path, input_tensor_name, bottleneck_tensor_name): &nbsp; &nbsp; with gfile.FastGFile(model_path, &#39;rb&#39;) as rf: &nbsp; &nbsp; &nbsp; &nbsp; graph_def = tf.GraphDef() &nbsp; &nbsp; &nbsp; &nbsp; graph_def.ParseFromString(rf.read()) &nbsp; &nbsp; in_tensor, out_tensor, &nbsp;= tf.import_graph_def(graph_def, return_elements=[input_tensor_name, bottleneck_tensor_name]) &nbsp; &nbsp; return in_tensor, out_tensor def run_training(epoch=STEPS): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; n_classes = len(imgs_training.keys()) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; placeholder_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name=&#39;in_images&#39;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, n_classes]) &nbsp; &nbsp; logits = inference(placeholder_input, n_classes) &nbsp; &nbsp; this_loss = loss(logits, placeholder_labels) &nbsp; &nbsp; train_step = training(this_loss, LEARNING_RATE) &nbsp; &nbsp; evaluation_step = evaluation(logits, placeholder_labels) &nbsp; &nbsp; init = tf.global_variables_initializer() &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(init) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: placeholder_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; for step in range(epoch): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_training, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sess.run(train_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if step % 100 == 0 or step + 1 == STEPS: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_validation, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Step %d: Validation accuracy on random sampled %d examples = %.2f%%&quot; % (step, BATCH, accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=fill_feed_dict(sess_mod, imgs_testing)[0]) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; model_save(sess, os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images&quot;, &#39;logits&#39;) def predict_test(): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; m2_input, m2_bottleneck = model_restore(os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images:0&quot;, &quot;logits:0&quot;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, len(imgs_training.keys())]) &nbsp; &nbsp; evaluation_step = evaluation(m2_bottleneck, placeholder_labels) &nbsp; &nbsp; placeholder_logits = tf.placeholder(tf.float32, [None, len(imgs_training.keys())]) &nbsp; &nbsp; final_tensor = tf.nn.softmax(placeholder_logits) &nbsp; &nbsp; final_index = tf.argmax(final_tensor, 1) &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(tf.global_variables_initializer()) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: m2_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_testing) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; while True: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_testing, 1) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_logits = sess.run(m2_bottleneck, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_tensor, f_index = sess.run([final_tensor, final_index], feed_dict={placeholder_logits: this_logits}) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image_path = image_path[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_tensor = f_tensor[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_index = f_index[0] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;image_path:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_tensor:&quot;, f_tensor) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_index&quot;, f_index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; label_list = list(imgs_testing.keys()) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_predict = label_list[f_index] &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;f_predict:&quot;, f_predict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.imread(image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if img is None: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;File not found:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.resize(img, (500, 500)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.putText(img, os.path.basename(image_path), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.putText(img, f_predict, (50, 150), cv2.FONT_HERSHEY_COMPLEX, 3, (255, 0, 255), 5) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.imshow(&quot;predict&quot;, img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; key = cv2.waitKey() &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if key &amp; 0xFF == ord(&#39;q&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elif key &amp; 0xFF == ord(&#39;d&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;removing:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.remove(image_path) def main(argv=None): &nbsp; &nbsp; #run_training(STEPS) &nbsp; &nbsp; predict_test() if __name__ == &quot;__main__&quot;: &nbsp; &nbsp; tf.app.run() 运行过程中如果出现错误，一般是图片文件无法打开（文件损坏、原图是gif文件等），直接将其删除就好了。输出：94.2%的准确率，还算不错。【可视化预测结果】主函数修改如下再运行：def main(argv=None): &nbsp; &nbsp; #run_training(500) &nbsp; &nbsp; predict_test()按q键退出，按d键删除当前文件，按其它何意键切换到下一张：【代码详解】：主函数开始：def main(argv=None): &nbsp; &nbsp; run_training(STEPS) &nbsp; &nbsp; #predict_test()可以看出，我们的模型分训练和预测两个阶段： &nbsp; &nbsp;run_training()是将inception-3迁移到我们的水果分类，训练并将保存新模型； &nbsp; &nbsp;predict_test()是使用新模型进行预测，并可视化展示预测结果；【模型保存及恢复】：model_save()、model_restore()分别是保存和恢复模型def model_save(sess, model_path, input_tensor_name, bottelneck_tensor_name): &nbsp; &nbsp; graph_def = tf.get_default_graph().as_graph_def() &nbsp; &nbsp; outpput_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, [input_tensor_name, bottelneck_tensor_name]) &nbsp; &nbsp; with tf.gfile.GFile(model_path, &quot;wb&quot;) as wf: &nbsp; &nbsp; &nbsp; &nbsp; wf.write(outpput_graph_def.SerializeToString()) def model_restore(model_path, input_tensor_name, bottelneck_tensor_name): &nbsp; &nbsp; with gfile.FastGFile(model_path, &#39;rb&#39;) as rf: &nbsp; &nbsp; &nbsp; &nbsp; graph_def = tf.GraphDef() &nbsp; &nbsp; &nbsp; &nbsp; graph_def.ParseFromString(rf.read()) &nbsp; &nbsp; in_tensor, out_tensor, &nbsp;= tf.import_graph_def(graph_def, return_elements=[input_tensor_name, bottelneck_tensor_name]) &nbsp; &nbsp; return in_tensor, out_tensor参数： &nbsp; &nbsp;model_path：指定了模型文件所在的路径； &nbsp; &nbsp;input_tensor_name: &nbsp;模型的输入张量名称； &nbsp; &nbsp;bottelneck_tensor_name: 模型的瓶颈张量； &nbsp; &nbsp;sess: 保存模型时需要传入当前的会话；model_restore()在run_training()和predict_test()中都有使用：在run_training()中是恢复inception-v3模型；而在predict_test()中不仅要恢复inception-v3模型，还要恢复我们刚刚训练好的新模型，因此调用了两次。【四大金刚】：模型、损失、训练、评估def inference(inputs, n_classes): &nbsp; &nbsp; this_input = tf.reshape(inputs, [-1, BOTTLENECK_TENSOR_SIZE], name=&#39;input_images&#39;) &nbsp; &nbsp; weights = tf.get_variable(&quot;weights&quot;, [BOTTLENECK_TENSOR_SIZE, n_classes], initializer=tf.truncated_normal_initializer(stddev=0.001)) &nbsp; &nbsp; biases = tf.get_variable(&quot;biases&quot;, [n_classes], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; logits = tf.add(tf.matmul(this_input, weights), biases, &quot;logits&quot;) &nbsp; &nbsp; return logits def loss(logits, labels): &nbsp; &nbsp; labels = tf.to_int64(labels) &nbsp; &nbsp; cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels) &nbsp; &nbsp; return tf.reduce_mean(cross_entropy) def training(loss, learning_rate): &nbsp; &nbsp; tf.summary.scalar(&#39;loss&#39;, loss) &nbsp; &nbsp; optimizer = tf.train.GradientDescentOptimizer(learning_rate) &nbsp; &nbsp; global_step = tf.Variable(0, name=&#39;global_step&#39;, trainable=False) &nbsp; &nbsp; train_op = optimizer.minimize(loss, global_step=global_step) &nbsp; &nbsp; return train_op def evaluation(logits, labels): &nbsp; &nbsp; with tf.name_scope(&#39;evaluation&#39;): &nbsp; &nbsp; &nbsp; &nbsp; correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1)) &nbsp; &nbsp; &nbsp; &nbsp; evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) &nbsp; &nbsp; &nbsp; &nbsp; return evaluation_step这四个函数都是针对我们的新模型而言： &nbsp; &nbsp;inference: &nbsp;向前传播模型； &nbsp; &nbsp;loss: 损失的计算； &nbsp; &nbsp;training: 通过最小化损失训练模型参数； &nbsp; &nbsp;evaluation: 计算预测的精确度；【瓶颈张量的计算】def create_image_lists(file_dir): &nbsp; &nbsp; training = {} &nbsp; &nbsp; validation = {} &nbsp; &nbsp; testing = {} &nbsp; &nbsp; if not os.path.exists(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Not such path:&quot;, file_dir) &nbsp; &nbsp; &nbsp; &nbsp; return None, None, None &nbsp; &nbsp; for this_dir, sub_dirs, files in os.walk(file_dir): &nbsp; &nbsp; &nbsp; &nbsp; if this_dir == file_dir or not files: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(files) &nbsp; &nbsp; &nbsp; &nbsp; percent10 = int(len(files) * 0.1) &nbsp; &nbsp; &nbsp; &nbsp; this_dir = os.path.basename(this_dir.lower()) &nbsp; &nbsp; &nbsp; &nbsp; training[this_dir] = files[:percent10 * 8] &nbsp; &nbsp; &nbsp; &nbsp; validation[this_dir] = files[percent10 * 8:percent10 * 9] &nbsp; &nbsp; &nbsp; &nbsp; testing[this_dir] = files[percent10 * 9:] &nbsp; &nbsp; return training, validation, testing def get_or_create_bottleneck(sess_mod, image_path): &nbsp; &nbsp; path_seg = image_path.split(&#39;\\\\&#39;) &nbsp; &nbsp; label_name = path_seg[-2] &nbsp; &nbsp; os.makedirs(os.path.join(CACHE_DIR, label_name), exist_ok=True) &nbsp; &nbsp; bottleneck_path = os.path.join(CACHE_DIR, path_seg[-2], path_seg[-1]) + &quot;.txt&quot; &nbsp; &nbsp; if not os.path.exists(bottleneck_path): &nbsp; &nbsp; &nbsp; &nbsp; image_data = gfile.FastGFile(image_path, &#39;rb&#39;).read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data}) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = np.squeeze(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;HHHA:0====&gt;&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; print(bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = &#39;,&#39;.join(str(x &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;) for x in bottleneck_values) &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;w&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_file.write(bottleneck_string) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, &#39;r&#39;) as bottleneck_file: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = bottleneck_file.read() &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = [float(x) for x in bottleneck_string.split(&#39;,&#39;)] &nbsp; &nbsp; return bottleneck_values def get_cached_bottleneck(sess_mod, images, label=None, index=None): &nbsp; &nbsp; label_list = list(images.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; if label is None: &nbsp; &nbsp; &nbsp; &nbsp; label = label_list[random.randrange(len(label_list))] &nbsp; &nbsp; if index is None: &nbsp; &nbsp; &nbsp; &nbsp; index = random.randrange(len(images[label])) &nbsp; &nbsp; image_path = os.path.join(INPUT_DATA, label, images[label][index]) &nbsp; &nbsp; bottleneck = get_or_create_bottleneck(sess_mod, image_path) &nbsp; &nbsp; ground_truth = np.zeros(len(label_list), dtype=np.float32) &nbsp; &nbsp; ground_truth[label_list.index(label)] = 1.0 &nbsp; &nbsp; return bottleneck, ground_truth, image_pathcreate_image_lists()：理解这个函数需要结合我们的目录结构：fruit_photos下面每种水果的图片放在一个以该水果命名的小目录中：参数file_dir传入的将是fruit_photos所在路径。用os.walk遍历这个目录，并按1：1：8的比例把所有图片分割成训练、验证、测试三个数据集，每个数据集都是一个字典：以水果名称为键，以图片名称列表为值。get_or_create_bottleneck():获取或创建瓶颈向量：用指定的模型计算指定图片的瓶颈向量。什么意思呢？具体就是获取图片A经过inception-v3这个模型之后的输出。参数sess_mod是封装了inception-v3的输入、输出、和用于计算的sess：bottleneck_values = sess_mod[&#39;sess&#39;].run(sess_mod[&#39;premod_bottleneck&#39;], feed_dict={sess_mod[&#39;premod_input&#39;]: image_data})可对比tensorflow的经典方式进行理解：sess.run(z, feed_dict={x:a, y:b})计算瓶颈向量比较耗时，为了避免重复计算，把计算结果存放在CACHE_DIR/水果名/中，以图片名.txt命名。每次获取时先尝试从该目录中获取，如果文件不存在，则用模型进行计算并保存。参数image_path指明了给获取哪张图片的瓶颈向量。get_cached_bottleneck():基于get_or_create_bottleneck()的封装，参数： &nbsp; images: 图片列表，也就是create_image_list中分割出来的training, validation, testing三个数据集中的一个； &nbsp; label: 水果名称，如果没有指定，则随机选择一种水果 &nbsp; index: 文件下标，如果没有指定，则随机选择一个下标如：get_cached_bottleneck(sess_mod, training, &quot;apple&quot;, 0)的意思是获取训练集中的苹果的下标为0的图片的瓶颈向量；又如：get_cached_bottleneck(sess_mod, training)的意思是从训练集中随机获取一张图片的瓶颈向量。【训练字典的生成】def fill_feed_dict(sess_mod, image_lists, amount=None): &nbsp; &nbsp; bottlenecks = [] &nbsp; &nbsp; ground_truths = [] &nbsp; &nbsp; this_paths = [] &nbsp; &nbsp; if amount is None: &nbsp; &nbsp; &nbsp; &nbsp; for label in list(image_lists.keys()): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for index, file in enumerate(image_lists[label]): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists, label, index) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(amount): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path) &nbsp; &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp; sess_mod[&#39;placeholder_labels&#39;]: ground_truths, &nbsp; &nbsp; } &nbsp; &nbsp; return feed_dict, this_paths这个函数最终输出一个字典，用于新模型的计算。 &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp;sess_mod[&#39;placeholder_input&#39;]: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp;sess_mod[&#39;placeholder_labels&#39;]: ground_truths,}bottlenecks是图片经过inception-v3的输出，它将作为新模型的输入。sess_mod[&#39;placeholder_input&#39;]是新模型的输出占位张量；sess_mod[&#39;placeholder_labels&#39;]是图片的正确标签——计算瓶颈向量的时候“顺便”生成的。再看amount这个参数：训练的时候用BATCH，评估的时候未指定——等效于None，predict_test()的时候用1，这是为什么呢？原来amount是指明要随机填充的图片数量，当为空时候将填充传入的整个图片列表。predict_test()阶段由于要向用户展示图片，因此每次只填充一张。【运行训练】def run_training(epoch=STEPS): &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA) &nbsp; &nbsp; n_classes = len(imgs_training.keys()) &nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME) &nbsp; &nbsp; placeholder_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name=&#39;in_images&#39;) &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, n_classes]) &nbsp; &nbsp; logits = inference(placeholder_input, n_classes) &nbsp; &nbsp; this_loss = loss(logits, placeholder_labels) &nbsp; &nbsp; train_step = training(this_loss, LEARNING_RATE) &nbsp; &nbsp; evaluation_step = evaluation(logits, placeholder_labels) &nbsp; &nbsp; init = tf.global_variables_initializer() &nbsp; &nbsp; with tf.Session() as sess: &nbsp; &nbsp; &nbsp; &nbsp; sess.run(init) &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = { &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;sess&#39;: sess, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_input&#39;: m1_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;premod_bottleneck&#39;: m1_bottleneck, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_input&#39;: placeholder_input, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &#39;placeholder_labels&#39;: placeholder_labels &nbsp; &nbsp; &nbsp; &nbsp; } &nbsp; &nbsp; &nbsp; &nbsp; for step in range(epoch): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_training, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sess.run(train_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if step % 100 == 0 or step + 1 == STEPS: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_validation, BATCH) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Step %d: Validation accuracy on random sampled %d examples = %.2f%%&quot; % (step, BATCH, accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=fill_feed_dict(sess_mod, imgs_testing)[0]) &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;Final test accuracy = %.1f%%&quot; % (accuracy * 100)) &nbsp; &nbsp; &nbsp; &nbsp; model_save(sess, os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), &quot;in_images&quot;, &#39;logits&#39;)这是训练的主干过程，解释完前面的小函数之后，这个函数似乎没有太多需要解释的了，它就是把前介绍的函数调用了一遍！sess_mod的这样封装的原因是sess、m1_input，m1_bottelneck这几个参数经过多层传递最终执行，把它们入在字典中可减少中间函数的参数数量，增加代码的可读性。【图片展示函数片段】while True: &nbsp; &nbsp; this_logits = sess.run(m2_bottleneck, feed_dict=feed_dict) &nbsp; &nbsp; f_tensor, f_index = sess.run([final_tensor, final_index], feed_dict={placeholder_logits: this_logits}) &nbsp; &nbsp; image_path = image_path[0] &nbsp; &nbsp; f_tensor = f_tensor[0] &nbsp; &nbsp; f_index = f_index[0] &nbsp; &nbsp; print(&quot;image_path:&quot;, image_path) &nbsp; &nbsp; print(&quot;f_tensor:&quot;, f_tensor) &nbsp; &nbsp; print(&quot;f_index&quot;, f_index) &nbsp; &nbsp; label_list = list(imgs_testing.keys()) &nbsp; &nbsp; label_list.sort() &nbsp; &nbsp; f_predict = label_list[f_index] &nbsp; &nbsp; print(&quot;f_predict:&quot;, f_predict) &nbsp; &nbsp; img = cv2.imread(image_path) &nbsp; &nbsp; if img is None: &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;File not found:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; continue &nbsp; &nbsp; img = cv2.resize(img, (500, 500)) &nbsp; &nbsp; cv2.putText(img, os.path.basename(image_path), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1) &nbsp; &nbsp; cv2.putText(img, f_predict, (50, 150), cv2.FONT_HERSHEY_COMPLEX, 3, (255, 0, 255), 5) &nbsp; &nbsp; cv2.imshow(&quot;predict&quot;, img) &nbsp; &nbsp; key = cv2.waitKey() &nbsp; &nbsp; if key &amp; 0xFF == ord(&#39;q&#39;): &nbsp; &nbsp; &nbsp; &nbsp; break &nbsp; &nbsp; elif key &amp; 0xFF == ord(&#39;d&#39;): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;removing:&quot;, image_path) &nbsp; &nbsp; &nbsp; &nbsp; os.remove(image_path)用opencv，cv2.imread(): 读取图片；cv2.resize(): 将图片大小调整为500*500，这是因为原图的大小并非统一的，建议读者试试去掉的效果；cv2.putText(): 在图上显示文字；cv2.imshow(): 显示图片；cv2.waitKey(): 等待用户输入: &nbsp; &nbsp;如果用户输入q: 退出循环； &nbsp; &nbsp;如果用户输入d: 删除当前图片，这在剔除错误图片时相当方便【扩展】将model_save()/model_restore()收入ulibs.py中，然后通过以下方式调用:import ulibs ulibs.model_save() &nbsp;ulibs.model_restore()参考：《TensorFlow实战Google尝试学习框架》--郑泽宇 顾思宇 &nbsp;","@type":"BlogPosting","url":"https://mlh.app/2019/02/22/f28f7f2b0411ff52857f850eda59d3a7.html","headline":"TensorFlow-一种改进的inception-v3迁移学习(图文）","dateModified":"2019-02-22T00:00:00+08:00","datePublished":"2019-02-22T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/02/22/f28f7f2b0411ff52857f850eda59d3a7.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>TensorFlow-一种改进的inception-v3迁移学习(图文）</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>本文是关于如何用谷歌提供的训练好的Inception-v3进行水果图片分类，涉及以下几个内容：下载inception-v3（谷歌训练好的模型）图片数据的下载图片数据的清洗将模型用于图片分类-------------------------------------------------------------------详解：【创建文件】 &nbsp;|--baidu_search.py &nbsp; &nbsp; #通过百度爬取图片 &nbsp;|--ulibs.py &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#用于存放数据清洗等功能函数 &nbsp;|--inception-v3.py &nbsp; &nbsp; &nbsp; # 模型训练函数 &nbsp;|--data/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #存放数据 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--model/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;#存放已训练好的模型 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--fruit_photos/ &nbsp; #存放爬取的图片 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; |--tmp/ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; #存放临时文件【下载inception-v3】https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip解压后放在./data/model/目录下【下载水果图片】：通过关键字从百度爬取baidu_search.py:# -*- coding: utf-8 -*-<br> """<br> Created on Tue Feb 27 11:10:45 2018</p> 
  <p>@author: mc.meng<br> """<br> import re, os<br> import requests<br> from urllib.request import urlretrieve</p> 
  <p><br> def download1(url, filename, filepath):<br> &nbsp; &nbsp; full_name = os.path.join(filepath, filename)<br> &nbsp; &nbsp; if os.path.exists(full_name):<br> &nbsp; &nbsp; &nbsp; &nbsp; print("【消息】文件已经存在：", full_name)<br> &nbsp; &nbsp; try:<br> &nbsp; &nbsp; &nbsp; &nbsp; pic = requests.get(url, timeout=5)<br> &nbsp; &nbsp; except:<br> &nbsp; &nbsp; &nbsp; &nbsp; print('【错误】当前图片无法下载')<br> &nbsp; &nbsp; &nbsp; &nbsp; return<br> &nbsp; &nbsp; try:<br> &nbsp; &nbsp; &nbsp; &nbsp; with open(filepath + "/" + filename, 'wb') as wf:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; wf.write(pic.content)<br> &nbsp; &nbsp; except :<br> &nbsp; &nbsp; &nbsp; &nbsp; print("【错误】写入失败")</p> 
  <p><br> def download2(url, filename, filepath):<br> &nbsp; &nbsp; full_name = os.path.join(filepath, filename)<br> &nbsp; &nbsp; if os.path.exists(full_name):<br> &nbsp; &nbsp; &nbsp; &nbsp; print("【消息】文件已经存在：", full_name)<br> &nbsp; &nbsp; try:<br> &nbsp; &nbsp; &nbsp; &nbsp; urlretrieve(url, full_name)<br> &nbsp; &nbsp; except:<br> &nbsp; &nbsp; &nbsp; &nbsp; print('【错误】当前图片无法下载')</p> 
  <p><br> def search(word="美女", local_path="./data/down/", page=None, keep_original_name=True):<br> &nbsp; &nbsp; local_path += word<br> &nbsp; &nbsp; os.makedirs(local_path, exist_ok=True)<br> &nbsp; &nbsp; url = 'http://image.baidu.com/search/flip?tn=baiduimage&amp;ie=utf-8&amp;word={word}&amp;pn={pn}&amp;gsm={gsm:x}&amp;ct=&amp;ic=0&amp;lm=-1&amp;width=0&amp;height=0'.format(word=word, pn=20 * page, gsm=40 + 20 * page)</p> 
  <p>&nbsp; &nbsp; print("HHHC:0====&gt;page=%d,url=\"%s\"" % (page,url))<br> &nbsp; &nbsp; html = requests.get(url).text<br> &nbsp; &nbsp; pic_url = re.findall('"objURL":"(.*?)",', html, re.S)</p> 
  <p>&nbsp; &nbsp; i = 0<br> &nbsp; &nbsp; for url in pic_url:<br> &nbsp; &nbsp; &nbsp; &nbsp; print(url)<br> &nbsp; &nbsp; &nbsp; &nbsp; i = i + 1<br> &nbsp; &nbsp; &nbsp; &nbsp; filename = os.path.split(url)[1].split('?')[0]<br> &nbsp; &nbsp; &nbsp; &nbsp; filename_split = filename.split('.')<br> &nbsp; &nbsp; &nbsp; &nbsp; if len(filename_split) != 2:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("【错误】文件名异常:" + filename)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue<br> &nbsp; &nbsp; &nbsp; &nbsp; #print("HHHA:0====&gt;", filename_split[1])<br> &nbsp; &nbsp; &nbsp; &nbsp; if filename_split[1] != 'jpg' and filename_split[1] != 'JPG' \<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; and filename_split[1] != 'png' and filename_split[1] != 'PNG':<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("【错误】类型异常:" + filename)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; if not keep_original_name:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; filename = filename.split('.')[0].strip() + "-" + str(page) + "-" + str(i) + "." + filename.split('.')[1].strip()</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; download1(url, filename, local_path)<br> &nbsp; &nbsp; return</p> 
  <p><br> def search_50_page(word, local_path="./data/down/"):<br> &nbsp; &nbsp; for i in range(1, 50):<br> &nbsp; &nbsp; &nbsp; &nbsp; search(word, local_path, i)</p> 
  <p><br> def search_50_page_test():<br> &nbsp; &nbsp; search_50_page("美女")</p> 
  <p><br> def search_list_test():<br> &nbsp; &nbsp; obj_list = ["苹果", "香蕉", "桔子", "桃子", "樱桃", "龙眼", "荔枝"]<br> &nbsp; &nbsp; #obj_list = ["苹果", "香蕉", "桔子", "橙子", "桃子", "樱桃", "龙眼", "荔枝", "雪梨", "草莓", "葡萄", "猕猴桃", "菠萝", "番石榴", "青梅"]<br> &nbsp; &nbsp; #obj_list = ["菊花", "蒲公英", "玫瑰", "向日葵", "郁金香"]<br> &nbsp; &nbsp; for obj in obj_list:<br> &nbsp; &nbsp; &nbsp; &nbsp; search_50_page(obj, "./data/fruit_photos/")</p> 
  <p><br> if __name__ == '__main__':<br> &nbsp; &nbsp; search_list_test()</p> 
  <p>&nbsp;</p> 
  <p><br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; （PS：源码暗藏福利，但是我不说^V^）等效于按下图步骤把百度图片切换到”传统翻页版“，然后手动把前面50页都下载下来了如果你尝试过手动下载，你就会发现图片中有很多是相同的——文件名和URL都一样。此爬虫在文件保存的时候用原始文件名保存，并在在保存新文件前先判断文件是否存在，这就避免了重复的文件。如果把“苹果”换成“apple"你将看到：这显然不是我们想要的效果——我们今天需要的是水果图片，因此我们先用中文关键字爬取，完了之后再手动把文件夹名改成英文的：【图片统一转成jpg】从百度爬取的图片文件有png、jpg、gpeg等格式，为了方便处理，先把它们统一成jpg(创建ulibs.py用于存放我们的清洗函数):def png_to_jpg(path):<br> &nbsp; &nbsp; """convert images into jpg format under the path"""<br> &nbsp; &nbsp; print("【消息】将图片转换成jpg", path)<br> &nbsp; &nbsp; for root, sub_dir, files in os.walk(path):<br> &nbsp; &nbsp; &nbsp; &nbsp; print("【消息】进入目录：%s" % root)<br> &nbsp; &nbsp; &nbsp; &nbsp; if root == path or not files:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; for file in files:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if file.split('.')[1] != 'jpg':<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("【消息】不是jpg:", file)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; old_file = os.path.join(root, file)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.imread(old_file)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; new_file = os.path.join(root, file.split('.')[0] + ".jpg")<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("转换成:", new_file)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.imwrite(new_file, img)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.remove(old_file)<br> &nbsp; &nbsp; print("【消息】转换完毕")</p> 
  <p>def png_to_jpg_test():<br> &nbsp; &nbsp; png_to_jpg("./data/fruit_photos/")【手动删除无法预览及明显错误的图片】：【统一命名】：从百度爬取的图片的文件名不统一，很多“%”，长度也参差不齐，为了美观起见我们也把文件名处理一下：类型+编号：def rename_files(path):<br> &nbsp; &nbsp; """rename files under path"""<br> &nbsp; &nbsp; for root, sub_dir, files in os.walk(path):<br> &nbsp; &nbsp; &nbsp; &nbsp; if root == path or not files:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue<br> &nbsp; &nbsp; &nbsp; &nbsp; print("will rename files under[%s]" % root)<br> &nbsp; &nbsp; &nbsp; &nbsp; count = 1<br> &nbsp; &nbsp; &nbsp; &nbsp; for file in files:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.rename(os.path.join(root, file), os.path.join(root, os.path.basename(root) + "-" + str(count) + ".jpg"))<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; count += 1</p> 
  <p><br> def rename_files_test():<br> &nbsp; &nbsp; rename_files("./data/fruit_photos/")效果：【将inception-v3用于水果分类】重头戏终于开始了，先上完整代码，然后看效果，然后再详解代码：'''<br> data: http://download.tensorflow.org/example_images/flower_photos.tgz<br> model: https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip</p> 
  <p>inception-v4: http://download.tensorflow.org/models/inception_v4_2016_09_09.tar.gz</p> 
  <p>'''<br> import glob<br> import os.path<br> import random<br> import cv2<br> import numpy as np<br> import tensorflow as tf<br> from tensorflow.python.platform import gfile<br> from tensorflow.python.framework import graph_util</p> 
  <p>os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'</p> 
  <p>BOTTLENECK_TENSOR_SIZE = 2048<br> BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'<br> JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'<br> MODEL_DIR = './data/model/inception_dec_2015'<br> MODEL_FILE = 'tensorflow_inception_graph.pb'<br> THIS_MODEL_DIR = "./data/model/inception/"<br> THIS_MODEL_FILE = "inception.pb"<br> CACHE_DIR = './data/tmp/bottleneck/inception'<br> #INPUT_DATA = './data/flower_photos'<br> INPUT_DATA = './data/fruit_photos'<br> INPUT_DATA = './data/animal_photos'<br> VALIDATION_PERCENTAGE = 10<br> TEST_PERCENTAGE = 10<br> LEARNING_RATE = 0.01<br> STEPS = 1000<br> BATCH = 100</p> 
  <p><br> def create_image_lists(file_dir):<br> &nbsp; &nbsp; training = {}<br> &nbsp; &nbsp; validation = {}<br> &nbsp; &nbsp; testing = {}<br> &nbsp; &nbsp; if not os.path.exists(file_dir):<br> &nbsp; &nbsp; &nbsp; &nbsp; print("Not such path:", file_dir)<br> &nbsp; &nbsp; &nbsp; &nbsp; return None, None, None</p> 
  <p>&nbsp; &nbsp; for this_dir, sub_dirs, files in os.walk(file_dir):<br> &nbsp; &nbsp; &nbsp; &nbsp; if this_dir == file_dir or not files:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue<br> &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(files)<br> &nbsp; &nbsp; &nbsp; &nbsp; percent10 = int(len(files) * 0.1)<br> &nbsp; &nbsp; &nbsp; &nbsp; this_dir = os.path.basename(this_dir.lower())<br> &nbsp; &nbsp; &nbsp; &nbsp; training[this_dir] = files[:percent10 * 8]<br> &nbsp; &nbsp; &nbsp; &nbsp; validation[this_dir] = files[percent10 * 8:percent10 * 9]<br> &nbsp; &nbsp; &nbsp; &nbsp; testing[this_dir] = files[percent10 * 9:]<br> &nbsp; &nbsp; return training, validation, testing</p> 
  <p><br> def get_or_create_bottleneck(sess_mod, image_path):<br> &nbsp; &nbsp; path_seg = image_path.split('\\')<br> &nbsp; &nbsp; label_name = path_seg[-2]<br> &nbsp; &nbsp; os.makedirs(os.path.join(CACHE_DIR, label_name), exist_ok=True)<br> &nbsp; &nbsp; bottleneck_path = os.path.join(CACHE_DIR, path_seg[-2], path_seg[-1]) + ".txt"</p> 
  <p>&nbsp; &nbsp; if not os.path.exists(bottleneck_path):<br> &nbsp; &nbsp; &nbsp; &nbsp; image_data = gfile.FastGFile(image_path, 'rb').read()<br> &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = sess_mod['sess'].run(sess_mod['premod_bottleneck'], feed_dict={sess_mod['premod_input']: image_data})<br> &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = np.squeeze(bottleneck_values)<br> &nbsp; &nbsp; &nbsp; &nbsp; print("HHHA:0====&gt;", image_path)<br> &nbsp; &nbsp; &nbsp; &nbsp; print(bottleneck_values)<br> &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = ','.join(str(x<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;) for x in bottleneck_values)<br> &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, 'w') as bottleneck_file:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_file.write(bottleneck_string)<br> &nbsp; &nbsp; else:<br> &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, 'r') as bottleneck_file:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = bottleneck_file.read()<br> &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = [float(x) for x in bottleneck_string.split(',')]<br> &nbsp; &nbsp; return bottleneck_values</p> 
  <p><br> def get_cached_bottleneck(sess_mod, images, label=None, index=None):<br> &nbsp; &nbsp; label_list = list(images.keys())<br> &nbsp; &nbsp; label_list.sort()<br> &nbsp; &nbsp; if label is None:<br> &nbsp; &nbsp; &nbsp; &nbsp; label = label_list[random.randrange(len(label_list))]<br> &nbsp; &nbsp; if index is None:<br> &nbsp; &nbsp; &nbsp; &nbsp; index = random.randrange(len(images[label]))</p> 
  <p>&nbsp; &nbsp; image_path = os.path.join(INPUT_DATA, label, images[label][index])<br> &nbsp; &nbsp; bottleneck = get_or_create_bottleneck(sess_mod, image_path)<br> &nbsp; &nbsp; ground_truth = np.zeros(len(label_list), dtype=np.float32)<br> &nbsp; &nbsp; ground_truth[label_list.index(label)] = 1.0<br> &nbsp; &nbsp; return bottleneck, ground_truth, image_path</p> 
  <p><br> def fill_feed_dict(sess_mod, image_lists, amount=None):<br> &nbsp; &nbsp; bottlenecks = []<br> &nbsp; &nbsp; ground_truths = []<br> &nbsp; &nbsp; this_paths = []<br> &nbsp; &nbsp; if amount is None:<br> &nbsp; &nbsp; &nbsp; &nbsp; for label in list(image_lists.keys()):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for index, file in enumerate(image_lists[label]):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists, label, index)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path)<br> &nbsp; &nbsp; else:<br> &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(amount):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path)</p> 
  <p>&nbsp; &nbsp; feed_dict = {<br> &nbsp; &nbsp; &nbsp; &nbsp; sess_mod['placeholder_input']: bottlenecks,<br> &nbsp; &nbsp; &nbsp; &nbsp; sess_mod['placeholder_labels']: ground_truths,<br> &nbsp; &nbsp; }<br> &nbsp; &nbsp; return feed_dict, this_paths</p> 
  <p><br> def inference(inputs, n_classes):<br> &nbsp; &nbsp; this_input = tf.reshape(inputs, [-1, BOTTLENECK_TENSOR_SIZE], name='input_images')<br> &nbsp; &nbsp; weights = tf.get_variable("weights", [BOTTLENECK_TENSOR_SIZE, n_classes], initializer=tf.truncated_normal_initializer(stddev=0.001))<br> &nbsp; &nbsp; biases = tf.get_variable("biases", [n_classes], initializer=tf.constant_initializer(0.0))<br> &nbsp; &nbsp; logits = tf.add(tf.matmul(this_input, weights), biases, "logits")<br> &nbsp; &nbsp; return logits</p> 
  <p><br> def loss(logits, labels):<br> &nbsp; &nbsp; labels = tf.to_int64(labels)<br> &nbsp; &nbsp; cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)<br> &nbsp; &nbsp; return tf.reduce_mean(cross_entropy)</p> 
  <p><br> def training(loss, learning_rate):<br> &nbsp; &nbsp; tf.summary.scalar('loss', loss)<br> &nbsp; &nbsp; optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br> &nbsp; &nbsp; global_step = tf.Variable(0, name='global_step', trainable=False)<br> &nbsp; &nbsp; train_op = optimizer.minimize(loss, global_step=global_step)<br> &nbsp; &nbsp; return train_op</p> 
  <p><br> def evaluation(logits, labels):<br> &nbsp; &nbsp; with tf.name_scope('evaluation'):<br> &nbsp; &nbsp; &nbsp; &nbsp; correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))<br> &nbsp; &nbsp; &nbsp; &nbsp; evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))<br> &nbsp; &nbsp; &nbsp; &nbsp; return evaluation_step</p> 
  <p><br> def model_save(sess, model_path, input_tensor_name, bottleneck_tensor_name):<br> &nbsp; &nbsp; graph_def = tf.get_default_graph().as_graph_def()<br> &nbsp; &nbsp; outpput_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, [input_tensor_name, bottleneck_tensor_name])</p> 
  <p>&nbsp; &nbsp; with tf.gfile.GFile(model_path, "wb") as wf:<br> &nbsp; &nbsp; &nbsp; &nbsp; wf.write(outpput_graph_def.SerializeToString())</p> 
  <p><br> def model_restore(model_path, input_tensor_name, bottleneck_tensor_name):<br> &nbsp; &nbsp; with gfile.FastGFile(model_path, 'rb') as rf:<br> &nbsp; &nbsp; &nbsp; &nbsp; graph_def = tf.GraphDef()<br> &nbsp; &nbsp; &nbsp; &nbsp; graph_def.ParseFromString(rf.read())</p> 
  <p>&nbsp; &nbsp; in_tensor, out_tensor, &nbsp;= tf.import_graph_def(graph_def, return_elements=[input_tensor_name, bottleneck_tensor_name])<br> &nbsp; &nbsp; return in_tensor, out_tensor</p> 
  <p><br> def run_training(epoch=STEPS):<br> &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA)<br> &nbsp; &nbsp; n_classes = len(imgs_training.keys())</p> 
  <p>&nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME)</p> 
  <p>&nbsp; &nbsp; placeholder_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name='in_images')<br> &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, n_classes])</p> 
  <p>&nbsp; &nbsp; logits = inference(placeholder_input, n_classes)</p> 
  <p>&nbsp; &nbsp; this_loss = loss(logits, placeholder_labels)</p> 
  <p>&nbsp; &nbsp; train_step = training(this_loss, LEARNING_RATE)</p> 
  <p>&nbsp; &nbsp; evaluation_step = evaluation(logits, placeholder_labels)</p> 
  <p>&nbsp; &nbsp; init = tf.global_variables_initializer()</p> 
  <p>&nbsp; &nbsp; with tf.Session() as sess:<br> &nbsp; &nbsp; &nbsp; &nbsp; sess.run(init)<br> &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = {<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'sess': sess,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'premod_input': m1_input,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'premod_bottleneck': m1_bottleneck,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'placeholder_input': placeholder_input,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'placeholder_labels': placeholder_labels<br> &nbsp; &nbsp; &nbsp; &nbsp; }</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; for step in range(epoch):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_training, BATCH)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sess.run(train_step, feed_dict=feed_dict)</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if step % 100 == 0 or step + 1 == STEPS:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_validation, BATCH)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("Step %d: Validation accuracy on random sampled %d examples = %.2f%%" % (step, BATCH, accuracy * 100))</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=fill_feed_dict(sess_mod, imgs_testing)[0])<br> &nbsp; &nbsp; &nbsp; &nbsp; print("Final test accuracy = %.1f%%" % (accuracy * 100))</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; model_save(sess, os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), "in_images", 'logits')</p> 
  <p><br> def predict_test():<br> &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA)</p> 
  <p>&nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME)</p> 
  <p>&nbsp; &nbsp; m2_input, m2_bottleneck = model_restore(os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), "in_images:0", "logits:0")</p> 
  <p>&nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, len(imgs_training.keys())])</p> 
  <p>&nbsp; &nbsp; evaluation_step = evaluation(m2_bottleneck, placeholder_labels)</p> 
  <p>&nbsp; &nbsp; placeholder_logits = tf.placeholder(tf.float32, [None, len(imgs_training.keys())])<br> &nbsp; &nbsp; final_tensor = tf.nn.softmax(placeholder_logits)<br> &nbsp; &nbsp; final_index = tf.argmax(final_tensor, 1)</p> 
  <p>&nbsp; &nbsp; with tf.Session() as sess:<br> &nbsp; &nbsp; &nbsp; &nbsp; sess.run(tf.global_variables_initializer())<br> &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = {<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'sess': sess,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'premod_input': m1_input,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'premod_bottleneck': m1_bottleneck,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'placeholder_input': m2_input,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'placeholder_labels': placeholder_labels<br> &nbsp; &nbsp; &nbsp; &nbsp; }<br> &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_testing)<br> &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict)<br> &nbsp; &nbsp; &nbsp; &nbsp; print("Final test accuracy = %.1f%%" % (accuracy * 100))</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; while True:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_testing, 1)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_logits = sess.run(m2_bottleneck, feed_dict=feed_dict)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_tensor, f_index = sess.run([final_tensor, final_index], feed_dict={placeholder_logits: this_logits})<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; image_path = image_path[0]<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_tensor = f_tensor[0]<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_index = f_index[0]<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("image_path:", image_path)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("f_tensor:", f_tensor)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("f_index", f_index)</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; label_list = list(imgs_testing.keys())<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; label_list.sort()<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; f_predict = label_list[f_index]</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("f_predict:", f_predict)</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.imread(image_path)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if img is None:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("File not found:", image_path)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img = cv2.resize(img, (500, 500))<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.putText(img, os.path.basename(image_path), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.putText(img, f_predict, (50, 150), cv2.FONT_HERSHEY_COMPLEX, 3, (255, 0, 255), 5)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; cv2.imshow("predict", img)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; key = cv2.waitKey()<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if key &amp; 0xFF == ord('q'):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; break<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; elif key &amp; 0xFF == ord('d'):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("removing:", image_path)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; os.remove(image_path)</p> 
  <p><br> def main(argv=None):<br> &nbsp; &nbsp; #run_training(STEPS)<br> &nbsp; &nbsp; predict_test()</p> 
  <p><br> if __name__ == "__main__":<br> &nbsp; &nbsp; tf.app.run()<br> 运行过程中如果出现错误，一般是图片文件无法打开（文件损坏、原图是gif文件等），直接将其删除就好了。输出：94.2%的准确率，还算不错。【可视化预测结果】主函数修改如下再运行：def main(argv=None):<br> &nbsp; &nbsp; #run_training(500)<br> &nbsp; &nbsp; predict_test()按q键退出，按d键删除当前文件，按其它何意键切换到下一张：【代码详解】：主函数开始：def main(argv=None):<br> &nbsp; &nbsp; run_training(STEPS)<br> &nbsp; &nbsp; #predict_test()可以看出，我们的模型分训练和预测两个阶段： &nbsp; &nbsp;run_training()是将inception-3迁移到我们的水果分类，训练并将保存新模型； &nbsp; &nbsp;predict_test()是使用新模型进行预测，并可视化展示预测结果；【模型保存及恢复】：model_save()、model_restore()分别是保存和恢复模型def model_save(sess, model_path, input_tensor_name, bottelneck_tensor_name):<br> &nbsp; &nbsp; graph_def = tf.get_default_graph().as_graph_def()<br> &nbsp; &nbsp; outpput_graph_def = graph_util.convert_variables_to_constants(sess, graph_def, [input_tensor_name, bottelneck_tensor_name])</p> 
  <p>&nbsp; &nbsp; with tf.gfile.GFile(model_path, "wb") as wf:<br> &nbsp; &nbsp; &nbsp; &nbsp; wf.write(outpput_graph_def.SerializeToString())</p> 
  <p><br> def model_restore(model_path, input_tensor_name, bottelneck_tensor_name):<br> &nbsp; &nbsp; with gfile.FastGFile(model_path, 'rb') as rf:<br> &nbsp; &nbsp; &nbsp; &nbsp; graph_def = tf.GraphDef()<br> &nbsp; &nbsp; &nbsp; &nbsp; graph_def.ParseFromString(rf.read())</p> 
  <p>&nbsp; &nbsp; in_tensor, out_tensor, &nbsp;= tf.import_graph_def(graph_def, return_elements=[input_tensor_name, bottelneck_tensor_name])<br> &nbsp; &nbsp; return in_tensor, out_tensor参数： &nbsp; &nbsp;model_path：指定了模型文件所在的路径； &nbsp; &nbsp;input_tensor_name: &nbsp;模型的输入张量名称； &nbsp; &nbsp;bottelneck_tensor_name: 模型的瓶颈张量； &nbsp; &nbsp;sess: 保存模型时需要传入当前的会话；model_restore()在run_training()和predict_test()中都有使用：在run_training()中是恢复inception-v3模型；而在predict_test()中不仅要恢复inception-v3模型，还要恢复我们刚刚训练好的新模型，因此调用了两次。【四大金刚】：模型、损失、训练、评估def inference(inputs, n_classes):<br> &nbsp; &nbsp; this_input = tf.reshape(inputs, [-1, BOTTLENECK_TENSOR_SIZE], name='input_images')<br> &nbsp; &nbsp; weights = tf.get_variable("weights", [BOTTLENECK_TENSOR_SIZE, n_classes], initializer=tf.truncated_normal_initializer(stddev=0.001))<br> &nbsp; &nbsp; biases = tf.get_variable("biases", [n_classes], initializer=tf.constant_initializer(0.0))<br> &nbsp; &nbsp; logits = tf.add(tf.matmul(this_input, weights), biases, "logits")<br> &nbsp; &nbsp; return logits</p> 
  <p><br> def loss(logits, labels):<br> &nbsp; &nbsp; labels = tf.to_int64(labels)<br> &nbsp; &nbsp; cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels)<br> &nbsp; &nbsp; return tf.reduce_mean(cross_entropy)</p> 
  <p><br> def training(loss, learning_rate):<br> &nbsp; &nbsp; tf.summary.scalar('loss', loss)<br> &nbsp; &nbsp; optimizer = tf.train.GradientDescentOptimizer(learning_rate)<br> &nbsp; &nbsp; global_step = tf.Variable(0, name='global_step', trainable=False)<br> &nbsp; &nbsp; train_op = optimizer.minimize(loss, global_step=global_step)<br> &nbsp; &nbsp; return train_op</p> 
  <p><br> def evaluation(logits, labels):<br> &nbsp; &nbsp; with tf.name_scope('evaluation'):<br> &nbsp; &nbsp; &nbsp; &nbsp; correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))<br> &nbsp; &nbsp; &nbsp; &nbsp; evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))<br> &nbsp; &nbsp; &nbsp; &nbsp; return evaluation_step这四个函数都是针对我们的新模型而言： &nbsp; &nbsp;inference: &nbsp;向前传播模型； &nbsp; &nbsp;loss: 损失的计算； &nbsp; &nbsp;training: 通过最小化损失训练模型参数； &nbsp; &nbsp;evaluation: 计算预测的精确度；【瓶颈张量的计算】def create_image_lists(file_dir):<br> &nbsp; &nbsp; training = {}<br> &nbsp; &nbsp; validation = {}<br> &nbsp; &nbsp; testing = {}<br> &nbsp; &nbsp; if not os.path.exists(file_dir):<br> &nbsp; &nbsp; &nbsp; &nbsp; print("Not such path:", file_dir)<br> &nbsp; &nbsp; &nbsp; &nbsp; return None, None, None</p> 
  <p>&nbsp; &nbsp; for this_dir, sub_dirs, files in os.walk(file_dir):<br> &nbsp; &nbsp; &nbsp; &nbsp; if this_dir == file_dir or not files:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; continue<br> &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(files)<br> &nbsp; &nbsp; &nbsp; &nbsp; percent10 = int(len(files) * 0.1)<br> &nbsp; &nbsp; &nbsp; &nbsp; this_dir = os.path.basename(this_dir.lower())<br> &nbsp; &nbsp; &nbsp; &nbsp; training[this_dir] = files[:percent10 * 8]<br> &nbsp; &nbsp; &nbsp; &nbsp; validation[this_dir] = files[percent10 * 8:percent10 * 9]<br> &nbsp; &nbsp; &nbsp; &nbsp; testing[this_dir] = files[percent10 * 9:]<br> &nbsp; &nbsp; return training, validation, testing</p> 
  <p><br> def get_or_create_bottleneck(sess_mod, image_path):<br> &nbsp; &nbsp; path_seg = image_path.split('\\')<br> &nbsp; &nbsp; label_name = path_seg[-2]<br> &nbsp; &nbsp; os.makedirs(os.path.join(CACHE_DIR, label_name), exist_ok=True)<br> &nbsp; &nbsp; bottleneck_path = os.path.join(CACHE_DIR, path_seg[-2], path_seg[-1]) + ".txt"</p> 
  <p>&nbsp; &nbsp; if not os.path.exists(bottleneck_path):<br> &nbsp; &nbsp; &nbsp; &nbsp; image_data = gfile.FastGFile(image_path, 'rb').read()<br> &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = sess_mod['sess'].run(sess_mod['premod_bottleneck'], feed_dict={sess_mod['premod_input']: image_data})<br> &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = np.squeeze(bottleneck_values)<br> &nbsp; &nbsp; &nbsp; &nbsp; print("HHHA:0====&gt;", image_path)<br> &nbsp; &nbsp; &nbsp; &nbsp; print(bottleneck_values)<br> &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = ','.join(str(x<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;) for x in bottleneck_values)<br> &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, 'w') as bottleneck_file:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_file.write(bottleneck_string)<br> &nbsp; &nbsp; else:<br> &nbsp; &nbsp; &nbsp; &nbsp; with open(bottleneck_path, 'r') as bottleneck_file:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_string = bottleneck_file.read()<br> &nbsp; &nbsp; &nbsp; &nbsp; bottleneck_values = [float(x) for x in bottleneck_string.split(',')]<br> &nbsp; &nbsp; return bottleneck_values</p> 
  <p><br> def get_cached_bottleneck(sess_mod, images, label=None, index=None):<br> &nbsp; &nbsp; label_list = list(images.keys())<br> &nbsp; &nbsp; label_list.sort()<br> &nbsp; &nbsp; if label is None:<br> &nbsp; &nbsp; &nbsp; &nbsp; label = label_list[random.randrange(len(label_list))]<br> &nbsp; &nbsp; if index is None:<br> &nbsp; &nbsp; &nbsp; &nbsp; index = random.randrange(len(images[label]))</p> 
  <p>&nbsp; &nbsp; image_path = os.path.join(INPUT_DATA, label, images[label][index])<br> &nbsp; &nbsp; bottleneck = get_or_create_bottleneck(sess_mod, image_path)<br> &nbsp; &nbsp; ground_truth = np.zeros(len(label_list), dtype=np.float32)<br> &nbsp; &nbsp; ground_truth[label_list.index(label)] = 1.0<br> &nbsp; &nbsp; return bottleneck, ground_truth, image_pathcreate_image_lists()：理解这个函数需要结合我们的目录结构：fruit_photos下面每种水果的图片放在一个以该水果命名的小目录中：参数file_dir传入的将是fruit_photos所在路径。用os.walk遍历这个目录，并按1：1：8的比例把所有图片分割成训练、验证、测试三个数据集，每个数据集都是一个字典：以水果名称为键，以图片名称列表为值。get_or_create_bottleneck():获取或创建瓶颈向量：用指定的模型计算指定图片的瓶颈向量。什么意思呢？具体就是获取图片A经过inception-v3这个模型之后的输出。参数sess_mod是封装了inception-v3的输入、输出、和用于计算的sess：bottleneck_values = sess_mod['sess'].run(sess_mod['premod_bottleneck'], feed_dict={sess_mod['premod_input']: image_data})可对比tensorflow的经典方式进行理解：sess.run(z, feed_dict={x:a, y:b})计算瓶颈向量比较耗时，为了避免重复计算，把计算结果存放在CACHE_DIR/水果名/中，以图片名.txt命名。每次获取时先尝试从该目录中获取，如果文件不存在，则用模型进行计算并保存。参数image_path指明了给获取哪张图片的瓶颈向量。get_cached_bottleneck():基于get_or_create_bottleneck()的封装，参数： &nbsp; images: 图片列表，也就是create_image_list中分割出来的training, validation, testing三个数据集中的一个； &nbsp; label: 水果名称，如果没有指定，则随机选择一种水果 &nbsp; index: 文件下标，如果没有指定，则随机选择一个下标如：get_cached_bottleneck(sess_mod, training, "apple", 0)的意思是获取训练集中的苹果的下标为0的图片的瓶颈向量；又如：get_cached_bottleneck(sess_mod, training)的意思是从训练集中随机获取一张图片的瓶颈向量。【训练字典的生成】def fill_feed_dict(sess_mod, image_lists, amount=None):<br> &nbsp; &nbsp; bottlenecks = []<br> &nbsp; &nbsp; ground_truths = []<br> &nbsp; &nbsp; this_paths = []<br> &nbsp; &nbsp; if amount is None:<br> &nbsp; &nbsp; &nbsp; &nbsp; for label in list(image_lists.keys()):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; for index, file in enumerate(image_lists[label]):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists, label, index)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path)<br> &nbsp; &nbsp; else:<br> &nbsp; &nbsp; &nbsp; &nbsp; for _ in range(amount):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottleneck, ground_truth, path = get_cached_bottleneck(sess_mod, image_lists)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; bottlenecks.append(bottleneck)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ground_truths.append(ground_truth)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; this_paths.append(path)</p> 
  <p>&nbsp; &nbsp; feed_dict = {<br> &nbsp; &nbsp; &nbsp; &nbsp; sess_mod['placeholder_input']: bottlenecks,<br> &nbsp; &nbsp; &nbsp; &nbsp; sess_mod['placeholder_labels']: ground_truths,<br> &nbsp; &nbsp; }<br> &nbsp; &nbsp; return feed_dict, this_paths这个函数最终输出一个字典，用于新模型的计算。 &nbsp; feed_dict = { &nbsp; &nbsp; &nbsp; &nbsp;sess_mod['placeholder_input']: bottlenecks, &nbsp; &nbsp; &nbsp; &nbsp;sess_mod['placeholder_labels']: ground_truths,}bottlenecks是图片经过inception-v3的输出，它将作为新模型的输入。sess_mod['placeholder_input']是新模型的输出占位张量；sess_mod['placeholder_labels']是图片的正确标签——计算瓶颈向量的时候“顺便”生成的。再看amount这个参数：训练的时候用BATCH，评估的时候未指定——等效于None，predict_test()的时候用1，这是为什么呢？原来amount是指明要随机填充的图片数量，当为空时候将填充传入的整个图片列表。predict_test()阶段由于要向用户展示图片，因此每次只填充一张。【运行训练】def run_training(epoch=STEPS):<br> &nbsp; &nbsp; imgs_training, imgs_validation, imgs_testing = create_image_lists(INPUT_DATA)<br> &nbsp; &nbsp; n_classes = len(imgs_training.keys())</p> 
  <p>&nbsp; &nbsp; m1_input, m1_bottleneck = model_restore(os.path.join(MODEL_DIR, MODEL_FILE), JPEG_DATA_TENSOR_NAME, BOTTLENECK_TENSOR_NAME)</p> 
  <p>&nbsp; &nbsp; placeholder_input = tf.placeholder(tf.float32, [None, BOTTLENECK_TENSOR_SIZE], name='in_images')<br> &nbsp; &nbsp; placeholder_labels = tf.placeholder(tf.float32, [None, n_classes])</p> 
  <p>&nbsp; &nbsp; logits = inference(placeholder_input, n_classes)</p> 
  <p>&nbsp; &nbsp; this_loss = loss(logits, placeholder_labels)</p> 
  <p>&nbsp; &nbsp; train_step = training(this_loss, LEARNING_RATE)</p> 
  <p>&nbsp; &nbsp; evaluation_step = evaluation(logits, placeholder_labels)</p> 
  <p>&nbsp; &nbsp; init = tf.global_variables_initializer()</p> 
  <p>&nbsp; &nbsp; with tf.Session() as sess:<br> &nbsp; &nbsp; &nbsp; &nbsp; sess.run(init)<br> &nbsp; &nbsp; &nbsp; &nbsp; sess_mod = {<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'sess': sess,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'premod_input': m1_input,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'premod_bottleneck': m1_bottleneck,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'placeholder_input': placeholder_input,<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 'placeholder_labels': placeholder_labels<br> &nbsp; &nbsp; &nbsp; &nbsp; }</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; for step in range(epoch):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_training, BATCH)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; sess.run(train_step, feed_dict=feed_dict)</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; if step % 100 == 0 or step + 1 == STEPS:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; feed_dict, image_path = fill_feed_dict(sess_mod, imgs_validation, BATCH)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=feed_dict)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print("Step %d: Validation accuracy on random sampled %d examples = %.2f%%" % (step, BATCH, accuracy * 100))</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; accuracy = sess.run(evaluation_step, feed_dict=fill_feed_dict(sess_mod, imgs_testing)[0])<br> &nbsp; &nbsp; &nbsp; &nbsp; print("Final test accuracy = %.1f%%" % (accuracy * 100))</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; model_save(sess, os.path.join(THIS_MODEL_DIR, THIS_MODEL_FILE), "in_images", 'logits')这是训练的主干过程，解释完前面的小函数之后，这个函数似乎没有太多需要解释的了，它就是把前介绍的函数调用了一遍！sess_mod的这样封装的原因是sess、m1_input，m1_bottelneck这几个参数经过多层传递最终执行，把它们入在字典中可减少中间函数的参数数量，增加代码的可读性。【图片展示函数片段】while True:<br> &nbsp; &nbsp; this_logits = sess.run(m2_bottleneck, feed_dict=feed_dict)<br> &nbsp; &nbsp; f_tensor, f_index = sess.run([final_tensor, final_index], feed_dict={placeholder_logits: this_logits})<br> &nbsp; &nbsp; image_path = image_path[0]<br> &nbsp; &nbsp; f_tensor = f_tensor[0]<br> &nbsp; &nbsp; f_index = f_index[0]<br> &nbsp; &nbsp; print("image_path:", image_path)<br> &nbsp; &nbsp; print("f_tensor:", f_tensor)<br> &nbsp; &nbsp; print("f_index", f_index)</p> 
  <p>&nbsp; &nbsp; label_list = list(imgs_testing.keys())<br> &nbsp; &nbsp; label_list.sort()<br> &nbsp; &nbsp; f_predict = label_list[f_index]</p> 
  <p>&nbsp; &nbsp; print("f_predict:", f_predict)</p> 
  <p>&nbsp; &nbsp; img = cv2.imread(image_path)<br> &nbsp; &nbsp; if img is None:<br> &nbsp; &nbsp; &nbsp; &nbsp; print("File not found:", image_path)<br> &nbsp; &nbsp; &nbsp; &nbsp; continue<br> &nbsp; &nbsp; img = cv2.resize(img, (500, 500))<br> &nbsp; &nbsp; cv2.putText(img, os.path.basename(image_path), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 1)<br> &nbsp; &nbsp; cv2.putText(img, f_predict, (50, 150), cv2.FONT_HERSHEY_COMPLEX, 3, (255, 0, 255), 5)<br> &nbsp; &nbsp; cv2.imshow("predict", img)<br> &nbsp; &nbsp; key = cv2.waitKey()<br> &nbsp; &nbsp; if key &amp; 0xFF == ord('q'):<br> &nbsp; &nbsp; &nbsp; &nbsp; break<br> &nbsp; &nbsp; elif key &amp; 0xFF == ord('d'):<br> &nbsp; &nbsp; &nbsp; &nbsp; print("removing:", image_path)<br> &nbsp; &nbsp; &nbsp; &nbsp; os.remove(image_path)用opencv，cv2.imread(): 读取图片；cv2.resize(): 将图片大小调整为500*500，这是因为原图的大小并非统一的，建议读者试试去掉的效果；cv2.putText(): 在图上显示文字；cv2.imshow(): 显示图片；cv2.waitKey(): 等待用户输入: &nbsp; &nbsp;如果用户输入q: 退出循环； &nbsp; &nbsp;如果用户输入d: 删除当前图片，这在剔除错误图片时相当方便【扩展】将model_save()/model_restore()收入ulibs.py中，然后通过以下方式调用:import ulibs ulibs.model_save() &nbsp;ulibs.model_restore()参考：《TensorFlow实战Google尝试学习框架》--郑泽宇 顾思宇<br> &nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
