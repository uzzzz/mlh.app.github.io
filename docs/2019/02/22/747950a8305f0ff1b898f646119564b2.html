<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>【个人笔记】迁移学习：tensorflow利用inception_v3模型和retrain实现图像分类训练 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="【个人笔记】迁移学习：tensorflow利用inception_v3模型和retrain实现图像分类训练" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：本文为博主原创文章，转载请注明出处 https://blog.csdn.net/ZeyiRTangent/article/details/87886445 【个人笔记】迁移学习：tensorflow利用inception_v3模型和retrain实现图像分类训练 数据集 这里以Visual Geometry Group Home Page上的动物分类图片为例。 在下载的7000张动物图片中手动挑选了五种分类，分别创建了五个文件夹装入，剩下的6000余张照片丢弃。 注意，文件夹及其内图片的名称全小写，绝对路径名中不能包含中文 文件夹中只需包含图片文件，损坏的图片文件和mat类型的文件都需要去除，可以手动或者利用程序自动去除 inception_v3模型下载 http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz 无需解压 github tensorflow及retrain文件下载 从github上克隆tensorflow的源码和retraining的源码到本地并进行解压缩 在~hub-master\examples\image_retraining中找到retrain.py文件，待会需要定位文件位置 创建文件夹框架 新建一个文件夹，包含如下几个文件（夹） bottleneck文件夹为空 test_images中为检测模型效果的图片文件（在数据集代表的对象范围内），不能从数据集中抽取，需要从网上下载。 data文件夹中包含一个包含images子文件夹的train文件夹，images中放入数据集图片文件夹 下一步，新建retrain.bat批处理文件，内容如下： 下图为即将开始训练时后的文件布局 运行retrain.bat开始训练。到这一步为止会出现一些小错误，比如无法使用指定的本地inception_v3模型，GPU或者tensorflow环境没有配置好等，在百度或者google上全部可以搜索解决 训练结果 通过训练后可以看到在文件夹中产生了output_graph.pb，output_labels等文件 bottleneck文件夹中会产生对应图片分类的文件夹 打开后可以看到每个图片对应一个的txt文件，这是每一张图片在inception_v3模型中除去softmax层的固化模型中计算得到的特征数据，不用理会 output_labels中为标签数据，不用理会 调用模型进行分类检测 调用训练好的.pb文件和output_labels文件，输入准备好的检测文件的路径，检测成果 代码源自学习的网络教程 import tensorflow as tf import os import numpy as np from PIL import Image import matplotlib.pyplot as plt os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; lines = tf.gfile.GFile(r&#39;E:\Python\Tensorflow\retrain\output_labels.txt&#39;).readlines() uid_to_human = {} for uid, line in enumerate(lines): line = line.strip(&#39;\n&#39;) uid_to_human[uid] = line def id_to_string(node_id): if node_id not in uid_to_human: return &#39;&#39; return uid_to_human[node_id] with tf.gfile.FastGFile(r&#39;E:\Python\Tensorflow\retrain\output_graph.pb&#39;, &#39;rb&#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) tf.import_graph_def(graph_def, name=&#39;&#39;) with tf.Session() as sess: softmax_tensor = sess.graph.get_tensor_by_name(&#39;final_result:0&#39;) for root, dirs, files in os.walk(r&#39;E:\Python\Tensorflow\retrain\test_images&#39;): for file in files: image_data = tf.gfile.FastGFile(os.path.join(root, file), &#39;rb&#39;).read() predictions = sess.run(softmax_tensor, {&#39;DecodeJpeg/contents:0&#39;: image_data}) predictions = np.squeeze(predictions) image_path = os.path.join(root, file) print(image_path) img = Image.open(image_path) plt.imshow(img) plt.axis(&#39;off&#39;) plt.show() top_k = predictions.argsort()[::-1] print(top_k) for node_id in top_k: human_string = id_to_string(node_id) score = predictions[node_id] print(&#39;%s (score = %.5f)&#39; % (human_string, score)) print() 检测效果感人，模型训练成功 经验+5" />
<meta property="og:description" content="版权声明：本文为博主原创文章，转载请注明出处 https://blog.csdn.net/ZeyiRTangent/article/details/87886445 【个人笔记】迁移学习：tensorflow利用inception_v3模型和retrain实现图像分类训练 数据集 这里以Visual Geometry Group Home Page上的动物分类图片为例。 在下载的7000张动物图片中手动挑选了五种分类，分别创建了五个文件夹装入，剩下的6000余张照片丢弃。 注意，文件夹及其内图片的名称全小写，绝对路径名中不能包含中文 文件夹中只需包含图片文件，损坏的图片文件和mat类型的文件都需要去除，可以手动或者利用程序自动去除 inception_v3模型下载 http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz 无需解压 github tensorflow及retrain文件下载 从github上克隆tensorflow的源码和retraining的源码到本地并进行解压缩 在~hub-master\examples\image_retraining中找到retrain.py文件，待会需要定位文件位置 创建文件夹框架 新建一个文件夹，包含如下几个文件（夹） bottleneck文件夹为空 test_images中为检测模型效果的图片文件（在数据集代表的对象范围内），不能从数据集中抽取，需要从网上下载。 data文件夹中包含一个包含images子文件夹的train文件夹，images中放入数据集图片文件夹 下一步，新建retrain.bat批处理文件，内容如下： 下图为即将开始训练时后的文件布局 运行retrain.bat开始训练。到这一步为止会出现一些小错误，比如无法使用指定的本地inception_v3模型，GPU或者tensorflow环境没有配置好等，在百度或者google上全部可以搜索解决 训练结果 通过训练后可以看到在文件夹中产生了output_graph.pb，output_labels等文件 bottleneck文件夹中会产生对应图片分类的文件夹 打开后可以看到每个图片对应一个的txt文件，这是每一张图片在inception_v3模型中除去softmax层的固化模型中计算得到的特征数据，不用理会 output_labels中为标签数据，不用理会 调用模型进行分类检测 调用训练好的.pb文件和output_labels文件，输入准备好的检测文件的路径，检测成果 代码源自学习的网络教程 import tensorflow as tf import os import numpy as np from PIL import Image import matplotlib.pyplot as plt os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; lines = tf.gfile.GFile(r&#39;E:\Python\Tensorflow\retrain\output_labels.txt&#39;).readlines() uid_to_human = {} for uid, line in enumerate(lines): line = line.strip(&#39;\n&#39;) uid_to_human[uid] = line def id_to_string(node_id): if node_id not in uid_to_human: return &#39;&#39; return uid_to_human[node_id] with tf.gfile.FastGFile(r&#39;E:\Python\Tensorflow\retrain\output_graph.pb&#39;, &#39;rb&#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) tf.import_graph_def(graph_def, name=&#39;&#39;) with tf.Session() as sess: softmax_tensor = sess.graph.get_tensor_by_name(&#39;final_result:0&#39;) for root, dirs, files in os.walk(r&#39;E:\Python\Tensorflow\retrain\test_images&#39;): for file in files: image_data = tf.gfile.FastGFile(os.path.join(root, file), &#39;rb&#39;).read() predictions = sess.run(softmax_tensor, {&#39;DecodeJpeg/contents:0&#39;: image_data}) predictions = np.squeeze(predictions) image_path = os.path.join(root, file) print(image_path) img = Image.open(image_path) plt.imshow(img) plt.axis(&#39;off&#39;) plt.show() top_k = predictions.argsort()[::-1] print(top_k) for node_id in top_k: human_string = id_to_string(node_id) score = predictions[node_id] print(&#39;%s (score = %.5f)&#39; % (human_string, score)) print() 检测效果感人，模型训练成功 经验+5" />
<link rel="canonical" href="https://mlh.app/2019/02/22/747950a8305f0ff1b898f646119564b2.html" />
<meta property="og:url" content="https://mlh.app/2019/02/22/747950a8305f0ff1b898f646119564b2.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-22T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：本文为博主原创文章，转载请注明出处 https://blog.csdn.net/ZeyiRTangent/article/details/87886445 【个人笔记】迁移学习：tensorflow利用inception_v3模型和retrain实现图像分类训练 数据集 这里以Visual Geometry Group Home Page上的动物分类图片为例。 在下载的7000张动物图片中手动挑选了五种分类，分别创建了五个文件夹装入，剩下的6000余张照片丢弃。 注意，文件夹及其内图片的名称全小写，绝对路径名中不能包含中文 文件夹中只需包含图片文件，损坏的图片文件和mat类型的文件都需要去除，可以手动或者利用程序自动去除 inception_v3模型下载 http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz 无需解压 github tensorflow及retrain文件下载 从github上克隆tensorflow的源码和retraining的源码到本地并进行解压缩 在~hub-master\\examples\\image_retraining中找到retrain.py文件，待会需要定位文件位置 创建文件夹框架 新建一个文件夹，包含如下几个文件（夹） bottleneck文件夹为空 test_images中为检测模型效果的图片文件（在数据集代表的对象范围内），不能从数据集中抽取，需要从网上下载。 data文件夹中包含一个包含images子文件夹的train文件夹，images中放入数据集图片文件夹 下一步，新建retrain.bat批处理文件，内容如下： 下图为即将开始训练时后的文件布局 运行retrain.bat开始训练。到这一步为止会出现一些小错误，比如无法使用指定的本地inception_v3模型，GPU或者tensorflow环境没有配置好等，在百度或者google上全部可以搜索解决 训练结果 通过训练后可以看到在文件夹中产生了output_graph.pb，output_labels等文件 bottleneck文件夹中会产生对应图片分类的文件夹 打开后可以看到每个图片对应一个的txt文件，这是每一张图片在inception_v3模型中除去softmax层的固化模型中计算得到的特征数据，不用理会 output_labels中为标签数据，不用理会 调用模型进行分类检测 调用训练好的.pb文件和output_labels文件，输入准备好的检测文件的路径，检测成果 代码源自学习的网络教程 import tensorflow as tf import os import numpy as np from PIL import Image import matplotlib.pyplot as plt os.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;] = &#39;2&#39; lines = tf.gfile.GFile(r&#39;E:\\Python\\Tensorflow\\retrain\\output_labels.txt&#39;).readlines() uid_to_human = {} for uid, line in enumerate(lines): line = line.strip(&#39;\\n&#39;) uid_to_human[uid] = line def id_to_string(node_id): if node_id not in uid_to_human: return &#39;&#39; return uid_to_human[node_id] with tf.gfile.FastGFile(r&#39;E:\\Python\\Tensorflow\\retrain\\output_graph.pb&#39;, &#39;rb&#39;) as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) tf.import_graph_def(graph_def, name=&#39;&#39;) with tf.Session() as sess: softmax_tensor = sess.graph.get_tensor_by_name(&#39;final_result:0&#39;) for root, dirs, files in os.walk(r&#39;E:\\Python\\Tensorflow\\retrain\\test_images&#39;): for file in files: image_data = tf.gfile.FastGFile(os.path.join(root, file), &#39;rb&#39;).read() predictions = sess.run(softmax_tensor, {&#39;DecodeJpeg/contents:0&#39;: image_data}) predictions = np.squeeze(predictions) image_path = os.path.join(root, file) print(image_path) img = Image.open(image_path) plt.imshow(img) plt.axis(&#39;off&#39;) plt.show() top_k = predictions.argsort()[::-1] print(top_k) for node_id in top_k: human_string = id_to_string(node_id) score = predictions[node_id] print(&#39;%s (score = %.5f)&#39; % (human_string, score)) print() 检测效果感人，模型训练成功 经验+5","@type":"BlogPosting","url":"https://mlh.app/2019/02/22/747950a8305f0ff1b898f646119564b2.html","headline":"【个人笔记】迁移学习：tensorflow利用inception_v3模型和retrain实现图像分类训练","dateModified":"2019-02-22T00:00:00+08:00","datePublished":"2019-02-22T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/02/22/747950a8305f0ff1b898f646119564b2.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>【个人笔记】迁移学习：tensorflow利用inception_v3模型和retrain实现图像分类训练</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：本文为博主原创文章，转载请注明出处 https://blog.csdn.net/ZeyiRTangent/article/details/87886445 
 </div> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h1><a id="tensorflowinception_v3retrain_0"></a>【个人笔记】迁移学习：tensorflow利用inception_v3模型和retrain实现图像分类训练</h1> 
  <h2><a id="_2"></a>数据集</h2> 
  <p>这里以<a href="http://www.robots.ox.ac.uk/~vgg/data/" rel="nofollow">Visual Geometry Group Home Page</a>上的动物分类图片为例。<br> 在下载的7000张动物图片中手动挑选了五种分类，分别创建了五个文件夹装入，剩下的6000余张照片丢弃。<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222220445522.PNG" alt="在这里插入图片描述"><br> 注意，文件夹及其内图片的名称全小写，绝对路径名中不能包含中文<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222220813711.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 文件夹中只需包含图片文件，损坏的图片文件和mat类型的文件都需要去除，可以手动或者利用程序自动去除</p> 
  <h2><a id="inception_v3_9"></a>inception_v3模型下载</h2> 
  <pre><code>http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz
</code></pre> 
  <p>无需解压<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222224056193.png" alt="在这里插入图片描述"></p> 
  <h2><a id="github_tensorflowretrain_16"></a>github tensorflow及retrain文件下载</h2> 
  <p>从github上克隆tensorflow的源码和retraining的源码到本地并进行解压缩<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222221501461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222221812200.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 在<code>~hub-master\examples\image_retraining</code>中找到retrain.py文件，待会需要定位文件位置<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222222104393.png" alt="在这里插入图片描述"></p> 
  <h2><a id="_22"></a>创建文件夹框架</h2> 
  <p>新建一个文件夹，包含如下几个文件（夹）<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222222236884.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> bottleneck文件夹为空<br> test_images中为检测模型效果的图片文件（在数据集代表的对象范围内），不能从数据集中抽取，需要从网上下载。<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/2019022222504753.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p>data文件夹中包含一个包含images子文件夹的train文件夹，images中放入数据集图片文件夹<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222222349585.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 下一步，新建retrain.bat批处理文件，内容如下：<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222223225879.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 下图为即将开始训练时后的文件布局<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222225236375.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 运行retrain.bat开始训练。到这一步为止会出现一些小错误，比如无法使用指定的本地inception_v3模型，GPU或者tensorflow环境没有配置好等，在百度或者google上全部可以搜索解决</p> 
  <h2><a id="_37"></a>训练结果</h2> 
  <p>通过训练后可以看到在文件夹中产生了output_graph.pb，output_labels等文件<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222224751646.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p>bottleneck文件夹中会产生对应图片分类的文件夹<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/2019022222422878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 打开后可以看到每个图片对应一个的txt文件，这是每一张图片在inception_v3模型中除去softmax层的固化模型中计算得到的特征数据，不用理会<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222224440919.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> output_labels中为标签数据，不用理会<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222224611155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_48"></a>调用模型进行分类检测</h2> 
  <p>调用训练好的.pb文件和output_labels文件，输入准备好的检测文件的路径，检测成果<br> 代码源自学习的网络教程</p> 
  <pre><code>import tensorflow as tf
import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

lines = tf.gfile.GFile(r'E:\Python\Tensorflow\retrain\output_labels.txt').readlines()
uid_to_human = {}
for uid, line in enumerate(lines):
    line = line.strip('\n')
    uid_to_human[uid] = line


def id_to_string(node_id):
    if node_id not in uid_to_human:
        return ''
    return uid_to_human[node_id]

with tf.gfile.FastGFile(r'E:\Python\Tensorflow\retrain\output_graph.pb', 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    tf.import_graph_def(graph_def, name='')


with tf.Session() as sess:
    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')
    for root, dirs, files in os.walk(r'E:\Python\Tensorflow\retrain\test_images'):
        for file in files:
            image_data = tf.gfile.FastGFile(os.path.join(root, file), 'rb').read()
            predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data}) 
            predictions = np.squeeze(predictions)  

            image_path = os.path.join(root, file)
            print(image_path)
            img = Image.open(image_path)
            plt.imshow(img)
            plt.axis('off')
            plt.show()

            top_k = predictions.argsort()[::-1]
            print(top_k)
            for node_id in top_k:     
                human_string = id_to_string(node_id)
                score = predictions[node_id]
                print('%s (score = %.5f)' % (human_string, score))
            print()
</code></pre> 
  <p>检测效果感人，模型训练成功<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190222225907240.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1pleWlSVGFuZ2VudA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <em>经验+5</em></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
