<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>什么是end-to-end神经网络？ | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="什么是end-to-end神经网络？" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="来源：知乎 著作权归作者所有。 讨论: 张旭--------------------------------------------------------------------------------------------------------------------&gt; 端到端指的是输入是原始数据，输出是最后的结果，原来输入端不是直接的原始数据，而是在原始数据中提取的特征，这一点在图像问题上尤为突出，因为图像像素数太多，数据维度高，会产生维度灾难，所以原来一个思路是手工提取图像的一些关键特征，这实际就是就一个降维的过程。 那么问题来了，特征怎么提？ 特征提取的好坏异常关键，甚至比学习算法还重要，举个例子，对一系列人的数据分类，分类结果是性别，如果你提取的特征是头发的颜色，无论分类算法如何，分类效果都不会好，如果你提取的特征是头发的长短，这个特征就会好很多，但是还是会有错误，如果你提取了一个超强特征，比如染色体的数据，那你的分类基本就不会错了。 这就意味着，特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难。 于是就出现了端到端网络，特征可以自己去学习，所以特征提取这一步也就融入到算法当中，不需要人来干预了。 &nbsp; YJango------------------------------------------------------------------------------------------------------------------&gt; 经典机器学习方式是以人类的先验知识将raw数据预处理成feature，然后对feature进行分类。分类结果十分取决于feature的好坏。所以过去的机器学习专家将大部分时间花费在设计feature上。那时的机器学习有个更合适的名字叫feature engineering 。 后来人们发现，利用神经网络，让网络自己学习如何抓取feature效果更佳。于是兴起了representation learning。这种方式对数据的拟合更加灵活。 网络进一步加深，多层次概念的representation learning将识别率达到了另一个新高度。于是你听到了是个搞机器学习的人都知道的名字：deep learning。实指多层次的特征提取器与识别器统一训练和预测的网络。 end to end的好处：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到最终输出，给模型更多可以根据数据自动调节的空间，增加模型的整体契合度。 拿语音识别为具体实例。普遍方法是将语音信号转成频域信号，并可以进一步加工成符合人耳特点的MFCC进行编码（encode）。也可以选择Convolutional layers对频谱图进行特征抓取。这样可在encode的部分更接近end to end 中的第一个end。 但识别出的结果并不可以告诉我们这段语音到底是什么。DNN-HMM混合模型还需要将DNN识别出的结果通过HMM来解码（decode）。而RNN-CTC就将HMM的对齐工作交给了网络的output layer来实现。在decode的部分更接近end to end 中的第二个end。 &nbsp; 王赟--------------------------------------------------------------------------------------------------------------------&gt; 我的理解跟@YJango&nbsp;不太一样。我就在语音识别的范围内说说我的理解吧。 传统的语音识别系统，是由许多个模块组成的，包括声学模型、发音词典、语言模型。其中声学模型和语言模型是需要训练的。这些模块的训练一般都是独立进行的，各有各的目标函数，比如声学模型的训练目标是最大化训练语音的概率，语言模型的训练目标是最小化 perplexity。由于各个模块在训练时不能互相取长补短，训练的目标函数又与系统整体的性能指标（一般是词错误率 WER）有偏差，这样训练出的网络往往达不到最优性能。 针对这个问题，一般有两种解决方案： 端到端训练（end-to-end training）：一般指的是在训练好语言模型后，将声学模型和语言模型接在一起，以 WER 或它的一种近似为目标函数去训练声学模型。由于训练声学模型时要计算系统整体的输出，所以称为「端到端」训练。可以看出这种方法并没有彻底解决问题，因为语言模型还是独立训练的。 端到端模型（end-to-end models）：系统中不再有独立的声学模型、发音词典、语言模型等模块，而是从输入端（语音波形或特征序列）到输出端（单词或字符序列）直接用一个神经网络相连，让这个神经网络来承担原先所有模块的功能。典型的代表如使用 CTC 的 EESEN [1]、使用注意力机制的 Listen, Attend and Spell [2]。这种模型非常简洁，但灵活性就差一些：一般来说用于训练语言模型的文本数据比较容易大量获取，但不与语音配对的文本数据无法用于训练端到端的模型。因此，端到端模型也常常再外接一个语言模型，用于在解码时调整候选输出的排名（rescoring），如 [1]。 「端到端训练」和「端到端模型」的区分，在 [2] 的 introduction 部分有比较好的论述。 与&nbsp;@YJango&nbsp;的答案不同，我觉得「输入是语音波形（raw waveform）」并不是端到端模型的本质特征，端到端模型的输入也可以是特征序列（MFCC 等）。端到端模型的本质特征是把声学模型、发音词典、语言模型这些传统模块融合在一起。 参考文献： [1] Yajie Miao, Mohammad Gowayyed, and Florian Metze, &quot;EESEN: End-to-End Speech Recognition using Deep RNN Models and WFST-based Decoding,&quot; in Proc. ASRU 2015. [2] William Chan, et al. &quot;Listen, attend and spell: A neural network for large vocabulary conversational speech recognition,&quot; in Proc. ICASSP 2016. 陈永志--------------------------------------------------------------------------------------------------------------------&gt; 我从目标检测角度来说说我对end-to-end的理解。 非end-to-end方法： 目前目标检测领域，效果最好，影响力最大的还是RCNN那一套框架，这种方法需要先在图像中提取可能含有目标的候选框（region proposal）， 然后将这些候选框输入到CNN模型，让CNN判断候选框中是否真的有目标，以及目标的类别是什么。在我们看到的结果中，往往是类似与下图这种，在整幅图中用矩形框标记目标的位置和大小，并且告诉我们框中的物体是什么。 这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。 end-to-end方法： end-to-end方法的典型代表就是有名的yolo。前面的方法中，CNN本质的作用还是用来分类，定位的功能其并没有做到。而yolo这种方法就是只通过CNN网络，就能够实现目标的定位和识别。也就是原始图像输入到CNN网络中，直接输出图像中所有目标的位置和目标的类别。这种方法就是end-to-end（端对端）的方法，一端输入我的原始图像，一端输出我想得到的结果。只关心输入和输出，中间的步骤全部都不管。 &nbsp; 杨楠----------------------------------------------------------------------------------------------------------------------&gt; end-end在不同应用场景下有不同的具体诠释，对于视觉领域而言，end-end一词多用于基于视觉的机器控制方面，具体表现是，神经网络的输入为原始图片，神经网络的输出为（可以直接控制机器的）控制指令，如： 1. Nvidia的基于CNNs的end-end自动驾驶，输入图片，直接输出steering angle。从视频来看效果拔群，但其实这个系统目前只能做简单的follow lane，与真正的自动驾驶差距较大。亮点是证实了end-end在自动驾驶领域的可行性，并且对于数据集进行了augmentation。链接：https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/ 2. Google的paper: Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection，也可以算是end-end学习：输入图片，输出控制机械手移动的指令来抓取物品。这篇论文很赞，推荐：https://arxiv.org/pdf/1603.02199v4.pdf 3. DeepMind神作Human-level control through deep reinforcement learning，其实也可以归为end-end，深度增强学习开山之作，值得学习：http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html 4. Princeton大学有个Deep Driving项目，介于end-end和传统的model based的自动驾驶之间，输入为图片，输出一些有用的affordance（实在不知道这词怎么翻译合适…）例如车身姿态、与前车距离、距路边距离等，然后利用这些数据通过公式计算所需的具体驾驶指令如加速、刹车、转向等。链接：http://deepdriving.cs.princeton.edu/ 总之，end-end不是什么新东西，也不是什么神奇的东西，仅仅是直接输入原始数据，直接输出最终目标的一种思想。 &nbsp; 胖子不胖-----------------------------------------------------------------------------------------------------------&gt; &nbsp; 其实就是joint learning. end-to-end 的本质是你要解决的问题是多阶段的或多步的(跟所谓的raw feature没啥关系)。如果分阶段学习的话，第一阶段的最优解不能保证第二阶段的问题达到最优。end-to-end把他们堆在一起来优化，确保最后阶段的解达到最优。 &nbsp; 想飞的石头------------------------------------------------------------------------------------------------------&gt; &nbsp; 因为多层神经网络被证明能够耦合任意非线性函数，通过一些配置能让网络去做以前需要人工参与的特征设计这些工作，然后配置合适的功能如classifier,regression，而现在神经网络可以通过配置layers的参数达到这些功能，整个输入到最终输出无需太多人工设置，从raw data 到最终输出指标。 &nbsp;" />
<meta property="og:description" content="来源：知乎 著作权归作者所有。 讨论: 张旭--------------------------------------------------------------------------------------------------------------------&gt; 端到端指的是输入是原始数据，输出是最后的结果，原来输入端不是直接的原始数据，而是在原始数据中提取的特征，这一点在图像问题上尤为突出，因为图像像素数太多，数据维度高，会产生维度灾难，所以原来一个思路是手工提取图像的一些关键特征，这实际就是就一个降维的过程。 那么问题来了，特征怎么提？ 特征提取的好坏异常关键，甚至比学习算法还重要，举个例子，对一系列人的数据分类，分类结果是性别，如果你提取的特征是头发的颜色，无论分类算法如何，分类效果都不会好，如果你提取的特征是头发的长短，这个特征就会好很多，但是还是会有错误，如果你提取了一个超强特征，比如染色体的数据，那你的分类基本就不会错了。 这就意味着，特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难。 于是就出现了端到端网络，特征可以自己去学习，所以特征提取这一步也就融入到算法当中，不需要人来干预了。 &nbsp; YJango------------------------------------------------------------------------------------------------------------------&gt; 经典机器学习方式是以人类的先验知识将raw数据预处理成feature，然后对feature进行分类。分类结果十分取决于feature的好坏。所以过去的机器学习专家将大部分时间花费在设计feature上。那时的机器学习有个更合适的名字叫feature engineering 。 后来人们发现，利用神经网络，让网络自己学习如何抓取feature效果更佳。于是兴起了representation learning。这种方式对数据的拟合更加灵活。 网络进一步加深，多层次概念的representation learning将识别率达到了另一个新高度。于是你听到了是个搞机器学习的人都知道的名字：deep learning。实指多层次的特征提取器与识别器统一训练和预测的网络。 end to end的好处：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到最终输出，给模型更多可以根据数据自动调节的空间，增加模型的整体契合度。 拿语音识别为具体实例。普遍方法是将语音信号转成频域信号，并可以进一步加工成符合人耳特点的MFCC进行编码（encode）。也可以选择Convolutional layers对频谱图进行特征抓取。这样可在encode的部分更接近end to end 中的第一个end。 但识别出的结果并不可以告诉我们这段语音到底是什么。DNN-HMM混合模型还需要将DNN识别出的结果通过HMM来解码（decode）。而RNN-CTC就将HMM的对齐工作交给了网络的output layer来实现。在decode的部分更接近end to end 中的第二个end。 &nbsp; 王赟--------------------------------------------------------------------------------------------------------------------&gt; 我的理解跟@YJango&nbsp;不太一样。我就在语音识别的范围内说说我的理解吧。 传统的语音识别系统，是由许多个模块组成的，包括声学模型、发音词典、语言模型。其中声学模型和语言模型是需要训练的。这些模块的训练一般都是独立进行的，各有各的目标函数，比如声学模型的训练目标是最大化训练语音的概率，语言模型的训练目标是最小化 perplexity。由于各个模块在训练时不能互相取长补短，训练的目标函数又与系统整体的性能指标（一般是词错误率 WER）有偏差，这样训练出的网络往往达不到最优性能。 针对这个问题，一般有两种解决方案： 端到端训练（end-to-end training）：一般指的是在训练好语言模型后，将声学模型和语言模型接在一起，以 WER 或它的一种近似为目标函数去训练声学模型。由于训练声学模型时要计算系统整体的输出，所以称为「端到端」训练。可以看出这种方法并没有彻底解决问题，因为语言模型还是独立训练的。 端到端模型（end-to-end models）：系统中不再有独立的声学模型、发音词典、语言模型等模块，而是从输入端（语音波形或特征序列）到输出端（单词或字符序列）直接用一个神经网络相连，让这个神经网络来承担原先所有模块的功能。典型的代表如使用 CTC 的 EESEN [1]、使用注意力机制的 Listen, Attend and Spell [2]。这种模型非常简洁，但灵活性就差一些：一般来说用于训练语言模型的文本数据比较容易大量获取，但不与语音配对的文本数据无法用于训练端到端的模型。因此，端到端模型也常常再外接一个语言模型，用于在解码时调整候选输出的排名（rescoring），如 [1]。 「端到端训练」和「端到端模型」的区分，在 [2] 的 introduction 部分有比较好的论述。 与&nbsp;@YJango&nbsp;的答案不同，我觉得「输入是语音波形（raw waveform）」并不是端到端模型的本质特征，端到端模型的输入也可以是特征序列（MFCC 等）。端到端模型的本质特征是把声学模型、发音词典、语言模型这些传统模块融合在一起。 参考文献： [1] Yajie Miao, Mohammad Gowayyed, and Florian Metze, &quot;EESEN: End-to-End Speech Recognition using Deep RNN Models and WFST-based Decoding,&quot; in Proc. ASRU 2015. [2] William Chan, et al. &quot;Listen, attend and spell: A neural network for large vocabulary conversational speech recognition,&quot; in Proc. ICASSP 2016. 陈永志--------------------------------------------------------------------------------------------------------------------&gt; 我从目标检测角度来说说我对end-to-end的理解。 非end-to-end方法： 目前目标检测领域，效果最好，影响力最大的还是RCNN那一套框架，这种方法需要先在图像中提取可能含有目标的候选框（region proposal）， 然后将这些候选框输入到CNN模型，让CNN判断候选框中是否真的有目标，以及目标的类别是什么。在我们看到的结果中，往往是类似与下图这种，在整幅图中用矩形框标记目标的位置和大小，并且告诉我们框中的物体是什么。 这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。 end-to-end方法： end-to-end方法的典型代表就是有名的yolo。前面的方法中，CNN本质的作用还是用来分类，定位的功能其并没有做到。而yolo这种方法就是只通过CNN网络，就能够实现目标的定位和识别。也就是原始图像输入到CNN网络中，直接输出图像中所有目标的位置和目标的类别。这种方法就是end-to-end（端对端）的方法，一端输入我的原始图像，一端输出我想得到的结果。只关心输入和输出，中间的步骤全部都不管。 &nbsp; 杨楠----------------------------------------------------------------------------------------------------------------------&gt; end-end在不同应用场景下有不同的具体诠释，对于视觉领域而言，end-end一词多用于基于视觉的机器控制方面，具体表现是，神经网络的输入为原始图片，神经网络的输出为（可以直接控制机器的）控制指令，如： 1. Nvidia的基于CNNs的end-end自动驾驶，输入图片，直接输出steering angle。从视频来看效果拔群，但其实这个系统目前只能做简单的follow lane，与真正的自动驾驶差距较大。亮点是证实了end-end在自动驾驶领域的可行性，并且对于数据集进行了augmentation。链接：https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/ 2. Google的paper: Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection，也可以算是end-end学习：输入图片，输出控制机械手移动的指令来抓取物品。这篇论文很赞，推荐：https://arxiv.org/pdf/1603.02199v4.pdf 3. DeepMind神作Human-level control through deep reinforcement learning，其实也可以归为end-end，深度增强学习开山之作，值得学习：http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html 4. Princeton大学有个Deep Driving项目，介于end-end和传统的model based的自动驾驶之间，输入为图片，输出一些有用的affordance（实在不知道这词怎么翻译合适…）例如车身姿态、与前车距离、距路边距离等，然后利用这些数据通过公式计算所需的具体驾驶指令如加速、刹车、转向等。链接：http://deepdriving.cs.princeton.edu/ 总之，end-end不是什么新东西，也不是什么神奇的东西，仅仅是直接输入原始数据，直接输出最终目标的一种思想。 &nbsp; 胖子不胖-----------------------------------------------------------------------------------------------------------&gt; &nbsp; 其实就是joint learning. end-to-end 的本质是你要解决的问题是多阶段的或多步的(跟所谓的raw feature没啥关系)。如果分阶段学习的话，第一阶段的最优解不能保证第二阶段的问题达到最优。end-to-end把他们堆在一起来优化，确保最后阶段的解达到最优。 &nbsp; 想飞的石头------------------------------------------------------------------------------------------------------&gt; &nbsp; 因为多层神经网络被证明能够耦合任意非线性函数，通过一些配置能让网络去做以前需要人工参与的特征设计这些工作，然后配置合适的功能如classifier,regression，而现在神经网络可以通过配置layers的参数达到这些功能，整个输入到最终输出无需太多人工设置，从raw data 到最终输出指标。 &nbsp;" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-22T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"来源：知乎 著作权归作者所有。 讨论: 张旭--------------------------------------------------------------------------------------------------------------------&gt; 端到端指的是输入是原始数据，输出是最后的结果，原来输入端不是直接的原始数据，而是在原始数据中提取的特征，这一点在图像问题上尤为突出，因为图像像素数太多，数据维度高，会产生维度灾难，所以原来一个思路是手工提取图像的一些关键特征，这实际就是就一个降维的过程。 那么问题来了，特征怎么提？ 特征提取的好坏异常关键，甚至比学习算法还重要，举个例子，对一系列人的数据分类，分类结果是性别，如果你提取的特征是头发的颜色，无论分类算法如何，分类效果都不会好，如果你提取的特征是头发的长短，这个特征就会好很多，但是还是会有错误，如果你提取了一个超强特征，比如染色体的数据，那你的分类基本就不会错了。 这就意味着，特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难。 于是就出现了端到端网络，特征可以自己去学习，所以特征提取这一步也就融入到算法当中，不需要人来干预了。 &nbsp; YJango------------------------------------------------------------------------------------------------------------------&gt; 经典机器学习方式是以人类的先验知识将raw数据预处理成feature，然后对feature进行分类。分类结果十分取决于feature的好坏。所以过去的机器学习专家将大部分时间花费在设计feature上。那时的机器学习有个更合适的名字叫feature engineering 。 后来人们发现，利用神经网络，让网络自己学习如何抓取feature效果更佳。于是兴起了representation learning。这种方式对数据的拟合更加灵活。 网络进一步加深，多层次概念的representation learning将识别率达到了另一个新高度。于是你听到了是个搞机器学习的人都知道的名字：deep learning。实指多层次的特征提取器与识别器统一训练和预测的网络。 end to end的好处：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到最终输出，给模型更多可以根据数据自动调节的空间，增加模型的整体契合度。 拿语音识别为具体实例。普遍方法是将语音信号转成频域信号，并可以进一步加工成符合人耳特点的MFCC进行编码（encode）。也可以选择Convolutional layers对频谱图进行特征抓取。这样可在encode的部分更接近end to end 中的第一个end。 但识别出的结果并不可以告诉我们这段语音到底是什么。DNN-HMM混合模型还需要将DNN识别出的结果通过HMM来解码（decode）。而RNN-CTC就将HMM的对齐工作交给了网络的output layer来实现。在decode的部分更接近end to end 中的第二个end。 &nbsp; 王赟--------------------------------------------------------------------------------------------------------------------&gt; 我的理解跟@YJango&nbsp;不太一样。我就在语音识别的范围内说说我的理解吧。 传统的语音识别系统，是由许多个模块组成的，包括声学模型、发音词典、语言模型。其中声学模型和语言模型是需要训练的。这些模块的训练一般都是独立进行的，各有各的目标函数，比如声学模型的训练目标是最大化训练语音的概率，语言模型的训练目标是最小化 perplexity。由于各个模块在训练时不能互相取长补短，训练的目标函数又与系统整体的性能指标（一般是词错误率 WER）有偏差，这样训练出的网络往往达不到最优性能。 针对这个问题，一般有两种解决方案： 端到端训练（end-to-end training）：一般指的是在训练好语言模型后，将声学模型和语言模型接在一起，以 WER 或它的一种近似为目标函数去训练声学模型。由于训练声学模型时要计算系统整体的输出，所以称为「端到端」训练。可以看出这种方法并没有彻底解决问题，因为语言模型还是独立训练的。 端到端模型（end-to-end models）：系统中不再有独立的声学模型、发音词典、语言模型等模块，而是从输入端（语音波形或特征序列）到输出端（单词或字符序列）直接用一个神经网络相连，让这个神经网络来承担原先所有模块的功能。典型的代表如使用 CTC 的 EESEN [1]、使用注意力机制的 Listen, Attend and Spell [2]。这种模型非常简洁，但灵活性就差一些：一般来说用于训练语言模型的文本数据比较容易大量获取，但不与语音配对的文本数据无法用于训练端到端的模型。因此，端到端模型也常常再外接一个语言模型，用于在解码时调整候选输出的排名（rescoring），如 [1]。 「端到端训练」和「端到端模型」的区分，在 [2] 的 introduction 部分有比较好的论述。 与&nbsp;@YJango&nbsp;的答案不同，我觉得「输入是语音波形（raw waveform）」并不是端到端模型的本质特征，端到端模型的输入也可以是特征序列（MFCC 等）。端到端模型的本质特征是把声学模型、发音词典、语言模型这些传统模块融合在一起。 参考文献： [1] Yajie Miao, Mohammad Gowayyed, and Florian Metze, &quot;EESEN: End-to-End Speech Recognition using Deep RNN Models and WFST-based Decoding,&quot; in Proc. ASRU 2015. [2] William Chan, et al. &quot;Listen, attend and spell: A neural network for large vocabulary conversational speech recognition,&quot; in Proc. ICASSP 2016. 陈永志--------------------------------------------------------------------------------------------------------------------&gt; 我从目标检测角度来说说我对end-to-end的理解。 非end-to-end方法： 目前目标检测领域，效果最好，影响力最大的还是RCNN那一套框架，这种方法需要先在图像中提取可能含有目标的候选框（region proposal）， 然后将这些候选框输入到CNN模型，让CNN判断候选框中是否真的有目标，以及目标的类别是什么。在我们看到的结果中，往往是类似与下图这种，在整幅图中用矩形框标记目标的位置和大小，并且告诉我们框中的物体是什么。 这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。 end-to-end方法： end-to-end方法的典型代表就是有名的yolo。前面的方法中，CNN本质的作用还是用来分类，定位的功能其并没有做到。而yolo这种方法就是只通过CNN网络，就能够实现目标的定位和识别。也就是原始图像输入到CNN网络中，直接输出图像中所有目标的位置和目标的类别。这种方法就是end-to-end（端对端）的方法，一端输入我的原始图像，一端输出我想得到的结果。只关心输入和输出，中间的步骤全部都不管。 &nbsp; 杨楠----------------------------------------------------------------------------------------------------------------------&gt; end-end在不同应用场景下有不同的具体诠释，对于视觉领域而言，end-end一词多用于基于视觉的机器控制方面，具体表现是，神经网络的输入为原始图片，神经网络的输出为（可以直接控制机器的）控制指令，如： 1. Nvidia的基于CNNs的end-end自动驾驶，输入图片，直接输出steering angle。从视频来看效果拔群，但其实这个系统目前只能做简单的follow lane，与真正的自动驾驶差距较大。亮点是证实了end-end在自动驾驶领域的可行性，并且对于数据集进行了augmentation。链接：https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/ 2. Google的paper: Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection，也可以算是end-end学习：输入图片，输出控制机械手移动的指令来抓取物品。这篇论文很赞，推荐：https://arxiv.org/pdf/1603.02199v4.pdf 3. DeepMind神作Human-level control through deep reinforcement learning，其实也可以归为end-end，深度增强学习开山之作，值得学习：http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html 4. Princeton大学有个Deep Driving项目，介于end-end和传统的model based的自动驾驶之间，输入为图片，输出一些有用的affordance（实在不知道这词怎么翻译合适…）例如车身姿态、与前车距离、距路边距离等，然后利用这些数据通过公式计算所需的具体驾驶指令如加速、刹车、转向等。链接：http://deepdriving.cs.princeton.edu/ 总之，end-end不是什么新东西，也不是什么神奇的东西，仅仅是直接输入原始数据，直接输出最终目标的一种思想。 &nbsp; 胖子不胖-----------------------------------------------------------------------------------------------------------&gt; &nbsp; 其实就是joint learning. end-to-end 的本质是你要解决的问题是多阶段的或多步的(跟所谓的raw feature没啥关系)。如果分阶段学习的话，第一阶段的最优解不能保证第二阶段的问题达到最优。end-to-end把他们堆在一起来优化，确保最后阶段的解达到最优。 &nbsp; 想飞的石头------------------------------------------------------------------------------------------------------&gt; &nbsp; 因为多层神经网络被证明能够耦合任意非线性函数，通过一些配置能让网络去做以前需要人工参与的特征设计这些工作，然后配置合适的功能如classifier,regression，而现在神经网络可以通过配置layers的参数达到这些功能，整个输入到最终输出无需太多人工设置，从raw data 到最终输出指标。 &nbsp;","@type":"BlogPosting","url":"/2019/02/22/c2ceba394a3486ccda78fe4c0e113626.html","headline":"什么是end-to-end神经网络？","dateModified":"2019-02-22T00:00:00+08:00","datePublished":"2019-02-22T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/02/22/c2ceba394a3486ccda78fe4c0e113626.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>什么是end-to-end神经网络？</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>来源：<a href="http://www.zhihu.com/question/51435499" rel="nofollow">知乎</a><br> 著作权归作者所有。</p> 
  <p>讨论:</p> 
  <p>张旭--------------------------------------------------------------------------------------------------------------------&gt;</p> 
  <p>端到端指的是输入是原始数据，输出是最后的结果，原来输入端不是直接的原始数据，而是在原始数据中提取的特征，这一点在图像问题上尤为突出，因为图像像素数太多，数据维度高，会产生维度灾难，所以原来一个思路是手工提取图像的一些关键特征，这实际就是就一个降维的过程。<br> 那么问题来了，特征怎么提？<br> 特征提取的好坏异常关键，甚至比学习算法还重要，举个例子，对一系列人的数据分类，分类结果是性别，如果你提取的特征是头发的颜色，无论分类算法如何，分类效果都不会好，如果你提取的特征是头发的长短，这个特征就会好很多，但是还是会有错误，如果你提取了一个超强特征，比如染色体的数据，那你的分类基本就不会错了。<br> 这就意味着，特征需要足够的经验去设计，这在数据量越来越大的情况下也越来越困难。<br> 于是就出现了端到端网络，特征可以自己去学习，所以特征提取这一步也就融入到算法当中，不需要人来干预了。</p> 
  <p>&nbsp;</p> 
  <p>YJango------------------------------------------------------------------------------------------------------------------&gt;</p> 
  <p><img alt="" class="has" src="https://pic2.zhimg.com/v2-a7d48bb680b24da6567baf87ee259595_b.png" width="579"><br> 经典机器学习方式是以人类的先验知识将raw数据预处理成feature，然后对feature进行分类。分类结果十分取决于feature的好坏。所以过去的机器学习专家将大部分时间花费在设计feature上。那时的机器学习有个更合适的名字叫feature engineering 。<br><br> 后来人们发现，利用神经网络，让网络自己学习如何抓取feature效果更佳。于是兴起了representation learning。这种方式对数据的拟合更加灵活。<br><br> 网络进一步加深，多层次概念的representation learning将识别率达到了另一个新高度。于是你听到了是个搞机器学习的人都知道的名字：deep learning。实指多层次的特征提取器与识别器统一训练和预测的网络。<br><br> end to end的好处：通过缩减人工预处理和后续处理，尽可能使模型从原始输入到最终输出，给模型更多可以根据数据自动调节的空间，增加模型的整体契合度。<br><br> 拿语音识别为具体实例。普遍方法是将语音信号转成频域信号，并可以进一步加工成符合人耳特点的MFCC进行编码（encode）。也可以选择Convolutional layers对频谱图进行特征抓取。这样可在encode的部分更接近end to end 中的第一个end。<br><br> 但识别出的结果并不可以告诉我们这段语音到底是什么。DNN-HMM混合模型还需要将DNN识别出的结果通过HMM来解码（decode）。而RNN-CTC就将HMM的对齐工作交给了网络的output layer来实现。在decode的部分更接近end to end 中的第二个end。</p> 
  <p>&nbsp;</p> 
  <p>王赟--------------------------------------------------------------------------------------------------------------------&gt;<br><br> 我的理解跟<a href="http://www.zhihu.com/people/4eedf55cf1de9f94173b352f9c5a8d2b" rel="nofollow">@YJango</a>&nbsp;不太一样。我就在语音识别的范围内说说我的理解吧。<br><br> 传统的语音识别系统，是由许多个模块组成的，包括声学模型、发音词典、语言模型。其中声学模型和语言模型是需要训练的。这些模块的训练一般都是独立进行的，各有各的目标函数，比如声学模型的训练目标是最大化训练语音的概率，语言模型的训练目标是最小化 perplexity。由于各个模块在训练时不能互相取长补短，训练的目标函数又与系统整体的性能指标（一般是词错误率 WER）有偏差，这样训练出的网络往往达不到最优性能。<br><br> 针对这个问题，一般有两种解决方案：</p> 
  <ul>
   <li>端到端训练（end-to-end training）：一般指的是在训练好语言模型后，将声学模型和语言模型接在一起，以 WER 或它的一种近似为目标函数去训练声学模型。由于训练声学模型时要计算系统整体的输出，所以称为「端到端」训练。可以看出这种方法并没有彻底解决问题，因为语言模型还是独立训练的。</li> 
   <li>端到端模型（end-to-end models）：系统中不再有独立的声学模型、发音词典、语言模型等模块，而是从输入端（语音波形或特征序列）到输出端（单词或字符序列）直接用一个神经网络相连，让这个神经网络来承担原先所有模块的功能。典型的代表如使用 CTC 的 EESEN [1]、使用注意力机制的 Listen, Attend and Spell [2]。这种模型非常简洁，但灵活性就差一些：一般来说用于训练语言模型的文本数据比较容易大量获取，但不与语音配对的文本数据无法用于训练端到端的模型。因此，端到端模型也常常再外接一个语言模型，用于在解码时调整候选输出的排名（rescoring），如 [1]。</li> 
  </ul>
  <p>「端到端训练」和「端到端模型」的区分，在 [2] 的 introduction 部分有比较好的论述。<br><br> 与&nbsp;<a href="http://www.zhihu.com/people/4eedf55cf1de9f94173b352f9c5a8d2b" rel="nofollow">@YJango</a>&nbsp;的答案不同，我觉得「输入是语音波形（raw waveform）」并不是端到端模型的本质特征，端到端模型的输入也可以是特征序列（MFCC 等）。端到端模型的本质特征是把声学模型、发音词典、语言模型这些传统模块融合在一起。<br><br> 参考文献：<br> [1] Yajie Miao, Mohammad Gowayyed, and Florian Metze, "EESEN: End-to-End Speech Recognition using Deep RNN Models and WFST-based Decoding," in Proc. ASRU 2015.<br> [2] William Chan, et al. "Listen, attend and spell: A neural network for large vocabulary conversational speech recognition," in Proc. ICASSP 2016.</p> 
  <p>陈永志--------------------------------------------------------------------------------------------------------------------&gt;</p> 
  <p>我从目标检测角度来说说我对end-to-end的理解。<br><br> 非end-to-end方法：<br> 目前目标检测领域，效果最好，影响力最大的还是RCNN那一套框架，这种方法需要先在图像中提取可能含有目标的候选框（region proposal）， 然后将这些候选框输入到CNN模型，让CNN判断候选框中是否真的有目标，以及目标的类别是什么。在我们看到的结果中，往往是类似与下图这种，在整幅图中用矩形框标记目标的位置和大小，并且告诉我们框中的物体是什么。<br> 这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。<img alt="" class="has" src="https://pic3.zhimg.com/v2-f4e390056c5efc696a14791eae34218a_b.png" width="640">这种标记的过程，其实是有两部分组成，一是目标所在位置及大小，二是目标的类别。在整个算法中，目标位置和大小其实是包含在region proposal的过程里，而类别的判定则是在CNN中来判定的。<br><br> end-to-end方法：<br> end-to-end方法的典型代表就是有名的yolo。前面的方法中，CNN本质的作用还是用来分类，定位的功能其并没有做到。而yolo这种方法就是只通过CNN网络，就能够实现目标的定位和识别。也就是原始图像输入到CNN网络中，直接输出图像中所有目标的位置和目标的类别。这种方法就是end-to-end（端对端）的方法，一端输入我的原始图像，一端输出我想得到的结果。只关心输入和输出，中间的步骤全部都不管。</p> 
  <p>&nbsp;</p> 
  <p>杨楠----------------------------------------------------------------------------------------------------------------------&gt;</p> 
  <p>end-end在不同应用场景下有不同的具体诠释，对于视觉领域而言，end-end一词多用于基于视觉的机器控制方面，具体表现是，神经网络的输入为原始图片，神经网络的输出为（可以直接控制机器的）控制指令，如：<br><br> 1. Nvidia的基于CNNs的end-end自动驾驶，输入图片，直接输出steering angle。从视频来看效果拔群，但其实这个系统目前只能做简单的follow lane，与真正的自动驾驶差距较大。亮点是证实了end-end在自动驾驶领域的可行性，并且对于数据集进行了augmentation。链接：<a href="http://link.zhihu.com/?target=https%3A//devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/" rel="nofollow">https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars/</a><br><br> 2. Google的paper: Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection，也可以算是end-end学习：输入图片，输出控制机械手移动的指令来抓取物品。这篇论文很赞，推荐：<a href="http://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1603.02199v4.pdf" rel="nofollow">https://arxiv.org/pdf/1603.02199v4.pdf</a><br><br> 3. DeepMind神作Human-level control through deep reinforcement learning，其实也可以归为end-end，深度增强学习开山之作，值得学习：<a href="http://link.zhihu.com/?target=http%3A//www.nature.com/nature/journal/v518/n7540/full/nature14236.html" rel="nofollow">http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html</a><br><br> 4. Princeton大学有个Deep Driving项目，介于end-end和传统的model based的自动驾驶之间，输入为图片，输出一些有用的affordance（实在不知道这词怎么翻译合适…）例如车身姿态、与前车距离、距路边距离等，然后利用这些数据通过公式计算所需的具体驾驶指令如加速、刹车、转向等。链接：<a href="http://link.zhihu.com/?target=http%3A//deepdriving.cs.princeton.edu/" rel="nofollow">http://deepdriving.cs.princeton.edu/</a><br><br> 总之，end-end不是什么新东西，也不是什么神奇的东西，仅仅是直接输入原始数据，直接输出最终目标的一种思想。</p> 
  <p>&nbsp;</p> 
  <p>胖子不胖-----------------------------------------------------------------------------------------------------------&gt;</p> 
  <p>&nbsp;</p> 
  <p>其实就是joint learning.<br><br> end-to-end 的本质是你要解决的问题是多阶段的或多步的(跟所谓的raw feature没啥关系)。如果分阶段学习的话，第一阶段的最优解不能保证第二阶段的问题达到最优。end-to-end把他们堆在一起来优化，确保最后阶段的解达到最优。</p> 
  <p>&nbsp;</p> 
  <p>想飞的石头------------------------------------------------------------------------------------------------------&gt;</p> 
  <p>&nbsp;</p> 
  <p>因为多层神经网络被证明能够耦合任意非线性函数，通过一些配置能让网络去做以前需要人工参与的特征设计这些工作，然后配置合适的功能如classifier,regression，而现在神经网络可以通过配置layers的参数达到这些功能，整个输入到最终输出无需太多人工设置，从raw data 到最终输出指标。</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
