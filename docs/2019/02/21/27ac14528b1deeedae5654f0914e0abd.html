<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>TensorFlow之迁移学习CNN图像分类及模型保存与调用 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="TensorFlow之迁移学习CNN图像分类及模型保存与调用" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="本文主要通过CNN进行花卉的分类，训练结束保存模型，最后通过调用模型，输入花卉的图片通过模型来进行类别的预测。 &nbsp; &nbsp; &nbsp; &nbsp;测试平台：win 10+tensorflow 1.2 &nbsp; &nbsp; &nbsp; &nbsp;数据集：http://download.tensorflow.org/example_images/flower_photos.tgz &nbsp; &nbsp; &nbsp; &nbsp;数据集中总共有五种花，分别放在五个文件夹下。 &nbsp; &nbsp; &nbsp; &nbsp;一、CNN训练模型 &nbsp; &nbsp; &nbsp; &nbsp;模型尺寸分析：卷积层全都采用了补0，所以经过卷积层长和宽不变，只有深度加深。池化层全都没有补0，所以经过池化层长和宽均减小，深度不变。 &nbsp; &nbsp; &nbsp; &nbsp;模型尺寸变化：100×100×3-&gt;100×100×32-&gt;50×50×32-&gt;50×50×64-&gt;25×25×64-&gt;25×25×128-&gt;12×12×128-&gt;12×12×128-&gt;6×6×128 &nbsp; &nbsp; &nbsp; &nbsp;CNN训练代码如下： &nbsp; from skimage import io,transform import glob import os import tensorflow as tf import numpy as np import time #数据集地址 path=&#39;E:/data/datasets/flower_photos/&#39; #模型保存地址 model_path=&#39;E:/data/model/flower/model.ckpt&#39; #将所有的图片resize成100*100 w=100 h=100 c=3 #读取图片 def read_img(path): &nbsp; &nbsp; cate=[path+x for x in os.listdir(path) if os.path.isdir(path+x)] &nbsp; &nbsp; imgs=[] &nbsp; &nbsp; labels=[] &nbsp; &nbsp; for idx,folder in enumerate(cate): &nbsp; &nbsp; &nbsp; &nbsp; for im in glob.glob(folder+&#39;/*.jpg&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;reading the images:%s&#39;%(im)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img=io.imread(im) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img=transform.resize(img,(w,h)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imgs.append(img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; labels.append(idx) &nbsp; &nbsp; return np.asarray(imgs,np.float32),np.asarray(labels,np.int32) data,label=read_img(path) #打乱顺序 num_example=data.shape[0] arr=np.arange(num_example) np.random.shuffle(arr) data=data[arr] label=label[arr] #将所有数据分为训练集和验证集 ratio=0.8 s=np.int(num_example*ratio) x_train=data[:s] y_train=label[:s] x_val=data[s:] y_val=label[s:] #-----------------构建网络---------------------- #占位符 x=tf.placeholder(tf.float32,shape=[None,w,h,c],name=&#39;x&#39;) y_=tf.placeholder(tf.int32,shape=[None,],name=&#39;y_&#39;) def inference(input_tensor, train, regularizer): &nbsp; &nbsp; with tf.variable_scope(&#39;layer1-conv1&#39;): &nbsp; &nbsp; &nbsp; &nbsp; conv1_weights = tf.get_variable(&quot;weight&quot;,[5,5,3,32],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv1_biases = tf.get_variable(&quot;bias&quot;, [32], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv1 = tf.nn.conv2d(input_tensor, conv1_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer2-pool1&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool1 = tf.nn.max_pool(relu1, ksize = [1,2,2,1],strides=[1,2,2,1],padding=&quot;VALID&quot;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer3-conv2&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv2_weights = tf.get_variable(&quot;weight&quot;,[5,5,32,64],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv2_biases = tf.get_variable(&quot;bias&quot;, [64], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer4-pool2&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer5-conv3&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv3_weights = tf.get_variable(&quot;weight&quot;,[3,3,64,128],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv3_biases = tf.get_variable(&quot;bias&quot;, [128], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv3 = tf.nn.conv2d(pool2, conv3_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer6-pool3&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool3 = tf.nn.max_pool(relu3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer7-conv4&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv4_weights = tf.get_variable(&quot;weight&quot;,[3,3,128,128],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv4_biases = tf.get_variable(&quot;bias&quot;, [128], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv4 = tf.nn.conv2d(pool3, conv4_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu4 = tf.nn.relu(tf.nn.bias_add(conv4, conv4_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer8-pool4&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool4 = tf.nn.max_pool(relu4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; &nbsp; &nbsp; nodes = 6*6*128 &nbsp; &nbsp; &nbsp; &nbsp; reshaped = tf.reshape(pool4,[-1,nodes]) &nbsp; &nbsp; with tf.variable_scope(&#39;layer9-fc1&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc1_weights = tf.get_variable(&quot;weight&quot;, [nodes, 1024], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc1_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc1_biases = tf.get_variable(&quot;bias&quot;, [1024], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_weights) + fc1_biases) &nbsp; &nbsp; &nbsp; &nbsp; if train: fc1 = tf.nn.dropout(fc1, 0.5) &nbsp; &nbsp; with tf.variable_scope(&#39;layer10-fc2&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc2_weights = tf.get_variable(&quot;weight&quot;, [1024, 512], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc2_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc2_biases = tf.get_variable(&quot;bias&quot;, [512], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; fc2 = tf.nn.relu(tf.matmul(fc1, fc2_weights) + fc2_biases) &nbsp; &nbsp; &nbsp; &nbsp; if train: fc2 = tf.nn.dropout(fc2, 0.5) &nbsp; &nbsp; with tf.variable_scope(&#39;layer11-fc3&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc3_weights = tf.get_variable(&quot;weight&quot;, [512, 5], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc3_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc3_biases = tf.get_variable(&quot;bias&quot;, [5], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; logit = tf.matmul(fc2, fc3_weights) + fc3_biases &nbsp; &nbsp; return logit #---------------------------网络结束--------------------------- regularizer = tf.contrib.layers.l2_regularizer(0.0001) logits = inference(x,False,regularizer) #(小处理)将logits乘以1赋值给logits_eval，定义name，方便在后续调用模型时通过tensor名字调用输出tensor b = tf.constant(value=1,dtype=tf.float32) logits_eval = tf.multiply(logits,b,name=&#39;logits_eval&#39;)&nbsp; loss=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_) train_op=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) correct_prediction = tf.equal(tf.cast(tf.argmax(logits,1),tf.int32), y_) &nbsp; &nbsp; acc= tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #定义一个函数，按批次取数据 def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False): &nbsp; &nbsp; assert len(inputs) == len(targets) &nbsp; &nbsp; if shuffle: &nbsp; &nbsp; &nbsp; &nbsp; indices = np.arange(len(inputs)) &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(indices) &nbsp; &nbsp; for start_idx in range(0, len(inputs) - batch_size + 1, batch_size): &nbsp; &nbsp; &nbsp; &nbsp; if shuffle: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; excerpt = indices[start_idx:start_idx + batch_size] &nbsp; &nbsp; &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; excerpt = slice(start_idx, start_idx + batch_size) &nbsp; &nbsp; &nbsp; &nbsp; yield inputs[excerpt], targets[excerpt] #训练和测试数据，可将n_epoch设置更大一些 n_epoch=10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; batch_size=64 saver=tf.train.Saver() sess=tf.Session() &nbsp; sess.run(tf.global_variables_initializer()) for epoch in range(n_epoch): &nbsp; &nbsp; start_time = time.time() &nbsp; &nbsp; #training &nbsp; &nbsp; train_loss, train_acc, n_batch = 0, 0, 0 &nbsp; &nbsp; for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True): &nbsp; &nbsp; &nbsp; &nbsp; _,err,ac=sess.run([train_op,loss,acc], feed_dict={x: x_train_a, y_: y_train_a}) &nbsp; &nbsp; &nbsp; &nbsp; train_loss += err; train_acc += ac; n_batch += 1 &nbsp; &nbsp; print(&quot; &nbsp; train loss: %f&quot; % (np.sum(train_loss)/ n_batch)) &nbsp; &nbsp; print(&quot; &nbsp; train acc: %f&quot; % (np.sum(train_acc)/ n_batch)) &nbsp; &nbsp; #validation &nbsp; &nbsp; val_loss, val_acc, n_batch = 0, 0, 0 &nbsp; &nbsp; for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False): &nbsp; &nbsp; &nbsp; &nbsp; err, ac = sess.run([loss,acc], feed_dict={x: x_val_a, y_: y_val_a}) &nbsp; &nbsp; &nbsp; &nbsp; val_loss += err; val_acc += ac; n_batch += 1 &nbsp; &nbsp; print(&quot; &nbsp; validation loss: %f&quot; % (np.sum(val_loss)/ n_batch)) &nbsp; &nbsp; print(&quot; &nbsp; validation acc: %f&quot; % (np.sum(val_acc)/ n_batch)) saver.save(sess,model_path) sess.close()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177 &nbsp; &nbsp; &nbsp; &nbsp;二、调用模型进行预测 &nbsp; &nbsp; &nbsp; &nbsp;调用模型进行花卉的预测，代码如下： &nbsp; from skimage import io,transform import tensorflow as tf import numpy as np path1 = &quot;E:/data/datasets/flower_photos/daisy/5547758_eea9edfd54_n.jpg&quot; path2 = &quot;E:/data/datasets/flower_photos/dandelion/7355522_b66e5d3078_m.jpg&quot; path3 = &quot;E:/data/datasets/flower_photos/roses/394990940_7af082cf8d_n.jpg&quot; path4 = &quot;E:/data/datasets/flower_photos/sunflowers/6953297_8576bf4ea3.jpg&quot; path5 = &quot;E:/data/datasets/flower_photos/tulips/10791227_7168491604.jpg&quot; flower_dict = {0:&#39;dasiy&#39;,1:&#39;dandelion&#39;,2:&#39;roses&#39;,3:&#39;sunflowers&#39;,4:&#39;tulips&#39;} w=100 h=100 c=3 def read_one_image(path): &nbsp; &nbsp; img = io.imread(path) &nbsp; &nbsp; img = transform.resize(img,(w,h)) &nbsp; &nbsp; return np.asarray(img) with tf.Session() as sess: &nbsp; &nbsp; data = [] &nbsp; &nbsp; data1 = read_one_image(path1) &nbsp; &nbsp; data2 = read_one_image(path2) &nbsp; &nbsp; data3 = read_one_image(path3) &nbsp; &nbsp; data4 = read_one_image(path4) &nbsp; &nbsp; data5 = read_one_image(path5) &nbsp; &nbsp; data.append(data1) &nbsp; &nbsp; data.append(data2) &nbsp; &nbsp; data.append(data3) &nbsp; &nbsp; data.append(data4) &nbsp; &nbsp; data.append(data5) &nbsp; &nbsp; saver = tf.train.import_meta_graph(&#39;E:/data/model/flower/model.ckpt.meta&#39;) &nbsp; &nbsp; saver.restore(sess,tf.train.latest_checkpoint(&#39;E:/data/model/flower/&#39;)) &nbsp; &nbsp; graph = tf.get_default_graph() &nbsp; &nbsp; x = graph.get_tensor_by_name(&quot;x:0&quot;) &nbsp; &nbsp; feed_dict = {x:data} &nbsp; &nbsp; logits = graph.get_tensor_by_name(&quot;logits_eval:0&quot;) &nbsp; &nbsp; classification_result = sess.run(logits,feed_dict) &nbsp; &nbsp; #打印出预测矩阵 &nbsp; &nbsp; print(classification_result) &nbsp; &nbsp; #打印出预测矩阵每一行最大值的索引 &nbsp; &nbsp; print(tf.argmax(classification_result,1).eval()) &nbsp; &nbsp; #根据索引通过字典对应花的分类 &nbsp; &nbsp; output = [] &nbsp; &nbsp; output = tf.argmax(classification_result,1).eval() &nbsp; &nbsp; for i in range(len(output)): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;第&quot;,i+1,&quot;朵花预测:&quot;+flower_dict[output[i]]) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 &nbsp; &nbsp; &nbsp; &nbsp;运行结果： &nbsp; [[ &nbsp;5.76620245 &nbsp; 3.18228579 &nbsp;-3.89464641 &nbsp;-2.81310582 &nbsp; 1.40294015] &nbsp;[ -1.01490593 &nbsp; 3.55570269 &nbsp;-2.76053429 &nbsp; 2.93104005 &nbsp;-3.47138596] &nbsp;[ -8.05292606 &nbsp;-7.26499033 &nbsp;11.70479774 &nbsp; 0.59627819 &nbsp; 2.15948296] &nbsp;[ -5.12940931 &nbsp; 2.18423128 &nbsp;-3.33257103 &nbsp; 9.0591135 &nbsp; &nbsp;5.03963232] &nbsp;[ -4.25288343 &nbsp;-0.95963973 &nbsp;-2.33347392 &nbsp; 1.54485476 &nbsp; 5.76069307]] [0 1 2 3 4] 第 1 朵花预测:dasiy 第 2 朵花预测:dandelion 第 3 朵花预测:roses 第 4 朵花预测:sunflowers 第 5 朵花预测:tulips1234567891011 &nbsp; &nbsp; &nbsp; &nbsp;预测结果和调用模型代码中的五个路径相比较是完全准确的。 &nbsp; &nbsp; &nbsp; &nbsp;本文的模型对于花卉的分类准确率大概在70%左右，采用迁移学习调用Inception-v3模型对本文中的花卉数据集分类准确率在95%左右。主要的原因在于本文的CNN模型较于简单，而且花卉数据集本身就比mnist手写数字数据集分类难度就要大一点，同样的模型在mnist手写数字的识别上准确率要比花卉数据集准确率高不少。 &nbsp; &nbsp; &nbsp; &nbsp;本文的CNN模型完全可以通过增大模型复杂度或者改参数调试以及对图像进行预处理来提高准确率，但本文只是想记录一下最近的学习，这已经足够了。 &nbsp; &nbsp; &nbsp; &nbsp;参考博客：http://www.cnblogs.com/denny402/p/6931338.html ---------------------&nbsp; 作者：Enchanted_ZhouH&nbsp; 来源：CSDN&nbsp; 原文：https://blog.csdn.net/Enchanted_ZhouH/article/details/74116823&nbsp; 版权声明：本文为博主原创文章，转载请附上博文链接！" />
<meta property="og:description" content="本文主要通过CNN进行花卉的分类，训练结束保存模型，最后通过调用模型，输入花卉的图片通过模型来进行类别的预测。 &nbsp; &nbsp; &nbsp; &nbsp;测试平台：win 10+tensorflow 1.2 &nbsp; &nbsp; &nbsp; &nbsp;数据集：http://download.tensorflow.org/example_images/flower_photos.tgz &nbsp; &nbsp; &nbsp; &nbsp;数据集中总共有五种花，分别放在五个文件夹下。 &nbsp; &nbsp; &nbsp; &nbsp;一、CNN训练模型 &nbsp; &nbsp; &nbsp; &nbsp;模型尺寸分析：卷积层全都采用了补0，所以经过卷积层长和宽不变，只有深度加深。池化层全都没有补0，所以经过池化层长和宽均减小，深度不变。 &nbsp; &nbsp; &nbsp; &nbsp;模型尺寸变化：100×100×3-&gt;100×100×32-&gt;50×50×32-&gt;50×50×64-&gt;25×25×64-&gt;25×25×128-&gt;12×12×128-&gt;12×12×128-&gt;6×6×128 &nbsp; &nbsp; &nbsp; &nbsp;CNN训练代码如下： &nbsp; from skimage import io,transform import glob import os import tensorflow as tf import numpy as np import time #数据集地址 path=&#39;E:/data/datasets/flower_photos/&#39; #模型保存地址 model_path=&#39;E:/data/model/flower/model.ckpt&#39; #将所有的图片resize成100*100 w=100 h=100 c=3 #读取图片 def read_img(path): &nbsp; &nbsp; cate=[path+x for x in os.listdir(path) if os.path.isdir(path+x)] &nbsp; &nbsp; imgs=[] &nbsp; &nbsp; labels=[] &nbsp; &nbsp; for idx,folder in enumerate(cate): &nbsp; &nbsp; &nbsp; &nbsp; for im in glob.glob(folder+&#39;/*.jpg&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;reading the images:%s&#39;%(im)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img=io.imread(im) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img=transform.resize(img,(w,h)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imgs.append(img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; labels.append(idx) &nbsp; &nbsp; return np.asarray(imgs,np.float32),np.asarray(labels,np.int32) data,label=read_img(path) #打乱顺序 num_example=data.shape[0] arr=np.arange(num_example) np.random.shuffle(arr) data=data[arr] label=label[arr] #将所有数据分为训练集和验证集 ratio=0.8 s=np.int(num_example*ratio) x_train=data[:s] y_train=label[:s] x_val=data[s:] y_val=label[s:] #-----------------构建网络---------------------- #占位符 x=tf.placeholder(tf.float32,shape=[None,w,h,c],name=&#39;x&#39;) y_=tf.placeholder(tf.int32,shape=[None,],name=&#39;y_&#39;) def inference(input_tensor, train, regularizer): &nbsp; &nbsp; with tf.variable_scope(&#39;layer1-conv1&#39;): &nbsp; &nbsp; &nbsp; &nbsp; conv1_weights = tf.get_variable(&quot;weight&quot;,[5,5,3,32],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv1_biases = tf.get_variable(&quot;bias&quot;, [32], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv1 = tf.nn.conv2d(input_tensor, conv1_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer2-pool1&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool1 = tf.nn.max_pool(relu1, ksize = [1,2,2,1],strides=[1,2,2,1],padding=&quot;VALID&quot;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer3-conv2&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv2_weights = tf.get_variable(&quot;weight&quot;,[5,5,32,64],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv2_biases = tf.get_variable(&quot;bias&quot;, [64], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer4-pool2&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer5-conv3&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv3_weights = tf.get_variable(&quot;weight&quot;,[3,3,64,128],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv3_biases = tf.get_variable(&quot;bias&quot;, [128], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv3 = tf.nn.conv2d(pool2, conv3_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer6-pool3&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool3 = tf.nn.max_pool(relu3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer7-conv4&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv4_weights = tf.get_variable(&quot;weight&quot;,[3,3,128,128],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv4_biases = tf.get_variable(&quot;bias&quot;, [128], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv4 = tf.nn.conv2d(pool3, conv4_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu4 = tf.nn.relu(tf.nn.bias_add(conv4, conv4_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer8-pool4&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool4 = tf.nn.max_pool(relu4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; &nbsp; &nbsp; nodes = 6*6*128 &nbsp; &nbsp; &nbsp; &nbsp; reshaped = tf.reshape(pool4,[-1,nodes]) &nbsp; &nbsp; with tf.variable_scope(&#39;layer9-fc1&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc1_weights = tf.get_variable(&quot;weight&quot;, [nodes, 1024], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc1_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc1_biases = tf.get_variable(&quot;bias&quot;, [1024], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_weights) + fc1_biases) &nbsp; &nbsp; &nbsp; &nbsp; if train: fc1 = tf.nn.dropout(fc1, 0.5) &nbsp; &nbsp; with tf.variable_scope(&#39;layer10-fc2&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc2_weights = tf.get_variable(&quot;weight&quot;, [1024, 512], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc2_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc2_biases = tf.get_variable(&quot;bias&quot;, [512], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; fc2 = tf.nn.relu(tf.matmul(fc1, fc2_weights) + fc2_biases) &nbsp; &nbsp; &nbsp; &nbsp; if train: fc2 = tf.nn.dropout(fc2, 0.5) &nbsp; &nbsp; with tf.variable_scope(&#39;layer11-fc3&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc3_weights = tf.get_variable(&quot;weight&quot;, [512, 5], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc3_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc3_biases = tf.get_variable(&quot;bias&quot;, [5], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; logit = tf.matmul(fc2, fc3_weights) + fc3_biases &nbsp; &nbsp; return logit #---------------------------网络结束--------------------------- regularizer = tf.contrib.layers.l2_regularizer(0.0001) logits = inference(x,False,regularizer) #(小处理)将logits乘以1赋值给logits_eval，定义name，方便在后续调用模型时通过tensor名字调用输出tensor b = tf.constant(value=1,dtype=tf.float32) logits_eval = tf.multiply(logits,b,name=&#39;logits_eval&#39;)&nbsp; loss=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_) train_op=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) correct_prediction = tf.equal(tf.cast(tf.argmax(logits,1),tf.int32), y_) &nbsp; &nbsp; acc= tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #定义一个函数，按批次取数据 def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False): &nbsp; &nbsp; assert len(inputs) == len(targets) &nbsp; &nbsp; if shuffle: &nbsp; &nbsp; &nbsp; &nbsp; indices = np.arange(len(inputs)) &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(indices) &nbsp; &nbsp; for start_idx in range(0, len(inputs) - batch_size + 1, batch_size): &nbsp; &nbsp; &nbsp; &nbsp; if shuffle: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; excerpt = indices[start_idx:start_idx + batch_size] &nbsp; &nbsp; &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; excerpt = slice(start_idx, start_idx + batch_size) &nbsp; &nbsp; &nbsp; &nbsp; yield inputs[excerpt], targets[excerpt] #训练和测试数据，可将n_epoch设置更大一些 n_epoch=10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; batch_size=64 saver=tf.train.Saver() sess=tf.Session() &nbsp; sess.run(tf.global_variables_initializer()) for epoch in range(n_epoch): &nbsp; &nbsp; start_time = time.time() &nbsp; &nbsp; #training &nbsp; &nbsp; train_loss, train_acc, n_batch = 0, 0, 0 &nbsp; &nbsp; for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True): &nbsp; &nbsp; &nbsp; &nbsp; _,err,ac=sess.run([train_op,loss,acc], feed_dict={x: x_train_a, y_: y_train_a}) &nbsp; &nbsp; &nbsp; &nbsp; train_loss += err; train_acc += ac; n_batch += 1 &nbsp; &nbsp; print(&quot; &nbsp; train loss: %f&quot; % (np.sum(train_loss)/ n_batch)) &nbsp; &nbsp; print(&quot; &nbsp; train acc: %f&quot; % (np.sum(train_acc)/ n_batch)) &nbsp; &nbsp; #validation &nbsp; &nbsp; val_loss, val_acc, n_batch = 0, 0, 0 &nbsp; &nbsp; for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False): &nbsp; &nbsp; &nbsp; &nbsp; err, ac = sess.run([loss,acc], feed_dict={x: x_val_a, y_: y_val_a}) &nbsp; &nbsp; &nbsp; &nbsp; val_loss += err; val_acc += ac; n_batch += 1 &nbsp; &nbsp; print(&quot; &nbsp; validation loss: %f&quot; % (np.sum(val_loss)/ n_batch)) &nbsp; &nbsp; print(&quot; &nbsp; validation acc: %f&quot; % (np.sum(val_acc)/ n_batch)) saver.save(sess,model_path) sess.close()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177 &nbsp; &nbsp; &nbsp; &nbsp;二、调用模型进行预测 &nbsp; &nbsp; &nbsp; &nbsp;调用模型进行花卉的预测，代码如下： &nbsp; from skimage import io,transform import tensorflow as tf import numpy as np path1 = &quot;E:/data/datasets/flower_photos/daisy/5547758_eea9edfd54_n.jpg&quot; path2 = &quot;E:/data/datasets/flower_photos/dandelion/7355522_b66e5d3078_m.jpg&quot; path3 = &quot;E:/data/datasets/flower_photos/roses/394990940_7af082cf8d_n.jpg&quot; path4 = &quot;E:/data/datasets/flower_photos/sunflowers/6953297_8576bf4ea3.jpg&quot; path5 = &quot;E:/data/datasets/flower_photos/tulips/10791227_7168491604.jpg&quot; flower_dict = {0:&#39;dasiy&#39;,1:&#39;dandelion&#39;,2:&#39;roses&#39;,3:&#39;sunflowers&#39;,4:&#39;tulips&#39;} w=100 h=100 c=3 def read_one_image(path): &nbsp; &nbsp; img = io.imread(path) &nbsp; &nbsp; img = transform.resize(img,(w,h)) &nbsp; &nbsp; return np.asarray(img) with tf.Session() as sess: &nbsp; &nbsp; data = [] &nbsp; &nbsp; data1 = read_one_image(path1) &nbsp; &nbsp; data2 = read_one_image(path2) &nbsp; &nbsp; data3 = read_one_image(path3) &nbsp; &nbsp; data4 = read_one_image(path4) &nbsp; &nbsp; data5 = read_one_image(path5) &nbsp; &nbsp; data.append(data1) &nbsp; &nbsp; data.append(data2) &nbsp; &nbsp; data.append(data3) &nbsp; &nbsp; data.append(data4) &nbsp; &nbsp; data.append(data5) &nbsp; &nbsp; saver = tf.train.import_meta_graph(&#39;E:/data/model/flower/model.ckpt.meta&#39;) &nbsp; &nbsp; saver.restore(sess,tf.train.latest_checkpoint(&#39;E:/data/model/flower/&#39;)) &nbsp; &nbsp; graph = tf.get_default_graph() &nbsp; &nbsp; x = graph.get_tensor_by_name(&quot;x:0&quot;) &nbsp; &nbsp; feed_dict = {x:data} &nbsp; &nbsp; logits = graph.get_tensor_by_name(&quot;logits_eval:0&quot;) &nbsp; &nbsp; classification_result = sess.run(logits,feed_dict) &nbsp; &nbsp; #打印出预测矩阵 &nbsp; &nbsp; print(classification_result) &nbsp; &nbsp; #打印出预测矩阵每一行最大值的索引 &nbsp; &nbsp; print(tf.argmax(classification_result,1).eval()) &nbsp; &nbsp; #根据索引通过字典对应花的分类 &nbsp; &nbsp; output = [] &nbsp; &nbsp; output = tf.argmax(classification_result,1).eval() &nbsp; &nbsp; for i in range(len(output)): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;第&quot;,i+1,&quot;朵花预测:&quot;+flower_dict[output[i]]) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 &nbsp; &nbsp; &nbsp; &nbsp;运行结果： &nbsp; [[ &nbsp;5.76620245 &nbsp; 3.18228579 &nbsp;-3.89464641 &nbsp;-2.81310582 &nbsp; 1.40294015] &nbsp;[ -1.01490593 &nbsp; 3.55570269 &nbsp;-2.76053429 &nbsp; 2.93104005 &nbsp;-3.47138596] &nbsp;[ -8.05292606 &nbsp;-7.26499033 &nbsp;11.70479774 &nbsp; 0.59627819 &nbsp; 2.15948296] &nbsp;[ -5.12940931 &nbsp; 2.18423128 &nbsp;-3.33257103 &nbsp; 9.0591135 &nbsp; &nbsp;5.03963232] &nbsp;[ -4.25288343 &nbsp;-0.95963973 &nbsp;-2.33347392 &nbsp; 1.54485476 &nbsp; 5.76069307]] [0 1 2 3 4] 第 1 朵花预测:dasiy 第 2 朵花预测:dandelion 第 3 朵花预测:roses 第 4 朵花预测:sunflowers 第 5 朵花预测:tulips1234567891011 &nbsp; &nbsp; &nbsp; &nbsp;预测结果和调用模型代码中的五个路径相比较是完全准确的。 &nbsp; &nbsp; &nbsp; &nbsp;本文的模型对于花卉的分类准确率大概在70%左右，采用迁移学习调用Inception-v3模型对本文中的花卉数据集分类准确率在95%左右。主要的原因在于本文的CNN模型较于简单，而且花卉数据集本身就比mnist手写数字数据集分类难度就要大一点，同样的模型在mnist手写数字的识别上准确率要比花卉数据集准确率高不少。 &nbsp; &nbsp; &nbsp; &nbsp;本文的CNN模型完全可以通过增大模型复杂度或者改参数调试以及对图像进行预处理来提高准确率，但本文只是想记录一下最近的学习，这已经足够了。 &nbsp; &nbsp; &nbsp; &nbsp;参考博客：http://www.cnblogs.com/denny402/p/6931338.html ---------------------&nbsp; 作者：Enchanted_ZhouH&nbsp; 来源：CSDN&nbsp; 原文：https://blog.csdn.net/Enchanted_ZhouH/article/details/74116823&nbsp; 版权声明：本文为博主原创文章，转载请附上博文链接！" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-21T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"本文主要通过CNN进行花卉的分类，训练结束保存模型，最后通过调用模型，输入花卉的图片通过模型来进行类别的预测。 &nbsp; &nbsp; &nbsp; &nbsp;测试平台：win 10+tensorflow 1.2 &nbsp; &nbsp; &nbsp; &nbsp;数据集：http://download.tensorflow.org/example_images/flower_photos.tgz &nbsp; &nbsp; &nbsp; &nbsp;数据集中总共有五种花，分别放在五个文件夹下。 &nbsp; &nbsp; &nbsp; &nbsp;一、CNN训练模型 &nbsp; &nbsp; &nbsp; &nbsp;模型尺寸分析：卷积层全都采用了补0，所以经过卷积层长和宽不变，只有深度加深。池化层全都没有补0，所以经过池化层长和宽均减小，深度不变。 &nbsp; &nbsp; &nbsp; &nbsp;模型尺寸变化：100×100×3-&gt;100×100×32-&gt;50×50×32-&gt;50×50×64-&gt;25×25×64-&gt;25×25×128-&gt;12×12×128-&gt;12×12×128-&gt;6×6×128 &nbsp; &nbsp; &nbsp; &nbsp;CNN训练代码如下： &nbsp; from skimage import io,transform import glob import os import tensorflow as tf import numpy as np import time #数据集地址 path=&#39;E:/data/datasets/flower_photos/&#39; #模型保存地址 model_path=&#39;E:/data/model/flower/model.ckpt&#39; #将所有的图片resize成100*100 w=100 h=100 c=3 #读取图片 def read_img(path): &nbsp; &nbsp; cate=[path+x for x in os.listdir(path) if os.path.isdir(path+x)] &nbsp; &nbsp; imgs=[] &nbsp; &nbsp; labels=[] &nbsp; &nbsp; for idx,folder in enumerate(cate): &nbsp; &nbsp; &nbsp; &nbsp; for im in glob.glob(folder+&#39;/*.jpg&#39;): &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print(&#39;reading the images:%s&#39;%(im)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img=io.imread(im) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img=transform.resize(img,(w,h)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imgs.append(img) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; labels.append(idx) &nbsp; &nbsp; return np.asarray(imgs,np.float32),np.asarray(labels,np.int32) data,label=read_img(path) #打乱顺序 num_example=data.shape[0] arr=np.arange(num_example) np.random.shuffle(arr) data=data[arr] label=label[arr] #将所有数据分为训练集和验证集 ratio=0.8 s=np.int(num_example*ratio) x_train=data[:s] y_train=label[:s] x_val=data[s:] y_val=label[s:] #-----------------构建网络---------------------- #占位符 x=tf.placeholder(tf.float32,shape=[None,w,h,c],name=&#39;x&#39;) y_=tf.placeholder(tf.int32,shape=[None,],name=&#39;y_&#39;) def inference(input_tensor, train, regularizer): &nbsp; &nbsp; with tf.variable_scope(&#39;layer1-conv1&#39;): &nbsp; &nbsp; &nbsp; &nbsp; conv1_weights = tf.get_variable(&quot;weight&quot;,[5,5,3,32],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv1_biases = tf.get_variable(&quot;bias&quot;, [32], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv1 = tf.nn.conv2d(input_tensor, conv1_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer2-pool1&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool1 = tf.nn.max_pool(relu1, ksize = [1,2,2,1],strides=[1,2,2,1],padding=&quot;VALID&quot;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer3-conv2&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv2_weights = tf.get_variable(&quot;weight&quot;,[5,5,32,64],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv2_biases = tf.get_variable(&quot;bias&quot;, [64], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer4-pool2&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer5-conv3&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv3_weights = tf.get_variable(&quot;weight&quot;,[3,3,64,128],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv3_biases = tf.get_variable(&quot;bias&quot;, [128], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv3 = tf.nn.conv2d(pool2, conv3_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer6-pool3&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool3 = tf.nn.max_pool(relu3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; with tf.variable_scope(&quot;layer7-conv4&quot;): &nbsp; &nbsp; &nbsp; &nbsp; conv4_weights = tf.get_variable(&quot;weight&quot;,[3,3,128,128],initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; conv4_biases = tf.get_variable(&quot;bias&quot;, [128], initializer=tf.constant_initializer(0.0)) &nbsp; &nbsp; &nbsp; &nbsp; conv4 = tf.nn.conv2d(pool3, conv4_weights, strides=[1, 1, 1, 1], padding=&#39;SAME&#39;) &nbsp; &nbsp; &nbsp; &nbsp; relu4 = tf.nn.relu(tf.nn.bias_add(conv4, conv4_biases)) &nbsp; &nbsp; with tf.name_scope(&quot;layer8-pool4&quot;): &nbsp; &nbsp; &nbsp; &nbsp; pool4 = tf.nn.max_pool(relu4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=&#39;VALID&#39;) &nbsp; &nbsp; &nbsp; &nbsp; nodes = 6*6*128 &nbsp; &nbsp; &nbsp; &nbsp; reshaped = tf.reshape(pool4,[-1,nodes]) &nbsp; &nbsp; with tf.variable_scope(&#39;layer9-fc1&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc1_weights = tf.get_variable(&quot;weight&quot;, [nodes, 1024], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc1_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc1_biases = tf.get_variable(&quot;bias&quot;, [1024], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_weights) + fc1_biases) &nbsp; &nbsp; &nbsp; &nbsp; if train: fc1 = tf.nn.dropout(fc1, 0.5) &nbsp; &nbsp; with tf.variable_scope(&#39;layer10-fc2&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc2_weights = tf.get_variable(&quot;weight&quot;, [1024, 512], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc2_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc2_biases = tf.get_variable(&quot;bias&quot;, [512], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; fc2 = tf.nn.relu(tf.matmul(fc1, fc2_weights) + fc2_biases) &nbsp; &nbsp; &nbsp; &nbsp; if train: fc2 = tf.nn.dropout(fc2, 0.5) &nbsp; &nbsp; with tf.variable_scope(&#39;layer11-fc3&#39;): &nbsp; &nbsp; &nbsp; &nbsp; fc3_weights = tf.get_variable(&quot;weight&quot;, [512, 5], &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1)) &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection(&#39;losses&#39;, regularizer(fc3_weights)) &nbsp; &nbsp; &nbsp; &nbsp; fc3_biases = tf.get_variable(&quot;bias&quot;, [5], initializer=tf.constant_initializer(0.1)) &nbsp; &nbsp; &nbsp; &nbsp; logit = tf.matmul(fc2, fc3_weights) + fc3_biases &nbsp; &nbsp; return logit #---------------------------网络结束--------------------------- regularizer = tf.contrib.layers.l2_regularizer(0.0001) logits = inference(x,False,regularizer) #(小处理)将logits乘以1赋值给logits_eval，定义name，方便在后续调用模型时通过tensor名字调用输出tensor b = tf.constant(value=1,dtype=tf.float32) logits_eval = tf.multiply(logits,b,name=&#39;logits_eval&#39;)&nbsp; loss=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_) train_op=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) correct_prediction = tf.equal(tf.cast(tf.argmax(logits,1),tf.int32), y_) &nbsp; &nbsp; acc= tf.reduce_mean(tf.cast(correct_prediction, tf.float32)) #定义一个函数，按批次取数据 def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False): &nbsp; &nbsp; assert len(inputs) == len(targets) &nbsp; &nbsp; if shuffle: &nbsp; &nbsp; &nbsp; &nbsp; indices = np.arange(len(inputs)) &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(indices) &nbsp; &nbsp; for start_idx in range(0, len(inputs) - batch_size + 1, batch_size): &nbsp; &nbsp; &nbsp; &nbsp; if shuffle: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; excerpt = indices[start_idx:start_idx + batch_size] &nbsp; &nbsp; &nbsp; &nbsp; else: &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; excerpt = slice(start_idx, start_idx + batch_size) &nbsp; &nbsp; &nbsp; &nbsp; yield inputs[excerpt], targets[excerpt] #训练和测试数据，可将n_epoch设置更大一些 n_epoch=10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; batch_size=64 saver=tf.train.Saver() sess=tf.Session() &nbsp; sess.run(tf.global_variables_initializer()) for epoch in range(n_epoch): &nbsp; &nbsp; start_time = time.time() &nbsp; &nbsp; #training &nbsp; &nbsp; train_loss, train_acc, n_batch = 0, 0, 0 &nbsp; &nbsp; for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True): &nbsp; &nbsp; &nbsp; &nbsp; _,err,ac=sess.run([train_op,loss,acc], feed_dict={x: x_train_a, y_: y_train_a}) &nbsp; &nbsp; &nbsp; &nbsp; train_loss += err; train_acc += ac; n_batch += 1 &nbsp; &nbsp; print(&quot; &nbsp; train loss: %f&quot; % (np.sum(train_loss)/ n_batch)) &nbsp; &nbsp; print(&quot; &nbsp; train acc: %f&quot; % (np.sum(train_acc)/ n_batch)) &nbsp; &nbsp; #validation &nbsp; &nbsp; val_loss, val_acc, n_batch = 0, 0, 0 &nbsp; &nbsp; for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False): &nbsp; &nbsp; &nbsp; &nbsp; err, ac = sess.run([loss,acc], feed_dict={x: x_val_a, y_: y_val_a}) &nbsp; &nbsp; &nbsp; &nbsp; val_loss += err; val_acc += ac; n_batch += 1 &nbsp; &nbsp; print(&quot; &nbsp; validation loss: %f&quot; % (np.sum(val_loss)/ n_batch)) &nbsp; &nbsp; print(&quot; &nbsp; validation acc: %f&quot; % (np.sum(val_acc)/ n_batch)) saver.save(sess,model_path) sess.close()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177 &nbsp; &nbsp; &nbsp; &nbsp;二、调用模型进行预测 &nbsp; &nbsp; &nbsp; &nbsp;调用模型进行花卉的预测，代码如下： &nbsp; from skimage import io,transform import tensorflow as tf import numpy as np path1 = &quot;E:/data/datasets/flower_photos/daisy/5547758_eea9edfd54_n.jpg&quot; path2 = &quot;E:/data/datasets/flower_photos/dandelion/7355522_b66e5d3078_m.jpg&quot; path3 = &quot;E:/data/datasets/flower_photos/roses/394990940_7af082cf8d_n.jpg&quot; path4 = &quot;E:/data/datasets/flower_photos/sunflowers/6953297_8576bf4ea3.jpg&quot; path5 = &quot;E:/data/datasets/flower_photos/tulips/10791227_7168491604.jpg&quot; flower_dict = {0:&#39;dasiy&#39;,1:&#39;dandelion&#39;,2:&#39;roses&#39;,3:&#39;sunflowers&#39;,4:&#39;tulips&#39;} w=100 h=100 c=3 def read_one_image(path): &nbsp; &nbsp; img = io.imread(path) &nbsp; &nbsp; img = transform.resize(img,(w,h)) &nbsp; &nbsp; return np.asarray(img) with tf.Session() as sess: &nbsp; &nbsp; data = [] &nbsp; &nbsp; data1 = read_one_image(path1) &nbsp; &nbsp; data2 = read_one_image(path2) &nbsp; &nbsp; data3 = read_one_image(path3) &nbsp; &nbsp; data4 = read_one_image(path4) &nbsp; &nbsp; data5 = read_one_image(path5) &nbsp; &nbsp; data.append(data1) &nbsp; &nbsp; data.append(data2) &nbsp; &nbsp; data.append(data3) &nbsp; &nbsp; data.append(data4) &nbsp; &nbsp; data.append(data5) &nbsp; &nbsp; saver = tf.train.import_meta_graph(&#39;E:/data/model/flower/model.ckpt.meta&#39;) &nbsp; &nbsp; saver.restore(sess,tf.train.latest_checkpoint(&#39;E:/data/model/flower/&#39;)) &nbsp; &nbsp; graph = tf.get_default_graph() &nbsp; &nbsp; x = graph.get_tensor_by_name(&quot;x:0&quot;) &nbsp; &nbsp; feed_dict = {x:data} &nbsp; &nbsp; logits = graph.get_tensor_by_name(&quot;logits_eval:0&quot;) &nbsp; &nbsp; classification_result = sess.run(logits,feed_dict) &nbsp; &nbsp; #打印出预测矩阵 &nbsp; &nbsp; print(classification_result) &nbsp; &nbsp; #打印出预测矩阵每一行最大值的索引 &nbsp; &nbsp; print(tf.argmax(classification_result,1).eval()) &nbsp; &nbsp; #根据索引通过字典对应花的分类 &nbsp; &nbsp; output = [] &nbsp; &nbsp; output = tf.argmax(classification_result,1).eval() &nbsp; &nbsp; for i in range(len(output)): &nbsp; &nbsp; &nbsp; &nbsp; print(&quot;第&quot;,i+1,&quot;朵花预测:&quot;+flower_dict[output[i]]) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 &nbsp; &nbsp; &nbsp; &nbsp;运行结果： &nbsp; [[ &nbsp;5.76620245 &nbsp; 3.18228579 &nbsp;-3.89464641 &nbsp;-2.81310582 &nbsp; 1.40294015] &nbsp;[ -1.01490593 &nbsp; 3.55570269 &nbsp;-2.76053429 &nbsp; 2.93104005 &nbsp;-3.47138596] &nbsp;[ -8.05292606 &nbsp;-7.26499033 &nbsp;11.70479774 &nbsp; 0.59627819 &nbsp; 2.15948296] &nbsp;[ -5.12940931 &nbsp; 2.18423128 &nbsp;-3.33257103 &nbsp; 9.0591135 &nbsp; &nbsp;5.03963232] &nbsp;[ -4.25288343 &nbsp;-0.95963973 &nbsp;-2.33347392 &nbsp; 1.54485476 &nbsp; 5.76069307]] [0 1 2 3 4] 第 1 朵花预测:dasiy 第 2 朵花预测:dandelion 第 3 朵花预测:roses 第 4 朵花预测:sunflowers 第 5 朵花预测:tulips1234567891011 &nbsp; &nbsp; &nbsp; &nbsp;预测结果和调用模型代码中的五个路径相比较是完全准确的。 &nbsp; &nbsp; &nbsp; &nbsp;本文的模型对于花卉的分类准确率大概在70%左右，采用迁移学习调用Inception-v3模型对本文中的花卉数据集分类准确率在95%左右。主要的原因在于本文的CNN模型较于简单，而且花卉数据集本身就比mnist手写数字数据集分类难度就要大一点，同样的模型在mnist手写数字的识别上准确率要比花卉数据集准确率高不少。 &nbsp; &nbsp; &nbsp; &nbsp;本文的CNN模型完全可以通过增大模型复杂度或者改参数调试以及对图像进行预处理来提高准确率，但本文只是想记录一下最近的学习，这已经足够了。 &nbsp; &nbsp; &nbsp; &nbsp;参考博客：http://www.cnblogs.com/denny402/p/6931338.html ---------------------&nbsp; 作者：Enchanted_ZhouH&nbsp; 来源：CSDN&nbsp; 原文：https://blog.csdn.net/Enchanted_ZhouH/article/details/74116823&nbsp; 版权声明：本文为博主原创文章，转载请附上博文链接！","@type":"BlogPosting","url":"/2019/02/21/27ac14528b1deeedae5654f0914e0abd.html","headline":"TensorFlow之迁移学习CNN图像分类及模型保存与调用","dateModified":"2019-02-21T00:00:00+08:00","datePublished":"2019-02-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/02/21/27ac14528b1deeedae5654f0914e0abd.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>TensorFlow之迁移学习CNN图像分类及模型保存与调用</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>本文主要通过CNN进行花卉的分类，训练结束保存模型，最后通过调用模型，输入花卉的图片通过模型来进行类别的预测。</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;测试平台：win 10+tensorflow 1.2</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;数据集：http://download.tensorflow.org/example_images/flower_photos.tgz</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;数据集中总共有五种花，分别放在五个文件夹下。</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;一、CNN训练模型</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;模型尺寸分析：卷积层全都采用了补0，所以经过卷积层长和宽不变，只有深度加深。池化层全都没有补0，所以经过池化层长和宽均减小，深度不变。</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;模型尺寸变化：100×100×3-&gt;100×100×32-&gt;50×50×32-&gt;50×50×64-&gt;25×25×64-&gt;25×25×128-&gt;12×12×128-&gt;12×12×128-&gt;6×6×128</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;CNN训练代码如下：</p> 
  <p>&nbsp;</p> 
  <p><br> from skimage import io,transform<br> import glob<br> import os<br> import tensorflow as tf<br> import numpy as np<br> import time</p> 
  <p>#数据集地址<br> path='E:/data/datasets/flower_photos/'<br> #模型保存地址<br> model_path='E:/data/model/flower/model.ckpt'</p> 
  <p>#将所有的图片resize成100*100<br> w=100<br> h=100<br> c=3</p> 
  <p><br> #读取图片<br> def read_img(path):<br> &nbsp; &nbsp; cate=[path+x for x in os.listdir(path) if os.path.isdir(path+x)]<br> &nbsp; &nbsp; imgs=[]<br> &nbsp; &nbsp; labels=[]<br> &nbsp; &nbsp; for idx,folder in enumerate(cate):<br> &nbsp; &nbsp; &nbsp; &nbsp; for im in glob.glob(folder+'/*.jpg'):<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; print('reading the images:%s'%(im))<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img=io.imread(im)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; img=transform.resize(img,(w,h))<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; imgs.append(img)<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; labels.append(idx)<br> &nbsp; &nbsp; return np.asarray(imgs,np.float32),np.asarray(labels,np.int32)<br> data,label=read_img(path)</p> 
  <p><br> #打乱顺序<br> num_example=data.shape[0]<br> arr=np.arange(num_example)<br> np.random.shuffle(arr)<br> data=data[arr]<br> label=label[arr]</p> 
  <p><br> #将所有数据分为训练集和验证集<br> ratio=0.8<br> s=np.int(num_example*ratio)<br> x_train=data[:s]<br> y_train=label[:s]<br> x_val=data[s:]<br> y_val=label[s:]</p> 
  <p>#-----------------构建网络----------------------<br> #占位符<br> x=tf.placeholder(tf.float32,shape=[None,w,h,c],name='x')<br> y_=tf.placeholder(tf.int32,shape=[None,],name='y_')</p> 
  <p>def inference(input_tensor, train, regularizer):<br> &nbsp; &nbsp; with tf.variable_scope('layer1-conv1'):<br> &nbsp; &nbsp; &nbsp; &nbsp; conv1_weights = tf.get_variable("weight",[5,5,3,32],initializer=tf.truncated_normal_initializer(stddev=0.1))<br> &nbsp; &nbsp; &nbsp; &nbsp; conv1_biases = tf.get_variable("bias", [32], initializer=tf.constant_initializer(0.0))<br> &nbsp; &nbsp; &nbsp; &nbsp; conv1 = tf.nn.conv2d(input_tensor, conv1_weights, strides=[1, 1, 1, 1], padding='SAME')<br> &nbsp; &nbsp; &nbsp; &nbsp; relu1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_biases))</p> 
  <p>&nbsp; &nbsp; with tf.name_scope("layer2-pool1"):<br> &nbsp; &nbsp; &nbsp; &nbsp; pool1 = tf.nn.max_pool(relu1, ksize = [1,2,2,1],strides=[1,2,2,1],padding="VALID")</p> 
  <p>&nbsp; &nbsp; with tf.variable_scope("layer3-conv2"):<br> &nbsp; &nbsp; &nbsp; &nbsp; conv2_weights = tf.get_variable("weight",[5,5,32,64],initializer=tf.truncated_normal_initializer(stddev=0.1))<br> &nbsp; &nbsp; &nbsp; &nbsp; conv2_biases = tf.get_variable("bias", [64], initializer=tf.constant_initializer(0.0))<br> &nbsp; &nbsp; &nbsp; &nbsp; conv2 = tf.nn.conv2d(pool1, conv2_weights, strides=[1, 1, 1, 1], padding='SAME')<br> &nbsp; &nbsp; &nbsp; &nbsp; relu2 = tf.nn.relu(tf.nn.bias_add(conv2, conv2_biases))</p> 
  <p>&nbsp; &nbsp; with tf.name_scope("layer4-pool2"):<br> &nbsp; &nbsp; &nbsp; &nbsp; pool2 = tf.nn.max_pool(relu2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')</p> 
  <p>&nbsp; &nbsp; with tf.variable_scope("layer5-conv3"):<br> &nbsp; &nbsp; &nbsp; &nbsp; conv3_weights = tf.get_variable("weight",[3,3,64,128],initializer=tf.truncated_normal_initializer(stddev=0.1))<br> &nbsp; &nbsp; &nbsp; &nbsp; conv3_biases = tf.get_variable("bias", [128], initializer=tf.constant_initializer(0.0))<br> &nbsp; &nbsp; &nbsp; &nbsp; conv3 = tf.nn.conv2d(pool2, conv3_weights, strides=[1, 1, 1, 1], padding='SAME')<br> &nbsp; &nbsp; &nbsp; &nbsp; relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))</p> 
  <p>&nbsp; &nbsp; with tf.name_scope("layer6-pool3"):<br> &nbsp; &nbsp; &nbsp; &nbsp; pool3 = tf.nn.max_pool(relu3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')</p> 
  <p>&nbsp; &nbsp; with tf.variable_scope("layer7-conv4"):<br> &nbsp; &nbsp; &nbsp; &nbsp; conv4_weights = tf.get_variable("weight",[3,3,128,128],initializer=tf.truncated_normal_initializer(stddev=0.1))<br> &nbsp; &nbsp; &nbsp; &nbsp; conv4_biases = tf.get_variable("bias", [128], initializer=tf.constant_initializer(0.0))<br> &nbsp; &nbsp; &nbsp; &nbsp; conv4 = tf.nn.conv2d(pool3, conv4_weights, strides=[1, 1, 1, 1], padding='SAME')<br> &nbsp; &nbsp; &nbsp; &nbsp; relu4 = tf.nn.relu(tf.nn.bias_add(conv4, conv4_biases))</p> 
  <p>&nbsp; &nbsp; with tf.name_scope("layer8-pool4"):<br> &nbsp; &nbsp; &nbsp; &nbsp; pool4 = tf.nn.max_pool(relu4, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')<br> &nbsp; &nbsp; &nbsp; &nbsp; nodes = 6*6*128<br> &nbsp; &nbsp; &nbsp; &nbsp; reshaped = tf.reshape(pool4,[-1,nodes])</p> 
  <p>&nbsp; &nbsp; with tf.variable_scope('layer9-fc1'):<br> &nbsp; &nbsp; &nbsp; &nbsp; fc1_weights = tf.get_variable("weight", [nodes, 1024],<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1))<br> &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection('losses', regularizer(fc1_weights))<br> &nbsp; &nbsp; &nbsp; &nbsp; fc1_biases = tf.get_variable("bias", [1024], initializer=tf.constant_initializer(0.1))</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; fc1 = tf.nn.relu(tf.matmul(reshaped, fc1_weights) + fc1_biases)<br> &nbsp; &nbsp; &nbsp; &nbsp; if train: fc1 = tf.nn.dropout(fc1, 0.5)</p> 
  <p>&nbsp; &nbsp; with tf.variable_scope('layer10-fc2'):<br> &nbsp; &nbsp; &nbsp; &nbsp; fc2_weights = tf.get_variable("weight", [1024, 512],<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1))<br> &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection('losses', regularizer(fc2_weights))<br> &nbsp; &nbsp; &nbsp; &nbsp; fc2_biases = tf.get_variable("bias", [512], initializer=tf.constant_initializer(0.1))</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; fc2 = tf.nn.relu(tf.matmul(fc1, fc2_weights) + fc2_biases)<br> &nbsp; &nbsp; &nbsp; &nbsp; if train: fc2 = tf.nn.dropout(fc2, 0.5)</p> 
  <p>&nbsp; &nbsp; with tf.variable_scope('layer11-fc3'):<br> &nbsp; &nbsp; &nbsp; &nbsp; fc3_weights = tf.get_variable("weight", [512, 5],<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; initializer=tf.truncated_normal_initializer(stddev=0.1))<br> &nbsp; &nbsp; &nbsp; &nbsp; if regularizer != None: tf.add_to_collection('losses', regularizer(fc3_weights))<br> &nbsp; &nbsp; &nbsp; &nbsp; fc3_biases = tf.get_variable("bias", [5], initializer=tf.constant_initializer(0.1))<br> &nbsp; &nbsp; &nbsp; &nbsp; logit = tf.matmul(fc2, fc3_weights) + fc3_biases</p> 
  <p>&nbsp; &nbsp; return logit</p> 
  <p>#---------------------------网络结束---------------------------<br> regularizer = tf.contrib.layers.l2_regularizer(0.0001)<br> logits = inference(x,False,regularizer)</p> 
  <p>#(小处理)将logits乘以1赋值给logits_eval，定义name，方便在后续调用模型时通过tensor名字调用输出tensor<br> b = tf.constant(value=1,dtype=tf.float32)<br> logits_eval = tf.multiply(logits,b,name='logits_eval')&nbsp;</p> 
  <p>loss=tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_)<br> train_op=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)<br> correct_prediction = tf.equal(tf.cast(tf.argmax(logits,1),tf.int32), y_) &nbsp; &nbsp;<br> acc= tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</p> 
  <p><br> #定义一个函数，按批次取数据<br> def minibatches(inputs=None, targets=None, batch_size=None, shuffle=False):<br> &nbsp; &nbsp; assert len(inputs) == len(targets)<br> &nbsp; &nbsp; if shuffle:<br> &nbsp; &nbsp; &nbsp; &nbsp; indices = np.arange(len(inputs))<br> &nbsp; &nbsp; &nbsp; &nbsp; np.random.shuffle(indices)<br> &nbsp; &nbsp; for start_idx in range(0, len(inputs) - batch_size + 1, batch_size):<br> &nbsp; &nbsp; &nbsp; &nbsp; if shuffle:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; excerpt = indices[start_idx:start_idx + batch_size]<br> &nbsp; &nbsp; &nbsp; &nbsp; else:<br> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; excerpt = slice(start_idx, start_idx + batch_size)<br> &nbsp; &nbsp; &nbsp; &nbsp; yield inputs[excerpt], targets[excerpt]</p> 
  <p><br> #训练和测试数据，可将n_epoch设置更大一些</p> 
  <p>n_epoch=10 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<br> batch_size=64<br> saver=tf.train.Saver()<br> sess=tf.Session() &nbsp;<br> sess.run(tf.global_variables_initializer())<br> for epoch in range(n_epoch):<br> &nbsp; &nbsp; start_time = time.time()</p> 
  <p>&nbsp; &nbsp; #training<br> &nbsp; &nbsp; train_loss, train_acc, n_batch = 0, 0, 0<br> &nbsp; &nbsp; for x_train_a, y_train_a in minibatches(x_train, y_train, batch_size, shuffle=True):<br> &nbsp; &nbsp; &nbsp; &nbsp; _,err,ac=sess.run([train_op,loss,acc], feed_dict={x: x_train_a, y_: y_train_a})<br> &nbsp; &nbsp; &nbsp; &nbsp; train_loss += err; train_acc += ac; n_batch += 1<br> &nbsp; &nbsp; print(" &nbsp; train loss: %f" % (np.sum(train_loss)/ n_batch))<br> &nbsp; &nbsp; print(" &nbsp; train acc: %f" % (np.sum(train_acc)/ n_batch))</p> 
  <p>&nbsp; &nbsp; #validation<br> &nbsp; &nbsp; val_loss, val_acc, n_batch = 0, 0, 0<br> &nbsp; &nbsp; for x_val_a, y_val_a in minibatches(x_val, y_val, batch_size, shuffle=False):<br> &nbsp; &nbsp; &nbsp; &nbsp; err, ac = sess.run([loss,acc], feed_dict={x: x_val_a, y_: y_val_a})<br> &nbsp; &nbsp; &nbsp; &nbsp; val_loss += err; val_acc += ac; n_batch += 1<br> &nbsp; &nbsp; print(" &nbsp; validation loss: %f" % (np.sum(val_loss)/ n_batch))<br> &nbsp; &nbsp; print(" &nbsp; validation acc: %f" % (np.sum(val_acc)/ n_batch))<br> saver.save(sess,model_path)<br> sess.close()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;二、调用模型进行预测</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;调用模型进行花卉的预测，代码如下：</p> 
  <p>&nbsp;</p> 
  <p>from skimage import io,transform<br> import tensorflow as tf<br> import numpy as np</p> 
  <p><br> path1 = "E:/data/datasets/flower_photos/daisy/5547758_eea9edfd54_n.jpg"<br> path2 = "E:/data/datasets/flower_photos/dandelion/7355522_b66e5d3078_m.jpg"<br> path3 = "E:/data/datasets/flower_photos/roses/394990940_7af082cf8d_n.jpg"<br> path4 = "E:/data/datasets/flower_photos/sunflowers/6953297_8576bf4ea3.jpg"<br> path5 = "E:/data/datasets/flower_photos/tulips/10791227_7168491604.jpg"</p> 
  <p>flower_dict = {0:'dasiy',1:'dandelion',2:'roses',3:'sunflowers',4:'tulips'}</p> 
  <p>w=100<br> h=100<br> c=3</p> 
  <p>def read_one_image(path):<br> &nbsp; &nbsp; img = io.imread(path)<br> &nbsp; &nbsp; img = transform.resize(img,(w,h))<br> &nbsp; &nbsp; return np.asarray(img)</p> 
  <p>with tf.Session() as sess:<br> &nbsp; &nbsp; data = []<br> &nbsp; &nbsp; data1 = read_one_image(path1)<br> &nbsp; &nbsp; data2 = read_one_image(path2)<br> &nbsp; &nbsp; data3 = read_one_image(path3)<br> &nbsp; &nbsp; data4 = read_one_image(path4)<br> &nbsp; &nbsp; data5 = read_one_image(path5)<br> &nbsp; &nbsp; data.append(data1)<br> &nbsp; &nbsp; data.append(data2)<br> &nbsp; &nbsp; data.append(data3)<br> &nbsp; &nbsp; data.append(data4)<br> &nbsp; &nbsp; data.append(data5)</p> 
  <p>&nbsp; &nbsp; saver = tf.train.import_meta_graph('E:/data/model/flower/model.ckpt.meta')<br> &nbsp; &nbsp; saver.restore(sess,tf.train.latest_checkpoint('E:/data/model/flower/'))</p> 
  <p>&nbsp; &nbsp; graph = tf.get_default_graph()<br> &nbsp; &nbsp; x = graph.get_tensor_by_name("x:0")<br> &nbsp; &nbsp; feed_dict = {x:data}</p> 
  <p>&nbsp; &nbsp; logits = graph.get_tensor_by_name("logits_eval:0")</p> 
  <p>&nbsp; &nbsp; classification_result = sess.run(logits,feed_dict)</p> 
  <p>&nbsp; &nbsp; #打印出预测矩阵<br> &nbsp; &nbsp; print(classification_result)<br> &nbsp; &nbsp; #打印出预测矩阵每一行最大值的索引<br> &nbsp; &nbsp; print(tf.argmax(classification_result,1).eval())<br> &nbsp; &nbsp; #根据索引通过字典对应花的分类<br> &nbsp; &nbsp; output = []<br> &nbsp; &nbsp; output = tf.argmax(classification_result,1).eval()<br> &nbsp; &nbsp; for i in range(len(output)):<br> &nbsp; &nbsp; &nbsp; &nbsp; print("第",i+1,"朵花预测:"+flower_dict[output[i]])</p> 
  <p>123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;运行结果：</p> 
  <p>&nbsp;</p> 
  <p>[[ &nbsp;5.76620245 &nbsp; 3.18228579 &nbsp;-3.89464641 &nbsp;-2.81310582 &nbsp; 1.40294015]<br> &nbsp;[ -1.01490593 &nbsp; 3.55570269 &nbsp;-2.76053429 &nbsp; 2.93104005 &nbsp;-3.47138596]<br> &nbsp;[ -8.05292606 &nbsp;-7.26499033 &nbsp;11.70479774 &nbsp; 0.59627819 &nbsp; 2.15948296]<br> &nbsp;[ -5.12940931 &nbsp; 2.18423128 &nbsp;-3.33257103 &nbsp; 9.0591135 &nbsp; &nbsp;5.03963232]<br> &nbsp;[ -4.25288343 &nbsp;-0.95963973 &nbsp;-2.33347392 &nbsp; 1.54485476 &nbsp; 5.76069307]]<br> [0 1 2 3 4]<br> 第 1 朵花预测:dasiy<br> 第 2 朵花预测:dandelion<br> 第 3 朵花预测:roses<br> 第 4 朵花预测:sunflowers<br> 第 5 朵花预测:tulips1234567891011</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;预测结果和调用模型代码中的五个路径相比较是完全准确的。</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;本文的模型对于花卉的分类准确率大概在70%左右，采用迁移学习调用Inception-v3模型对本文中的花卉数据集分类准确率在95%左右。主要的原因在于本文的CNN模型较于简单，而且花卉数据集本身就比mnist手写数字数据集分类难度就要大一点，同样的模型在mnist手写数字的识别上准确率要比花卉数据集准确率高不少。</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;本文的CNN模型完全可以通过增大模型复杂度或者改参数调试以及对图像进行预处理来提高准确率，但本文只是想记录一下最近的学习，这已经足够了。</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp;参考博客：http://www.cnblogs.com/denny402/p/6931338.html<br> ---------------------&nbsp;<br> 作者：Enchanted_ZhouH&nbsp;<br> 来源：CSDN&nbsp;<br> 原文：https://blog.csdn.net/Enchanted_ZhouH/article/details/74116823&nbsp;<br> 版权声明：本文为博主原创文章，转载请附上博文链接！</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
