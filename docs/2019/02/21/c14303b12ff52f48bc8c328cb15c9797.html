<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>深度学习入门 中根据源代码下载到mnist数据集,训练识别率超级低问题 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="深度学习入门 中根据源代码下载到mnist数据集,训练识别率超级低问题" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/MHeartWGO/article/details/87867533 深度学习入门 中根据源代码下载到mnist数据集,训练识别率超级低问题 上图是没有拷贝原文件mnist.pkl的训练结果 上图是拷贝原文件mnist.pkl的训练结果 现在的问题是，相同的代码，得要的识别精度差距较大，所以我想可能原文件mnist.py在训练的时候还采取了其他办法来提高识别精度。恩，我暂时不会，所以后面会尝试着能不能解决了这个问题。 下面附上mnist.py文件和mnist_show文件，希望大家可以帮忙看一下。 mnist.py文件： # coding: utf-8 try: import urllib.request except ImportError: raise ImportError(&#39;You should use Python 3.x&#39;) import os.path import gzip import pickle import os import numpy as np url_base = &#39;http://yann.lecun.com/exdb/mnist/&#39; key_file = { &#39;train_img&#39;:&#39;train-images-idx3-ubyte.gz&#39;, &#39;train_label&#39;:&#39;train-labels-idx1-ubyte.gz&#39;, &#39;test_img&#39;:&#39;t10k-images-idx3-ubyte.gz&#39;, &#39;test_label&#39;:&#39;t10k-labels-idx1-ubyte.gz&#39; } dataset_dir = os.path.dirname(os.path.abspath(__file__))#得到当前文件所在文件夹 save_file = dataset_dir + &quot;/mnist.pkl&quot; #在这个文件夹下保存一个mnist.pkl文件 train_num = 60000 test_num = 10000 img_dim = (1, 28, 28) img_size = 784 def _download(file_name): #下载训练集包所需调用函数 file_path = dataset_dir + &quot;/&quot; + file_name if os.path.exists(file_path): return print(&quot;Downloading &quot; + file_name + &quot; ... &quot;) urllib.request.urlretrieve(url_base + file_name, file_path) print(&quot;Done&quot;) def download_mnist():#下载mnist文件 for v in key_file.values(): _download(v) def _load_label(file_name):#把label.gz文件转换为numpy数组 file_path = dataset_dir + &quot;/&quot; + file_name print(&quot;Converting &quot; + file_name + &quot; to NumPy Array ...&quot;) with gzip.open(file_path, &#39;rb&#39;) as f: labels = np.frombuffer(f.read(), np.uint8, offset=24) print(&quot;Done&quot;) return labels def _load_img(file_name): #把image.gz文件转换为numpy数组 file_path = dataset_dir + &quot;/&quot; + file_name print(&quot;Converting &quot; + file_name + &quot; to NumPy Array ...&quot;) with gzip.open(file_path, &#39;rb&#39;) as f: data = np.frombuffer(f.read(), np.uint8, offset=16) data = data.reshape(-1, img_size) print(&quot;Done&quot;) return data def _convert_numpy(): #将数组保存在dataset数组中 dataset = {} dataset[&#39;train_img&#39;] = _load_img(key_file[&#39;train_img&#39;]) dataset[&#39;train_label&#39;] = _load_label(key_file[&#39;train_label&#39;]) dataset[&#39;test_img&#39;] = _load_img(key_file[&#39;test_img&#39;]) dataset[&#39;test_label&#39;] = _load_label(key_file[&#39;test_label&#39;]) return dataset def init_mnist(): download_mnist() dataset = _convert_numpy() print(&quot;Creating pickle file ...&quot;) with open(save_file, &#39;wb&#39;) as f: pickle.dump(dataset, f, -1) print(&quot;Done!&quot;) def _change_one_hot_label(X): T = np.zeros((X.size, 10)) for idx, row in enumerate(T): row[X[idx]] = 1 return T def load_mnist(normalize=True, flatten=True, one_hot_label=False): &quot;&quot;&quot;读入MNIST数据集 Parameters ---------- normalize : 将图像的像素值正规化为0.0~1.0 one_hot_label : one_hot_label为True的情况下，标签作为one-hot数组返回 one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组 flatten : 是否将图像展开为一维数组 Returns ------- (训练图像, 训练标签), (测试图像, 测试标签) &quot;&quot;&quot; if not os.path.exists(save_file): init_mnist() with open(save_file, &#39;rb&#39;) as f: dataset = pickle.load(f) if normalize: for key in (&#39;train_img&#39;, &#39;test_img&#39;): dataset[key] = dataset[key].astype(np.float32) dataset[key] /= 255.0 if one_hot_label: dataset[&#39;train_label&#39;] = _change_one_hot_label(dataset[&#39;train_label&#39;]) dataset[&#39;test_label&#39;] = _change_one_hot_label(dataset[&#39;test_label&#39;]) if not flatten: for key in (&#39;train_img&#39;, &#39;test_img&#39;): dataset[key] = dataset[key].reshape(-1, 1, 28, 28) return (dataset[&#39;train_img&#39;], dataset[&#39;train_label&#39;]), (dataset[&#39;test_img&#39;], dataset[&#39;test_label&#39;]) if __name__ == &#39;__main__&#39;: init_mnist() mnist_show.py文件： import sys, os sys.path.append(os.pardir) import numpy as np from dataest.mnist import load_mnist from PIL import Image def img_show(img): pil_img = Image.fromarray(np.uint8(img)) pil_img .show() (x_train,t_train),(x_test,t_test) = load_mnist(flatten=True,normalize=False) img = x_train[0] label = t_train[0] print(label) print(img.shape) img = img.reshape(28,28) print(img.shape) img_show(img) &nbsp;" />
<meta property="og:description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/MHeartWGO/article/details/87867533 深度学习入门 中根据源代码下载到mnist数据集,训练识别率超级低问题 上图是没有拷贝原文件mnist.pkl的训练结果 上图是拷贝原文件mnist.pkl的训练结果 现在的问题是，相同的代码，得要的识别精度差距较大，所以我想可能原文件mnist.py在训练的时候还采取了其他办法来提高识别精度。恩，我暂时不会，所以后面会尝试着能不能解决了这个问题。 下面附上mnist.py文件和mnist_show文件，希望大家可以帮忙看一下。 mnist.py文件： # coding: utf-8 try: import urllib.request except ImportError: raise ImportError(&#39;You should use Python 3.x&#39;) import os.path import gzip import pickle import os import numpy as np url_base = &#39;http://yann.lecun.com/exdb/mnist/&#39; key_file = { &#39;train_img&#39;:&#39;train-images-idx3-ubyte.gz&#39;, &#39;train_label&#39;:&#39;train-labels-idx1-ubyte.gz&#39;, &#39;test_img&#39;:&#39;t10k-images-idx3-ubyte.gz&#39;, &#39;test_label&#39;:&#39;t10k-labels-idx1-ubyte.gz&#39; } dataset_dir = os.path.dirname(os.path.abspath(__file__))#得到当前文件所在文件夹 save_file = dataset_dir + &quot;/mnist.pkl&quot; #在这个文件夹下保存一个mnist.pkl文件 train_num = 60000 test_num = 10000 img_dim = (1, 28, 28) img_size = 784 def _download(file_name): #下载训练集包所需调用函数 file_path = dataset_dir + &quot;/&quot; + file_name if os.path.exists(file_path): return print(&quot;Downloading &quot; + file_name + &quot; ... &quot;) urllib.request.urlretrieve(url_base + file_name, file_path) print(&quot;Done&quot;) def download_mnist():#下载mnist文件 for v in key_file.values(): _download(v) def _load_label(file_name):#把label.gz文件转换为numpy数组 file_path = dataset_dir + &quot;/&quot; + file_name print(&quot;Converting &quot; + file_name + &quot; to NumPy Array ...&quot;) with gzip.open(file_path, &#39;rb&#39;) as f: labels = np.frombuffer(f.read(), np.uint8, offset=24) print(&quot;Done&quot;) return labels def _load_img(file_name): #把image.gz文件转换为numpy数组 file_path = dataset_dir + &quot;/&quot; + file_name print(&quot;Converting &quot; + file_name + &quot; to NumPy Array ...&quot;) with gzip.open(file_path, &#39;rb&#39;) as f: data = np.frombuffer(f.read(), np.uint8, offset=16) data = data.reshape(-1, img_size) print(&quot;Done&quot;) return data def _convert_numpy(): #将数组保存在dataset数组中 dataset = {} dataset[&#39;train_img&#39;] = _load_img(key_file[&#39;train_img&#39;]) dataset[&#39;train_label&#39;] = _load_label(key_file[&#39;train_label&#39;]) dataset[&#39;test_img&#39;] = _load_img(key_file[&#39;test_img&#39;]) dataset[&#39;test_label&#39;] = _load_label(key_file[&#39;test_label&#39;]) return dataset def init_mnist(): download_mnist() dataset = _convert_numpy() print(&quot;Creating pickle file ...&quot;) with open(save_file, &#39;wb&#39;) as f: pickle.dump(dataset, f, -1) print(&quot;Done!&quot;) def _change_one_hot_label(X): T = np.zeros((X.size, 10)) for idx, row in enumerate(T): row[X[idx]] = 1 return T def load_mnist(normalize=True, flatten=True, one_hot_label=False): &quot;&quot;&quot;读入MNIST数据集 Parameters ---------- normalize : 将图像的像素值正规化为0.0~1.0 one_hot_label : one_hot_label为True的情况下，标签作为one-hot数组返回 one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组 flatten : 是否将图像展开为一维数组 Returns ------- (训练图像, 训练标签), (测试图像, 测试标签) &quot;&quot;&quot; if not os.path.exists(save_file): init_mnist() with open(save_file, &#39;rb&#39;) as f: dataset = pickle.load(f) if normalize: for key in (&#39;train_img&#39;, &#39;test_img&#39;): dataset[key] = dataset[key].astype(np.float32) dataset[key] /= 255.0 if one_hot_label: dataset[&#39;train_label&#39;] = _change_one_hot_label(dataset[&#39;train_label&#39;]) dataset[&#39;test_label&#39;] = _change_one_hot_label(dataset[&#39;test_label&#39;]) if not flatten: for key in (&#39;train_img&#39;, &#39;test_img&#39;): dataset[key] = dataset[key].reshape(-1, 1, 28, 28) return (dataset[&#39;train_img&#39;], dataset[&#39;train_label&#39;]), (dataset[&#39;test_img&#39;], dataset[&#39;test_label&#39;]) if __name__ == &#39;__main__&#39;: init_mnist() mnist_show.py文件： import sys, os sys.path.append(os.pardir) import numpy as np from dataest.mnist import load_mnist from PIL import Image def img_show(img): pil_img = Image.fromarray(np.uint8(img)) pil_img .show() (x_train,t_train),(x_test,t_test) = load_mnist(flatten=True,normalize=False) img = x_train[0] label = t_train[0] print(label) print(img.shape) img = img.reshape(28,28) print(img.shape) img_show(img) &nbsp;" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-21T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/MHeartWGO/article/details/87867533 深度学习入门 中根据源代码下载到mnist数据集,训练识别率超级低问题 上图是没有拷贝原文件mnist.pkl的训练结果 上图是拷贝原文件mnist.pkl的训练结果 现在的问题是，相同的代码，得要的识别精度差距较大，所以我想可能原文件mnist.py在训练的时候还采取了其他办法来提高识别精度。恩，我暂时不会，所以后面会尝试着能不能解决了这个问题。 下面附上mnist.py文件和mnist_show文件，希望大家可以帮忙看一下。 mnist.py文件： # coding: utf-8 try: import urllib.request except ImportError: raise ImportError(&#39;You should use Python 3.x&#39;) import os.path import gzip import pickle import os import numpy as np url_base = &#39;http://yann.lecun.com/exdb/mnist/&#39; key_file = { &#39;train_img&#39;:&#39;train-images-idx3-ubyte.gz&#39;, &#39;train_label&#39;:&#39;train-labels-idx1-ubyte.gz&#39;, &#39;test_img&#39;:&#39;t10k-images-idx3-ubyte.gz&#39;, &#39;test_label&#39;:&#39;t10k-labels-idx1-ubyte.gz&#39; } dataset_dir = os.path.dirname(os.path.abspath(__file__))#得到当前文件所在文件夹 save_file = dataset_dir + &quot;/mnist.pkl&quot; #在这个文件夹下保存一个mnist.pkl文件 train_num = 60000 test_num = 10000 img_dim = (1, 28, 28) img_size = 784 def _download(file_name): #下载训练集包所需调用函数 file_path = dataset_dir + &quot;/&quot; + file_name if os.path.exists(file_path): return print(&quot;Downloading &quot; + file_name + &quot; ... &quot;) urllib.request.urlretrieve(url_base + file_name, file_path) print(&quot;Done&quot;) def download_mnist():#下载mnist文件 for v in key_file.values(): _download(v) def _load_label(file_name):#把label.gz文件转换为numpy数组 file_path = dataset_dir + &quot;/&quot; + file_name print(&quot;Converting &quot; + file_name + &quot; to NumPy Array ...&quot;) with gzip.open(file_path, &#39;rb&#39;) as f: labels = np.frombuffer(f.read(), np.uint8, offset=24) print(&quot;Done&quot;) return labels def _load_img(file_name): #把image.gz文件转换为numpy数组 file_path = dataset_dir + &quot;/&quot; + file_name print(&quot;Converting &quot; + file_name + &quot; to NumPy Array ...&quot;) with gzip.open(file_path, &#39;rb&#39;) as f: data = np.frombuffer(f.read(), np.uint8, offset=16) data = data.reshape(-1, img_size) print(&quot;Done&quot;) return data def _convert_numpy(): #将数组保存在dataset数组中 dataset = {} dataset[&#39;train_img&#39;] = _load_img(key_file[&#39;train_img&#39;]) dataset[&#39;train_label&#39;] = _load_label(key_file[&#39;train_label&#39;]) dataset[&#39;test_img&#39;] = _load_img(key_file[&#39;test_img&#39;]) dataset[&#39;test_label&#39;] = _load_label(key_file[&#39;test_label&#39;]) return dataset def init_mnist(): download_mnist() dataset = _convert_numpy() print(&quot;Creating pickle file ...&quot;) with open(save_file, &#39;wb&#39;) as f: pickle.dump(dataset, f, -1) print(&quot;Done!&quot;) def _change_one_hot_label(X): T = np.zeros((X.size, 10)) for idx, row in enumerate(T): row[X[idx]] = 1 return T def load_mnist(normalize=True, flatten=True, one_hot_label=False): &quot;&quot;&quot;读入MNIST数据集 Parameters ---------- normalize : 将图像的像素值正规化为0.0~1.0 one_hot_label : one_hot_label为True的情况下，标签作为one-hot数组返回 one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组 flatten : 是否将图像展开为一维数组 Returns ------- (训练图像, 训练标签), (测试图像, 测试标签) &quot;&quot;&quot; if not os.path.exists(save_file): init_mnist() with open(save_file, &#39;rb&#39;) as f: dataset = pickle.load(f) if normalize: for key in (&#39;train_img&#39;, &#39;test_img&#39;): dataset[key] = dataset[key].astype(np.float32) dataset[key] /= 255.0 if one_hot_label: dataset[&#39;train_label&#39;] = _change_one_hot_label(dataset[&#39;train_label&#39;]) dataset[&#39;test_label&#39;] = _change_one_hot_label(dataset[&#39;test_label&#39;]) if not flatten: for key in (&#39;train_img&#39;, &#39;test_img&#39;): dataset[key] = dataset[key].reshape(-1, 1, 28, 28) return (dataset[&#39;train_img&#39;], dataset[&#39;train_label&#39;]), (dataset[&#39;test_img&#39;], dataset[&#39;test_label&#39;]) if __name__ == &#39;__main__&#39;: init_mnist() mnist_show.py文件： import sys, os sys.path.append(os.pardir) import numpy as np from dataest.mnist import load_mnist from PIL import Image def img_show(img): pil_img = Image.fromarray(np.uint8(img)) pil_img .show() (x_train,t_train),(x_test,t_test) = load_mnist(flatten=True,normalize=False) img = x_train[0] label = t_train[0] print(label) print(img.shape) img = img.reshape(28,28) print(img.shape) img_show(img) &nbsp;","@type":"BlogPosting","url":"/2019/02/21/c14303b12ff52f48bc8c328cb15c9797.html","headline":"深度学习入门 中根据源代码下载到mnist数据集,训练识别率超级低问题","dateModified":"2019-02-21T00:00:00+08:00","datePublished":"2019-02-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/02/21/c14303b12ff52f48bc8c328cb15c9797.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>深度学习入门 中根据源代码下载到mnist数据集,训练识别率超级低问题</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/MHeartWGO/article/details/87867533 
 </div> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>深度学习入门 中根据源代码下载到mnist数据集,训练识别率超级低问题</p> 
  <p style="text-align:center;"><img alt="" class="has" height="285" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221195910510.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01IZWFydFdHTw==,size_16,color_FFFFFF,t_70" width="669"></p> 
  <p>上图是没有拷贝原文件mnist.pkl的训练结果</p> 
  <p style="text-align:center;"><img alt="" class="has" height="285" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200153174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L01IZWFydFdHTw==,size_16,color_FFFFFF,t_70" width="669"></p> 
  <p>上图是拷贝原文件mnist.pkl的训练结果</p> 
  <p>现在的问题是，相同的代码，得要的识别精度差距较大，所以我想可能原文件mnist.py在训练的时候还采取了其他办法来提高识别精度。恩，我暂时不会，所以后面会尝试着能不能解决了这个问题。</p> 
  <p>下面附上mnist.py文件和mnist_show文件，希望大家可以帮忙看一下。</p> 
  <p>mnist.py文件：</p> 
  <pre class="has">
<code class="language-python"># coding: utf-8
try:
    import urllib.request
except ImportError:
    raise ImportError('You should use Python 3.x')
import os.path
import gzip
import pickle
import os
import numpy as np


url_base = 'http://yann.lecun.com/exdb/mnist/'
key_file = {
    'train_img':'train-images-idx3-ubyte.gz',
    'train_label':'train-labels-idx1-ubyte.gz',
    'test_img':'t10k-images-idx3-ubyte.gz',
    'test_label':'t10k-labels-idx1-ubyte.gz'
}

dataset_dir = os.path.dirname(os.path.abspath(__file__))#得到当前文件所在文件夹
save_file = dataset_dir + "/mnist.pkl" #在这个文件夹下保存一个mnist.pkl文件

train_num = 60000
test_num = 10000
img_dim = (1, 28, 28)
img_size = 784


def _download(file_name):     #下载训练集包所需调用函数
    file_path = dataset_dir + "/" + file_name
    
    if os.path.exists(file_path):
        return

    print("Downloading " + file_name + " ... ")
    urllib.request.urlretrieve(url_base + file_name, file_path)
    print("Done")
    
def download_mnist():#下载mnist文件
    for v in key_file.values():
       _download(v)
        
def _load_label(file_name):#把label.gz文件转换为numpy数组
    file_path = dataset_dir + "/" + file_name
    
    print("Converting " + file_name + " to NumPy Array ...")
    with gzip.open(file_path, 'rb') as f:
            labels = np.frombuffer(f.read(), np.uint8, offset=24)
    print("Done")
    
    return labels

def _load_img(file_name): #把image.gz文件转换为numpy数组
    file_path = dataset_dir + "/" + file_name
    
    print("Converting " + file_name + " to NumPy Array ...")    
    with gzip.open(file_path, 'rb') as f:
            data = np.frombuffer(f.read(), np.uint8, offset=16)
    data = data.reshape(-1, img_size)
    print("Done")
    
    return data
    
def _convert_numpy(): #将数组保存在dataset数组中
    dataset = {}
    dataset['train_img'] =  _load_img(key_file['train_img'])
    dataset['train_label'] = _load_label(key_file['train_label'])    
    dataset['test_img'] = _load_img(key_file['test_img'])
    dataset['test_label'] = _load_label(key_file['test_label'])
    
    return dataset

def init_mnist():
    download_mnist()
    dataset = _convert_numpy()
    print("Creating pickle file ...")
    with open(save_file, 'wb') as f:
        pickle.dump(dataset, f, -1)
    print("Done!")

def _change_one_hot_label(X):
    T = np.zeros((X.size, 10))
    for idx, row in enumerate(T):
        row[X[idx]] = 1
        
    return T
    

def load_mnist(normalize=True, flatten=True, one_hot_label=False):
    """读入MNIST数据集
    
    Parameters
    ----------
    normalize : 将图像的像素值正规化为0.0~1.0
    one_hot_label : 
        one_hot_label为True的情况下，标签作为one-hot数组返回
        one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组
    flatten : 是否将图像展开为一维数组
    
    Returns
    -------
    (训练图像, 训练标签), (测试图像, 测试标签)
    """
    if not os.path.exists(save_file):
        init_mnist()
        
    with open(save_file, 'rb') as f:
        dataset = pickle.load(f)
    
    if normalize:
        for key in ('train_img', 'test_img'):
            dataset[key] = dataset[key].astype(np.float32)
            dataset[key] /= 255.0
            
    if one_hot_label:
        dataset['train_label'] = _change_one_hot_label(dataset['train_label'])
        dataset['test_label'] = _change_one_hot_label(dataset['test_label'])
    
    if not flatten:
         for key in ('train_img', 'test_img'):
            dataset[key] = dataset[key].reshape(-1, 1, 28, 28)

    return (dataset['train_img'], dataset['train_label']), (dataset['test_img'], dataset['test_label']) 


if __name__ == '__main__':
    init_mnist()</code></pre> 
  <p>mnist_show.py文件：</p> 
  <pre class="has">
<code class="language-python">import sys, os
sys.path.append(os.pardir)
import numpy as np 
from dataest.mnist import load_mnist
from PIL import Image

def img_show(img):
	pil_img = Image.fromarray(np.uint8(img))
	pil_img .show()

(x_train,t_train),(x_test,t_test) = load_mnist(flatten=True,normalize=False)
img = x_train[0]
label = t_train[0]
print(label)

print(img.shape)
img = img.reshape(28,28)
print(img.shape)

img_show(img)</code></pre> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
