<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>《深度学习工程师-吴恩达》04结构化机器学习项目–机器学习（ML）策略2 学习笔记（如何进一步优化系统的方法论） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="《深度学习工程师-吴恩达》04结构化机器学习项目–机器学习（ML）策略2 学习笔记（如何进一步优化系统的方法论）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="作者：jliang https://blog.csdn.net/jliang3 《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略2 学习笔记 &nbsp; 1.重点归纳 1）误差分析：如果算法还达不到理想效果，那么人工检查一下算法所犯的错误，也许可以让你了解接下来应该做什么，这个过程称为误差分析。 （1）例子：一个取得90%准确率猫分类器，注意到有部分狗样本被识别为猫，使用误差分析来估计是否应该专门解决这个问题。随机抽样100个错误样本，检查把狗分类成猫的样本数量，如果这个样本占比很小，则不值得专门去优化这个问题。 （2）在做误差分析时也可以同时并行评估几个想法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 （3）进行误差分析时应该找一组错误例子（验证集或测试集中的错误例子），观察错误标记的例子看看假阳性和假阴性，统计属于不同错误类型的错误数量。 这个过程中，可能会得到启发，归纳出新的误差类型。 通过统计不同类型错误标记类型占比总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。 2）标注错误的数据 （1）深度学习算法对训练集的随机误差是相当鲁棒的 只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们 只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们 （2）深度学习算法对系统性的错误就没有那么鲁棒了。比如说，如果做标记的人一直把白色的狗标记成猫。 （3）如果验证集和测试集中有标记错误的样本 误差分析时增加一个额外的列来统计标记出错的例子数，根据标记出错样本数来估计修改错误后对误差值的影响。 如果这些标记错误的例子验证影响了你在验证集上评估算法的能力，那么就应该花时间修正错误的标签。如果它没有严重到影响到用验证集评估成本偏差的能力，那就不需要花费宝贵的时间去处理。 需要修正验证集标记错误的例子：假设系统达到98%准确度（2%的错误），假设错误标记引起的错误对验证集误差的影响为0.6%（30%*2%=0.6%）。评估模型时模型A误差是2.1%，模型B为1.9%，此时标记错误的样本足以影响我们评估哪个模型更好，此时应该修正验证集中的错误标记 （4）修正数据时指引和原则 应该同时修改验证集和测试集上的错误，验证集和测试集必须来自相同的分布，但训练集可以来自稍微不同的分布。 检查数据时检测全部验证/测试集，而不是只检测判断错误的样本。否则有可能有些被正确判断的样本其实是判断错误的，修正样本标签后导致对算法偏差的估计可能变得更大。 由于训练集数据量比较大，也因为前面讨论过的训练集的随机误差对算法影响不大，所以我们可能会只修正验证集和测试集的错误标记，而不修改训练集的错误标记。此时，训练集与验证集和测试集来自不同的数据分布。 3）开发一个全新的机器学习应用时，应该尽快建立第一个系统原型，然后快速迭代。 （1）流程 首先，快速设立验证集和测试集，还有评估指标。它决定了你的目标在哪里，如果你的目标定错了，之后改也是可以的。 然后搭好一个机器学习系统原型，然后找到训练集，看看训练效果如何，在验证集合测试集评估指标表现如何。 再进行偏差方差分析以及误差分析来确定下一步优先做什么。特别是如果误差分析让你了解到大部分误差的来源。 建立初始系统的意义在于有一个训练过的系统让你确定偏差方差的范围，就可以知道下一步应该优先做什么。让你能够进行误差分析，可以观察一些错误，然后想出所有能进行的方向，知道哪些是最优希望的方向。 （2）以下情况，快速搭建第一个系统的建议的适用程度要低一些，一开始就搭建比较复杂的系统 如果你在这个应用程序领域有很多经验 如果一个领域有很多可以借鉴的学术文献（如人脸识别领域），可以从现有大量文献为基础出发，一开始就搭建比较复杂的系统 4）训练样本与验证/测试来自不同的分布 （1）深度学习算法需要大量的数据，即使大部分数据来自不同的分布也比只有很少的数据好，从而导致训练集、验证集和测试集数据分布不一样的情况出现，越来越多团队都用来自和验证集和测试集分布不同的数据来训练。 （2）例子：猫分类器，训练数据来自网络（很清晰），测试数据来自手机拍照（很模糊） （3）错误的组合数据方式：把两组照片混合在一起，然后进行混洗，然后再按比例把照片分配到训练集、 验证集和测试集上。 （4）猫分类器正确的组合数据方式： 训练集205000张=全部网络照片20万张+一半用户上传的照片5000张，验证集和测试集都是2500张用户上传的照片（都是真实关心的数据分布）。 这样划分数据的好处在于，现在瞄准的目标就是我们想要处理的目标。 缺点在于训练集分布和验证集以及测试集分布不一样，但事实证明这样的数据划分在长期能带来更好的系统性能。 （5）例子：语音识别系统的后视镜，如：“后视镜，请帮我找找到最近的加油站的导航方向”。很多数据（共500000条）来自其他语音识别应用，如：数据供应商买来的数据、智能语音激活音箱的数据、语音激活键盘的数据，只有20000条数据来自后视镜设备 划分方式一：训练集=全部其他语音识别数据500000条，验证集和测试集数据都是来自后视镜的数据各10000条。 划分方式二（如果你觉得验证集和测试集不需要这么多数据）：训练集=全部其他语音识别数据500000条+后视镜数据10000条，验证集和测试集数据都是来自后视镜的数据各5000条。 5） 不匹配数据划分的偏差和方差 （1）估计学习算法的偏差和方差可以帮我们确定接下来应该优先做的方向，但是如果训练集和验证集及测试集分布不同时，分析偏差和方差的方式会不一样。 （2）为了确认是由于泛化能力，还是由于数据分布不一样的原因，需要定义一组新的数据“训练-验证集”。数据集分为4份：训练集、训练-验证集、验证集、测试集 （3）训练集误差与训练-验证集误差的差距代表了模型的方差问题的可优化空间，从中可以知道模型的泛化能力。 （4）训练-验证集误差与验证集误差之间的差距代表数据不匹配的程度，因为算法没有直接在训练-验证集或验证集上训练过，这两者的数据来自不同的分布。 （5）各个数据集误差差距总结 训练集误差与贝叶斯误差的差值为可避免偏差值大小。 训练-验证集误差与训练集误差的差值为方差值大小。 验证集误差与训练-验证集误差的差值为数据不匹配问题的大小。 测试集误差与验证集误差的差值为对验证集过拟合的程度，如果差值很大，说明需要一个更大的验证集。 （6）贝叶斯误差、训练集误差、训练-验证集误差、验证集误差和测试集误差的值应该是从越来越大 训练集和训练-验证集误差是从训练集分布评估的，验证集和测试集误差是对验证集测试集分布评估的。 如果某个值没有变大（比上一个误差要小），如下面例子，说明训练数据比验证集和测试集数据难识别多了。 人类水平误差为4% 训练集误差为7% 训练-验证集误差为10% 验证集误差为6% 测试集误差为6% （7）通用的分析方法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 制定以上表格，横轴是不同分布的训练集数据（例子中为来：自其它方式语音识别数据）和验证集/测试集数据（来自后视镜的语音识别数据）；纵轴是人类水平误差、参与训练的数据误差和没有参与训练的数据误差。 正常情况下，我只需要分析图中红色框几项就可以找到方向：训练集与贝叶斯误差差值（可避免偏差）、训练-验证集与训练集误差差值（方差）、验证集与训练-验证集误差差值（数据不匹配）。 进行表格中剩余的两项分析也是有用的：人类在真实分布（验证集/测试集数据）的误差、真实分布用于训练时的训练误差。当你继续进行更多分析时，分析并不一定会给你指明方向，但有时候你会洞察到一些特征。 对比人类在两种不同分布上的表现可以看出哪种数据分布更难被识别，上例中后视镜的数据更难被识别。 对比两种分布数据在训练集上的误差可以了解到偏差和方差，还有数据不匹配这个问题的不同程度。 6）定位数据不匹配 （1）数据不匹配问题没有完全系统的解决方案，但是有一些可以尝试的方法 人工做误差分析，尝试了解训练集和验证测试集的具体差异。为了误差分析时避免对测试集过拟合，应该只人工去看验证集而不看测试集数据。汽车后视镜例子中： 假设发现验证集中有很多汽车噪音，这是验证集和训练集差异之一 发现在汽车里语音激活后视镜经常错误识别街道号码，真实使用时经常导航到某些街道，而训练数据中没有这些导航数据 可以尝试把训练数据变得更像验证集数据，或者采集更多类似验证测试集的数据 如果发现车辆背景噪音是主要误差来源，可以模拟车辆噪声数据，人工合成噪音数据 如果发现很难识别街道号码，可以有意识收集更多人们说数字的音频数据，加到训练集中 （2）人工数据合成 例子1：清晰对话+汽车噪音=人工合成有噪音的对话。存在问题：假设在一辆车上录了1h的汽车噪音，并重复合并到10000h的清晰对话中，这些噪音录音可能只是汽车噪音的很小的一个集合，模型可能会对这辆车的噪声过拟合。使用10000h噪音与10000h清晰对话合成比只使用1h噪音合成效果要更好，但是实际上很难采集这么多数据。 例子2：汽车识别，通过软件模拟合成很多汽车图片作为训练集，这些合成数据可能只是车辆的很小的子集，但是算法可能会对合成的一个小集合过拟合。 （3）如果你任务数据不匹配问题，建议进行误差分析或看看训练集和验证集，试图了解两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像验证集的数据作训练。人工数据合成可以提升模型表现，但使用人工合成数据时一定要谨慎，要记住有可能只从所有可能性的空间只选了很小一部分去模拟数。 7）迁移学习：神经网络可以从一个任务中学习得到知识，并将这些知识应用到另一个独立的任务中。 （1）适用场景：迁移来源问题有很多数据，但迁移目标问题没有那么多数据，找一个相关但不相同的任务可以帮助学习目标任务。 （2）不适用场景：迁移来源问题数据很少，但迁移目标问题数据很多。可以使用迁移学习不会有害处，但是对目标问题没有什么帮助。 （3）例子：从图像（猫、狗、鸟等）识别任务迁移学习阅读X射线扫描图 做法：把神经网络最后的输出层删除，重新创建输出层并赋予随机权重，然后使用放射诊断数据训练模型。如果有更多的数据，可以删除最后面几层网络，重新添加几层网络后再用新数据重新训练这几层，数据越多就可以重新训练越多层。如果有足够多的数据时就可以重新训练整个网络，那么这个网络在之前的数据训练称为预训练，在新数据上重新训练称为微调。 有很多低层次的特征（如边缘检测、曲线检测、点检测、阳性对象检测）从非常大的图像识别数据库中学习到这些知识，线条、点、曲线等这些知识（也许是对象的一小部分）可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。 算法学习到很多结构和图像形状信息（中层特征），其中一些知识可能会很有用，它就可能学到足够多的信息，学习到不同图像是有哪些部分组成的。 （4）例子：已经学习一个语音识别系统（输入音频，输出文本），利用迁移学习迁移到一个“唤醒词”/“触发词”检测系统（输入指定音频来唤醒设备）。 语音识别系统从10000小时数据训练，但对于触发字检测也许只有1小时数据（数据太少，不能用来拟合很多参数）。 即使触发字任务数据集很小，在训练语音识别系统时预先学到很多人类声音的特征、人类语言组成部分等知识，可以帮助我们建立一个很好的触发字检测系统。 （5）迁移学习的场景：源任务A，目标任务B 任务A和B有相同的输入时，迁移学习才有意义。例如输入的都是图像，或者输入的都是音频。 任务A的数据比任务B的数据多很多时，迁移学习才有意义。因为任务B的每个数据更有价值，对任务B来说通常任务A的数据量必须大得多才有帮助。 任务A的低层次特征可以帮助学习任务。 8）多任务学习能让你训练一个神经网络来执行许多任务。 （1）例如：计算机视觉物体检测系统中同时检测人、汽车、交通标志等多个任务，一个神经网络学习多个任务。 （2）多任务学习意义 可以共用低层次特征 如果每个任务的数据量差不多，多任务学习可以。这个准则不一定对。 例子：有100个任务在同时学习，任务的样本量只有1000个，如果只关注第100个任务。如果单独去学习第100个任务，只有1000个样本训练模型，而通过其它99项任务的训练共1000*99个样本，这可能大幅提高算法性能，可以提供很多知识来增强这个任务的性能。 当你可以训练一个足够大的神经网络，同时做好所有的工作，那么多任务学习比每个任务训练一个神经网络来完成各个单独的任务性能更好。否则如果不能够训练一个足够大的网络，多任务学习的替代方法是为每个任务训练一个单独的神经网络，而不是同一个神经网络中同时处理多个任务。 （3）多任务学习使用的频率要低于迁移学习，多任务学习比较少见，但计算机视觉物体检测是一个是一个例外。 9）端到端学习：以前有一些数据处理系统需要多个阶段的处理，端到端学习就是忽略所有这些不同的阶段，用单个神经网络代替它。 （1）例子：语音识别系统，输入音频，输出文本 传统语音识别需要很多个阶段处理：从语音中提取一些特征，在提取一些低层次特征之后应用机器学习算法在音频片段中找到音位（声音的基本单位，每个单词由多个音位组成）。 端到端学习：输入一段音频，直接输出文本。 （2）端到端学习挑战之一是需要大量的数据才能让系统表现良好。 当你只有3000h音频时，传统流水线的语音识别系统可能比端到端学习效果要好。 当你有10000h音频，甚至100000h音频时，端到端突然开始很厉害。 （3）例子：人脸识别系统 人脸识别系统分两步完成效果较好，第一步找到摄像头中人脸位置，第二步再把人脸放到放到识别系统进行训练。 虽然没有足够的数据进行端到端学习，但是有足够的数据直接对以上两个步骤同时进行学习。 10）是否要使用端到端的深度学习 （1）端到端学习的优点 只是让数据说话。如果你有足够多的训练数据，如果你训练一个足够大的神经网络，那么那么就可以学习从x到y最适合的函数映射是什么。 很少需要手工设计的组件，能够简化工作流程，不需要花太多时间去手工设计功能。 （2）端到端学习缺点 需要大量的数据。 它排除了可能有用的手工设计组件，当数据量不足时，没有使用手工设计组件。 2.进行误差分析 1）误差分析：如果算法还达不到理想效果，那么人工检查一下算法所犯的错误，也许可以让你了解接下来应该做什么，这个过程称为误差分析。 2）使用误差分析来估计某个想法是否值得解决的例子：调试一个取得90%准确率猫分类器 （1）检查一下算法分类出错的例子，注意到算法将一些狗分类为猫。 也许有人建议你针对狗图片优化算法：为了让算法不再将狗分类成猫，针对狗收集更多的狗图片，或者设计一些只处理狗的算法功能之类的。 问题是是否应该做一个项目专门处理狗的问题？这可能花费几个月时间才能让算法在狗问题上少识别为猫，也许没有效果。 （2）这里有个误差分析流程可以让你很快知道这个优化方向是否值得尝试： 收集一些（比如说100个）错误标记的验证集例子 逐一检查每个被错误识别的样本，看有多少个例子是狗。假如只有5%错误例子是狗，意味着即使完全解决狗的问题，只能修正100个错误中的5个，误差从10%下降到9.5%（10%*(1-5%)=9.5%），这就是关于这个优化的上限。 （3）在搭建应用系统时，这个简单的人工统计步骤（统计错误数量）误差分析可以节省大量时间，可以迅速决定什么是最重要的或最有希望的方向。 3）在做误差分析时也可以同时并行评估几个想法 （1）几个改善猫检测器的想法： 狗被识别为猫的问题 猫科动物（狮子、豹、猎豹等）被识别为猫的问题 图像模糊而误分类，改善算法来识别模糊图片 （2）建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 （3）这个分析步骤的结果可以给出一个估计，看是否值得去处理每个不同的错误类型。这里不一定是要解决占比最大的问题，它能让你对应该选择那些手段有个概念，给出了每个问题的性能上限，了解每种手段对性能有多大的提升空间。 4）进行误差分析时应该找一组错误例子（验证集或测试集中的错误例子），观察错误标记的例子看看假阳性和假阴性，统计属于不同错误类型的错误数量。 这个过程中，可能会得到启发，归纳出新的误差类型。 通过统计不同类型错误标记类型占比总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。 3. 清楚标注错误的数据 1）深度学习算法对训练集的随机误差是相当鲁棒的 （1）只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们。 （2）只要总数据集足够大，实际误差可能不会太高。 2）深度学习算法对随机误差是相当鲁棒的，但对系统性的错误就没有那么鲁棒了。 比如说，如果做标记的人一直把白色的狗标记成猫，那就是系统性的错误，经过学习后，分类器会把所有白色的狗都分类为猫。 3）如果验证集和测试集中有标记错误的样本 （1）如果担心验证集和测试集中标记出错的例子带来影响，建议在误差分析时增加一个额外的列来统计标记出错的例子数。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; （2）如果这些标记错误的例子验证影响了你在验证集上评估算法的能力，那么就应该花时间修正错误的标签。如果它没有严重到影响到用验证集评估成本偏差的能力，那就不需要花费宝贵的时间去处理。 （3）判断是否值得去修改标记出错的数据 假设系统达到90%准确度，10%的错误。 错误标记引起的错误的数量或百分比对验证集误差的影响，此处是6%*10%=0.6%。 其他原因导致的验证集错误对验证集误差的影响，此处是9.4%。 这种情况下，需要集中精力修正9.4%的误差，而标记出错导致的错误是总体错误的一小部分而已，不是当下最重要的任务。 （4）需要修正验证集标记错误的例子 假设系统达到98%准确度，2%的错误。 假设错误标记引起的错误对验证集误差的影响为0.6%，其他原因导致的影响为1.4%。 在评估模型时，假设模型A误差2.1%，模型B误差为1.9%。此时标记错误的样本足以影响我们评估哪个模型更好，此时应该修正验证集中的错误标记。 4）修正数据时指引和原则 （1）不管用什么方法来修改错误，都应该同时修改验证集和测试集上的错误，验证集和测试集必须来自相同的分布。 （2）强烈建议你同时检验算法判断正确和判断错误的样本，而不是只检测判断错误的样本。否则有可能有些被正确判断的样本其实是判断错误的，修正样本标签后导致对算法偏差的估计可能变得更大。 （3）由于训练集数据量比较大，也因为前面讨论过的训练集的随机误差对算法影响不大，所以我们可能会只修正验证集和测试集的错误标记，而不修改训练集的错误标记。此时，训练集与验证集和测试集来自不同的数据分布。 （4）验证集和测试集来自同一分布非常重要，但如果训练集来自稍微不同的分布是一件很合理的事情。 4. 快速搭建你的第一个系统，并进行迭代 1）开发一个全新的机器学习应用时，应该尽快建立第一个系统原型，然后快速迭代。 2）例子：语音识别系统有很多优化方向 有一些特定的技术可以让语音识别系统对嘈杂的背景更加健壮：咖啡店的噪音（很多人聊天）、车辆的噪音（高速上汽车的噪音等） 有一些方法可以让语音识别系统在处理带口音时更健壮 远场语音识别问题：麦克风与说话人距离很远的问题 儿童的语音识别带来的特征挑战（来自单词发音方面） 说话口吃问题 … 3）一般情况下，对于所有的机器学习程序可能会有50个方向可以优化前进，并且每个方向都是相对合理的，可以改善系统，如何选择一个方向集中精力处理是一个挑战。 4）如果搭建一个全新的机器学习程序，就是快速搭建好第一个系统，然后开始迭代。 （1）首先，快速设立验证集和测试集，还有评估指标。它决定了你的目标在哪里，如果你的目标定错了，之后改也是可以的。 （2）然后搭好一个机器学习系统原型，然后找到训练集，看看训练效果如何，在验证集合测试集评估指标表现如何。 （3）再进行偏差方差分析以及误差分析来确定下一步优先做什么。特别是如果误差分析让你了解到大部分误差的来源。 （4）建立初始系统的意义在于有一个训练过的系统让你确定偏差方差的范围，就可以知道下一步应该优先做什么。让你能够进行误差分析，可以观察一些错误，然后想出所有能进行的方向，知道哪些是最优希望的方向。 5）以下情况，快速搭建第一个系统的建议的适用程度要低一些，一开始就搭建比较复杂的系统 （1）如果你在这个应用程序领域有很多经验 （2）如果一个领域有很多可以借鉴的学术文献（如人脸识别领域），可以从现有大量文献为基础出发，一开始就搭建比较复杂的系统 5. 在不同的划分上进行训练并测试 1）深度学习算法对训练数据胃口很大，越多数据对训练越好，即使大部分数据来自不同的分布，从而导致训练集、验证集和测试集数据分布不一样的情况出现，越来越多团队都用来自和验证集和测试集分布不同的数据来训练。 2）处理训练集和测试集数据分布不一样的例子：猫分类器，训练数据来自网络（很清晰），测试数据来自手机拍照（很模糊） （1）来自手机上传的照片是真正关系的数据分布，手机上传的数量不多（如1万张），来自网络的照片数量很多（超过20万）。只用手机上的照片训练的话照片数量太少了，只使用网络的照片的话与真正关心的数据分布不一样，所以需要结合两组照片数据。 （2）错误的组合方式 把两组照片混合在一起，然后进行混洗，然后再按比例把照片分配到训练集、 验证集和测试集上。 比如，205000张照片作为训练集、2500张照片作为验证集、2500张照片作为测试集。验证集和测试集中只有119张照片来自手机上传，设立验证集的目的是告诉团队瞄准的目标，而瞄准的目标大部分来自网络下载的照片，这其实不是真实希望的。 （3）正确的组合方式 训练集205000张=全部网络照片20万张+一半用户上传的照片5000张，验证集和测试集都是2500张用户上传的照片（都是真实关心的数据分布）。 这样划分数据的好处在于，现在瞄准的目标就是我们想要处理的目标。 缺点在于训练集分布和验证集以及测试集分布不一样，但事实证明这样的数据划分在长期能带来更好的系统性能。 3）例子：语音识别系统的后视镜，可以语音沟通，如：“后视镜，请帮我找找到最近的加油站的导航方向”。很多数据（共500000条）来自其他语音识别应用，如：数据供应商买来的数据、智能语音激活音箱的数据、语音激活键盘的数据，只有20000条数据来自后视镜设备。 （1）划分方式一：训练集=全部其他语音识别数据500000条，验证集和测试集数据都是来自后视镜的数据各10000条。 （2）划分方式二（如果你觉得验证集和测试集不需要这么多数据）：训练集=全部其他语音识别数据500000条+后视镜数据10000条，验证集和测试集数据都是来自后视镜的数据各5000条。 6. 不匹配数据划分的偏差和方差 1）估计学习算法的偏差和方差可以帮我们确定接下来应该优先做的方向，但是如果训练集和验证集及测试集分布不同时，分析偏差和方差的方式会不一样。 2）例子：猫分类器，假设人类水平接近0%误差 （1）假设训练误差1%，验证集误差10% 在分布一样的时候，可以说这里存在很大的方差问题。 如果训练数据和验证数据来自不同的分布时，就不能确定的说这里存在很大的方差了。也许算法在验证集上做得不错，只是由于训练集更容易被识别，而验证集很难被识别。从训练集到验证集有两个因素发生变化：算法见过的训练数据没有见过验证集数据、验证集的数据分布不同。 （2）为了确认是由于泛化能力，还是由于数据分布不一样的原因，需要定义一组新的数据“训练-验证集” 这数据来源于训练集数据，但是不用于训练模型。把训练集随机打乱，并分一部分出来作为训练-验证集。 数据集分为4份：训练集、训练-验证集、验证集、测试集。 训练集和训练-验证集分布一样，验证集和测试集分布一样，验证集和测试集的数据是最后真实评估模型的数据，而训练集和训练-验证集与验证集和测试集数据分布不一样。 （3）训练集误差与训练-验证集误差的差距代表了模型的方差问题的可优化空间，从中可以知道模型的泛化能力。以下为方差很大的例子： 训练集误差为1% 训练-验证集误差为9% 验证集误差为10% （4）训练-验证集误差与验证集误差之间的差距代表数据不匹配的程度，因为算法没有直接在训练-验证集或验证集上训练过，这两者的数据来自不同的分布。以下为数据不匹配问题的例子： 训练集误差为1% 训练-验证集误差为1.5% 验证集误差为10% （5）存在很大偏差问题的例子： 人类水平误差为0% 训练集误差为10% 训练-验证集误差为11% 验证集误差为12% （6）同时存在偏差问题和数据不匹配问题的例子： 人类水平误差为0% 训练集误差为10% 训练-验证集误差为11% 验证集误差为20% 3）各个数据集误差差距总结 （1）训练集误差与贝叶斯误差的差值为可避免偏差值大小。 （2）训练-验证集误差与训练集误差的差值为方差值大小。 （3）验证集误差与训练-验证集误差的差值为数据不匹配问题的大小。 （4）测试集误差与验证集误差的差值为对验证集过拟合的程度，如果差值很大，说明需要一个更大的验证集。 4）贝叶斯误差、训练集误差、训练-验证集误差、验证集误差和测试集误差的值应该是从越来越大 （1）训练集和训练-验证集误差是从训练集分布评估的，验证集和测试集误差是对验证集测试集分布评估的。 （2）如果某个值没有变大（比上一个误差要小），如下面例子，说明训练数据比验证集和测试集数据难识别多了。 人类水平误差为4% 训练集误差为7% 训练-验证集误差为10% 验证集误差为6% 测试集误差为6% 5）更通用的分析方法 （1）制定以上表格，横轴是不同分布的训练集数据（例子中为来：自其它方式语音识别数据）和验证集/测试集数据（来自后视镜的语音识别数据）；纵轴是人类水平误差、参与训练的数据误差和没有参与训练的数据误差。 （2）正常情况下，我只需要分析图中红色框几项就可以找到方向：训练集与贝叶斯误差差值（可避免偏差）、训练-验证集与训练集误差差值（方差）、验证集与训练-验证集误差差值（数据不匹配）。 （3）进行表格中剩余的两项分析也是有用的：人类在真实分布（验证集/测试集数据）的误差、真实分布用于训练时的训练误差。当你继续进行更多分析时，分析并不一定会给你指明方向，但有时候你会洞察到一些特征。 对比人类在两种不同分布上的表现可以看出哪种数据分布更难被识别，上例中后视镜的数据更难被识别。 对比两种分布数据在训练集上的误差可以了解到偏差和方差，还有数据不匹配这个问题的不同程度。 7. 定位数据不匹配 1）数据不匹配问题没有完全系统的解决方案，但是有一些可以尝试的方法 （1）人工做误差分析，尝试了解训练集和验证测试集的具体差异。为了误差分析时避免对测试集过拟合，应该只人工去看验证集而不看测试集数据。汽车后视镜例子中： 假设发现验证集中有很多汽车噪音，这是验证集和训练集差异之一 发现在汽车里语音激活后视镜经常错误识别街道号码，真实使用时经常导航到某些街道，而训练数据中没有这些导航数据 （2）可以尝试把训练数据变得更像验证集数据，或者采集更多类似验证测试集的数据 如果发现车辆背景噪音是主要误差来源，可以模拟车辆噪声数据，人工合成噪音数据 如果发现很难识别街道号码，可以有意识收集更多人们说数字的音频数据，加到训练集中 2）人工数据合成 （1）例子1：清晰对话+汽车噪音=人工合成有噪音的对话 通过人工数据合成，可以快速制造更多的训练数据，那就不需要花时间实际出去收集数据了。 存在问题：假设在一辆车上录了1h的汽车噪音，并重复合并到10000h的清晰对话中，这些噪音录音可能只是汽车噪音的很小的一个集合，模型可能会对这辆车的噪声过拟合。使用10000h噪音与10000h清晰对话合成比只使用1h噪音合成效果要更好，但是实际上很难采集这么多数据。 还有一个难点是，人耳无法区分采集到的1h噪音与验证集中的噪音是否一致。 （2）例子2：汽车识别 通过软件模拟合成很多汽车图片作为训练集，这些合成数据可能只是车辆的很小的子集，但是算法可能会对合成的一个小集合过拟合 3）如果你任务数据不匹配问题，建议进行误差分析或看看训练集和验证集，试图了解两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像验证集的数据作训练。人工数据合成可以提升模型表现，但使用人工合成数据时一定要谨慎，要记住有可能只从所有可能性的空间只选了很小一部分去模拟数。 8. 迁移学习 1）迁移学习：神经网络可以从一个任务中学习得到知识，并将这些知识应用到另一个独立的任务中。 （1）适用场景：迁移来源问题有很多数据，但迁移目标问题没有那么多数据，找一个相关但不相同的任务可以帮助学习目标任务。 （2）不适用场景：迁移来源问题数据很少，但迁移目标问题数据很多。可以使用迁移学习不会有害处，但是对目标问题没有什么帮助。 2）例子：从图像（猫、狗、鸟等）识别任务迁移学习阅读X射线扫描图 （1）做法：把神经网络最后的输出层删除，重新创建输出层并赋予随机权重，然后使用放射诊断数据训练模型。 （2）如果有更多的数据，可以删除最后面几层网络，重新添加几层网络后再用新数据重新训练这几层，数据越多就可以重新训练越多层。 （3）如果有足够多的数据时就可以重新训练整个网络，那么这个网络在之前的数据训练称为预训练，在新数据上重新训练称为微调。 （4）当你做图像识别任务时，可以训练神经网络的所有常用参数，所有层的权重，然后得到一个图像识别预测网络。 有很多低层次的特征（如边缘检测、曲线检测、点检测、阳性对象检测）从非常大的图像识别数据库中学习到这些知识，线条、点、曲线等这些知识（也许是对象的一小部分）可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。 算法学习到很多结构和图像形状信息，其中一些知识可能会很有用，它就可能学到足够多的信息，学习到不同图像是有哪些部分组成的。 3）例子：已经学习一个语音识别系统（输入音频，输出文本），利用迁移学习迁移到一个“唤醒词”/“触发词”检测系统（输入指定音频来唤醒设备） （1）做法：把最后一层删除并加入新网络层，有时可以加入多层节点，这取决于你有多少数据 （2）迁移学习起作用的场合：迁移来源问题有很多数据，但迁移目标问题没有那么多数据。 例如：图像识别任务迁移学习到放射科任务 图像识别任务中有1百万个样本（有足够的数据学习低层次特征，前面几层学习到如何识别很多有用的特征），但对放射科任务只有1百个样本（数据非常少）。 即使放射科数据很少，但可以从图像识别训练中学到很多知识可以迁移并帮助放射科识别任务的性能。 如果图像识别任务数据很少，放射科数据很多，则不适合使用迁移学习，也许没有害处，但是没有帮助。 例子：语音识别系统迁移学习到触发字检测系统 语音识别系统从10000小时数据训练，但对于触发字检测也许只有1小时数据（数据太少，不能用来拟合很多参数）。 即使触发字任务数据集很小，在训练语音识别系统时预先学到很多人类声音的特征、人类语言组成部分等知识，可以帮助我们建立一个很好的触发字检测系统。 4）迁移学习的场景：源任务A，目标任务B （1）任务A和B有相同的输入时，迁移学习才有意义。例如输入的都是图像，或者输入的都是音频。 （2）任务A的数据比任务B的数据多很多时，迁移学习才有意义。因为任务B的每个数据更有价值，对任务B来说通常任务A的数据量必须大得多才有帮助。 （3）任务A的低层次特征可以帮助学习任务。 9. 多任务学习 1）多任务学习能让你训练一个神经网络来执行许多任务。例如：计算机视觉物体检测系统中同时检测人、汽车、交通标志等多个任务，一个神经网络学习多个任务。 2）多任务学习意义 （1）可以共用低层次特征 （2）如果每个任务的数据量差不多，多任务学习可以。这个准则不一定对。 例子：有100个任务在同时学习，任务的样本量只有1000个，如果只关注第100个任务。如果单独去学习第100个任务，只有1000个样本训练模型，而通过其它99项任务的训练共1000*99个样本，这可能大幅提高算法性能，可以提供很多知识来增强这个任务的性能。 （3）当你可以训练一个足够大的神经网络，同时做好所有的工作，那么多任务学习比每个任务训练一个神经网络来完成各个单独的任务性能更好。否则如果不能够训练一个足够大的网络，多任务学习的替代方法是为每个任务训练一个单独的神经网络，而不是同一个神经网络中同时处理多个任务。 3）多任务学习使用的频率要低于迁移学习，多任务学习比较少见，但计算机视觉物体检测是一个是一个例外。 10. 什么是端到端的深度学习 1）端到端学习：以前有一些数据处理系统需要多个阶段的处理，端到端学习就是忽略所有这些不同的阶段，用单个神经网络代替它。 2）例子：语音识别系统，输入音频，输出文本 （1）传统语音识别需要很多个阶段处理：从语音中提取一些特征，在提取一些低层次特征之后应用机器学习算法在音频片段中找到音位（声音的基本单位，每个单词由多个音位组成）。 （2）端到端学习：输入一段音频，直接输出文本。 3）端到端学习挑战之一是需要大量的数据才能让系统表现良好。例子：语音识别系统 （1）当你只有3000h音频时，传统流水线可能比端到端学习效果要好。 （2）当你有10000h音频，甚至100000h音频时，端到端突然开始很厉害。 4）例子：人脸识别系统 （1）人脸识别系统分两步完成效果较好，第一步找到摄像头中人脸位置，第二步再把人脸放到放到识别系统进行训练。 （2）虽然没有足够的数据进行端到端学习，但是有足够的数据直接对以上两个步骤同时进行学习。 11. 是否要使用端到端的深度学习 1）端到端学习的优点 （1）只是让数据说话。如果你有足够多的训练数据，如果你训练一个足够大的神经网络，那么那么就可以学习从x到y最适合的函数映射是什么。 （2）很少需要手工设计的组件，能够简化工作流程，不需要花太多时间去手工设计功能。 2）端到端学习缺点 （1）需要大量的数据。 （2）它排除了可能有用的手工设计组件。 如果你没有足够的数据，学习算法就没办法从很小的训练集中获得洞察力，所以手工设计组件在这种情况可能是把人类知识直接注入算法的途径。 我们学习的算法有两个主要的知识来源：来自数据和来自手工设计的任何东西。 &nbsp; 相关文章： 《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略1 学习总结 （如何进一步优化系统的方法论）" />
<meta property="og:description" content="作者：jliang https://blog.csdn.net/jliang3 《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略2 学习笔记 &nbsp; 1.重点归纳 1）误差分析：如果算法还达不到理想效果，那么人工检查一下算法所犯的错误，也许可以让你了解接下来应该做什么，这个过程称为误差分析。 （1）例子：一个取得90%准确率猫分类器，注意到有部分狗样本被识别为猫，使用误差分析来估计是否应该专门解决这个问题。随机抽样100个错误样本，检查把狗分类成猫的样本数量，如果这个样本占比很小，则不值得专门去优化这个问题。 （2）在做误差分析时也可以同时并行评估几个想法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 （3）进行误差分析时应该找一组错误例子（验证集或测试集中的错误例子），观察错误标记的例子看看假阳性和假阴性，统计属于不同错误类型的错误数量。 这个过程中，可能会得到启发，归纳出新的误差类型。 通过统计不同类型错误标记类型占比总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。 2）标注错误的数据 （1）深度学习算法对训练集的随机误差是相当鲁棒的 只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们 只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们 （2）深度学习算法对系统性的错误就没有那么鲁棒了。比如说，如果做标记的人一直把白色的狗标记成猫。 （3）如果验证集和测试集中有标记错误的样本 误差分析时增加一个额外的列来统计标记出错的例子数，根据标记出错样本数来估计修改错误后对误差值的影响。 如果这些标记错误的例子验证影响了你在验证集上评估算法的能力，那么就应该花时间修正错误的标签。如果它没有严重到影响到用验证集评估成本偏差的能力，那就不需要花费宝贵的时间去处理。 需要修正验证集标记错误的例子：假设系统达到98%准确度（2%的错误），假设错误标记引起的错误对验证集误差的影响为0.6%（30%*2%=0.6%）。评估模型时模型A误差是2.1%，模型B为1.9%，此时标记错误的样本足以影响我们评估哪个模型更好，此时应该修正验证集中的错误标记 （4）修正数据时指引和原则 应该同时修改验证集和测试集上的错误，验证集和测试集必须来自相同的分布，但训练集可以来自稍微不同的分布。 检查数据时检测全部验证/测试集，而不是只检测判断错误的样本。否则有可能有些被正确判断的样本其实是判断错误的，修正样本标签后导致对算法偏差的估计可能变得更大。 由于训练集数据量比较大，也因为前面讨论过的训练集的随机误差对算法影响不大，所以我们可能会只修正验证集和测试集的错误标记，而不修改训练集的错误标记。此时，训练集与验证集和测试集来自不同的数据分布。 3）开发一个全新的机器学习应用时，应该尽快建立第一个系统原型，然后快速迭代。 （1）流程 首先，快速设立验证集和测试集，还有评估指标。它决定了你的目标在哪里，如果你的目标定错了，之后改也是可以的。 然后搭好一个机器学习系统原型，然后找到训练集，看看训练效果如何，在验证集合测试集评估指标表现如何。 再进行偏差方差分析以及误差分析来确定下一步优先做什么。特别是如果误差分析让你了解到大部分误差的来源。 建立初始系统的意义在于有一个训练过的系统让你确定偏差方差的范围，就可以知道下一步应该优先做什么。让你能够进行误差分析，可以观察一些错误，然后想出所有能进行的方向，知道哪些是最优希望的方向。 （2）以下情况，快速搭建第一个系统的建议的适用程度要低一些，一开始就搭建比较复杂的系统 如果你在这个应用程序领域有很多经验 如果一个领域有很多可以借鉴的学术文献（如人脸识别领域），可以从现有大量文献为基础出发，一开始就搭建比较复杂的系统 4）训练样本与验证/测试来自不同的分布 （1）深度学习算法需要大量的数据，即使大部分数据来自不同的分布也比只有很少的数据好，从而导致训练集、验证集和测试集数据分布不一样的情况出现，越来越多团队都用来自和验证集和测试集分布不同的数据来训练。 （2）例子：猫分类器，训练数据来自网络（很清晰），测试数据来自手机拍照（很模糊） （3）错误的组合数据方式：把两组照片混合在一起，然后进行混洗，然后再按比例把照片分配到训练集、 验证集和测试集上。 （4）猫分类器正确的组合数据方式： 训练集205000张=全部网络照片20万张+一半用户上传的照片5000张，验证集和测试集都是2500张用户上传的照片（都是真实关心的数据分布）。 这样划分数据的好处在于，现在瞄准的目标就是我们想要处理的目标。 缺点在于训练集分布和验证集以及测试集分布不一样，但事实证明这样的数据划分在长期能带来更好的系统性能。 （5）例子：语音识别系统的后视镜，如：“后视镜，请帮我找找到最近的加油站的导航方向”。很多数据（共500000条）来自其他语音识别应用，如：数据供应商买来的数据、智能语音激活音箱的数据、语音激活键盘的数据，只有20000条数据来自后视镜设备 划分方式一：训练集=全部其他语音识别数据500000条，验证集和测试集数据都是来自后视镜的数据各10000条。 划分方式二（如果你觉得验证集和测试集不需要这么多数据）：训练集=全部其他语音识别数据500000条+后视镜数据10000条，验证集和测试集数据都是来自后视镜的数据各5000条。 5） 不匹配数据划分的偏差和方差 （1）估计学习算法的偏差和方差可以帮我们确定接下来应该优先做的方向，但是如果训练集和验证集及测试集分布不同时，分析偏差和方差的方式会不一样。 （2）为了确认是由于泛化能力，还是由于数据分布不一样的原因，需要定义一组新的数据“训练-验证集”。数据集分为4份：训练集、训练-验证集、验证集、测试集 （3）训练集误差与训练-验证集误差的差距代表了模型的方差问题的可优化空间，从中可以知道模型的泛化能力。 （4）训练-验证集误差与验证集误差之间的差距代表数据不匹配的程度，因为算法没有直接在训练-验证集或验证集上训练过，这两者的数据来自不同的分布。 （5）各个数据集误差差距总结 训练集误差与贝叶斯误差的差值为可避免偏差值大小。 训练-验证集误差与训练集误差的差值为方差值大小。 验证集误差与训练-验证集误差的差值为数据不匹配问题的大小。 测试集误差与验证集误差的差值为对验证集过拟合的程度，如果差值很大，说明需要一个更大的验证集。 （6）贝叶斯误差、训练集误差、训练-验证集误差、验证集误差和测试集误差的值应该是从越来越大 训练集和训练-验证集误差是从训练集分布评估的，验证集和测试集误差是对验证集测试集分布评估的。 如果某个值没有变大（比上一个误差要小），如下面例子，说明训练数据比验证集和测试集数据难识别多了。 人类水平误差为4% 训练集误差为7% 训练-验证集误差为10% 验证集误差为6% 测试集误差为6% （7）通用的分析方法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 制定以上表格，横轴是不同分布的训练集数据（例子中为来：自其它方式语音识别数据）和验证集/测试集数据（来自后视镜的语音识别数据）；纵轴是人类水平误差、参与训练的数据误差和没有参与训练的数据误差。 正常情况下，我只需要分析图中红色框几项就可以找到方向：训练集与贝叶斯误差差值（可避免偏差）、训练-验证集与训练集误差差值（方差）、验证集与训练-验证集误差差值（数据不匹配）。 进行表格中剩余的两项分析也是有用的：人类在真实分布（验证集/测试集数据）的误差、真实分布用于训练时的训练误差。当你继续进行更多分析时，分析并不一定会给你指明方向，但有时候你会洞察到一些特征。 对比人类在两种不同分布上的表现可以看出哪种数据分布更难被识别，上例中后视镜的数据更难被识别。 对比两种分布数据在训练集上的误差可以了解到偏差和方差，还有数据不匹配这个问题的不同程度。 6）定位数据不匹配 （1）数据不匹配问题没有完全系统的解决方案，但是有一些可以尝试的方法 人工做误差分析，尝试了解训练集和验证测试集的具体差异。为了误差分析时避免对测试集过拟合，应该只人工去看验证集而不看测试集数据。汽车后视镜例子中： 假设发现验证集中有很多汽车噪音，这是验证集和训练集差异之一 发现在汽车里语音激活后视镜经常错误识别街道号码，真实使用时经常导航到某些街道，而训练数据中没有这些导航数据 可以尝试把训练数据变得更像验证集数据，或者采集更多类似验证测试集的数据 如果发现车辆背景噪音是主要误差来源，可以模拟车辆噪声数据，人工合成噪音数据 如果发现很难识别街道号码，可以有意识收集更多人们说数字的音频数据，加到训练集中 （2）人工数据合成 例子1：清晰对话+汽车噪音=人工合成有噪音的对话。存在问题：假设在一辆车上录了1h的汽车噪音，并重复合并到10000h的清晰对话中，这些噪音录音可能只是汽车噪音的很小的一个集合，模型可能会对这辆车的噪声过拟合。使用10000h噪音与10000h清晰对话合成比只使用1h噪音合成效果要更好，但是实际上很难采集这么多数据。 例子2：汽车识别，通过软件模拟合成很多汽车图片作为训练集，这些合成数据可能只是车辆的很小的子集，但是算法可能会对合成的一个小集合过拟合。 （3）如果你任务数据不匹配问题，建议进行误差分析或看看训练集和验证集，试图了解两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像验证集的数据作训练。人工数据合成可以提升模型表现，但使用人工合成数据时一定要谨慎，要记住有可能只从所有可能性的空间只选了很小一部分去模拟数。 7）迁移学习：神经网络可以从一个任务中学习得到知识，并将这些知识应用到另一个独立的任务中。 （1）适用场景：迁移来源问题有很多数据，但迁移目标问题没有那么多数据，找一个相关但不相同的任务可以帮助学习目标任务。 （2）不适用场景：迁移来源问题数据很少，但迁移目标问题数据很多。可以使用迁移学习不会有害处，但是对目标问题没有什么帮助。 （3）例子：从图像（猫、狗、鸟等）识别任务迁移学习阅读X射线扫描图 做法：把神经网络最后的输出层删除，重新创建输出层并赋予随机权重，然后使用放射诊断数据训练模型。如果有更多的数据，可以删除最后面几层网络，重新添加几层网络后再用新数据重新训练这几层，数据越多就可以重新训练越多层。如果有足够多的数据时就可以重新训练整个网络，那么这个网络在之前的数据训练称为预训练，在新数据上重新训练称为微调。 有很多低层次的特征（如边缘检测、曲线检测、点检测、阳性对象检测）从非常大的图像识别数据库中学习到这些知识，线条、点、曲线等这些知识（也许是对象的一小部分）可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。 算法学习到很多结构和图像形状信息（中层特征），其中一些知识可能会很有用，它就可能学到足够多的信息，学习到不同图像是有哪些部分组成的。 （4）例子：已经学习一个语音识别系统（输入音频，输出文本），利用迁移学习迁移到一个“唤醒词”/“触发词”检测系统（输入指定音频来唤醒设备）。 语音识别系统从10000小时数据训练，但对于触发字检测也许只有1小时数据（数据太少，不能用来拟合很多参数）。 即使触发字任务数据集很小，在训练语音识别系统时预先学到很多人类声音的特征、人类语言组成部分等知识，可以帮助我们建立一个很好的触发字检测系统。 （5）迁移学习的场景：源任务A，目标任务B 任务A和B有相同的输入时，迁移学习才有意义。例如输入的都是图像，或者输入的都是音频。 任务A的数据比任务B的数据多很多时，迁移学习才有意义。因为任务B的每个数据更有价值，对任务B来说通常任务A的数据量必须大得多才有帮助。 任务A的低层次特征可以帮助学习任务。 8）多任务学习能让你训练一个神经网络来执行许多任务。 （1）例如：计算机视觉物体检测系统中同时检测人、汽车、交通标志等多个任务，一个神经网络学习多个任务。 （2）多任务学习意义 可以共用低层次特征 如果每个任务的数据量差不多，多任务学习可以。这个准则不一定对。 例子：有100个任务在同时学习，任务的样本量只有1000个，如果只关注第100个任务。如果单独去学习第100个任务，只有1000个样本训练模型，而通过其它99项任务的训练共1000*99个样本，这可能大幅提高算法性能，可以提供很多知识来增强这个任务的性能。 当你可以训练一个足够大的神经网络，同时做好所有的工作，那么多任务学习比每个任务训练一个神经网络来完成各个单独的任务性能更好。否则如果不能够训练一个足够大的网络，多任务学习的替代方法是为每个任务训练一个单独的神经网络，而不是同一个神经网络中同时处理多个任务。 （3）多任务学习使用的频率要低于迁移学习，多任务学习比较少见，但计算机视觉物体检测是一个是一个例外。 9）端到端学习：以前有一些数据处理系统需要多个阶段的处理，端到端学习就是忽略所有这些不同的阶段，用单个神经网络代替它。 （1）例子：语音识别系统，输入音频，输出文本 传统语音识别需要很多个阶段处理：从语音中提取一些特征，在提取一些低层次特征之后应用机器学习算法在音频片段中找到音位（声音的基本单位，每个单词由多个音位组成）。 端到端学习：输入一段音频，直接输出文本。 （2）端到端学习挑战之一是需要大量的数据才能让系统表现良好。 当你只有3000h音频时，传统流水线的语音识别系统可能比端到端学习效果要好。 当你有10000h音频，甚至100000h音频时，端到端突然开始很厉害。 （3）例子：人脸识别系统 人脸识别系统分两步完成效果较好，第一步找到摄像头中人脸位置，第二步再把人脸放到放到识别系统进行训练。 虽然没有足够的数据进行端到端学习，但是有足够的数据直接对以上两个步骤同时进行学习。 10）是否要使用端到端的深度学习 （1）端到端学习的优点 只是让数据说话。如果你有足够多的训练数据，如果你训练一个足够大的神经网络，那么那么就可以学习从x到y最适合的函数映射是什么。 很少需要手工设计的组件，能够简化工作流程，不需要花太多时间去手工设计功能。 （2）端到端学习缺点 需要大量的数据。 它排除了可能有用的手工设计组件，当数据量不足时，没有使用手工设计组件。 2.进行误差分析 1）误差分析：如果算法还达不到理想效果，那么人工检查一下算法所犯的错误，也许可以让你了解接下来应该做什么，这个过程称为误差分析。 2）使用误差分析来估计某个想法是否值得解决的例子：调试一个取得90%准确率猫分类器 （1）检查一下算法分类出错的例子，注意到算法将一些狗分类为猫。 也许有人建议你针对狗图片优化算法：为了让算法不再将狗分类成猫，针对狗收集更多的狗图片，或者设计一些只处理狗的算法功能之类的。 问题是是否应该做一个项目专门处理狗的问题？这可能花费几个月时间才能让算法在狗问题上少识别为猫，也许没有效果。 （2）这里有个误差分析流程可以让你很快知道这个优化方向是否值得尝试： 收集一些（比如说100个）错误标记的验证集例子 逐一检查每个被错误识别的样本，看有多少个例子是狗。假如只有5%错误例子是狗，意味着即使完全解决狗的问题，只能修正100个错误中的5个，误差从10%下降到9.5%（10%*(1-5%)=9.5%），这就是关于这个优化的上限。 （3）在搭建应用系统时，这个简单的人工统计步骤（统计错误数量）误差分析可以节省大量时间，可以迅速决定什么是最重要的或最有希望的方向。 3）在做误差分析时也可以同时并行评估几个想法 （1）几个改善猫检测器的想法： 狗被识别为猫的问题 猫科动物（狮子、豹、猎豹等）被识别为猫的问题 图像模糊而误分类，改善算法来识别模糊图片 （2）建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 （3）这个分析步骤的结果可以给出一个估计，看是否值得去处理每个不同的错误类型。这里不一定是要解决占比最大的问题，它能让你对应该选择那些手段有个概念，给出了每个问题的性能上限，了解每种手段对性能有多大的提升空间。 4）进行误差分析时应该找一组错误例子（验证集或测试集中的错误例子），观察错误标记的例子看看假阳性和假阴性，统计属于不同错误类型的错误数量。 这个过程中，可能会得到启发，归纳出新的误差类型。 通过统计不同类型错误标记类型占比总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。 3. 清楚标注错误的数据 1）深度学习算法对训练集的随机误差是相当鲁棒的 （1）只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们。 （2）只要总数据集足够大，实际误差可能不会太高。 2）深度学习算法对随机误差是相当鲁棒的，但对系统性的错误就没有那么鲁棒了。 比如说，如果做标记的人一直把白色的狗标记成猫，那就是系统性的错误，经过学习后，分类器会把所有白色的狗都分类为猫。 3）如果验证集和测试集中有标记错误的样本 （1）如果担心验证集和测试集中标记出错的例子带来影响，建议在误差分析时增加一个额外的列来统计标记出错的例子数。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; （2）如果这些标记错误的例子验证影响了你在验证集上评估算法的能力，那么就应该花时间修正错误的标签。如果它没有严重到影响到用验证集评估成本偏差的能力，那就不需要花费宝贵的时间去处理。 （3）判断是否值得去修改标记出错的数据 假设系统达到90%准确度，10%的错误。 错误标记引起的错误的数量或百分比对验证集误差的影响，此处是6%*10%=0.6%。 其他原因导致的验证集错误对验证集误差的影响，此处是9.4%。 这种情况下，需要集中精力修正9.4%的误差，而标记出错导致的错误是总体错误的一小部分而已，不是当下最重要的任务。 （4）需要修正验证集标记错误的例子 假设系统达到98%准确度，2%的错误。 假设错误标记引起的错误对验证集误差的影响为0.6%，其他原因导致的影响为1.4%。 在评估模型时，假设模型A误差2.1%，模型B误差为1.9%。此时标记错误的样本足以影响我们评估哪个模型更好，此时应该修正验证集中的错误标记。 4）修正数据时指引和原则 （1）不管用什么方法来修改错误，都应该同时修改验证集和测试集上的错误，验证集和测试集必须来自相同的分布。 （2）强烈建议你同时检验算法判断正确和判断错误的样本，而不是只检测判断错误的样本。否则有可能有些被正确判断的样本其实是判断错误的，修正样本标签后导致对算法偏差的估计可能变得更大。 （3）由于训练集数据量比较大，也因为前面讨论过的训练集的随机误差对算法影响不大，所以我们可能会只修正验证集和测试集的错误标记，而不修改训练集的错误标记。此时，训练集与验证集和测试集来自不同的数据分布。 （4）验证集和测试集来自同一分布非常重要，但如果训练集来自稍微不同的分布是一件很合理的事情。 4. 快速搭建你的第一个系统，并进行迭代 1）开发一个全新的机器学习应用时，应该尽快建立第一个系统原型，然后快速迭代。 2）例子：语音识别系统有很多优化方向 有一些特定的技术可以让语音识别系统对嘈杂的背景更加健壮：咖啡店的噪音（很多人聊天）、车辆的噪音（高速上汽车的噪音等） 有一些方法可以让语音识别系统在处理带口音时更健壮 远场语音识别问题：麦克风与说话人距离很远的问题 儿童的语音识别带来的特征挑战（来自单词发音方面） 说话口吃问题 … 3）一般情况下，对于所有的机器学习程序可能会有50个方向可以优化前进，并且每个方向都是相对合理的，可以改善系统，如何选择一个方向集中精力处理是一个挑战。 4）如果搭建一个全新的机器学习程序，就是快速搭建好第一个系统，然后开始迭代。 （1）首先，快速设立验证集和测试集，还有评估指标。它决定了你的目标在哪里，如果你的目标定错了，之后改也是可以的。 （2）然后搭好一个机器学习系统原型，然后找到训练集，看看训练效果如何，在验证集合测试集评估指标表现如何。 （3）再进行偏差方差分析以及误差分析来确定下一步优先做什么。特别是如果误差分析让你了解到大部分误差的来源。 （4）建立初始系统的意义在于有一个训练过的系统让你确定偏差方差的范围，就可以知道下一步应该优先做什么。让你能够进行误差分析，可以观察一些错误，然后想出所有能进行的方向，知道哪些是最优希望的方向。 5）以下情况，快速搭建第一个系统的建议的适用程度要低一些，一开始就搭建比较复杂的系统 （1）如果你在这个应用程序领域有很多经验 （2）如果一个领域有很多可以借鉴的学术文献（如人脸识别领域），可以从现有大量文献为基础出发，一开始就搭建比较复杂的系统 5. 在不同的划分上进行训练并测试 1）深度学习算法对训练数据胃口很大，越多数据对训练越好，即使大部分数据来自不同的分布，从而导致训练集、验证集和测试集数据分布不一样的情况出现，越来越多团队都用来自和验证集和测试集分布不同的数据来训练。 2）处理训练集和测试集数据分布不一样的例子：猫分类器，训练数据来自网络（很清晰），测试数据来自手机拍照（很模糊） （1）来自手机上传的照片是真正关系的数据分布，手机上传的数量不多（如1万张），来自网络的照片数量很多（超过20万）。只用手机上的照片训练的话照片数量太少了，只使用网络的照片的话与真正关心的数据分布不一样，所以需要结合两组照片数据。 （2）错误的组合方式 把两组照片混合在一起，然后进行混洗，然后再按比例把照片分配到训练集、 验证集和测试集上。 比如，205000张照片作为训练集、2500张照片作为验证集、2500张照片作为测试集。验证集和测试集中只有119张照片来自手机上传，设立验证集的目的是告诉团队瞄准的目标，而瞄准的目标大部分来自网络下载的照片，这其实不是真实希望的。 （3）正确的组合方式 训练集205000张=全部网络照片20万张+一半用户上传的照片5000张，验证集和测试集都是2500张用户上传的照片（都是真实关心的数据分布）。 这样划分数据的好处在于，现在瞄准的目标就是我们想要处理的目标。 缺点在于训练集分布和验证集以及测试集分布不一样，但事实证明这样的数据划分在长期能带来更好的系统性能。 3）例子：语音识别系统的后视镜，可以语音沟通，如：“后视镜，请帮我找找到最近的加油站的导航方向”。很多数据（共500000条）来自其他语音识别应用，如：数据供应商买来的数据、智能语音激活音箱的数据、语音激活键盘的数据，只有20000条数据来自后视镜设备。 （1）划分方式一：训练集=全部其他语音识别数据500000条，验证集和测试集数据都是来自后视镜的数据各10000条。 （2）划分方式二（如果你觉得验证集和测试集不需要这么多数据）：训练集=全部其他语音识别数据500000条+后视镜数据10000条，验证集和测试集数据都是来自后视镜的数据各5000条。 6. 不匹配数据划分的偏差和方差 1）估计学习算法的偏差和方差可以帮我们确定接下来应该优先做的方向，但是如果训练集和验证集及测试集分布不同时，分析偏差和方差的方式会不一样。 2）例子：猫分类器，假设人类水平接近0%误差 （1）假设训练误差1%，验证集误差10% 在分布一样的时候，可以说这里存在很大的方差问题。 如果训练数据和验证数据来自不同的分布时，就不能确定的说这里存在很大的方差了。也许算法在验证集上做得不错，只是由于训练集更容易被识别，而验证集很难被识别。从训练集到验证集有两个因素发生变化：算法见过的训练数据没有见过验证集数据、验证集的数据分布不同。 （2）为了确认是由于泛化能力，还是由于数据分布不一样的原因，需要定义一组新的数据“训练-验证集” 这数据来源于训练集数据，但是不用于训练模型。把训练集随机打乱，并分一部分出来作为训练-验证集。 数据集分为4份：训练集、训练-验证集、验证集、测试集。 训练集和训练-验证集分布一样，验证集和测试集分布一样，验证集和测试集的数据是最后真实评估模型的数据，而训练集和训练-验证集与验证集和测试集数据分布不一样。 （3）训练集误差与训练-验证集误差的差距代表了模型的方差问题的可优化空间，从中可以知道模型的泛化能力。以下为方差很大的例子： 训练集误差为1% 训练-验证集误差为9% 验证集误差为10% （4）训练-验证集误差与验证集误差之间的差距代表数据不匹配的程度，因为算法没有直接在训练-验证集或验证集上训练过，这两者的数据来自不同的分布。以下为数据不匹配问题的例子： 训练集误差为1% 训练-验证集误差为1.5% 验证集误差为10% （5）存在很大偏差问题的例子： 人类水平误差为0% 训练集误差为10% 训练-验证集误差为11% 验证集误差为12% （6）同时存在偏差问题和数据不匹配问题的例子： 人类水平误差为0% 训练集误差为10% 训练-验证集误差为11% 验证集误差为20% 3）各个数据集误差差距总结 （1）训练集误差与贝叶斯误差的差值为可避免偏差值大小。 （2）训练-验证集误差与训练集误差的差值为方差值大小。 （3）验证集误差与训练-验证集误差的差值为数据不匹配问题的大小。 （4）测试集误差与验证集误差的差值为对验证集过拟合的程度，如果差值很大，说明需要一个更大的验证集。 4）贝叶斯误差、训练集误差、训练-验证集误差、验证集误差和测试集误差的值应该是从越来越大 （1）训练集和训练-验证集误差是从训练集分布评估的，验证集和测试集误差是对验证集测试集分布评估的。 （2）如果某个值没有变大（比上一个误差要小），如下面例子，说明训练数据比验证集和测试集数据难识别多了。 人类水平误差为4% 训练集误差为7% 训练-验证集误差为10% 验证集误差为6% 测试集误差为6% 5）更通用的分析方法 （1）制定以上表格，横轴是不同分布的训练集数据（例子中为来：自其它方式语音识别数据）和验证集/测试集数据（来自后视镜的语音识别数据）；纵轴是人类水平误差、参与训练的数据误差和没有参与训练的数据误差。 （2）正常情况下，我只需要分析图中红色框几项就可以找到方向：训练集与贝叶斯误差差值（可避免偏差）、训练-验证集与训练集误差差值（方差）、验证集与训练-验证集误差差值（数据不匹配）。 （3）进行表格中剩余的两项分析也是有用的：人类在真实分布（验证集/测试集数据）的误差、真实分布用于训练时的训练误差。当你继续进行更多分析时，分析并不一定会给你指明方向，但有时候你会洞察到一些特征。 对比人类在两种不同分布上的表现可以看出哪种数据分布更难被识别，上例中后视镜的数据更难被识别。 对比两种分布数据在训练集上的误差可以了解到偏差和方差，还有数据不匹配这个问题的不同程度。 7. 定位数据不匹配 1）数据不匹配问题没有完全系统的解决方案，但是有一些可以尝试的方法 （1）人工做误差分析，尝试了解训练集和验证测试集的具体差异。为了误差分析时避免对测试集过拟合，应该只人工去看验证集而不看测试集数据。汽车后视镜例子中： 假设发现验证集中有很多汽车噪音，这是验证集和训练集差异之一 发现在汽车里语音激活后视镜经常错误识别街道号码，真实使用时经常导航到某些街道，而训练数据中没有这些导航数据 （2）可以尝试把训练数据变得更像验证集数据，或者采集更多类似验证测试集的数据 如果发现车辆背景噪音是主要误差来源，可以模拟车辆噪声数据，人工合成噪音数据 如果发现很难识别街道号码，可以有意识收集更多人们说数字的音频数据，加到训练集中 2）人工数据合成 （1）例子1：清晰对话+汽车噪音=人工合成有噪音的对话 通过人工数据合成，可以快速制造更多的训练数据，那就不需要花时间实际出去收集数据了。 存在问题：假设在一辆车上录了1h的汽车噪音，并重复合并到10000h的清晰对话中，这些噪音录音可能只是汽车噪音的很小的一个集合，模型可能会对这辆车的噪声过拟合。使用10000h噪音与10000h清晰对话合成比只使用1h噪音合成效果要更好，但是实际上很难采集这么多数据。 还有一个难点是，人耳无法区分采集到的1h噪音与验证集中的噪音是否一致。 （2）例子2：汽车识别 通过软件模拟合成很多汽车图片作为训练集，这些合成数据可能只是车辆的很小的子集，但是算法可能会对合成的一个小集合过拟合 3）如果你任务数据不匹配问题，建议进行误差分析或看看训练集和验证集，试图了解两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像验证集的数据作训练。人工数据合成可以提升模型表现，但使用人工合成数据时一定要谨慎，要记住有可能只从所有可能性的空间只选了很小一部分去模拟数。 8. 迁移学习 1）迁移学习：神经网络可以从一个任务中学习得到知识，并将这些知识应用到另一个独立的任务中。 （1）适用场景：迁移来源问题有很多数据，但迁移目标问题没有那么多数据，找一个相关但不相同的任务可以帮助学习目标任务。 （2）不适用场景：迁移来源问题数据很少，但迁移目标问题数据很多。可以使用迁移学习不会有害处，但是对目标问题没有什么帮助。 2）例子：从图像（猫、狗、鸟等）识别任务迁移学习阅读X射线扫描图 （1）做法：把神经网络最后的输出层删除，重新创建输出层并赋予随机权重，然后使用放射诊断数据训练模型。 （2）如果有更多的数据，可以删除最后面几层网络，重新添加几层网络后再用新数据重新训练这几层，数据越多就可以重新训练越多层。 （3）如果有足够多的数据时就可以重新训练整个网络，那么这个网络在之前的数据训练称为预训练，在新数据上重新训练称为微调。 （4）当你做图像识别任务时，可以训练神经网络的所有常用参数，所有层的权重，然后得到一个图像识别预测网络。 有很多低层次的特征（如边缘检测、曲线检测、点检测、阳性对象检测）从非常大的图像识别数据库中学习到这些知识，线条、点、曲线等这些知识（也许是对象的一小部分）可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。 算法学习到很多结构和图像形状信息，其中一些知识可能会很有用，它就可能学到足够多的信息，学习到不同图像是有哪些部分组成的。 3）例子：已经学习一个语音识别系统（输入音频，输出文本），利用迁移学习迁移到一个“唤醒词”/“触发词”检测系统（输入指定音频来唤醒设备） （1）做法：把最后一层删除并加入新网络层，有时可以加入多层节点，这取决于你有多少数据 （2）迁移学习起作用的场合：迁移来源问题有很多数据，但迁移目标问题没有那么多数据。 例如：图像识别任务迁移学习到放射科任务 图像识别任务中有1百万个样本（有足够的数据学习低层次特征，前面几层学习到如何识别很多有用的特征），但对放射科任务只有1百个样本（数据非常少）。 即使放射科数据很少，但可以从图像识别训练中学到很多知识可以迁移并帮助放射科识别任务的性能。 如果图像识别任务数据很少，放射科数据很多，则不适合使用迁移学习，也许没有害处，但是没有帮助。 例子：语音识别系统迁移学习到触发字检测系统 语音识别系统从10000小时数据训练，但对于触发字检测也许只有1小时数据（数据太少，不能用来拟合很多参数）。 即使触发字任务数据集很小，在训练语音识别系统时预先学到很多人类声音的特征、人类语言组成部分等知识，可以帮助我们建立一个很好的触发字检测系统。 4）迁移学习的场景：源任务A，目标任务B （1）任务A和B有相同的输入时，迁移学习才有意义。例如输入的都是图像，或者输入的都是音频。 （2）任务A的数据比任务B的数据多很多时，迁移学习才有意义。因为任务B的每个数据更有价值，对任务B来说通常任务A的数据量必须大得多才有帮助。 （3）任务A的低层次特征可以帮助学习任务。 9. 多任务学习 1）多任务学习能让你训练一个神经网络来执行许多任务。例如：计算机视觉物体检测系统中同时检测人、汽车、交通标志等多个任务，一个神经网络学习多个任务。 2）多任务学习意义 （1）可以共用低层次特征 （2）如果每个任务的数据量差不多，多任务学习可以。这个准则不一定对。 例子：有100个任务在同时学习，任务的样本量只有1000个，如果只关注第100个任务。如果单独去学习第100个任务，只有1000个样本训练模型，而通过其它99项任务的训练共1000*99个样本，这可能大幅提高算法性能，可以提供很多知识来增强这个任务的性能。 （3）当你可以训练一个足够大的神经网络，同时做好所有的工作，那么多任务学习比每个任务训练一个神经网络来完成各个单独的任务性能更好。否则如果不能够训练一个足够大的网络，多任务学习的替代方法是为每个任务训练一个单独的神经网络，而不是同一个神经网络中同时处理多个任务。 3）多任务学习使用的频率要低于迁移学习，多任务学习比较少见，但计算机视觉物体检测是一个是一个例外。 10. 什么是端到端的深度学习 1）端到端学习：以前有一些数据处理系统需要多个阶段的处理，端到端学习就是忽略所有这些不同的阶段，用单个神经网络代替它。 2）例子：语音识别系统，输入音频，输出文本 （1）传统语音识别需要很多个阶段处理：从语音中提取一些特征，在提取一些低层次特征之后应用机器学习算法在音频片段中找到音位（声音的基本单位，每个单词由多个音位组成）。 （2）端到端学习：输入一段音频，直接输出文本。 3）端到端学习挑战之一是需要大量的数据才能让系统表现良好。例子：语音识别系统 （1）当你只有3000h音频时，传统流水线可能比端到端学习效果要好。 （2）当你有10000h音频，甚至100000h音频时，端到端突然开始很厉害。 4）例子：人脸识别系统 （1）人脸识别系统分两步完成效果较好，第一步找到摄像头中人脸位置，第二步再把人脸放到放到识别系统进行训练。 （2）虽然没有足够的数据进行端到端学习，但是有足够的数据直接对以上两个步骤同时进行学习。 11. 是否要使用端到端的深度学习 1）端到端学习的优点 （1）只是让数据说话。如果你有足够多的训练数据，如果你训练一个足够大的神经网络，那么那么就可以学习从x到y最适合的函数映射是什么。 （2）很少需要手工设计的组件，能够简化工作流程，不需要花太多时间去手工设计功能。 2）端到端学习缺点 （1）需要大量的数据。 （2）它排除了可能有用的手工设计组件。 如果你没有足够的数据，学习算法就没办法从很小的训练集中获得洞察力，所以手工设计组件在这种情况可能是把人类知识直接注入算法的途径。 我们学习的算法有两个主要的知识来源：来自数据和来自手工设计的任何东西。 &nbsp; 相关文章： 《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略1 学习总结 （如何进一步优化系统的方法论）" />
<link rel="canonical" href="https://mlh.app/2019/02/21/3de7d596a9ba463e1d737beb82a72bed.html" />
<meta property="og:url" content="https://mlh.app/2019/02/21/3de7d596a9ba463e1d737beb82a72bed.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-21T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"作者：jliang https://blog.csdn.net/jliang3 《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略2 学习笔记 &nbsp; 1.重点归纳 1）误差分析：如果算法还达不到理想效果，那么人工检查一下算法所犯的错误，也许可以让你了解接下来应该做什么，这个过程称为误差分析。 （1）例子：一个取得90%准确率猫分类器，注意到有部分狗样本被识别为猫，使用误差分析来估计是否应该专门解决这个问题。随机抽样100个错误样本，检查把狗分类成猫的样本数量，如果这个样本占比很小，则不值得专门去优化这个问题。 （2）在做误差分析时也可以同时并行评估几个想法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 （3）进行误差分析时应该找一组错误例子（验证集或测试集中的错误例子），观察错误标记的例子看看假阳性和假阴性，统计属于不同错误类型的错误数量。 这个过程中，可能会得到启发，归纳出新的误差类型。 通过统计不同类型错误标记类型占比总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。 2）标注错误的数据 （1）深度学习算法对训练集的随机误差是相当鲁棒的 只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们 只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们 （2）深度学习算法对系统性的错误就没有那么鲁棒了。比如说，如果做标记的人一直把白色的狗标记成猫。 （3）如果验证集和测试集中有标记错误的样本 误差分析时增加一个额外的列来统计标记出错的例子数，根据标记出错样本数来估计修改错误后对误差值的影响。 如果这些标记错误的例子验证影响了你在验证集上评估算法的能力，那么就应该花时间修正错误的标签。如果它没有严重到影响到用验证集评估成本偏差的能力，那就不需要花费宝贵的时间去处理。 需要修正验证集标记错误的例子：假设系统达到98%准确度（2%的错误），假设错误标记引起的错误对验证集误差的影响为0.6%（30%*2%=0.6%）。评估模型时模型A误差是2.1%，模型B为1.9%，此时标记错误的样本足以影响我们评估哪个模型更好，此时应该修正验证集中的错误标记 （4）修正数据时指引和原则 应该同时修改验证集和测试集上的错误，验证集和测试集必须来自相同的分布，但训练集可以来自稍微不同的分布。 检查数据时检测全部验证/测试集，而不是只检测判断错误的样本。否则有可能有些被正确判断的样本其实是判断错误的，修正样本标签后导致对算法偏差的估计可能变得更大。 由于训练集数据量比较大，也因为前面讨论过的训练集的随机误差对算法影响不大，所以我们可能会只修正验证集和测试集的错误标记，而不修改训练集的错误标记。此时，训练集与验证集和测试集来自不同的数据分布。 3）开发一个全新的机器学习应用时，应该尽快建立第一个系统原型，然后快速迭代。 （1）流程 首先，快速设立验证集和测试集，还有评估指标。它决定了你的目标在哪里，如果你的目标定错了，之后改也是可以的。 然后搭好一个机器学习系统原型，然后找到训练集，看看训练效果如何，在验证集合测试集评估指标表现如何。 再进行偏差方差分析以及误差分析来确定下一步优先做什么。特别是如果误差分析让你了解到大部分误差的来源。 建立初始系统的意义在于有一个训练过的系统让你确定偏差方差的范围，就可以知道下一步应该优先做什么。让你能够进行误差分析，可以观察一些错误，然后想出所有能进行的方向，知道哪些是最优希望的方向。 （2）以下情况，快速搭建第一个系统的建议的适用程度要低一些，一开始就搭建比较复杂的系统 如果你在这个应用程序领域有很多经验 如果一个领域有很多可以借鉴的学术文献（如人脸识别领域），可以从现有大量文献为基础出发，一开始就搭建比较复杂的系统 4）训练样本与验证/测试来自不同的分布 （1）深度学习算法需要大量的数据，即使大部分数据来自不同的分布也比只有很少的数据好，从而导致训练集、验证集和测试集数据分布不一样的情况出现，越来越多团队都用来自和验证集和测试集分布不同的数据来训练。 （2）例子：猫分类器，训练数据来自网络（很清晰），测试数据来自手机拍照（很模糊） （3）错误的组合数据方式：把两组照片混合在一起，然后进行混洗，然后再按比例把照片分配到训练集、 验证集和测试集上。 （4）猫分类器正确的组合数据方式： 训练集205000张=全部网络照片20万张+一半用户上传的照片5000张，验证集和测试集都是2500张用户上传的照片（都是真实关心的数据分布）。 这样划分数据的好处在于，现在瞄准的目标就是我们想要处理的目标。 缺点在于训练集分布和验证集以及测试集分布不一样，但事实证明这样的数据划分在长期能带来更好的系统性能。 （5）例子：语音识别系统的后视镜，如：“后视镜，请帮我找找到最近的加油站的导航方向”。很多数据（共500000条）来自其他语音识别应用，如：数据供应商买来的数据、智能语音激活音箱的数据、语音激活键盘的数据，只有20000条数据来自后视镜设备 划分方式一：训练集=全部其他语音识别数据500000条，验证集和测试集数据都是来自后视镜的数据各10000条。 划分方式二（如果你觉得验证集和测试集不需要这么多数据）：训练集=全部其他语音识别数据500000条+后视镜数据10000条，验证集和测试集数据都是来自后视镜的数据各5000条。 5） 不匹配数据划分的偏差和方差 （1）估计学习算法的偏差和方差可以帮我们确定接下来应该优先做的方向，但是如果训练集和验证集及测试集分布不同时，分析偏差和方差的方式会不一样。 （2）为了确认是由于泛化能力，还是由于数据分布不一样的原因，需要定义一组新的数据“训练-验证集”。数据集分为4份：训练集、训练-验证集、验证集、测试集 （3）训练集误差与训练-验证集误差的差距代表了模型的方差问题的可优化空间，从中可以知道模型的泛化能力。 （4）训练-验证集误差与验证集误差之间的差距代表数据不匹配的程度，因为算法没有直接在训练-验证集或验证集上训练过，这两者的数据来自不同的分布。 （5）各个数据集误差差距总结 训练集误差与贝叶斯误差的差值为可避免偏差值大小。 训练-验证集误差与训练集误差的差值为方差值大小。 验证集误差与训练-验证集误差的差值为数据不匹配问题的大小。 测试集误差与验证集误差的差值为对验证集过拟合的程度，如果差值很大，说明需要一个更大的验证集。 （6）贝叶斯误差、训练集误差、训练-验证集误差、验证集误差和测试集误差的值应该是从越来越大 训练集和训练-验证集误差是从训练集分布评估的，验证集和测试集误差是对验证集测试集分布评估的。 如果某个值没有变大（比上一个误差要小），如下面例子，说明训练数据比验证集和测试集数据难识别多了。 人类水平误差为4% 训练集误差为7% 训练-验证集误差为10% 验证集误差为6% 测试集误差为6% （7）通用的分析方法 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 制定以上表格，横轴是不同分布的训练集数据（例子中为来：自其它方式语音识别数据）和验证集/测试集数据（来自后视镜的语音识别数据）；纵轴是人类水平误差、参与训练的数据误差和没有参与训练的数据误差。 正常情况下，我只需要分析图中红色框几项就可以找到方向：训练集与贝叶斯误差差值（可避免偏差）、训练-验证集与训练集误差差值（方差）、验证集与训练-验证集误差差值（数据不匹配）。 进行表格中剩余的两项分析也是有用的：人类在真实分布（验证集/测试集数据）的误差、真实分布用于训练时的训练误差。当你继续进行更多分析时，分析并不一定会给你指明方向，但有时候你会洞察到一些特征。 对比人类在两种不同分布上的表现可以看出哪种数据分布更难被识别，上例中后视镜的数据更难被识别。 对比两种分布数据在训练集上的误差可以了解到偏差和方差，还有数据不匹配这个问题的不同程度。 6）定位数据不匹配 （1）数据不匹配问题没有完全系统的解决方案，但是有一些可以尝试的方法 人工做误差分析，尝试了解训练集和验证测试集的具体差异。为了误差分析时避免对测试集过拟合，应该只人工去看验证集而不看测试集数据。汽车后视镜例子中： 假设发现验证集中有很多汽车噪音，这是验证集和训练集差异之一 发现在汽车里语音激活后视镜经常错误识别街道号码，真实使用时经常导航到某些街道，而训练数据中没有这些导航数据 可以尝试把训练数据变得更像验证集数据，或者采集更多类似验证测试集的数据 如果发现车辆背景噪音是主要误差来源，可以模拟车辆噪声数据，人工合成噪音数据 如果发现很难识别街道号码，可以有意识收集更多人们说数字的音频数据，加到训练集中 （2）人工数据合成 例子1：清晰对话+汽车噪音=人工合成有噪音的对话。存在问题：假设在一辆车上录了1h的汽车噪音，并重复合并到10000h的清晰对话中，这些噪音录音可能只是汽车噪音的很小的一个集合，模型可能会对这辆车的噪声过拟合。使用10000h噪音与10000h清晰对话合成比只使用1h噪音合成效果要更好，但是实际上很难采集这么多数据。 例子2：汽车识别，通过软件模拟合成很多汽车图片作为训练集，这些合成数据可能只是车辆的很小的子集，但是算法可能会对合成的一个小集合过拟合。 （3）如果你任务数据不匹配问题，建议进行误差分析或看看训练集和验证集，试图了解两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像验证集的数据作训练。人工数据合成可以提升模型表现，但使用人工合成数据时一定要谨慎，要记住有可能只从所有可能性的空间只选了很小一部分去模拟数。 7）迁移学习：神经网络可以从一个任务中学习得到知识，并将这些知识应用到另一个独立的任务中。 （1）适用场景：迁移来源问题有很多数据，但迁移目标问题没有那么多数据，找一个相关但不相同的任务可以帮助学习目标任务。 （2）不适用场景：迁移来源问题数据很少，但迁移目标问题数据很多。可以使用迁移学习不会有害处，但是对目标问题没有什么帮助。 （3）例子：从图像（猫、狗、鸟等）识别任务迁移学习阅读X射线扫描图 做法：把神经网络最后的输出层删除，重新创建输出层并赋予随机权重，然后使用放射诊断数据训练模型。如果有更多的数据，可以删除最后面几层网络，重新添加几层网络后再用新数据重新训练这几层，数据越多就可以重新训练越多层。如果有足够多的数据时就可以重新训练整个网络，那么这个网络在之前的数据训练称为预训练，在新数据上重新训练称为微调。 有很多低层次的特征（如边缘检测、曲线检测、点检测、阳性对象检测）从非常大的图像识别数据库中学习到这些知识，线条、点、曲线等这些知识（也许是对象的一小部分）可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。 算法学习到很多结构和图像形状信息（中层特征），其中一些知识可能会很有用，它就可能学到足够多的信息，学习到不同图像是有哪些部分组成的。 （4）例子：已经学习一个语音识别系统（输入音频，输出文本），利用迁移学习迁移到一个“唤醒词”/“触发词”检测系统（输入指定音频来唤醒设备）。 语音识别系统从10000小时数据训练，但对于触发字检测也许只有1小时数据（数据太少，不能用来拟合很多参数）。 即使触发字任务数据集很小，在训练语音识别系统时预先学到很多人类声音的特征、人类语言组成部分等知识，可以帮助我们建立一个很好的触发字检测系统。 （5）迁移学习的场景：源任务A，目标任务B 任务A和B有相同的输入时，迁移学习才有意义。例如输入的都是图像，或者输入的都是音频。 任务A的数据比任务B的数据多很多时，迁移学习才有意义。因为任务B的每个数据更有价值，对任务B来说通常任务A的数据量必须大得多才有帮助。 任务A的低层次特征可以帮助学习任务。 8）多任务学习能让你训练一个神经网络来执行许多任务。 （1）例如：计算机视觉物体检测系统中同时检测人、汽车、交通标志等多个任务，一个神经网络学习多个任务。 （2）多任务学习意义 可以共用低层次特征 如果每个任务的数据量差不多，多任务学习可以。这个准则不一定对。 例子：有100个任务在同时学习，任务的样本量只有1000个，如果只关注第100个任务。如果单独去学习第100个任务，只有1000个样本训练模型，而通过其它99项任务的训练共1000*99个样本，这可能大幅提高算法性能，可以提供很多知识来增强这个任务的性能。 当你可以训练一个足够大的神经网络，同时做好所有的工作，那么多任务学习比每个任务训练一个神经网络来完成各个单独的任务性能更好。否则如果不能够训练一个足够大的网络，多任务学习的替代方法是为每个任务训练一个单独的神经网络，而不是同一个神经网络中同时处理多个任务。 （3）多任务学习使用的频率要低于迁移学习，多任务学习比较少见，但计算机视觉物体检测是一个是一个例外。 9）端到端学习：以前有一些数据处理系统需要多个阶段的处理，端到端学习就是忽略所有这些不同的阶段，用单个神经网络代替它。 （1）例子：语音识别系统，输入音频，输出文本 传统语音识别需要很多个阶段处理：从语音中提取一些特征，在提取一些低层次特征之后应用机器学习算法在音频片段中找到音位（声音的基本单位，每个单词由多个音位组成）。 端到端学习：输入一段音频，直接输出文本。 （2）端到端学习挑战之一是需要大量的数据才能让系统表现良好。 当你只有3000h音频时，传统流水线的语音识别系统可能比端到端学习效果要好。 当你有10000h音频，甚至100000h音频时，端到端突然开始很厉害。 （3）例子：人脸识别系统 人脸识别系统分两步完成效果较好，第一步找到摄像头中人脸位置，第二步再把人脸放到放到识别系统进行训练。 虽然没有足够的数据进行端到端学习，但是有足够的数据直接对以上两个步骤同时进行学习。 10）是否要使用端到端的深度学习 （1）端到端学习的优点 只是让数据说话。如果你有足够多的训练数据，如果你训练一个足够大的神经网络，那么那么就可以学习从x到y最适合的函数映射是什么。 很少需要手工设计的组件，能够简化工作流程，不需要花太多时间去手工设计功能。 （2）端到端学习缺点 需要大量的数据。 它排除了可能有用的手工设计组件，当数据量不足时，没有使用手工设计组件。 2.进行误差分析 1）误差分析：如果算法还达不到理想效果，那么人工检查一下算法所犯的错误，也许可以让你了解接下来应该做什么，这个过程称为误差分析。 2）使用误差分析来估计某个想法是否值得解决的例子：调试一个取得90%准确率猫分类器 （1）检查一下算法分类出错的例子，注意到算法将一些狗分类为猫。 也许有人建议你针对狗图片优化算法：为了让算法不再将狗分类成猫，针对狗收集更多的狗图片，或者设计一些只处理狗的算法功能之类的。 问题是是否应该做一个项目专门处理狗的问题？这可能花费几个月时间才能让算法在狗问题上少识别为猫，也许没有效果。 （2）这里有个误差分析流程可以让你很快知道这个优化方向是否值得尝试： 收集一些（比如说100个）错误标记的验证集例子 逐一检查每个被错误识别的样本，看有多少个例子是狗。假如只有5%错误例子是狗，意味着即使完全解决狗的问题，只能修正100个错误中的5个，误差从10%下降到9.5%（10%*(1-5%)=9.5%），这就是关于这个优化的上限。 （3）在搭建应用系统时，这个简单的人工统计步骤（统计错误数量）误差分析可以节省大量时间，可以迅速决定什么是最重要的或最有希望的方向。 3）在做误差分析时也可以同时并行评估几个想法 （1）几个改善猫检测器的想法： 狗被识别为猫的问题 猫科动物（狮子、豹、猎豹等）被识别为猫的问题 图像模糊而误分类，改善算法来识别模糊图片 （2）建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。 （3）这个分析步骤的结果可以给出一个估计，看是否值得去处理每个不同的错误类型。这里不一定是要解决占比最大的问题，它能让你对应该选择那些手段有个概念，给出了每个问题的性能上限，了解每种手段对性能有多大的提升空间。 4）进行误差分析时应该找一组错误例子（验证集或测试集中的错误例子），观察错误标记的例子看看假阳性和假阴性，统计属于不同错误类型的错误数量。 这个过程中，可能会得到启发，归纳出新的误差类型。 通过统计不同类型错误标记类型占比总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。 3. 清楚标注错误的数据 1）深度学习算法对训练集的随机误差是相当鲁棒的 （1）只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们。 （2）只要总数据集足够大，实际误差可能不会太高。 2）深度学习算法对随机误差是相当鲁棒的，但对系统性的错误就没有那么鲁棒了。 比如说，如果做标记的人一直把白色的狗标记成猫，那就是系统性的错误，经过学习后，分类器会把所有白色的狗都分类为猫。 3）如果验证集和测试集中有标记错误的样本 （1）如果担心验证集和测试集中标记出错的例子带来影响，建议在误差分析时增加一个额外的列来统计标记出错的例子数。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; （2）如果这些标记错误的例子验证影响了你在验证集上评估算法的能力，那么就应该花时间修正错误的标签。如果它没有严重到影响到用验证集评估成本偏差的能力，那就不需要花费宝贵的时间去处理。 （3）判断是否值得去修改标记出错的数据 假设系统达到90%准确度，10%的错误。 错误标记引起的错误的数量或百分比对验证集误差的影响，此处是6%*10%=0.6%。 其他原因导致的验证集错误对验证集误差的影响，此处是9.4%。 这种情况下，需要集中精力修正9.4%的误差，而标记出错导致的错误是总体错误的一小部分而已，不是当下最重要的任务。 （4）需要修正验证集标记错误的例子 假设系统达到98%准确度，2%的错误。 假设错误标记引起的错误对验证集误差的影响为0.6%，其他原因导致的影响为1.4%。 在评估模型时，假设模型A误差2.1%，模型B误差为1.9%。此时标记错误的样本足以影响我们评估哪个模型更好，此时应该修正验证集中的错误标记。 4）修正数据时指引和原则 （1）不管用什么方法来修改错误，都应该同时修改验证集和测试集上的错误，验证集和测试集必须来自相同的分布。 （2）强烈建议你同时检验算法判断正确和判断错误的样本，而不是只检测判断错误的样本。否则有可能有些被正确判断的样本其实是判断错误的，修正样本标签后导致对算法偏差的估计可能变得更大。 （3）由于训练集数据量比较大，也因为前面讨论过的训练集的随机误差对算法影响不大，所以我们可能会只修正验证集和测试集的错误标记，而不修改训练集的错误标记。此时，训练集与验证集和测试集来自不同的数据分布。 （4）验证集和测试集来自同一分布非常重要，但如果训练集来自稍微不同的分布是一件很合理的事情。 4. 快速搭建你的第一个系统，并进行迭代 1）开发一个全新的机器学习应用时，应该尽快建立第一个系统原型，然后快速迭代。 2）例子：语音识别系统有很多优化方向 有一些特定的技术可以让语音识别系统对嘈杂的背景更加健壮：咖啡店的噪音（很多人聊天）、车辆的噪音（高速上汽车的噪音等） 有一些方法可以让语音识别系统在处理带口音时更健壮 远场语音识别问题：麦克风与说话人距离很远的问题 儿童的语音识别带来的特征挑战（来自单词发音方面） 说话口吃问题 … 3）一般情况下，对于所有的机器学习程序可能会有50个方向可以优化前进，并且每个方向都是相对合理的，可以改善系统，如何选择一个方向集中精力处理是一个挑战。 4）如果搭建一个全新的机器学习程序，就是快速搭建好第一个系统，然后开始迭代。 （1）首先，快速设立验证集和测试集，还有评估指标。它决定了你的目标在哪里，如果你的目标定错了，之后改也是可以的。 （2）然后搭好一个机器学习系统原型，然后找到训练集，看看训练效果如何，在验证集合测试集评估指标表现如何。 （3）再进行偏差方差分析以及误差分析来确定下一步优先做什么。特别是如果误差分析让你了解到大部分误差的来源。 （4）建立初始系统的意义在于有一个训练过的系统让你确定偏差方差的范围，就可以知道下一步应该优先做什么。让你能够进行误差分析，可以观察一些错误，然后想出所有能进行的方向，知道哪些是最优希望的方向。 5）以下情况，快速搭建第一个系统的建议的适用程度要低一些，一开始就搭建比较复杂的系统 （1）如果你在这个应用程序领域有很多经验 （2）如果一个领域有很多可以借鉴的学术文献（如人脸识别领域），可以从现有大量文献为基础出发，一开始就搭建比较复杂的系统 5. 在不同的划分上进行训练并测试 1）深度学习算法对训练数据胃口很大，越多数据对训练越好，即使大部分数据来自不同的分布，从而导致训练集、验证集和测试集数据分布不一样的情况出现，越来越多团队都用来自和验证集和测试集分布不同的数据来训练。 2）处理训练集和测试集数据分布不一样的例子：猫分类器，训练数据来自网络（很清晰），测试数据来自手机拍照（很模糊） （1）来自手机上传的照片是真正关系的数据分布，手机上传的数量不多（如1万张），来自网络的照片数量很多（超过20万）。只用手机上的照片训练的话照片数量太少了，只使用网络的照片的话与真正关心的数据分布不一样，所以需要结合两组照片数据。 （2）错误的组合方式 把两组照片混合在一起，然后进行混洗，然后再按比例把照片分配到训练集、 验证集和测试集上。 比如，205000张照片作为训练集、2500张照片作为验证集、2500张照片作为测试集。验证集和测试集中只有119张照片来自手机上传，设立验证集的目的是告诉团队瞄准的目标，而瞄准的目标大部分来自网络下载的照片，这其实不是真实希望的。 （3）正确的组合方式 训练集205000张=全部网络照片20万张+一半用户上传的照片5000张，验证集和测试集都是2500张用户上传的照片（都是真实关心的数据分布）。 这样划分数据的好处在于，现在瞄准的目标就是我们想要处理的目标。 缺点在于训练集分布和验证集以及测试集分布不一样，但事实证明这样的数据划分在长期能带来更好的系统性能。 3）例子：语音识别系统的后视镜，可以语音沟通，如：“后视镜，请帮我找找到最近的加油站的导航方向”。很多数据（共500000条）来自其他语音识别应用，如：数据供应商买来的数据、智能语音激活音箱的数据、语音激活键盘的数据，只有20000条数据来自后视镜设备。 （1）划分方式一：训练集=全部其他语音识别数据500000条，验证集和测试集数据都是来自后视镜的数据各10000条。 （2）划分方式二（如果你觉得验证集和测试集不需要这么多数据）：训练集=全部其他语音识别数据500000条+后视镜数据10000条，验证集和测试集数据都是来自后视镜的数据各5000条。 6. 不匹配数据划分的偏差和方差 1）估计学习算法的偏差和方差可以帮我们确定接下来应该优先做的方向，但是如果训练集和验证集及测试集分布不同时，分析偏差和方差的方式会不一样。 2）例子：猫分类器，假设人类水平接近0%误差 （1）假设训练误差1%，验证集误差10% 在分布一样的时候，可以说这里存在很大的方差问题。 如果训练数据和验证数据来自不同的分布时，就不能确定的说这里存在很大的方差了。也许算法在验证集上做得不错，只是由于训练集更容易被识别，而验证集很难被识别。从训练集到验证集有两个因素发生变化：算法见过的训练数据没有见过验证集数据、验证集的数据分布不同。 （2）为了确认是由于泛化能力，还是由于数据分布不一样的原因，需要定义一组新的数据“训练-验证集” 这数据来源于训练集数据，但是不用于训练模型。把训练集随机打乱，并分一部分出来作为训练-验证集。 数据集分为4份：训练集、训练-验证集、验证集、测试集。 训练集和训练-验证集分布一样，验证集和测试集分布一样，验证集和测试集的数据是最后真实评估模型的数据，而训练集和训练-验证集与验证集和测试集数据分布不一样。 （3）训练集误差与训练-验证集误差的差距代表了模型的方差问题的可优化空间，从中可以知道模型的泛化能力。以下为方差很大的例子： 训练集误差为1% 训练-验证集误差为9% 验证集误差为10% （4）训练-验证集误差与验证集误差之间的差距代表数据不匹配的程度，因为算法没有直接在训练-验证集或验证集上训练过，这两者的数据来自不同的分布。以下为数据不匹配问题的例子： 训练集误差为1% 训练-验证集误差为1.5% 验证集误差为10% （5）存在很大偏差问题的例子： 人类水平误差为0% 训练集误差为10% 训练-验证集误差为11% 验证集误差为12% （6）同时存在偏差问题和数据不匹配问题的例子： 人类水平误差为0% 训练集误差为10% 训练-验证集误差为11% 验证集误差为20% 3）各个数据集误差差距总结 （1）训练集误差与贝叶斯误差的差值为可避免偏差值大小。 （2）训练-验证集误差与训练集误差的差值为方差值大小。 （3）验证集误差与训练-验证集误差的差值为数据不匹配问题的大小。 （4）测试集误差与验证集误差的差值为对验证集过拟合的程度，如果差值很大，说明需要一个更大的验证集。 4）贝叶斯误差、训练集误差、训练-验证集误差、验证集误差和测试集误差的值应该是从越来越大 （1）训练集和训练-验证集误差是从训练集分布评估的，验证集和测试集误差是对验证集测试集分布评估的。 （2）如果某个值没有变大（比上一个误差要小），如下面例子，说明训练数据比验证集和测试集数据难识别多了。 人类水平误差为4% 训练集误差为7% 训练-验证集误差为10% 验证集误差为6% 测试集误差为6% 5）更通用的分析方法 （1）制定以上表格，横轴是不同分布的训练集数据（例子中为来：自其它方式语音识别数据）和验证集/测试集数据（来自后视镜的语音识别数据）；纵轴是人类水平误差、参与训练的数据误差和没有参与训练的数据误差。 （2）正常情况下，我只需要分析图中红色框几项就可以找到方向：训练集与贝叶斯误差差值（可避免偏差）、训练-验证集与训练集误差差值（方差）、验证集与训练-验证集误差差值（数据不匹配）。 （3）进行表格中剩余的两项分析也是有用的：人类在真实分布（验证集/测试集数据）的误差、真实分布用于训练时的训练误差。当你继续进行更多分析时，分析并不一定会给你指明方向，但有时候你会洞察到一些特征。 对比人类在两种不同分布上的表现可以看出哪种数据分布更难被识别，上例中后视镜的数据更难被识别。 对比两种分布数据在训练集上的误差可以了解到偏差和方差，还有数据不匹配这个问题的不同程度。 7. 定位数据不匹配 1）数据不匹配问题没有完全系统的解决方案，但是有一些可以尝试的方法 （1）人工做误差分析，尝试了解训练集和验证测试集的具体差异。为了误差分析时避免对测试集过拟合，应该只人工去看验证集而不看测试集数据。汽车后视镜例子中： 假设发现验证集中有很多汽车噪音，这是验证集和训练集差异之一 发现在汽车里语音激活后视镜经常错误识别街道号码，真实使用时经常导航到某些街道，而训练数据中没有这些导航数据 （2）可以尝试把训练数据变得更像验证集数据，或者采集更多类似验证测试集的数据 如果发现车辆背景噪音是主要误差来源，可以模拟车辆噪声数据，人工合成噪音数据 如果发现很难识别街道号码，可以有意识收集更多人们说数字的音频数据，加到训练集中 2）人工数据合成 （1）例子1：清晰对话+汽车噪音=人工合成有噪音的对话 通过人工数据合成，可以快速制造更多的训练数据，那就不需要花时间实际出去收集数据了。 存在问题：假设在一辆车上录了1h的汽车噪音，并重复合并到10000h的清晰对话中，这些噪音录音可能只是汽车噪音的很小的一个集合，模型可能会对这辆车的噪声过拟合。使用10000h噪音与10000h清晰对话合成比只使用1h噪音合成效果要更好，但是实际上很难采集这么多数据。 还有一个难点是，人耳无法区分采集到的1h噪音与验证集中的噪音是否一致。 （2）例子2：汽车识别 通过软件模拟合成很多汽车图片作为训练集，这些合成数据可能只是车辆的很小的子集，但是算法可能会对合成的一个小集合过拟合 3）如果你任务数据不匹配问题，建议进行误差分析或看看训练集和验证集，试图了解两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像验证集的数据作训练。人工数据合成可以提升模型表现，但使用人工合成数据时一定要谨慎，要记住有可能只从所有可能性的空间只选了很小一部分去模拟数。 8. 迁移学习 1）迁移学习：神经网络可以从一个任务中学习得到知识，并将这些知识应用到另一个独立的任务中。 （1）适用场景：迁移来源问题有很多数据，但迁移目标问题没有那么多数据，找一个相关但不相同的任务可以帮助学习目标任务。 （2）不适用场景：迁移来源问题数据很少，但迁移目标问题数据很多。可以使用迁移学习不会有害处，但是对目标问题没有什么帮助。 2）例子：从图像（猫、狗、鸟等）识别任务迁移学习阅读X射线扫描图 （1）做法：把神经网络最后的输出层删除，重新创建输出层并赋予随机权重，然后使用放射诊断数据训练模型。 （2）如果有更多的数据，可以删除最后面几层网络，重新添加几层网络后再用新数据重新训练这几层，数据越多就可以重新训练越多层。 （3）如果有足够多的数据时就可以重新训练整个网络，那么这个网络在之前的数据训练称为预训练，在新数据上重新训练称为微调。 （4）当你做图像识别任务时，可以训练神经网络的所有常用参数，所有层的权重，然后得到一个图像识别预测网络。 有很多低层次的特征（如边缘检测、曲线检测、点检测、阳性对象检测）从非常大的图像识别数据库中学习到这些知识，线条、点、曲线等这些知识（也许是对象的一小部分）可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。 算法学习到很多结构和图像形状信息，其中一些知识可能会很有用，它就可能学到足够多的信息，学习到不同图像是有哪些部分组成的。 3）例子：已经学习一个语音识别系统（输入音频，输出文本），利用迁移学习迁移到一个“唤醒词”/“触发词”检测系统（输入指定音频来唤醒设备） （1）做法：把最后一层删除并加入新网络层，有时可以加入多层节点，这取决于你有多少数据 （2）迁移学习起作用的场合：迁移来源问题有很多数据，但迁移目标问题没有那么多数据。 例如：图像识别任务迁移学习到放射科任务 图像识别任务中有1百万个样本（有足够的数据学习低层次特征，前面几层学习到如何识别很多有用的特征），但对放射科任务只有1百个样本（数据非常少）。 即使放射科数据很少，但可以从图像识别训练中学到很多知识可以迁移并帮助放射科识别任务的性能。 如果图像识别任务数据很少，放射科数据很多，则不适合使用迁移学习，也许没有害处，但是没有帮助。 例子：语音识别系统迁移学习到触发字检测系统 语音识别系统从10000小时数据训练，但对于触发字检测也许只有1小时数据（数据太少，不能用来拟合很多参数）。 即使触发字任务数据集很小，在训练语音识别系统时预先学到很多人类声音的特征、人类语言组成部分等知识，可以帮助我们建立一个很好的触发字检测系统。 4）迁移学习的场景：源任务A，目标任务B （1）任务A和B有相同的输入时，迁移学习才有意义。例如输入的都是图像，或者输入的都是音频。 （2）任务A的数据比任务B的数据多很多时，迁移学习才有意义。因为任务B的每个数据更有价值，对任务B来说通常任务A的数据量必须大得多才有帮助。 （3）任务A的低层次特征可以帮助学习任务。 9. 多任务学习 1）多任务学习能让你训练一个神经网络来执行许多任务。例如：计算机视觉物体检测系统中同时检测人、汽车、交通标志等多个任务，一个神经网络学习多个任务。 2）多任务学习意义 （1）可以共用低层次特征 （2）如果每个任务的数据量差不多，多任务学习可以。这个准则不一定对。 例子：有100个任务在同时学习，任务的样本量只有1000个，如果只关注第100个任务。如果单独去学习第100个任务，只有1000个样本训练模型，而通过其它99项任务的训练共1000*99个样本，这可能大幅提高算法性能，可以提供很多知识来增强这个任务的性能。 （3）当你可以训练一个足够大的神经网络，同时做好所有的工作，那么多任务学习比每个任务训练一个神经网络来完成各个单独的任务性能更好。否则如果不能够训练一个足够大的网络，多任务学习的替代方法是为每个任务训练一个单独的神经网络，而不是同一个神经网络中同时处理多个任务。 3）多任务学习使用的频率要低于迁移学习，多任务学习比较少见，但计算机视觉物体检测是一个是一个例外。 10. 什么是端到端的深度学习 1）端到端学习：以前有一些数据处理系统需要多个阶段的处理，端到端学习就是忽略所有这些不同的阶段，用单个神经网络代替它。 2）例子：语音识别系统，输入音频，输出文本 （1）传统语音识别需要很多个阶段处理：从语音中提取一些特征，在提取一些低层次特征之后应用机器学习算法在音频片段中找到音位（声音的基本单位，每个单词由多个音位组成）。 （2）端到端学习：输入一段音频，直接输出文本。 3）端到端学习挑战之一是需要大量的数据才能让系统表现良好。例子：语音识别系统 （1）当你只有3000h音频时，传统流水线可能比端到端学习效果要好。 （2）当你有10000h音频，甚至100000h音频时，端到端突然开始很厉害。 4）例子：人脸识别系统 （1）人脸识别系统分两步完成效果较好，第一步找到摄像头中人脸位置，第二步再把人脸放到放到识别系统进行训练。 （2）虽然没有足够的数据进行端到端学习，但是有足够的数据直接对以上两个步骤同时进行学习。 11. 是否要使用端到端的深度学习 1）端到端学习的优点 （1）只是让数据说话。如果你有足够多的训练数据，如果你训练一个足够大的神经网络，那么那么就可以学习从x到y最适合的函数映射是什么。 （2）很少需要手工设计的组件，能够简化工作流程，不需要花太多时间去手工设计功能。 2）端到端学习缺点 （1）需要大量的数据。 （2）它排除了可能有用的手工设计组件。 如果你没有足够的数据，学习算法就没办法从很小的训练集中获得洞察力，所以手工设计组件在这种情况可能是把人类知识直接注入算法的途径。 我们学习的算法有两个主要的知识来源：来自数据和来自手工设计的任何东西。 &nbsp; 相关文章： 《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略1 学习总结 （如何进一步优化系统的方法论）","@type":"BlogPosting","url":"https://mlh.app/2019/02/21/3de7d596a9ba463e1d737beb82a72bed.html","headline":"《深度学习工程师-吴恩达》04结构化机器学习项目–机器学习（ML）策略2 学习笔记（如何进一步优化系统的方法论）","dateModified":"2019-02-21T00:00:00+08:00","datePublished":"2019-02-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/02/21/3de7d596a9ba463e1d737beb82a72bed.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略2 学习笔记（如何进一步优化系统的方法论）</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h1 id="%E4%BD%9C%E8%80%85%EF%BC%9Ajliang">作者：jliang</h1> 
  <p><a href="https://blog.csdn.net/jliang3" rel="nofollow">https://blog.csdn.net/jliang3</a></p> 
  <h1 style="margin-left:0cm;"><span style="color:#4472c4;">《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略2 学习笔记</span></h1> 
  <p style="margin-left:0cm;">&nbsp;</p> 
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>1.重点归纳</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）误差分析：如果算法还达不到理想效果，那么人工检查一下算法所犯的错误，也许可以让你了解接下来应该做什么，这个过程称为误差分析。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）例子：一个取得90%准确率猫分类器，注意到有部分狗样本被识别为猫，使用误差分析来估计是否应该专门解决这个问题。随机抽样100个错误样本，检查把狗分类成猫的样本数量，如果这个样本占比很小，则不值得专门去优化这个问题。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）在做误差分析时也可以同时并行评估几个想法</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><img alt="" class="has" height="446" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221203436311.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2psaWFuZzM=,size_16,color_FFFFFF,t_70" width="457"></p> 
  <ul>
   <li><span style="color:#595959;">建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。</span></li> 
   <li><span style="color:#595959;">建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）进行误差分析时应该找一组错误例子（验证集或测试集中的错误例子），观察错误标记的例子看看假阳性和假阴性，统计属于不同错误类型的错误数量。</span></p> 
  <ul>
   <li><span style="color:#595959;">这个过程中，可能会得到启发，归纳出新的误差类型。</span></li> 
   <li><span style="color:#595959;">通过统计不同类型错误标记类型占比总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">2）标注错误的数据</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）深度学习算法对训练集的随机误差是相当鲁棒的</span></p> 
  <ul>
   <li><span style="color:#595959;">只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们</span></li> 
   <li><span style="color:#595959;">只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）深度学习算法对系统性的错误就没有那么鲁棒了。比如说，如果做标记的人一直把白色的狗标记成猫。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）如果验证集和测试集中有标记错误的样本</span></p> 
  <ul>
   <li><span style="color:#595959;">误差分析时增加一个额外的列来统计标记出错的例子数，根据标记出错样本数来估计修改错误后对误差值的影响。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><img alt="" class="has" height="225" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221203436348.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2psaWFuZzM=,size_16,color_FFFFFF,t_70" width="426"></p> 
  <ul>
   <li><span style="color:#595959;">如果这些标记错误的例子验证影响了你在验证集上评估算法的能力，那么就应该花时间修正错误的标签。如果它没有严重到影响到用验证集评估成本偏差的能力，那就不需要花费宝贵的时间去处理。</span></li> 
   <li><span style="color:#595959;">需要修正验证集标记错误的例子：假设系统达到98%准确度（2%的错误），假设错误标记引起的错误对验证集误差的影响为0.6%（30%*2%=0.6%）。评估模型时模型A误差是2.1%，模型B为1.9%，此时标记错误的样本足以影响我们评估哪个模型更好，此时应该修正验证集中的错误标记</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）修正数据时指引和原则</span></p> 
  <ul>
   <li><span style="color:#595959;">应该同时修改验证集和测试集上的错误，验证集和测试集必须来自相同的分布，但训练集可以来自稍微不同的分布。</span></li> 
   <li><span style="color:#595959;">检查数据时检测全部验证/测试集，而不是只检测判断错误的样本。否则有可能有些被正确判断的样本其实是判断错误的，修正样本标签后导致对算法偏差的估计可能变得更大。</span></li> 
   <li><span style="color:#595959;">由于训练集数据量比较大，也因为前面讨论过的训练集的随机误差对算法影响不大，所以我们可能会只修正验证集和测试集的错误标记，而不修改训练集的错误标记。此时，训练集与验证集和测试集来自不同的数据分布。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">3）开发一个全新的机器学习应用时，应该尽快建立第一个系统原型，然后快速迭代。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）流程</span></p> 
  <ul>
   <li><span style="color:#595959;">首先，快速设立验证集和测试集，还有评估指标。它决定了你的目标在哪里，如果你的目标定错了，之后改也是可以的。</span></li> 
   <li><span style="color:#595959;">然后搭好一个机器学习系统原型，然后找到训练集，看看训练效果如何，在验证集合测试集评估指标表现如何。</span></li> 
   <li><span style="color:#595959;">再进行偏差方差分析以及误差分析来确定下一步优先做什么。特别是如果误差分析让你了解到大部分误差的来源。</span></li> 
   <li><span style="color:#595959;">建立初始系统的意义在于有一个训练过的系统让你确定偏差方差的范围，就可以知道下一步应该优先做什么。让你能够进行误差分析，可以观察一些错误，然后想出所有能进行的方向，知道哪些是最优希望的方向。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）以下情况，快速搭建第一个系统的建议的适用程度要低一些，一开始就搭建比较复杂的系统</span></p> 
  <ul>
   <li><span style="color:#595959;">如果你在这个应用程序领域有很多经验</span></li> 
   <li><span style="color:#595959;">如果一个领域有很多可以借鉴的学术文献（如人脸识别领域），可以从现有大量文献为基础出发，一开始就搭建比较复杂的系统</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">4）训练样本与验证/测试来自不同的分布</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）深度学习算法需要大量的数据，即使大部分数据来自不同的分布也比只有很少的数据好，从而导致训练集、验证集和测试集数据分布不一样的情况出现，越来越多团队都用来自和验证集和测试集分布不同的数据来训练。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）例子：猫分类器，训练数据来自网络（很清晰），测试数据来自手机拍照（很模糊）</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）错误的组合数据方式：把两组照片混合在一起，然后进行混洗，然后再按比例把照片分配到训练集、 验证集和测试集上。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）猫分类器正确的组合数据方式：</span></p> 
  <ul>
   <li><span style="color:#595959;">训练集205000张=全部网络照片20万张+一半用户上传的照片5000张，验证集和测试集都是2500张用户上传的照片（都是真实关心的数据分布）。</span></li> 
   <li><span style="color:#595959;">这样划分数据的好处在于，现在瞄准的目标就是我们想要处理的目标。</span></li> 
   <li><span style="color:#595959;">缺点在于训练集分布和验证集以及测试集分布不一样，但事实证明这样的数据划分在长期能带来更好的系统性能。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（5）例子：语音识别系统的后视镜，如：“后视镜，请帮我找找到最近的加油站的导航方向”。很多数据（共500000条）来自其他语音识别应用，如：数据供应商买来的数据、智能语音激活音箱的数据、语音激活键盘的数据，只有20000条数据来自后视镜设备</span></p> 
  <ul>
   <li><span style="color:#595959;">划分方式一：训练集=全部其他语音识别数据500000条，验证集和测试集数据都是来自后视镜的数据各10000条。</span></li> 
   <li><span style="color:#595959;">划分方式二（如果你觉得验证集和测试集不需要这么多数据）：训练集=全部其他语音识别数据500000条+后视镜数据10000条，验证集和测试集数据都是来自后视镜的数据各5000条。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">5） 不匹配数据划分的偏差和方差</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）估计学习算法的偏差和方差可以帮我们确定接下来应该优先做的方向，但是如果训练集和验证集及测试集分布不同时，分析偏差和方差的方式会不一样。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）为了确认是由于泛化能力，还是由于数据分布不一样的原因，需要定义一组新的数据“训练-验证集”。数据集分为4份：训练集、训练-验证集、验证集、测试集</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）训练集误差与训练-验证集误差的差距代表了模型的方差问题的可优化空间，从中可以知道模型的泛化能力。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）训练-验证集误差与验证集误差之间的差距代表数据不匹配的程度，因为算法没有直接在训练-验证集或验证集上训练过，这两者的数据来自不同的分布。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（5）各个数据集误差差距总结</span></p> 
  <ul>
   <li><span style="color:#595959;">训练集误差与贝叶斯误差的差值为可避免偏差值大小。</span></li> 
   <li><span style="color:#595959;">训练-验证集误差与训练集误差的差值为方差值大小。</span></li> 
   <li><span style="color:#595959;">验证集误差与训练-验证集误差的差值为数据不匹配问题的大小。</span></li> 
   <li><span style="color:#595959;">测试集误差与验证集误差的差值为对验证集过拟合的程度，如果差值很大，说明需要一个更大的验证集。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（6）贝叶斯误差、训练集误差、训练-验证集误差、验证集误差和测试集误差的值应该是从越来越大</span></p> 
  <ul>
   <li><span style="color:#595959;">训练集和训练-验证集误差是从训练集分布评估的，验证集和测试集误差是对验证集测试集分布评估的。</span></li> 
   <li><span style="color:#595959;">如果某个值没有变大（比上一个误差要小），如下面例子，说明训练数据比验证集和测试集数据难识别多了。</span> 
    <ul>
     <li><span style="color:#595959;">人类水平误差为4%</span></li> 
     <li><span style="color:#595959;">训练集误差为7%</span></li> 
     <li><span style="color:#595959;">训练-验证集误差为10%</span></li> 
     <li><span style="color:#595959;">验证集误差为6%</span></li> 
     <li><span style="color:#595959;">测试集误差为6%</span></li> 
    </ul></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（7）通用的分析方法</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><img alt="" class="has" height="501" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221203436143.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2psaWFuZzM=,size_16,color_FFFFFF,t_70" width="481"></p> 
  <ul>
   <li><span style="color:#595959;">制定以上表格，横轴是不同分布的训练集数据（例子中为来：自其它方式语音识别数据）和验证集/测试集数据（来自后视镜的语音识别数据）；纵轴是人类水平误差、参与训练的数据误差和没有参与训练的数据误差。</span></li> 
   <li><span style="color:#595959;">正常情况下，我只需要分析图中红色框几项就可以找到方向：训练集与贝叶斯误差差值（可避免偏差）、训练-验证集与训练集误差差值（方差）、验证集与训练-验证集误差差值（数据不匹配）。</span></li> 
   <li><span style="color:#595959;">进行表格中剩余的两项分析也是有用的：人类在真实分布（验证集/测试集数据）的误差、真实分布用于训练时的训练误差。当你继续进行更多分析时，分析并不一定会给你指明方向，但有时候你会洞察到一些特征。</span> 
    <ul>
     <li><span style="color:#595959;">对比人类在两种不同分布上的表现可以看出哪种数据分布更难被识别，上例中后视镜的数据更难被识别。</span></li> 
     <li><span style="color:#595959;">对比两种分布数据在训练集上的误差可以了解到偏差和方差，还有数据不匹配这个问题的不同程度。</span></li> 
    </ul></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">6）定位数据不匹配</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）数据不匹配问题没有完全系统的解决方案，但是有一些可以尝试的方法</span></p> 
  <ul>
   <li><span style="color:#595959;">人工做误差分析，尝试了解训练集和验证测试集的具体差异。为了误差分析时避免对测试集过拟合，应该只人工去看验证集而不看测试集数据。汽车后视镜例子中：</span> 
    <ul>
     <li><span style="color:#595959;">假设发现验证集中有很多汽车噪音，这是验证集和训练集差异之一</span></li> 
     <li><span style="color:#595959;">发现在汽车里语音激活后视镜经常错误识别街道号码，真实使用时经常导航到某些街道，而训练数据中没有这些导航数据</span></li> 
    </ul></li> 
   <li><span style="color:#595959;">可以尝试把训练数据变得更像验证集数据，或者采集更多类似验证测试集的数据</span> 
    <ul>
     <li><span style="color:#595959;">如果发现车辆背景噪音是主要误差来源，可以模拟车辆噪声数据，人工合成噪音数据</span></li> 
     <li><span style="color:#595959;">如果发现很难识别街道号码，可以有意识收集更多人们说数字的音频数据，加到训练集中</span></li> 
    </ul></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）人工数据合成</span></p> 
  <ul>
   <li><span style="color:#595959;">例子1：清晰对话+汽车噪音=人工合成有噪音的对话。存在问题：假设在一辆车上录了1h的汽车噪音，并重复合并到10000h的清晰对话中，这些噪音录音可能只是汽车噪音的很小的一个集合，模型可能会对这辆车的噪声过拟合。使用10000h噪音与10000h清晰对话合成比只使用1h噪音合成效果要更好，但是实际上很难采集这么多数据。</span></li> 
   <li><span style="color:#595959;">例子2：汽车识别，通过软件模拟合成很多汽车图片作为训练集，这些合成数据可能只是车辆的很小的子集，但是算法可能会对合成的一个小集合过拟合。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）如果你任务数据不匹配问题，建议进行误差分析或看看训练集和验证集，试图了解两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像验证集的数据作训练。人工数据合成可以提升模型表现，但使用人工合成数据时一定要谨慎，要记住有可能只从所有可能性的空间只选了很小一部分去模拟数。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">7）迁移学习：神经网络可以从一个任务中学习得到知识，并将这些知识应用到另一个独立的任务中。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）适用场景：迁移来源问题有很多数据，但迁移目标问题没有那么多数据，找一个相关但不相同的任务可以帮助学习目标任务。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）不适用场景：迁移来源问题数据很少，但迁移目标问题数据很多。可以使用迁移学习不会有害处，但是对目标问题没有什么帮助。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）例子：从图像（猫、狗、鸟等）识别任务迁移学习阅读X射线扫描图</span></p> 
  <ul>
   <li><span style="color:#595959;">做法：把神经网络最后的输出层删除，重新创建输出层并赋予随机权重，然后使用放射诊断数据训练模型。如果有更多的数据，可以删除最后面几层网络，重新添加几层网络后再用新数据重新训练这几层，数据越多就可以重新训练越多层。如果有足够多的数据时就可以重新训练整个网络，那么这个网络在之前的数据训练称为预训练，在新数据上重新训练称为微调。</span></li> 
   <li><span style="color:#595959;">有很多低层次的特征（如边缘检测、曲线检测、点检测、阳性对象检测）从非常大的图像识别数据库中学习到这些知识，线条、点、曲线等这些知识（也许是对象的一小部分）可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。</span></li> 
   <li><span style="color:#595959;">算法学习到很多结构和图像形状信息（中层特征），其中一些知识可能会很有用，它就可能学到足够多的信息，学习到不同图像是有哪些部分组成的。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）例子：已经学习一个语音识别系统（输入音频，输出文本），利用迁移学习迁移到一个“唤醒词”/“触发词”检测系统（输入指定音频来唤醒设备）。</span></p> 
  <ul>
   <li><span style="color:#595959;">语音识别系统从10000小时数据训练，但对于触发字检测也许只有1小时数据（数据太少，不能用来拟合很多参数）。</span></li> 
   <li><span style="color:#595959;">即使触发字任务数据集很小，在训练语音识别系统时预先学到很多人类声音的特征、人类语言组成部分等知识，可以帮助我们建立一个很好的触发字检测系统。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（5）迁移学习的场景：源任务A，目标任务B</span></p> 
  <ul>
   <li><span style="color:#595959;">任务A和B有相同的输入时，迁移学习才有意义。例如输入的都是图像，或者输入的都是音频。</span></li> 
   <li><span style="color:#595959;">任务A的数据比任务B的数据多很多时，迁移学习才有意义。因为任务B的每个数据更有价值，对任务B来说通常任务A的数据量必须大得多才有帮助。</span></li> 
   <li><span style="color:#595959;">任务A的低层次特征可以帮助学习任务。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">8）多任务学习能让你训练一个神经网络来执行许多任务。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）例如：计算机视觉物体检测系统中同时检测人、汽车、交通标志等多个任务，一个神经网络学习多个任务。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）多任务学习意义</span></p> 
  <ul>
   <li><span style="color:#595959;">可以共用低层次特征</span></li> 
   <li><span style="color:#595959;">如果每个任务的数据量差不多，多任务学习可以。这个准则不一定对。</span> 
    <ul>
     <li><span style="color:#595959;">例子：有100个任务在同时学习，任务的样本量只有1000个，如果只关注第100个任务。如果单独去学习第100个任务，只有1000个样本训练模型，而通过其它99项任务的训练共1000*99个样本，这可能大幅提高算法性能，可以提供很多知识来增强这个任务的性能。</span></li> 
    </ul></li> 
   <li><span style="color:#595959;">当你可以训练一个足够大的神经网络，同时做好所有的工作，那么多任务学习比每个任务训练一个神经网络来完成各个单独的任务性能更好。否则如果不能够训练一个足够大的网络，多任务学习的替代方法是为每个任务训练一个单独的神经网络，而不是同一个神经网络中同时处理多个任务。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）多任务学习使用的频率要低于迁移学习，多任务学习比较少见，但计算机视觉物体检测是一个是一个例外。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">9）端到端学习：以前有一些数据处理系统需要多个阶段的处理，端到端学习就是忽略所有这些不同的阶段，用单个神经网络代替它。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）例子：语音识别系统，输入音频，输出文本</span></p> 
  <ul>
   <li><span style="color:#595959;">传统语音识别需要很多个阶段处理：从语音中提取一些特征，在提取一些低层次特征之后应用机器学习算法在音频片段中找到音位（声音的基本单位，每个单词由多个音位组成）。</span></li> 
   <li><span style="color:#595959;">端到端学习：输入一段音频，直接输出文本。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）端到端学习挑战之一是需要大量的数据才能让系统表现良好。</span></p> 
  <ul>
   <li><span style="color:#595959;">当你只有3000h音频时，传统流水线的语音识别系统可能比端到端学习效果要好。</span></li> 
   <li><span style="color:#595959;">当你有10000h音频，甚至100000h音频时，端到端突然开始很厉害。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）例子：人脸识别系统</span></p> 
  <ul>
   <li><span style="color:#595959;">人脸识别系统分两步完成效果较好，第一步找到摄像头中人脸位置，第二步再把人脸放到放到识别系统进行训练。</span></li> 
   <li><span style="color:#595959;">虽然没有足够的数据进行端到端学习，但是有足够的数据直接对以上两个步骤同时进行学习。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">10）是否要使用端到端的深度学习</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）端到端学习的优点</span></p> 
  <ul>
   <li><span style="color:#595959;">只是让数据说话。如果你有足够多的训练数据，如果你训练一个足够大的神经网络，那么那么就可以学习从x到y最适合的函数映射是什么。</span></li> 
   <li><span style="color:#595959;">很少需要手工设计的组件，能够简化工作流程，不需要花太多时间去手工设计功能。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）端到端学习缺点</span></p> 
  <ul>
   <li><span style="color:#595959;">需要大量的数据。</span></li> 
   <li><span style="color:#595959;">它排除了可能有用的手工设计组件，当数据量不足时，没有使用手工设计组件。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>2.进行误差分析</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）误差分析：如果算法还达不到理想效果，那么人工检查一下算法所犯的错误，也许可以让你了解接下来应该做什么，这个过程称为误差分析。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）使用误差分析来估计某个想法是否值得解决的例子：调试一个取得90%准确率猫分类器</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）检查一下算法分类出错的例子，注意到算法将一些狗分类为猫。</span></p> 
  <ul>
   <li><span style="color:#595959;">也许有人建议你针对狗图片优化算法：为了让算法不再将狗分类成猫，针对狗收集更多的狗图片，或者设计一些只处理狗的算法功能之类的。</span></li> 
   <li><span style="color:#595959;">问题是是否应该做一个项目专门处理狗的问题？这可能花费几个月时间才能让算法在狗问题上少识别为猫，也许没有效果。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）这里有个误差分析流程可以让你很快知道这个优化方向是否值得尝试：</span></p> 
  <ul>
   <li><span style="color:#595959;">收集一些（比如说100个）错误标记的验证集例子</span></li> 
   <li><span style="color:#595959;">逐一检查每个被错误识别的样本，看有多少个例子是狗。假如只有5%错误例子是狗，意味着即使完全解决狗的问题，只能修正100个错误中的5个，误差从10%下降到9.5%（10%*(1-5%)=9.5%），这就是关于这个优化的上限。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）在搭建应用系统时，这个简单的人工统计步骤（统计错误数量）误差分析可以节省大量时间，可以迅速决定什么是最重要的或最有希望的方向。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">3）在做误差分析时也可以同时并行评估几个想法</span></p> 
  <p style="margin-left:18pt;"><img alt="" class="has" height="492" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221203436538.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2psaWFuZzM=,size_16,color_FFFFFF,t_70" width="504"></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）几个改善猫检测器的想法：</span></p> 
  <ul>
   <li><span style="color:#595959;">狗被识别为猫的问题</span></li> 
   <li><span style="color:#595959;">猫科动物（狮子、豹、猎豹等）被识别为猫的问题</span></li> 
   <li><span style="color:#595959;">图像模糊而误分类，改善算法来识别模糊图片</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）建立一个表格来记录被抽样的错误样本属于哪种情况，并在每个样本中备注情况（如狗被识别为猫，备注上写上狗类型）。分别人工统计每种想法中误分类的错误样本数量，并计算每个错误类型的百分比。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）这个分析步骤的结果可以给出一个估计，看是否值得去处理每个不同的错误类型。这里不一定是要解决占比最大的问题，它能让你对应该选择那些手段有个概念，给出了每个问题的性能上限，了解每种手段对性能有多大的提升空间。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">4）进行误差分析时应该找一组错误例子（验证集或测试集中的错误例子），观察错误标记的例子看看假阳性和假阴性，统计属于不同错误类型的错误数量。</span></p> 
  <ul>
   <li><span style="color:#595959;">这个过程中，可能会得到启发，归纳出新的误差类型。</span></li> 
   <li><span style="color:#595959;">通过统计不同类型错误标记类型占比总数的百分比，可以帮你发现哪些问题需要优先解决，或者给你构思新优化方向的灵感。</span></li> 
   <li style="margin-left:18pt;"><span style="color:#595959;"><strong>3. 清楚标注错误的数据</strong></span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">1）深度学习算法对训练集的随机误差是相当鲁棒的</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）只要你的标记出错的例子与随机误差相差不大，误差足够随机，那么不管这些误差也没有问题，而不要花太多时间修复它们。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）只要总数据集足够大，实际误差可能不会太高。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）深度学习算法对随机误差是相当鲁棒的，但对系统性的错误就没有那么鲁棒了。</span></p> 
  <ul>
   <li><span style="color:#595959;">比如说，如果做标记的人一直把白色的狗标记成猫，那就是系统性的错误，经过学习后，分类器会把所有白色的狗都分类为猫。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">3）如果验证集和测试集中有标记错误的样本</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）如果担心验证集和测试集中标记出错的例子带来影响，建议在误差分析时增加一个额外的列来统计标记出错的例子数。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><img alt="" class="has" height="474" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221203436512.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2psaWFuZzM=,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）如果这些标记错误的例子验证影响了你在验证集上评估算法的能力，那么就应该花时间修正错误的标签。如果它没有严重到影响到用验证集评估成本偏差的能力，那就不需要花费宝贵的时间去处理。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）判断是否值得去修改标记出错的数据</span></p> 
  <ul>
   <li><span style="color:#595959;">假设系统达到90%准确度，10%的错误。</span></li> 
   <li><span style="color:#595959;">错误标记引起的错误的数量或百分比对验证集误差的影响，此处是6%*10%=0.6%。</span></li> 
   <li><span style="color:#595959;">其他原因导致的验证集错误对验证集误差的影响，此处是9.4%。</span></li> 
   <li><span style="color:#595959;">这种情况下，需要集中精力修正9.4%的误差，而标记出错导致的错误是总体错误的一小部分而已，不是当下最重要的任务。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）需要修正验证集标记错误的例子</span></p> 
  <ul>
   <li><span style="color:#595959;">假设系统达到98%准确度，2%的错误。</span></li> 
   <li><span style="color:#595959;">假设错误标记引起的错误对验证集误差的影响为0.6%，其他原因导致的影响为1.4%。</span></li> 
   <li><span style="color:#595959;">在评估模型时，假设模型A误差2.1%，模型B误差为1.9%。此时标记错误的样本足以影响我们评估哪个模型更好，此时应该修正验证集中的错误标记。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">4）修正数据时指引和原则</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）不管用什么方法来修改错误，都应该同时修改验证集和测试集上的错误，验证集和测试集必须来自相同的分布。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）强烈建议你同时检验算法判断正确和判断错误的样本，而不是只检测判断错误的样本。否则有可能有些被正确判断的样本其实是判断错误的，修正样本标签后导致对算法偏差的估计可能变得更大。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）由于训练集数据量比较大，也因为前面讨论过的训练集的随机误差对算法影响不大，所以我们可能会只修正验证集和测试集的错误标记，而不修改训练集的错误标记。此时，训练集与验证集和测试集来自不同的数据分布。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）验证集和测试集来自同一分布非常重要，但如果训练集来自稍微不同的分布是一件很合理的事情。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>4. 快速搭建你的第一个系统，并进行迭代</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）开发一个全新的机器学习应用时，应该尽快建立第一个系统原型，然后快速迭代。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）例子：语音识别系统有很多优化方向 </span></p> 
  <ul>
   <li><span style="color:#595959;">有一些特定的技术可以让语音识别系统对嘈杂的背景更加健壮：咖啡店的噪音（很多人聊天）、车辆的噪音（高速上汽车的噪音等）</span></li> 
   <li><span style="color:#595959;">有一些方法可以让语音识别系统在处理带口音时更健壮</span></li> 
   <li><span style="color:#595959;">远场语音识别问题：麦克风与说话人距离很远的问题</span></li> 
   <li><span style="color:#595959;">儿童的语音识别带来的特征挑战（来自单词发音方面）</span></li> 
   <li><span style="color:#595959;">说话口吃问题</span></li> 
   <li><span style="color:#595959;">…</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">3）一般情况下，对于所有的机器学习程序可能会有50个方向可以优化前进，并且每个方向都是相对合理的，可以改善系统，如何选择一个方向集中精力处理是一个挑战。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">4）如果搭建一个全新的机器学习程序，就是快速搭建好第一个系统，然后开始迭代。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）首先，快速设立验证集和测试集，还有评估指标。它决定了你的目标在哪里，如果你的目标定错了，之后改也是可以的。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）然后搭好一个机器学习系统原型，然后找到训练集，看看训练效果如何，在验证集合测试集评估指标表现如何。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）再进行偏差方差分析以及误差分析来确定下一步优先做什么。特别是如果误差分析让你了解到大部分误差的来源。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）建立初始系统的意义在于有一个训练过的系统让你确定偏差方差的范围，就可以知道下一步应该优先做什么。让你能够进行误差分析，可以观察一些错误，然后想出所有能进行的方向，知道哪些是最优希望的方向。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">5）以下情况，快速搭建第一个系统的建议的适用程度要低一些，一开始就搭建比较复杂的系统</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）如果你在这个应用程序领域有很多经验</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）如果一个领域有很多可以借鉴的学术文献（如人脸识别领域），可以从现有大量文献为基础出发，一开始就搭建比较复杂的系统</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>5. 在不同的划分上进行训练并测试</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）深度学习算法对训练数据胃口很大，越多数据对训练越好，即使大部分数据来自不同的分布，从而导致训练集、验证集和测试集数据分布不一样的情况出现，越来越多团队都用来自和验证集和测试集分布不同的数据来训练。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）处理训练集和测试集数据分布不一样的例子：猫分类器，训练数据来自网络（很清晰），测试数据来自手机拍照（很模糊）</span></p> 
  <p style="margin-left:18pt;"><img alt="" class="has" height="454" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/201902212034379.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2psaWFuZzM=,size_16,color_FFFFFF,t_70" width="516"></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）来自手机上传的照片是真正关系的数据分布，手机上传的数量不多（如1万张），来自网络的照片数量很多（超过20万）。只用手机上的照片训练的话照片数量太少了，只使用网络的照片的话与真正关心的数据分布不一样，所以需要结合两组照片数据。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）错误的组合方式</span></p> 
  <ul>
   <li><span style="color:#595959;">把两组照片混合在一起，然后进行混洗，然后再按比例把照片分配到训练集、 验证集和测试集上。</span></li> 
   <li><span style="color:#595959;">比如，205000张照片作为训练集、2500张照片作为验证集、2500张照片作为测试集。验证集和测试集中只有119张照片来自手机上传，设立验证集的目的是告诉团队瞄准的目标，而瞄准的目标大部分来自网络下载的照片，这其实不是真实希望的。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）正确的组合方式</span></p> 
  <ul>
   <li><span style="color:#595959;">训练集205000张=全部网络照片20万张+一半用户上传的照片5000张，验证集和测试集都是2500张用户上传的照片（都是真实关心的数据分布）。</span></li> 
   <li><span style="color:#595959;">这样划分数据的好处在于，现在瞄准的目标就是我们想要处理的目标。</span></li> 
   <li><span style="color:#595959;">缺点在于训练集分布和验证集以及测试集分布不一样，但事实证明这样的数据划分在长期能带来更好的系统性能。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">3）例子：语音识别系统的后视镜，可以语音沟通，如：“后视镜，请帮我找找到最近的加油站的导航方向”。很多数据（共500000条）来自其他语音识别应用，如：数据供应商买来的数据、智能语音激活音箱的数据、语音激活键盘的数据，只有20000条数据来自后视镜设备。</span></p> 
  <p style="margin-left:18pt;"><img alt="" class="has" height="477" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221203436742.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2psaWFuZzM=,size_16,color_FFFFFF,t_70" width="559"></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）划分方式一：训练集=全部其他语音识别数据500000条，验证集和测试集数据都是来自后视镜的数据各10000条。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）划分方式二（如果你觉得验证集和测试集不需要这么多数据）：训练集=全部其他语音识别数据500000条+后视镜数据10000条，验证集和测试集数据都是来自后视镜的数据各5000条。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>6. 不匹配数据划分的偏差和方差</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）估计学习算法的偏差和方差可以帮我们确定接下来应该优先做的方向，但是如果训练集和验证集及测试集分布不同时，分析偏差和方差的方式会不一样。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）例子：猫分类器，假设人类水平接近0%误差</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）假设训练误差1%，验证集误差10%</span></p> 
  <ul>
   <li><span style="color:#595959;">在分布一样的时候，可以说这里存在很大的方差问题。</span></li> 
   <li><span style="color:#595959;">如果训练数据和验证数据来自不同的分布时，就不能确定的说这里存在很大的方差了。也许算法在验证集上做得不错，只是由于训练集更容易被识别，而验证集很难被识别。从训练集到验证集有两个因素发生变化：算法见过的训练数据没有见过验证集数据、验证集的数据分布不同。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）为了确认是由于泛化能力，还是由于数据分布不一样的原因，需要定义一组新的数据“训练-验证集”</span></p> 
  <ul>
   <li><span style="color:#595959;">这数据来源于训练集数据，但是不用于训练模型。把训练集随机打乱，并分一部分出来作为训练-验证集。</span></li> 
   <li><span style="color:#595959;">数据集分为4份：训练集、训练-验证集、验证集、测试集。</span></li> 
   <li><span style="color:#595959;">训练集和训练-验证集分布一样，验证集和测试集分布一样，验证集和测试集的数据是最后真实评估模型的数据，而训练集和训练-验证集与验证集和测试集数据分布不一样。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）训练集误差与训练-验证集误差的差距代表了模型的方差问题的可优化空间，从中可以知道模型的泛化能力。以下为方差很大的例子：</span></p> 
  <ul>
   <li><span style="color:#595959;">训练集误差为1%</span></li> 
   <li><span style="color:#595959;">训练-验证集误差为9%</span></li> 
   <li><span style="color:#595959;">验证集误差为10%</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）训练-验证集误差与验证集误差之间的差距代表数据不匹配的程度，因为算法没有直接在训练-验证集或验证集上训练过，这两者的数据来自不同的分布。以下为数据不匹配问题的例子：</span></p> 
  <ul>
   <li><span style="color:#595959;">训练集误差为1%</span></li> 
   <li><span style="color:#595959;">训练-验证集误差为1.5%</span></li> 
   <li><span style="color:#595959;">验证集误差为10%</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（5）存在很大偏差问题的例子：</span></p> 
  <ul>
   <li><span style="color:#595959;">人类水平误差为0%</span></li> 
   <li><span style="color:#595959;">训练集误差为10%</span></li> 
   <li><span style="color:#595959;">训练-验证集误差为11%</span></li> 
   <li><span style="color:#595959;">验证集误差为12%</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（6）同时存在偏差问题和数据不匹配问题的例子：</span></p> 
  <ul>
   <li><span style="color:#595959;">人类水平误差为0%</span></li> 
   <li><span style="color:#595959;">训练集误差为10%</span></li> 
   <li><span style="color:#595959;">训练-验证集误差为11%</span></li> 
   <li><span style="color:#595959;">验证集误差为20%</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">3）各个数据集误差差距总结</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）训练集误差与贝叶斯误差的差值为可避免偏差值大小。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）训练-验证集误差与训练集误差的差值为方差值大小。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）验证集误差与训练-验证集误差的差值为数据不匹配问题的大小。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）测试集误差与验证集误差的差值为对验证集过拟合的程度，如果差值很大，说明需要一个更大的验证集。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">4）贝叶斯误差、训练集误差、训练-验证集误差、验证集误差和测试集误差的值应该是从越来越大</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）训练集和训练-验证集误差是从训练集分布评估的，验证集和测试集误差是对验证集测试集分布评估的。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）如果某个值没有变大（比上一个误差要小），如下面例子，说明训练数据比验证集和测试集数据难识别多了。</span></p> 
  <ul>
   <li><span style="color:#595959;">人类水平误差为4%</span></li> 
   <li><span style="color:#595959;">训练集误差为7%</span></li> 
   <li><span style="color:#595959;">训练-验证集误差为10%</span></li> 
   <li><span style="color:#595959;">验证集误差为6%</span></li> 
   <li><span style="color:#595959;">测试集误差为6%</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">5）更通用的分析方法</span></p> 
  <p style="margin-left:18pt;"><img alt="" class="has" height="589" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221203436279.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2psaWFuZzM=,size_16,color_FFFFFF,t_70" width="565"></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）制定以上表格，横轴是不同分布的训练集数据（例子中为来：自其它方式语音识别数据）和验证集/测试集数据（来自后视镜的语音识别数据）；纵轴是人类水平误差、参与训练的数据误差和没有参与训练的数据误差。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）正常情况下，我只需要分析图中红色框几项就可以找到方向：训练集与贝叶斯误差差值（可避免偏差）、训练-验证集与训练集误差差值（方差）、验证集与训练-验证集误差差值（数据不匹配）。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）进行表格中剩余的两项分析也是有用的：人类在真实分布（验证集/测试集数据）的误差、真实分布用于训练时的训练误差。当你继续进行更多分析时，分析并不一定会给你指明方向，但有时候你会洞察到一些特征。</span></p> 
  <ul>
   <li><span style="color:#595959;">对比人类在两种不同分布上的表现可以看出哪种数据分布更难被识别，上例中后视镜的数据更难被识别。</span></li> 
   <li><span style="color:#595959;">对比两种分布数据在训练集上的误差可以了解到偏差和方差，还有数据不匹配这个问题的不同程度。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>7. 定位数据不匹配</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）数据不匹配问题没有完全系统的解决方案，但是有一些可以尝试的方法</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）人工做误差分析，尝试了解训练集和验证测试集的具体差异。为了误差分析时避免对测试集过拟合，应该只人工去看验证集而不看测试集数据。汽车后视镜例子中：</span></p> 
  <ul>
   <li><span style="color:#595959;">假设发现验证集中有很多汽车噪音，这是验证集和训练集差异之一</span></li> 
   <li><span style="color:#595959;">发现在汽车里语音激活后视镜经常错误识别街道号码，真实使用时经常导航到某些街道，而训练数据中没有这些导航数据</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）可以尝试把训练数据变得更像验证集数据，或者采集更多类似验证测试集的数据</span></p> 
  <ul>
   <li><span style="color:#595959;">如果发现车辆背景噪音是主要误差来源，可以模拟车辆噪声数据，人工合成噪音数据</span></li> 
   <li><span style="color:#595959;">如果发现很难识别街道号码，可以有意识收集更多人们说数字的音频数据，加到训练集中</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">2）人工数据合成</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）例子1：清晰对话+汽车噪音=人工合成有噪音的对话</span></p> 
  <ul>
   <li><span style="color:#595959;">通过人工数据合成，可以快速制造更多的训练数据，那就不需要花时间实际出去收集数据了。</span></li> 
   <li><span style="color:#595959;">存在问题：假设在一辆车上录了1h的汽车噪音，并重复合并到10000h的清晰对话中，这些噪音录音可能只是汽车噪音的很小的一个集合，模型可能会对这辆车的噪声过拟合。使用10000h噪音与10000h清晰对话合成比只使用1h噪音合成效果要更好，但是实际上很难采集这么多数据。</span></li> 
   <li><span style="color:#595959;">还有一个难点是，人耳无法区分采集到的1h噪音与验证集中的噪音是否一致。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）例子2：汽车识别</span></p> 
  <ul>
   <li><span style="color:#595959;">通过软件模拟合成很多汽车图片作为训练集，这些合成数据可能只是车辆的很小的子集，但是算法可能会对合成的一个小集合过拟合</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">3）如果你任务数据不匹配问题，建议进行误差分析或看看训练集和验证集，试图了解两个数据分布到底有什么不同，然后看看是否有办法收集更多看起来像验证集的数据作训练。人工数据合成可以提升模型表现，但使用人工合成数据时一定要谨慎，要记住有可能只从所有可能性的空间只选了很小一部分去模拟数。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>8. 迁移学习</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）迁移学习：神经网络可以从一个任务中学习得到知识，并将这些知识应用到另一个独立的任务中。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）适用场景：迁移来源问题有很多数据，但迁移目标问题没有那么多数据，找一个相关但不相同的任务可以帮助学习目标任务。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）不适用场景：迁移来源问题数据很少，但迁移目标问题数据很多。可以使用迁移学习不会有害处，但是对目标问题没有什么帮助。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）例子：从图像（猫、狗、鸟等）识别任务迁移学习阅读X射线扫描图</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）做法：把神经网络最后的输出层删除，重新创建输出层并赋予随机权重，然后使用放射诊断数据训练模型。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）如果有更多的数据，可以删除最后面几层网络，重新添加几层网络后再用新数据重新训练这几层，数据越多就可以重新训练越多层。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）如果有足够多的数据时就可以重新训练整个网络，那么这个网络在之前的数据训练称为预训练，在新数据上重新训练称为微调。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（4）当你做图像识别任务时，可以训练神经网络的所有常用参数，所有层的权重，然后得到一个图像识别预测网络。</span></p> 
  <ul>
   <li><span style="color:#595959;">有很多低层次的特征（如边缘检测、曲线检测、点检测、阳性对象检测）从非常大的图像识别数据库中学习到这些知识，线条、点、曲线等这些知识（也许是对象的一小部分）可以帮助放射科诊断网络学习更快一些，或者需要更少的学习数据。</span></li> 
   <li><span style="color:#595959;">算法学习到很多结构和图像形状信息，其中一些知识可能会很有用，它就可能学到足够多的信息，学习到不同图像是有哪些部分组成的。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">3）例子：已经学习一个语音识别系统（输入音频，输出文本），利用迁移学习迁移到一个“唤醒词”/“触发词”检测系统（输入指定音频来唤醒设备）</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）做法：把最后一层删除并加入新网络层，有时可以加入多层节点，这取决于你有多少数据</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）迁移学习起作用的场合：迁移来源问题有很多数据，但迁移目标问题没有那么多数据。</span></p> 
  <ul>
   <li><span style="color:#595959;">例如：图像识别任务迁移学习到放射科任务</span> 
    <ul>
     <li><span style="color:#595959;">图像识别任务中有1百万个样本（有足够的数据学习低层次特征，前面几层学习到如何识别很多有用的特征），但对放射科任务只有1百个样本（数据非常少）。</span></li> 
     <li><span style="color:#595959;">即使放射科数据很少，但可以从图像识别训练中学到很多知识可以迁移并帮助放射科识别任务的性能。</span></li> 
     <li><span style="color:#595959;">如果图像识别任务数据很少，放射科数据很多，则不适合使用迁移学习，也许没有害处，但是没有帮助。</span></li> 
    </ul></li> 
   <li><span style="color:#595959;">例子：语音识别系统迁移学习到触发字检测系统</span> 
    <ul>
     <li><span style="color:#595959;">语音识别系统从10000小时数据训练，但对于触发字检测也许只有1小时数据（数据太少，不能用来拟合很多参数）。</span></li> 
     <li><span style="color:#595959;">即使触发字任务数据集很小，在训练语音识别系统时预先学到很多人类声音的特征、人类语言组成部分等知识，可以帮助我们建立一个很好的触发字检测系统。</span></li> 
    </ul></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">4）迁移学习的场景：源任务A，目标任务B</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）任务A和B有相同的输入时，迁移学习才有意义。例如输入的都是图像，或者输入的都是音频。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）任务A的数据比任务B的数据多很多时，迁移学习才有意义。因为任务B的每个数据更有价值，对任务B来说通常任务A的数据量必须大得多才有帮助。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）任务A的低层次特征可以帮助学习任务。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>9. 多任务学习</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）多任务学习能让你训练一个神经网络来执行许多任务。例如：计算机视觉物体检测系统中同时检测人、汽车、交通标志等多个任务，一个神经网络学习多个任务。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）多任务学习意义</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）可以共用低层次特征</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）如果每个任务的数据量差不多，多任务学习可以。这个准则不一定对。</span></p> 
  <ul>
   <li><span style="color:#595959;">例子：有100个任务在同时学习，任务的样本量只有1000个，如果只关注第100个任务。如果单独去学习第100个任务，只有1000个样本训练模型，而通过其它99项任务的训练共1000*99个样本，这可能大幅提高算法性能，可以提供很多知识来增强这个任务的性能。</span></li> 
  </ul>
  <p style="margin-left:18pt;"><span style="color:#595959;">（3）当你可以训练一个足够大的神经网络，同时做好所有的工作，那么多任务学习比每个任务训练一个神经网络来完成各个单独的任务性能更好。否则如果不能够训练一个足够大的网络，多任务学习的替代方法是为每个任务训练一个单独的神经网络，而不是同一个神经网络中同时处理多个任务。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">3）多任务学习使用的频率要低于迁移学习，多任务学习比较少见，但计算机视觉物体检测是一个是一个例外。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>10. 什么是端到端的深度学习</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）端到端学习：以前有一些数据处理系统需要多个阶段的处理，端到端学习就是忽略所有这些不同的阶段，用单个神经网络代替它。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）例子：语音识别系统，输入音频，输出文本</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）传统语音识别需要很多个阶段处理：从语音中提取一些特征，在提取一些低层次特征之后应用机器学习算法在音频片段中找到音位（声音的基本单位，每个单词由多个音位组成）。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）端到端学习：输入一段音频，直接输出文本。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">3）端到端学习挑战之一是需要大量的数据才能让系统表现良好。例子：语音识别系统</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）当你只有3000h音频时，传统流水线可能比端到端学习效果要好。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）当你有10000h音频，甚至100000h音频时，端到端突然开始很厉害。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">4）例子：人脸识别系统</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）人脸识别系统分两步完成效果较好，第一步找到摄像头中人脸位置，第二步再把人脸放到放到识别系统进行训练。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）虽然没有足够的数据进行端到端学习，但是有足够的数据直接对以上两个步骤同时进行学习。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;"><strong>11. 是否要使用端到端的深度学习</strong></span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">1）端到端学习的优点</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）只是让数据说话。如果你有足够多的训练数据，如果你训练一个足够大的神经网络，那么那么就可以学习从x到y最适合的函数映射是什么。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）很少需要手工设计的组件，能够简化工作流程，不需要花太多时间去手工设计功能。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">2）端到端学习缺点</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（1）需要大量的数据。</span></p> 
  <p style="margin-left:18pt;"><span style="color:#595959;">（2）它排除了可能有用的手工设计组件。</span></p> 
  <ul>
   <li><span style="color:#595959;">如果你没有足够的数据，学习算法就没办法从很小的训练集中获得洞察力，所以手工设计组件在这种情况可能是把人类知识直接注入算法的途径。</span></li> 
   <li><span style="color:#595959;">我们学习的算法有两个主要的知识来源：来自数据和来自手工设计的任何东西。</span></li> 
  </ul>
  <p style="margin-left:18pt;">&nbsp;</p> 
  <p style="margin-left:18pt;">相关文章：</p> 
  <h1><a href="https://blog.csdn.net/jliang3/article/details/87539769" rel="nofollow">《深度学习工程师-吴恩达》04结构化机器学习项目--机器学习（ML）策略1 学习总结 （如何进一步优化系统的方法论）</a></h1> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
