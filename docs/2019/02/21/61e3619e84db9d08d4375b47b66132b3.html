<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>肖仰华 基于知识图谱的问答系统 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="肖仰华 基于知识图谱的问答系统" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="&nbsp;&nbsp;&nbsp; 本文整理自复旦大学知识工场肖仰华教授在VLDB 2017 会议上的论文报告，题目为《KBQA: Learning Question Answering over QA Corpora and Knowledge Bases》，作者包括：崔万云博士（现上海财经大学讲师），肖仰华教授（复旦大学）等等。 VLDB (Very Large Data Base) 是数据库领域最顶尖的国际会议之一，被中国计算机学会推荐国际学术会议列表认定为 A 类会议。涵盖数据库系统、数据管理、大数据处理、数据挖掘等各个研究领域，是展现数据库前沿科研成果以及探讨数据库未来发展方向的盛会。 640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1 肖仰华：大家好，非常高兴能在这里与大家分享我们的论文。 640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1 问答系统（QA）已经成为人类访问十亿级知识图谱的流行方式，它回答的是自然语言问题。 QA系统最有名的故事之一就是IBM WATSON在2011年参加了Jeopardy竞赛，打败了所有人类竞争对手，获得了100万美元的奖励。 640?wx_fmt=png QA的研究非常重要。首先，从应用角度来看，QA系统降低了人机交互的门槛， 非常适合成为互联网的新入口。作为聊天机器人的重要组件，吸引了来自工业界的大量关注。 从人工智能角度来看，QA是评估机器智能的一个重要任务，也就是图灵测试。同时，QA还是许多AI技术的重要测试平台，比如机器学习，自然语言处理，机器认知等等 &nbsp; 640?wx_fmt=png 现在我们来谈谈知识库。近年来，我们目睹了知识库的发展，越来越多的大规模知识库涌现出来，如Google Knowledge graph，Yago和Freebase等。这些知识库具有体量大，质量高的特点。 一个知识库包含了大量的结构化数据。右图给出了一个关于Obama的知识图谱示例。知识库中的每一个三元组代表一个知识或某个事实。 例如，一个三元组（d，人口，390k）表示檀香山的人口为390k。 &nbsp; 640?wx_fmt=png KBQA指的是以知识库作为答案来源的问答系统。 那么它是如何工作的呢？关键在于将自然语言问题转换为知识库上的结构化查询。例如，要回答“有多少人住在檀香山？”这个问题，我们需要将其转移到SPARQL或者SQL查询。 这里的关键问题是属性推断。 640?wx_fmt=png 关于属性推断，我们面临两个挑战。 第一个挑战是问题表示。对于任意一个QA系统，我们需要一个具有代表性的问题表示来帮助识别具有相同语义的问题，同时区分不同意图的问题。 第二个挑战是语义匹配，如何将问题表示映射到知识库中的结构化查询？ 640?wx_fmt=png 然而，之前的解决方案并不能解决上述提出的挑战。 我们研究了两个主流的解决方案。 第一个是基于模板/规则的方法。这个方法用模板表示句子，语义解析往往通过人工标记来实现。这种方法的优点是它的结果是用户可控的，这使得它更适用于工业用途。缺点是严重依赖人工，成本太高，昂贵的人力成本使得它无法处理多样性的问题。 另一个是基于神经网络的方法。最近这种做法很受欢迎，它们通过embedding的方式来表示一个问题，并从QA语料库中学习出它的语义解析。这种方法的优点是embedding是灵活的，所以它可以理解各种各样的问题。缺点是基于神经网络的方法通常具有较差的解释性，此外，结果是不可控的，所以他们并不适用于工业应用。 因此，我们不禁会想：能不能提出一种新的方法兼备这两种方法的优点？ 640?wx_fmt=png 为了做到这一点，我们用模板来表示自然语言问题。 例如，“檀香山有多少人？”的模板成为“城市里有多少人？”。因为使用了模板作为问题表示，我们的方法具有可解释性和用户可控性。 然而，我们并不是手动标记模板，而是从QA语料库中自动学习模板。 最终，我们为2,782个意图学到了2,700万个模板，这么大量的数据保证我们可以理解不同的问题。 640?wx_fmt=png 这个系统体系结构如图所示。它主要包括两个过程：离线预处理部分和在线QA部分。 我们先来看看离线过程，离线过程的目标是学习出从模板到属性的映射。 再来看在线部分，当一个问题进来，系统首先将其解析和分解为一组二元事实型问题。对于每个二元事实型问题，系统使用概率推断来寻找它的值。这个推断是基于给定模板的属性分布来得到的。 &nbsp; 640?wx_fmt=png 接下来，我们对这个问题进行形式化定义。给定问题q，问答系统的目标是寻找具有最大概率的答案v（其中，v是一个简单值）。 我们提出了一个生成模型来解释如何为一个问题找到它的答案。 我们认为使用概率推断的方法来做KBQA是非常合理的。首先，一些问题的意图是模糊的。其次，大多数知识库都是不完整的。最后，QA语料库中的答案也可能是错误的。 &nbsp; &nbsp; 640?wx_fmt=png 我们以这个问答对来说明这个生成过程。 640?wx_fmt=png 从用户问题q开始，我们首先生成或者说识别出其中对应的知识库中的实体d。 640?wx_fmt=png 在知道问题和实体之后，我们根据d的概念分布生成模板t。 这样，我们得到了一个模板“有多少人住在某城市？” 640?wx_fmt=png 由于属性只与模板有关，所以我们推断出这个属性的模板为“population”。 640?wx_fmt=png 最后，给定实体d和属性population，我们通过查找知识库来得到它的答案。 640?wx_fmt=png 通过这种方法，我们完成了从一个自然语言问题到生成答案的整个过程。这个过程可以建模为一个概率图模型。 基于这个生成模型，可以得到一个联合概率分布，进而用来解决给定其他变量求最大v的条件概率问题。 &nbsp; 640?wx_fmt=png 下一个问题是如何计算出联合概率分布公式中的每一种概率。 我们可以从语料库直接估计出来大部分的概率。例如实体分布的概率，模板分布的概率以及值分布的概率。 我们从雅虎问答的4200万的QA pairs中，学习出问题模板和属性的映射关系。表中展示了QA语料库中的一些例子。 &nbsp; 640?wx_fmt=png 最后我们来估计P(P|T)的值。基本思路是将P(P|T)作为参数，然后使用极大似然法来估计P(P|T)。 这里我们使用了EM算法来进行参数估计。 &nbsp; 640?wx_fmt=png KBQA的另一个难点就是回答复杂问题。在面对复杂问题时，我们采用了分治算法。首先，系统把问题分解为一系列的二元事实型问题，然后系统依次回答每个问题。每个问题的答案都是一个概率，我们通过动态规划算法找到最优分解。 640?wx_fmt=png 接下来我们来看看实验部分。我们首先通过实验证明属性推断的有效性。我们从学习出的属性数量和模板数据来对比我们的方法和bootstrapping方法。结果表明，我们的KBQA方法能得到更多的属性和模板， 这意味着KBQA在属性推理中更有效。大量的模板可以确保KBQA理解不同的问题模板，同时，大量的属性可以确保KBQA理解不同的关系。 640?wx_fmt=png 我们也在很多benchmarks上用到了我们的KBQA。图为QALD-5的结果。结果表明，KBQA具有最高的准确度。由于KBQA只回答二元事实型问题，因此召回率相对较低。如果我们只考虑二元事实型问答，召回率能上升到0.67。 640?wx_fmt=png 即使在一个不以二元事实型问题为主的数据集中（如WEBQUESTIONS，QALD-3），KBQA也可以作为混合问答系统的一个完美组件。 我们这样构建混合问题系统：一个问题过来，首先提交给我们的KBQA系统。如果KBQA系统不能回答，这意味着这个问题很可能不是二元事实型问题。然后，我们再将这个问题提交给baseline系统。 结果表明，当使用了我们的KBQA系统后，baseline系统的性能都有了很明显的提高。 640?wx_fmt=png 最后，我们对本文进行总结。我们构建了一个基于知识库的问答系统KBQA。 我们的QA系统和以前的系统有两个明显区别：第一，它使用模板理解问题；第二，它从非常大的QA语料库中学习语义解析。 我们认为系统还有很多可以改进的地方。 首先，目前关于QA系统的研究主要建立在开放领域的知识库上。因此，研究如何使这些系统适应不同特定领域的应用是非常重要的。 其次，我们希望可以通过常识推理来更深入的理解问题。 再者，由于知识库仍然存在数据缺陷问题，如何使用互联网作为外部知识变得非常重要。 640?wx_fmt=png 640?wx_fmt=png 获取论文和完整PPT 关注“知识工场”微信公众号，回复“20170907”获取下载链接。 以上就是肖仰华教授在VLDB 2017 会议上为大家带来的全部内容。知识工场实验室后续将为大家带来更精彩的文章。请大家关注！ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 640?wx_fmt=png OpenKG.CN 中文开放知识图谱（简称OpenKG.CN）旨在促进中文知识图谱数据的开放与互联，促进知识图谱和语义技术的普及和广泛应用。 0?wx_fmt=jpeg &nbsp; &nbsp;" />
<meta property="og:description" content="&nbsp;&nbsp;&nbsp; 本文整理自复旦大学知识工场肖仰华教授在VLDB 2017 会议上的论文报告，题目为《KBQA: Learning Question Answering over QA Corpora and Knowledge Bases》，作者包括：崔万云博士（现上海财经大学讲师），肖仰华教授（复旦大学）等等。 VLDB (Very Large Data Base) 是数据库领域最顶尖的国际会议之一，被中国计算机学会推荐国际学术会议列表认定为 A 类会议。涵盖数据库系统、数据管理、大数据处理、数据挖掘等各个研究领域，是展现数据库前沿科研成果以及探讨数据库未来发展方向的盛会。 640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1 肖仰华：大家好，非常高兴能在这里与大家分享我们的论文。 640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1 问答系统（QA）已经成为人类访问十亿级知识图谱的流行方式，它回答的是自然语言问题。 QA系统最有名的故事之一就是IBM WATSON在2011年参加了Jeopardy竞赛，打败了所有人类竞争对手，获得了100万美元的奖励。 640?wx_fmt=png QA的研究非常重要。首先，从应用角度来看，QA系统降低了人机交互的门槛， 非常适合成为互联网的新入口。作为聊天机器人的重要组件，吸引了来自工业界的大量关注。 从人工智能角度来看，QA是评估机器智能的一个重要任务，也就是图灵测试。同时，QA还是许多AI技术的重要测试平台，比如机器学习，自然语言处理，机器认知等等 &nbsp; 640?wx_fmt=png 现在我们来谈谈知识库。近年来，我们目睹了知识库的发展，越来越多的大规模知识库涌现出来，如Google Knowledge graph，Yago和Freebase等。这些知识库具有体量大，质量高的特点。 一个知识库包含了大量的结构化数据。右图给出了一个关于Obama的知识图谱示例。知识库中的每一个三元组代表一个知识或某个事实。 例如，一个三元组（d，人口，390k）表示檀香山的人口为390k。 &nbsp; 640?wx_fmt=png KBQA指的是以知识库作为答案来源的问答系统。 那么它是如何工作的呢？关键在于将自然语言问题转换为知识库上的结构化查询。例如，要回答“有多少人住在檀香山？”这个问题，我们需要将其转移到SPARQL或者SQL查询。 这里的关键问题是属性推断。 640?wx_fmt=png 关于属性推断，我们面临两个挑战。 第一个挑战是问题表示。对于任意一个QA系统，我们需要一个具有代表性的问题表示来帮助识别具有相同语义的问题，同时区分不同意图的问题。 第二个挑战是语义匹配，如何将问题表示映射到知识库中的结构化查询？ 640?wx_fmt=png 然而，之前的解决方案并不能解决上述提出的挑战。 我们研究了两个主流的解决方案。 第一个是基于模板/规则的方法。这个方法用模板表示句子，语义解析往往通过人工标记来实现。这种方法的优点是它的结果是用户可控的，这使得它更适用于工业用途。缺点是严重依赖人工，成本太高，昂贵的人力成本使得它无法处理多样性的问题。 另一个是基于神经网络的方法。最近这种做法很受欢迎，它们通过embedding的方式来表示一个问题，并从QA语料库中学习出它的语义解析。这种方法的优点是embedding是灵活的，所以它可以理解各种各样的问题。缺点是基于神经网络的方法通常具有较差的解释性，此外，结果是不可控的，所以他们并不适用于工业应用。 因此，我们不禁会想：能不能提出一种新的方法兼备这两种方法的优点？ 640?wx_fmt=png 为了做到这一点，我们用模板来表示自然语言问题。 例如，“檀香山有多少人？”的模板成为“城市里有多少人？”。因为使用了模板作为问题表示，我们的方法具有可解释性和用户可控性。 然而，我们并不是手动标记模板，而是从QA语料库中自动学习模板。 最终，我们为2,782个意图学到了2,700万个模板，这么大量的数据保证我们可以理解不同的问题。 640?wx_fmt=png 这个系统体系结构如图所示。它主要包括两个过程：离线预处理部分和在线QA部分。 我们先来看看离线过程，离线过程的目标是学习出从模板到属性的映射。 再来看在线部分，当一个问题进来，系统首先将其解析和分解为一组二元事实型问题。对于每个二元事实型问题，系统使用概率推断来寻找它的值。这个推断是基于给定模板的属性分布来得到的。 &nbsp; 640?wx_fmt=png 接下来，我们对这个问题进行形式化定义。给定问题q，问答系统的目标是寻找具有最大概率的答案v（其中，v是一个简单值）。 我们提出了一个生成模型来解释如何为一个问题找到它的答案。 我们认为使用概率推断的方法来做KBQA是非常合理的。首先，一些问题的意图是模糊的。其次，大多数知识库都是不完整的。最后，QA语料库中的答案也可能是错误的。 &nbsp; &nbsp; 640?wx_fmt=png 我们以这个问答对来说明这个生成过程。 640?wx_fmt=png 从用户问题q开始，我们首先生成或者说识别出其中对应的知识库中的实体d。 640?wx_fmt=png 在知道问题和实体之后，我们根据d的概念分布生成模板t。 这样，我们得到了一个模板“有多少人住在某城市？” 640?wx_fmt=png 由于属性只与模板有关，所以我们推断出这个属性的模板为“population”。 640?wx_fmt=png 最后，给定实体d和属性population，我们通过查找知识库来得到它的答案。 640?wx_fmt=png 通过这种方法，我们完成了从一个自然语言问题到生成答案的整个过程。这个过程可以建模为一个概率图模型。 基于这个生成模型，可以得到一个联合概率分布，进而用来解决给定其他变量求最大v的条件概率问题。 &nbsp; 640?wx_fmt=png 下一个问题是如何计算出联合概率分布公式中的每一种概率。 我们可以从语料库直接估计出来大部分的概率。例如实体分布的概率，模板分布的概率以及值分布的概率。 我们从雅虎问答的4200万的QA pairs中，学习出问题模板和属性的映射关系。表中展示了QA语料库中的一些例子。 &nbsp; 640?wx_fmt=png 最后我们来估计P(P|T)的值。基本思路是将P(P|T)作为参数，然后使用极大似然法来估计P(P|T)。 这里我们使用了EM算法来进行参数估计。 &nbsp; 640?wx_fmt=png KBQA的另一个难点就是回答复杂问题。在面对复杂问题时，我们采用了分治算法。首先，系统把问题分解为一系列的二元事实型问题，然后系统依次回答每个问题。每个问题的答案都是一个概率，我们通过动态规划算法找到最优分解。 640?wx_fmt=png 接下来我们来看看实验部分。我们首先通过实验证明属性推断的有效性。我们从学习出的属性数量和模板数据来对比我们的方法和bootstrapping方法。结果表明，我们的KBQA方法能得到更多的属性和模板， 这意味着KBQA在属性推理中更有效。大量的模板可以确保KBQA理解不同的问题模板，同时，大量的属性可以确保KBQA理解不同的关系。 640?wx_fmt=png 我们也在很多benchmarks上用到了我们的KBQA。图为QALD-5的结果。结果表明，KBQA具有最高的准确度。由于KBQA只回答二元事实型问题，因此召回率相对较低。如果我们只考虑二元事实型问答，召回率能上升到0.67。 640?wx_fmt=png 即使在一个不以二元事实型问题为主的数据集中（如WEBQUESTIONS，QALD-3），KBQA也可以作为混合问答系统的一个完美组件。 我们这样构建混合问题系统：一个问题过来，首先提交给我们的KBQA系统。如果KBQA系统不能回答，这意味着这个问题很可能不是二元事实型问题。然后，我们再将这个问题提交给baseline系统。 结果表明，当使用了我们的KBQA系统后，baseline系统的性能都有了很明显的提高。 640?wx_fmt=png 最后，我们对本文进行总结。我们构建了一个基于知识库的问答系统KBQA。 我们的QA系统和以前的系统有两个明显区别：第一，它使用模板理解问题；第二，它从非常大的QA语料库中学习语义解析。 我们认为系统还有很多可以改进的地方。 首先，目前关于QA系统的研究主要建立在开放领域的知识库上。因此，研究如何使这些系统适应不同特定领域的应用是非常重要的。 其次，我们希望可以通过常识推理来更深入的理解问题。 再者，由于知识库仍然存在数据缺陷问题，如何使用互联网作为外部知识变得非常重要。 640?wx_fmt=png 640?wx_fmt=png 获取论文和完整PPT 关注“知识工场”微信公众号，回复“20170907”获取下载链接。 以上就是肖仰华教授在VLDB 2017 会议上为大家带来的全部内容。知识工场实验室后续将为大家带来更精彩的文章。请大家关注！ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 640?wx_fmt=png OpenKG.CN 中文开放知识图谱（简称OpenKG.CN）旨在促进中文知识图谱数据的开放与互联，促进知识图谱和语义技术的普及和广泛应用。 0?wx_fmt=jpeg &nbsp; &nbsp;" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-21T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"&nbsp;&nbsp;&nbsp; 本文整理自复旦大学知识工场肖仰华教授在VLDB 2017 会议上的论文报告，题目为《KBQA: Learning Question Answering over QA Corpora and Knowledge Bases》，作者包括：崔万云博士（现上海财经大学讲师），肖仰华教授（复旦大学）等等。 VLDB (Very Large Data Base) 是数据库领域最顶尖的国际会议之一，被中国计算机学会推荐国际学术会议列表认定为 A 类会议。涵盖数据库系统、数据管理、大数据处理、数据挖掘等各个研究领域，是展现数据库前沿科研成果以及探讨数据库未来发展方向的盛会。 640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1 肖仰华：大家好，非常高兴能在这里与大家分享我们的论文。 640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1 问答系统（QA）已经成为人类访问十亿级知识图谱的流行方式，它回答的是自然语言问题。 QA系统最有名的故事之一就是IBM WATSON在2011年参加了Jeopardy竞赛，打败了所有人类竞争对手，获得了100万美元的奖励。 640?wx_fmt=png QA的研究非常重要。首先，从应用角度来看，QA系统降低了人机交互的门槛， 非常适合成为互联网的新入口。作为聊天机器人的重要组件，吸引了来自工业界的大量关注。 从人工智能角度来看，QA是评估机器智能的一个重要任务，也就是图灵测试。同时，QA还是许多AI技术的重要测试平台，比如机器学习，自然语言处理，机器认知等等 &nbsp; 640?wx_fmt=png 现在我们来谈谈知识库。近年来，我们目睹了知识库的发展，越来越多的大规模知识库涌现出来，如Google Knowledge graph，Yago和Freebase等。这些知识库具有体量大，质量高的特点。 一个知识库包含了大量的结构化数据。右图给出了一个关于Obama的知识图谱示例。知识库中的每一个三元组代表一个知识或某个事实。 例如，一个三元组（d，人口，390k）表示檀香山的人口为390k。 &nbsp; 640?wx_fmt=png KBQA指的是以知识库作为答案来源的问答系统。 那么它是如何工作的呢？关键在于将自然语言问题转换为知识库上的结构化查询。例如，要回答“有多少人住在檀香山？”这个问题，我们需要将其转移到SPARQL或者SQL查询。 这里的关键问题是属性推断。 640?wx_fmt=png 关于属性推断，我们面临两个挑战。 第一个挑战是问题表示。对于任意一个QA系统，我们需要一个具有代表性的问题表示来帮助识别具有相同语义的问题，同时区分不同意图的问题。 第二个挑战是语义匹配，如何将问题表示映射到知识库中的结构化查询？ 640?wx_fmt=png 然而，之前的解决方案并不能解决上述提出的挑战。 我们研究了两个主流的解决方案。 第一个是基于模板/规则的方法。这个方法用模板表示句子，语义解析往往通过人工标记来实现。这种方法的优点是它的结果是用户可控的，这使得它更适用于工业用途。缺点是严重依赖人工，成本太高，昂贵的人力成本使得它无法处理多样性的问题。 另一个是基于神经网络的方法。最近这种做法很受欢迎，它们通过embedding的方式来表示一个问题，并从QA语料库中学习出它的语义解析。这种方法的优点是embedding是灵活的，所以它可以理解各种各样的问题。缺点是基于神经网络的方法通常具有较差的解释性，此外，结果是不可控的，所以他们并不适用于工业应用。 因此，我们不禁会想：能不能提出一种新的方法兼备这两种方法的优点？ 640?wx_fmt=png 为了做到这一点，我们用模板来表示自然语言问题。 例如，“檀香山有多少人？”的模板成为“城市里有多少人？”。因为使用了模板作为问题表示，我们的方法具有可解释性和用户可控性。 然而，我们并不是手动标记模板，而是从QA语料库中自动学习模板。 最终，我们为2,782个意图学到了2,700万个模板，这么大量的数据保证我们可以理解不同的问题。 640?wx_fmt=png 这个系统体系结构如图所示。它主要包括两个过程：离线预处理部分和在线QA部分。 我们先来看看离线过程，离线过程的目标是学习出从模板到属性的映射。 再来看在线部分，当一个问题进来，系统首先将其解析和分解为一组二元事实型问题。对于每个二元事实型问题，系统使用概率推断来寻找它的值。这个推断是基于给定模板的属性分布来得到的。 &nbsp; 640?wx_fmt=png 接下来，我们对这个问题进行形式化定义。给定问题q，问答系统的目标是寻找具有最大概率的答案v（其中，v是一个简单值）。 我们提出了一个生成模型来解释如何为一个问题找到它的答案。 我们认为使用概率推断的方法来做KBQA是非常合理的。首先，一些问题的意图是模糊的。其次，大多数知识库都是不完整的。最后，QA语料库中的答案也可能是错误的。 &nbsp; &nbsp; 640?wx_fmt=png 我们以这个问答对来说明这个生成过程。 640?wx_fmt=png 从用户问题q开始，我们首先生成或者说识别出其中对应的知识库中的实体d。 640?wx_fmt=png 在知道问题和实体之后，我们根据d的概念分布生成模板t。 这样，我们得到了一个模板“有多少人住在某城市？” 640?wx_fmt=png 由于属性只与模板有关，所以我们推断出这个属性的模板为“population”。 640?wx_fmt=png 最后，给定实体d和属性population，我们通过查找知识库来得到它的答案。 640?wx_fmt=png 通过这种方法，我们完成了从一个自然语言问题到生成答案的整个过程。这个过程可以建模为一个概率图模型。 基于这个生成模型，可以得到一个联合概率分布，进而用来解决给定其他变量求最大v的条件概率问题。 &nbsp; 640?wx_fmt=png 下一个问题是如何计算出联合概率分布公式中的每一种概率。 我们可以从语料库直接估计出来大部分的概率。例如实体分布的概率，模板分布的概率以及值分布的概率。 我们从雅虎问答的4200万的QA pairs中，学习出问题模板和属性的映射关系。表中展示了QA语料库中的一些例子。 &nbsp; 640?wx_fmt=png 最后我们来估计P(P|T)的值。基本思路是将P(P|T)作为参数，然后使用极大似然法来估计P(P|T)。 这里我们使用了EM算法来进行参数估计。 &nbsp; 640?wx_fmt=png KBQA的另一个难点就是回答复杂问题。在面对复杂问题时，我们采用了分治算法。首先，系统把问题分解为一系列的二元事实型问题，然后系统依次回答每个问题。每个问题的答案都是一个概率，我们通过动态规划算法找到最优分解。 640?wx_fmt=png 接下来我们来看看实验部分。我们首先通过实验证明属性推断的有效性。我们从学习出的属性数量和模板数据来对比我们的方法和bootstrapping方法。结果表明，我们的KBQA方法能得到更多的属性和模板， 这意味着KBQA在属性推理中更有效。大量的模板可以确保KBQA理解不同的问题模板，同时，大量的属性可以确保KBQA理解不同的关系。 640?wx_fmt=png 我们也在很多benchmarks上用到了我们的KBQA。图为QALD-5的结果。结果表明，KBQA具有最高的准确度。由于KBQA只回答二元事实型问题，因此召回率相对较低。如果我们只考虑二元事实型问答，召回率能上升到0.67。 640?wx_fmt=png 即使在一个不以二元事实型问题为主的数据集中（如WEBQUESTIONS，QALD-3），KBQA也可以作为混合问答系统的一个完美组件。 我们这样构建混合问题系统：一个问题过来，首先提交给我们的KBQA系统。如果KBQA系统不能回答，这意味着这个问题很可能不是二元事实型问题。然后，我们再将这个问题提交给baseline系统。 结果表明，当使用了我们的KBQA系统后，baseline系统的性能都有了很明显的提高。 640?wx_fmt=png 最后，我们对本文进行总结。我们构建了一个基于知识库的问答系统KBQA。 我们的QA系统和以前的系统有两个明显区别：第一，它使用模板理解问题；第二，它从非常大的QA语料库中学习语义解析。 我们认为系统还有很多可以改进的地方。 首先，目前关于QA系统的研究主要建立在开放领域的知识库上。因此，研究如何使这些系统适应不同特定领域的应用是非常重要的。 其次，我们希望可以通过常识推理来更深入的理解问题。 再者，由于知识库仍然存在数据缺陷问题，如何使用互联网作为外部知识变得非常重要。 640?wx_fmt=png 640?wx_fmt=png 获取论文和完整PPT 关注“知识工场”微信公众号，回复“20170907”获取下载链接。 以上就是肖仰华教授在VLDB 2017 会议上为大家带来的全部内容。知识工场实验室后续将为大家带来更精彩的文章。请大家关注！ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 640?wx_fmt=png OpenKG.CN 中文开放知识图谱（简称OpenKG.CN）旨在促进中文知识图谱数据的开放与互联，促进知识图谱和语义技术的普及和广泛应用。 0?wx_fmt=jpeg &nbsp; &nbsp;","@type":"BlogPosting","url":"/2019/02/21/61e3619e84db9d08d4375b47b66132b3.html","headline":"肖仰华 基于知识图谱的问答系统","dateModified":"2019-02-21T00:00:00+08:00","datePublished":"2019-02-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/02/21/61e3619e84db9d08d4375b47b66132b3.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>肖仰华 | 基于知识图谱的问答系统</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>&nbsp;&nbsp;&nbsp; 本文整理自复旦大学知识工场肖仰华教授在VLDB 2017 会议上的论文报告，题目为《KBQA: Learning Question Answering over QA Corpora and Knowledge Bases》，作者包括：崔万云博士（现上海财经大学讲师），肖仰华教授（复旦大学）等等。</p> 
  <p><br> VLDB (Very Large Data Base) 是数据库领域最顶尖的国际会议之一，被中国计算机学会推荐国际学术会议列表认定为 A 类会议。涵盖数据库系统、数据管理、大数据处理、数据挖掘等各个研究领域，是展现数据库前沿科研成果以及探讨数据库未来发展方向的盛会。</p> 
  <p><br> 640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1</p> 
  <p>肖仰华：大家好，非常高兴能在这里与大家分享我们的论文。</p> 
  <p><br> 640?wx_fmt=png&amp;wxfrom=5&amp;wx_lazy=1</p> 
  <p>问答系统（QA）已经成为人类访问十亿级知识图谱的流行方式，它回答的是自然语言问题。 QA系统最有名的故事之一就是IBM WATSON在2011年参加了Jeopardy竞赛，打败了所有人类竞争对手，获得了100万美元的奖励。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p><br> QA的研究非常重要。首先，从应用角度来看，QA系统降低了人机交互的门槛， 非常适合成为互联网的新入口。作为聊天机器人的重要组件，吸引了来自工业界的大量关注。</p> 
  <p>从人工智能角度来看，QA是评估机器智能的一个重要任务，也就是图灵测试。同时，QA还是许多AI技术的重要测试平台，比如机器学习，自然语言处理，机器认知等等</p> 
  <p>&nbsp;</p> 
  <p>640?wx_fmt=png</p> 
  <p><br> 现在我们来谈谈知识库。近年来，我们目睹了知识库的发展，越来越多的大规模知识库涌现出来，如Google Knowledge graph，Yago和Freebase等。这些知识库具有体量大，质量高的特点。</p> 
  <p>一个知识库包含了大量的结构化数据。右图给出了一个关于Obama的知识图谱示例。知识库中的每一个三元组代表一个知识或某个事实。 例如，一个三元组（d，人口，390k）表示檀香山的人口为390k。</p> 
  <p>&nbsp;</p> 
  <p>640?wx_fmt=png</p> 
  <p><br> KBQA指的是以知识库作为答案来源的问答系统。</p> 
  <p>那么它是如何工作的呢？关键在于将自然语言问题转换为知识库上的结构化查询。例如，要回答“有多少人住在檀香山？”这个问题，我们需要将其转移到SPARQL或者SQL查询。 这里的关键问题是属性推断。</p> 
  <p>640?wx_fmt=png</p> 
  <p><br> 关于属性推断，我们面临两个挑战。</p> 
  <p>第一个挑战是问题表示。对于任意一个QA系统，我们需要一个具有代表性的问题表示来帮助识别具有相同语义的问题，同时区分不同意图的问题。</p> 
  <p>第二个挑战是语义匹配，如何将问题表示映射到知识库中的结构化查询？</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p><br> 然而，之前的解决方案并不能解决上述提出的挑战。</p> 
  <p>我们研究了两个主流的解决方案。</p> 
  <p>第一个是基于模板/规则的方法。这个方法用模板表示句子，语义解析往往通过人工标记来实现。这种方法的优点是它的结果是用户可控的，这使得它更适用于工业用途。缺点是严重依赖人工，成本太高，昂贵的人力成本使得它无法处理多样性的问题。</p> 
  <p>另一个是基于神经网络的方法。最近这种做法很受欢迎，它们通过embedding的方式来表示一个问题，并从QA语料库中学习出它的语义解析。这种方法的优点是embedding是灵活的，所以它可以理解各种各样的问题。缺点是基于神经网络的方法通常具有较差的解释性，此外，结果是不可控的，所以他们并不适用于工业应用。</p> 
  <p>因此，我们不禁会想：能不能提出一种新的方法兼备这两种方法的优点？</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p><br> 为了做到这一点，我们用模板来表示自然语言问题。 例如，“檀香山有多少人？”的模板成为“城市里有多少人？”。因为使用了模板作为问题表示，我们的方法具有可解释性和用户可控性。</p> 
  <p>然而，我们并不是手动标记模板，而是从QA语料库中自动学习模板。 最终，我们为2,782个意图学到了2,700万个模板，这么大量的数据保证我们可以理解不同的问题。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p>这个系统体系结构如图所示。它主要包括两个过程：离线预处理部分和在线QA部分。</p> 
  <p>我们先来看看离线过程，离线过程的目标是学习出从模板到属性的映射。</p> 
  <p>再来看在线部分，当一个问题进来，系统首先将其解析和分解为一组二元事实型问题。对于每个二元事实型问题，系统使用概率推断来寻找它的值。这个推断是基于给定模板的属性分布来得到的。</p> 
  <p>&nbsp;</p> 
  <p>640?wx_fmt=png</p> 
  <p>接下来，我们对这个问题进行形式化定义。给定问题q，问答系统的目标是寻找具有最大概率的答案v（其中，v是一个简单值）。</p> 
  <p>我们提出了一个生成模型来解释如何为一个问题找到它的答案。</p> 
  <p>我们认为使用概率推断的方法来做KBQA是非常合理的。首先，一些问题的意图是模糊的。其次，大多数知识库都是不完整的。最后，QA语料库中的答案也可能是错误的。</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>640?wx_fmt=png</p> 
  <p>我们以这个问答对来说明这个生成过程。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p>从用户问题q开始，我们首先生成或者说识别出其中对应的知识库中的实体d。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p>在知道问题和实体之后，我们根据d的概念分布生成模板t。 这样，我们得到了一个模板“有多少人住在某城市？”</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p><br> 由于属性只与模板有关，所以我们推断出这个属性的模板为“population”。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p>最后，给定实体d和属性population，我们通过查找知识库来得到它的答案。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p><br> 通过这种方法，我们完成了从一个自然语言问题到生成答案的整个过程。这个过程可以建模为一个概率图模型。</p> 
  <p>基于这个生成模型，可以得到一个联合概率分布，进而用来解决给定其他变量求最大v的条件概率问题。</p> 
  <p>&nbsp;</p> 
  <p>640?wx_fmt=png</p> 
  <p>下一个问题是如何计算出联合概率分布公式中的每一种概率。</p> 
  <p>我们可以从语料库直接估计出来大部分的概率。例如实体分布的概率，模板分布的概率以及值分布的概率。</p> 
  <p>我们从雅虎问答的4200万的QA pairs中，学习出问题模板和属性的映射关系。表中展示了QA语料库中的一些例子。</p> 
  <p>&nbsp;</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p>最后我们来估计P(P|T)的值。基本思路是将P(P|T)作为参数，然后使用极大似然法来估计P(P|T)。</p> 
  <p>这里我们使用了EM算法来进行参数估计。</p> 
  <p>&nbsp;</p> 
  <p>640?wx_fmt=png</p> 
  <p>KBQA的另一个难点就是回答复杂问题。在面对复杂问题时，我们采用了分治算法。首先，系统把问题分解为一系列的二元事实型问题，然后系统依次回答每个问题。每个问题的答案都是一个概率，我们通过动态规划算法找到最优分解。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p><br> 接下来我们来看看实验部分。我们首先通过实验证明属性推断的有效性。我们从学习出的属性数量和模板数据来对比我们的方法和bootstrapping方法。结果表明，我们的KBQA方法能得到更多的属性和模板， 这意味着KBQA在属性推理中更有效。大量的模板可以确保KBQA理解不同的问题模板，同时，大量的属性可以确保KBQA理解不同的关系。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p>我们也在很多benchmarks上用到了我们的KBQA。图为QALD-5的结果。结果表明，KBQA具有最高的准确度。由于KBQA只回答二元事实型问题，因此召回率相对较低。如果我们只考虑二元事实型问答，召回率能上升到0.67。</p> 
  <p><br> 640?wx_fmt=png</p> 
  <p>即使在一个不以二元事实型问题为主的数据集中（如WEBQUESTIONS，QALD-3），KBQA也可以作为混合问答系统的一个完美组件。</p> 
  <p><br> 我们这样构建混合问题系统：一个问题过来，首先提交给我们的KBQA系统。如果KBQA系统不能回答，这意味着这个问题很可能不是二元事实型问题。然后，我们再将这个问题提交给baseline系统。</p> 
  <p><br> 结果表明，当使用了我们的KBQA系统后，baseline系统的性能都有了很明显的提高。</p> 
  <p>640?wx_fmt=png</p> 
  <p>最后，我们对本文进行总结。我们构建了一个基于知识库的问答系统KBQA。 我们的QA系统和以前的系统有两个明显区别：第一，它使用模板理解问题；第二，它从非常大的QA语料库中学习语义解析。</p> 
  <p><br> 我们认为系统还有很多可以改进的地方。 首先，目前关于QA系统的研究主要建立在开放领域的知识库上。因此，研究如何使这些系统适应不同特定领域的应用是非常重要的。 其次，我们希望可以通过常识推理来更深入的理解问题。 再者，由于知识库仍然存在数据缺陷问题，如何使用互联网作为外部知识变得非常重要。</p> 
  <p>640?wx_fmt=png</p> 
  <p>640?wx_fmt=png 获取论文和完整PPT</p> 
  <p>关注“知识工场”微信公众号，回复“20170907”获取下载链接。</p> 
  <p><br> 以上就是肖仰华教授在VLDB 2017 会议上为大家带来的全部内容。知识工场实验室后续将为大家带来更精彩的文章。请大家关注！</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 640?wx_fmt=png</p> 
  <p><br> OpenKG.CN</p> 
  <p><br> 中文开放知识图谱（简称OpenKG.CN）旨在促进中文知识图谱数据的开放与互联，促进知识图谱和语义技术的普及和广泛应用。</p> 
  <p>0?wx_fmt=jpeg</p> 
  <p>&nbsp;<br> &nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
