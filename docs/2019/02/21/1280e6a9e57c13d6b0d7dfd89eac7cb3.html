<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>深度学习 吴恩达序列模型专项课程第一周编程作业实验3 — Jazz Music Generator | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="深度学习 吴恩达序列模型专项课程第一周编程作业实验3 — Jazz Music Generator" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="吴恩达深度学习专项课程的所有实验均采用iPython Notebooks实现，不熟悉的朋友可以提前使用一下Notebooks。 完整代码(中文翻译版带答案) 目录 1.实验综述 2.导入必要的包 3.问题描述 4.构建模型 5.生成音乐 6.总结&nbsp; ​ 1.实验综述 2.导入必要的包 from __future__ import print_function import IPython import sys from music21 import * import numpy as np from grammar import * from qa import * from preprocess import * from music_utils import * #music_utils.py from data_utils import * #data_utils.py from keras.models import load_model, Model from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector from keras.initializers import glorot_uniform from keras.utils import to_categorical from keras.optimizers import Adam from keras import backend as K 3.问题描述 数据集 我们将在一个爵士乐语料库上训练我们的模型. 下面先听一段训练集中音频片段: IPython.display.Audio(&#39;./data/30s_seq.mp3&#39;) #播放音频 X, Y, n_values, indices_values = load_music_utils() print(&#39;shape of X:&#39;, X.shape) print(&#39;number of training examples:&#39;, X.shape[0]) print(&#39;Tx (length of sequence):&#39;, X.shape[1]) print(&#39;total # of unique values:&#39;, n_values) print(&#39;Shape of Y:&#39;, Y.shape) 模型结构 4.构建模型 n_a = 64 reshapor = Reshape((1,78)) LSTM_cell = LSTM(n_a,return_state=True) #定义LSTM单元 有n_a个隐藏单元 densor = Dense(n_values,activation=&#39;softmax&#39;)#定义输出层 n_values个单元 使用softmax多分类 # GRADED FUNCTION: djmodel def djmodel(Tx, n_a, n_values): &quot;&quot;&quot; 实现模型 Arguments: Tx -- 一个训练样本/序列的长度，需要的时间步骤 n_a -- LSTM单元中隐藏单元的数量 n_values -- 输出层的单元数，不同音符/音乐值的数量 Returns: model -- Keras模型 &quot;&quot;&quot; # 定义输入的placeholder 传入一个训练样本/序列的维度 X(?,Tx=30,n_values=78) X = Input(shape=(Tx, n_values)) # 定义LSTM的初始隐藏状态和单元状态 a0 = Input(shape=(n_a,), name=&#39;a0&#39;) c0 = Input(shape=(n_a,), name=&#39;c0&#39;) a = a0 c = c0 # Step 1: 创建存储预测输出的列表 outputs = [] # Step 2: 对?个样本在每个时间步骤上进行迭代 for t in range(Tx): # Step 2.A: 从X中选择第t个时间步骤的输入tensor x = Lambda(lambda X: X[:,t,:])(X) #(?,78) # Step 2.B: 对x进行转型 x = reshapor(x) #(?,78) -&gt; (?,1,78) # Step 2.C: 把当前时间步骤的x输入到LSTM单元 a, _, c = LSTM_cell(x,initial_state=[a,c]) # Step 2.D: 把当前时间步骤产生的隐藏状态a 通过一个输出层(softmax)得到预测输出 out = densor(a) # Step 2.E: 把out添加到 &quot;outputs&quot;中 outputs.append(out) # Step 3: 创建模型实例 model = Model(inputs=[X,a0,c0],outputs=outputs) return model #预处理后每个训练样本/序列都是等长的 都有需要30个时间步骤 #便于同时对多个样本进行向量化处理 #n_a LSTM单元中隐藏单元的数量 #n_values 输出层单元数 不同的音乐值/音符(序列的基本组成单元)的个数 #第一步：创建模型 model = djmodel(Tx=30,n_a=64,n_values=78) #第二步： 编译模型 #选择一个优化算法 Adam #可以使用默认参数 也可以自己设置 采用学习率衰减decay为衰减率 opt = Adam(lr=0.01,beta_1=0.9,beta_2=0.999,decay=0.01) #多分类使用 categorical_crossentropy 损失 指标采用accuracy model.compile(optimizer=opt,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;]) #初始化隐藏状态和单元状态为0 m = 60 #所有训练样本数 60 a0 = np.zeros((m,n_a)) c0 = np.zeros((m,n_a)) #第三步 训练模型 model.fit([X,a0,c0],list(Y),epochs=100,batch_size=20) #默认batch_size维训练集的大小 此时采用batch GD。 #可以设置batch_size的大小 采用 mini-batch GD 5.生成音乐 我们现在已经训练完了模型，该模型已经学习了jazz乐的模式。现在让我们用这个模型来生成新的音乐。 预测和采样 # GRADED FUNCTION: music_inference_model def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100): &quot;&quot;&quot; 使用model()中训练好的 &quot;LSTM_cell&quot; 和 &quot;densor&quot; 生成一系列值. Arguments: LSTM_cell -- model()中训练好的&quot;LSTM_cell&quot; , Keras 层对象 densor -- model()中训练好的&quot;densor&quot; , Keras 层对象 n_values -- 整数 所有不同的音乐值数 n_a -- LSTM隐藏单元数 Ty -- 整数 用于生成的时间步骤 Returns: inference_model -- Keras 模型实例 &quot;&quot;&quot; # 定义模型的输入 x0 = Input(shape=(1, n_values)) # 初始化decoder LSTM的隐藏状态 a0 = Input(shape=(n_a,), name=&#39;a0&#39;) c0 = Input(shape=(n_a,), name=&#39;c0&#39;) a = a0 c = c0 x = x0 # Step 1: 创建一个空的 &quot;outputs&quot; 列表，存储预测值 outputs = [] # Step 2: 遍历 Ty个时间步骤 ，每个时间步骤生成一个值 for t in range(Ty): # Step 2.A: 执行一步 LSTM_cell a, _, c = LSTM_cell(x,initial_state=[a,c]) # Step 2.B: 对 LSTM_cell输出的隐藏状态a 经过Dense 得到当前时间步骤上的输出 out = densor(a) # Step 2.C: 将预测结果out添加到outputs列表中. out.shape = (None, 78) outputs.append(out) # Step 2.D: 根据 &quot;out&quot;选择 下一时间步骤LSTM的输入, one-hot表示形式 x = Lambda(one_hot)(out) # Step 3: 创建模型实例 inference_model = Model(inputs = [x0,a0,c0],outputs=outputs) return inference_model 运行下列代码定义inference模型。这个模型被硬编码生成50(可以设置)个值(音乐值) inference_model = music_inference_model(LSTM_cell,densor,n_values=78,n_a=64,Ty=50) 最后需要初始化x和LSTM状态变量a，c为0向量。 x_initializer = np.zeros((1, 1, 78)) a_initializer = np.zeros((1, n_a)) c_initializer = np.zeros((1, n_a)) # GRADED FUNCTION: predict_and_sample def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, c_initializer = c_initializer): &quot;&quot;&quot; Predicts the next value of values using the inference model. Arguments: inference_model -- Keras model instance for inference time x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel Returns: results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated &quot;&quot;&quot; # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer. pred = inference_model.predict([x_initializer,a_initializer,c_initializer]) # Step 2: Convert &quot;pred&quot; into an np.array() of indices with the maximum probabilities indices = np.argmax(np.array(pred),axis=-1) # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, ) results = to_categorical(indices,num_classes=x_initializer.shape[-1]) ### END CODE HERE ### return results, indices 生成音乐 out_stream = generate_music(inference_model) IPython.display.Audio(&#39;./data/30s_trained_model.mp3&#39;) 6.总结&nbsp; &nbsp; &nbsp; &nbsp;" />
<meta property="og:description" content="吴恩达深度学习专项课程的所有实验均采用iPython Notebooks实现，不熟悉的朋友可以提前使用一下Notebooks。 完整代码(中文翻译版带答案) 目录 1.实验综述 2.导入必要的包 3.问题描述 4.构建模型 5.生成音乐 6.总结&nbsp; ​ 1.实验综述 2.导入必要的包 from __future__ import print_function import IPython import sys from music21 import * import numpy as np from grammar import * from qa import * from preprocess import * from music_utils import * #music_utils.py from data_utils import * #data_utils.py from keras.models import load_model, Model from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector from keras.initializers import glorot_uniform from keras.utils import to_categorical from keras.optimizers import Adam from keras import backend as K 3.问题描述 数据集 我们将在一个爵士乐语料库上训练我们的模型. 下面先听一段训练集中音频片段: IPython.display.Audio(&#39;./data/30s_seq.mp3&#39;) #播放音频 X, Y, n_values, indices_values = load_music_utils() print(&#39;shape of X:&#39;, X.shape) print(&#39;number of training examples:&#39;, X.shape[0]) print(&#39;Tx (length of sequence):&#39;, X.shape[1]) print(&#39;total # of unique values:&#39;, n_values) print(&#39;Shape of Y:&#39;, Y.shape) 模型结构 4.构建模型 n_a = 64 reshapor = Reshape((1,78)) LSTM_cell = LSTM(n_a,return_state=True) #定义LSTM单元 有n_a个隐藏单元 densor = Dense(n_values,activation=&#39;softmax&#39;)#定义输出层 n_values个单元 使用softmax多分类 # GRADED FUNCTION: djmodel def djmodel(Tx, n_a, n_values): &quot;&quot;&quot; 实现模型 Arguments: Tx -- 一个训练样本/序列的长度，需要的时间步骤 n_a -- LSTM单元中隐藏单元的数量 n_values -- 输出层的单元数，不同音符/音乐值的数量 Returns: model -- Keras模型 &quot;&quot;&quot; # 定义输入的placeholder 传入一个训练样本/序列的维度 X(?,Tx=30,n_values=78) X = Input(shape=(Tx, n_values)) # 定义LSTM的初始隐藏状态和单元状态 a0 = Input(shape=(n_a,), name=&#39;a0&#39;) c0 = Input(shape=(n_a,), name=&#39;c0&#39;) a = a0 c = c0 # Step 1: 创建存储预测输出的列表 outputs = [] # Step 2: 对?个样本在每个时间步骤上进行迭代 for t in range(Tx): # Step 2.A: 从X中选择第t个时间步骤的输入tensor x = Lambda(lambda X: X[:,t,:])(X) #(?,78) # Step 2.B: 对x进行转型 x = reshapor(x) #(?,78) -&gt; (?,1,78) # Step 2.C: 把当前时间步骤的x输入到LSTM单元 a, _, c = LSTM_cell(x,initial_state=[a,c]) # Step 2.D: 把当前时间步骤产生的隐藏状态a 通过一个输出层(softmax)得到预测输出 out = densor(a) # Step 2.E: 把out添加到 &quot;outputs&quot;中 outputs.append(out) # Step 3: 创建模型实例 model = Model(inputs=[X,a0,c0],outputs=outputs) return model #预处理后每个训练样本/序列都是等长的 都有需要30个时间步骤 #便于同时对多个样本进行向量化处理 #n_a LSTM单元中隐藏单元的数量 #n_values 输出层单元数 不同的音乐值/音符(序列的基本组成单元)的个数 #第一步：创建模型 model = djmodel(Tx=30,n_a=64,n_values=78) #第二步： 编译模型 #选择一个优化算法 Adam #可以使用默认参数 也可以自己设置 采用学习率衰减decay为衰减率 opt = Adam(lr=0.01,beta_1=0.9,beta_2=0.999,decay=0.01) #多分类使用 categorical_crossentropy 损失 指标采用accuracy model.compile(optimizer=opt,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;]) #初始化隐藏状态和单元状态为0 m = 60 #所有训练样本数 60 a0 = np.zeros((m,n_a)) c0 = np.zeros((m,n_a)) #第三步 训练模型 model.fit([X,a0,c0],list(Y),epochs=100,batch_size=20) #默认batch_size维训练集的大小 此时采用batch GD。 #可以设置batch_size的大小 采用 mini-batch GD 5.生成音乐 我们现在已经训练完了模型，该模型已经学习了jazz乐的模式。现在让我们用这个模型来生成新的音乐。 预测和采样 # GRADED FUNCTION: music_inference_model def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100): &quot;&quot;&quot; 使用model()中训练好的 &quot;LSTM_cell&quot; 和 &quot;densor&quot; 生成一系列值. Arguments: LSTM_cell -- model()中训练好的&quot;LSTM_cell&quot; , Keras 层对象 densor -- model()中训练好的&quot;densor&quot; , Keras 层对象 n_values -- 整数 所有不同的音乐值数 n_a -- LSTM隐藏单元数 Ty -- 整数 用于生成的时间步骤 Returns: inference_model -- Keras 模型实例 &quot;&quot;&quot; # 定义模型的输入 x0 = Input(shape=(1, n_values)) # 初始化decoder LSTM的隐藏状态 a0 = Input(shape=(n_a,), name=&#39;a0&#39;) c0 = Input(shape=(n_a,), name=&#39;c0&#39;) a = a0 c = c0 x = x0 # Step 1: 创建一个空的 &quot;outputs&quot; 列表，存储预测值 outputs = [] # Step 2: 遍历 Ty个时间步骤 ，每个时间步骤生成一个值 for t in range(Ty): # Step 2.A: 执行一步 LSTM_cell a, _, c = LSTM_cell(x,initial_state=[a,c]) # Step 2.B: 对 LSTM_cell输出的隐藏状态a 经过Dense 得到当前时间步骤上的输出 out = densor(a) # Step 2.C: 将预测结果out添加到outputs列表中. out.shape = (None, 78) outputs.append(out) # Step 2.D: 根据 &quot;out&quot;选择 下一时间步骤LSTM的输入, one-hot表示形式 x = Lambda(one_hot)(out) # Step 3: 创建模型实例 inference_model = Model(inputs = [x0,a0,c0],outputs=outputs) return inference_model 运行下列代码定义inference模型。这个模型被硬编码生成50(可以设置)个值(音乐值) inference_model = music_inference_model(LSTM_cell,densor,n_values=78,n_a=64,Ty=50) 最后需要初始化x和LSTM状态变量a，c为0向量。 x_initializer = np.zeros((1, 1, 78)) a_initializer = np.zeros((1, n_a)) c_initializer = np.zeros((1, n_a)) # GRADED FUNCTION: predict_and_sample def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, c_initializer = c_initializer): &quot;&quot;&quot; Predicts the next value of values using the inference model. Arguments: inference_model -- Keras model instance for inference time x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel Returns: results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated &quot;&quot;&quot; # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer. pred = inference_model.predict([x_initializer,a_initializer,c_initializer]) # Step 2: Convert &quot;pred&quot; into an np.array() of indices with the maximum probabilities indices = np.argmax(np.array(pred),axis=-1) # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, ) results = to_categorical(indices,num_classes=x_initializer.shape[-1]) ### END CODE HERE ### return results, indices 生成音乐 out_stream = generate_music(inference_model) IPython.display.Audio(&#39;./data/30s_trained_model.mp3&#39;) 6.总结&nbsp; &nbsp; &nbsp; &nbsp;" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-21T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"吴恩达深度学习专项课程的所有实验均采用iPython Notebooks实现，不熟悉的朋友可以提前使用一下Notebooks。 完整代码(中文翻译版带答案) 目录 1.实验综述 2.导入必要的包 3.问题描述 4.构建模型 5.生成音乐 6.总结&nbsp; ​ 1.实验综述 2.导入必要的包 from __future__ import print_function import IPython import sys from music21 import * import numpy as np from grammar import * from qa import * from preprocess import * from music_utils import * #music_utils.py from data_utils import * #data_utils.py from keras.models import load_model, Model from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector from keras.initializers import glorot_uniform from keras.utils import to_categorical from keras.optimizers import Adam from keras import backend as K 3.问题描述 数据集 我们将在一个爵士乐语料库上训练我们的模型. 下面先听一段训练集中音频片段: IPython.display.Audio(&#39;./data/30s_seq.mp3&#39;) #播放音频 X, Y, n_values, indices_values = load_music_utils() print(&#39;shape of X:&#39;, X.shape) print(&#39;number of training examples:&#39;, X.shape[0]) print(&#39;Tx (length of sequence):&#39;, X.shape[1]) print(&#39;total # of unique values:&#39;, n_values) print(&#39;Shape of Y:&#39;, Y.shape) 模型结构 4.构建模型 n_a = 64 reshapor = Reshape((1,78)) LSTM_cell = LSTM(n_a,return_state=True) #定义LSTM单元 有n_a个隐藏单元 densor = Dense(n_values,activation=&#39;softmax&#39;)#定义输出层 n_values个单元 使用softmax多分类 # GRADED FUNCTION: djmodel def djmodel(Tx, n_a, n_values): &quot;&quot;&quot; 实现模型 Arguments: Tx -- 一个训练样本/序列的长度，需要的时间步骤 n_a -- LSTM单元中隐藏单元的数量 n_values -- 输出层的单元数，不同音符/音乐值的数量 Returns: model -- Keras模型 &quot;&quot;&quot; # 定义输入的placeholder 传入一个训练样本/序列的维度 X(?,Tx=30,n_values=78) X = Input(shape=(Tx, n_values)) # 定义LSTM的初始隐藏状态和单元状态 a0 = Input(shape=(n_a,), name=&#39;a0&#39;) c0 = Input(shape=(n_a,), name=&#39;c0&#39;) a = a0 c = c0 # Step 1: 创建存储预测输出的列表 outputs = [] # Step 2: 对?个样本在每个时间步骤上进行迭代 for t in range(Tx): # Step 2.A: 从X中选择第t个时间步骤的输入tensor x = Lambda(lambda X: X[:,t,:])(X) #(?,78) # Step 2.B: 对x进行转型 x = reshapor(x) #(?,78) -&gt; (?,1,78) # Step 2.C: 把当前时间步骤的x输入到LSTM单元 a, _, c = LSTM_cell(x,initial_state=[a,c]) # Step 2.D: 把当前时间步骤产生的隐藏状态a 通过一个输出层(softmax)得到预测输出 out = densor(a) # Step 2.E: 把out添加到 &quot;outputs&quot;中 outputs.append(out) # Step 3: 创建模型实例 model = Model(inputs=[X,a0,c0],outputs=outputs) return model #预处理后每个训练样本/序列都是等长的 都有需要30个时间步骤 #便于同时对多个样本进行向量化处理 #n_a LSTM单元中隐藏单元的数量 #n_values 输出层单元数 不同的音乐值/音符(序列的基本组成单元)的个数 #第一步：创建模型 model = djmodel(Tx=30,n_a=64,n_values=78) #第二步： 编译模型 #选择一个优化算法 Adam #可以使用默认参数 也可以自己设置 采用学习率衰减decay为衰减率 opt = Adam(lr=0.01,beta_1=0.9,beta_2=0.999,decay=0.01) #多分类使用 categorical_crossentropy 损失 指标采用accuracy model.compile(optimizer=opt,loss=&#39;categorical_crossentropy&#39;,metrics=[&#39;accuracy&#39;]) #初始化隐藏状态和单元状态为0 m = 60 #所有训练样本数 60 a0 = np.zeros((m,n_a)) c0 = np.zeros((m,n_a)) #第三步 训练模型 model.fit([X,a0,c0],list(Y),epochs=100,batch_size=20) #默认batch_size维训练集的大小 此时采用batch GD。 #可以设置batch_size的大小 采用 mini-batch GD 5.生成音乐 我们现在已经训练完了模型，该模型已经学习了jazz乐的模式。现在让我们用这个模型来生成新的音乐。 预测和采样 # GRADED FUNCTION: music_inference_model def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100): &quot;&quot;&quot; 使用model()中训练好的 &quot;LSTM_cell&quot; 和 &quot;densor&quot; 生成一系列值. Arguments: LSTM_cell -- model()中训练好的&quot;LSTM_cell&quot; , Keras 层对象 densor -- model()中训练好的&quot;densor&quot; , Keras 层对象 n_values -- 整数 所有不同的音乐值数 n_a -- LSTM隐藏单元数 Ty -- 整数 用于生成的时间步骤 Returns: inference_model -- Keras 模型实例 &quot;&quot;&quot; # 定义模型的输入 x0 = Input(shape=(1, n_values)) # 初始化decoder LSTM的隐藏状态 a0 = Input(shape=(n_a,), name=&#39;a0&#39;) c0 = Input(shape=(n_a,), name=&#39;c0&#39;) a = a0 c = c0 x = x0 # Step 1: 创建一个空的 &quot;outputs&quot; 列表，存储预测值 outputs = [] # Step 2: 遍历 Ty个时间步骤 ，每个时间步骤生成一个值 for t in range(Ty): # Step 2.A: 执行一步 LSTM_cell a, _, c = LSTM_cell(x,initial_state=[a,c]) # Step 2.B: 对 LSTM_cell输出的隐藏状态a 经过Dense 得到当前时间步骤上的输出 out = densor(a) # Step 2.C: 将预测结果out添加到outputs列表中. out.shape = (None, 78) outputs.append(out) # Step 2.D: 根据 &quot;out&quot;选择 下一时间步骤LSTM的输入, one-hot表示形式 x = Lambda(one_hot)(out) # Step 3: 创建模型实例 inference_model = Model(inputs = [x0,a0,c0],outputs=outputs) return inference_model 运行下列代码定义inference模型。这个模型被硬编码生成50(可以设置)个值(音乐值) inference_model = music_inference_model(LSTM_cell,densor,n_values=78,n_a=64,Ty=50) 最后需要初始化x和LSTM状态变量a，c为0向量。 x_initializer = np.zeros((1, 1, 78)) a_initializer = np.zeros((1, n_a)) c_initializer = np.zeros((1, n_a)) # GRADED FUNCTION: predict_and_sample def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, c_initializer = c_initializer): &quot;&quot;&quot; Predicts the next value of values using the inference model. Arguments: inference_model -- Keras model instance for inference time x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel Returns: results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated &quot;&quot;&quot; # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer. pred = inference_model.predict([x_initializer,a_initializer,c_initializer]) # Step 2: Convert &quot;pred&quot; into an np.array() of indices with the maximum probabilities indices = np.argmax(np.array(pred),axis=-1) # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, ) results = to_categorical(indices,num_classes=x_initializer.shape[-1]) ### END CODE HERE ### return results, indices 生成音乐 out_stream = generate_music(inference_model) IPython.display.Audio(&#39;./data/30s_trained_model.mp3&#39;) 6.总结&nbsp; &nbsp; &nbsp; &nbsp;","@type":"BlogPosting","url":"/2019/02/21/1280e6a9e57c13d6b0d7dfd89eac7cb3.html","headline":"深度学习 吴恩达序列模型专项课程第一周编程作业实验3 — Jazz Music Generator","dateModified":"2019-02-21T00:00:00+08:00","datePublished":"2019-02-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/02/21/1280e6a9e57c13d6b0d7dfd89eac7cb3.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>深度学习 | 吴恩达序列模型专项课程第一周编程作业实验3 --- Jazz Music Generator</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p style="text-indent:50px;">吴恩达深度学习专项课程的所有实验均采用iPython Notebooks实现，不熟悉的朋友可以提前使用一下Notebooks。</p> 
  <p style="text-indent:50px;"><a href="https://pan.baidu.com/s/1WAyQO2mykyTZQMkGtTKV_w" rel="nofollow">完整代码(中文翻译版带答案)</a></p> 
  <p id="main-toc"><strong>目录</strong></p> 
  <p id="1.%E5%AE%9E%E9%AA%8C%E7%BB%BC%E8%BF%B0-toc" style="margin-left:40px;"><a href="#1.%E5%AE%9E%E9%AA%8C%E7%BB%BC%E8%BF%B0" rel="nofollow">1.实验综述</a></p> 
  <p id="2.%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%8C%85-toc" style="margin-left:40px;"><a href="#2.%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%8C%85" rel="nofollow">2.导入必要的包</a></p> 
  <p id="3.%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0-toc" style="margin-left:40px;"><a href="#3.%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0" rel="nofollow">3.问题描述</a></p> 
  <p id="4.%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B-toc" style="margin-left:40px;"><a href="#4.%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B" rel="nofollow">4.构建模型</a></p> 
  <p id="5.%E7%94%9F%E6%88%90%E9%9F%B3%E4%B9%90-toc" style="margin-left:40px;"><a href="#5.%E7%94%9F%E6%88%90%E9%9F%B3%E4%B9%90" rel="nofollow">5.生成音乐</a></p> 
  <p id="6.%E6%80%BB%E7%BB%93%C2%A0-toc" style="margin-left:40px;"><a href="#6.%E6%80%BB%E7%BB%93%C2%A0" rel="nofollow">6.总结&nbsp;</a></p> 
  <p id="%E2%80%8B-toc" style="margin-left:40px;"><a href="#%E2%80%8B" rel="nofollow">​</a></p> 
  <h2 id="1.%E5%AE%9E%E9%AA%8C%E7%BB%BC%E8%BF%B0" style="text-indent:0;">1.实验综述</h2> 
  <p style="text-align:center;"><img alt="" class="has" height="260" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200406338.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="826"></p> 
  <h2 id="2.%E5%AF%BC%E5%85%A5%E5%BF%85%E8%A6%81%E7%9A%84%E5%8C%85">2.导入必要的包</h2> 
  <pre class="has">
<code class="language-python">from __future__ import print_function
import IPython
import sys
from music21 import *
import numpy as np
from grammar import *
from qa import *
from preprocess import * 
from music_utils import * #music_utils.py
from data_utils import *  #data_utils.py
from keras.models import load_model, Model
from keras.layers import Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector
from keras.initializers import glorot_uniform
from keras.utils import to_categorical
from keras.optimizers import Adam
from keras import backend as K</code></pre> 
  <h2 id="3.%E9%97%AE%E9%A2%98%E6%8F%8F%E8%BF%B0">3.问题描述</h2> 
  <p style="text-align:center;"><img alt="" class="has" height="550" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200453801.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="819"></p> 
  <ul>
   <li>数据集</li> 
  </ul>
  <p style="text-indent:50px;">我们将在一个爵士乐语料库上训练我们的模型. 下面先听一段训练集中音频片段:</p> 
  <pre class="has">
<code class="language-python">IPython.display.Audio('./data/30s_seq.mp3') #播放音频</code></pre> 
  <p style="text-align:center;"><img alt="" class="has" height="260" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200540148.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="884"></p> 
  <pre class="has">
<code class="language-python">X, Y, n_values, indices_values = load_music_utils()
print('shape of X:', X.shape)
print('number of training examples:', X.shape[0])
print('Tx (length of sequence):', X.shape[1])
print('total # of unique values:', n_values)
print('Shape of Y:', Y.shape)</code></pre> 
  <p style="text-align:center;"><img alt="" class="has" height="550" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200613586.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="850"></p> 
  <ul>
   <li>模型结构</li> 
  </ul>
  <p style="text-align:center;"><img alt="" class="has" height="800" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200636232.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="832"></p> 
  <h2 id="4.%E6%9E%84%E5%BB%BA%E6%A8%A1%E5%9E%8B">4.构建模型</h2> 
  <p style="text-align:center;"><img alt="" class="has" height="70" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200707625.png" width="873"></p> 
  <pre class="has">
<code class="language-python">n_a = 64</code></pre> 
  <p style="text-align:center;"><img alt="" class="has" height="460" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200736680.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="823"></p> 
  <pre class="has">
<code class="language-python">reshapor = Reshape((1,78))
LSTM_cell = LSTM(n_a,return_state=True) #定义LSTM单元 有n_a个隐藏单元
densor = Dense(n_values,activation='softmax')#定义输出层 n_values个单元 使用softmax多分类</code></pre> 
  <p style="text-align:center;"><img alt="" class="has" height="660" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200807454.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="842"></p> 
  <pre class="has">
<code class="language-python"># GRADED FUNCTION: djmodel

def djmodel(Tx, n_a, n_values):
    """
    实现模型
    
    Arguments:
    Tx -- 一个训练样本/序列的长度，需要的时间步骤
    n_a -- LSTM单元中隐藏单元的数量
    n_values -- 输出层的单元数，不同音符/音乐值的数量
    
    Returns:
    model -- Keras模型
    """
    
    # 定义输入的placeholder 传入一个训练样本/序列的维度  X(?,Tx=30,n_values=78)
    X = Input(shape=(Tx, n_values))
    
    # 定义LSTM的初始隐藏状态和单元状态 
    a0 = Input(shape=(n_a,), name='a0') 
    c0 = Input(shape=(n_a,), name='c0') 
    a = a0 
    c = c0 
    

    # Step 1: 创建存储预测输出的列表
    outputs = []
    
    # Step 2: 对?个样本在每个时间步骤上进行迭代
    for t in range(Tx):
        
        # Step 2.A: 从X中选择第t个时间步骤的输入tensor
        x = Lambda(lambda X: X[:,t,:])(X) #(?,78)
        # Step 2.B: 对x进行转型
        x = reshapor(x)  #(?,78) -&gt; (?,1,78)
        # Step 2.C: 把当前时间步骤的x输入到LSTM单元
        a, _, c = LSTM_cell(x,initial_state=[a,c])
        # Step 2.D: 把当前时间步骤产生的隐藏状态a 通过一个输出层(softmax)得到预测输出
        out = densor(a)
        # Step 2.E: 把out添加到 "outputs"中
        outputs.append(out)
        
    # Step 3: 创建模型实例
    model = Model(inputs=[X,a0,c0],outputs=outputs)
    
    return model</code></pre> 
  <pre class="has">
<code class="language-python">#预处理后每个训练样本/序列都是等长的 都有需要30个时间步骤
#便于同时对多个样本进行向量化处理
#n_a LSTM单元中隐藏单元的数量
#n_values 输出层单元数  不同的音乐值/音符(序列的基本组成单元)的个数

#第一步：创建模型
model = djmodel(Tx=30,n_a=64,n_values=78) </code></pre> 
  <pre class="has">
<code class="language-python">#第二步： 编译模型
#选择一个优化算法 Adam
#可以使用默认参数  也可以自己设置  采用学习率衰减decay为衰减率
opt = Adam(lr=0.01,beta_1=0.9,beta_2=0.999,decay=0.01)
#多分类使用 categorical_crossentropy 损失  指标采用accuracy
model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])</code></pre> 
  <pre class="has">
<code class="language-python">#初始化隐藏状态和单元状态为0   
m = 60 #所有训练样本数 60
a0 = np.zeros((m,n_a)) 
c0 = np.zeros((m,n_a))</code></pre> 
  <p style="text-align:center;"><img alt="" class="has" height="100" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200922751.png" width="765"></p> 
  <pre class="has">
<code class="language-python">#第三步 训练模型
model.fit([X,a0,c0],list(Y),epochs=100,batch_size=20) #默认batch_size维训练集的大小 此时采用batch GD。
#可以设置batch_size的大小  采用 mini-batch GD</code></pre> 
  <p style="text-align:center;"><img alt="" class="has" height="450" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221200956535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="849"></p> 
  <h2 id="5.%E7%94%9F%E6%88%90%E9%9F%B3%E4%B9%90">5.生成音乐</h2> 
  <p style="text-indent:50px;">我们现在已经训练完了模型，该模型已经学习了jazz乐的模式。现在让我们用这个模型来生成新的音乐。</p> 
  <ul>
   <li style="text-indent:0;">预测和采样</li> 
  </ul>
  <p style="text-align:center;"><img alt="" class="has" height="700" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221201038174.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="852"></p> 
  <p style="text-align:center;"><img alt="" class="has" height="420" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221201102341.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="805"></p> 
  <pre class="has">
<code class="language-python"># GRADED FUNCTION: music_inference_model

def music_inference_model(LSTM_cell, densor, n_values = 78, n_a = 64, Ty = 100):
    """
    使用model()中训练好的 "LSTM_cell" 和 "densor"  生成一系列值.
    
    Arguments:
    LSTM_cell -- model()中训练好的"LSTM_cell" , Keras 层对象
    densor --  model()中训练好的"densor" , Keras 层对象
    n_values -- 整数 所有不同的音乐值数
    n_a -- LSTM隐藏单元数
    Ty -- 整数 用于生成的时间步骤
    
    Returns:
    inference_model -- Keras 模型实例
    """
    
    # 定义模型的输入 
    x0 = Input(shape=(1, n_values)) 
    
    # 初始化decoder LSTM的隐藏状态
    a0 = Input(shape=(n_a,), name='a0')
    c0 = Input(shape=(n_a,), name='c0')
    a = a0
    c = c0
    x = x0


    # Step 1: 创建一个空的 "outputs" 列表，存储预测值
    outputs = []
    
    # Step 2: 遍历 Ty个时间步骤 ，每个时间步骤生成一个值
    for t in range(Ty):
        
        # Step 2.A: 执行一步 LSTM_cell 
        a, _, c = LSTM_cell(x,initial_state=[a,c])
        
        # Step 2.B: 对 LSTM_cell输出的隐藏状态a 经过Dense 得到当前时间步骤上的输出
        out = densor(a)

        # Step 2.C: 将预测结果out添加到outputs列表中. out.shape = (None, 78)
        outputs.append(out)
        
        # Step 2.D: 根据 "out"选择 下一时间步骤LSTM的输入, one-hot表示形式
        x = Lambda(one_hot)(out)
        
    # Step 3: 创建模型实例
    inference_model = Model(inputs = [x0,a0,c0],outputs=outputs)
    

    
    return inference_model</code></pre> 
  <p style="text-indent:50px;">运行下列代码定义inference模型。这个模型被硬编码生成50(可以设置)个值(音乐值)</p> 
  <pre class="has">
<code class="language-python">inference_model = music_inference_model(LSTM_cell,densor,n_values=78,n_a=64,Ty=50)</code></pre> 
  <p style="text-indent:50px;">最后需要初始化x和LSTM状态变量a，c为0向量。</p> 
  <pre class="has">
<code class="language-python">x_initializer = np.zeros((1, 1, 78))
a_initializer = np.zeros((1, n_a))
c_initializer = np.zeros((1, n_a))</code></pre> 
  <p style="text-align:center;"><img alt="" class="has" height="180" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221201207834.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="840"></p> 
  <pre class="has">
<code class="language-python"># GRADED FUNCTION: predict_and_sample

def predict_and_sample(inference_model, x_initializer = x_initializer, a_initializer = a_initializer, 
                       c_initializer = c_initializer):
    """
    Predicts the next value of values using the inference model.
    
    Arguments:
    inference_model -- Keras model instance for inference time
    x_initializer -- numpy array of shape (1, 1, 78), one-hot vector initializing the values generation
    a_initializer -- numpy array of shape (1, n_a), initializing the hidden state of the LSTM_cell
    c_initializer -- numpy array of shape (1, n_a), initializing the cell state of the LSTM_cel
    
    Returns:
    results -- numpy-array of shape (Ty, 78), matrix of one-hot vectors representing the values generated
    indices -- numpy-array of shape (Ty, 1), matrix of indices representing the values generated
    """
    
    # Step 1: Use your inference model to predict an output sequence given x_initializer, a_initializer and c_initializer.
    pred = inference_model.predict([x_initializer,a_initializer,c_initializer])
    # Step 2: Convert "pred" into an np.array() of indices with the maximum probabilities
    indices = np.argmax(np.array(pred),axis=-1)
    # Step 3: Convert indices to one-hot vectors, the shape of the results should be (1, )
    results = to_categorical(indices,num_classes=x_initializer.shape[-1])
    ### END CODE HERE ###
    
    return results, indices</code></pre> 
  <ul>
   <li>生成音乐</li> 
  </ul>
  <p style="text-align:center;"><img alt="" class="has" height="320" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221201245553.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="826"></p> 
  <pre class="has">
<code class="language-python">out_stream = generate_music(inference_model)</code></pre> 
  <p style="text-align:center;"><img alt="" class="has" height="160" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221201321935.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="803"></p> 
  <pre class="has">
<code class="language-python">IPython.display.Audio('./data/30s_trained_model.mp3')</code></pre> 
  <h2 id="6.%E6%80%BB%E7%BB%93%C2%A0">6.总结&nbsp;</h2> 
  <h2 id="%E2%80%8B"><img alt="" class="has" height="214" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190221201354325.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NkdV9oYW8=,size_16,color_FFFFFF,t_70" width="1152"></h2> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
