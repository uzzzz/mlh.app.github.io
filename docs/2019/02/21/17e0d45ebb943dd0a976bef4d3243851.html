<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>ML–决策树与随机森林 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="ML–决策树与随机森林" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="ML–决策树与随机森林 在生活中，我们经常遇到一些事情需要作出决策来应对。说到决策，自然想到决策树算法，而说到决策树算法，又自然会想到随机森林 主要涉及的知识点有： 决策树的基本原理和构造 决策树的优势和不足 随机森林的基本原理和构造 随机森林的优势和不足 实例演示：相亲事件 一.决策树 决策树是一种在分类与回归中都有非常广泛应用的算法，它的原理是通过对一系列问题进行if/else的推导，最终实现决策 1.决策树的基本原理 举个例子：假设出题者心理想的是Google,百度，Facebook，阿里，四个公司中的一个，则提问决策树：最终的4个节点，也就是4个公司的名字，被称为决策树的树叶。例子中的这棵决策树只有4片树叶，所以通过手动的方式就可以进行建模。但是如果样本的特征特别多，就不得不使用机器学习的办法来进行建模了 2.决策树的构建 下面我们先载入酒的数据集，然后将它做成训练集和测试集，输入代码如下： # 导入numpy import numpy as np # 导入画图工具 import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap # 导入tree模型和数据集加载工具 from sklearn import tree,datasets # 导入数据集拆分工具 from sklearn.model_selection import train_test_split wine=datasets.load_wine() # 只选取数据集的前两个特征 X=wine.data[:,:2] y=wine.target # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y) 现在完成了数据集的准备，开始用决策树分类器进行分类 注意 ：为了便于图形进行演示，我们仍然只选取了数据集中样本的前两个特征 # 设定决策树分类器最大深度为1 clf=tree.DecisionTreeClassifier(max_depth=1) # 拟合训练数据集 clf.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=1, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) [结果分析] 把分类器的参数返回，这些参数中，我们先关注其中之一，就是max_depth参数。这个参数指的是决策树的深度，也就是所问问题的数量，问题数量越多，就代表决策树的深度 现在我们看看分类器的表现如何，我们把图形画出来： # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=1)&quot;) plt.show() [结果分析] 很显然，最大深度等于1时分类器的表现肯定不会太好，分类器只分了两类。我们需要加大深度试试看 # 设定决策树最大深度为3 clf2=tree.DecisionTreeClassifier(max_depth=3) # 重新拟合数据 clf2.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf2.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=3)&quot;) plt.show() [结果分析] 当决策树最大深度设为3的时候，分类器能够进行3个分类的识别，而且大部分数据点都进入了正确的分类，当然还有一小部分数据点的分类是错误的 接下来进一步调整max_depth的值 # 设定决策树最大深度为5 clf3=tree.DecisionTreeClassifier(max_depth=5) # 重新拟合数据 clf3.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=5, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf3.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=5)&quot;) plt.show() 我们可能会感到好奇，在这个过程中，决策树在每一层当中都做了哪些事情呢？我们可以用一个名叫graphviz的库来展示一下这个过程。首先需要安装这个库： pip install graphviz 注意 graphviz只是帮助我们演示决策树的工作过程，对于读者来说，安装他并不是必须的 # 导入graphviz工具 import graphviz # 导入决策树中输出graphviz的接口 from sklearn.tree import export_graphviz # 选择最大深度为3的分类模型 export_graphviz(clf2,out_file=&quot;wine.dot&quot;,class_names=wine.target_names,feature_names=wine.feature_names[:2],impurity=False,filled=True) # 打开一个dot文件 with open(&quot;wine.dot&quot;) as f: dot_graph=f.read() # 显示dot文件中的图形 graphviz.Source(dot_graph) 注意 为了控制图片不要太大，我们选择用max_depth=3的分类器来绘制图形，这样可以方便观看 3.决策树的优势和不足 相比其他算法，决策树有一个非常大的优势，就是可以很容易地将模型进行可视化，就像我们在上图中所做的一样。另外，由于决策树算法对每个样本特征进行单独处理，因此并不需要对数据进行转换。这样一来，如果使用决策树算法的话，我们几乎不需要对数据进行预处理。这也是决策树算法的一个优点 当然，决策树算法也有它的不足之处—即便我们在建模的时候可以使用类似max_depth或是max_leaf_nodes等参数来对决决策树进行预剪枝处理，但它还是不可避免会出现多拟合的问题，也就让模型的泛化性能大打折扣了 为了避免过拟合的问题出现，可以使用集合学习的方法，也就是我们下面要介绍的—随机森林算法 二.随机森林 常言道，不要为了一棵树放弃一片森林。这句话在机器学习算法方面也是非常正确的 1.随机森林的基本概念 随机森林有的时候也被称为是随机决策森林，是一种集合学习方法，既可以用于分类，也可以用于回归。而所谓集合学习算法，其实就是把多个机器学习算法综合在一起，制造出一个更加大模型的意思。这也就很好地解释了为什么这种算法称为随机森林 在机器学习的领域，其实有很多中集合算法，目前应用比较广泛的就包括随机森林(Random Forests)和梯度上升决策树(Gradient Boosted Decision Trees,GBDT) 前面我们提到，决策树算法很容易出现过拟合的现象。那么为什么随机森林可以解决这个问题呢？因为随机森林是把不同的几棵决策树打包到一起，每棵树的参数都不相同，然后我们把每棵树预测的结果取平均值，这样即可以保留决策树们的工作成效，又可以降低过拟合的风险 2.随机森林的构建 这次我们继续用在决策树中来展示酒的数据集，输入代码如下： # 导入随机森林模型 from sklearn.ensemble import RandomForestClassifier # 载人红酒数据集 wine=datasets.load_wine() # 选择数据集前两个特征 X=wine.data[:,:2] y=wine.target # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y) # 设定随机森林中有6颗树 forest=RandomForestClassifier(n_estimators=6,random_state=3) # 使用模型拟合数据 forest.fit(X_train,y_train) RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=6, n_jobs=None, oob_score=False, random_state=3, verbose=0, warm_start=False) [结果分析] 可以看到，随机森林向我们返回了包含其自身全部参数的信息，让我们重点看一下其中几个必要重要的参数 首先是bootstrap参数，代表的是bootstrap sample，也就是&quot;有放回抽样&quot;的意思，指每次从样本空间中可以重复抽取同一个样本(因为样本在第一次被抽取之后又被放回去了)，形象一点来说，如原始样本是[‘苹果’,‘西瓜’,‘香蕉’,‘桃子’]，那么经过bootstrap sample重构的样本就可能是[‘西瓜’,‘西瓜’,‘香蕉’,‘桃子’]，还有可能是[‘苹果’,‘西瓜’,‘桃子’,‘桃子’]。Bootstrap sample生成的数据集和原始数据集在数据量上是完全一样的，D但由于进行了重复采样，因此其中有一些数据点会丢失 看到这里，可能会问为什么要生成bootstrap sample数据集。这是因为通过重新生成数据集，可以让随机森林中的每一棵决策树在构建的时候，会彼此之间有些差异。再加上每棵树的节点都会去选择不同的样本特征，经过这两步动作之后，可以完全肯定随机森林中的每棵树都不一样，这也符合我们使用随机森林的初衷 另外还有一个要强调的参数，是n_estimators，这个参数控制的是随机森林中决策树的数量。在随机森林构建完成之后，每棵决策树都会单独进行预测。如果是用来进行回归分析的话，随机森林会把所有决策树预测的值取平均数；如果是用来进行分类的话，在森林内部会进行&quot;投票&quot;，每棵树预测出数据类别的概率，比如其中一棵树说，“这瓶酒80%数据class_1”，另外一棵树说，“这瓶酒60%属于class_2”，随机森林会把这些概率取平均值，然后把样本放入概率最高的分类当中 下面我们用图像直观地看一下随机森林分类的表现，输入代码如下： # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=forest.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=5)&quot;) plt.show() 3.随机森林的优势和不足 从优势的角度来说，随机森林集成了决策树的所有优点，而且能够弥补决策树的不足。但也不是说决策树算法就被彻底抛弃了。从便于展示决策过程的角度来说，决策树依旧表现强悍。尤其是随机森林中每棵决策树的层级要比单独的决策树更深，所以如果需要向非专业人士展示模型工作过程的话，还是需要用到决策树的 还有，随机森林算法支持并行处理。对于超大数据集来说，随机森林会比较耗时，不过我们可以用多进程并行处理的方式来解决这个问题。实现方式是调节随机森林的n_jobs参数，记得把n_jobs参数数值设为和CPU内核数一致。如果你搞不清楚自己的CPU到底就多少内核，可以设置n_jobs=-1，这样随机森林会使用CPU的全部内核，速度就会极大提升了 需要注意的是，因为随机森林生成每棵决策树的方法是随机的，那么不同的random_state参数会导致模型完全不同，所以如果不希望建模的结果太过于不稳定，一定要固化random_state这个参数的数值 缺点是，对于超高维数据集，稀疏数据集等来说，随机森林就有点捉襟见肘了，在这种情况下，线性模型要比随机森林的表现更好一些 三.随机森林实例—相亲事件 小花的同事给她介绍了一个对象Mr-L，现在Mr-L现年37岁，在某省机关做文员工作。但是小花的择偶标准是需要对方月薪在5万以上(只是为了引入后面的内容)，但是又不好直接问Mr-L，所以拿不定主意，这时我们用决策树和随机森林 1.数据集的准备 在网站下载数据集：成年人数据集 下载好的数据集是.data格式的文件，不过不用担心，它其实就是一个csv文件，我们把它重命名为adult.csv 下面我们载人这个数据集，输入代码如下： # 导入pandas库 import pandas as pd # 用pd打开csv文件 data=pd.read_csv(&#39;adult.csv&#39;,header=None,index_col=False, names=[&#39;年龄&#39;,&#39;单位性质&#39;,&#39;权重&#39;,&#39;学历&#39;,&#39;受教育时长&#39;, &#39;婚姻状况&#39;,&#39;职业&#39;,&#39;家庭情况&#39;,&#39;种族&#39;,&#39;性别&#39;, &#39;资产所得&#39;,&#39;资产损失&#39;,&#39;周工作时长&#39;,&#39;原籍&#39;, &#39;收入&#39; ] ) #为了方便展示，我们选取其中一部分数据 data_list=data[[&#39;年龄&#39;,&#39;单位性质&#39;,&#39;学历&#39;,&#39;性别&#39;,&#39;周工作时长&#39;,&#39;职业&#39;,&#39;收入&#39;]] display(data_list.head()) 年龄 单位性质 学历 性别 周工作时长 职业 收入 0 39 State-gov Bachelors Male 40 Adm-clerical &lt;=50K 1 50 Self-emp-not-inc Bachelors Male 13 Exec-managerial &lt;=50K 2 38 Private HS-grad Male 40 Handlers-cleaners &lt;=50K 3 53 Private 11th Male 40 Handlers-cleaners &lt;=50K 4 28 Private Bachelors Female 40 Prof-specialty &lt;=50K 注意 为了方便演示，我们只选了年龄，单位性质，学历，性别，周工作时长，职业和收入等特征 2.用get_dummies处理数据 在这个数据集中，单位性质，学历，性别，职业还有收入都不是整型数值，而是字符串，怎么使用我们现在所学的知识进行建模呢？这里我们用到pandas的一个功能，叫作get_dummies，它可以在现有的数据集上添加虚拟变量，让数据集变成可以用的格式 # 使用get_dummies将文本数据转化为数值 data_dummies=pd.get_dummies(data_list) # 对比样本原始特征和虚拟变量特征 print(&quot;样本原始特征：\n&quot;,list(data_list.columns),&#39;\n&#39;) print(&quot;虚拟变量特征：\n&quot;,list(data_dummies.columns)) 样本原始特征： [&#39;年龄&#39;, &#39;单位性质&#39;, &#39;学历&#39;, &#39;性别&#39;, &#39;周工作时长&#39;, &#39;职业&#39;, &#39;收入&#39;] 虚拟变量特征： [&#39;年龄&#39;, &#39;周工作时长&#39;, &#39;单位性质_ ?&#39;, &#39;单位性质_ Federal-gov&#39;, &#39;单位性质_ Local-gov&#39;, &#39;单位性质_ Never-worked&#39;, &#39;单位性质_ Private&#39;, &#39;单位性质_ Self-emp-inc&#39;, &#39;单位性质_ Self-emp-not-inc&#39;, &#39;单位性质_ State-gov&#39;, &#39;单位性质_ Without-pay&#39;, &#39;学历_ 10th&#39;, &#39;学历_ 11th&#39;, &#39;学历_ 12th&#39;, &#39;学历_ 1st-4th&#39;, &#39;学历_ 5th-6th&#39;, &#39;学历_ 7th-8th&#39;, &#39;学历_ 9th&#39;, &#39;学历_ Assoc-acdm&#39;, &#39;学历_ Assoc-voc&#39;, &#39;学历_ Bachelors&#39;, &#39;学历_ Doctorate&#39;, &#39;学历_ HS-grad&#39;, &#39;学历_ Masters&#39;, &#39;学历_ Preschool&#39;, &#39;学历_ Prof-school&#39;, &#39;学历_ Some-college&#39;, &#39;性别_ Female&#39;, &#39;性别_ Male&#39;, &#39;职业_ ?&#39;, &#39;职业_ Adm-clerical&#39;, &#39;职业_ Armed-Forces&#39;, &#39;职业_ Craft-repair&#39;, &#39;职业_ Exec-managerial&#39;, &#39;职业_ Farming-fishing&#39;, &#39;职业_ Handlers-cleaners&#39;, &#39;职业_ Machine-op-inspct&#39;, &#39;职业_ Other-service&#39;, &#39;职业_ Priv-house-serv&#39;, &#39;职业_ Prof-specialty&#39;, &#39;职业_ Protective-serv&#39;, &#39;职业_ Sales&#39;, &#39;职业_ Tech-support&#39;, &#39;职业_ Transport-moving&#39;, &#39;收入_ &lt;=50K&#39;, &#39;收入_ &gt;50K&#39;] 下面我们看下进行get_dummies后数据集的样子，显示前5行数据： # 显示数据集中的前5行 data_dummies.head() 年龄 周工作时长 单位性质_ ? 单位性质_ Federal-gov 单位性质_ Local-gov 单位性质_ Never-worked 单位性质_ Private 单位性质_ Self-emp-inc 单位性质_ Self-emp-not-inc 单位性质_ State-gov … 职业_ Machine-op-inspct 职业_ Other-service 职业_ Priv-house-serv 职业_ Prof-specialty 职业_ Protective-serv 职业_ Sales 职业_ Tech-support 职业_ Transport-moving 收入_ &lt;=50K 收入_ &gt;50K 0 39 40 0 0 0 0 0 0 0 1 … 0 0 0 0 0 0 0 0 1 0 1 50 13 0 0 0 0 0 0 1 0 … 0 0 0 0 0 0 0 0 1 0 2 38 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 3 53 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 4 28 40 0 0 0 0 1 0 0 0 … 0 0 0 1 0 0 0 0 1 0 5 rows × 46 columns 现在我们各列分配给特征向量X和分类标签y，输入代码如下： # 定义数据集的特征值 features=data_dummies.loc[:,&#39;年龄&#39;:&#39;职业_ Transport-moving&#39;] # 将特征数值赋值为x X=features.values # 将收入大于50k作为预测目标 y=data_dummies[&#39;收入_ &gt;50K&#39;].values print(&quot;特征形态：{},标签形态：{}&quot;.format(X.shape,y.shape)) 特征形态：(32561, 44),标签形态：(32561,) 3.用决策树建模并作出预测 数据集共有32561条样本数据，每条数据有44个特征值，接下来将数据集拆分成训练集和测试集，然后用决策树算法进行建模，并对模型进行评估： # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0) # 用最大深度为5的随机森林拟合数据 go_dating_tree=tree.DecisionTreeClassifier(max_depth=5) go_dating_tree.fit(X_train,y_train) print(&quot;模型得分：{:.2f}&quot;.format(go_dating_tree.score(X_test,y_test))) 模型得分：0.80 使用模型对Mr-L的收入进行预测，输入代码如下： # 将Mr Z的数据输入给模型 Mr=[[37,40,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]] # 使用模型做出预测 dating_dec=go_dating_tree.predict(Mr) if dating_dec==1: print(&quot;大胆追求真爱，这人月薪过5万&quot;) else: print(&quot;不用去了，不满足&quot;) 不用去了，不满足" />
<meta property="og:description" content="ML–决策树与随机森林 在生活中，我们经常遇到一些事情需要作出决策来应对。说到决策，自然想到决策树算法，而说到决策树算法，又自然会想到随机森林 主要涉及的知识点有： 决策树的基本原理和构造 决策树的优势和不足 随机森林的基本原理和构造 随机森林的优势和不足 实例演示：相亲事件 一.决策树 决策树是一种在分类与回归中都有非常广泛应用的算法，它的原理是通过对一系列问题进行if/else的推导，最终实现决策 1.决策树的基本原理 举个例子：假设出题者心理想的是Google,百度，Facebook，阿里，四个公司中的一个，则提问决策树：最终的4个节点，也就是4个公司的名字，被称为决策树的树叶。例子中的这棵决策树只有4片树叶，所以通过手动的方式就可以进行建模。但是如果样本的特征特别多，就不得不使用机器学习的办法来进行建模了 2.决策树的构建 下面我们先载入酒的数据集，然后将它做成训练集和测试集，输入代码如下： # 导入numpy import numpy as np # 导入画图工具 import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap # 导入tree模型和数据集加载工具 from sklearn import tree,datasets # 导入数据集拆分工具 from sklearn.model_selection import train_test_split wine=datasets.load_wine() # 只选取数据集的前两个特征 X=wine.data[:,:2] y=wine.target # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y) 现在完成了数据集的准备，开始用决策树分类器进行分类 注意 ：为了便于图形进行演示，我们仍然只选取了数据集中样本的前两个特征 # 设定决策树分类器最大深度为1 clf=tree.DecisionTreeClassifier(max_depth=1) # 拟合训练数据集 clf.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=1, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) [结果分析] 把分类器的参数返回，这些参数中，我们先关注其中之一，就是max_depth参数。这个参数指的是决策树的深度，也就是所问问题的数量，问题数量越多，就代表决策树的深度 现在我们看看分类器的表现如何，我们把图形画出来： # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=1)&quot;) plt.show() [结果分析] 很显然，最大深度等于1时分类器的表现肯定不会太好，分类器只分了两类。我们需要加大深度试试看 # 设定决策树最大深度为3 clf2=tree.DecisionTreeClassifier(max_depth=3) # 重新拟合数据 clf2.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf2.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=3)&quot;) plt.show() [结果分析] 当决策树最大深度设为3的时候，分类器能够进行3个分类的识别，而且大部分数据点都进入了正确的分类，当然还有一小部分数据点的分类是错误的 接下来进一步调整max_depth的值 # 设定决策树最大深度为5 clf3=tree.DecisionTreeClassifier(max_depth=5) # 重新拟合数据 clf3.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=5, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf3.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=5)&quot;) plt.show() 我们可能会感到好奇，在这个过程中，决策树在每一层当中都做了哪些事情呢？我们可以用一个名叫graphviz的库来展示一下这个过程。首先需要安装这个库： pip install graphviz 注意 graphviz只是帮助我们演示决策树的工作过程，对于读者来说，安装他并不是必须的 # 导入graphviz工具 import graphviz # 导入决策树中输出graphviz的接口 from sklearn.tree import export_graphviz # 选择最大深度为3的分类模型 export_graphviz(clf2,out_file=&quot;wine.dot&quot;,class_names=wine.target_names,feature_names=wine.feature_names[:2],impurity=False,filled=True) # 打开一个dot文件 with open(&quot;wine.dot&quot;) as f: dot_graph=f.read() # 显示dot文件中的图形 graphviz.Source(dot_graph) 注意 为了控制图片不要太大，我们选择用max_depth=3的分类器来绘制图形，这样可以方便观看 3.决策树的优势和不足 相比其他算法，决策树有一个非常大的优势，就是可以很容易地将模型进行可视化，就像我们在上图中所做的一样。另外，由于决策树算法对每个样本特征进行单独处理，因此并不需要对数据进行转换。这样一来，如果使用决策树算法的话，我们几乎不需要对数据进行预处理。这也是决策树算法的一个优点 当然，决策树算法也有它的不足之处—即便我们在建模的时候可以使用类似max_depth或是max_leaf_nodes等参数来对决决策树进行预剪枝处理，但它还是不可避免会出现多拟合的问题，也就让模型的泛化性能大打折扣了 为了避免过拟合的问题出现，可以使用集合学习的方法，也就是我们下面要介绍的—随机森林算法 二.随机森林 常言道，不要为了一棵树放弃一片森林。这句话在机器学习算法方面也是非常正确的 1.随机森林的基本概念 随机森林有的时候也被称为是随机决策森林，是一种集合学习方法，既可以用于分类，也可以用于回归。而所谓集合学习算法，其实就是把多个机器学习算法综合在一起，制造出一个更加大模型的意思。这也就很好地解释了为什么这种算法称为随机森林 在机器学习的领域，其实有很多中集合算法，目前应用比较广泛的就包括随机森林(Random Forests)和梯度上升决策树(Gradient Boosted Decision Trees,GBDT) 前面我们提到，决策树算法很容易出现过拟合的现象。那么为什么随机森林可以解决这个问题呢？因为随机森林是把不同的几棵决策树打包到一起，每棵树的参数都不相同，然后我们把每棵树预测的结果取平均值，这样即可以保留决策树们的工作成效，又可以降低过拟合的风险 2.随机森林的构建 这次我们继续用在决策树中来展示酒的数据集，输入代码如下： # 导入随机森林模型 from sklearn.ensemble import RandomForestClassifier # 载人红酒数据集 wine=datasets.load_wine() # 选择数据集前两个特征 X=wine.data[:,:2] y=wine.target # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y) # 设定随机森林中有6颗树 forest=RandomForestClassifier(n_estimators=6,random_state=3) # 使用模型拟合数据 forest.fit(X_train,y_train) RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=6, n_jobs=None, oob_score=False, random_state=3, verbose=0, warm_start=False) [结果分析] 可以看到，随机森林向我们返回了包含其自身全部参数的信息，让我们重点看一下其中几个必要重要的参数 首先是bootstrap参数，代表的是bootstrap sample，也就是&quot;有放回抽样&quot;的意思，指每次从样本空间中可以重复抽取同一个样本(因为样本在第一次被抽取之后又被放回去了)，形象一点来说，如原始样本是[‘苹果’,‘西瓜’,‘香蕉’,‘桃子’]，那么经过bootstrap sample重构的样本就可能是[‘西瓜’,‘西瓜’,‘香蕉’,‘桃子’]，还有可能是[‘苹果’,‘西瓜’,‘桃子’,‘桃子’]。Bootstrap sample生成的数据集和原始数据集在数据量上是完全一样的，D但由于进行了重复采样，因此其中有一些数据点会丢失 看到这里，可能会问为什么要生成bootstrap sample数据集。这是因为通过重新生成数据集，可以让随机森林中的每一棵决策树在构建的时候，会彼此之间有些差异。再加上每棵树的节点都会去选择不同的样本特征，经过这两步动作之后，可以完全肯定随机森林中的每棵树都不一样，这也符合我们使用随机森林的初衷 另外还有一个要强调的参数，是n_estimators，这个参数控制的是随机森林中决策树的数量。在随机森林构建完成之后，每棵决策树都会单独进行预测。如果是用来进行回归分析的话，随机森林会把所有决策树预测的值取平均数；如果是用来进行分类的话，在森林内部会进行&quot;投票&quot;，每棵树预测出数据类别的概率，比如其中一棵树说，“这瓶酒80%数据class_1”，另外一棵树说，“这瓶酒60%属于class_2”，随机森林会把这些概率取平均值，然后把样本放入概率最高的分类当中 下面我们用图像直观地看一下随机森林分类的表现，输入代码如下： # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=forest.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=5)&quot;) plt.show() 3.随机森林的优势和不足 从优势的角度来说，随机森林集成了决策树的所有优点，而且能够弥补决策树的不足。但也不是说决策树算法就被彻底抛弃了。从便于展示决策过程的角度来说，决策树依旧表现强悍。尤其是随机森林中每棵决策树的层级要比单独的决策树更深，所以如果需要向非专业人士展示模型工作过程的话，还是需要用到决策树的 还有，随机森林算法支持并行处理。对于超大数据集来说，随机森林会比较耗时，不过我们可以用多进程并行处理的方式来解决这个问题。实现方式是调节随机森林的n_jobs参数，记得把n_jobs参数数值设为和CPU内核数一致。如果你搞不清楚自己的CPU到底就多少内核，可以设置n_jobs=-1，这样随机森林会使用CPU的全部内核，速度就会极大提升了 需要注意的是，因为随机森林生成每棵决策树的方法是随机的，那么不同的random_state参数会导致模型完全不同，所以如果不希望建模的结果太过于不稳定，一定要固化random_state这个参数的数值 缺点是，对于超高维数据集，稀疏数据集等来说，随机森林就有点捉襟见肘了，在这种情况下，线性模型要比随机森林的表现更好一些 三.随机森林实例—相亲事件 小花的同事给她介绍了一个对象Mr-L，现在Mr-L现年37岁，在某省机关做文员工作。但是小花的择偶标准是需要对方月薪在5万以上(只是为了引入后面的内容)，但是又不好直接问Mr-L，所以拿不定主意，这时我们用决策树和随机森林 1.数据集的准备 在网站下载数据集：成年人数据集 下载好的数据集是.data格式的文件，不过不用担心，它其实就是一个csv文件，我们把它重命名为adult.csv 下面我们载人这个数据集，输入代码如下： # 导入pandas库 import pandas as pd # 用pd打开csv文件 data=pd.read_csv(&#39;adult.csv&#39;,header=None,index_col=False, names=[&#39;年龄&#39;,&#39;单位性质&#39;,&#39;权重&#39;,&#39;学历&#39;,&#39;受教育时长&#39;, &#39;婚姻状况&#39;,&#39;职业&#39;,&#39;家庭情况&#39;,&#39;种族&#39;,&#39;性别&#39;, &#39;资产所得&#39;,&#39;资产损失&#39;,&#39;周工作时长&#39;,&#39;原籍&#39;, &#39;收入&#39; ] ) #为了方便展示，我们选取其中一部分数据 data_list=data[[&#39;年龄&#39;,&#39;单位性质&#39;,&#39;学历&#39;,&#39;性别&#39;,&#39;周工作时长&#39;,&#39;职业&#39;,&#39;收入&#39;]] display(data_list.head()) 年龄 单位性质 学历 性别 周工作时长 职业 收入 0 39 State-gov Bachelors Male 40 Adm-clerical &lt;=50K 1 50 Self-emp-not-inc Bachelors Male 13 Exec-managerial &lt;=50K 2 38 Private HS-grad Male 40 Handlers-cleaners &lt;=50K 3 53 Private 11th Male 40 Handlers-cleaners &lt;=50K 4 28 Private Bachelors Female 40 Prof-specialty &lt;=50K 注意 为了方便演示，我们只选了年龄，单位性质，学历，性别，周工作时长，职业和收入等特征 2.用get_dummies处理数据 在这个数据集中，单位性质，学历，性别，职业还有收入都不是整型数值，而是字符串，怎么使用我们现在所学的知识进行建模呢？这里我们用到pandas的一个功能，叫作get_dummies，它可以在现有的数据集上添加虚拟变量，让数据集变成可以用的格式 # 使用get_dummies将文本数据转化为数值 data_dummies=pd.get_dummies(data_list) # 对比样本原始特征和虚拟变量特征 print(&quot;样本原始特征：\n&quot;,list(data_list.columns),&#39;\n&#39;) print(&quot;虚拟变量特征：\n&quot;,list(data_dummies.columns)) 样本原始特征： [&#39;年龄&#39;, &#39;单位性质&#39;, &#39;学历&#39;, &#39;性别&#39;, &#39;周工作时长&#39;, &#39;职业&#39;, &#39;收入&#39;] 虚拟变量特征： [&#39;年龄&#39;, &#39;周工作时长&#39;, &#39;单位性质_ ?&#39;, &#39;单位性质_ Federal-gov&#39;, &#39;单位性质_ Local-gov&#39;, &#39;单位性质_ Never-worked&#39;, &#39;单位性质_ Private&#39;, &#39;单位性质_ Self-emp-inc&#39;, &#39;单位性质_ Self-emp-not-inc&#39;, &#39;单位性质_ State-gov&#39;, &#39;单位性质_ Without-pay&#39;, &#39;学历_ 10th&#39;, &#39;学历_ 11th&#39;, &#39;学历_ 12th&#39;, &#39;学历_ 1st-4th&#39;, &#39;学历_ 5th-6th&#39;, &#39;学历_ 7th-8th&#39;, &#39;学历_ 9th&#39;, &#39;学历_ Assoc-acdm&#39;, &#39;学历_ Assoc-voc&#39;, &#39;学历_ Bachelors&#39;, &#39;学历_ Doctorate&#39;, &#39;学历_ HS-grad&#39;, &#39;学历_ Masters&#39;, &#39;学历_ Preschool&#39;, &#39;学历_ Prof-school&#39;, &#39;学历_ Some-college&#39;, &#39;性别_ Female&#39;, &#39;性别_ Male&#39;, &#39;职业_ ?&#39;, &#39;职业_ Adm-clerical&#39;, &#39;职业_ Armed-Forces&#39;, &#39;职业_ Craft-repair&#39;, &#39;职业_ Exec-managerial&#39;, &#39;职业_ Farming-fishing&#39;, &#39;职业_ Handlers-cleaners&#39;, &#39;职业_ Machine-op-inspct&#39;, &#39;职业_ Other-service&#39;, &#39;职业_ Priv-house-serv&#39;, &#39;职业_ Prof-specialty&#39;, &#39;职业_ Protective-serv&#39;, &#39;职业_ Sales&#39;, &#39;职业_ Tech-support&#39;, &#39;职业_ Transport-moving&#39;, &#39;收入_ &lt;=50K&#39;, &#39;收入_ &gt;50K&#39;] 下面我们看下进行get_dummies后数据集的样子，显示前5行数据： # 显示数据集中的前5行 data_dummies.head() 年龄 周工作时长 单位性质_ ? 单位性质_ Federal-gov 单位性质_ Local-gov 单位性质_ Never-worked 单位性质_ Private 单位性质_ Self-emp-inc 单位性质_ Self-emp-not-inc 单位性质_ State-gov … 职业_ Machine-op-inspct 职业_ Other-service 职业_ Priv-house-serv 职业_ Prof-specialty 职业_ Protective-serv 职业_ Sales 职业_ Tech-support 职业_ Transport-moving 收入_ &lt;=50K 收入_ &gt;50K 0 39 40 0 0 0 0 0 0 0 1 … 0 0 0 0 0 0 0 0 1 0 1 50 13 0 0 0 0 0 0 1 0 … 0 0 0 0 0 0 0 0 1 0 2 38 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 3 53 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 4 28 40 0 0 0 0 1 0 0 0 … 0 0 0 1 0 0 0 0 1 0 5 rows × 46 columns 现在我们各列分配给特征向量X和分类标签y，输入代码如下： # 定义数据集的特征值 features=data_dummies.loc[:,&#39;年龄&#39;:&#39;职业_ Transport-moving&#39;] # 将特征数值赋值为x X=features.values # 将收入大于50k作为预测目标 y=data_dummies[&#39;收入_ &gt;50K&#39;].values print(&quot;特征形态：{},标签形态：{}&quot;.format(X.shape,y.shape)) 特征形态：(32561, 44),标签形态：(32561,) 3.用决策树建模并作出预测 数据集共有32561条样本数据，每条数据有44个特征值，接下来将数据集拆分成训练集和测试集，然后用决策树算法进行建模，并对模型进行评估： # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0) # 用最大深度为5的随机森林拟合数据 go_dating_tree=tree.DecisionTreeClassifier(max_depth=5) go_dating_tree.fit(X_train,y_train) print(&quot;模型得分：{:.2f}&quot;.format(go_dating_tree.score(X_test,y_test))) 模型得分：0.80 使用模型对Mr-L的收入进行预测，输入代码如下： # 将Mr Z的数据输入给模型 Mr=[[37,40,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]] # 使用模型做出预测 dating_dec=go_dating_tree.predict(Mr) if dating_dec==1: print(&quot;大胆追求真爱，这人月薪过5万&quot;) else: print(&quot;不用去了，不满足&quot;) 不用去了，不满足" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-21T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"ML–决策树与随机森林 在生活中，我们经常遇到一些事情需要作出决策来应对。说到决策，自然想到决策树算法，而说到决策树算法，又自然会想到随机森林 主要涉及的知识点有： 决策树的基本原理和构造 决策树的优势和不足 随机森林的基本原理和构造 随机森林的优势和不足 实例演示：相亲事件 一.决策树 决策树是一种在分类与回归中都有非常广泛应用的算法，它的原理是通过对一系列问题进行if/else的推导，最终实现决策 1.决策树的基本原理 举个例子：假设出题者心理想的是Google,百度，Facebook，阿里，四个公司中的一个，则提问决策树：最终的4个节点，也就是4个公司的名字，被称为决策树的树叶。例子中的这棵决策树只有4片树叶，所以通过手动的方式就可以进行建模。但是如果样本的特征特别多，就不得不使用机器学习的办法来进行建模了 2.决策树的构建 下面我们先载入酒的数据集，然后将它做成训练集和测试集，输入代码如下： # 导入numpy import numpy as np # 导入画图工具 import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap # 导入tree模型和数据集加载工具 from sklearn import tree,datasets # 导入数据集拆分工具 from sklearn.model_selection import train_test_split wine=datasets.load_wine() # 只选取数据集的前两个特征 X=wine.data[:,:2] y=wine.target # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y) 现在完成了数据集的准备，开始用决策树分类器进行分类 注意 ：为了便于图形进行演示，我们仍然只选取了数据集中样本的前两个特征 # 设定决策树分类器最大深度为1 clf=tree.DecisionTreeClassifier(max_depth=1) # 拟合训练数据集 clf.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=1, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) [结果分析] 把分类器的参数返回，这些参数中，我们先关注其中之一，就是max_depth参数。这个参数指的是决策树的深度，也就是所问问题的数量，问题数量越多，就代表决策树的深度 现在我们看看分类器的表现如何，我们把图形画出来： # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=1)&quot;) plt.show() [结果分析] 很显然，最大深度等于1时分类器的表现肯定不会太好，分类器只分了两类。我们需要加大深度试试看 # 设定决策树最大深度为3 clf2=tree.DecisionTreeClassifier(max_depth=3) # 重新拟合数据 clf2.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=3, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf2.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=3)&quot;) plt.show() [结果分析] 当决策树最大深度设为3的时候，分类器能够进行3个分类的识别，而且大部分数据点都进入了正确的分类，当然还有一小部分数据点的分类是错误的 接下来进一步调整max_depth的值 # 设定决策树最大深度为5 clf3=tree.DecisionTreeClassifier(max_depth=5) # 重新拟合数据 clf3.fit(X_train,y_train) DecisionTreeClassifier(class_weight=None, criterion=&#39;gini&#39;, max_depth=5, max_features=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, presort=False, random_state=None, splitter=&#39;best&#39;) # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=clf3.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=5)&quot;) plt.show() 我们可能会感到好奇，在这个过程中，决策树在每一层当中都做了哪些事情呢？我们可以用一个名叫graphviz的库来展示一下这个过程。首先需要安装这个库： pip install graphviz 注意 graphviz只是帮助我们演示决策树的工作过程，对于读者来说，安装他并不是必须的 # 导入graphviz工具 import graphviz # 导入决策树中输出graphviz的接口 from sklearn.tree import export_graphviz # 选择最大深度为3的分类模型 export_graphviz(clf2,out_file=&quot;wine.dot&quot;,class_names=wine.target_names,feature_names=wine.feature_names[:2],impurity=False,filled=True) # 打开一个dot文件 with open(&quot;wine.dot&quot;) as f: dot_graph=f.read() # 显示dot文件中的图形 graphviz.Source(dot_graph) 注意 为了控制图片不要太大，我们选择用max_depth=3的分类器来绘制图形，这样可以方便观看 3.决策树的优势和不足 相比其他算法，决策树有一个非常大的优势，就是可以很容易地将模型进行可视化，就像我们在上图中所做的一样。另外，由于决策树算法对每个样本特征进行单独处理，因此并不需要对数据进行转换。这样一来，如果使用决策树算法的话，我们几乎不需要对数据进行预处理。这也是决策树算法的一个优点 当然，决策树算法也有它的不足之处—即便我们在建模的时候可以使用类似max_depth或是max_leaf_nodes等参数来对决决策树进行预剪枝处理，但它还是不可避免会出现多拟合的问题，也就让模型的泛化性能大打折扣了 为了避免过拟合的问题出现，可以使用集合学习的方法，也就是我们下面要介绍的—随机森林算法 二.随机森林 常言道，不要为了一棵树放弃一片森林。这句话在机器学习算法方面也是非常正确的 1.随机森林的基本概念 随机森林有的时候也被称为是随机决策森林，是一种集合学习方法，既可以用于分类，也可以用于回归。而所谓集合学习算法，其实就是把多个机器学习算法综合在一起，制造出一个更加大模型的意思。这也就很好地解释了为什么这种算法称为随机森林 在机器学习的领域，其实有很多中集合算法，目前应用比较广泛的就包括随机森林(Random Forests)和梯度上升决策树(Gradient Boosted Decision Trees,GBDT) 前面我们提到，决策树算法很容易出现过拟合的现象。那么为什么随机森林可以解决这个问题呢？因为随机森林是把不同的几棵决策树打包到一起，每棵树的参数都不相同，然后我们把每棵树预测的结果取平均值，这样即可以保留决策树们的工作成效，又可以降低过拟合的风险 2.随机森林的构建 这次我们继续用在决策树中来展示酒的数据集，输入代码如下： # 导入随机森林模型 from sklearn.ensemble import RandomForestClassifier # 载人红酒数据集 wine=datasets.load_wine() # 选择数据集前两个特征 X=wine.data[:,:2] y=wine.target # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y) # 设定随机森林中有6颗树 forest=RandomForestClassifier(n_estimators=6,random_state=3) # 使用模型拟合数据 forest.fit(X_train,y_train) RandomForestClassifier(bootstrap=True, class_weight=None, criterion=&#39;gini&#39;, max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=6, n_jobs=None, oob_score=False, random_state=3, verbose=0, warm_start=False) [结果分析] 可以看到，随机森林向我们返回了包含其自身全部参数的信息，让我们重点看一下其中几个必要重要的参数 首先是bootstrap参数，代表的是bootstrap sample，也就是&quot;有放回抽样&quot;的意思，指每次从样本空间中可以重复抽取同一个样本(因为样本在第一次被抽取之后又被放回去了)，形象一点来说，如原始样本是[‘苹果’,‘西瓜’,‘香蕉’,‘桃子’]，那么经过bootstrap sample重构的样本就可能是[‘西瓜’,‘西瓜’,‘香蕉’,‘桃子’]，还有可能是[‘苹果’,‘西瓜’,‘桃子’,‘桃子’]。Bootstrap sample生成的数据集和原始数据集在数据量上是完全一样的，D但由于进行了重复采样，因此其中有一些数据点会丢失 看到这里，可能会问为什么要生成bootstrap sample数据集。这是因为通过重新生成数据集，可以让随机森林中的每一棵决策树在构建的时候，会彼此之间有些差异。再加上每棵树的节点都会去选择不同的样本特征，经过这两步动作之后，可以完全肯定随机森林中的每棵树都不一样，这也符合我们使用随机森林的初衷 另外还有一个要强调的参数，是n_estimators，这个参数控制的是随机森林中决策树的数量。在随机森林构建完成之后，每棵决策树都会单独进行预测。如果是用来进行回归分析的话，随机森林会把所有决策树预测的值取平均数；如果是用来进行分类的话，在森林内部会进行&quot;投票&quot;，每棵树预测出数据类别的概率，比如其中一棵树说，“这瓶酒80%数据class_1”，另外一棵树说，“这瓶酒60%属于class_2”，随机森林会把这些概率取平均值，然后把样本放入概率最高的分类当中 下面我们用图像直观地看一下随机森林分类的表现，输入代码如下： # 定义图像中分区的颜色和散点的颜色 cmap_light=ListedColormap([&#39;#FFAAAA&#39;,&#39;#AAFFAA&#39;,&#39;#AAAAFF&#39;]) cmap_bold=ListedColormap([&#39;#FF0000&#39;,&#39;#00FF00&#39;,&#39;#0000FF&#39;]) # 分别用样本的两个特征创建图像和横轴和纵轴 x_min,x_max=X_train[:,0].min()-1,X_train[:,0].max()+1 y_min,y_max=X_train[:,1].min()-1,X_train[:,1].max()+1 xx,yy=np.meshgrid(np.arange(x_min,x_max,.02),np.arange(y_min,y_max,.02)) z=forest.predict(np.c_[xx.ravel(),yy.ravel()]) # 给每个分类中的样本分配不同的颜色 Z=z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx,yy,Z,cmap=cmap_light) # 用散点图把样本表示出来 plt.scatter(X[:,0],X[:,1],c=y,cmap=cmap_bold,edgecolors=&#39;k&#39;,s=20) plt.xlim(xx.min(),xx.max()) plt.ylim(yy.min(),yy.max()) plt.title(&quot;Classifier:(max_depth=5)&quot;) plt.show() 3.随机森林的优势和不足 从优势的角度来说，随机森林集成了决策树的所有优点，而且能够弥补决策树的不足。但也不是说决策树算法就被彻底抛弃了。从便于展示决策过程的角度来说，决策树依旧表现强悍。尤其是随机森林中每棵决策树的层级要比单独的决策树更深，所以如果需要向非专业人士展示模型工作过程的话，还是需要用到决策树的 还有，随机森林算法支持并行处理。对于超大数据集来说，随机森林会比较耗时，不过我们可以用多进程并行处理的方式来解决这个问题。实现方式是调节随机森林的n_jobs参数，记得把n_jobs参数数值设为和CPU内核数一致。如果你搞不清楚自己的CPU到底就多少内核，可以设置n_jobs=-1，这样随机森林会使用CPU的全部内核，速度就会极大提升了 需要注意的是，因为随机森林生成每棵决策树的方法是随机的，那么不同的random_state参数会导致模型完全不同，所以如果不希望建模的结果太过于不稳定，一定要固化random_state这个参数的数值 缺点是，对于超高维数据集，稀疏数据集等来说，随机森林就有点捉襟见肘了，在这种情况下，线性模型要比随机森林的表现更好一些 三.随机森林实例—相亲事件 小花的同事给她介绍了一个对象Mr-L，现在Mr-L现年37岁，在某省机关做文员工作。但是小花的择偶标准是需要对方月薪在5万以上(只是为了引入后面的内容)，但是又不好直接问Mr-L，所以拿不定主意，这时我们用决策树和随机森林 1.数据集的准备 在网站下载数据集：成年人数据集 下载好的数据集是.data格式的文件，不过不用担心，它其实就是一个csv文件，我们把它重命名为adult.csv 下面我们载人这个数据集，输入代码如下： # 导入pandas库 import pandas as pd # 用pd打开csv文件 data=pd.read_csv(&#39;adult.csv&#39;,header=None,index_col=False, names=[&#39;年龄&#39;,&#39;单位性质&#39;,&#39;权重&#39;,&#39;学历&#39;,&#39;受教育时长&#39;, &#39;婚姻状况&#39;,&#39;职业&#39;,&#39;家庭情况&#39;,&#39;种族&#39;,&#39;性别&#39;, &#39;资产所得&#39;,&#39;资产损失&#39;,&#39;周工作时长&#39;,&#39;原籍&#39;, &#39;收入&#39; ] ) #为了方便展示，我们选取其中一部分数据 data_list=data[[&#39;年龄&#39;,&#39;单位性质&#39;,&#39;学历&#39;,&#39;性别&#39;,&#39;周工作时长&#39;,&#39;职业&#39;,&#39;收入&#39;]] display(data_list.head()) 年龄 单位性质 学历 性别 周工作时长 职业 收入 0 39 State-gov Bachelors Male 40 Adm-clerical &lt;=50K 1 50 Self-emp-not-inc Bachelors Male 13 Exec-managerial &lt;=50K 2 38 Private HS-grad Male 40 Handlers-cleaners &lt;=50K 3 53 Private 11th Male 40 Handlers-cleaners &lt;=50K 4 28 Private Bachelors Female 40 Prof-specialty &lt;=50K 注意 为了方便演示，我们只选了年龄，单位性质，学历，性别，周工作时长，职业和收入等特征 2.用get_dummies处理数据 在这个数据集中，单位性质，学历，性别，职业还有收入都不是整型数值，而是字符串，怎么使用我们现在所学的知识进行建模呢？这里我们用到pandas的一个功能，叫作get_dummies，它可以在现有的数据集上添加虚拟变量，让数据集变成可以用的格式 # 使用get_dummies将文本数据转化为数值 data_dummies=pd.get_dummies(data_list) # 对比样本原始特征和虚拟变量特征 print(&quot;样本原始特征：\\n&quot;,list(data_list.columns),&#39;\\n&#39;) print(&quot;虚拟变量特征：\\n&quot;,list(data_dummies.columns)) 样本原始特征： [&#39;年龄&#39;, &#39;单位性质&#39;, &#39;学历&#39;, &#39;性别&#39;, &#39;周工作时长&#39;, &#39;职业&#39;, &#39;收入&#39;] 虚拟变量特征： [&#39;年龄&#39;, &#39;周工作时长&#39;, &#39;单位性质_ ?&#39;, &#39;单位性质_ Federal-gov&#39;, &#39;单位性质_ Local-gov&#39;, &#39;单位性质_ Never-worked&#39;, &#39;单位性质_ Private&#39;, &#39;单位性质_ Self-emp-inc&#39;, &#39;单位性质_ Self-emp-not-inc&#39;, &#39;单位性质_ State-gov&#39;, &#39;单位性质_ Without-pay&#39;, &#39;学历_ 10th&#39;, &#39;学历_ 11th&#39;, &#39;学历_ 12th&#39;, &#39;学历_ 1st-4th&#39;, &#39;学历_ 5th-6th&#39;, &#39;学历_ 7th-8th&#39;, &#39;学历_ 9th&#39;, &#39;学历_ Assoc-acdm&#39;, &#39;学历_ Assoc-voc&#39;, &#39;学历_ Bachelors&#39;, &#39;学历_ Doctorate&#39;, &#39;学历_ HS-grad&#39;, &#39;学历_ Masters&#39;, &#39;学历_ Preschool&#39;, &#39;学历_ Prof-school&#39;, &#39;学历_ Some-college&#39;, &#39;性别_ Female&#39;, &#39;性别_ Male&#39;, &#39;职业_ ?&#39;, &#39;职业_ Adm-clerical&#39;, &#39;职业_ Armed-Forces&#39;, &#39;职业_ Craft-repair&#39;, &#39;职业_ Exec-managerial&#39;, &#39;职业_ Farming-fishing&#39;, &#39;职业_ Handlers-cleaners&#39;, &#39;职业_ Machine-op-inspct&#39;, &#39;职业_ Other-service&#39;, &#39;职业_ Priv-house-serv&#39;, &#39;职业_ Prof-specialty&#39;, &#39;职业_ Protective-serv&#39;, &#39;职业_ Sales&#39;, &#39;职业_ Tech-support&#39;, &#39;职业_ Transport-moving&#39;, &#39;收入_ &lt;=50K&#39;, &#39;收入_ &gt;50K&#39;] 下面我们看下进行get_dummies后数据集的样子，显示前5行数据： # 显示数据集中的前5行 data_dummies.head() 年龄 周工作时长 单位性质_ ? 单位性质_ Federal-gov 单位性质_ Local-gov 单位性质_ Never-worked 单位性质_ Private 单位性质_ Self-emp-inc 单位性质_ Self-emp-not-inc 单位性质_ State-gov … 职业_ Machine-op-inspct 职业_ Other-service 职业_ Priv-house-serv 职业_ Prof-specialty 职业_ Protective-serv 职业_ Sales 职业_ Tech-support 职业_ Transport-moving 收入_ &lt;=50K 收入_ &gt;50K 0 39 40 0 0 0 0 0 0 0 1 … 0 0 0 0 0 0 0 0 1 0 1 50 13 0 0 0 0 0 0 1 0 … 0 0 0 0 0 0 0 0 1 0 2 38 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 3 53 40 0 0 0 0 1 0 0 0 … 0 0 0 0 0 0 0 0 1 0 4 28 40 0 0 0 0 1 0 0 0 … 0 0 0 1 0 0 0 0 1 0 5 rows × 46 columns 现在我们各列分配给特征向量X和分类标签y，输入代码如下： # 定义数据集的特征值 features=data_dummies.loc[:,&#39;年龄&#39;:&#39;职业_ Transport-moving&#39;] # 将特征数值赋值为x X=features.values # 将收入大于50k作为预测目标 y=data_dummies[&#39;收入_ &gt;50K&#39;].values print(&quot;特征形态：{},标签形态：{}&quot;.format(X.shape,y.shape)) 特征形态：(32561, 44),标签形态：(32561,) 3.用决策树建模并作出预测 数据集共有32561条样本数据，每条数据有44个特征值，接下来将数据集拆分成训练集和测试集，然后用决策树算法进行建模，并对模型进行评估： # 将数据集拆分为训练集和测试集 X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0) # 用最大深度为5的随机森林拟合数据 go_dating_tree=tree.DecisionTreeClassifier(max_depth=5) go_dating_tree.fit(X_train,y_train) print(&quot;模型得分：{:.2f}&quot;.format(go_dating_tree.score(X_test,y_test))) 模型得分：0.80 使用模型对Mr-L的收入进行预测，输入代码如下： # 将Mr Z的数据输入给模型 Mr=[[37,40,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]] # 使用模型做出预测 dating_dec=go_dating_tree.predict(Mr) if dating_dec==1: print(&quot;大胆追求真爱，这人月薪过5万&quot;) else: print(&quot;不用去了，不满足&quot;) 不用去了，不满足","@type":"BlogPosting","url":"/2019/02/21/17e0d45ebb943dd0a976bef4d3243851.html","headline":"ML–决策树与随机森林","dateModified":"2019-02-21T00:00:00+08:00","datePublished":"2019-02-21T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/02/21/17e0d45ebb943dd0a976bef4d3243851.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>ML--决策树与随机森林</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div id="content_views" class="markdown_views prism-dracula"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h1><a id="ML_0"></a>ML–决策树与随机森林</h1> 
  <p>在生活中，我们经常遇到一些事情需要作出决策来应对。说到决策，自然想到决策树算法，而说到决策树算法，又自然会想到随机森林</p> 
  <p>主要涉及的知识点有：</p> 
  <ul> 
   <li>决策树的基本原理和构造</li> 
   <li>决策树的优势和不足</li> 
   <li>随机森林的基本原理和构造</li> 
   <li>随机森林的优势和不足</li> 
   <li>实例演示：相亲事件</li> 
  </ul> 
  <h2><a id="_12"></a>一.决策树</h2> 
  <p>决策树是一种在分类与回归中都有非常广泛应用的算法，它的原理是通过对一系列问题进行<code>if/else</code>的推导，最终实现决策</p> 
  <h3><a id="1_16"></a>1.决策树的基本原理</h3> 
  <p>举个例子：假设出题者心理想的是<code>Google,百度，Facebook，阿里</code>，四个公司中的一个，则提问决策树：<br><img src="https://cdn.nlark.com/yuque/0/2019/png/214438/1550752028080-3ecf7abf-0002-4add-a35b-96cebf370e70.png#align=left&amp;display=inline&amp;height=353&amp;linkTarget=_blank&amp;name=%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6.png&amp;originHeight=364&amp;originWidth=770&amp;size=23138&amp;width=746" alt="未命名文件.png"><br>最终的4个节点，也就是4个公司的名字，被称为决策树的树叶。例子中的这棵决策树只有4片树叶，所以通过手动的方式就可以进行建模。但是如果样本的特征特别多，就不得不使用机器学习的办法来进行建模了</p> 
  <h3><a id="2_20"></a>2.决策树的构建</h3> 
  <p>下面我们先载入酒的数据集，然后将它做成训练集和测试集，输入代码如下：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 导入numpy</span>
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

<span class="token comment"># 导入画图工具</span>
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> matplotlib<span class="token punctuation">.</span>colors <span class="token keyword">import</span> ListedColormap

<span class="token comment"># 导入tree模型和数据集加载工具</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> tree<span class="token punctuation">,</span>datasets

<span class="token comment"># 导入数据集拆分工具</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

wine<span class="token operator">=</span>datasets<span class="token punctuation">.</span>load_wine<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 只选取数据集的前两个特征</span>
X<span class="token operator">=</span>wine<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>
y<span class="token operator">=</span>wine<span class="token punctuation">.</span>target

<span class="token comment"># 将数据集拆分为训练集和测试集</span>
X_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>
</code></pre> 
  <p>现在完成了数据集的准备，开始用决策树分类器进行分类</p> 
  <p><strong>注意</strong> ：为了便于图形进行演示，我们仍然只选取了数据集中样本的前两个特征</p> 
  <pre><code class="prism language-python"><span class="token comment"># 设定决策树分类器最大深度为1</span>
clf<span class="token operator">=</span>tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 拟合训练数据集</span>
clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
</code></pre> 
  <p><strong>[结果分析]</strong> 把分类器的参数返回，这些参数中，我们先关注其中之一，就是<code>max_depth</code>参数。这个参数指的是决策树的深度，也就是所问问题的数量，问题数量越多，就代表决策树的深度</p> 
  <p>现在我们看看分类器的表现如何，我们把图形画出来：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 定义图像中分区的颜色和散点的颜色</span>
cmap_light<span class="token operator">=</span>ListedColormap<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'#FFAAAA'</span><span class="token punctuation">,</span><span class="token string">'#AAFFAA'</span><span class="token punctuation">,</span><span class="token string">'#AAAAFF'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
cmap_bold<span class="token operator">=</span>ListedColormap<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'#FF0000'</span><span class="token punctuation">,</span><span class="token string">'#00FF00'</span><span class="token punctuation">,</span><span class="token string">'#0000FF'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 分别用样本的两个特征创建图像和横轴和纵轴</span>
x_min<span class="token punctuation">,</span>x_max<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>
y_min<span class="token punctuation">,</span>y_max<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>

xx<span class="token punctuation">,</span>yy<span class="token operator">=</span>np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x_min<span class="token punctuation">,</span>x_max<span class="token punctuation">,</span><span class="token number">.02</span><span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>y_min<span class="token punctuation">,</span>y_max<span class="token punctuation">,</span><span class="token number">.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

z<span class="token operator">=</span>clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 给每个分类中的样本分配不同的颜色</span>
Z<span class="token operator">=</span>z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>pcolormesh<span class="token punctuation">(</span>xx<span class="token punctuation">,</span>yy<span class="token punctuation">,</span>Z<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap_light<span class="token punctuation">)</span>

<span class="token comment"># 用散点图把样本表示出来</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>y<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap_bold<span class="token punctuation">,</span>edgecolors<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>xx<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>xx<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>yy<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yy<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Classifier:(max_depth=1)"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <p><img src="https://cdn.nlark.com/yuque/0/2019/png/214438/1550752054254-23e5ddcb-57c7-4b7a-8886-f8a2d5dbf7f5.png#align=left&amp;display=inline&amp;height=264&amp;linkTarget=_blank&amp;name=output_10_0.png&amp;originHeight=264&amp;originWidth=366&amp;size=24252&amp;width=366" alt="output_10_0.png"></p> 
  <p><strong>[结果分析]</strong> 很显然，最大深度等于1时分类器的表现肯定不会太好，分类器只分了两类。我们需要加大深度试试看</p> 
  <pre><code class="prism language-python"><span class="token comment"># 设定决策树最大深度为3</span>
clf2<span class="token operator">=</span>tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>

<span class="token comment"># 重新拟合数据</span>
clf2<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
</code></pre> 
  <pre><code class="prism language-python"><span class="token comment"># 定义图像中分区的颜色和散点的颜色</span>
cmap_light<span class="token operator">=</span>ListedColormap<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'#FFAAAA'</span><span class="token punctuation">,</span><span class="token string">'#AAFFAA'</span><span class="token punctuation">,</span><span class="token string">'#AAAAFF'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
cmap_bold<span class="token operator">=</span>ListedColormap<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'#FF0000'</span><span class="token punctuation">,</span><span class="token string">'#00FF00'</span><span class="token punctuation">,</span><span class="token string">'#0000FF'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 分别用样本的两个特征创建图像和横轴和纵轴</span>
x_min<span class="token punctuation">,</span>x_max<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>
y_min<span class="token punctuation">,</span>y_max<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>
xx<span class="token punctuation">,</span>yy<span class="token operator">=</span>np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x_min<span class="token punctuation">,</span>x_max<span class="token punctuation">,</span><span class="token number">.02</span><span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>y_min<span class="token punctuation">,</span>y_max<span class="token punctuation">,</span><span class="token number">.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

z<span class="token operator">=</span>clf2<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 给每个分类中的样本分配不同的颜色</span>
Z<span class="token operator">=</span>z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>pcolormesh<span class="token punctuation">(</span>xx<span class="token punctuation">,</span>yy<span class="token punctuation">,</span>Z<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap_light<span class="token punctuation">)</span>

<span class="token comment"># 用散点图把样本表示出来</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>y<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap_bold<span class="token punctuation">,</span>edgecolors<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>xx<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>xx<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>yy<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yy<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Classifier:(max_depth=3)"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <p><img src="https://cdn.nlark.com/yuque/0/2019/png/214438/1550752072833-6820f025-8ff4-4b49-b4fa-25a33407419c.png#align=left&amp;display=inline&amp;height=264&amp;linkTarget=_blank&amp;name=output_13_0.png&amp;originHeight=264&amp;originWidth=366&amp;size=24338&amp;width=366" alt="output_13_0.png"></p> 
  <p><strong>[结果分析]</strong> 当决策树最大深度设为3的时候，分类器能够进行3个分类的识别，而且大部分数据点都进入了正确的分类，当然还有一小部分数据点的分类是错误的</p> 
  <p>接下来进一步调整<code>max_depth</code>的值</p> 
  <pre><code class="prism language-python"><span class="token comment"># 设定决策树最大深度为5</span>
clf3<span class="token operator">=</span>tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>

<span class="token comment"># 重新拟合数据</span>
clf3<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,
            max_features=None, max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, presort=False, random_state=None,
            splitter='best')
</code></pre> 
  <pre><code class="prism language-python"><span class="token comment"># 定义图像中分区的颜色和散点的颜色</span>
cmap_light<span class="token operator">=</span>ListedColormap<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'#FFAAAA'</span><span class="token punctuation">,</span><span class="token string">'#AAFFAA'</span><span class="token punctuation">,</span><span class="token string">'#AAAAFF'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
cmap_bold<span class="token operator">=</span>ListedColormap<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'#FF0000'</span><span class="token punctuation">,</span><span class="token string">'#00FF00'</span><span class="token punctuation">,</span><span class="token string">'#0000FF'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 分别用样本的两个特征创建图像和横轴和纵轴</span>
x_min<span class="token punctuation">,</span>x_max<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>
y_min<span class="token punctuation">,</span>y_max<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>
xx<span class="token punctuation">,</span>yy<span class="token operator">=</span>np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x_min<span class="token punctuation">,</span>x_max<span class="token punctuation">,</span><span class="token number">.02</span><span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>y_min<span class="token punctuation">,</span>y_max<span class="token punctuation">,</span><span class="token number">.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

z<span class="token operator">=</span>clf3<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 给每个分类中的样本分配不同的颜色</span>
Z<span class="token operator">=</span>z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>pcolormesh<span class="token punctuation">(</span>xx<span class="token punctuation">,</span>yy<span class="token punctuation">,</span>Z<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap_light<span class="token punctuation">)</span>

<span class="token comment"># 用散点图把样本表示出来</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>y<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap_bold<span class="token punctuation">,</span>edgecolors<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>xx<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>xx<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>yy<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yy<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Classifier:(max_depth=5)"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <p><img src="https://cdn.nlark.com/yuque/0/2019/png/214438/1550752096913-21700558-6a54-44b6-84aa-a519c4e9711a.png#align=left&amp;display=inline&amp;height=264&amp;linkTarget=_blank&amp;name=output_16_0.png&amp;originHeight=264&amp;originWidth=366&amp;size=24466&amp;width=366" alt="output_16_0.png"></p> 
  <p>我们可能会感到好奇，在这个过程中，决策树在每一层当中都做了哪些事情呢？我们可以用一个名叫<code>graphviz</code>的库来展示一下这个过程。首先需要安装这个库：</p> 
  <p><code>pip install graphviz</code></p> 
  <p><strong>注意</strong> <code>graphviz</code>只是帮助我们演示决策树的工作过程，对于读者来说，安装他并不是必须的</p> 
  <pre><code class="prism language-python"><span class="token comment"># 导入graphviz工具</span>
<span class="token keyword">import</span> graphviz
<span class="token comment"># 导入决策树中输出graphviz的接口</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> export_graphviz
<span class="token comment"># 选择最大深度为3的分类模型</span>
export_graphviz<span class="token punctuation">(</span>clf2<span class="token punctuation">,</span>out_file<span class="token operator">=</span><span class="token string">"wine.dot"</span><span class="token punctuation">,</span>class_names<span class="token operator">=</span>wine<span class="token punctuation">.</span>target_names<span class="token punctuation">,</span>feature_names<span class="token operator">=</span>wine<span class="token punctuation">.</span>feature_names<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>impurity<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>filled<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 打开一个dot文件</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">"wine.dot"</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    dot_graph<span class="token operator">=</span>f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
<span class="token comment"># 显示dot文件中的图形</span>
graphviz<span class="token punctuation">.</span>Source<span class="token punctuation">(</span>dot_graph<span class="token punctuation">)</span>
</code></pre> 
  <p><img src="https://cdn.nlark.com/yuque/0/2019/svg/214438/1550752134444-3580b6ea-daa1-44ac-8dbd-e0802f51ad31.svg#align=left&amp;display=inline&amp;height=497&amp;linkTarget=_blank&amp;name=output_18_0.svg&amp;originHeight=497&amp;originWidth=1329&amp;size=14408&amp;width=1329" alt="output_18_0.svg"></p> 
  <p><strong>注意</strong> 为了控制图片不要太大，我们选择用<code>max_depth=3</code>的分类器来绘制图形，这样可以方便观看</p> 
  <h3><a id="3_233"></a>3.决策树的优势和不足</h3> 
  <p>相比其他算法，决策树有一个非常大的优势，就是可以很容易地将模型进行可视化，就像我们在上图中所做的一样。另外，由于决策树算法对每个样本特征进行单独处理，因此并不需要对数据进行转换。这样一来，如果使用决策树算法的话，我们几乎不需要对数据进行预处理。这也是决策树算法的一个优点</p> 
  <p>当然，决策树算法也有它的不足之处—即便我们在建模的时候可以使用类似<code>max_depth</code>或是<code>max_leaf_nodes</code>等参数来对决决策树进行预剪枝处理，但它还是不可避免会出现多拟合的问题，也就让模型的泛化性能大打折扣了</p> 
  <p>为了避免过拟合的问题出现，可以使用集合学习的方法，也就是我们下面要介绍的—<code>随机森林算法</code></p> 
  <h2><a id="_241"></a>二.随机森林</h2> 
  <p>常言道，不要为了一棵树放弃一片森林。这句话在机器学习算法方面也是非常正确的</p> 
  <h3><a id="1_245"></a>1.随机森林的基本概念</h3> 
  <p>随机森林有的时候也被称为是随机决策森林，是一种集合学习方法，既可以用于分类，也可以用于回归。而所谓集合学习算法，其实就是把多个机器学习算法综合在一起，制造出一个更加大模型的意思。这也就很好地解释了为什么这种算法称为随机森林</p> 
  <p>在机器学习的领域，其实有很多中集合算法，目前应用比较广泛的就包括<code>随机森林(Random Forests)</code>和<code>梯度上升决策树(Gradient Boosted Decision Trees,GBDT)</code></p> 
  <p>前面我们提到，决策树算法很容易出现过拟合的现象。那么为什么随机森林可以解决这个问题呢？因为随机森林是把不同的几棵决策树打包到一起，每棵树的参数都不相同，然后我们把每棵树预测的结果取平均值，这样即可以保留决策树们的工作成效，又可以降低过拟合的风险</p> 
  <h3><a id="2_253"></a>2.随机森林的构建</h3> 
  <p>这次我们继续用在决策树中来展示酒的数据集，输入代码如下：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 导入随机森林模型</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>ensemble <span class="token keyword">import</span> RandomForestClassifier

<span class="token comment"># 载人红酒数据集</span>
wine<span class="token operator">=</span>datasets<span class="token punctuation">.</span>load_wine<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 选择数据集前两个特征</span>
X<span class="token operator">=</span>wine<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span>
y<span class="token operator">=</span>wine<span class="token punctuation">.</span>target

<span class="token comment"># 将数据集拆分为训练集和测试集</span>
X_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span>

<span class="token comment"># 设定随机森林中有6颗树</span>
forest<span class="token operator">=</span>RandomForestClassifier<span class="token punctuation">(</span>n_estimators<span class="token operator">=</span><span class="token number">6</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>

<span class="token comment"># 使用模型拟合数据</span>
forest<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',
            max_depth=None, max_features='auto', max_leaf_nodes=None,
            min_impurity_decrease=0.0, min_impurity_split=None,
            min_samples_leaf=1, min_samples_split=2,
            min_weight_fraction_leaf=0.0, n_estimators=6, n_jobs=None,
            oob_score=False, random_state=3, verbose=0, warm_start=False)
</code></pre> 
  <p><strong>[结果分析]</strong> 可以看到，随机森林向我们返回了包含其自身全部参数的信息，让我们重点看一下其中几个必要重要的参数</p> 
  <p>首先是<code>bootstrap</code>参数，代表的是<code>bootstrap sample</code>，也就是"有放回抽样"的意思，指每次从样本空间中可以重复抽取同一个样本(因为样本在第一次被抽取之后又被放回去了)，形象一点来说，如原始样本是[‘苹果’,‘西瓜’,‘香蕉’,‘桃子’]，那么经过<code>bootstrap sample</code>重构的样本就可能是[‘西瓜’,‘西瓜’,‘香蕉’,‘桃子’]，还有可能是[‘苹果’,‘西瓜’,‘桃子’,‘桃子’]。<code>Bootstrap sample</code>生成的数据集和原始数据集在数据量上是完全一样的，D但由于进行了重复采样，因此其中有一些数据点会丢失</p> 
  <p>看到这里，可能会问为什么要生成<code>bootstrap sample</code>数据集。这是因为通过重新生成数据集，可以让随机森林中的每一棵决策树在构建的时候，会彼此之间有些差异。再加上每棵树的节点都会去选择不同的样本特征，经过这两步动作之后，可以完全肯定随机森林中的每棵树都不一样，这也符合我们使用随机森林的初衷</p> 
  <p>另外还有一个要强调的参数，是<code>n_estimators</code>，这个参数控制的是随机森林中决策树的数量。在随机森林构建完成之后，每棵决策树都会单独进行预测。如果是用来进行回归分析的话，随机森林会把所有决策树预测的值取平均数；如果是用来进行分类的话，在森林内部会进行"投票"，每棵树预测出数据类别的概率，比如其中一棵树说，“这瓶酒80%数据class_1”，另外一棵树说，“这瓶酒60%属于class_2”，随机森林会把这些概率取平均值，然后把样本放入概率最高的分类当中</p> 
  <p>下面我们用图像直观地看一下随机森林分类的表现，输入代码如下：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 定义图像中分区的颜色和散点的颜色</span>
cmap_light<span class="token operator">=</span>ListedColormap<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'#FFAAAA'</span><span class="token punctuation">,</span><span class="token string">'#AAFFAA'</span><span class="token punctuation">,</span><span class="token string">'#AAAAFF'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
cmap_bold<span class="token operator">=</span>ListedColormap<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'#FF0000'</span><span class="token punctuation">,</span><span class="token string">'#00FF00'</span><span class="token punctuation">,</span><span class="token string">'#0000FF'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 分别用样本的两个特征创建图像和横轴和纵轴</span>
x_min<span class="token punctuation">,</span>x_max<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>
y_min<span class="token punctuation">,</span>y_max<span class="token operator">=</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span>
xx<span class="token punctuation">,</span>yy<span class="token operator">=</span>np<span class="token punctuation">.</span>meshgrid<span class="token punctuation">(</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>x_min<span class="token punctuation">,</span>x_max<span class="token punctuation">,</span><span class="token number">.02</span><span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span>y_min<span class="token punctuation">,</span>y_max<span class="token punctuation">,</span><span class="token number">.02</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

z<span class="token operator">=</span>forest<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>np<span class="token punctuation">.</span>c_<span class="token punctuation">[</span>xx<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yy<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 给每个分类中的样本分配不同的颜色</span>
Z<span class="token operator">=</span>z<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>xx<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>pcolormesh<span class="token punctuation">(</span>xx<span class="token punctuation">,</span>yy<span class="token punctuation">,</span>Z<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap_light<span class="token punctuation">)</span>

<span class="token comment"># 用散点图把样本表示出来</span>
plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>X<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>c<span class="token operator">=</span>y<span class="token punctuation">,</span>cmap<span class="token operator">=</span>cmap_bold<span class="token punctuation">,</span>edgecolors<span class="token operator">=</span><span class="token string">'k'</span><span class="token punctuation">,</span>s<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span>xx<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>xx<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span>yy<span class="token punctuation">.</span><span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>yy<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">"Classifier:(max_depth=5)"</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <p><img src="https://cdn.nlark.com/yuque/0/2019/png/214438/1550752154956-bfdc27bb-3b95-4b3f-b7c1-0e215838e58e.png#align=left&amp;display=inline&amp;height=264&amp;linkTarget=_blank&amp;name=output_24_0.png&amp;originHeight=264&amp;originWidth=366&amp;size=24323&amp;width=366" alt="output_24_0.png"></p> 
  <h3><a id="3_328"></a>3.随机森林的优势和不足</h3> 
  <p>从优势的角度来说，随机森林集成了决策树的所有优点，而且能够弥补决策树的不足。但也不是说决策树算法就被彻底抛弃了。从便于展示决策过程的角度来说，决策树依旧表现强悍。尤其是随机森林中每棵决策树的层级要比单独的决策树更深，所以如果需要向非专业人士展示模型工作过程的话，还是需要用到决策树的</p> 
  <p>还有，随机森林算法支持并行处理。对于超大数据集来说，随机森林会比较耗时，不过我们可以用多进程并行处理的方式来解决这个问题。实现方式是调节随机森林的<code>n_jobs</code>参数，记得把<code>n_jobs</code>参数数值设为和CPU内核数一致。如果你搞不清楚自己的CPU到底就多少内核，可以设置<code>n_jobs=-1</code>，这样随机森林会使用CPU的全部内核，速度就会极大提升了</p> 
  <p>需要注意的是，因为随机森林生成每棵决策树的方法是随机的，那么不同的<code>random_state</code>参数会导致模型完全不同，所以如果不希望建模的结果太过于不稳定，一定要固化<code>random_state</code>这个参数的数值</p> 
  <p>缺点是，对于超高维数据集，稀疏数据集等来说，随机森林就有点捉襟见肘了，在这种情况下，线性模型要比随机森林的表现更好一些</p> 
  <h2><a id="_338"></a>三.随机森林实例—相亲事件</h2> 
  <p>小花的同事给她介绍了一个对象Mr-L，现在Mr-L现年37岁，在某省机关做文员工作。但是小花的择偶标准是需要对方月薪在5万以上(只是为了引入后面的内容)，但是又不好直接问Mr-L，所以拿不定主意，这时我们用决策树和随机森林</p> 
  <h3><a id="1_342"></a>1.数据集的准备</h3> 
  <p>在网站下载数据集：<a href="http://archive.ics.uci.edu/ml/machine-learning-databases/adult/" rel="nofollow">成年人数据集</a></p> 
  <p>下载好的数据集是.data格式的文件，不过不用担心，它其实就是一个csv文件，我们把它重命名为<code>adult.csv</code></p> 
  <p>下面我们载人这个数据集，输入代码如下：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 导入pandas库</span>
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token comment"># 用pd打开csv文件</span>
data<span class="token operator">=</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'adult.csv'</span><span class="token punctuation">,</span>header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>index_col<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>
                 names<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'年龄'</span><span class="token punctuation">,</span><span class="token string">'单位性质'</span><span class="token punctuation">,</span><span class="token string">'权重'</span><span class="token punctuation">,</span><span class="token string">'学历'</span><span class="token punctuation">,</span><span class="token string">'受教育时长'</span><span class="token punctuation">,</span>
                        <span class="token string">'婚姻状况'</span><span class="token punctuation">,</span><span class="token string">'职业'</span><span class="token punctuation">,</span><span class="token string">'家庭情况'</span><span class="token punctuation">,</span><span class="token string">'种族'</span><span class="token punctuation">,</span><span class="token string">'性别'</span><span class="token punctuation">,</span>
                        <span class="token string">'资产所得'</span><span class="token punctuation">,</span><span class="token string">'资产损失'</span><span class="token punctuation">,</span><span class="token string">'周工作时长'</span><span class="token punctuation">,</span><span class="token string">'原籍'</span><span class="token punctuation">,</span>
                        <span class="token string">'收入'</span>
                       <span class="token punctuation">]</span>
                <span class="token punctuation">)</span>
<span class="token comment">#为了方便展示，我们选取其中一部分数据</span>
data_list<span class="token operator">=</span>data<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'年龄'</span><span class="token punctuation">,</span><span class="token string">'单位性质'</span><span class="token punctuation">,</span><span class="token string">'学历'</span><span class="token punctuation">,</span><span class="token string">'性别'</span><span class="token punctuation">,</span><span class="token string">'周工作时长'</span><span class="token punctuation">,</span><span class="token string">'职业'</span><span class="token punctuation">,</span><span class="token string">'收入'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

display<span class="token punctuation">(</span>data_list<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <table> 
   <thead> 
    <tr> 
     <th></th> 
     <th>年龄</th> 
     <th>单位性质</th> 
     <th>学历</th> 
     <th>性别</th> 
     <th>周工作时长</th> 
     <th>职业</th> 
     <th>收入</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>0</td> 
     <td>39</td> 
     <td>State-gov</td> 
     <td>Bachelors</td> 
     <td>Male</td> 
     <td>40</td> 
     <td>Adm-clerical</td> 
     <td>&lt;=50K</td> 
    </tr> 
    <tr> 
     <td>1</td> 
     <td>50</td> 
     <td>Self-emp-not-inc</td> 
     <td>Bachelors</td> 
     <td>Male</td> 
     <td>13</td> 
     <td>Exec-managerial</td> 
     <td>&lt;=50K</td> 
    </tr> 
    <tr> 
     <td>2</td> 
     <td>38</td> 
     <td>Private</td> 
     <td>HS-grad</td> 
     <td>Male</td> 
     <td>40</td> 
     <td>Handlers-cleaners</td> 
     <td>&lt;=50K</td> 
    </tr> 
    <tr> 
     <td>3</td> 
     <td>53</td> 
     <td>Private</td> 
     <td>11th</td> 
     <td>Male</td> 
     <td>40</td> 
     <td>Handlers-cleaners</td> 
     <td>&lt;=50K</td> 
    </tr> 
    <tr> 
     <td>4</td> 
     <td>28</td> 
     <td>Private</td> 
     <td>Bachelors</td> 
     <td>Female</td> 
     <td>40</td> 
     <td>Prof-specialty</td> 
     <td>&lt;=50K</td> 
    </tr> 
   </tbody> 
  </table>
  <p><strong>注意</strong> 为了方便演示，我们只选了年龄，单位性质，学历，性别，周工作时长，职业和收入等特征</p> 
  <h3><a id="2get_dummies_379"></a>2.用get_dummies处理数据</h3> 
  <p>在这个数据集中，单位性质，学历，性别，职业还有收入都不是整型数值，而是字符串，怎么使用我们现在所学的知识进行建模呢？这里我们用到<code>pandas</code>的一个功能，叫作<code>get_dummies</code>，它可以在现有的数据集上添加虚拟变量，让数据集变成可以用的格式</p> 
  <pre><code class="prism language-python"><span class="token comment"># 使用get_dummies将文本数据转化为数值</span>
data_dummies<span class="token operator">=</span>pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>data_list<span class="token punctuation">)</span>

<span class="token comment"># 对比样本原始特征和虚拟变量特征</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"样本原始特征：\n"</span><span class="token punctuation">,</span><span class="token builtin">list</span><span class="token punctuation">(</span>data_list<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"虚拟变量特征：\n"</span><span class="token punctuation">,</span><span class="token builtin">list</span><span class="token punctuation">(</span>data_dummies<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>样本原始特征：
 ['年龄', '单位性质', '学历', '性别', '周工作时长', '职业', '收入'] 

虚拟变量特征：
 ['年龄', '周工作时长', '单位性质_ ?', '单位性质_ Federal-gov', '单位性质_ Local-gov', '单位性质_ Never-worked', '单位性质_ Private', '单位性质_ Self-emp-inc', '单位性质_ Self-emp-not-inc', '单位性质_ State-gov', '单位性质_ Without-pay', '学历_ 10th', '学历_ 11th', '学历_ 12th', '学历_ 1st-4th', '学历_ 5th-6th', '学历_ 7th-8th', '学历_ 9th', '学历_ Assoc-acdm', '学历_ Assoc-voc', '学历_ Bachelors', '学历_ Doctorate', '学历_ HS-grad', '学历_ Masters', '学历_ Preschool', '学历_ Prof-school', '学历_ Some-college', '性别_ Female', '性别_ Male', '职业_ ?', '职业_ Adm-clerical', '职业_ Armed-Forces', '职业_ Craft-repair', '职业_ Exec-managerial', '职业_ Farming-fishing', '职业_ Handlers-cleaners', '职业_ Machine-op-inspct', '职业_ Other-service', '职业_ Priv-house-serv', '职业_ Prof-specialty', '职业_ Protective-serv', '职业_ Sales', '职业_ Tech-support', '职业_ Transport-moving', '收入_ &lt;=50K', '收入_ &gt;50K']
</code></pre> 
  <p>下面我们看下进行<code>get_dummies</code>后数据集的样子，显示前5行数据：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 显示数据集中的前5行</span>
data_dummies<span class="token punctuation">.</span>head<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <table> 
   <thead> 
    <tr> 
     <th></th> 
     <th>年龄</th> 
     <th>周工作时长</th> 
     <th>单位性质_ ?</th> 
     <th>单位性质_ Federal-gov</th> 
     <th>单位性质_ Local-gov</th> 
     <th>单位性质_ Never-worked</th> 
     <th>单位性质_ Private</th> 
     <th>单位性质_ Self-emp-inc</th> 
     <th>单位性质_ Self-emp-not-inc</th> 
     <th>单位性质_ State-gov</th> 
     <th>…</th> 
     <th>职业_ Machine-op-inspct</th> 
     <th>职业_ Other-service</th> 
     <th>职业_ Priv-house-serv</th> 
     <th>职业_ Prof-specialty</th> 
     <th>职业_ Protective-serv</th> 
     <th>职业_ Sales</th> 
     <th>职业_ Tech-support</th> 
     <th>职业_ Transport-moving</th> 
     <th>收入_ &lt;=50K</th> 
     <th>收入_ &gt;50K</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>0</td> 
     <td>39</td> 
     <td>40</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>…</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
    </tr> 
    <tr> 
     <td>1</td> 
     <td>50</td> 
     <td>13</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
     <td>…</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
    </tr> 
    <tr> 
     <td>2</td> 
     <td>38</td> 
     <td>40</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>…</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
    </tr> 
    <tr> 
     <td>3</td> 
     <td>53</td> 
     <td>40</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>…</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
    </tr> 
    <tr> 
     <td>4</td> 
     <td>28</td> 
     <td>40</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>…</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>0</td> 
     <td>1</td> 
     <td>0</td> 
    </tr> 
   </tbody> 
  </table>
  <p>5 rows × 46 columns</p> 
  <p>现在我们各列分配给特征向量X和分类标签y，输入代码如下：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 定义数据集的特征值</span>
features<span class="token operator">=</span>data_dummies<span class="token punctuation">.</span>loc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token string">'年龄'</span><span class="token punctuation">:</span><span class="token string">'职业_ Transport-moving'</span><span class="token punctuation">]</span>

<span class="token comment"># 将特征数值赋值为x</span>
X<span class="token operator">=</span>features<span class="token punctuation">.</span>values

<span class="token comment"># 将收入大于50k作为预测目标</span>
y<span class="token operator">=</span>data_dummies<span class="token punctuation">[</span><span class="token string">'收入_ &gt;50K'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"特征形态：{},标签形态：{}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">,</span>y<span class="token punctuation">.</span>shape<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>特征形态：(32561, 44),标签形态：(32561,)
</code></pre> 
  <h3><a id="3_436"></a>3.用决策树建模并作出预测</h3> 
  <p>数据集共有32561条样本数据，每条数据有44个特征值，接下来将数据集拆分成训练集和测试集，然后用决策树算法进行建模，并对模型进行评估：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 将数据集拆分为训练集和测试集</span>
X_train<span class="token punctuation">,</span>X_test<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>y_test<span class="token operator">=</span>train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 用最大深度为5的随机森林拟合数据</span>
go_dating_tree<span class="token operator">=</span>tree<span class="token punctuation">.</span>DecisionTreeClassifier<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
go_dating_tree<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型得分：{:.2f}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>go_dating_tree<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span>y_test<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>模型得分：0.80
</code></pre> 
  <p>使用模型对Mr-L的收入进行预测，输入代码如下：</p> 
  <pre><code class="prism language-python"><span class="token comment"># 将Mr Z的数据输入给模型</span>
Mr<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">37</span><span class="token punctuation">,</span><span class="token number">40</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>

<span class="token comment"># 使用模型做出预测</span>
dating_dec<span class="token operator">=</span>go_dating_tree<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>Mr<span class="token punctuation">)</span>

<span class="token keyword">if</span> dating_dec<span class="token operator">==</span><span class="token number">1</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"大胆追求真爱，这人月薪过5万"</span><span class="token punctuation">)</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"不用去了，不满足"</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>不用去了，不满足
</code></pre> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
