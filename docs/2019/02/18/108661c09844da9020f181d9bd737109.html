<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>注意力机制（二）——在计算机视觉中的应用 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="注意力机制（二）——在计算机视觉中的应用" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="惯例，除了蓝字都不是我写的。 在计算机视觉里attention应用在目标检测、语义分割等方面。在之前的机器翻译里提到了CNN的特点，图像领域最常用的就是CNN方法。 Non-local Neural Networks Local这个词主要是针对感受野(receptive field)来说的。以卷积操作为例，它的感受野大小就是卷积核大小，而我们一般都选用3*3，5*5之类的卷积核，它们只考虑局部区域，因此都是local的运算。全连接就是non-local的，而且是global的。但是全连接带来了大量的参数，给优化带来困难。 提出问题：CNN事实上只能获取局部信息，是通过层叠来增大感受野，在某一时刻只能处理一个局部区域。想要捕捉long-range dependencies(此处range可理解为time、distance)，就只能重复地执行上述操作，通过数据逐步传递信号。 这样会导致：1.计算量大 2.优化困难，需要小心处理 3.难以构建multihop dependency model(多跳依赖模型)。 解决方法：本文提出非局部模块来捕捉long-range依赖，计算所有位置上特征的的加权和来作为对应位置的响应。这组位置可以是空间、时间或者时空坐标上的，这也就意味着这种泛化的非局部操作可以应用于图片、序列和视频问题。 特点： 1、non-local操作不考虑时空距离，而是通过直接计算两个位置间的交互来捕捉long-range依赖 这里模糊了欧式距离 这种计算方法其实就是求自相关矩阵，只不过是泛化的自相关矩阵. 2、non-local操作高效，只需少量几层就能实现很好的效果（non-local neural networks比现有的2D和3D convolutional networks的视频分类精度高） 3、non-local操作维持变量输入原先的大小，因此能方便地与其他操作相结合（因为pixel-pixel计算开销比较大，所以使用在 Mask R-CNN的基础上应用non-local block） 理念： 只在高阶语义层中引入non-local layer或者通过对embedding( )的结果加pooling层来减少计算量 &nbsp; x为输入信号，可以是图片、序列或者视频，通常是它们的特征；x_i是一个向量，维数跟x的channel数一样 self-attention y为输出信号，与x相同尺寸； i和j是位置的索引，它可以是空间、时间或者时空上的位置 g是一个映射函数，将一个点映射成一个向量，可以看成是计算一个点的特征。 f(a,b)函数用于计算a与b之间关系的相关 C(x)为正规化因子 以图像为例，为了简化问题，作者简单地设置g函数为一个1*1的卷积，其实就是对原图做了一个线性变换。相似性度量函数f的选择有多种。 Gaussian: Embedded Gaussian: Dot Product: Concatenation: ，这相当于embedded的两个点拼接作为带ReLU激活函数全连接层的输入。它在visual reasoning中用的比较多。 &nbsp; 为了能让non-local操作作为一个组件，可以直接插入任意的神经网络中，作者把non-local设计成residual block的形式，让non-local操作去学x的residual： Wz实际上是一个卷积操作，它的输出channel数跟x一致。这样以来，non-local操作就可以作为一个组件，组装到任意卷积神经网络中 具体实现 原文考虑的是T帧的视频为例，这里以一个batch的图像、f选为embedded Gaussian为例，对于其他形式的相似性度量，可以类似地化为矩阵操作。 如果在尺寸很大的输入上应用non-local layer，也是计算量很大的。后者的解决方案是，只在高阶语义层中引入non-local layer。还可以通过对embedding( )的结果加pooling层来进一步地减少计算量。 对于前者，注意到f的计算可以化为矩阵运算，我们实际上可以将整个non-local化为矩阵乘法运算+卷积运算。如下图所示，其中oc为output_channels，卷积操作的输出filter数量。 &nbsp; 比较： 1、跟全连接层的联系 我们知道，non-local block利用两个点的相似性对每个位置的特征做加权，而全连接层则是利用position-related的weight对每个位置做加权。于是，全连接层可以看成non-local block的一个特例： 任意两点的相似性仅跟两点的位置有关，而与两点的具体坐标无关，即 g是identity函数， 归一化系数为1。归一化系数跟输入无关，全连接层不能处理任意尺寸的输入。 2、跟机器翻译的Self-attention的联系 non-local block主要是一个non-local均值计算，具体的算法方法如下公式（1）： 同样，下面给出了机器翻译中的Self Attention的具体计算公式： 通过对比公式(2)和公式(1)可以发现，当公式(1)中的f函数具体化为softmax，C(x)操作赋值为Xj维度的开根号时，两个公式是等价的。此时可以看出，f函数中的Xi变量等价于公式(2)中的Q，Xj等价于K，g函数中的Xj等价于变量V。 &nbsp; 本文里Embedded Gaussian: Embedding的1*1卷积操作可以看成矩阵乘法： 于是， &nbsp;&nbsp; 图像的embedding层 我们把一个12个元素的矩阵变成6个元素的矩阵，直观上大小缩小了一半 embedding层，在某种程度上，就是用来降维的，降维的原理就是矩阵乘法。在卷积网络中，可以理解为特殊全连接层操作，跟1x1卷积核异曲同工 假如我们有一个100W X10W的矩阵，用它乘上一个10W X 20的矩阵，我们可以把它降到100W X 20，这就是嵌入层的一个作用——降维。然后中间那个10W X 20的矩阵，可以理解为查询表，也可以理解为映射表，也可以理解为过度表 embedding可以降维，当然可以升维。对低维的数据进行升维时，可能把一些其他特征放大了，或者把笼统的特征分开了。 --------------------- 作者：罗大黑 来源：CSDN 原文：https://blog.csdn.net/weixin_42078618/article/details/82999906 原文来源 non-local 笔记 https://zhuanlan.zhihu.com/p/52510471&nbsp; https://zhuanlan.zhihu.com/p/33345791 https://zhuanlan.zhihu.com/p/53155423" />
<meta property="og:description" content="惯例，除了蓝字都不是我写的。 在计算机视觉里attention应用在目标检测、语义分割等方面。在之前的机器翻译里提到了CNN的特点，图像领域最常用的就是CNN方法。 Non-local Neural Networks Local这个词主要是针对感受野(receptive field)来说的。以卷积操作为例，它的感受野大小就是卷积核大小，而我们一般都选用3*3，5*5之类的卷积核，它们只考虑局部区域，因此都是local的运算。全连接就是non-local的，而且是global的。但是全连接带来了大量的参数，给优化带来困难。 提出问题：CNN事实上只能获取局部信息，是通过层叠来增大感受野，在某一时刻只能处理一个局部区域。想要捕捉long-range dependencies(此处range可理解为time、distance)，就只能重复地执行上述操作，通过数据逐步传递信号。 这样会导致：1.计算量大 2.优化困难，需要小心处理 3.难以构建multihop dependency model(多跳依赖模型)。 解决方法：本文提出非局部模块来捕捉long-range依赖，计算所有位置上特征的的加权和来作为对应位置的响应。这组位置可以是空间、时间或者时空坐标上的，这也就意味着这种泛化的非局部操作可以应用于图片、序列和视频问题。 特点： 1、non-local操作不考虑时空距离，而是通过直接计算两个位置间的交互来捕捉long-range依赖 这里模糊了欧式距离 这种计算方法其实就是求自相关矩阵，只不过是泛化的自相关矩阵. 2、non-local操作高效，只需少量几层就能实现很好的效果（non-local neural networks比现有的2D和3D convolutional networks的视频分类精度高） 3、non-local操作维持变量输入原先的大小，因此能方便地与其他操作相结合（因为pixel-pixel计算开销比较大，所以使用在 Mask R-CNN的基础上应用non-local block） 理念： 只在高阶语义层中引入non-local layer或者通过对embedding( )的结果加pooling层来减少计算量 &nbsp; x为输入信号，可以是图片、序列或者视频，通常是它们的特征；x_i是一个向量，维数跟x的channel数一样 self-attention y为输出信号，与x相同尺寸； i和j是位置的索引，它可以是空间、时间或者时空上的位置 g是一个映射函数，将一个点映射成一个向量，可以看成是计算一个点的特征。 f(a,b)函数用于计算a与b之间关系的相关 C(x)为正规化因子 以图像为例，为了简化问题，作者简单地设置g函数为一个1*1的卷积，其实就是对原图做了一个线性变换。相似性度量函数f的选择有多种。 Gaussian: Embedded Gaussian: Dot Product: Concatenation: ，这相当于embedded的两个点拼接作为带ReLU激活函数全连接层的输入。它在visual reasoning中用的比较多。 &nbsp; 为了能让non-local操作作为一个组件，可以直接插入任意的神经网络中，作者把non-local设计成residual block的形式，让non-local操作去学x的residual： Wz实际上是一个卷积操作，它的输出channel数跟x一致。这样以来，non-local操作就可以作为一个组件，组装到任意卷积神经网络中 具体实现 原文考虑的是T帧的视频为例，这里以一个batch的图像、f选为embedded Gaussian为例，对于其他形式的相似性度量，可以类似地化为矩阵操作。 如果在尺寸很大的输入上应用non-local layer，也是计算量很大的。后者的解决方案是，只在高阶语义层中引入non-local layer。还可以通过对embedding( )的结果加pooling层来进一步地减少计算量。 对于前者，注意到f的计算可以化为矩阵运算，我们实际上可以将整个non-local化为矩阵乘法运算+卷积运算。如下图所示，其中oc为output_channels，卷积操作的输出filter数量。 &nbsp; 比较： 1、跟全连接层的联系 我们知道，non-local block利用两个点的相似性对每个位置的特征做加权，而全连接层则是利用position-related的weight对每个位置做加权。于是，全连接层可以看成non-local block的一个特例： 任意两点的相似性仅跟两点的位置有关，而与两点的具体坐标无关，即 g是identity函数， 归一化系数为1。归一化系数跟输入无关，全连接层不能处理任意尺寸的输入。 2、跟机器翻译的Self-attention的联系 non-local block主要是一个non-local均值计算，具体的算法方法如下公式（1）： 同样，下面给出了机器翻译中的Self Attention的具体计算公式： 通过对比公式(2)和公式(1)可以发现，当公式(1)中的f函数具体化为softmax，C(x)操作赋值为Xj维度的开根号时，两个公式是等价的。此时可以看出，f函数中的Xi变量等价于公式(2)中的Q，Xj等价于K，g函数中的Xj等价于变量V。 &nbsp; 本文里Embedded Gaussian: Embedding的1*1卷积操作可以看成矩阵乘法： 于是， &nbsp;&nbsp; 图像的embedding层 我们把一个12个元素的矩阵变成6个元素的矩阵，直观上大小缩小了一半 embedding层，在某种程度上，就是用来降维的，降维的原理就是矩阵乘法。在卷积网络中，可以理解为特殊全连接层操作，跟1x1卷积核异曲同工 假如我们有一个100W X10W的矩阵，用它乘上一个10W X 20的矩阵，我们可以把它降到100W X 20，这就是嵌入层的一个作用——降维。然后中间那个10W X 20的矩阵，可以理解为查询表，也可以理解为映射表，也可以理解为过度表 embedding可以降维，当然可以升维。对低维的数据进行升维时，可能把一些其他特征放大了，或者把笼统的特征分开了。 --------------------- 作者：罗大黑 来源：CSDN 原文：https://blog.csdn.net/weixin_42078618/article/details/82999906 原文来源 non-local 笔记 https://zhuanlan.zhihu.com/p/52510471&nbsp; https://zhuanlan.zhihu.com/p/33345791 https://zhuanlan.zhihu.com/p/53155423" />
<link rel="canonical" href="https://mlh.app/2019/02/18/108661c09844da9020f181d9bd737109.html" />
<meta property="og:url" content="https://mlh.app/2019/02/18/108661c09844da9020f181d9bd737109.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-18T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"惯例，除了蓝字都不是我写的。 在计算机视觉里attention应用在目标检测、语义分割等方面。在之前的机器翻译里提到了CNN的特点，图像领域最常用的就是CNN方法。 Non-local Neural Networks Local这个词主要是针对感受野(receptive field)来说的。以卷积操作为例，它的感受野大小就是卷积核大小，而我们一般都选用3*3，5*5之类的卷积核，它们只考虑局部区域，因此都是local的运算。全连接就是non-local的，而且是global的。但是全连接带来了大量的参数，给优化带来困难。 提出问题：CNN事实上只能获取局部信息，是通过层叠来增大感受野，在某一时刻只能处理一个局部区域。想要捕捉long-range dependencies(此处range可理解为time、distance)，就只能重复地执行上述操作，通过数据逐步传递信号。 这样会导致：1.计算量大 2.优化困难，需要小心处理 3.难以构建multihop dependency model(多跳依赖模型)。 解决方法：本文提出非局部模块来捕捉long-range依赖，计算所有位置上特征的的加权和来作为对应位置的响应。这组位置可以是空间、时间或者时空坐标上的，这也就意味着这种泛化的非局部操作可以应用于图片、序列和视频问题。 特点： 1、non-local操作不考虑时空距离，而是通过直接计算两个位置间的交互来捕捉long-range依赖 这里模糊了欧式距离 这种计算方法其实就是求自相关矩阵，只不过是泛化的自相关矩阵. 2、non-local操作高效，只需少量几层就能实现很好的效果（non-local neural networks比现有的2D和3D convolutional networks的视频分类精度高） 3、non-local操作维持变量输入原先的大小，因此能方便地与其他操作相结合（因为pixel-pixel计算开销比较大，所以使用在 Mask R-CNN的基础上应用non-local block） 理念： 只在高阶语义层中引入non-local layer或者通过对embedding( )的结果加pooling层来减少计算量 &nbsp; x为输入信号，可以是图片、序列或者视频，通常是它们的特征；x_i是一个向量，维数跟x的channel数一样 self-attention y为输出信号，与x相同尺寸； i和j是位置的索引，它可以是空间、时间或者时空上的位置 g是一个映射函数，将一个点映射成一个向量，可以看成是计算一个点的特征。 f(a,b)函数用于计算a与b之间关系的相关 C(x)为正规化因子 以图像为例，为了简化问题，作者简单地设置g函数为一个1*1的卷积，其实就是对原图做了一个线性变换。相似性度量函数f的选择有多种。 Gaussian: Embedded Gaussian: Dot Product: Concatenation: ，这相当于embedded的两个点拼接作为带ReLU激活函数全连接层的输入。它在visual reasoning中用的比较多。 &nbsp; 为了能让non-local操作作为一个组件，可以直接插入任意的神经网络中，作者把non-local设计成residual block的形式，让non-local操作去学x的residual： Wz实际上是一个卷积操作，它的输出channel数跟x一致。这样以来，non-local操作就可以作为一个组件，组装到任意卷积神经网络中 具体实现 原文考虑的是T帧的视频为例，这里以一个batch的图像、f选为embedded Gaussian为例，对于其他形式的相似性度量，可以类似地化为矩阵操作。 如果在尺寸很大的输入上应用non-local layer，也是计算量很大的。后者的解决方案是，只在高阶语义层中引入non-local layer。还可以通过对embedding( )的结果加pooling层来进一步地减少计算量。 对于前者，注意到f的计算可以化为矩阵运算，我们实际上可以将整个non-local化为矩阵乘法运算+卷积运算。如下图所示，其中oc为output_channels，卷积操作的输出filter数量。 &nbsp; 比较： 1、跟全连接层的联系 我们知道，non-local block利用两个点的相似性对每个位置的特征做加权，而全连接层则是利用position-related的weight对每个位置做加权。于是，全连接层可以看成non-local block的一个特例： 任意两点的相似性仅跟两点的位置有关，而与两点的具体坐标无关，即 g是identity函数， 归一化系数为1。归一化系数跟输入无关，全连接层不能处理任意尺寸的输入。 2、跟机器翻译的Self-attention的联系 non-local block主要是一个non-local均值计算，具体的算法方法如下公式（1）： 同样，下面给出了机器翻译中的Self Attention的具体计算公式： 通过对比公式(2)和公式(1)可以发现，当公式(1)中的f函数具体化为softmax，C(x)操作赋值为Xj维度的开根号时，两个公式是等价的。此时可以看出，f函数中的Xi变量等价于公式(2)中的Q，Xj等价于K，g函数中的Xj等价于变量V。 &nbsp; 本文里Embedded Gaussian: Embedding的1*1卷积操作可以看成矩阵乘法： 于是， &nbsp;&nbsp; 图像的embedding层 我们把一个12个元素的矩阵变成6个元素的矩阵，直观上大小缩小了一半 embedding层，在某种程度上，就是用来降维的，降维的原理就是矩阵乘法。在卷积网络中，可以理解为特殊全连接层操作，跟1x1卷积核异曲同工 假如我们有一个100W X10W的矩阵，用它乘上一个10W X 20的矩阵，我们可以把它降到100W X 20，这就是嵌入层的一个作用——降维。然后中间那个10W X 20的矩阵，可以理解为查询表，也可以理解为映射表，也可以理解为过度表 embedding可以降维，当然可以升维。对低维的数据进行升维时，可能把一些其他特征放大了，或者把笼统的特征分开了。 --------------------- 作者：罗大黑 来源：CSDN 原文：https://blog.csdn.net/weixin_42078618/article/details/82999906 原文来源 non-local 笔记 https://zhuanlan.zhihu.com/p/52510471&nbsp; https://zhuanlan.zhihu.com/p/33345791 https://zhuanlan.zhihu.com/p/53155423","@type":"BlogPosting","url":"https://mlh.app/2019/02/18/108661c09844da9020f181d9bd737109.html","headline":"注意力机制（二）——在计算机视觉中的应用","dateModified":"2019-02-18T00:00:00+08:00","datePublished":"2019-02-18T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/02/18/108661c09844da9020f181d9bd737109.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>注意力机制（二）——在计算机视觉中的应用</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p><span style="color:#3399ea;">惯例，除了蓝字都不是我写的。</span></p> 
  <p><span style="color:#3399ea;">在计算机视觉里attention应用在目标检测、语义分割等方面。在之前的机器翻译里提到了CNN的特点，图像领域最常用的就是CNN方法。</span></p> 
  <h2>Non-local Neural Networks</h2> 
  <p>Local这个词主要是针对感受野(receptive field)来说的。以卷积操作为例，它的感受野大小就是卷积核大小，而我们一般都选用3*3，5*5之类的卷积核，它们只考虑局部区域，因此都是local的运算。全连接就是non-local的，而且是global的。但是全连接带来了大量的参数，给优化带来困难。</p> 
  <p><strong>提出问题：</strong>CNN事实上只能获取局部信息，是通过层叠来增大感受野，在某一时刻只能处理一个局部区域。想要捕捉long-range dependencies(此处range可理解为time、distance)，就只能重复地执行上述操作，通过数据逐步传递信号。</p> 
  <p>这样会导致：1.计算量大 2.优化困难，需要小心处理 3.难以构建multihop dependency model(多跳依赖模型)。</p> 
  <p><strong>解决方法：</strong>本文提出非局部模块来捕捉long-range依赖，计算所有位置上特征的的加权和来作为对应位置的响应。这组位置可以是空间、时间或者时空坐标上的，这也就意味着这种泛化的非局部操作可以应用于图片、序列和视频问题。</p> 
  <p><strong>特点：</strong></p> 
  <p>1、non-local操作不考虑时空距离，而是通过直接计算两个位置间的交互来捕捉long-range依赖 <span style="color:#3399ea;">这里模糊了欧式距离 </span>这种计算方法其实就是求<span style="color:#86ca5e;">自相关矩阵</span>，只不过是泛化的自相关矩阵.</p> 
  <p>2、non-local操作高效，只需少量几层就能实现很好的效果（non-local neural networks比现有的2D和3D convolutional networks的视频分类精度高）</p> 
  <p>3、non-local操作维持变量输入原先的大小，因此能方便地与其他操作相结合（<span style="color:#3399ea;">因为pixel-pixel计算开销比较大，所以使用在 Mask R-CNN的基础上应用non-local block</span>）</p> 
  <p><strong>理念：</strong></p> 
  <p>只在高阶语义层中引入non-local layer或者通过对embedding( <img alt="\theta, \phi" class="has" src="https://www.zhihu.com/equation?tex=%5Ctheta%2C+%5Cphi"> )的结果加pooling层来减少计算量</p> 
  <p>&nbsp;</p> 
  <p><img alt="" class="has" height="82" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190218192805837.png" width="314"></p> 
  <ul>
   <li>x为输入信号，可以是图片、序列或者视频，通常是它们的特征；x_i是一个向量，维数跟x的channel数一样<span style="color:#3399ea;"> self-attention</span></li> 
   <li>y为输出信号，与x相同尺寸；</li> 
   <li>i和j是位置的索引，它可以是空间、时间或者时空上的位置</li> 
   <li>g是一个映射函数，将一个点映射成一个向量，可以看成是计算一个点的特征。</li> 
   <li>f(a,b)函数用于计算a与b之间关系的相关</li> 
   <li>C(x)为正规化因子</li> 
  </ul>
  <p><img alt="" class="has" height="439" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190218193104183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXdhbnNodQ==,size_16,color_FFFFFF,t_70" width="697"></p> 
  <p>以图像为例，为了简化问题，作者简单地设置g函数为一个1*1的卷积，<span style="color:#3399ea;">其实就是对原图做了一个线性变换</span>。相似性度量函数f的选择有多种。</p> 
  <ul>
   <li>Gaussian: <img alt="f(\mathbb{x}_i, \mathbb{x}_j)=e^{\mathbb{x}_i^T \cdot \mathbb{x}_j}, \mathcal{C}(x)=\sum_{\forall j} f(\mathbb{x}_i, \mathbb{x}_j)" class="has" src="https://www.zhihu.com/equation?tex=f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29%3De%5E%7B%5Cmathbb%7Bx%7D_i%5ET+%5Ccdot+%5Cmathbb%7Bx%7D_j%7D%2C+%5Cmathcal%7BC%7D%28x%29%3D%5Csum_%7B%5Cforall+j%7D+f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29"></li> 
   <li>Embedded Gaussian: <img alt="f(\mathbb{x}_i, \mathbb{x}_j)=e^{\theta(\mathbb{x}_i)^T \cdot \phi(\mathbb{x}_j)}, \mathcal{C}(x)=\sum_{\forall j} f(\mathbb{x}_i, \mathbb{x}_j)" class="has" src="https://www.zhihu.com/equation?tex=f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29%3De%5E%7B%5Ctheta%28%5Cmathbb%7Bx%7D_i%29%5ET+%5Ccdot+%5Cphi%28%5Cmathbb%7Bx%7D_j%29%7D%2C+%5Cmathcal%7BC%7D%28x%29%3D%5Csum_%7B%5Cforall+j%7D+f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29"></li> 
   <li>Dot Product: <img alt="f(\mathbb{x}_i, \mathbb{x}_j)=\theta(\mathbb{x}_i)^T \cdot \phi(\mathbb{x}_j), \mathcal{C}(x)=|\{i|i \text{ is a valid index of } \mathbb{x}\}|" class="has" src="https://www.zhihu.com/equation?tex=f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29%3D%5Ctheta%28%5Cmathbb%7Bx%7D_i%29%5ET+%5Ccdot+%5Cphi%28%5Cmathbb%7Bx%7D_j%29%2C+%5Cmathcal%7BC%7D%28x%29%3D%7C%5C%7Bi%7Ci+%5Ctext%7B+is+a+valid+index+of+%7D+%5Cmathbb%7Bx%7D%5C%7D%7C"></li> 
   <li>Concatenation: <img alt="f(\mathbb{x}_i, \mathbb{x}_j)=\text{ReLU}(\mathbb{w}_f^T \cdot [\theta(\mathbb{x}_i), \phi(\mathbb{x}_j)]), \mathcal{C}(x)=|\{i|i \text{ is a valid index of } \mathbb{x}\}|" class="has" src="https://www.zhihu.com/equation?tex=f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29%3D%5Ctext%7BReLU%7D%28%5Cmathbb%7Bw%7D_f%5ET+%5Ccdot+%5B%5Ctheta%28%5Cmathbb%7Bx%7D_i%29%2C+%5Cphi%28%5Cmathbb%7Bx%7D_j%29%5D%29%2C+%5Cmathcal%7BC%7D%28x%29%3D%7C%5C%7Bi%7Ci+%5Ctext%7B+is+a+valid+index+of+%7D+%5Cmathbb%7Bx%7D%5C%7D%7C"> ，这相当于embedded的两个点拼接作为带ReLU激活函数全连接层的输入。它在visual reasoning中用的比较多。</li> 
  </ul>
  <p>&nbsp;</p> 
  <p>为了能让non-local操作作为一个组件，可以直接插入任意的神经网络中，作者把non-local设计成residual block的形式，让non-local操作去学x的residual：</p> 
  <p><img alt="" class="has" height="29" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190218193310519.png" width="185"></p> 
  <p>Wz实际上是一个卷积操作，它的输出channel数跟x一致。这样以来，non-local操作就可以作为一个组件，组装到任意卷积神经网络中</p> 
  <p><strong>具体实现</strong></p> 
  <p>原文考虑的是T帧的视频为例，这里以一个batch的图像、f选为embedded Gaussian为例，对于其他形式的相似性度量，可以类似地化为矩阵操作。</p> 
  <p>如果在尺寸很大的输入上应用non-local layer，也是计算量很大的。后者的解决方案是，只在高阶语义层中引入non-local layer。还可以通过对embedding( <img alt="\theta, \phi" class="has" src="https://www.zhihu.com/equation?tex=%5Ctheta%2C+%5Cphi"> )的结果加pooling层来进一步地减少计算量。</p> 
  <p>对于前者，注意到f的计算可以化为矩阵运算，我们实际上可以将整个non-local化为矩阵乘法运算+卷积运算。如下图所示，其中oc为output_channels，卷积操作的输出filter数量。</p> 
  <p><img alt="" class="has" height="509" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190218205634630.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXdhbnNodQ==,size_16,color_FFFFFF,t_70" width="655"></p> 
  <p>&nbsp;</p> 
  <p><strong>比较：</strong></p> 
  <p>1、<strong>跟全连接层的联系</strong></p> 
  <p>我们知道，non-local block利用两个点的相似性对每个位置的特征做加权，而全连接层则是利用<span style="color:#86ca5e;">position-related的weight对每个位置做加权</span>。于是，全连接层可以看成non-local block的一个<span style="color:#86ca5e;">特例</span>：</p> 
  <ul>
   <li>任意两点的相似性<span style="color:#86ca5e;">仅跟两点的位置有关</span>，而与两点的<span style="color:#86ca5e;">具体坐标无关</span>，即 <img alt="f(\mathbb{x}_i, \mathbb{x}_j)=w_{ij}" class="has" src="https://www.zhihu.com/equation?tex=f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29%3Dw_%7Bij%7D"></li> 
   <li><span style="color:#86ca5e;">g是identity函数</span>， <img alt="g(\mathbb{x}_i)=\mathbb{x}_i" class="has" src="https://www.zhihu.com/equation?tex=g%28%5Cmathbb%7Bx%7D_i%29%3D%5Cmathbb%7Bx%7D_i"></li> 
   <li><span style="color:#86ca5e;">归一化系数为1</span>。归一化系数跟输入无关，全连接层不能处理任意尺寸的输入。</li> 
  </ul>
  <p><strong>2、跟机器翻译的Self-attention的联系</strong><br> non-local block主要是一个non-local均值计算，具体的算法方法如下公式（1）：</p> 
  <p><img alt="" class="has" src="https://pic4.zhimg.com/80/v2-7c6b3cc02a494e24fcb44dd4cd9298af_hd.jpg" width="714"></p> 
  <p>同样，下面给出了机器翻译中的Self Attention的具体计算公式：</p> 
  <p><img alt="" class="has" height="76" src="https://pic3.zhimg.com/80/v2-7bbcb1c828cb2f0426d3465ed85fa502_hd.jpg" width="730"></p> 
  <p>通过对比公式(2)和公式(1)可以发现，当公式(1)中的f函数具体化为softmax，C(x)操作赋值为Xj维度的开根号时，两个公式是等价的。此时可以看出，<span style="color:#86ca5e;">f函数中的Xi变量等价于公式(2)中的Q，Xj等价于K，g函数中的Xj等价于变量V</span>。</p> 
  <p>&nbsp;</p> 
  <p>本文里Embedded Gaussian: <img alt="f(\mathbb{x}_i, \mathbb{x}_j)=e^{\theta(\mathbb{x}_i)^T \cdot \phi(\mathbb{x}_j)}, \mathcal{C}(x)=\sum_{\forall j} f(\mathbb{x}_i, \mathbb{x}_j)" class="has" src="https://www.zhihu.com/equation?tex=f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29%3De%5E%7B%5Ctheta%28%5Cmathbb%7Bx%7D_i%29%5ET+%5Ccdot+%5Cphi%28%5Cmathbb%7Bx%7D_j%29%7D%2C+%5Cmathcal%7BC%7D%28x%29%3D%5Csum_%7B%5Cforall+j%7D+f%28%5Cmathbb%7Bx%7D_i%2C+%5Cmathbb%7Bx%7D_j%29"></p> 
  <p>Embedding的1*1卷积操作可以看成矩阵乘法：</p> 
  <p><img alt="\theta(\mathbb{x}_i)= W_{\theta} \cdot \mathbb{x}_i; \quad \phi(\mathbb{x}_j)=W_{\phi} \cdot \mathbb{x}_j \quad \Rightarrow \quad \theta(\mathbb{x})= W_{\theta} \cdot \mathbb{x}; \quad \phi(\mathbb{x})= W_{\phi} \cdot \mathbb{x}" class="has" src="https://www.zhihu.com/equation?tex=%5Ctheta%28%5Cmathbb%7Bx%7D_i%29%3D+W_%7B%5Ctheta%7D+%5Ccdot+%5Cmathbb%7Bx%7D_i%3B+%5Cquad+%5Cphi%28%5Cmathbb%7Bx%7D_j%29%3DW_%7B%5Cphi%7D+%5Ccdot+%5Cmathbb%7Bx%7D_j+%5Cquad+%5CRightarrow+%5Cquad+%5Ctheta%28%5Cmathbb%7Bx%7D%29%3D+W_%7B%5Ctheta%7D+%5Ccdot+%5Cmathbb%7Bx%7D%3B+%5Cquad+%5Cphi%28%5Cmathbb%7Bx%7D%29%3D+W_%7B%5Cphi%7D+%5Ccdot+%5Cmathbb%7Bx%7D"></p> 
  <p>于是，</p> 
  <p><img alt="y=\text{softmax}(\mathbb{x}^T \cdot W_{\theta}^T \cdot W_\phi \cdot \mathbb{x}) \cdot g(\mathbb{x})" class="has" src="https://www.zhihu.com/equation?tex=y%3D%5Ctext%7Bsoftmax%7D%28%5Cmathbb%7Bx%7D%5ET+%5Ccdot+W_%7B%5Ctheta%7D%5ET+%5Ccdot+W_%5Cphi+%5Ccdot+%5Cmathbb%7Bx%7D%29+%5Ccdot+g%28%5Cmathbb%7Bx%7D%29">&nbsp;&nbsp;</p> 
  <blockquote> 
   <p><strong>图像的embedding层</strong></p> 
   <p><img alt="" class="has" height="130" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190218203959922.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXdhbnNodQ==,size_16,color_FFFFFF,t_70" width="430"></p> 
   <p>我们把一个12个元素的矩阵变成6个元素的矩阵，直观上大小缩小了一半</p> 
   <p>embedding层，在某种程度上，就是用来降维的，降维的原理就是矩阵乘法。在卷积网络中，可以理解为特殊全连接层操作，跟1x1卷积核异曲同工</p> 
   <p>假如我们有一个100W X10W的矩阵，用它乘上一个10W X 20的矩阵，我们可以把它降到100W X 20，这就是嵌入层的一个作用——降维。然后中间那个10W X 20的矩阵，可以理解为查询表，也可以理解为映射表，也可以理解为过度表</p> 
   <p>embedding可以降维，当然可以升维。对低维的数据进行升维时，可能把一些其他特征放大了，或者把笼统的特征分开了。</p> 
   <p><br> ---------------------<br> 作者：罗大黑<br> 来源：CSDN<br> 原文：https://blog.csdn.net/weixin_42078618/article/details/82999906</p> 
  </blockquote> 
  <p><strong>原文来源</strong></p> 
  <p>non-local 笔记 <a href="https://zhuanlan.zhihu.com/p/52510471" rel="nofollow">https://zhuanlan.zhihu.com/p/52510471&nbsp; </a><a href="https://zhuanlan.zhihu.com/p/33345791" rel="nofollow">https://zhuanlan.zhihu.com/p/33345791 </a><a href="https://zhuanlan.zhihu.com/p/53155423" rel="nofollow">https://zhuanlan.zhihu.com/p/53155423</a></p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
