<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>SVM支持向量机–sklearn研究 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="SVM支持向量机–sklearn研究" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/a19990412/article/details/87896639 Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. 支持向量机（SVM）是一组有监督学习方法，被用于分类，回归和边界探测 支持向量机有以下的几个优点： Effective in high dimensional spaces. 在高维空间有效性 Still effective in cases where number of dimensions is greater than the number of samples. 在维度数量大于样本数量的时候仍然有效 Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient. 再决策函数上（支持向量）使用训练点的一个子集，因此内存有效性（占用的空间小） Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels. 多功能的：不同的核函数，可以被特别的用于决策函数，普通的核被提供，但是这仍然可能去特异化核函数。 支持向量机也有下面的这些缺点： If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial. 如果特征的数量远比样本的数量要大，选择核函数和正则化余项在避免过拟合上是至关重要的。 SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below). 支持向量机们不直接提供概率估计，而是用耗费时间的5-fold 交叉验证来计算的。 sklearn中的支持向量机同时支持dense（密集）和 sparse（稀疏）的样本数据作为输入。但是，如果是在稀疏的数据上做预测，那么一定也是要在稀疏的数据上做训练才行。 分类 SVC, NuSVC and LinearSVC are classes capable of performing multi-class classification on a dataset. SVC，NuSVC 和LinearSVC是一类在数据集上有能力去实现多类分类的分类器。 SVC and NuSVC are similar methods, but accept slightly different sets of parameters and have different mathematical formulations (see section Mathematical formulation). On the other hand, LinearSVC is another implementation of Support Vector Classification for the case of a linear kernel. SVC和NuSVC是比较类似的方法，但是在接受的参数上有轻微的不同，同时也有不同的数学表达式。 LinearSVC是对于另一种针对于线性核情况的支持向量机分类器的实现 注意： LinearSVC不接受key wordkernal，因为被假设为线性了的。同时相比于SVC和NuSVC也缺少了一些方法，例如：support_方法 SVC，NuSVC和LinearSVC都一样，接受两个输入X（[n_samples, n_features]）和 y ([n_samples] )。前者表示样本特征，后者表示样本标签，用于训练。 简单测试 &gt;&gt;&gt; from sklearn import svm D:\SoftWare\Python\lib\site-packages\sklearn\externals\joblib\externals\cloudpickle\cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module&#39;s documentation for alternative uses import imp &gt;&gt;&gt; X = [[0, 1], [1, 0]] &gt;&gt;&gt; y = [0, 1] &gt;&gt;&gt; clf = svm.SVC(gamma=&#39;scale&#39;) &gt;&gt;&gt; clf.fit(X, y) SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) 测试也很简单 &gt;&gt;&gt; data = [[0 for i in range(2)] for j in range(2)] &gt;&gt;&gt; data [[0, 0], [0, 0]] &gt;&gt;&gt; for i in range(2): ... for j in range(2): ... data[i][j] = clf.predict([[i , j]])[0] ... &gt;&gt;&gt; data [[1, 0], [1, 1]] 多类分类 svc和NuSVC提供了一种“一对一”的方式来实现多类分类。如果n_class是类的数量的话，那么n_class * (n_class - 1) / 2 个分类器被建立，来不同的两个类别之间的相互区分。 To provide a consistent interface with other classifiers, the decision_function_shape option allows to aggregate the results of the “one-against-one” classifiers to a decision function of shape (n_samples, n_classes): 为了提供一个和其他分类器一致性的接口，这这个 decision_function_shape 选项，允许去累积这个“1对1”的分类器们去一个决策函数的shape 例如： &gt;&gt;&gt; X = [[0], [1], [2], [3]] &gt;&gt;&gt; Y = [0, 1, 2, 3] &gt;&gt;&gt; clf = svm.SVC(gamma=&#39;scale&#39;, decision_function_shape=&#39;ovo&#39;) &gt;&gt;&gt; clf.fit(X, Y) SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovo&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) &gt;&gt;&gt; dec = clf.decision_function([[1]]) &gt;&gt;&gt; dec.shape[1] 6 &gt;&gt;&gt; clf.decision_function_shape = &#39;ovr&#39; &gt;&gt;&gt; dec = clf.decision_function([[1]]) &gt;&gt;&gt; dec.shape[1] 4 &gt;&gt;&gt; dec array([[ 1.95120255, 3.5 , 0.95120255, -0.4024051 ]]) &gt;&gt;&gt; clf SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) On the other hand, LinearSVC implements “one-vs-the-rest” multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained: 另一方面，LinearSVC 实现了一个“One-vs-the-rest”的多类分类方式，因此，训练n_class个模型。如果这只有两个类别，那就只有一个模型被训练。（注意最后的这个强调，这是一种特殊的情况，因为one和the rest是重复的~） 非均衡的问题 In problems where it is desired to give more importance to certain classes or certain individual samples keywords class_weight and sample_weight can be used. 在某些问题上，需要更多的关注特定的类别，或者是特定的样本个体。这时候，可以使用 class_weight 和 sample_weight" />
<meta property="og:description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/a19990412/article/details/87896639 Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. 支持向量机（SVM）是一组有监督学习方法，被用于分类，回归和边界探测 支持向量机有以下的几个优点： Effective in high dimensional spaces. 在高维空间有效性 Still effective in cases where number of dimensions is greater than the number of samples. 在维度数量大于样本数量的时候仍然有效 Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient. 再决策函数上（支持向量）使用训练点的一个子集，因此内存有效性（占用的空间小） Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels. 多功能的：不同的核函数，可以被特别的用于决策函数，普通的核被提供，但是这仍然可能去特异化核函数。 支持向量机也有下面的这些缺点： If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial. 如果特征的数量远比样本的数量要大，选择核函数和正则化余项在避免过拟合上是至关重要的。 SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below). 支持向量机们不直接提供概率估计，而是用耗费时间的5-fold 交叉验证来计算的。 sklearn中的支持向量机同时支持dense（密集）和 sparse（稀疏）的样本数据作为输入。但是，如果是在稀疏的数据上做预测，那么一定也是要在稀疏的数据上做训练才行。 分类 SVC, NuSVC and LinearSVC are classes capable of performing multi-class classification on a dataset. SVC，NuSVC 和LinearSVC是一类在数据集上有能力去实现多类分类的分类器。 SVC and NuSVC are similar methods, but accept slightly different sets of parameters and have different mathematical formulations (see section Mathematical formulation). On the other hand, LinearSVC is another implementation of Support Vector Classification for the case of a linear kernel. SVC和NuSVC是比较类似的方法，但是在接受的参数上有轻微的不同，同时也有不同的数学表达式。 LinearSVC是对于另一种针对于线性核情况的支持向量机分类器的实现 注意： LinearSVC不接受key wordkernal，因为被假设为线性了的。同时相比于SVC和NuSVC也缺少了一些方法，例如：support_方法 SVC，NuSVC和LinearSVC都一样，接受两个输入X（[n_samples, n_features]）和 y ([n_samples] )。前者表示样本特征，后者表示样本标签，用于训练。 简单测试 &gt;&gt;&gt; from sklearn import svm D:\SoftWare\Python\lib\site-packages\sklearn\externals\joblib\externals\cloudpickle\cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module&#39;s documentation for alternative uses import imp &gt;&gt;&gt; X = [[0, 1], [1, 0]] &gt;&gt;&gt; y = [0, 1] &gt;&gt;&gt; clf = svm.SVC(gamma=&#39;scale&#39;) &gt;&gt;&gt; clf.fit(X, y) SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) 测试也很简单 &gt;&gt;&gt; data = [[0 for i in range(2)] for j in range(2)] &gt;&gt;&gt; data [[0, 0], [0, 0]] &gt;&gt;&gt; for i in range(2): ... for j in range(2): ... data[i][j] = clf.predict([[i , j]])[0] ... &gt;&gt;&gt; data [[1, 0], [1, 1]] 多类分类 svc和NuSVC提供了一种“一对一”的方式来实现多类分类。如果n_class是类的数量的话，那么n_class * (n_class - 1) / 2 个分类器被建立，来不同的两个类别之间的相互区分。 To provide a consistent interface with other classifiers, the decision_function_shape option allows to aggregate the results of the “one-against-one” classifiers to a decision function of shape (n_samples, n_classes): 为了提供一个和其他分类器一致性的接口，这这个 decision_function_shape 选项，允许去累积这个“1对1”的分类器们去一个决策函数的shape 例如： &gt;&gt;&gt; X = [[0], [1], [2], [3]] &gt;&gt;&gt; Y = [0, 1, 2, 3] &gt;&gt;&gt; clf = svm.SVC(gamma=&#39;scale&#39;, decision_function_shape=&#39;ovo&#39;) &gt;&gt;&gt; clf.fit(X, Y) SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovo&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) &gt;&gt;&gt; dec = clf.decision_function([[1]]) &gt;&gt;&gt; dec.shape[1] 6 &gt;&gt;&gt; clf.decision_function_shape = &#39;ovr&#39; &gt;&gt;&gt; dec = clf.decision_function([[1]]) &gt;&gt;&gt; dec.shape[1] 4 &gt;&gt;&gt; dec array([[ 1.95120255, 3.5 , 0.95120255, -0.4024051 ]]) &gt;&gt;&gt; clf SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) On the other hand, LinearSVC implements “one-vs-the-rest” multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained: 另一方面，LinearSVC 实现了一个“One-vs-the-rest”的多类分类方式，因此，训练n_class个模型。如果这只有两个类别，那就只有一个模型被训练。（注意最后的这个强调，这是一种特殊的情况，因为one和the rest是重复的~） 非均衡的问题 In problems where it is desired to give more importance to certain classes or certain individual samples keywords class_weight and sample_weight can be used. 在某些问题上，需要更多的关注特定的类别，或者是特定的样本个体。这时候，可以使用 class_weight 和 sample_weight" />
<link rel="canonical" href="https://mlh.app/2019/02/23/5a28d9dde0b797a40060491bdb67c81c.html" />
<meta property="og:url" content="https://mlh.app/2019/02/23/5a28d9dde0b797a40060491bdb67c81c.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-02-23T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/a19990412/article/details/87896639 Support vector machines (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection. 支持向量机（SVM）是一组有监督学习方法，被用于分类，回归和边界探测 支持向量机有以下的几个优点： Effective in high dimensional spaces. 在高维空间有效性 Still effective in cases where number of dimensions is greater than the number of samples. 在维度数量大于样本数量的时候仍然有效 Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient. 再决策函数上（支持向量）使用训练点的一个子集，因此内存有效性（占用的空间小） Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels. 多功能的：不同的核函数，可以被特别的用于决策函数，普通的核被提供，但是这仍然可能去特异化核函数。 支持向量机也有下面的这些缺点： If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial. 如果特征的数量远比样本的数量要大，选择核函数和正则化余项在避免过拟合上是至关重要的。 SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below). 支持向量机们不直接提供概率估计，而是用耗费时间的5-fold 交叉验证来计算的。 sklearn中的支持向量机同时支持dense（密集）和 sparse（稀疏）的样本数据作为输入。但是，如果是在稀疏的数据上做预测，那么一定也是要在稀疏的数据上做训练才行。 分类 SVC, NuSVC and LinearSVC are classes capable of performing multi-class classification on a dataset. SVC，NuSVC 和LinearSVC是一类在数据集上有能力去实现多类分类的分类器。 SVC and NuSVC are similar methods, but accept slightly different sets of parameters and have different mathematical formulations (see section Mathematical formulation). On the other hand, LinearSVC is another implementation of Support Vector Classification for the case of a linear kernel. SVC和NuSVC是比较类似的方法，但是在接受的参数上有轻微的不同，同时也有不同的数学表达式。 LinearSVC是对于另一种针对于线性核情况的支持向量机分类器的实现 注意： LinearSVC不接受key wordkernal，因为被假设为线性了的。同时相比于SVC和NuSVC也缺少了一些方法，例如：support_方法 SVC，NuSVC和LinearSVC都一样，接受两个输入X（[n_samples, n_features]）和 y ([n_samples] )。前者表示样本特征，后者表示样本标签，用于训练。 简单测试 &gt;&gt;&gt; from sklearn import svm D:\\SoftWare\\Python\\lib\\site-packages\\sklearn\\externals\\joblib\\externals\\cloudpickle\\cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module&#39;s documentation for alternative uses import imp &gt;&gt;&gt; X = [[0, 1], [1, 0]] &gt;&gt;&gt; y = [0, 1] &gt;&gt;&gt; clf = svm.SVC(gamma=&#39;scale&#39;) &gt;&gt;&gt; clf.fit(X, y) SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) 测试也很简单 &gt;&gt;&gt; data = [[0 for i in range(2)] for j in range(2)] &gt;&gt;&gt; data [[0, 0], [0, 0]] &gt;&gt;&gt; for i in range(2): ... for j in range(2): ... data[i][j] = clf.predict([[i , j]])[0] ... &gt;&gt;&gt; data [[1, 0], [1, 1]] 多类分类 svc和NuSVC提供了一种“一对一”的方式来实现多类分类。如果n_class是类的数量的话，那么n_class * (n_class - 1) / 2 个分类器被建立，来不同的两个类别之间的相互区分。 To provide a consistent interface with other classifiers, the decision_function_shape option allows to aggregate the results of the “one-against-one” classifiers to a decision function of shape (n_samples, n_classes): 为了提供一个和其他分类器一致性的接口，这这个 decision_function_shape 选项，允许去累积这个“1对1”的分类器们去一个决策函数的shape 例如： &gt;&gt;&gt; X = [[0], [1], [2], [3]] &gt;&gt;&gt; Y = [0, 1, 2, 3] &gt;&gt;&gt; clf = svm.SVC(gamma=&#39;scale&#39;, decision_function_shape=&#39;ovo&#39;) &gt;&gt;&gt; clf.fit(X, Y) SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovo&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) &gt;&gt;&gt; dec = clf.decision_function([[1]]) &gt;&gt;&gt; dec.shape[1] 6 &gt;&gt;&gt; clf.decision_function_shape = &#39;ovr&#39; &gt;&gt;&gt; dec = clf.decision_function([[1]]) &gt;&gt;&gt; dec.shape[1] 4 &gt;&gt;&gt; dec array([[ 1.95120255, 3.5 , 0.95120255, -0.4024051 ]]) &gt;&gt;&gt; clf SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=&#39;ovr&#39;, degree=3, gamma=&#39;scale&#39;, kernel=&#39;rbf&#39;, max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False) On the other hand, LinearSVC implements “one-vs-the-rest” multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained: 另一方面，LinearSVC 实现了一个“One-vs-the-rest”的多类分类方式，因此，训练n_class个模型。如果这只有两个类别，那就只有一个模型被训练。（注意最后的这个强调，这是一种特殊的情况，因为one和the rest是重复的~） 非均衡的问题 In problems where it is desired to give more importance to certain classes or certain individual samples keywords class_weight and sample_weight can be used. 在某些问题上，需要更多的关注特定的类别，或者是特定的样本个体。这时候，可以使用 class_weight 和 sample_weight","@type":"BlogPosting","url":"https://mlh.app/2019/02/23/5a28d9dde0b797a40060491bdb67c81c.html","headline":"SVM支持向量机–sklearn研究","dateModified":"2019-02-23T00:00:00+08:00","datePublished":"2019-02-23T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/02/23/5a28d9dde0b797a40060491bdb67c81c.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>SVM支持向量机--sklearn研究</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/a19990412/article/details/87896639 
 </div> 
 <div id="content_views" class="markdown_views prism-atom-one-light"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <blockquote> 
   <p><strong>Support vector machines</strong> (SVMs) are a set of supervised learning methods used for classification, regression and outliers detection.</p> 
  </blockquote> 
  <p>支持向量机（SVM）是一组有监督学习方法，被用于分类，回归和边界探测</p> 
  <p><strong>支持向量机有以下的几个优点：</strong></p> 
  <ul> 
   <li>Effective in high dimensional spaces. 在高维空间有效性</li> 
   <li>Still effective in cases where number of dimensions is greater than the number of samples. 在维度数量大于样本数量的时候仍然有效</li> 
   <li>Uses a subset of training points in the decision function (called support vectors), so it is also memory efficient. 再决策函数上（支持向量）使用训练点的一个子集，因此内存有效性（占用的空间小）</li> 
   <li>Versatile: different Kernel functions can be specified for the decision function. Common kernels are provided, but it is also possible to specify custom kernels. 多功能的：不同的核函数，可以被特别的用于决策函数，普通的核被提供，但是这仍然可能去特异化核函数。</li> 
  </ul> 
  <p><strong>支持向量机也有下面的这些缺点：</strong></p> 
  <ul> 
   <li>If the number of features is much greater than the number of samples, avoid over-fitting in choosing Kernel functions and regularization term is crucial. 如果特征的数量远比样本的数量要大，选择核函数和正则化余项在避免过拟合上是至关重要的。</li> 
   <li>SVMs do not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation (see Scores and probabilities, below). 支持向量机们不直接提供概率估计，而是用耗费时间的5-fold 交叉验证来计算的。</li> 
  </ul> 
  <p>sklearn中的支持向量机同时支持dense（密集）和 sparse（稀疏）的样本数据作为输入。但是，如果是在稀疏的数据上做预测，那么一定也是要在稀疏的数据上做训练才行。</p> 
  <h3><a id="_20"></a>分类</h3> 
  <p>SVC, NuSVC and LinearSVC are classes capable of performing multi-class classification on a dataset.</p> 
  <p>SVC，NuSVC 和LinearSVC是一类在数据集上有能力去实现多类分类的分类器。</p> 
  <blockquote> 
   <p>SVC and NuSVC are similar methods, but accept slightly different sets of parameters and have different mathematical formulations (see section Mathematical formulation). On the other hand, LinearSVC is another implementation of Support Vector Classification for the case of a linear kernel.</p> 
   <ul> 
    <li>SVC和NuSVC是比较类似的方法，但是在接受的参数上有轻微的不同，同时也有不同的数学表达式。</li> 
    <li>LinearSVC是对于另一种针对于线性核情况的支持向量机分类器的实现</li> 
   </ul> 
  </blockquote> 
  <p><strong>注意：</strong> LinearSVC不接受key word<code>kernal</code>，因为被假设为线性了的。同时相比于SVC和NuSVC也缺少了一些方法，例如：<code>support_</code>方法</p> 
  <p>SVC，NuSVC和LinearSVC都一样，接受两个输入X（<code>[n_samples, n_features]</code>）和 y (<code>[n_samples]</code> )。前者表示样本特征，后者表示样本标签，用于训练。</p> 
  <h4><a id="_34"></a>简单测试</h4> 
  <pre><code class="prism language-py"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword">from</span> sklearn <span class="token keyword">import</span> svm
D<span class="token punctuation">:</span>\SoftWare\Python\lib\site<span class="token operator">-</span>packages\sklearn\externals\joblib\externals\cloudpickle\cloudpickle<span class="token punctuation">.</span>py<span class="token punctuation">:</span><span class="token number">47</span><span class="token punctuation">:</span> DeprecationWarning<span class="token punctuation">:</span> the imp module <span class="token keyword">is</span> deprecated <span class="token keyword">in</span> favour of importlib<span class="token punctuation">;</span> see the module's documentation <span class="token keyword">for</span> alternative uses
  <span class="token keyword">import</span> imp
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf <span class="token operator">=</span> svm<span class="token punctuation">.</span>SVC<span class="token punctuation">(</span>gamma<span class="token operator">=</span><span class="token string">'scale'</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
SVC<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> cache_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> class_weight<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> coef0<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
  decision_function_shape<span class="token operator">=</span><span class="token string">'ovr'</span><span class="token punctuation">,</span> degree<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token string">'scale'</span><span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token string">'rbf'</span><span class="token punctuation">,</span>
  max_iter<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> probability<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> shrinking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
  tol<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
  <ul> 
   <li>测试也很简单</li> 
  </ul> 
  <pre><code class="prism language-py"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> data <span class="token operator">=</span>  <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> data
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>     <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>             data<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>j<span class="token punctuation">]</span> <span class="token operator">=</span> clf<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span>i <span class="token punctuation">,</span> j<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> data
<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
</code></pre> 
  <h4><a id="_64"></a>多类分类</h4> 
  <p>svc和NuSVC提供了一种“一对一”的方式来实现多类分类。如果<code>n_class</code>是类的数量的话，那么<code>n_class * (n_class - 1) / 2</code> 个分类器被建立，来不同的两个类别之间的相互区分。</p> 
  <p>To provide a consistent interface with other classifiers, the <code>decision_function_shape</code> option allows to aggregate the results of the “one-against-one” classifiers to a decision function of shape (n_samples, n_classes):<br> 为了提供一个和其他分类器一致性的接口，这这个 <code>decision_function_shape</code> 选项，允许去累积这个“1对1”的分类器们去一个决策函数的shape</p> 
  <ul> 
   <li>例如：</li> 
  </ul> 
  <pre><code class="prism language-py"><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> X <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf <span class="token operator">=</span> svm<span class="token punctuation">.</span>SVC<span class="token punctuation">(</span>gamma<span class="token operator">=</span><span class="token string">'scale'</span><span class="token punctuation">,</span> decision_function_shape<span class="token operator">=</span><span class="token string">'ovo'</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span>
SVC<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> cache_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> class_weight<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> coef0<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
  decision_function_shape<span class="token operator">=</span><span class="token string">'ovo'</span><span class="token punctuation">,</span> degree<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token string">'scale'</span><span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token string">'rbf'</span><span class="token punctuation">,</span>
  max_iter<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> probability<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> shrinking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
  tol<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> dec <span class="token operator">=</span> clf<span class="token punctuation">.</span>decision_function<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> dec<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token number">6</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf<span class="token punctuation">.</span>decision_function_shape <span class="token operator">=</span> <span class="token string">'ovr'</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> dec <span class="token operator">=</span> clf<span class="token punctuation">.</span>decision_function<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> dec<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
<span class="token number">4</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> dec
array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">1.95120255</span><span class="token punctuation">,</span>  <span class="token number">3.5</span>       <span class="token punctuation">,</span>  <span class="token number">0.95120255</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">0.4024051</span> <span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span> clf
SVC<span class="token punctuation">(</span>C<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> cache_size<span class="token operator">=</span><span class="token number">200</span><span class="token punctuation">,</span> class_weight<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> coef0<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span>
  decision_function_shape<span class="token operator">=</span><span class="token string">'ovr'</span><span class="token punctuation">,</span> degree<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token string">'scale'</span><span class="token punctuation">,</span> kernel<span class="token operator">=</span><span class="token string">'rbf'</span><span class="token punctuation">,</span>
  max_iter<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> probability<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> shrinking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
  tol<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
</code></pre> 
  <blockquote> 
   <p>On the other hand, LinearSVC implements “one-vs-the-rest” multi-class strategy, thus training n_class models. If there are only two classes, only one model is trained:<br> 另一方面，LinearSVC 实现了一个“One-vs-the-rest”的多类分类方式，因此，训练n_class个模型。如果这只有两个类别，那就只有一个模型被训练。（<strong>注意最后的这个强调，这是一种特殊的情况，因为one和the rest是重复的~</strong>）</p> 
  </blockquote> 
  <h3><a id="_101"></a>非均衡的问题</h3> 
  <p>In problems where it is desired to give more importance to certain classes or certain individual samples keywords <code>class_weight</code> and <code>sample_weight</code> can be used.</p> 
  <p>在某些问题上，需要更多的关注特定的类别，或者是特定的样本个体。这时候，可以使用 <code>class_weight</code> 和 <code>sample_weight</code></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
