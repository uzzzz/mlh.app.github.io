<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>《Python自然语言处理（第二版）-Steven Bird等》学习笔记：第09章 建立基于特征的文法 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="《Python自然语言处理（第二版）-Steven Bird等》学习笔记：第09章 建立基于特征的文法" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/weixin_43935926/article/details/86528015 第09章 建立基于特征的文法 9.1 文法特征 句法协议 使用属性和约束 术语 9.2 处理特征结构 包含和统一 9.3 扩展基于特征的文法 子类别 核心词回顾 助动词与倒装 无限制依赖成分 9.4 小结 import nltk 怎样用特征扩展上下文无关文法框架，以获得更细粒度的对文法类别和产生式的控制？ 特征结构的主要形式化属性是什么，如何使用它们来计算？ 用基于特征的文法能捕捉到什么语言模式和文法结构？ 9.1 文法特征 基于规则的文法上下文中，特征和特征值对被称为特征结构 kim = {&#39;CAT&#39;: &#39;NP&#39;, &#39;ORTH&#39;: &#39;Kim&#39;, &#39;REF&#39;: &#39;k&#39;} chase = {&#39;CAT&#39;: &#39;V&#39;, &#39;ORTH&#39;: &#39;chased&#39;, &#39;REL&#39;: &#39;chase&#39;} chase[&#39;AGT&#39;] = &#39;sbj&#39; chase[&#39;PAT&#39;] = &#39;obj&#39; 一个简单的假设：在动词直接左侧和右侧的NP 分别是主语和宾语。 sent = &quot;Kim chased Lee&quot; tokens = sent.split() lee = {&#39;CAT&#39;: &#39;NP&#39;, &#39;ORTH&#39;: &#39;Lee&#39;, &#39;REF&#39;: &#39;l&#39;} def lex2fs(word): for fs in [kim, lee, chase]: if fs[&#39;ORTH&#39;] == word: return fs subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2]) verb[&#39;AGT&#39;] = subj[&#39;REF&#39;] # agent of &#39;chase&#39; is Kim verb[&#39;PAT&#39;] = obj[&#39;REF&#39;] # patient of &#39;chase&#39; is Lee for k in [&#39;ORTH&#39;, &#39;REL&#39;, &#39;AGT&#39;, &#39;PAT&#39;]: # check featstruct of &#39;chase&#39; print(&quot;%-5s =&gt; %s&quot; % (k, verb[k])) ORTH =&gt; chased REL =&gt; chase AGT =&gt; k PAT =&gt; l surprise = {&#39;CAT&#39;: &#39;V&#39;, &#39;ORTH&#39;: &#39;surprised&#39;, &#39;REL&#39;: &#39;surprise&#39;, &#39;SRC&#39;: &#39;sbj&#39;, &#39;EXP&#39;: &#39;obj&#39;} 句法协议 动词的形态属性与主语名词短语的句法属性一起变化。这种一起变化被称为协议（agreement）。 表9-1. 英语规则动词的协议范式 单数 复数 第一人称 I run we run 第二人称 you run you run 第三人称 he/she/it runs they run 使用属性和约束 例9-1. 基于特征的文法的例子。 nltk.data.show_cfg(&#39;grammars/book_grammars/feat0.fcfg&#39;) % start S # ################### # Grammar Productions # ################### # S expansion productions S -&gt; NP[NUM=?n] VP[NUM=?n] # NP expansion productions NP[NUM=?n] -&gt; N[NUM=?n] NP[NUM=?n] -&gt; PropN[NUM=?n] NP[NUM=?n] -&gt; Det[NUM=?n] N[NUM=?n] NP[NUM=pl] -&gt; N[NUM=pl] # VP expansion productions VP[TENSE=?t, NUM=?n] -&gt; IV[TENSE=?t, NUM=?n] VP[TENSE=?t, NUM=?n] -&gt; TV[TENSE=?t, NUM=?n] NP # ################### # Lexical Productions # ################### Det[NUM=sg] -&gt; &#39;this&#39; | &#39;every&#39; Det[NUM=pl] -&gt; &#39;these&#39; | &#39;all&#39; Det -&gt; &#39;the&#39; | &#39;some&#39; | &#39;several&#39; PropN[NUM=sg]-&gt; &#39;Kim&#39; | &#39;Jody&#39; N[NUM=sg] -&gt; &#39;dog&#39; | &#39;girl&#39; | &#39;car&#39; | &#39;child&#39; N[NUM=pl] -&gt; &#39;dogs&#39; | &#39;girls&#39; | &#39;cars&#39; | &#39;children&#39; IV[TENSE=pres, NUM=sg] -&gt; &#39;disappears&#39; | &#39;walks&#39; TV[TENSE=pres, NUM=sg] -&gt; &#39;sees&#39; | &#39;likes&#39; IV[TENSE=pres, NUM=pl] -&gt; &#39;disappear&#39; | &#39;walk&#39; TV[TENSE=pres, NUM=pl] -&gt; &#39;see&#39; | &#39;like&#39; IV[TENSE=past] -&gt; &#39;disappeared&#39; | &#39;walked&#39; TV[TENSE=past] -&gt; &#39;saw&#39; | &#39;liked&#39; 例9-2. 跟踪基于特征的图表分析器 tokens = &#39;Kim likes children&#39;.split() from nltk import load_parser cp = load_parser(&#39;grammars/book_grammars/feat0.fcfg&#39;, trace=2) for tree in cp.parse(tokens): print(tree) |.Kim .like.chil.| Leaf Init Rule: |[----] . .| [0:1] &#39;Kim&#39; |. [----] .| [1:2] &#39;likes&#39; |. . [----]| [2:3] &#39;children&#39; Feature Bottom Up Predict Combine Rule: |[----] . .| [0:1] PropN[NUM=&#39;sg&#39;] -&gt; &#39;Kim&#39; * Feature Bottom Up Predict Combine Rule: |[----] . .| [0:1] NP[NUM=&#39;sg&#39;] -&gt; PropN[NUM=&#39;sg&#39;] * Feature Bottom Up Predict Combine Rule: |[----&gt; . .| [0:1] S[] -&gt; NP[NUM=?n] * VP[NUM=?n] {?n: &#39;sg&#39;} Feature Bottom Up Predict Combine Rule: |. [----] .| [1:2] TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] -&gt; &#39;likes&#39; * Feature Bottom Up Predict Combine Rule: |. [----&gt; .| [1:2] VP[NUM=?n, TENSE=?t] -&gt; TV[NUM=?n, TENSE=?t] * NP[] {?n: &#39;sg&#39;, ?t: &#39;pres&#39;} Feature Bottom Up Predict Combine Rule: |. . [----]| [2:3] N[NUM=&#39;pl&#39;] -&gt; &#39;children&#39; * Feature Bottom Up Predict Combine Rule: |. . [----]| [2:3] NP[NUM=&#39;pl&#39;] -&gt; N[NUM=&#39;pl&#39;] * Feature Bottom Up Predict Combine Rule: |. . [----&gt;| [2:3] S[] -&gt; NP[NUM=?n] * VP[NUM=?n] {?n: &#39;pl&#39;} Feature Single Edge Fundamental Rule: |. [---------]| [1:3] VP[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] -&gt; TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] NP[] * Feature Single Edge Fundamental Rule: |[==============]| [0:3] S[] -&gt; NP[NUM=&#39;sg&#39;] VP[NUM=&#39;sg&#39;] * (S[] (NP[NUM=&#39;sg&#39;] (PropN[NUM=&#39;sg&#39;] Kim)) (VP[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] (TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] likes) (NP[NUM=&#39;pl&#39;] (N[NUM=&#39;pl&#39;] children)))) 术语 9.2 处理特征结构 NLTK 中的特征结构使用构造函数FeatStruct()声明。原子特征值可以是字符串或整数。 fs1 = nltk.FeatStruct(TENSE=&#39;past&#39;, NUM=&#39;sg&#39;) print(fs1) [ NUM = &#39;sg&#39; ] [ TENSE = &#39;past&#39; ] fs1 = nltk.FeatStruct(PER=3, NUM=&#39;pl&#39;, GND=&#39;fem&#39;) print(fs1[&#39;GND&#39;]) fem fs1[&#39;CASE&#39;] = &#39;acc&#39; fs2 = nltk.FeatStruct(POS=&#39;N&#39;, AGR=fs1) print(fs2) [ [ CASE = &#39;acc&#39; ] ] [ AGR = [ GND = &#39;fem&#39; ] ] [ [ NUM = &#39;pl&#39; ] ] [ [ PER = 3 ] ] [ ] [ POS = &#39;N&#39; ] print(fs2[&#39;AGR&#39;]) [ CASE = &#39;acc&#39; ] [ GND = &#39;fem&#39; ] [ NUM = &#39;pl&#39; ] [ PER = 3 ] print(fs2[&#39;AGR&#39;][&#39;PER&#39;]) 3 print(nltk.FeatStruct(&quot;[POS=&#39;N&#39;, AGR=[PER=3, NUM=&#39;pl&#39;, GND=&#39;fem&#39;]]&quot;)) [ [ GND = &#39;fem&#39; ] ] [ AGR = [ NUM = &#39;pl&#39; ] ] [ [ PER = 3 ] ] [ ] [ POS = &#39;N&#39; ] print(nltk.FeatStruct(NAME=&#39;Lee&#39;, TELNO=&#39;01 27 86 42 96&#39;, AGE=33)) [ AGE = 33 ] [ NAME = &#39;Lee&#39; ] [ TELNO = &#39;01 27 86 42 96&#39; ] print(nltk.FeatStruct(&quot;&quot;&quot;[NAME=&#39;Lee&#39;, ADDRESS=(1)[NUMBER=74, STREET=&#39;rue Pascal&#39;],SPOUSE=[NAME=&#39;Kim&#39;, ADDRESS-&gt;(1)]]&quot;&quot;&quot;)) [ ADDRESS = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ SPOUSE = [ ADDRESS -&gt; (1) ] ] [ [ NAME = &#39;Kim&#39; ] ] print(nltk.FeatStruct(&quot;[A=&#39;a&#39;, B=(1)[C=&#39;c&#39;], D-&gt;(1), E-&gt;(1)]&quot;)) [ A = &#39;a&#39; ] [ ] [ B = (1) [ C = &#39;c&#39; ] ] [ ] [ D -&gt; (1) ] [ E -&gt; (1) ] 包含和统一 fs1 = nltk.FeatStruct(NUMBER=74, STREET=&#39;rue Pascal&#39;) fs2 = nltk.FeatStruct(CITY=&#39;Paris&#39;) print(fs2.unify(fs1)) [ CITY = &#39;Paris&#39; ] [ NUMBER = 74 ] [ STREET = &#39;rue Pascal&#39; ] fs0 = nltk.FeatStruct(A=&#39;a&#39;) fs1 = nltk.FeatStruct(A=&#39;b&#39;) fs2 = fs0.unify(fs1) print(fs2) None fs0 = nltk.FeatStruct(&quot;&quot;&quot;[NAME=Lee, ADDRESS=[NUMBER=74, STREET=&#39;rue Pascal&#39;], SPOUSE= [NAME=Kim, ADDRESS=[NUMBER=74, STREET=&#39;rue Pascal&#39;]]]&quot;&quot;&quot;) print(fs0) [ ADDRESS = [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ [ ADDRESS = [ NUMBER = 74 ] ] ] [ SPOUSE = [ [ STREET = &#39;rue Pascal&#39; ] ] ] [ [ ] ] [ [ NAME = &#39;Kim&#39; ] ] fs1 = nltk.FeatStruct(&quot;[SPOUSE = [ADDRESS = [CITY = Paris]]]&quot;) print(fs1.unify(fs0)) [ ADDRESS = [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ [ [ CITY = &#39;Paris&#39; ] ] ] [ [ ADDRESS = [ NUMBER = 74 ] ] ] [ SPOUSE = [ [ STREET = &#39;rue Pascal&#39; ] ] ] [ [ ] ] [ [ NAME = &#39;Kim&#39; ] ] fs2 = nltk.FeatStruct(&quot;&quot;&quot;[NAME=Lee, ADDRESS=(1)[NUMBER=74, STREET=&#39;rue Pascal&#39;], SPOUSE=[NAME=Kim, ADDRESS-&gt;(1)]]&quot;&quot;&quot;) print(fs1.unify(fs2)) [ [ CITY = &#39;Paris&#39; ] ] [ ADDRESS = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ SPOUSE = [ ADDRESS -&gt; (1) ] ] [ [ NAME = &#39;Kim&#39; ] ] fs1 = nltk.FeatStruct(&quot;[ADDRESS1=[NUMBER=74, STREET=&#39;rue Pascal&#39;]]&quot;) fs2 = nltk.FeatStruct(&quot;[ADDRESS1=?x, ADDRESS2=?x]&quot;) print(fs2) [ ADDRESS1 = ?x ] [ ADDRESS2 = ?x ] print(fs2.unify(fs1)) [ ADDRESS1 = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ ADDRESS2 -&gt; (1) ] 9.3 扩展基于特征的文法 子类别 核心词回顾 助动词与倒装 无限制依赖成分 例9-3. 具有倒装从句和长距离依赖的产生式的文法，使用斜线类别。 nltk.data.show_cfg(&#39;grammars/book_grammars/feat1.fcfg&#39;) % start S # ################### # Grammar Productions # ################### S[-INV] -&gt; NP VP S[-INV]/?x -&gt; NP VP/?x S[-INV] -&gt; NP S/NP S[-INV] -&gt; Adv[+NEG] S[+INV] S[+INV] -&gt; V[+AUX] NP VP S[+INV]/?x -&gt; V[+AUX] NP VP/?x SBar -&gt; Comp S[-INV] SBar/?x -&gt; Comp S[-INV]/?x VP -&gt; V[SUBCAT=intrans, -AUX] VP -&gt; V[SUBCAT=trans, -AUX] NP VP/?x -&gt; V[SUBCAT=trans, -AUX] NP/?x VP -&gt; V[SUBCAT=clause, -AUX] SBar VP/?x -&gt; V[SUBCAT=clause, -AUX] SBar/?x VP -&gt; V[+AUX] VP VP/?x -&gt; V[+AUX] VP/?x # ################### # Lexical Productions # ################### V[SUBCAT=intrans, -AUX] -&gt; &#39;walk&#39; | &#39;sing&#39; V[SUBCAT=trans, -AUX] -&gt; &#39;see&#39; | &#39;like&#39; V[SUBCAT=clause, -AUX] -&gt; &#39;say&#39; | &#39;claim&#39; V[+AUX] -&gt; &#39;do&#39; | &#39;can&#39; NP[-WH] -&gt; &#39;you&#39; | &#39;cats&#39; NP[+WH] -&gt; &#39;who&#39; Adv[+NEG] -&gt; &#39;rarely&#39; | &#39;never&#39; NP/NP -&gt; Comp -&gt; &#39;that&#39; tokens = &#39;who do you claim that you like&#39;.split() from nltk import load_parser cp = load_parser(&#39;grammars/book_grammars/feat1.fcfg&#39;) for tree in cp.parse(tokens): print(tree) (S[-INV] (NP[+WH] who) (S[+INV]/NP[] (V[+AUX] do) (NP[-WH] you) (VP[]/NP[] (V[-AUX, SUBCAT=&#39;clause&#39;] claim) (SBar[]/NP[] (Comp[] that) (S[-INV]/NP[] (NP[-WH] you) (VP[]/NP[] (V[-AUX, SUBCAT=&#39;trans&#39;] like) (NP[]/NP[] ))))))) tokens = &#39;you claim that you like cats&#39;.split() for tree in cp.parse(tokens): print(tree) (S[-INV] (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;clause&#39;] claim) (SBar[] (Comp[] that) (S[-INV] (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;trans&#39;] like) (NP[-WH] cats)))))) tokens = &#39;rarely do you sing&#39;.split() for tree in cp.parse(tokens): print(tree) (S[-INV] (Adv[+NEG] rarely) (S[+INV] (V[+AUX] do) (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;intrans&#39;] sing)))) 9.4 小结 上下文无关文法的传统分类是原子符号。特征结构的一个重要的作用是捕捉精细的区分，否则将需要数量翻倍的原子类别。 通过使用特征值上的变量，我们可以表达文法产生式中的限制，允许不同的特征规格的实现可以相互依赖。 通常情况下，我们在词汇层面指定固定的特征值，限制短语中的特征值与它们的原子中的对应值统一。 特征值可以是原子的或复杂的。原子值的一个特定类别是布尔值，按照惯例用[+/- feat]表示。 两个特征可以共享一个值（原子的或复杂的）。具有共享值的结构被称为重入。共享的值被表示为AVM 中的数字索引（或标记）。 一个特征结构中的路径是一个特征的元组，对应从图的根开始的弧的序列上的标签。 两条路径是等价的，如果它们共享一个值。 包含的特征结构是偏序的。FS0 包含FS1，当FS0 比FS1 更一般（较少信息）。 两种结构FS0 和FS1 的统一，如果成功，就是包含FS0 和FS1 的合并信息的特征结构FS2。 如果统一在FS 中指定一条路径π，那么它也指定等效与π的每个路径π’。 我们可以使用特征结构建立对大量广泛语言学现象的简洁的分析，包括动词子类别，倒装结构，无限制依赖结构和格支配。 致谢 《Python自然语言处理》123 4，作者：Steven Bird, Ewan Klein &amp; Edward Loper，是实践性很强的一部入门读物，2009年第一版，2015年第二版，本学习笔记结合上述版本，对部分内容进行了延伸学习、练习，在此分享，期待对大家有所帮助，欢迎加我微信（验证：NLP），一起学习讨论，不足之处，欢迎指正。 参考文献 http://nltk.org/ ↩︎ Steven Bird, Ewan Klein &amp; Edward Loper,Natural Language Processing with Python,2009 ↩︎ （英）伯德，（英）克莱因，（美）洛普，《Python自然语言处理》，2010年，东南大学出版社 ↩︎ Steven Bird, Ewan Klein &amp; Edward Loper,Natural Language Processing with Python,2015 ↩︎" />
<meta property="og:description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/weixin_43935926/article/details/86528015 第09章 建立基于特征的文法 9.1 文法特征 句法协议 使用属性和约束 术语 9.2 处理特征结构 包含和统一 9.3 扩展基于特征的文法 子类别 核心词回顾 助动词与倒装 无限制依赖成分 9.4 小结 import nltk 怎样用特征扩展上下文无关文法框架，以获得更细粒度的对文法类别和产生式的控制？ 特征结构的主要形式化属性是什么，如何使用它们来计算？ 用基于特征的文法能捕捉到什么语言模式和文法结构？ 9.1 文法特征 基于规则的文法上下文中，特征和特征值对被称为特征结构 kim = {&#39;CAT&#39;: &#39;NP&#39;, &#39;ORTH&#39;: &#39;Kim&#39;, &#39;REF&#39;: &#39;k&#39;} chase = {&#39;CAT&#39;: &#39;V&#39;, &#39;ORTH&#39;: &#39;chased&#39;, &#39;REL&#39;: &#39;chase&#39;} chase[&#39;AGT&#39;] = &#39;sbj&#39; chase[&#39;PAT&#39;] = &#39;obj&#39; 一个简单的假设：在动词直接左侧和右侧的NP 分别是主语和宾语。 sent = &quot;Kim chased Lee&quot; tokens = sent.split() lee = {&#39;CAT&#39;: &#39;NP&#39;, &#39;ORTH&#39;: &#39;Lee&#39;, &#39;REF&#39;: &#39;l&#39;} def lex2fs(word): for fs in [kim, lee, chase]: if fs[&#39;ORTH&#39;] == word: return fs subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2]) verb[&#39;AGT&#39;] = subj[&#39;REF&#39;] # agent of &#39;chase&#39; is Kim verb[&#39;PAT&#39;] = obj[&#39;REF&#39;] # patient of &#39;chase&#39; is Lee for k in [&#39;ORTH&#39;, &#39;REL&#39;, &#39;AGT&#39;, &#39;PAT&#39;]: # check featstruct of &#39;chase&#39; print(&quot;%-5s =&gt; %s&quot; % (k, verb[k])) ORTH =&gt; chased REL =&gt; chase AGT =&gt; k PAT =&gt; l surprise = {&#39;CAT&#39;: &#39;V&#39;, &#39;ORTH&#39;: &#39;surprised&#39;, &#39;REL&#39;: &#39;surprise&#39;, &#39;SRC&#39;: &#39;sbj&#39;, &#39;EXP&#39;: &#39;obj&#39;} 句法协议 动词的形态属性与主语名词短语的句法属性一起变化。这种一起变化被称为协议（agreement）。 表9-1. 英语规则动词的协议范式 单数 复数 第一人称 I run we run 第二人称 you run you run 第三人称 he/she/it runs they run 使用属性和约束 例9-1. 基于特征的文法的例子。 nltk.data.show_cfg(&#39;grammars/book_grammars/feat0.fcfg&#39;) % start S # ################### # Grammar Productions # ################### # S expansion productions S -&gt; NP[NUM=?n] VP[NUM=?n] # NP expansion productions NP[NUM=?n] -&gt; N[NUM=?n] NP[NUM=?n] -&gt; PropN[NUM=?n] NP[NUM=?n] -&gt; Det[NUM=?n] N[NUM=?n] NP[NUM=pl] -&gt; N[NUM=pl] # VP expansion productions VP[TENSE=?t, NUM=?n] -&gt; IV[TENSE=?t, NUM=?n] VP[TENSE=?t, NUM=?n] -&gt; TV[TENSE=?t, NUM=?n] NP # ################### # Lexical Productions # ################### Det[NUM=sg] -&gt; &#39;this&#39; | &#39;every&#39; Det[NUM=pl] -&gt; &#39;these&#39; | &#39;all&#39; Det -&gt; &#39;the&#39; | &#39;some&#39; | &#39;several&#39; PropN[NUM=sg]-&gt; &#39;Kim&#39; | &#39;Jody&#39; N[NUM=sg] -&gt; &#39;dog&#39; | &#39;girl&#39; | &#39;car&#39; | &#39;child&#39; N[NUM=pl] -&gt; &#39;dogs&#39; | &#39;girls&#39; | &#39;cars&#39; | &#39;children&#39; IV[TENSE=pres, NUM=sg] -&gt; &#39;disappears&#39; | &#39;walks&#39; TV[TENSE=pres, NUM=sg] -&gt; &#39;sees&#39; | &#39;likes&#39; IV[TENSE=pres, NUM=pl] -&gt; &#39;disappear&#39; | &#39;walk&#39; TV[TENSE=pres, NUM=pl] -&gt; &#39;see&#39; | &#39;like&#39; IV[TENSE=past] -&gt; &#39;disappeared&#39; | &#39;walked&#39; TV[TENSE=past] -&gt; &#39;saw&#39; | &#39;liked&#39; 例9-2. 跟踪基于特征的图表分析器 tokens = &#39;Kim likes children&#39;.split() from nltk import load_parser cp = load_parser(&#39;grammars/book_grammars/feat0.fcfg&#39;, trace=2) for tree in cp.parse(tokens): print(tree) |.Kim .like.chil.| Leaf Init Rule: |[----] . .| [0:1] &#39;Kim&#39; |. [----] .| [1:2] &#39;likes&#39; |. . [----]| [2:3] &#39;children&#39; Feature Bottom Up Predict Combine Rule: |[----] . .| [0:1] PropN[NUM=&#39;sg&#39;] -&gt; &#39;Kim&#39; * Feature Bottom Up Predict Combine Rule: |[----] . .| [0:1] NP[NUM=&#39;sg&#39;] -&gt; PropN[NUM=&#39;sg&#39;] * Feature Bottom Up Predict Combine Rule: |[----&gt; . .| [0:1] S[] -&gt; NP[NUM=?n] * VP[NUM=?n] {?n: &#39;sg&#39;} Feature Bottom Up Predict Combine Rule: |. [----] .| [1:2] TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] -&gt; &#39;likes&#39; * Feature Bottom Up Predict Combine Rule: |. [----&gt; .| [1:2] VP[NUM=?n, TENSE=?t] -&gt; TV[NUM=?n, TENSE=?t] * NP[] {?n: &#39;sg&#39;, ?t: &#39;pres&#39;} Feature Bottom Up Predict Combine Rule: |. . [----]| [2:3] N[NUM=&#39;pl&#39;] -&gt; &#39;children&#39; * Feature Bottom Up Predict Combine Rule: |. . [----]| [2:3] NP[NUM=&#39;pl&#39;] -&gt; N[NUM=&#39;pl&#39;] * Feature Bottom Up Predict Combine Rule: |. . [----&gt;| [2:3] S[] -&gt; NP[NUM=?n] * VP[NUM=?n] {?n: &#39;pl&#39;} Feature Single Edge Fundamental Rule: |. [---------]| [1:3] VP[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] -&gt; TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] NP[] * Feature Single Edge Fundamental Rule: |[==============]| [0:3] S[] -&gt; NP[NUM=&#39;sg&#39;] VP[NUM=&#39;sg&#39;] * (S[] (NP[NUM=&#39;sg&#39;] (PropN[NUM=&#39;sg&#39;] Kim)) (VP[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] (TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] likes) (NP[NUM=&#39;pl&#39;] (N[NUM=&#39;pl&#39;] children)))) 术语 9.2 处理特征结构 NLTK 中的特征结构使用构造函数FeatStruct()声明。原子特征值可以是字符串或整数。 fs1 = nltk.FeatStruct(TENSE=&#39;past&#39;, NUM=&#39;sg&#39;) print(fs1) [ NUM = &#39;sg&#39; ] [ TENSE = &#39;past&#39; ] fs1 = nltk.FeatStruct(PER=3, NUM=&#39;pl&#39;, GND=&#39;fem&#39;) print(fs1[&#39;GND&#39;]) fem fs1[&#39;CASE&#39;] = &#39;acc&#39; fs2 = nltk.FeatStruct(POS=&#39;N&#39;, AGR=fs1) print(fs2) [ [ CASE = &#39;acc&#39; ] ] [ AGR = [ GND = &#39;fem&#39; ] ] [ [ NUM = &#39;pl&#39; ] ] [ [ PER = 3 ] ] [ ] [ POS = &#39;N&#39; ] print(fs2[&#39;AGR&#39;]) [ CASE = &#39;acc&#39; ] [ GND = &#39;fem&#39; ] [ NUM = &#39;pl&#39; ] [ PER = 3 ] print(fs2[&#39;AGR&#39;][&#39;PER&#39;]) 3 print(nltk.FeatStruct(&quot;[POS=&#39;N&#39;, AGR=[PER=3, NUM=&#39;pl&#39;, GND=&#39;fem&#39;]]&quot;)) [ [ GND = &#39;fem&#39; ] ] [ AGR = [ NUM = &#39;pl&#39; ] ] [ [ PER = 3 ] ] [ ] [ POS = &#39;N&#39; ] print(nltk.FeatStruct(NAME=&#39;Lee&#39;, TELNO=&#39;01 27 86 42 96&#39;, AGE=33)) [ AGE = 33 ] [ NAME = &#39;Lee&#39; ] [ TELNO = &#39;01 27 86 42 96&#39; ] print(nltk.FeatStruct(&quot;&quot;&quot;[NAME=&#39;Lee&#39;, ADDRESS=(1)[NUMBER=74, STREET=&#39;rue Pascal&#39;],SPOUSE=[NAME=&#39;Kim&#39;, ADDRESS-&gt;(1)]]&quot;&quot;&quot;)) [ ADDRESS = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ SPOUSE = [ ADDRESS -&gt; (1) ] ] [ [ NAME = &#39;Kim&#39; ] ] print(nltk.FeatStruct(&quot;[A=&#39;a&#39;, B=(1)[C=&#39;c&#39;], D-&gt;(1), E-&gt;(1)]&quot;)) [ A = &#39;a&#39; ] [ ] [ B = (1) [ C = &#39;c&#39; ] ] [ ] [ D -&gt; (1) ] [ E -&gt; (1) ] 包含和统一 fs1 = nltk.FeatStruct(NUMBER=74, STREET=&#39;rue Pascal&#39;) fs2 = nltk.FeatStruct(CITY=&#39;Paris&#39;) print(fs2.unify(fs1)) [ CITY = &#39;Paris&#39; ] [ NUMBER = 74 ] [ STREET = &#39;rue Pascal&#39; ] fs0 = nltk.FeatStruct(A=&#39;a&#39;) fs1 = nltk.FeatStruct(A=&#39;b&#39;) fs2 = fs0.unify(fs1) print(fs2) None fs0 = nltk.FeatStruct(&quot;&quot;&quot;[NAME=Lee, ADDRESS=[NUMBER=74, STREET=&#39;rue Pascal&#39;], SPOUSE= [NAME=Kim, ADDRESS=[NUMBER=74, STREET=&#39;rue Pascal&#39;]]]&quot;&quot;&quot;) print(fs0) [ ADDRESS = [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ [ ADDRESS = [ NUMBER = 74 ] ] ] [ SPOUSE = [ [ STREET = &#39;rue Pascal&#39; ] ] ] [ [ ] ] [ [ NAME = &#39;Kim&#39; ] ] fs1 = nltk.FeatStruct(&quot;[SPOUSE = [ADDRESS = [CITY = Paris]]]&quot;) print(fs1.unify(fs0)) [ ADDRESS = [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ [ [ CITY = &#39;Paris&#39; ] ] ] [ [ ADDRESS = [ NUMBER = 74 ] ] ] [ SPOUSE = [ [ STREET = &#39;rue Pascal&#39; ] ] ] [ [ ] ] [ [ NAME = &#39;Kim&#39; ] ] fs2 = nltk.FeatStruct(&quot;&quot;&quot;[NAME=Lee, ADDRESS=(1)[NUMBER=74, STREET=&#39;rue Pascal&#39;], SPOUSE=[NAME=Kim, ADDRESS-&gt;(1)]]&quot;&quot;&quot;) print(fs1.unify(fs2)) [ [ CITY = &#39;Paris&#39; ] ] [ ADDRESS = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ SPOUSE = [ ADDRESS -&gt; (1) ] ] [ [ NAME = &#39;Kim&#39; ] ] fs1 = nltk.FeatStruct(&quot;[ADDRESS1=[NUMBER=74, STREET=&#39;rue Pascal&#39;]]&quot;) fs2 = nltk.FeatStruct(&quot;[ADDRESS1=?x, ADDRESS2=?x]&quot;) print(fs2) [ ADDRESS1 = ?x ] [ ADDRESS2 = ?x ] print(fs2.unify(fs1)) [ ADDRESS1 = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ ADDRESS2 -&gt; (1) ] 9.3 扩展基于特征的文法 子类别 核心词回顾 助动词与倒装 无限制依赖成分 例9-3. 具有倒装从句和长距离依赖的产生式的文法，使用斜线类别。 nltk.data.show_cfg(&#39;grammars/book_grammars/feat1.fcfg&#39;) % start S # ################### # Grammar Productions # ################### S[-INV] -&gt; NP VP S[-INV]/?x -&gt; NP VP/?x S[-INV] -&gt; NP S/NP S[-INV] -&gt; Adv[+NEG] S[+INV] S[+INV] -&gt; V[+AUX] NP VP S[+INV]/?x -&gt; V[+AUX] NP VP/?x SBar -&gt; Comp S[-INV] SBar/?x -&gt; Comp S[-INV]/?x VP -&gt; V[SUBCAT=intrans, -AUX] VP -&gt; V[SUBCAT=trans, -AUX] NP VP/?x -&gt; V[SUBCAT=trans, -AUX] NP/?x VP -&gt; V[SUBCAT=clause, -AUX] SBar VP/?x -&gt; V[SUBCAT=clause, -AUX] SBar/?x VP -&gt; V[+AUX] VP VP/?x -&gt; V[+AUX] VP/?x # ################### # Lexical Productions # ################### V[SUBCAT=intrans, -AUX] -&gt; &#39;walk&#39; | &#39;sing&#39; V[SUBCAT=trans, -AUX] -&gt; &#39;see&#39; | &#39;like&#39; V[SUBCAT=clause, -AUX] -&gt; &#39;say&#39; | &#39;claim&#39; V[+AUX] -&gt; &#39;do&#39; | &#39;can&#39; NP[-WH] -&gt; &#39;you&#39; | &#39;cats&#39; NP[+WH] -&gt; &#39;who&#39; Adv[+NEG] -&gt; &#39;rarely&#39; | &#39;never&#39; NP/NP -&gt; Comp -&gt; &#39;that&#39; tokens = &#39;who do you claim that you like&#39;.split() from nltk import load_parser cp = load_parser(&#39;grammars/book_grammars/feat1.fcfg&#39;) for tree in cp.parse(tokens): print(tree) (S[-INV] (NP[+WH] who) (S[+INV]/NP[] (V[+AUX] do) (NP[-WH] you) (VP[]/NP[] (V[-AUX, SUBCAT=&#39;clause&#39;] claim) (SBar[]/NP[] (Comp[] that) (S[-INV]/NP[] (NP[-WH] you) (VP[]/NP[] (V[-AUX, SUBCAT=&#39;trans&#39;] like) (NP[]/NP[] ))))))) tokens = &#39;you claim that you like cats&#39;.split() for tree in cp.parse(tokens): print(tree) (S[-INV] (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;clause&#39;] claim) (SBar[] (Comp[] that) (S[-INV] (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;trans&#39;] like) (NP[-WH] cats)))))) tokens = &#39;rarely do you sing&#39;.split() for tree in cp.parse(tokens): print(tree) (S[-INV] (Adv[+NEG] rarely) (S[+INV] (V[+AUX] do) (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;intrans&#39;] sing)))) 9.4 小结 上下文无关文法的传统分类是原子符号。特征结构的一个重要的作用是捕捉精细的区分，否则将需要数量翻倍的原子类别。 通过使用特征值上的变量，我们可以表达文法产生式中的限制，允许不同的特征规格的实现可以相互依赖。 通常情况下，我们在词汇层面指定固定的特征值，限制短语中的特征值与它们的原子中的对应值统一。 特征值可以是原子的或复杂的。原子值的一个特定类别是布尔值，按照惯例用[+/- feat]表示。 两个特征可以共享一个值（原子的或复杂的）。具有共享值的结构被称为重入。共享的值被表示为AVM 中的数字索引（或标记）。 一个特征结构中的路径是一个特征的元组，对应从图的根开始的弧的序列上的标签。 两条路径是等价的，如果它们共享一个值。 包含的特征结构是偏序的。FS0 包含FS1，当FS0 比FS1 更一般（较少信息）。 两种结构FS0 和FS1 的统一，如果成功，就是包含FS0 和FS1 的合并信息的特征结构FS2。 如果统一在FS 中指定一条路径π，那么它也指定等效与π的每个路径π’。 我们可以使用特征结构建立对大量广泛语言学现象的简洁的分析，包括动词子类别，倒装结构，无限制依赖结构和格支配。 致谢 《Python自然语言处理》123 4，作者：Steven Bird, Ewan Klein &amp; Edward Loper，是实践性很强的一部入门读物，2009年第一版，2015年第二版，本学习笔记结合上述版本，对部分内容进行了延伸学习、练习，在此分享，期待对大家有所帮助，欢迎加我微信（验证：NLP），一起学习讨论，不足之处，欢迎指正。 参考文献 http://nltk.org/ ↩︎ Steven Bird, Ewan Klein &amp; Edward Loper,Natural Language Processing with Python,2009 ↩︎ （英）伯德，（英）克莱因，（美）洛普，《Python自然语言处理》，2010年，东南大学出版社 ↩︎ Steven Bird, Ewan Klein &amp; Edward Loper,Natural Language Processing with Python,2015 ↩︎" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/weixin_43935926/article/details/86528015 第09章 建立基于特征的文法 9.1 文法特征 句法协议 使用属性和约束 术语 9.2 处理特征结构 包含和统一 9.3 扩展基于特征的文法 子类别 核心词回顾 助动词与倒装 无限制依赖成分 9.4 小结 import nltk 怎样用特征扩展上下文无关文法框架，以获得更细粒度的对文法类别和产生式的控制？ 特征结构的主要形式化属性是什么，如何使用它们来计算？ 用基于特征的文法能捕捉到什么语言模式和文法结构？ 9.1 文法特征 基于规则的文法上下文中，特征和特征值对被称为特征结构 kim = {&#39;CAT&#39;: &#39;NP&#39;, &#39;ORTH&#39;: &#39;Kim&#39;, &#39;REF&#39;: &#39;k&#39;} chase = {&#39;CAT&#39;: &#39;V&#39;, &#39;ORTH&#39;: &#39;chased&#39;, &#39;REL&#39;: &#39;chase&#39;} chase[&#39;AGT&#39;] = &#39;sbj&#39; chase[&#39;PAT&#39;] = &#39;obj&#39; 一个简单的假设：在动词直接左侧和右侧的NP 分别是主语和宾语。 sent = &quot;Kim chased Lee&quot; tokens = sent.split() lee = {&#39;CAT&#39;: &#39;NP&#39;, &#39;ORTH&#39;: &#39;Lee&#39;, &#39;REF&#39;: &#39;l&#39;} def lex2fs(word): for fs in [kim, lee, chase]: if fs[&#39;ORTH&#39;] == word: return fs subj, verb, obj = lex2fs(tokens[0]), lex2fs(tokens[1]), lex2fs(tokens[2]) verb[&#39;AGT&#39;] = subj[&#39;REF&#39;] # agent of &#39;chase&#39; is Kim verb[&#39;PAT&#39;] = obj[&#39;REF&#39;] # patient of &#39;chase&#39; is Lee for k in [&#39;ORTH&#39;, &#39;REL&#39;, &#39;AGT&#39;, &#39;PAT&#39;]: # check featstruct of &#39;chase&#39; print(&quot;%-5s =&gt; %s&quot; % (k, verb[k])) ORTH =&gt; chased REL =&gt; chase AGT =&gt; k PAT =&gt; l surprise = {&#39;CAT&#39;: &#39;V&#39;, &#39;ORTH&#39;: &#39;surprised&#39;, &#39;REL&#39;: &#39;surprise&#39;, &#39;SRC&#39;: &#39;sbj&#39;, &#39;EXP&#39;: &#39;obj&#39;} 句法协议 动词的形态属性与主语名词短语的句法属性一起变化。这种一起变化被称为协议（agreement）。 表9-1. 英语规则动词的协议范式 单数 复数 第一人称 I run we run 第二人称 you run you run 第三人称 he/she/it runs they run 使用属性和约束 例9-1. 基于特征的文法的例子。 nltk.data.show_cfg(&#39;grammars/book_grammars/feat0.fcfg&#39;) % start S # ################### # Grammar Productions # ################### # S expansion productions S -&gt; NP[NUM=?n] VP[NUM=?n] # NP expansion productions NP[NUM=?n] -&gt; N[NUM=?n] NP[NUM=?n] -&gt; PropN[NUM=?n] NP[NUM=?n] -&gt; Det[NUM=?n] N[NUM=?n] NP[NUM=pl] -&gt; N[NUM=pl] # VP expansion productions VP[TENSE=?t, NUM=?n] -&gt; IV[TENSE=?t, NUM=?n] VP[TENSE=?t, NUM=?n] -&gt; TV[TENSE=?t, NUM=?n] NP # ################### # Lexical Productions # ################### Det[NUM=sg] -&gt; &#39;this&#39; | &#39;every&#39; Det[NUM=pl] -&gt; &#39;these&#39; | &#39;all&#39; Det -&gt; &#39;the&#39; | &#39;some&#39; | &#39;several&#39; PropN[NUM=sg]-&gt; &#39;Kim&#39; | &#39;Jody&#39; N[NUM=sg] -&gt; &#39;dog&#39; | &#39;girl&#39; | &#39;car&#39; | &#39;child&#39; N[NUM=pl] -&gt; &#39;dogs&#39; | &#39;girls&#39; | &#39;cars&#39; | &#39;children&#39; IV[TENSE=pres, NUM=sg] -&gt; &#39;disappears&#39; | &#39;walks&#39; TV[TENSE=pres, NUM=sg] -&gt; &#39;sees&#39; | &#39;likes&#39; IV[TENSE=pres, NUM=pl] -&gt; &#39;disappear&#39; | &#39;walk&#39; TV[TENSE=pres, NUM=pl] -&gt; &#39;see&#39; | &#39;like&#39; IV[TENSE=past] -&gt; &#39;disappeared&#39; | &#39;walked&#39; TV[TENSE=past] -&gt; &#39;saw&#39; | &#39;liked&#39; 例9-2. 跟踪基于特征的图表分析器 tokens = &#39;Kim likes children&#39;.split() from nltk import load_parser cp = load_parser(&#39;grammars/book_grammars/feat0.fcfg&#39;, trace=2) for tree in cp.parse(tokens): print(tree) |.Kim .like.chil.| Leaf Init Rule: |[----] . .| [0:1] &#39;Kim&#39; |. [----] .| [1:2] &#39;likes&#39; |. . [----]| [2:3] &#39;children&#39; Feature Bottom Up Predict Combine Rule: |[----] . .| [0:1] PropN[NUM=&#39;sg&#39;] -&gt; &#39;Kim&#39; * Feature Bottom Up Predict Combine Rule: |[----] . .| [0:1] NP[NUM=&#39;sg&#39;] -&gt; PropN[NUM=&#39;sg&#39;] * Feature Bottom Up Predict Combine Rule: |[----&gt; . .| [0:1] S[] -&gt; NP[NUM=?n] * VP[NUM=?n] {?n: &#39;sg&#39;} Feature Bottom Up Predict Combine Rule: |. [----] .| [1:2] TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] -&gt; &#39;likes&#39; * Feature Bottom Up Predict Combine Rule: |. [----&gt; .| [1:2] VP[NUM=?n, TENSE=?t] -&gt; TV[NUM=?n, TENSE=?t] * NP[] {?n: &#39;sg&#39;, ?t: &#39;pres&#39;} Feature Bottom Up Predict Combine Rule: |. . [----]| [2:3] N[NUM=&#39;pl&#39;] -&gt; &#39;children&#39; * Feature Bottom Up Predict Combine Rule: |. . [----]| [2:3] NP[NUM=&#39;pl&#39;] -&gt; N[NUM=&#39;pl&#39;] * Feature Bottom Up Predict Combine Rule: |. . [----&gt;| [2:3] S[] -&gt; NP[NUM=?n] * VP[NUM=?n] {?n: &#39;pl&#39;} Feature Single Edge Fundamental Rule: |. [---------]| [1:3] VP[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] -&gt; TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] NP[] * Feature Single Edge Fundamental Rule: |[==============]| [0:3] S[] -&gt; NP[NUM=&#39;sg&#39;] VP[NUM=&#39;sg&#39;] * (S[] (NP[NUM=&#39;sg&#39;] (PropN[NUM=&#39;sg&#39;] Kim)) (VP[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] (TV[NUM=&#39;sg&#39;, TENSE=&#39;pres&#39;] likes) (NP[NUM=&#39;pl&#39;] (N[NUM=&#39;pl&#39;] children)))) 术语 9.2 处理特征结构 NLTK 中的特征结构使用构造函数FeatStruct()声明。原子特征值可以是字符串或整数。 fs1 = nltk.FeatStruct(TENSE=&#39;past&#39;, NUM=&#39;sg&#39;) print(fs1) [ NUM = &#39;sg&#39; ] [ TENSE = &#39;past&#39; ] fs1 = nltk.FeatStruct(PER=3, NUM=&#39;pl&#39;, GND=&#39;fem&#39;) print(fs1[&#39;GND&#39;]) fem fs1[&#39;CASE&#39;] = &#39;acc&#39; fs2 = nltk.FeatStruct(POS=&#39;N&#39;, AGR=fs1) print(fs2) [ [ CASE = &#39;acc&#39; ] ] [ AGR = [ GND = &#39;fem&#39; ] ] [ [ NUM = &#39;pl&#39; ] ] [ [ PER = 3 ] ] [ ] [ POS = &#39;N&#39; ] print(fs2[&#39;AGR&#39;]) [ CASE = &#39;acc&#39; ] [ GND = &#39;fem&#39; ] [ NUM = &#39;pl&#39; ] [ PER = 3 ] print(fs2[&#39;AGR&#39;][&#39;PER&#39;]) 3 print(nltk.FeatStruct(&quot;[POS=&#39;N&#39;, AGR=[PER=3, NUM=&#39;pl&#39;, GND=&#39;fem&#39;]]&quot;)) [ [ GND = &#39;fem&#39; ] ] [ AGR = [ NUM = &#39;pl&#39; ] ] [ [ PER = 3 ] ] [ ] [ POS = &#39;N&#39; ] print(nltk.FeatStruct(NAME=&#39;Lee&#39;, TELNO=&#39;01 27 86 42 96&#39;, AGE=33)) [ AGE = 33 ] [ NAME = &#39;Lee&#39; ] [ TELNO = &#39;01 27 86 42 96&#39; ] print(nltk.FeatStruct(&quot;&quot;&quot;[NAME=&#39;Lee&#39;, ADDRESS=(1)[NUMBER=74, STREET=&#39;rue Pascal&#39;],SPOUSE=[NAME=&#39;Kim&#39;, ADDRESS-&gt;(1)]]&quot;&quot;&quot;)) [ ADDRESS = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ SPOUSE = [ ADDRESS -&gt; (1) ] ] [ [ NAME = &#39;Kim&#39; ] ] print(nltk.FeatStruct(&quot;[A=&#39;a&#39;, B=(1)[C=&#39;c&#39;], D-&gt;(1), E-&gt;(1)]&quot;)) [ A = &#39;a&#39; ] [ ] [ B = (1) [ C = &#39;c&#39; ] ] [ ] [ D -&gt; (1) ] [ E -&gt; (1) ] 包含和统一 fs1 = nltk.FeatStruct(NUMBER=74, STREET=&#39;rue Pascal&#39;) fs2 = nltk.FeatStruct(CITY=&#39;Paris&#39;) print(fs2.unify(fs1)) [ CITY = &#39;Paris&#39; ] [ NUMBER = 74 ] [ STREET = &#39;rue Pascal&#39; ] fs0 = nltk.FeatStruct(A=&#39;a&#39;) fs1 = nltk.FeatStruct(A=&#39;b&#39;) fs2 = fs0.unify(fs1) print(fs2) None fs0 = nltk.FeatStruct(&quot;&quot;&quot;[NAME=Lee, ADDRESS=[NUMBER=74, STREET=&#39;rue Pascal&#39;], SPOUSE= [NAME=Kim, ADDRESS=[NUMBER=74, STREET=&#39;rue Pascal&#39;]]]&quot;&quot;&quot;) print(fs0) [ ADDRESS = [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ [ ADDRESS = [ NUMBER = 74 ] ] ] [ SPOUSE = [ [ STREET = &#39;rue Pascal&#39; ] ] ] [ [ ] ] [ [ NAME = &#39;Kim&#39; ] ] fs1 = nltk.FeatStruct(&quot;[SPOUSE = [ADDRESS = [CITY = Paris]]]&quot;) print(fs1.unify(fs0)) [ ADDRESS = [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ [ [ CITY = &#39;Paris&#39; ] ] ] [ [ ADDRESS = [ NUMBER = 74 ] ] ] [ SPOUSE = [ [ STREET = &#39;rue Pascal&#39; ] ] ] [ [ ] ] [ [ NAME = &#39;Kim&#39; ] ] fs2 = nltk.FeatStruct(&quot;&quot;&quot;[NAME=Lee, ADDRESS=(1)[NUMBER=74, STREET=&#39;rue Pascal&#39;], SPOUSE=[NAME=Kim, ADDRESS-&gt;(1)]]&quot;&quot;&quot;) print(fs1.unify(fs2)) [ [ CITY = &#39;Paris&#39; ] ] [ ADDRESS = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ NAME = &#39;Lee&#39; ] [ ] [ SPOUSE = [ ADDRESS -&gt; (1) ] ] [ [ NAME = &#39;Kim&#39; ] ] fs1 = nltk.FeatStruct(&quot;[ADDRESS1=[NUMBER=74, STREET=&#39;rue Pascal&#39;]]&quot;) fs2 = nltk.FeatStruct(&quot;[ADDRESS1=?x, ADDRESS2=?x]&quot;) print(fs2) [ ADDRESS1 = ?x ] [ ADDRESS2 = ?x ] print(fs2.unify(fs1)) [ ADDRESS1 = (1) [ NUMBER = 74 ] ] [ [ STREET = &#39;rue Pascal&#39; ] ] [ ] [ ADDRESS2 -&gt; (1) ] 9.3 扩展基于特征的文法 子类别 核心词回顾 助动词与倒装 无限制依赖成分 例9-3. 具有倒装从句和长距离依赖的产生式的文法，使用斜线类别。 nltk.data.show_cfg(&#39;grammars/book_grammars/feat1.fcfg&#39;) % start S # ################### # Grammar Productions # ################### S[-INV] -&gt; NP VP S[-INV]/?x -&gt; NP VP/?x S[-INV] -&gt; NP S/NP S[-INV] -&gt; Adv[+NEG] S[+INV] S[+INV] -&gt; V[+AUX] NP VP S[+INV]/?x -&gt; V[+AUX] NP VP/?x SBar -&gt; Comp S[-INV] SBar/?x -&gt; Comp S[-INV]/?x VP -&gt; V[SUBCAT=intrans, -AUX] VP -&gt; V[SUBCAT=trans, -AUX] NP VP/?x -&gt; V[SUBCAT=trans, -AUX] NP/?x VP -&gt; V[SUBCAT=clause, -AUX] SBar VP/?x -&gt; V[SUBCAT=clause, -AUX] SBar/?x VP -&gt; V[+AUX] VP VP/?x -&gt; V[+AUX] VP/?x # ################### # Lexical Productions # ################### V[SUBCAT=intrans, -AUX] -&gt; &#39;walk&#39; | &#39;sing&#39; V[SUBCAT=trans, -AUX] -&gt; &#39;see&#39; | &#39;like&#39; V[SUBCAT=clause, -AUX] -&gt; &#39;say&#39; | &#39;claim&#39; V[+AUX] -&gt; &#39;do&#39; | &#39;can&#39; NP[-WH] -&gt; &#39;you&#39; | &#39;cats&#39; NP[+WH] -&gt; &#39;who&#39; Adv[+NEG] -&gt; &#39;rarely&#39; | &#39;never&#39; NP/NP -&gt; Comp -&gt; &#39;that&#39; tokens = &#39;who do you claim that you like&#39;.split() from nltk import load_parser cp = load_parser(&#39;grammars/book_grammars/feat1.fcfg&#39;) for tree in cp.parse(tokens): print(tree) (S[-INV] (NP[+WH] who) (S[+INV]/NP[] (V[+AUX] do) (NP[-WH] you) (VP[]/NP[] (V[-AUX, SUBCAT=&#39;clause&#39;] claim) (SBar[]/NP[] (Comp[] that) (S[-INV]/NP[] (NP[-WH] you) (VP[]/NP[] (V[-AUX, SUBCAT=&#39;trans&#39;] like) (NP[]/NP[] ))))))) tokens = &#39;you claim that you like cats&#39;.split() for tree in cp.parse(tokens): print(tree) (S[-INV] (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;clause&#39;] claim) (SBar[] (Comp[] that) (S[-INV] (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;trans&#39;] like) (NP[-WH] cats)))))) tokens = &#39;rarely do you sing&#39;.split() for tree in cp.parse(tokens): print(tree) (S[-INV] (Adv[+NEG] rarely) (S[+INV] (V[+AUX] do) (NP[-WH] you) (VP[] (V[-AUX, SUBCAT=&#39;intrans&#39;] sing)))) 9.4 小结 上下文无关文法的传统分类是原子符号。特征结构的一个重要的作用是捕捉精细的区分，否则将需要数量翻倍的原子类别。 通过使用特征值上的变量，我们可以表达文法产生式中的限制，允许不同的特征规格的实现可以相互依赖。 通常情况下，我们在词汇层面指定固定的特征值，限制短语中的特征值与它们的原子中的对应值统一。 特征值可以是原子的或复杂的。原子值的一个特定类别是布尔值，按照惯例用[+/- feat]表示。 两个特征可以共享一个值（原子的或复杂的）。具有共享值的结构被称为重入。共享的值被表示为AVM 中的数字索引（或标记）。 一个特征结构中的路径是一个特征的元组，对应从图的根开始的弧的序列上的标签。 两条路径是等价的，如果它们共享一个值。 包含的特征结构是偏序的。FS0 包含FS1，当FS0 比FS1 更一般（较少信息）。 两种结构FS0 和FS1 的统一，如果成功，就是包含FS0 和FS1 的合并信息的特征结构FS2。 如果统一在FS 中指定一条路径π，那么它也指定等效与π的每个路径π’。 我们可以使用特征结构建立对大量广泛语言学现象的简洁的分析，包括动词子类别，倒装结构，无限制依赖结构和格支配。 致谢 《Python自然语言处理》123 4，作者：Steven Bird, Ewan Klein &amp; Edward Loper，是实践性很强的一部入门读物，2009年第一版，2015年第二版，本学习笔记结合上述版本，对部分内容进行了延伸学习、练习，在此分享，期待对大家有所帮助，欢迎加我微信（验证：NLP），一起学习讨论，不足之处，欢迎指正。 参考文献 http://nltk.org/ ↩︎ Steven Bird, Ewan Klein &amp; Edward Loper,Natural Language Processing with Python,2009 ↩︎ （英）伯德，（英）克莱因，（美）洛普，《Python自然语言处理》，2010年，东南大学出版社 ↩︎ Steven Bird, Ewan Klein &amp; Edward Loper,Natural Language Processing with Python,2015 ↩︎","@type":"BlogPosting","url":"/2019/01/17/0493318f9da7dbf2bf357e4add60fc2d.html","headline":"《Python自然语言处理（第二版）-Steven Bird等》学习笔记：第09章 建立基于特征的文法","dateModified":"2019-01-17T00:00:00+08:00","datePublished":"2019-01-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/01/17/0493318f9da7dbf2bf357e4add60fc2d.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>《Python自然语言处理（第二版）-Steven Bird等》学习笔记：第09章 建立基于特征的文法</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/weixin_43935926/article/details/86528015 
 </div> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p></p>
  <div class="toc">
   <h3>第09章 建立基于特征的文法</h3>
   <ul>
    <li><a href="#91__10" rel="nofollow">9.1 文法特征</a></li>
    <ul>
     <li><a href="#_92" rel="nofollow">句法协议</a></li>
     <li><a href="#_104" rel="nofollow">使用属性和约束</a></li>
     <li><a href="#_199" rel="nofollow">术语</a></li>
    </ul>
    <li><a href="#92__201" rel="nofollow">9.2 处理特征结构</a></li>
    <ul>
     <li><a href="#_323" rel="nofollow">包含和统一</a></li>
    </ul>
    <li><a href="#93__467" rel="nofollow">9.3 扩展基于特征的文法</a></li>
    <ul>
     <li><a href="#_469" rel="nofollow">子类别</a></li>
     <li><a href="#_471" rel="nofollow">核心词回顾</a></li>
     <li><a href="#_473" rel="nofollow">助动词与倒装</a></li>
     <li><a href="#_475" rel="nofollow">无限制依赖成分</a></li>
    </ul>
    <li><a href="#94__593" rel="nofollow">9.4 小结</a></li>
   </ul>
  </div>
  <p></p> 
  <pre><code class="prism language-python"><span class="token keyword">import</span> nltk
</code></pre> 
  <ol> 
   <li>怎样用特征扩展上下文无关文法框架，以获得更细粒度的对文法类别和产生式的控制？</li> 
   <li>特征结构的主要形式化属性是什么，如何使用它们来计算？</li> 
   <li>用基于特征的文法能捕捉到什么语言模式和文法结构？</li> 
  </ol> 
  <h1><a id="91__10"></a>9.1 文法特征</h1> 
  <p>基于规则的文法上下文中，特征和特征值对被称为特征结构</p> 
  <pre><code class="prism language-python">kim <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'CAT'</span><span class="token punctuation">:</span> <span class="token string">'NP'</span><span class="token punctuation">,</span> <span class="token string">'ORTH'</span><span class="token punctuation">:</span> <span class="token string">'Kim'</span><span class="token punctuation">,</span> <span class="token string">'REF'</span><span class="token punctuation">:</span> <span class="token string">'k'</span><span class="token punctuation">}</span>
</code></pre> 
  <pre><code class="prism language-python">chase <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'CAT'</span><span class="token punctuation">:</span> <span class="token string">'V'</span><span class="token punctuation">,</span> <span class="token string">'ORTH'</span><span class="token punctuation">:</span> <span class="token string">'chased'</span><span class="token punctuation">,</span> <span class="token string">'REL'</span><span class="token punctuation">:</span> <span class="token string">'chase'</span><span class="token punctuation">}</span>
</code></pre> 
  <pre><code class="prism language-python">chase<span class="token punctuation">[</span><span class="token string">'AGT'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'sbj'</span>
</code></pre> 
  <pre><code class="prism language-python">chase<span class="token punctuation">[</span><span class="token string">'PAT'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'obj'</span>
</code></pre> 
  <p>一个简单的假设：在动词直接左侧和右侧的NP 分别是主语和宾语。</p> 
  <pre><code class="prism language-python">sent <span class="token operator">=</span> <span class="token string">"Kim chased Lee"</span>
</code></pre> 
  <pre><code class="prism language-python">tokens <span class="token operator">=</span> sent<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python">lee <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'CAT'</span><span class="token punctuation">:</span> <span class="token string">'NP'</span><span class="token punctuation">,</span> <span class="token string">'ORTH'</span><span class="token punctuation">:</span> <span class="token string">'Lee'</span><span class="token punctuation">,</span> <span class="token string">'REF'</span><span class="token punctuation">:</span> <span class="token string">'l'</span><span class="token punctuation">}</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">lex2fs</span><span class="token punctuation">(</span>word<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> fs <span class="token keyword">in</span> <span class="token punctuation">[</span>kim<span class="token punctuation">,</span> lee<span class="token punctuation">,</span> chase<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> fs<span class="token punctuation">[</span><span class="token string">'ORTH'</span><span class="token punctuation">]</span> <span class="token operator">==</span> word<span class="token punctuation">:</span>
            <span class="token keyword">return</span> fs
</code></pre> 
  <pre><code class="prism language-python">subj<span class="token punctuation">,</span> verb<span class="token punctuation">,</span> obj <span class="token operator">=</span> lex2fs<span class="token punctuation">(</span>tokens<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lex2fs<span class="token punctuation">(</span>tokens<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lex2fs<span class="token punctuation">(</span>tokens<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python">verb<span class="token punctuation">[</span><span class="token string">'AGT'</span><span class="token punctuation">]</span> <span class="token operator">=</span> subj<span class="token punctuation">[</span><span class="token string">'REF'</span><span class="token punctuation">]</span> <span class="token comment"># agent of 'chase' is Kim</span>
</code></pre> 
  <pre><code class="prism language-python">verb<span class="token punctuation">[</span><span class="token string">'PAT'</span><span class="token punctuation">]</span> <span class="token operator">=</span> obj<span class="token punctuation">[</span><span class="token string">'REF'</span><span class="token punctuation">]</span> <span class="token comment"># patient of 'chase' is Lee</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'ORTH'</span><span class="token punctuation">,</span> <span class="token string">'REL'</span><span class="token punctuation">,</span> <span class="token string">'AGT'</span><span class="token punctuation">,</span> <span class="token string">'PAT'</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token comment"># check featstruct of 'chase'</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"%-5s =&gt; %s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>k<span class="token punctuation">,</span> verb<span class="token punctuation">[</span>k<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>ORTH  =&gt; chased
REL   =&gt; chase
AGT   =&gt; k
PAT   =&gt; l
</code></pre> 
  <pre><code class="prism language-python">surprise <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'CAT'</span><span class="token punctuation">:</span> <span class="token string">'V'</span><span class="token punctuation">,</span> <span class="token string">'ORTH'</span><span class="token punctuation">:</span> <span class="token string">'surprised'</span><span class="token punctuation">,</span> <span class="token string">'REL'</span><span class="token punctuation">:</span> <span class="token string">'surprise'</span><span class="token punctuation">,</span>
            <span class="token string">'SRC'</span><span class="token punctuation">:</span> <span class="token string">'sbj'</span><span class="token punctuation">,</span> <span class="token string">'EXP'</span><span class="token punctuation">:</span> <span class="token string">'obj'</span><span class="token punctuation">}</span>
</code></pre> 
  <h2><a id="_92"></a>句法协议</h2> 
  <p>动词的形态属性与主语名词短语的句法属性一起变化。这种一起变化被称为<strong>协议</strong>（agreement）。</p> 
  <p>表9-1. 英语规则动词的协议范式</p> 
  <table> 
   <thead> 
    <tr> 
     <th>单数</th> 
     <th>复数</th> 
    </tr> 
   </thead> 
   <tbody> 
    <tr> 
     <td>第一人称</td> 
     <td>I run we run</td> 
    </tr> 
    <tr> 
     <td>第二人称</td> 
     <td>you run you run</td> 
    </tr> 
    <tr> 
     <td>第三人称</td> 
     <td>he/she/it runs they run</td> 
    </tr> 
   </tbody> 
  </table>
  <h2><a id="_104"></a>使用属性和约束</h2> 
  <p><em>例9-1. 基于特征的文法的例子。</em></p> 
  <pre><code class="prism language-python">nltk<span class="token punctuation">.</span>data<span class="token punctuation">.</span>show_cfg<span class="token punctuation">(</span><span class="token string">'grammars/book_grammars/feat0.fcfg'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>% start S
# ###################
# Grammar Productions
# ###################
# S expansion productions
S -&gt; NP[NUM=?n] VP[NUM=?n]
# NP expansion productions
NP[NUM=?n] -&gt; N[NUM=?n] 
NP[NUM=?n] -&gt; PropN[NUM=?n] 
NP[NUM=?n] -&gt; Det[NUM=?n] N[NUM=?n]
NP[NUM=pl] -&gt; N[NUM=pl] 
# VP expansion productions
VP[TENSE=?t, NUM=?n] -&gt; IV[TENSE=?t, NUM=?n]
VP[TENSE=?t, NUM=?n] -&gt; TV[TENSE=?t, NUM=?n] NP
# ###################
# Lexical Productions
# ###################
Det[NUM=sg] -&gt; 'this' | 'every'
Det[NUM=pl] -&gt; 'these' | 'all'
Det -&gt; 'the' | 'some' | 'several'
PropN[NUM=sg]-&gt; 'Kim' | 'Jody'
N[NUM=sg] -&gt; 'dog' | 'girl' | 'car' | 'child'
N[NUM=pl] -&gt; 'dogs' | 'girls' | 'cars' | 'children' 
IV[TENSE=pres,  NUM=sg] -&gt; 'disappears' | 'walks'
TV[TENSE=pres, NUM=sg] -&gt; 'sees' | 'likes'
IV[TENSE=pres,  NUM=pl] -&gt; 'disappear' | 'walk'
TV[TENSE=pres, NUM=pl] -&gt; 'see' | 'like'
IV[TENSE=past] -&gt; 'disappeared' | 'walked'
TV[TENSE=past] -&gt; 'saw' | 'liked'
</code></pre> 
  <p><em>例9-2. 跟踪基于特征的图表分析器</em></p> 
  <pre><code class="prism language-python">tokens <span class="token operator">=</span> <span class="token string">'Kim likes children'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">from</span> nltk <span class="token keyword">import</span> load_parser
</code></pre> 
  <pre><code class="prism language-python">cp <span class="token operator">=</span> load_parser<span class="token punctuation">(</span><span class="token string">'grammars/book_grammars/feat0.fcfg'</span><span class="token punctuation">,</span> trace<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">for</span> tree <span class="token keyword">in</span> cp<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tree<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>|.Kim .like.chil.|
Leaf Init Rule:
|[----]    .    .| [0:1] 'Kim'
|.    [----]    .| [1:2] 'likes'
|.    .    [----]| [2:3] 'children'
Feature Bottom Up Predict Combine Rule:
|[----]    .    .| [0:1] PropN[NUM='sg'] -&gt; 'Kim' *
Feature Bottom Up Predict Combine Rule:
|[----]    .    .| [0:1] NP[NUM='sg'] -&gt; PropN[NUM='sg'] *
Feature Bottom Up Predict Combine Rule:
|[----&gt;    .    .| [0:1] S[] -&gt; NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}
Feature Bottom Up Predict Combine Rule:
|.    [----]    .| [1:2] TV[NUM='sg', TENSE='pres'] -&gt; 'likes' *
Feature Bottom Up Predict Combine Rule:
|.    [----&gt;    .| [1:2] VP[NUM=?n, TENSE=?t] -&gt; TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}
Feature Bottom Up Predict Combine Rule:
|.    .    [----]| [2:3] N[NUM='pl'] -&gt; 'children' *
Feature Bottom Up Predict Combine Rule:
|.    .    [----]| [2:3] NP[NUM='pl'] -&gt; N[NUM='pl'] *
Feature Bottom Up Predict Combine Rule:
|.    .    [----&gt;| [2:3] S[] -&gt; NP[NUM=?n] * VP[NUM=?n] {?n: 'pl'}
Feature Single Edge Fundamental Rule:
|.    [---------]| [1:3] VP[NUM='sg', TENSE='pres'] -&gt; TV[NUM='sg', TENSE='pres'] NP[] *
Feature Single Edge Fundamental Rule:
|[==============]| [0:3] S[] -&gt; NP[NUM='sg'] VP[NUM='sg'] *
(S[]
  (NP[NUM='sg'] (PropN[NUM='sg'] Kim))
  (VP[NUM='sg', TENSE='pres']
    (TV[NUM='sg', TENSE='pres'] likes)
    (NP[NUM='pl'] (N[NUM='pl'] children))))
</code></pre> 
  <h2><a id="_199"></a>术语</h2> 
  <h1><a id="92__201"></a>9.2 处理特征结构</h1> 
  <p>NLTK 中的特征结构使用构造函数FeatStruct()声明。原子特征值可以是字符串或整数。</p> 
  <pre><code class="prism language-python">fs1 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span>TENSE<span class="token operator">=</span><span class="token string">'past'</span><span class="token punctuation">,</span> NUM<span class="token operator">=</span><span class="token string">'sg'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs1<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ NUM   = 'sg'   ]
[ TENSE = 'past' ]
</code></pre> 
  <pre><code class="prism language-python">fs1 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span>PER<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> NUM<span class="token operator">=</span><span class="token string">'pl'</span><span class="token punctuation">,</span> GND<span class="token operator">=</span><span class="token string">'fem'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs1<span class="token punctuation">[</span><span class="token string">'GND'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>fem
</code></pre> 
  <pre><code class="prism language-python">fs1<span class="token punctuation">[</span><span class="token string">'CASE'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'acc'</span>
</code></pre> 
  <pre><code class="prism language-python">fs2 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span>POS<span class="token operator">=</span><span class="token string">'N'</span><span class="token punctuation">,</span> AGR<span class="token operator">=</span>fs1<span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs2<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[       [ CASE = 'acc' ] ]
[ AGR = [ GND  = 'fem' ] ]
[       [ NUM  = 'pl'  ] ]
[       [ PER  = 3     ] ]
[                        ]
[ POS = 'N'              ]
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs2<span class="token punctuation">[</span><span class="token string">'AGR'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ CASE = 'acc' ]
[ GND  = 'fem' ]
[ NUM  = 'pl'  ]
[ PER  = 3     ]
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs2<span class="token punctuation">[</span><span class="token string">'AGR'</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'PER'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>3
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span><span class="token string">"[POS='N', AGR=[PER=3, NUM='pl', GND='fem']]"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[       [ GND = 'fem' ] ]
[ AGR = [ NUM = 'pl'  ] ]
[       [ PER = 3     ] ]
[                       ]
[ POS = 'N'             ]
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span>NAME<span class="token operator">=</span><span class="token string">'Lee'</span><span class="token punctuation">,</span> TELNO<span class="token operator">=</span><span class="token string">'01 27 86 42 96'</span><span class="token punctuation">,</span> AGE<span class="token operator">=</span><span class="token number">33</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ AGE   = 33               ]
[ NAME  = 'Lee'            ]
[ TELNO = '01 27 86 42 96' ]
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""[NAME='Lee', ADDRESS=(1)[NUMBER=74, STREET='rue Pascal'],SPOUSE=[NAME='Kim', ADDRESS-&gt;(1)]]"""</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ ADDRESS = (1) [ NUMBER = 74           ] ]
[               [ STREET = 'rue Pascal' ] ]
[                                         ]
[ NAME    = 'Lee'                         ]
[                                         ]
[ SPOUSE  = [ ADDRESS -&gt; (1)  ]           ]
[           [ NAME    = 'Kim' ]           ]
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span><span class="token string">"[A='a', B=(1)[C='c'], D-&gt;(1), E-&gt;(1)]"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ A = 'a'             ]
[                     ]
[ B = (1) [ C = 'c' ] ]
[                     ]
[ D -&gt; (1)            ]
[ E -&gt; (1)            ]
</code></pre> 
  <h2><a id="_323"></a>包含和统一</h2> 
  <pre><code class="prism language-python">fs1 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span>NUMBER<span class="token operator">=</span><span class="token number">74</span><span class="token punctuation">,</span> STREET<span class="token operator">=</span><span class="token string">'rue Pascal'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python">fs2 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span>CITY<span class="token operator">=</span><span class="token string">'Paris'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs2<span class="token punctuation">.</span>unify<span class="token punctuation">(</span>fs1<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ CITY   = 'Paris'      ]
[ NUMBER = 74           ]
[ STREET = 'rue Pascal' ]
</code></pre> 
  <pre><code class="prism language-python">fs0 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span>A<span class="token operator">=</span><span class="token string">'a'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python">fs1 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span>A<span class="token operator">=</span><span class="token string">'b'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python">fs2 <span class="token operator">=</span> fs0<span class="token punctuation">.</span>unify<span class="token punctuation">(</span>fs1<span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs2<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>None
</code></pre> 
  <pre><code class="prism language-python">fs0 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""[NAME=Lee, ADDRESS=[NUMBER=74, STREET='rue Pascal'], SPOUSE= [NAME=Kim, ADDRESS=[NUMBER=74, STREET='rue Pascal']]]"""</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs0<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ ADDRESS = [ NUMBER = 74           ]               ]
[           [ STREET = 'rue Pascal' ]               ]
[                                                   ]
[ NAME    = 'Lee'                                   ]
[                                                   ]
[           [ ADDRESS = [ NUMBER = 74           ] ] ]
[ SPOUSE  = [           [ STREET = 'rue Pascal' ] ] ]
[           [                                     ] ]
[           [ NAME    = 'Kim'                     ] ]
</code></pre> 
  <pre><code class="prism language-python">fs1 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span><span class="token string">"[SPOUSE = [ADDRESS = [CITY = Paris]]]"</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs1<span class="token punctuation">.</span>unify<span class="token punctuation">(</span>fs0<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ ADDRESS = [ NUMBER = 74           ]               ]
[           [ STREET = 'rue Pascal' ]               ]
[                                                   ]
[ NAME    = 'Lee'                                   ]
[                                                   ]
[           [           [ CITY   = 'Paris'      ] ] ]
[           [ ADDRESS = [ NUMBER = 74           ] ] ]
[ SPOUSE  = [           [ STREET = 'rue Pascal' ] ] ]
[           [                                     ] ]
[           [ NAME    = 'Kim'                     ] ]
</code></pre> 
  <pre><code class="prism language-python">fs2 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span><span class="token triple-quoted-string string">"""[NAME=Lee, ADDRESS=(1)[NUMBER=74, STREET='rue Pascal'], SPOUSE=[NAME=Kim, ADDRESS-&gt;(1)]]"""</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs1<span class="token punctuation">.</span>unify<span class="token punctuation">(</span>fs2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[               [ CITY   = 'Paris'      ] ]
[ ADDRESS = (1) [ NUMBER = 74           ] ]
[               [ STREET = 'rue Pascal' ] ]
[                                         ]
[ NAME    = 'Lee'                         ]
[                                         ]
[ SPOUSE  = [ ADDRESS -&gt; (1)  ]           ]
[           [ NAME    = 'Kim' ]           ]
</code></pre> 
  <pre><code class="prism language-python">fs1 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span><span class="token string">"[ADDRESS1=[NUMBER=74, STREET='rue Pascal']]"</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python">fs2 <span class="token operator">=</span> nltk<span class="token punctuation">.</span>FeatStruct<span class="token punctuation">(</span><span class="token string">"[ADDRESS1=?x, ADDRESS2=?x]"</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs2<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ ADDRESS1 = ?x ]
[ ADDRESS2 = ?x ]
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>fs2<span class="token punctuation">.</span>unify<span class="token punctuation">(</span>fs1<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>[ ADDRESS1 = (1) [ NUMBER = 74           ] ]
[                [ STREET = 'rue Pascal' ] ]
[                                          ]
[ ADDRESS2 -&gt; (1)                          ]
</code></pre> 
  <h1><a id="93__467"></a>9.3 扩展基于特征的文法</h1> 
  <h2><a id="_469"></a>子类别</h2> 
  <h2><a id="_471"></a>核心词回顾</h2> 
  <h2><a id="_473"></a>助动词与倒装</h2> 
  <h2><a id="_475"></a>无限制依赖成分</h2> 
  <p><em>例9-3. 具有倒装从句和长距离依赖的产生式的文法，使用斜线类别。</em></p> 
  <pre><code class="prism language-python">nltk<span class="token punctuation">.</span>data<span class="token punctuation">.</span>show_cfg<span class="token punctuation">(</span><span class="token string">'grammars/book_grammars/feat1.fcfg'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>% start S
# ###################
# Grammar Productions
# ###################
S[-INV] -&gt; NP VP
S[-INV]/?x -&gt; NP VP/?x
S[-INV] -&gt; NP S/NP
S[-INV] -&gt; Adv[+NEG] S[+INV]
S[+INV] -&gt; V[+AUX] NP VP
S[+INV]/?x -&gt; V[+AUX] NP VP/?x
SBar -&gt; Comp S[-INV]
SBar/?x -&gt; Comp S[-INV]/?x
VP -&gt; V[SUBCAT=intrans, -AUX]
VP -&gt; V[SUBCAT=trans, -AUX] NP
VP/?x -&gt; V[SUBCAT=trans, -AUX] NP/?x
VP -&gt; V[SUBCAT=clause, -AUX] SBar
VP/?x -&gt; V[SUBCAT=clause, -AUX] SBar/?x
VP -&gt; V[+AUX] VP
VP/?x -&gt; V[+AUX] VP/?x
# ###################
# Lexical Productions
# ###################
V[SUBCAT=intrans, -AUX] -&gt; 'walk' | 'sing'
V[SUBCAT=trans, -AUX] -&gt; 'see' | 'like'
V[SUBCAT=clause, -AUX] -&gt; 'say' | 'claim'
V[+AUX] -&gt; 'do' | 'can'
NP[-WH] -&gt; 'you' | 'cats'
NP[+WH] -&gt; 'who'
Adv[+NEG] -&gt; 'rarely' | 'never'
NP/NP -&gt;
Comp -&gt; 'that'
</code></pre> 
  <pre><code class="prism language-python">tokens <span class="token operator">=</span> <span class="token string">'who do you claim that you like'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">from</span> nltk <span class="token keyword">import</span> load_parser
</code></pre> 
  <pre><code class="prism language-python">cp <span class="token operator">=</span> load_parser<span class="token punctuation">(</span><span class="token string">'grammars/book_grammars/feat1.fcfg'</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">for</span> tree <span class="token keyword">in</span> cp<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tree<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>(S[-INV]
  (NP[+WH] who)
  (S[+INV]/NP[]
    (V[+AUX] do)
    (NP[-WH] you)
    (VP[]/NP[]
      (V[-AUX, SUBCAT='clause'] claim)
      (SBar[]/NP[]
        (Comp[] that)
        (S[-INV]/NP[]
          (NP[-WH] you)
          (VP[]/NP[] (V[-AUX, SUBCAT='trans'] like) (NP[]/NP[] )))))))
</code></pre> 
  <pre><code class="prism language-python">tokens <span class="token operator">=</span> <span class="token string">'you claim that you like cats'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">for</span> tree <span class="token keyword">in</span> cp<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tree<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>(S[-INV]
  (NP[-WH] you)
  (VP[]
    (V[-AUX, SUBCAT='clause'] claim)
    (SBar[]
      (Comp[] that)
      (S[-INV]
        (NP[-WH] you)
        (VP[] (V[-AUX, SUBCAT='trans'] like) (NP[-WH] cats))))))
</code></pre> 
  <pre><code class="prism language-python">tokens <span class="token operator">=</span> <span class="token string">'rarely do you sing'</span><span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token keyword">for</span> tree <span class="token keyword">in</span> cp<span class="token punctuation">.</span>parse<span class="token punctuation">(</span>tokens<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>tree<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>(S[-INV]
  (Adv[+NEG] rarely)
  (S[+INV]
    (V[+AUX] do)
    (NP[-WH] you)
    (VP[] (V[-AUX, SUBCAT='intrans'] sing))))
</code></pre> 
  <h1><a id="94__593"></a>9.4 小结</h1> 
  <ul> 
   <li>上下文无关文法的传统分类是原子符号。特征结构的一个重要的作用是捕捉精细的区分，否则将需要数量翻倍的原子类别。</li> 
   <li>通过使用特征值上的变量，我们可以表达文法产生式中的限制，允许不同的特征规格的实现可以相互依赖。</li> 
   <li>通常情况下，我们在词汇层面指定固定的特征值，限制短语中的特征值与它们的原子中的对应值统一。</li> 
   <li>特征值可以是原子的或复杂的。原子值的一个特定类别是布尔值，按照惯例用[+/- feat]表示。</li> 
   <li>两个特征可以共享一个值（原子的或复杂的）。具有共享值的结构被称为重入。共享的值被表示为AVM 中的数字索引（或标记）。</li> 
   <li>一个特征结构中的路径是一个特征的元组，对应从图的根开始的弧的序列上的标签。</li> 
   <li>两条路径是等价的，如果它们共享一个值。</li> 
   <li>包含的特征结构是偏序的。FS0 包含FS1，当FS0 比FS1 更一般（较少信息）。</li> 
   <li>两种结构FS0 和FS1 的统一，如果成功，就是包含FS0 和FS1 的合并信息的特征结构FS2。</li> 
   <li>如果统一在FS 中指定一条路径π，那么它也指定等效与π的每个路径π’。</li> 
   <li>我们可以使用特征结构建立对大量广泛语言学现象的简洁的分析，包括动词子类别，倒装结构，无限制依赖结构和格支配。</li> 
  </ul> 
  <pre><code class="prism language-python">
</code></pre> 
  <p><strong>致谢</strong><br> 《Python自然语言处理》<sup class="footnote-ref"><a href="#fn1" rel="nofollow" id="fnref1">1</a></sup><sup class="footnote-ref"><a href="#fn2" rel="nofollow" id="fnref2">2</a></sup><sup class="footnote-ref"><a href="#fn3" rel="nofollow" id="fnref3">3</a></sup> <sup class="footnote-ref"><a href="#fn4" rel="nofollow" id="fnref4">4</a></sup>，作者：Steven Bird, Ewan Klein &amp; Edward Loper，是实践性很强的一部入门读物，2009年第一版，2015年第二版，本学习笔记结合上述版本，对部分内容进行了延伸学习、练习，在此分享，期待对大家有所帮助，欢迎加我微信（验证：NLP），一起学习讨论，不足之处，欢迎指正。<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190106111608264.png" alt="在这里插入图片描述"></p> 
  <p>参考文献</p> 
  <hr class="footnotes-sep"> 
  <section class="footnotes"> 
   <ol class="footnotes-list"> 
    <li id="fn1" class="footnote-item"><p><a href="http://nltk.org/" rel="nofollow">http://nltk.org/</a> <a href="#fnref1" rel="nofollow" class="footnote-backref">↩︎</a></p> </li> 
    <li id="fn2" class="footnote-item"><p>Steven Bird, Ewan Klein &amp; Edward Loper,Natural Language Processing with Python,2009 <a href="#fnref2" rel="nofollow" class="footnote-backref">↩︎</a></p> </li> 
    <li id="fn3" class="footnote-item"><p>（英）伯德，（英）克莱因，（美）洛普，《Python自然语言处理》，2010年，东南大学出版社 <a href="#fnref3" rel="nofollow" class="footnote-backref">↩︎</a></p> </li> 
    <li id="fn4" class="footnote-item"><p>Steven Bird, Ewan Klein &amp; Edward Loper,Natural Language Processing with Python,2015 <a href="#fnref4" rel="nofollow" class="footnote-backref">↩︎</a></p> </li> 
   </ol> 
  </section> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
