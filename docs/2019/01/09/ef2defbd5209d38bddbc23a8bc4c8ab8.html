<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>为什么要用卷积神经网络？ | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="为什么要用卷积神经网络？" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="结合吴恩达前辈deeplearning.ai 的卷积神经网络课程，我想我对卷积神经网络有了进一步深刻的了解。下面是我做的一些学习笔记，如果有不对的地方，欢迎一起讨论。 目录 什么是卷积？ 什么是池化？ 为什么要用卷积神经网络？ 卷积神经网络是怎么减少参数的？ 1.什么是卷积？ 用3*3 的卷积核对图像进行卷积遍历，对应元素相乘然后求和，得到特征图的过程，就是卷积。 填充（padding）：输入图像的角落（边缘）信息可能会丢失，在图像外围进行填充。 两种方式： 1.valid padding（no padding） 输出维度的计算公式：见下图 2.same padding : 经过这种填充之后，得到的输出维度与输入维度相同。 步长（stride）：卷积核移动的步幅 输出维度的公式计算：见下图 2.什么是池化？ 第一种，平均池化 第二种，最大池化 3.为什么要用卷积神经网络？ 如上图所示， 全连接神经网络中需要的参数大概是14millon 个 卷积神经网络中用的是 6个5阶的过滤器，参数是 156个 我在这里把卷积核理解为（特征提取器） 第一层，可能类似于边缘提取 第二层，根据第一层得到的边缘，进而提取到眼睛、鼻子、耳朵等特征 第三层，根据第二层得到的关键特征，得到整个人脸 运用多层网络，图像的信息就会尽可能完整，详尽的呈现出来，从而提取出的特征就会更加全面，更加符合我们需要就觉得问题。 以下两段内容参考了这篇文章，点击进入 在卷积神经网络中，一个卷积层可以有多个不同的卷积核（也可以说是滤波器），而每个卷积核在输入图像上滑动且每次只处理一小块图像。这样输入端的卷积层可以提取到图像中最基础的特征，比如不同方向的直线或者拐角；接着再组合成高阶特征，比如三角形、正方形等；再继续抽象组合，得到眼睛、鼻子和嘴等五官；最后再将五官组合成一张脸，完成匹配识别。即每个卷积层提取的特征，在后面的层中都会抽象组合成更高阶的特征。 图像具有很强的空间相关性。其中每一个卷积核滤波得到的图像就是一类特征的映射，即一个Feature Map。CNN训练的模型同样对缩放、平移、旋转等具有不变性，有着很强的泛化能力。 4.卷积神经网络是怎么减少参数的？ 如图所示， 第一，参数共享。 相比全连接网络一个参数对应一个像素特征，卷积网络中一个卷积核（9个参数）与特征之间不是一一对应的，实现了参数共享。 第二，稀疏连接（对比全连接理解）。 比如，我们看输入图像左上角的9个像素和卷积核进行卷积之后，对应得到的特征图中的左上角的1个像素（这个像素只会受到输入图像左上角的9个像素的影响，不会受到其他像素的影响）。" />
<meta property="og:description" content="结合吴恩达前辈deeplearning.ai 的卷积神经网络课程，我想我对卷积神经网络有了进一步深刻的了解。下面是我做的一些学习笔记，如果有不对的地方，欢迎一起讨论。 目录 什么是卷积？ 什么是池化？ 为什么要用卷积神经网络？ 卷积神经网络是怎么减少参数的？ 1.什么是卷积？ 用3*3 的卷积核对图像进行卷积遍历，对应元素相乘然后求和，得到特征图的过程，就是卷积。 填充（padding）：输入图像的角落（边缘）信息可能会丢失，在图像外围进行填充。 两种方式： 1.valid padding（no padding） 输出维度的计算公式：见下图 2.same padding : 经过这种填充之后，得到的输出维度与输入维度相同。 步长（stride）：卷积核移动的步幅 输出维度的公式计算：见下图 2.什么是池化？ 第一种，平均池化 第二种，最大池化 3.为什么要用卷积神经网络？ 如上图所示， 全连接神经网络中需要的参数大概是14millon 个 卷积神经网络中用的是 6个5阶的过滤器，参数是 156个 我在这里把卷积核理解为（特征提取器） 第一层，可能类似于边缘提取 第二层，根据第一层得到的边缘，进而提取到眼睛、鼻子、耳朵等特征 第三层，根据第二层得到的关键特征，得到整个人脸 运用多层网络，图像的信息就会尽可能完整，详尽的呈现出来，从而提取出的特征就会更加全面，更加符合我们需要就觉得问题。 以下两段内容参考了这篇文章，点击进入 在卷积神经网络中，一个卷积层可以有多个不同的卷积核（也可以说是滤波器），而每个卷积核在输入图像上滑动且每次只处理一小块图像。这样输入端的卷积层可以提取到图像中最基础的特征，比如不同方向的直线或者拐角；接着再组合成高阶特征，比如三角形、正方形等；再继续抽象组合，得到眼睛、鼻子和嘴等五官；最后再将五官组合成一张脸，完成匹配识别。即每个卷积层提取的特征，在后面的层中都会抽象组合成更高阶的特征。 图像具有很强的空间相关性。其中每一个卷积核滤波得到的图像就是一类特征的映射，即一个Feature Map。CNN训练的模型同样对缩放、平移、旋转等具有不变性，有着很强的泛化能力。 4.卷积神经网络是怎么减少参数的？ 如图所示， 第一，参数共享。 相比全连接网络一个参数对应一个像素特征，卷积网络中一个卷积核（9个参数）与特征之间不是一一对应的，实现了参数共享。 第二，稀疏连接（对比全连接理解）。 比如，我们看输入图像左上角的9个像素和卷积核进行卷积之后，对应得到的特征图中的左上角的1个像素（这个像素只会受到输入图像左上角的9个像素的影响，不会受到其他像素的影响）。" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-09T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"结合吴恩达前辈deeplearning.ai 的卷积神经网络课程，我想我对卷积神经网络有了进一步深刻的了解。下面是我做的一些学习笔记，如果有不对的地方，欢迎一起讨论。 目录 什么是卷积？ 什么是池化？ 为什么要用卷积神经网络？ 卷积神经网络是怎么减少参数的？ 1.什么是卷积？ 用3*3 的卷积核对图像进行卷积遍历，对应元素相乘然后求和，得到特征图的过程，就是卷积。 填充（padding）：输入图像的角落（边缘）信息可能会丢失，在图像外围进行填充。 两种方式： 1.valid padding（no padding） 输出维度的计算公式：见下图 2.same padding : 经过这种填充之后，得到的输出维度与输入维度相同。 步长（stride）：卷积核移动的步幅 输出维度的公式计算：见下图 2.什么是池化？ 第一种，平均池化 第二种，最大池化 3.为什么要用卷积神经网络？ 如上图所示， 全连接神经网络中需要的参数大概是14millon 个 卷积神经网络中用的是 6个5阶的过滤器，参数是 156个 我在这里把卷积核理解为（特征提取器） 第一层，可能类似于边缘提取 第二层，根据第一层得到的边缘，进而提取到眼睛、鼻子、耳朵等特征 第三层，根据第二层得到的关键特征，得到整个人脸 运用多层网络，图像的信息就会尽可能完整，详尽的呈现出来，从而提取出的特征就会更加全面，更加符合我们需要就觉得问题。 以下两段内容参考了这篇文章，点击进入 在卷积神经网络中，一个卷积层可以有多个不同的卷积核（也可以说是滤波器），而每个卷积核在输入图像上滑动且每次只处理一小块图像。这样输入端的卷积层可以提取到图像中最基础的特征，比如不同方向的直线或者拐角；接着再组合成高阶特征，比如三角形、正方形等；再继续抽象组合，得到眼睛、鼻子和嘴等五官；最后再将五官组合成一张脸，完成匹配识别。即每个卷积层提取的特征，在后面的层中都会抽象组合成更高阶的特征。 图像具有很强的空间相关性。其中每一个卷积核滤波得到的图像就是一类特征的映射，即一个Feature Map。CNN训练的模型同样对缩放、平移、旋转等具有不变性，有着很强的泛化能力。 4.卷积神经网络是怎么减少参数的？ 如图所示， 第一，参数共享。 相比全连接网络一个参数对应一个像素特征，卷积网络中一个卷积核（9个参数）与特征之间不是一一对应的，实现了参数共享。 第二，稀疏连接（对比全连接理解）。 比如，我们看输入图像左上角的9个像素和卷积核进行卷积之后，对应得到的特征图中的左上角的1个像素（这个像素只会受到输入图像左上角的9个像素的影响，不会受到其他像素的影响）。","@type":"BlogPosting","url":"/2019/01/09/ef2defbd5209d38bddbc23a8bc4c8ab8.html","headline":"为什么要用卷积神经网络？","dateModified":"2019-01-09T00:00:00+08:00","datePublished":"2019-01-09T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/01/09/ef2defbd5209d38bddbc23a8bc4c8ab8.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>为什么要用卷积神经网络？</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p>结合吴恩达前辈<a href="https://study.163.com/provider/2001053000/course.htm" rel="nofollow">deeplearning.ai 的卷积神经网络课程</a>，我想我对卷积神经网络有了进一步深刻的了解。下面是我做的一些学习笔记，如果有不对的地方，欢迎一起讨论。</p> 
  <hr> 
  <p><strong>目录</strong><br> 什么是卷积？<br> 什么是池化？<br> 为什么要用卷积神经网络？<br> 卷积神经网络是怎么减少参数的？</p> 
  <hr> 
  <h2><a id="1_9"></a>1.什么是卷积？</h2> 
  <p>用3*3 的卷积核对图像进行卷积遍历，对应元素相乘然后求和，得到特征图的过程，就是卷积。<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190109110851509.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYwNjQxOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <hr> 
  <p><strong>填充</strong>（padding）：输入图像的角落（边缘）信息可能会丢失，在图像外围进行填充。<br> 两种方式：<br> 1.valid padding（no padding）<br> 输出维度的计算公式：见下图<br> 2.same padding : 经过这种填充之后，得到的输出维度与输入维度相同。<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/2019010911514998.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYwNjQxOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <hr> 
  <p><strong>步长</strong>（stride）：卷积核移动的步幅<br> 输出维度的公式计算：见下图<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190109114952952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYwNjQxOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <hr> 
  <h2><a id="2_24"></a>2.什么是池化？</h2> 
  <p>第一种，平均池化<br> 第二种，最大池化<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190109120241453.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYwNjQxOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <hr> 
  <h2><a id="3_29"></a>3.为什么要用卷积神经网络？</h2> 
  <p><img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190109104152719.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYwNjQxOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 如上图所示，<br> 全连接神经网络中需要的参数大概是<strong>14millon</strong> 个<br> 卷积神经网络中用的是 6个5阶的过滤器，参数是 <strong>156</strong>个</p> 
  <hr> 
  <p><img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190109122922902.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYwNjQxOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 我在这里把卷积核理解为（特征提取器）<br> 第一层，可能类似于边缘提取<br> 第二层，根据第一层得到的边缘，进而提取到眼睛、鼻子、耳朵等特征<br> 第三层，根据第二层得到的关键特征，得到整个人脸</p> 
  <p>运用多层网络，图像的信息就会尽可能完整，详尽的呈现出来，从而提取出的特征就会更加全面，更加符合我们需要就觉得问题。</p> 
  <p><a href="https://blog.csdn.net/NNNNNNNNNNNNY/article/details/70148497" rel="nofollow">以下两段内容参考了这篇文章，点击进入</a></p> 
  <p>在卷积神经网络中，一个卷积层可以有多个不同的卷积核（也可以说是滤波器），而每个卷积核在输入图像上滑动且每次只处理一小块图像。这样输入端的卷积层可以提取到图像中最基础的特征，比如不同方向的直线或者拐角；接着再组合成高阶特征，比如三角形、正方形等；再继续抽象组合，得到眼睛、鼻子和嘴等五官；最后再将五官组合成一张脸，完成匹配识别。即每个卷积层提取的特征，在后面的层中都会抽象组合成更高阶的特征。</p> 
  <p>图像具有很强的空间相关性。其中每一个卷积核滤波得到的图像就是一类特征的映射，即一个Feature Map。CNN训练的模型同样对缩放、平移、旋转等具有不变性，有着很强的泛化能力。</p> 
  <hr> 
  <h2><a id="4_53"></a>4.卷积神经网络是怎么减少参数的？</h2> 
  <p><img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190109105130989.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYwNjQxOQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 如图所示，<br> 第一，参数共享。<br> 相比全连接网络一个参数对应一个像素特征，卷积网络中一个卷积核（9个参数）与特征之间不是一一对应的，实现了参数共享。</p> 
  <p>第二，稀疏连接（对比全连接理解）。<br> 比如，我们看输入图像左上角的9个像素和卷积核进行卷积之后，对应得到的特征图中的左上角的1个像素（这个像素只会受到输入图像左上角的9个像素的影响，不会受到其他像素的影响）。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
