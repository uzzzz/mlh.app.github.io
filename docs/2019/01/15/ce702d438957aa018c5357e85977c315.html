<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>机器学习：完整机器学习项目流程，数据清洗 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="机器学习：完整机器学习项目流程，数据清洗" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="一、完整机器学习项目流程 数学抽象--任务目标 明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。 这里的抽象成数学问题，指的是根据数据明确任务目标，是分类、还是回归，或者是聚类。 数据获取--数据集 数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。 数据要有代表性，否则必然会过拟合。 对于分类问题，数据偏斜不能过于严重（平衡），不同类别的数据数量不要有数个数量级的差距。 对数据的量级要有一个评估，多少个样本，多少个特征，据此估算出内存需求。如果放不下就得考虑改进算法或者使用一些降维技巧，或者采用分布式计算。 预处理与特征选择 良好的数据要能够提取出良好的特征才能真正发挥效力。 预处理/数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。 筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。 模型训练与调优 直到这一步才用到我们上面说的算法进行训练。 现在很多算法都能够封装成黑盒使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。 模型诊断 如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。 过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。 误差分析也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题...... 诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。 模型融合/集成 一般来说，模型融合后都能使得效果有一定提升。而且效果很好。 工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。 上线运行 这一部分内容主要跟工程实现的相关性更大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。 这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有多实践，多积累项目经验，才会有自己更深刻的认识。 二、数据清洗与特征处理 2.1 数据清洗 清洗标注数据，主要是数据采样和样本过滤 数据采样 数据采样，例如对于分类问题：选取正例，负例。对于回归问题，需要采集数据。对于采样得到的样本，根据需要，需要设定样本权重。当模型不能使用全部的数据来训练时，需要对数据进行采样，设定一定的采样率。采样的方法包括随机采样，固定比例采样等方法。 样本过滤 1.结合业务情况进行数据的过滤，例如去除crawler抓取，spam，作弊等数据。 2.异常点检测，采用异常点检测算法对样本进行分析，常用的异常点检测算法包括： 偏差检测，例如聚类，最近邻等。 基于统计的异常点检测算法 例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。 基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。 基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法 2.2特征处理 特征处理与分析 在对特征进行分类后，下面介绍下对特征常用的处理方法。包括1.特征归一化，离散化，缺省值处理。2.特征降维方法。3.特征选择方法等。 特征归一化，离散化，缺省值处理 主要用于单个特征的处理。 归一化 不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括1.函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。2.分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。3.排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。 离散化 在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，...，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。 缺省值处理 有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等。 三、关联规则挖掘的 3 个度量指标：支持度、置信度、提升度 支持度（Support） X → Y 的支持度表示项集 {X,Y} 在总项集中出现的概率 其中，I 表示总事务集，num()表示事务集中特定项集出现的次数，P(X)=num(X)/num(I) 置信度（Confidence） X → Y 的置信度表示在先决条件 X 发生的情况下，由规则 X → Y 推出 Y 的概率。 提升度（Lift） X → Y 的提升度表示含有X的条件下，同时含有Y的概率，与Y总体发生的概率之比。 规则的有效性： 满足最小支持度和最小置信度的规则，叫做“强关联规则” 最小支持度和最小置信度是人工设置的阈值 Lift(X→Y) &gt; 1&nbsp;的 X→Y 是有效的强关联规则 Lift(X→Y) &lt;=1&nbsp;的 X→Y 是有效的强关联规则 特别地，Lift(X→Y) = 1&nbsp;时，X 与 Y 相互独立。 判断规则的有效性 问题：已知有1000名顾客买年货，分为甲乙两组，每组各500人，其中甲组有500人买了茶叶，同时又有450人买了咖啡；乙组有450人买了咖啡，如表所示，请问“茶叶→咖啡”是一条有效的关联规则吗？ 组次 买茶叶的人数 买咖啡的人数 甲组（500人） 500 450 乙组（500人） 0 450 答： “茶叶→咖啡”的支持度：Support(X→Y) = 450 / 1000 = 45% “茶叶→咖啡”的置信度：Confidence(X→Y) = 450 / 500 = 90% “茶叶→咖啡”的提升度：Lift(X→Y) = 90% / 90% = 1 由于提升度&nbsp;Lift(X→Y) = 1，表示 X 与 Y 相互独立。也就是说，是否购买咖啡，与是否购买茶叶无关联。规则“茶叶→咖啡”不成立，或者说几乎没有关联，虽然它的置信度高达90%，但它不是一条有效的关联规则。" />
<meta property="og:description" content="一、完整机器学习项目流程 数学抽象--任务目标 明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。 这里的抽象成数学问题，指的是根据数据明确任务目标，是分类、还是回归，或者是聚类。 数据获取--数据集 数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。 数据要有代表性，否则必然会过拟合。 对于分类问题，数据偏斜不能过于严重（平衡），不同类别的数据数量不要有数个数量级的差距。 对数据的量级要有一个评估，多少个样本，多少个特征，据此估算出内存需求。如果放不下就得考虑改进算法或者使用一些降维技巧，或者采用分布式计算。 预处理与特征选择 良好的数据要能够提取出良好的特征才能真正发挥效力。 预处理/数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。 筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。 模型训练与调优 直到这一步才用到我们上面说的算法进行训练。 现在很多算法都能够封装成黑盒使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。 模型诊断 如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。 过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。 误差分析也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题...... 诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。 模型融合/集成 一般来说，模型融合后都能使得效果有一定提升。而且效果很好。 工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。 上线运行 这一部分内容主要跟工程实现的相关性更大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。 这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有多实践，多积累项目经验，才会有自己更深刻的认识。 二、数据清洗与特征处理 2.1 数据清洗 清洗标注数据，主要是数据采样和样本过滤 数据采样 数据采样，例如对于分类问题：选取正例，负例。对于回归问题，需要采集数据。对于采样得到的样本，根据需要，需要设定样本权重。当模型不能使用全部的数据来训练时，需要对数据进行采样，设定一定的采样率。采样的方法包括随机采样，固定比例采样等方法。 样本过滤 1.结合业务情况进行数据的过滤，例如去除crawler抓取，spam，作弊等数据。 2.异常点检测，采用异常点检测算法对样本进行分析，常用的异常点检测算法包括： 偏差检测，例如聚类，最近邻等。 基于统计的异常点检测算法 例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。 基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。 基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法 2.2特征处理 特征处理与分析 在对特征进行分类后，下面介绍下对特征常用的处理方法。包括1.特征归一化，离散化，缺省值处理。2.特征降维方法。3.特征选择方法等。 特征归一化，离散化，缺省值处理 主要用于单个特征的处理。 归一化 不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括1.函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。2.分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。3.排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。 离散化 在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，...，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。 缺省值处理 有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等。 三、关联规则挖掘的 3 个度量指标：支持度、置信度、提升度 支持度（Support） X → Y 的支持度表示项集 {X,Y} 在总项集中出现的概率 其中，I 表示总事务集，num()表示事务集中特定项集出现的次数，P(X)=num(X)/num(I) 置信度（Confidence） X → Y 的置信度表示在先决条件 X 发生的情况下，由规则 X → Y 推出 Y 的概率。 提升度（Lift） X → Y 的提升度表示含有X的条件下，同时含有Y的概率，与Y总体发生的概率之比。 规则的有效性： 满足最小支持度和最小置信度的规则，叫做“强关联规则” 最小支持度和最小置信度是人工设置的阈值 Lift(X→Y) &gt; 1&nbsp;的 X→Y 是有效的强关联规则 Lift(X→Y) &lt;=1&nbsp;的 X→Y 是有效的强关联规则 特别地，Lift(X→Y) = 1&nbsp;时，X 与 Y 相互独立。 判断规则的有效性 问题：已知有1000名顾客买年货，分为甲乙两组，每组各500人，其中甲组有500人买了茶叶，同时又有450人买了咖啡；乙组有450人买了咖啡，如表所示，请问“茶叶→咖啡”是一条有效的关联规则吗？ 组次 买茶叶的人数 买咖啡的人数 甲组（500人） 500 450 乙组（500人） 0 450 答： “茶叶→咖啡”的支持度：Support(X→Y) = 450 / 1000 = 45% “茶叶→咖啡”的置信度：Confidence(X→Y) = 450 / 500 = 90% “茶叶→咖啡”的提升度：Lift(X→Y) = 90% / 90% = 1 由于提升度&nbsp;Lift(X→Y) = 1，表示 X 与 Y 相互独立。也就是说，是否购买咖啡，与是否购买茶叶无关联。规则“茶叶→咖啡”不成立，或者说几乎没有关联，虽然它的置信度高达90%，但它不是一条有效的关联规则。" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-15T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"一、完整机器学习项目流程 数学抽象--任务目标 明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。 这里的抽象成数学问题，指的是根据数据明确任务目标，是分类、还是回归，或者是聚类。 数据获取--数据集 数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。 数据要有代表性，否则必然会过拟合。 对于分类问题，数据偏斜不能过于严重（平衡），不同类别的数据数量不要有数个数量级的差距。 对数据的量级要有一个评估，多少个样本，多少个特征，据此估算出内存需求。如果放不下就得考虑改进算法或者使用一些降维技巧，或者采用分布式计算。 预处理与特征选择 良好的数据要能够提取出良好的特征才能真正发挥效力。 预处理/数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。 筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。 模型训练与调优 直到这一步才用到我们上面说的算法进行训练。 现在很多算法都能够封装成黑盒使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。 模型诊断 如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。 过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。 误差分析也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题...... 诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。 模型融合/集成 一般来说，模型融合后都能使得效果有一定提升。而且效果很好。 工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。 上线运行 这一部分内容主要跟工程实现的相关性更大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。 这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有多实践，多积累项目经验，才会有自己更深刻的认识。 二、数据清洗与特征处理 2.1 数据清洗 清洗标注数据，主要是数据采样和样本过滤 数据采样 数据采样，例如对于分类问题：选取正例，负例。对于回归问题，需要采集数据。对于采样得到的样本，根据需要，需要设定样本权重。当模型不能使用全部的数据来训练时，需要对数据进行采样，设定一定的采样率。采样的方法包括随机采样，固定比例采样等方法。 样本过滤 1.结合业务情况进行数据的过滤，例如去除crawler抓取，spam，作弊等数据。 2.异常点检测，采用异常点检测算法对样本进行分析，常用的异常点检测算法包括： 偏差检测，例如聚类，最近邻等。 基于统计的异常点检测算法 例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。 基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。 基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法 2.2特征处理 特征处理与分析 在对特征进行分类后，下面介绍下对特征常用的处理方法。包括1.特征归一化，离散化，缺省值处理。2.特征降维方法。3.特征选择方法等。 特征归一化，离散化，缺省值处理 主要用于单个特征的处理。 归一化 不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括1.函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。2.分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。3.排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。 离散化 在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，...，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。 缺省值处理 有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等。 三、关联规则挖掘的 3 个度量指标：支持度、置信度、提升度 支持度（Support） X → Y 的支持度表示项集 {X,Y} 在总项集中出现的概率 其中，I 表示总事务集，num()表示事务集中特定项集出现的次数，P(X)=num(X)/num(I) 置信度（Confidence） X → Y 的置信度表示在先决条件 X 发生的情况下，由规则 X → Y 推出 Y 的概率。 提升度（Lift） X → Y 的提升度表示含有X的条件下，同时含有Y的概率，与Y总体发生的概率之比。 规则的有效性： 满足最小支持度和最小置信度的规则，叫做“强关联规则” 最小支持度和最小置信度是人工设置的阈值 Lift(X→Y) &gt; 1&nbsp;的 X→Y 是有效的强关联规则 Lift(X→Y) &lt;=1&nbsp;的 X→Y 是有效的强关联规则 特别地，Lift(X→Y) = 1&nbsp;时，X 与 Y 相互独立。 判断规则的有效性 问题：已知有1000名顾客买年货，分为甲乙两组，每组各500人，其中甲组有500人买了茶叶，同时又有450人买了咖啡；乙组有450人买了咖啡，如表所示，请问“茶叶→咖啡”是一条有效的关联规则吗？ 组次 买茶叶的人数 买咖啡的人数 甲组（500人） 500 450 乙组（500人） 0 450 答： “茶叶→咖啡”的支持度：Support(X→Y) = 450 / 1000 = 45% “茶叶→咖啡”的置信度：Confidence(X→Y) = 450 / 500 = 90% “茶叶→咖啡”的提升度：Lift(X→Y) = 90% / 90% = 1 由于提升度&nbsp;Lift(X→Y) = 1，表示 X 与 Y 相互独立。也就是说，是否购买咖啡，与是否购买茶叶无关联。规则“茶叶→咖啡”不成立，或者说几乎没有关联，虽然它的置信度高达90%，但它不是一条有效的关联规则。","@type":"BlogPosting","url":"/2019/01/15/ce702d438957aa018c5357e85977c315.html","headline":"机器学习：完整机器学习项目流程，数据清洗","dateModified":"2019-01-15T00:00:00+08:00","datePublished":"2019-01-15T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/01/15/ce702d438957aa018c5357e85977c315.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>机器学习：完整机器学习项目流程，数据清洗</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h1>一、完整机器学习项目流程</h1> 
  <ol>
   <li> <h3>数学抽象--任务目标</h3> <p>明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。</p> <p>这里的抽象成数学问题，指的是根据数据明确<span style="color:#f33b45;"><strong>任务目标</strong></span>，是分类、还是回归，或者是聚类。</p> </li> 
   <li> <h3>数据获取--数据集</h3> <p>数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。</p> <p>数据要有代表性，否则必然会过拟合。</p> <p>对于分类问题，数据偏斜不能过于严重（平衡），不同类别的数据数量不要有数个数量级的差距。</p> <p>对数据的量级要有一个评估，多少个样本，多少个特征，据此估算出内存需求。如果放不下就得考虑改进算法或者使用一些降维技巧，或者采用分布式计算。</p> </li> 
   <li> <h3>预处理与特征选择</h3> <p>良好的数据要能够提取出良好的特征才能真正发挥效力。</p> <p><strong>预处理/数据清洗是很关键的步骤</strong>，往往能够使得算法的效果和性能得到显著提高。归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。这些工作简单可复制，收益稳定可预期，是机器学习的基础必备步骤。</p> <p><strong>筛选出显著特征、摒弃非显著特征</strong>，需要机器学习工程师反复理解业务。这对很多结果有决定性的影响。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。</p> </li> 
   <li> <h3>模型训练与调优</h3> <p>直到这一步才用到我们上面说的算法进行训练。</p> <p>现在很多算法都能够封装成黑盒使用。但是真正考验水平的是调整这些算法的（超）参数，使得结果变得更加优良。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。</p> </li> 
   <li> <h3>模型诊断</h3> <p>如何确定模型调优的方向与思路呢？这就需要对模型进行诊断的技术。</p> <p><strong>过拟合、欠拟合</strong> 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。过拟合的基本调优思路是增加数据量，降低模型复杂度。欠拟合的基本调优思路是提高特征数量和质量，增加模型复杂度。</p> <p>误差分析也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因:是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题......</p> <p>诊断后的模型需要进行调优，调优后的新模型需要重新进行诊断，这是一个反复迭代不断逼近的过程，需要不断地尝试， 进而达到最优状态。</p> </li> 
   <li> <h3>模型融合/集成</h3> <p>一般来说，<strong>模型融合后都能使得效果有一定提升</strong>。而且效果很好。</p> <p>工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。</p> </li> 
   <li> <h3>上线运行</h3> <p>这一部分内容主要跟工程实现的相关性更大。工程上是结果导向，模型在线上运行的效果直接决定模型的成败。不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。</p> <p>这些工作流程主要是工程实践上总结出的一些经验。并不是每个项目都包含完整的一个流程。这里的部分只是一个指导性的说明，只有多实践，多积累项目经验，才会有自己更深刻的认识。</p> </li> 
  </ol>
  <h1>二、数据清洗与特征处理</h1> 
  <h2>2.1 数据清洗</h2> 
  <p>清洗标注数据，主要是数据采样和样本过滤</p> 
  <ul>
   <li><strong>数据采样</strong></li> 
  </ul>
  <p>数据采样，例如对于分类问题：选取正例，负例。对于回归问题，需要采集数据。对于采样得到的样本，根据需要，需要设定样本权重。当模型不能使用全部的数据来训练时，需要对数据进行采样，设定一定的采样率。采样的方法包括随机采样，固定比例采样等方法。</p> 
  <ul>
   <li><strong>样本过滤</strong></li> 
  </ul>
  <p>1.结合业务情况进行数据的过滤，例如去除crawler抓取，spam，作弊等数据。</p> 
  <p>2.异常点检测，采用异常点检测算法对样本进行分析，常用的异常点检测算法包括：</p> 
  <ul>
   <li>偏差检测，例如聚类，最近邻等。</li> 
   <li>基于统计的异常点检测算法 例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。</li> 
   <li>基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。</li> 
   <li>基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法</li> 
  </ul>
  <h2>2.2特征处理</h2> 
  <ul>
   <li> <h3>特征处理与分析</h3> </li> 
  </ul>
  <p>在对特征进行分类后，下面介绍下对特征常用的处理方法。包括1.特征归一化，离散化，缺省值处理。2.特征降维方法。3.特征选择方法等。</p> 
  <p>特征归一化，离散化，缺省值处理 主要用于单个特征的处理。</p> 
  <ul>
   <li><strong>归一化</strong></li> 
  </ul>
  <p>不同的特征有不同的取值范围，在有些算法中，例如线性模型或者距离相关的模型像聚类模型、knn模型等，特征的取值范围会对最终的结果产生较大影响，例如二元特征的取值范围为[0，1]，而距离特征取值可能是[0，正无穷)，在实际使用中会对距离进行截断，例如[0，3000000]，但是这两个特征由于取值范围不一致导致了模型可能会更偏向于取值范围较大的特征，为了平衡取值范围不一致的特征，需要对特征进行归一化处理，将特征取值归一化到［0，1］区间。常用的归一化方法包括1.函数归一化，通过映射函数将特征取值映射到［0，1］区间，例如最大最小值归一化方法，是一种线性的映射。还有通过非线性函数的映射，例如log函数等。2.分维度归一化，可以使用最大最小归一化方法，但是最大最小值选取的是所属类别的最大最小值，即使用的是局部最大最小值，不是全局的最大最小值。3.排序归一化，不管原来的特征取值是什么样的，将特征按大小排序，根据特征所对应的序给予一个新的值。</p> 
  <ul>
   <li><strong>离散化</strong></li> 
  </ul>
  <p>在上面介绍过连续值的取值空间可能是无穷的，为了便于表示和在模型中处理，需要对连续值特征进行离散化处理。常用的离散化方法包括等值划分和等量划分。等值划分是将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，...，[9，10)。等量划分是根据样本总数进行均分，每段等量个样本划分为1段。例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。</p> 
  <ul>
   <li><strong>缺省值处理</strong></li> 
  </ul>
  <p>有些特征可能因为无法采样或者没有观测值而缺失，例如距离特征，用户可能禁止获取地理位置或者获取地理位置失败，此时需要对这些特征做特殊的处理，赋予一个缺省值。缺省值如何赋予，也有很多种方法。例如单独表示，众数，平均值等。</p> 
  <p><a href="https://github.com/geekcircle/machine-learning-interview-qa/blob/master/questions/image/8.%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E4%B8%8E%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86.jpg" rel="nofollow"><img alt="数据清洗与特征处理" class="has" src="https://github.com/geekcircle/machine-learning-interview-qa/raw/master/questions/image/8.%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97%E4%B8%8E%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86.jpg"></a></p> 
  <h1>三、关联规则挖掘的 3 个度量指标：支持度、置信度、提升度</h1> 
  <p><strong>支持度</strong>（Support）</p> 
  <ul>
   <li> <p>X → Y 的支持度表示项集 {X,Y} 在总项集中出现的概率</p> <p><a href="http://www.codecogs.com/eqnedit.php?latex=Support(X%5Crightarrow&amp;space;Y)=%5Cfrac%7BP(X%5Ccup&amp;space;Y)%7D%7BP(I)%7D=%5Cfrac%7B%5Ctext%7Bnum%7D(X%5Ccup&amp;space;Y)%7D%7B%5Ctext%7Bnum%7D(I)%7D" rel="nofollow"><img alt="" class="has" src="https://github.com/HLinShan/Algorithm_Interview_Notes-Chinese/raw/master/_assets/%E5%85%AC%E5%BC%8F_20180620204006.png"></a></p> </li> 
   <li> <p>其中，I 表示总事务集，<code>num()</code>表示事务集中特定项集出现的次数，<code>P(X)=num(X)/num(I)</code></p> </li> 
  </ul>
  <p><strong>置信度</strong>（Confidence）</p> 
  <ul>
   <li> <p>X → Y 的置信度表示在先决条件 X 发生的情况下，由规则 X → Y 推出 Y 的概率。</p> <p><a href="http://www.codecogs.com/eqnedit.php?latex=Confidence(X%5Crightarrow&amp;space;Y)=P(Y%7CX)=%5Cfrac%7BP(X%5Ccup&amp;space;Y)%7D%7BP(X)%7D=%5Cfrac%7B%5Ctext%7Bnum%7D(X%5Ccup&amp;space;Y)%7D%7B%5Ctext%7Bnum%7D(X)%7D" rel="nofollow"><img alt="" class="has" src="https://github.com/HLinShan/Algorithm_Interview_Notes-Chinese/raw/master/_assets/%E5%85%AC%E5%BC%8F_20180620205055.png"></a></p> </li> 
  </ul>
  <p><strong>提升度</strong>（Lift）</p> 
  <ul>
   <li> <p>X → Y 的提升度表示含有X的条件下，同时含有Y的概率，与Y总体发生的概率之比。</p> <p><a href="http://www.codecogs.com/eqnedit.php?latex=%7B%5Cdisplaystyle&amp;space;%7B%5Cbegin%7Baligned%7D&amp;space;Lift(X%5Crightarrow&amp;space;Y)&amp;=%5Cfrac%7BP(Y%7CX)%7D%7BP(Y)%7D=%5Cfrac%7BConfidence(X%5Crightarrow&amp;space;Y)%7D%7B%5Ctext%7Bnum%7D(Y)/%5Ctext%7Bnum%7D(I)%7D%5C%5C&amp;space;&amp;=%5Cfrac%7BP(X%5Ccup&amp;space;Y)%7D%7BP(X)P(Y)%7D=%5Cfrac%7B%5Ctext%7Bnum%7D(X%5Ccup&amp;space;Y)%5Ctext%7Bnum%7D(I)%7D%7B%5Ctext%7Bnum%7D(X)%5Ctext%7Bnum%7D(Y)%7D&amp;space;%5Cend%7Baligned%7D%7D%7D" rel="nofollow"><img alt="" class="has" src="https://github.com/HLinShan/Algorithm_Interview_Notes-Chinese/raw/master/_assets/%E5%85%AC%E5%BC%8F_20180620213601.png"></a></p> </li> 
  </ul>
  <h2>规则的有效性：</h2> 
  <ul>
   <li>满足最小支持度和最小置信度的规则，叫做“强关联规则” 
    <blockquote> 
     <p>最小支持度和最小置信度是人工设置的阈值</p> 
    </blockquote> </li> 
   <li><code>Lift(X→Y) &gt; 1</code>&nbsp;的 X→Y 是有效的强关联规则</li> 
   <li><code>Lift(X→Y) &lt;=1</code>&nbsp;的 X→Y 是有效的强关联规则</li> 
   <li>特别地，<code>Lift(X→Y) = 1</code>&nbsp;时，X 与 Y 相互独立。</li> 
  </ul>
  <h2><strong>判断规则的有效性</strong></h2> 
  <p>问题：已知有1000名顾客买年货，分为甲乙两组，每组各500人，其中甲组有500人买了茶叶，同时又有450人买了咖啡；乙组有450人买了咖啡，如表所示，请问“茶叶→咖啡”是一条有效的关联规则吗？</p> 
  <table>
   <thead>
    <tr>
     <th>组次</th> 
     <th>买茶叶的人数</th> 
     <th>买咖啡的人数</th> 
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>甲组（500人）</td> 
     <td>500</td> 
     <td>450</td> 
    </tr>
    <tr>
     <td>乙组（500人）</td> 
     <td>0</td> 
     <td>450</td> 
    </tr>
   </tbody>
  </table>
  <p>答：</p> 
  <ul>
   <li>“茶叶→咖啡”的支持度：Support(X→Y) = 450 / 1000 = 45%</li> 
   <li>“茶叶→咖啡”的置信度：Confidence(X→Y) = 450 / 500 = 90%</li> 
   <li>“茶叶→咖啡”的提升度：Lift(X→Y) = 90% / 90% = 1</li> 
  </ul>
  <p>由于提升度&nbsp;<code>Lift(X→Y) = 1</code>，表示 X 与 Y 相互独立。也就是说，是否购买咖啡，与是否购买茶叶无关联。规则“茶叶→咖啡”不成立，或者说几乎没有关联，虽然它的置信度高达90%，但它不是一条有效的关联规则。</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
