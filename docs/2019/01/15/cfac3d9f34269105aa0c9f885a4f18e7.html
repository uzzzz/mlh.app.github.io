<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>（三）使用YOLOv3训练BDD100K数据集之开始训练 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="（三）使用YOLOv3训练BDD100K数据集之开始训练" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：转载请注明出处。 https://blog.csdn.net/qq583083658/article/details/86499208 目录 1 准备bdd100k.names文件 2 准备bdd100k.names文件准备bdd100k.data 3 准备yolov3-bdd100k.cfg 4 下载ImageNet预训练的网络参数 5 训练模型 6 测试一张图片 7 测试一个视频 8 测试网络摄像头输入 9 中断后继续训练模型 经过前面两篇博客（（一）使用YOLOv3训练BDD100K数据集之数据集下载 和（二）使用YOLOv3训练BDD100K数据集之标签格式转换），我们已经准备了BDD100K数据集，并且已经生成了darknet格式的标签，需要的训练集和验证集train.txt和val.txt，现在我们只需要简单地修改几个配置文件就可以开始训练了。 1 准备bdd100k.names文件 在darknet/data/目录下创建文件bdd100k.names，里面存放了每一类的类名，这个将在测试一张图片时在右上角显示一个物体的标签名。文件内容如下（注意顺序要与xml_to_yolo_txt.py文件里面的顺序一致。）： car bus person bike truck motor train rider traffic sign traffic light 2 准备bdd100k.names文件准备bdd100k.data 在darknet/data/目录下创建文件bdd100k.data，其内容如下，其中classes表示类的数目，train和val表示前一篇文章中生成的train.txt和val.txt的存放路径（相对于darknet安装路径），backup表示训练的yolo权重存放的位置。 classes = 10 train = bdd100k_data/train.txt valid = bdd100k_data/val.txt names = bdd100k_data/bdd100k.names backup = backup/ 3 准备yolov3-bdd100k.cfg 在darknet/cfg目录下，创建一个文件yolov3-bdd100k.cfg，里面的内容可以先拷贝yolov3.cfg，在修改以下几个部分： 三处classes=80修改为classes=10 三处filters=255（注意只需要修改[yolo]上面的[convolutional]的filters）修改为filters=45（ filters=3*(classes+5) ），如下： 也可以模仿此处，修改yolov3-tiny.cfg或yolov2.cfg来使用YOLOv3-tiny或YOLOv2模型训练BDD00K [convolutional] size=1 stride=1 pad=1 filters=255 # 此处需要修改为filters=45，注意一定要修改[yolo]层前面的第一个[convolutional] activation=linear [yolo] mask = 3,4,5 anchors = 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 classes=80 num=9 还可以修改batch，subdivisions和max_batches等参数。其中batch表示一个批次训练的图片数目，一个epoch=total_train_images/batch，而subdivisions表示将一个batch分为subdivisions个组进行分别训练，每个组有batch/subdivisions个图片。max_batches表示最大的批次数，而iterations=max_batches/batch。 4 下载ImageNet预训练的网络参数 yolov3默认的训练权重为darknet53，我们可以在darknet路径下打开终端，输入命令下载权重： wget https://pjreddie.com/media/files/darknet53.conv.74 5 训练模型 输入以下命令，即可开始训练 sudo ./darknet detector train bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg darknet53.conv.74 6 测试一张图片 输入以下命令，即可开始测试模型： sudo ./darknet detector test bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup data/000005.png 7 测试一个视频 sudo ./darknet detector demo bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup driving.mp4 8 测试网络摄像头输入 sudo ./darknet detector demo bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup -c 1 9 中断后继续训练模型 输入以下命令，即可开始测试模型： sudo ./darknet detector train bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup" />
<meta property="og:description" content="版权声明：转载请注明出处。 https://blog.csdn.net/qq583083658/article/details/86499208 目录 1 准备bdd100k.names文件 2 准备bdd100k.names文件准备bdd100k.data 3 准备yolov3-bdd100k.cfg 4 下载ImageNet预训练的网络参数 5 训练模型 6 测试一张图片 7 测试一个视频 8 测试网络摄像头输入 9 中断后继续训练模型 经过前面两篇博客（（一）使用YOLOv3训练BDD100K数据集之数据集下载 和（二）使用YOLOv3训练BDD100K数据集之标签格式转换），我们已经准备了BDD100K数据集，并且已经生成了darknet格式的标签，需要的训练集和验证集train.txt和val.txt，现在我们只需要简单地修改几个配置文件就可以开始训练了。 1 准备bdd100k.names文件 在darknet/data/目录下创建文件bdd100k.names，里面存放了每一类的类名，这个将在测试一张图片时在右上角显示一个物体的标签名。文件内容如下（注意顺序要与xml_to_yolo_txt.py文件里面的顺序一致。）： car bus person bike truck motor train rider traffic sign traffic light 2 准备bdd100k.names文件准备bdd100k.data 在darknet/data/目录下创建文件bdd100k.data，其内容如下，其中classes表示类的数目，train和val表示前一篇文章中生成的train.txt和val.txt的存放路径（相对于darknet安装路径），backup表示训练的yolo权重存放的位置。 classes = 10 train = bdd100k_data/train.txt valid = bdd100k_data/val.txt names = bdd100k_data/bdd100k.names backup = backup/ 3 准备yolov3-bdd100k.cfg 在darknet/cfg目录下，创建一个文件yolov3-bdd100k.cfg，里面的内容可以先拷贝yolov3.cfg，在修改以下几个部分： 三处classes=80修改为classes=10 三处filters=255（注意只需要修改[yolo]上面的[convolutional]的filters）修改为filters=45（ filters=3*(classes+5) ），如下： 也可以模仿此处，修改yolov3-tiny.cfg或yolov2.cfg来使用YOLOv3-tiny或YOLOv2模型训练BDD00K [convolutional] size=1 stride=1 pad=1 filters=255 # 此处需要修改为filters=45，注意一定要修改[yolo]层前面的第一个[convolutional] activation=linear [yolo] mask = 3,4,5 anchors = 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 classes=80 num=9 还可以修改batch，subdivisions和max_batches等参数。其中batch表示一个批次训练的图片数目，一个epoch=total_train_images/batch，而subdivisions表示将一个batch分为subdivisions个组进行分别训练，每个组有batch/subdivisions个图片。max_batches表示最大的批次数，而iterations=max_batches/batch。 4 下载ImageNet预训练的网络参数 yolov3默认的训练权重为darknet53，我们可以在darknet路径下打开终端，输入命令下载权重： wget https://pjreddie.com/media/files/darknet53.conv.74 5 训练模型 输入以下命令，即可开始训练 sudo ./darknet detector train bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg darknet53.conv.74 6 测试一张图片 输入以下命令，即可开始测试模型： sudo ./darknet detector test bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup data/000005.png 7 测试一个视频 sudo ./darknet detector demo bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup driving.mp4 8 测试网络摄像头输入 sudo ./darknet detector demo bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup -c 1 9 中断后继续训练模型 输入以下命令，即可开始测试模型： sudo ./darknet detector train bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup" />
<link rel="canonical" href="https://mlh.app/2019/01/15/cfac3d9f34269105aa0c9f885a4f18e7.html" />
<meta property="og:url" content="https://mlh.app/2019/01/15/cfac3d9f34269105aa0c9f885a4f18e7.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-15T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：转载请注明出处。 https://blog.csdn.net/qq583083658/article/details/86499208 目录 1 准备bdd100k.names文件 2 准备bdd100k.names文件准备bdd100k.data 3 准备yolov3-bdd100k.cfg 4 下载ImageNet预训练的网络参数 5 训练模型 6 测试一张图片 7 测试一个视频 8 测试网络摄像头输入 9 中断后继续训练模型 经过前面两篇博客（（一）使用YOLOv3训练BDD100K数据集之数据集下载 和（二）使用YOLOv3训练BDD100K数据集之标签格式转换），我们已经准备了BDD100K数据集，并且已经生成了darknet格式的标签，需要的训练集和验证集train.txt和val.txt，现在我们只需要简单地修改几个配置文件就可以开始训练了。 1 准备bdd100k.names文件 在darknet/data/目录下创建文件bdd100k.names，里面存放了每一类的类名，这个将在测试一张图片时在右上角显示一个物体的标签名。文件内容如下（注意顺序要与xml_to_yolo_txt.py文件里面的顺序一致。）： car bus person bike truck motor train rider traffic sign traffic light 2 准备bdd100k.names文件准备bdd100k.data 在darknet/data/目录下创建文件bdd100k.data，其内容如下，其中classes表示类的数目，train和val表示前一篇文章中生成的train.txt和val.txt的存放路径（相对于darknet安装路径），backup表示训练的yolo权重存放的位置。 classes = 10 train = bdd100k_data/train.txt valid = bdd100k_data/val.txt names = bdd100k_data/bdd100k.names backup = backup/ 3 准备yolov3-bdd100k.cfg 在darknet/cfg目录下，创建一个文件yolov3-bdd100k.cfg，里面的内容可以先拷贝yolov3.cfg，在修改以下几个部分： 三处classes=80修改为classes=10 三处filters=255（注意只需要修改[yolo]上面的[convolutional]的filters）修改为filters=45（ filters=3*(classes+5) ），如下： 也可以模仿此处，修改yolov3-tiny.cfg或yolov2.cfg来使用YOLOv3-tiny或YOLOv2模型训练BDD00K [convolutional] size=1 stride=1 pad=1 filters=255 # 此处需要修改为filters=45，注意一定要修改[yolo]层前面的第一个[convolutional] activation=linear [yolo] mask = 3,4,5 anchors = 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326 classes=80 num=9 还可以修改batch，subdivisions和max_batches等参数。其中batch表示一个批次训练的图片数目，一个epoch=total_train_images/batch，而subdivisions表示将一个batch分为subdivisions个组进行分别训练，每个组有batch/subdivisions个图片。max_batches表示最大的批次数，而iterations=max_batches/batch。 4 下载ImageNet预训练的网络参数 yolov3默认的训练权重为darknet53，我们可以在darknet路径下打开终端，输入命令下载权重： wget https://pjreddie.com/media/files/darknet53.conv.74 5 训练模型 输入以下命令，即可开始训练 sudo ./darknet detector train bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg darknet53.conv.74 6 测试一张图片 输入以下命令，即可开始测试模型： sudo ./darknet detector test bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup data/000005.png 7 测试一个视频 sudo ./darknet detector demo bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup driving.mp4 8 测试网络摄像头输入 sudo ./darknet detector demo bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup -c 1 9 中断后继续训练模型 输入以下命令，即可开始测试模型： sudo ./darknet detector train bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup","@type":"BlogPosting","url":"https://mlh.app/2019/01/15/cfac3d9f34269105aa0c9f885a4f18e7.html","headline":"（三）使用YOLOv3训练BDD100K数据集之开始训练","dateModified":"2019-01-15T00:00:00+08:00","datePublished":"2019-01-15T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/01/15/cfac3d9f34269105aa0c9f885a4f18e7.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>（三）使用YOLOv3训练BDD100K数据集之开始训练</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：转载请注明出处。 https://blog.csdn.net/qq583083658/article/details/86499208 
 </div> 
 <div id="content_views" class="markdown_views prism-tomorrow-night-eighties"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h2><a id="_0"></a>目录</h2> 
  <ul> 
   <li><a href="#1" rel="nofollow">1 准备bdd100k.names文件</a></li> 
   <li><a href="#2" rel="nofollow">2 准备bdd100k.names文件准备bdd100k.data</a></li> 
   <li><a href="#3" rel="nofollow">3 准备yolov3-bdd100k.cfg</a></li> 
   <li><a href="#4" rel="nofollow">4 下载ImageNet预训练的网络参数</a></li> 
   <li><a href="#5" rel="nofollow">5 训练模型</a></li> 
   <li><a href="#6" rel="nofollow">6 测试一张图片</a></li> 
   <li><a href="#7" rel="nofollow">7 测试一个视频</a></li> 
   <li><a href="#8" rel="nofollow">8 测试网络摄像头输入</a></li> 
   <li><a href="#9" rel="nofollow">9 中断后继续训练模型</a></li> 
  </ul> 
  <p>经过前面两篇博客（<a href="https://blog.csdn.net/qq583083658/article/details/86493752" rel="nofollow">（一）使用YOLOv3训练BDD100K数据集之数据集下载<br> </a>和<a href="https://blog.csdn.net/qq583083658/article/details/86496563" rel="nofollow">（二）使用YOLOv3训练BDD100K数据集之标签格式转换</a>），我们已经<code>准备了BDD100K数据集</code>，并且已经<code>生成了darknet格式的标签，需要的训练集和验证集train.txt和val.txt</code>，现在我们只需要简单地修改几个配置文件就可以开始训练了。</p> 
  <h3><a id="a_name1a_1_bdd100knames_14"></a><a></a> 1 准备bdd100k.names文件</h3> 
  <p>在darknet/data/目录下创建文件bdd100k.names，里面存放了每一类的类名，这个将在测试一张图片时在右上角显示一个物体的标签名。文件内容如下（注意顺序要与xml_to_yolo_txt.py文件里面的顺序一致。）：</p> 
  <pre><code class="prism language-bash">car
bus
person
bike
truck
motor
train
rider
traffic sign
traffic light
</code></pre> 
  <h3><a id="a_name2a_2_bdd100knamesbdd100kdata_28"></a><a></a> 2 准备bdd100k.names文件准备bdd100k.data</h3> 
  <p>在darknet/data/目录下创建文件bdd100k.data，其内容如下，其中classes表示类的数目，train和val表示前一篇文章中生成的train.txt和val.txt的存放路径（相对于darknet安装路径），backup表示训练的yolo权重存放的位置。</p> 
  <pre><code class="prism language-bash">classes <span class="token operator">=</span> 10
train <span class="token operator">=</span> bdd100k_data/train.txt
valid <span class="token operator">=</span> bdd100k_data/val.txt
names <span class="token operator">=</span> bdd100k_data/bdd100k.names
backup <span class="token operator">=</span> backup/
</code></pre> 
  <h3><a id="a_name3a_3_yolov3bdd100kcfg_37"></a><a></a> 3 准备yolov3-bdd100k.cfg</h3> 
  <p>在darknet/cfg目录下，创建一个文件yolov3-bdd100k.cfg，里面的内容可以先拷贝yolov3.cfg，在修改以下几个部分：</p> 
  <ul> 
   <li>三处classes=80修改为classes=10</li> 
   <li>三处filters=255（注意只需要修改[yolo]上面的[convolutional]的filters）修改为filters=45（ filters=3*(classes+5) ），如下： 
    <blockquote> 
     <p>也可以模仿此处，<code>修改yolov3-tiny.cfg或yolov2.cfg来使用YOLOv3-tiny或YOLOv2模型</code>训练BDD00K</p> 
    </blockquote> </li> 
  </ul> 
  <pre><code class="prism language-bash"><span class="token punctuation">[</span>convolutional<span class="token punctuation">]</span>
size<span class="token operator">=</span>1
stride<span class="token operator">=</span>1
pad<span class="token operator">=</span>1
filters<span class="token operator">=</span>255 <span class="token comment"># 此处需要修改为filters=45，注意一定要修改[yolo]层前面的第一个[convolutional]</span>
activation<span class="token operator">=</span>linear
<span class="token punctuation">[</span>yolo<span class="token punctuation">]</span>
mask <span class="token operator">=</span> 3,4,5
anchors <span class="token operator">=</span> 10,13, 16,30, 33,23, 30,61, 62,45, 59,119, 116,90, 156,198, 373,326
classes<span class="token operator">=</span>80
num<span class="token operator">=</span>9
</code></pre> 
  <ul> 
   <li>还可以修改batch，subdivisions和max_batches等参数。其中<code>batch表示一个批次训练的图片数目，一个epoch=total_train_images/batch</code>，而<code>subdivisions表示将一个batch分为subdivisions个组进行分别训练，每个组有batch/subdivisions个图片</code>。max_batches表示最大的批次数，而iterations=max_batches/batch。</li> 
  </ul> 
  <h3><a id="a_name4a_4_ImageNet_58"></a><a></a> 4 下载ImageNet预训练的网络参数</h3> 
  <p>yolov3默认的训练权重为<a href="https://pjreddie.com/darknet/imagenet/#darknet53" rel="nofollow">darknet53</a>，我们可以在darknet路径下打开终端，输入命令下载权重：</p> 
  <pre><code class="prism language-bash"><span class="token function">wget</span> https://pjreddie.com/media/files/darknet53.conv.74
</code></pre> 
  <h3><a id="a_name5a_5__63"></a><a></a> 5 训练模型</h3> 
  <p>输入以下命令，即可开始训练</p> 
  <pre><code class="prism language-bash"><span class="token function">sudo</span> ./darknet detector train bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg darknet53.conv.74
</code></pre> 
  <h3><a id="a_name6a_6__68"></a><a></a> 6 测试一张图片</h3> 
  <p>输入以下命令，即可开始测试模型：</p> 
  <pre><code class="prism language-bash"><span class="token function">sudo</span> ./darknet detector <span class="token function">test</span> bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup  data/000005.png
</code></pre> 
  <h3><a id="a_name7a_7__73"></a><a></a> 7 测试一个视频</h3> 
  <pre><code class="prism language-bash"><span class="token function">sudo</span> ./darknet detector demo bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup driving.mp4
</code></pre> 
  <h3><a id="a_name8a_8__77"></a><a></a> 8 测试网络摄像头输入</h3> 
  <pre><code class="prism language-bash"><span class="token function">sudo</span> ./darknet detector demo bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg backup/yolov3-bdd100k.backup -c 1
</code></pre> 
  <h3><a id="a_name9a_9__81"></a><a></a> 9 中断后继续训练模型</h3> 
  <p>输入以下命令，即可开始测试模型：</p> 
  <pre><code class="prism language-bash"><span class="token function">sudo</span> ./darknet detector train bdd100k_data/bdd100k.data cfg/yolov3-bdd100k.cfg  backup/yolov3-bdd100k.backup  
</code></pre> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
