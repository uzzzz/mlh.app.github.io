<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>自己数据制作tfrecords格式的数据集 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="自己数据制作tfrecords格式的数据集" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="数据集格式，将所有测试或者训练数据集各自保存在一个文件夹下：如下图：训练数据集 制作.tfrecords格式数据集的代码： import os import tensorflow as tf from PIL import Image #注意Image,后面会用到 # Imagenet图片都保存在/data目录下，里面有1000个子目录，获取这些子目录的名字 classes = os.listdir(&#39;G:\\train\\&#39;) cwd1=&#39;G:\\test\\&#39; cwd2=&#39;G:\\train\\&#39; print(classes) writer1 = tf.python_io.TFRecordWriter(&quot;test.tfrecords&quot;) # 要生成的文件 writer2 = tf.python_io.TFRecordWriter(&quot;train.tfrecords&quot;) # 要生成的文件 for index in range(10): print(index) name=classes[index] print(name) class_path1 = cwd1 + name + &#39;/&#39; #训练数据集的路径 class_path2 = cwd2 + name + &#39;/&#39; #测试数据集的路径 for img_name in os.listdir(class_path1): img_path = class_path1 + img_name # 每一个图片的地址 img = Image.open(img_path) img = img.resize((32, 32)) img_raw = img.tobytes() # 将图片转化为二进制格式 example = tf.train.Example(features=tf.train.Features(feature={ &quot;label&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=[index])), &#39;img_raw&#39;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])) })) # example对象对label和image数据进行封装 writer1.write(example.SerializeToString()) # 序列化为字符串 for img_name2 in os.listdir(class_path2): img_path2 = class_path2 + img_name2 # 每一个图片的地址 img2 = Image.open(img_path2) img2 = img2.resize((64, 64)) img_raw2 = img2.tobytes() # 将图片转化为二进制格式 example2 = tf.train.Example(features=tf.train.Features(feature={ &quot;label&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=[index])), &#39;img_raw&#39;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw2])) })) # example对象对label和image数据进行封装 writer2.write(example2.SerializeToString()) # 序列化为字符串 writer1.close() writer2.close() &nbsp; 读取数据集代码： def read_and_decode(filename): # 读入dog_train.tfrecords filename_queue = tf.train.string_input_producer([filename]) # 生成一个queue队列 reader = tf.TFRecordReader() _, serialized_example = reader.read(filename_queue) # 返回文件名和文件 features = tf.parse_single_example(serialized_example, features={ &#39;label&#39;: tf.FixedLenFeature([], tf.int64), &#39;img_raw&#39;: tf.FixedLenFeature([], tf.string), }) # 将image数据和label取出来 img = tf.decode_raw(features[&#39;img_raw&#39;], tf.uint8) img = tf.reshape(img, [32 * 32 * 3]) # reshape为128*128的3通道图片 img = tf.cast(img, tf.float32) * (1. / 255) label = tf.cast(features[&#39;label&#39;], tf.int32) # 在流中抛出label张量 return img, label #打乱数据 def createBatch(filename, batchsize): images, labels = read_and_decode(filename) min_after_dequeue = batchsize capacity = 3 * batchsize image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batchsize, capacity=capacity, min_after_dequeue=min_after_dequeue ) label_batch = tf.one_hot(label_batch, depth=10) return image_batch, label_batch 使用细节多个tfrecord文件 data_dir = &#39;/home/sanyuan/dataset_animal/dataset_tfrecords/&#39;&nbsp; &nbsp; filenames = [os.path.join(data_dir,&#39;train%d.tfrecords&#39; % ii) for ii in range(1)]　#如果有多个文件，直接更改这里即可 filename_queue = tf.train.string_input_producer(filenames) image = read_and_decode(filename_queue) tfrecord本质是创建一个文件队列，创建一个内存队列，内存队列不需要创建，文件队列则需要通过tfrecords文件名来创建。 shuffle参数判断远问是否需要打乱，num_epochs迭代的代数100 filename_queue = tf.train.string_input_producer([filename],shuffle=True,num_epochs=100) # 生成一个queue队列" />
<meta property="og:description" content="数据集格式，将所有测试或者训练数据集各自保存在一个文件夹下：如下图：训练数据集 制作.tfrecords格式数据集的代码： import os import tensorflow as tf from PIL import Image #注意Image,后面会用到 # Imagenet图片都保存在/data目录下，里面有1000个子目录，获取这些子目录的名字 classes = os.listdir(&#39;G:\\train\\&#39;) cwd1=&#39;G:\\test\\&#39; cwd2=&#39;G:\\train\\&#39; print(classes) writer1 = tf.python_io.TFRecordWriter(&quot;test.tfrecords&quot;) # 要生成的文件 writer2 = tf.python_io.TFRecordWriter(&quot;train.tfrecords&quot;) # 要生成的文件 for index in range(10): print(index) name=classes[index] print(name) class_path1 = cwd1 + name + &#39;/&#39; #训练数据集的路径 class_path2 = cwd2 + name + &#39;/&#39; #测试数据集的路径 for img_name in os.listdir(class_path1): img_path = class_path1 + img_name # 每一个图片的地址 img = Image.open(img_path) img = img.resize((32, 32)) img_raw = img.tobytes() # 将图片转化为二进制格式 example = tf.train.Example(features=tf.train.Features(feature={ &quot;label&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=[index])), &#39;img_raw&#39;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])) })) # example对象对label和image数据进行封装 writer1.write(example.SerializeToString()) # 序列化为字符串 for img_name2 in os.listdir(class_path2): img_path2 = class_path2 + img_name2 # 每一个图片的地址 img2 = Image.open(img_path2) img2 = img2.resize((64, 64)) img_raw2 = img2.tobytes() # 将图片转化为二进制格式 example2 = tf.train.Example(features=tf.train.Features(feature={ &quot;label&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=[index])), &#39;img_raw&#39;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw2])) })) # example对象对label和image数据进行封装 writer2.write(example2.SerializeToString()) # 序列化为字符串 writer1.close() writer2.close() &nbsp; 读取数据集代码： def read_and_decode(filename): # 读入dog_train.tfrecords filename_queue = tf.train.string_input_producer([filename]) # 生成一个queue队列 reader = tf.TFRecordReader() _, serialized_example = reader.read(filename_queue) # 返回文件名和文件 features = tf.parse_single_example(serialized_example, features={ &#39;label&#39;: tf.FixedLenFeature([], tf.int64), &#39;img_raw&#39;: tf.FixedLenFeature([], tf.string), }) # 将image数据和label取出来 img = tf.decode_raw(features[&#39;img_raw&#39;], tf.uint8) img = tf.reshape(img, [32 * 32 * 3]) # reshape为128*128的3通道图片 img = tf.cast(img, tf.float32) * (1. / 255) label = tf.cast(features[&#39;label&#39;], tf.int32) # 在流中抛出label张量 return img, label #打乱数据 def createBatch(filename, batchsize): images, labels = read_and_decode(filename) min_after_dequeue = batchsize capacity = 3 * batchsize image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batchsize, capacity=capacity, min_after_dequeue=min_after_dequeue ) label_batch = tf.one_hot(label_batch, depth=10) return image_batch, label_batch 使用细节多个tfrecord文件 data_dir = &#39;/home/sanyuan/dataset_animal/dataset_tfrecords/&#39;&nbsp; &nbsp; filenames = [os.path.join(data_dir,&#39;train%d.tfrecords&#39; % ii) for ii in range(1)]　#如果有多个文件，直接更改这里即可 filename_queue = tf.train.string_input_producer(filenames) image = read_and_decode(filename_queue) tfrecord本质是创建一个文件队列，创建一个内存队列，内存队列不需要创建，文件队列则需要通过tfrecords文件名来创建。 shuffle参数判断远问是否需要打乱，num_epochs迭代的代数100 filename_queue = tf.train.string_input_producer([filename],shuffle=True,num_epochs=100) # 生成一个queue队列" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-15T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"数据集格式，将所有测试或者训练数据集各自保存在一个文件夹下：如下图：训练数据集 制作.tfrecords格式数据集的代码： import os import tensorflow as tf from PIL import Image #注意Image,后面会用到 # Imagenet图片都保存在/data目录下，里面有1000个子目录，获取这些子目录的名字 classes = os.listdir(&#39;G:\\\\train\\\\&#39;) cwd1=&#39;G:\\\\test\\\\&#39; cwd2=&#39;G:\\\\train\\\\&#39; print(classes) writer1 = tf.python_io.TFRecordWriter(&quot;test.tfrecords&quot;) # 要生成的文件 writer2 = tf.python_io.TFRecordWriter(&quot;train.tfrecords&quot;) # 要生成的文件 for index in range(10): print(index) name=classes[index] print(name) class_path1 = cwd1 + name + &#39;/&#39; #训练数据集的路径 class_path2 = cwd2 + name + &#39;/&#39; #测试数据集的路径 for img_name in os.listdir(class_path1): img_path = class_path1 + img_name # 每一个图片的地址 img = Image.open(img_path) img = img.resize((32, 32)) img_raw = img.tobytes() # 将图片转化为二进制格式 example = tf.train.Example(features=tf.train.Features(feature={ &quot;label&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=[index])), &#39;img_raw&#39;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])) })) # example对象对label和image数据进行封装 writer1.write(example.SerializeToString()) # 序列化为字符串 for img_name2 in os.listdir(class_path2): img_path2 = class_path2 + img_name2 # 每一个图片的地址 img2 = Image.open(img_path2) img2 = img2.resize((64, 64)) img_raw2 = img2.tobytes() # 将图片转化为二进制格式 example2 = tf.train.Example(features=tf.train.Features(feature={ &quot;label&quot;: tf.train.Feature(int64_list=tf.train.Int64List(value=[index])), &#39;img_raw&#39;: tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw2])) })) # example对象对label和image数据进行封装 writer2.write(example2.SerializeToString()) # 序列化为字符串 writer1.close() writer2.close() &nbsp; 读取数据集代码： def read_and_decode(filename): # 读入dog_train.tfrecords filename_queue = tf.train.string_input_producer([filename]) # 生成一个queue队列 reader = tf.TFRecordReader() _, serialized_example = reader.read(filename_queue) # 返回文件名和文件 features = tf.parse_single_example(serialized_example, features={ &#39;label&#39;: tf.FixedLenFeature([], tf.int64), &#39;img_raw&#39;: tf.FixedLenFeature([], tf.string), }) # 将image数据和label取出来 img = tf.decode_raw(features[&#39;img_raw&#39;], tf.uint8) img = tf.reshape(img, [32 * 32 * 3]) # reshape为128*128的3通道图片 img = tf.cast(img, tf.float32) * (1. / 255) label = tf.cast(features[&#39;label&#39;], tf.int32) # 在流中抛出label张量 return img, label #打乱数据 def createBatch(filename, batchsize): images, labels = read_and_decode(filename) min_after_dequeue = batchsize capacity = 3 * batchsize image_batch, label_batch = tf.train.shuffle_batch([images, labels], batch_size=batchsize, capacity=capacity, min_after_dequeue=min_after_dequeue ) label_batch = tf.one_hot(label_batch, depth=10) return image_batch, label_batch 使用细节多个tfrecord文件 data_dir = &#39;/home/sanyuan/dataset_animal/dataset_tfrecords/&#39;&nbsp; &nbsp; filenames = [os.path.join(data_dir,&#39;train%d.tfrecords&#39; % ii) for ii in range(1)]　#如果有多个文件，直接更改这里即可 filename_queue = tf.train.string_input_producer(filenames) image = read_and_decode(filename_queue) tfrecord本质是创建一个文件队列，创建一个内存队列，内存队列不需要创建，文件队列则需要通过tfrecords文件名来创建。 shuffle参数判断远问是否需要打乱，num_epochs迭代的代数100 filename_queue = tf.train.string_input_producer([filename],shuffle=True,num_epochs=100) # 生成一个queue队列","@type":"BlogPosting","url":"/2019/01/15/9729d1008749ef56f187d24495801119.html","headline":"自己数据制作tfrecords格式的数据集","dateModified":"2019-01-15T00:00:00+08:00","datePublished":"2019-01-15T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/01/15/9729d1008749ef56f187d24495801119.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>自己数据制作tfrecords格式的数据集</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>数据集格式，将所有测试或者训练数据集各自保存在一个文件夹下：如下图：训练数据集</p> 
  <p><img alt="" class="has" height="287" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190115211608563.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwNDE0ODE4,size_16,color_FFFFFF,t_70" width="1109"></p> 
  <p>制作.tfrecords格式数据集的代码：</p> 
  <pre>
<code class="language-html hljs">import os
import tensorflow as tf
from PIL import Image  #注意Image,后面会用到

# Imagenet图片都保存在/data目录下，里面有1000个子目录，获取这些子目录的名字
classes = os.listdir('G:\\train\\')

cwd1='G:\\test\\'
cwd2='G:\\train\\'


print(classes)
writer1 = tf.python_io.TFRecordWriter("test.tfrecords")  # 要生成的文件
writer2 = tf.python_io.TFRecordWriter("train.tfrecords")  # 要生成的文件


for index in range(10):
    print(index)
    name=classes[index]
    print(name)
    class_path1 = cwd1 + name + '/'     #训练数据集的路径
    class_path2 = cwd2 + name + '/'     #测试数据集的路径
    for img_name in os.listdir(class_path1):
        img_path = class_path1 + img_name  # 每一个图片的地址
        img = Image.open(img_path)
        img = img.resize((32, 32))
        img_raw = img.tobytes()  # 将图片转化为二进制格式
        example = tf.train.Example(features=tf.train.Features(feature={
            "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),
            'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw]))
        }))  # example对象对label和image数据进行封装
        writer1.write(example.SerializeToString())  # 序列化为字符串
    for img_name2 in os.listdir(class_path2):
        img_path2 = class_path2 + img_name2  # 每一个图片的地址

        img2 = Image.open(img_path2)
        img2 = img2.resize((64, 64))
        img_raw2 = img2.tobytes()  # 将图片转化为二进制格式
        example2 = tf.train.Example(features=tf.train.Features(feature={
            "label": tf.train.Feature(int64_list=tf.train.Int64List(value=[index])),
            'img_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw2]))
        }))  # example对象对label和image数据进行封装
        writer2.write(example2.SerializeToString())  # 序列化为字符串
writer1.close()
writer2.close()
</code></pre> 
  <p>&nbsp;</p> 
  <p>读取数据集代码：</p> 
  <pre>
<code class="language-html hljs">def read_and_decode(filename):  # 读入dog_train.tfrecords
    filename_queue = tf.train.string_input_producer([filename])  # 生成一个queue队列

    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)  # 返回文件名和文件
    features = tf.parse_single_example(serialized_example,
                                       features={
                                           'label': tf.FixedLenFeature([], tf.int64),
                                           'img_raw': tf.FixedLenFeature([], tf.string),
                                       })  # 将image数据和label取出来
    img = tf.decode_raw(features['img_raw'], tf.uint8)
    img = tf.reshape(img, [32 * 32 * 3])  # reshape为128*128的3通道图片
    img = tf.cast(img, tf.float32) * (1. / 255)
    label = tf.cast(features['label'], tf.int32)  # 在流中抛出label张量
    return img, label

#打乱数据
def createBatch(filename, batchsize):
    images, labels = read_and_decode(filename)

    min_after_dequeue = batchsize
    capacity = 3 * batchsize
    image_batch, label_batch = tf.train.shuffle_batch([images, labels],
                                                      batch_size=batchsize,
                                                      capacity=capacity,
                                                      min_after_dequeue=min_after_dequeue
                                                      )
    label_batch = tf.one_hot(label_batch, depth=10)
    return image_batch, label_batch</code></pre> 
  <h1><code class="language-html hljs">使用细节</code>多个tfrecord文件</h1> 
  <p><br> data_dir = '/home/sanyuan/dataset_animal/dataset_tfrecords/'&nbsp;<br> &nbsp;<br> filenames = [os.path.join(data_dir,'train%d.tfrecords' % ii) for ii in range(1)]　#如果有多个文件，直接更改这里即可<br> filename_queue = tf.train.string_input_producer(filenames)<br> image = read_and_decode(filename_queue)<br> tfrecord本质是创建一个文件队列，创建一个内存队列，内存队列不需要创建，文件队列则需要通过tfrecords文件名来创建。</p> 
  <p>shuffle参数判断远问是否需要打乱，num_epochs迭代的代数100</p> 
  <pre>
filename_queue = tf.train.string_input_producer([filename],shuffle=True,num_epochs=100)  # 生成一个queue队列
</pre> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
