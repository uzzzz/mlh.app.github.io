<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>重读Youtube深度学习推荐系统论文，字字珠玑，惊为神文 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="重读Youtube深度学习推荐系统论文，字字珠玑，惊为神文" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="&nbsp;&nbsp;&nbsp;&nbsp; 作者：王喆&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 编辑：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 前 &nbsp;言 这里是王喆的机器学习笔记，每隔一到两周我会站在算法工程师的角度讲解一些计算广告、推荐系统相关的文章。选择文章必须满足一下三个条件： 一是工程导向的； 二是阿里、facebook、google等一线互联网公司出品的； 三是前沿或者经典的。 这周我们一起讨论一下Youtube的深度推荐系统论文《Deep Neural Networks for YouTube Recommendations》，这是2016年的论文，按照今天的标准来看，已经没有什么新颖的地方，我也是两年前读过这篇文章之后就放下了，但前几天重读这篇文章，竟让发现了诸多亮点，几乎处处是套路，处处是经验，不由惊为神文。这篇神文给我留下的深刻印象有两点： 这毫无疑问是工业界论文的典范，是我非常推崇的工程导向的，算法工程师必读的文章； 我以为毫不起眼的地方，也藏着Youtube工程师宝贵的工程经验，相比上周介绍的阿里的深度兴趣网络DIN，最重要的价值就在于Attention机制，这篇文章你应该精确到句子来体会，这是我惊为神文的原因。 废话不多说，下面就跟大家分享一下两次拜读这篇论文的不同体验和收获。 01 第一次阅读的收获 第一遍读这篇论文的时候，我想所有人都是冲着算法的架构去的，在深度学习推荐系统已经成为各大公司“基本操作”的今天，Youtube在算法架构上并无惊奇之处，我们来快速介绍一下文章中的深度学习推荐系统的算法架构。 Youtube的用户推荐场景自不必多说，作为全球最大的UGC的视频网站，需要在百万量级的视频规模下进行个性化推荐。由于候选视频集合过大，考虑online系统延迟问题，不宜用复杂网络直接进行推荐，所以Youtube采取了两层深度网络完成整个推荐过程： 第一层是Candidate Generation Model完成候选视频的快速筛选，这一步候选视频集合由百万降低到了百的量级。 第二层是用Ranking Model完成几百个候选视频的精排 首先介绍candidate generation模型的架构 Youtube Candidate Generation Model 我们自底而上看这个网络，最底层的输入是用户观看过的video的embedding向量，以及搜索词的embedding向量。至于这个embedding向量是怎么生成的，作者的原话是这样的 Inspired by continuous bag of words language models, we learn high dimensional embeddings for each video in a xed vocabulary and feed these embeddings into a feedforward neural network 所以作者是先用word2vec方法对video和search token做了embedding之后再作为输入的，这也是做embedding的“基本操作”，不用过多介绍；当然，除此之外另一种大家应该也比较熟悉，就是通过加一个embedding层跟上面的DNN一起训练，两种方法孰优孰劣，有什么适用场合，大家可以讨论一下。 特征向量里面还包括了用户的地理位置的embedding，年龄，性别等。然后把所有这些特征concatenate起来，喂给上层的ReLU神经网络。 三层神经网络过后，我们看到了softmax函数。这里Youtube的同学们把这个问题看作为用户推荐next watch的问题，所以输出应该是一个在所有candidate video上的概率分布，自然是一个多分类问题。 好了，这一套深度学习的“基本操作”下来，就构成了Youtube的candidate generation网络，看似平淡无奇，其实还是隐藏着一些问题的，比如 架构图的左上角，为什么在online serving的时候不直接用这套网络进行预测而要使用nearest neighbor search 的方法？ 多分类问题中，Youtube的candidate video有百万之巨，意味着有几百万个分类，这必然会影响训练效果和速度，如何改进？ 这些问题在读第一遍的时候我也没有深想深看，但却是工程实现中必然会遇到的问题，我们随后再深入介绍论文中的解决方法。 既然得到了几百个候选集合，下一步就是利用ranking模型进行精排序，下面是ranking深度学习网络的架构图。 Youtube Ranking Model 乍一看上面的ranking model似乎与candidate generation模型没有什么区别，模型架构还是深度学习的“基本操作”，唯一的区别就是特征工程，那么我们就讲讲特征工程。 事实上原文也明确说明了，引入另一套DNN作为ranking model的目的就是引入更多描述视频、用户以及二者之间关系的特征，达到对候选视频集合准确排序的目的。 During ranking, we have access to many more features describing the video and the user&#39;s relationship to the video because only a few hundred videos are being scored rather than the millions scored in candidate generation. 具体一点，从左至右的特征依次是 impression video ID embedding: 当前要计算的video的embedding watched video IDs average embedding: 用户观看过的最后N个视频embedding的average pooling language embedding: 用户语言的embedding和当前视频语言的embedding time since last watch: 自上次观看同channel视频的时间 #previous impressions: 该视频已经被曝光给该用户的次数 上面五个特征中，我想重点谈谈第4个和第5个。因为这两个很好的引入了对用户行为的观察。 第4个特征背后的思想是 We observe that the most important signals are those that describe a user&#39;s previous interaction with the item itself and other similar items. 有一些引入attention的意思，这里是用了time since last watch这个特征来反应用户看同类视频的间隔时间。从用户的角度想一想，假如我们刚看过“DOTA经典回顾”这个channel的视频，我们很大概率是会继续看这个channel的视频的，那么该特征就很好的捕捉到了这一用户行为。 第5个特征#previous impressions则一定程度上引入了exploration的思想，避免同一个视频持续对同一用户进行无效曝光。尽量增加用户没看过的新视频的曝光可能性。 至此，我的第一遍论文阅读就结束了，对Youtube的算法框架有了概念，但总觉得不过如此，没什么太多新颖的地方。。 但如果真这么想，还是太naive了，与上一篇阿里的深度兴趣网络DIN不同的是，你读懂了DIN的attention机制，你就抓住了其论文70%的价值，但这篇文章，如果你只读懂了Youtube的推荐系统架构，你只抓住了30%的价值。那么剩下的70%的价值在哪里呢？ 02 第二次阅读的收获 在重读这篇文章的时候，我从一个工程师的角度，始终绷着“如何实现”这根弦，发现这篇论文的工程价值之前被我大大忽略了。下面我列出十个文中解决的非常有价值的问题： 文中把推荐问题转换成多分类问题，在next watch的场景下，每一个备选video都会是一个分类，因此总共的分类有数百万之巨，这在使用softmax训练时无疑是低效的，这个问题Youtube是如何解决的？ 在candidate generation model的serving过程中，Youtube为什么不直接采用训练时的model进行预测，而是采用了一种最近邻搜索的方法？ Youtube的用户对新视频有偏好，那么在模型构建的过程中如何引入这个feature？ 在对训练集的预处理过程中，Youtube没有采用原始的用户日志，而是对每个用户提取等数量的训练样本，这是为什么？ Youtube为什么不采取类似RNN的Sequence model，而是完全摒弃了用户观看历史的时序特征，把用户最近的浏览历史等同看待，这不会损失有效信息吗？ 在处理测试集的时候，Youtube为什么不采用经典的随机留一法（random holdout），而是一定要把用户最近的一次观看行为作为测试集？ 在确定优化目标的时候，Youtube为什么不采用经典的CTR，或者播放率（Play Rate），而是采用了每次曝光预期播放时间（expected watch time per impression）作为优化目标？ 在进行video embedding的时候，为什么要直接把大量长尾的video直接用0向量代替？ 针对某些特征，比如#previous impressions，为什么要进行开方和平方处理后，当作三个特征输入模型？ 为什么ranking model不采用经典的logistic regression当作输出层，而是采用了weighted logistic regression？ 因为我也是在视频推荐领域工作，所以可以很负责任的说以上的十个问题都是非常有价值的。但今天一口气写到这里，感觉有点气力不足了。。大家如果感兴趣的话可以点个赞，我明天再详细分析一下以上十大问题的答案。 上面问题的解答已经完成啦，大家请参考我的下一篇文章。 好了，这里是王喆的机器学习笔记的第二篇文章，水平有限，欢迎大家吐槽，批评，纠错。 03 参考资料 1. Deep Neural Networks for YouTube Recommendation (https://github.com/wzhe06/Reco-papers/blob/master/Recommendation/Deep%20Neural%20Networks%20for%20YouTube%20Recommendations.pdf) 2. Recommender System Paper List (https://github.com/wzhe06/Reco-papers) 3. 推荐系统中的注意力机制——阿里深度兴趣网络（DIN） (https://zhuanlan.zhihu.com/p/51623339) &nbsp; END 往期回顾之作者王喆 【1】《为什么说算法工程师的面试是一门玄学？》‍ 【2】《从零开始学习自然语言处理（NLP）》 【3】《万物皆Embedding，从经典的word2vec到深度学习》 【4】《干货|一看就懂的卷积神经网络》 【5】《GAN-提升GAN训练的技巧汇总》 【6】《学会用Docker部署深度学习环境》 机器学习算法工程师 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一个用心的公众号 长按，识别，加关注 进群，学习，得帮助 你的关注，我们的热度， 我们一定给你学习最大的帮助 你点的每个赞，我都认真当成了喜欢" />
<meta property="og:description" content="&nbsp;&nbsp;&nbsp;&nbsp; 作者：王喆&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 编辑：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 前 &nbsp;言 这里是王喆的机器学习笔记，每隔一到两周我会站在算法工程师的角度讲解一些计算广告、推荐系统相关的文章。选择文章必须满足一下三个条件： 一是工程导向的； 二是阿里、facebook、google等一线互联网公司出品的； 三是前沿或者经典的。 这周我们一起讨论一下Youtube的深度推荐系统论文《Deep Neural Networks for YouTube Recommendations》，这是2016年的论文，按照今天的标准来看，已经没有什么新颖的地方，我也是两年前读过这篇文章之后就放下了，但前几天重读这篇文章，竟让发现了诸多亮点，几乎处处是套路，处处是经验，不由惊为神文。这篇神文给我留下的深刻印象有两点： 这毫无疑问是工业界论文的典范，是我非常推崇的工程导向的，算法工程师必读的文章； 我以为毫不起眼的地方，也藏着Youtube工程师宝贵的工程经验，相比上周介绍的阿里的深度兴趣网络DIN，最重要的价值就在于Attention机制，这篇文章你应该精确到句子来体会，这是我惊为神文的原因。 废话不多说，下面就跟大家分享一下两次拜读这篇论文的不同体验和收获。 01 第一次阅读的收获 第一遍读这篇论文的时候，我想所有人都是冲着算法的架构去的，在深度学习推荐系统已经成为各大公司“基本操作”的今天，Youtube在算法架构上并无惊奇之处，我们来快速介绍一下文章中的深度学习推荐系统的算法架构。 Youtube的用户推荐场景自不必多说，作为全球最大的UGC的视频网站，需要在百万量级的视频规模下进行个性化推荐。由于候选视频集合过大，考虑online系统延迟问题，不宜用复杂网络直接进行推荐，所以Youtube采取了两层深度网络完成整个推荐过程： 第一层是Candidate Generation Model完成候选视频的快速筛选，这一步候选视频集合由百万降低到了百的量级。 第二层是用Ranking Model完成几百个候选视频的精排 首先介绍candidate generation模型的架构 Youtube Candidate Generation Model 我们自底而上看这个网络，最底层的输入是用户观看过的video的embedding向量，以及搜索词的embedding向量。至于这个embedding向量是怎么生成的，作者的原话是这样的 Inspired by continuous bag of words language models, we learn high dimensional embeddings for each video in a xed vocabulary and feed these embeddings into a feedforward neural network 所以作者是先用word2vec方法对video和search token做了embedding之后再作为输入的，这也是做embedding的“基本操作”，不用过多介绍；当然，除此之外另一种大家应该也比较熟悉，就是通过加一个embedding层跟上面的DNN一起训练，两种方法孰优孰劣，有什么适用场合，大家可以讨论一下。 特征向量里面还包括了用户的地理位置的embedding，年龄，性别等。然后把所有这些特征concatenate起来，喂给上层的ReLU神经网络。 三层神经网络过后，我们看到了softmax函数。这里Youtube的同学们把这个问题看作为用户推荐next watch的问题，所以输出应该是一个在所有candidate video上的概率分布，自然是一个多分类问题。 好了，这一套深度学习的“基本操作”下来，就构成了Youtube的candidate generation网络，看似平淡无奇，其实还是隐藏着一些问题的，比如 架构图的左上角，为什么在online serving的时候不直接用这套网络进行预测而要使用nearest neighbor search 的方法？ 多分类问题中，Youtube的candidate video有百万之巨，意味着有几百万个分类，这必然会影响训练效果和速度，如何改进？ 这些问题在读第一遍的时候我也没有深想深看，但却是工程实现中必然会遇到的问题，我们随后再深入介绍论文中的解决方法。 既然得到了几百个候选集合，下一步就是利用ranking模型进行精排序，下面是ranking深度学习网络的架构图。 Youtube Ranking Model 乍一看上面的ranking model似乎与candidate generation模型没有什么区别，模型架构还是深度学习的“基本操作”，唯一的区别就是特征工程，那么我们就讲讲特征工程。 事实上原文也明确说明了，引入另一套DNN作为ranking model的目的就是引入更多描述视频、用户以及二者之间关系的特征，达到对候选视频集合准确排序的目的。 During ranking, we have access to many more features describing the video and the user&#39;s relationship to the video because only a few hundred videos are being scored rather than the millions scored in candidate generation. 具体一点，从左至右的特征依次是 impression video ID embedding: 当前要计算的video的embedding watched video IDs average embedding: 用户观看过的最后N个视频embedding的average pooling language embedding: 用户语言的embedding和当前视频语言的embedding time since last watch: 自上次观看同channel视频的时间 #previous impressions: 该视频已经被曝光给该用户的次数 上面五个特征中，我想重点谈谈第4个和第5个。因为这两个很好的引入了对用户行为的观察。 第4个特征背后的思想是 We observe that the most important signals are those that describe a user&#39;s previous interaction with the item itself and other similar items. 有一些引入attention的意思，这里是用了time since last watch这个特征来反应用户看同类视频的间隔时间。从用户的角度想一想，假如我们刚看过“DOTA经典回顾”这个channel的视频，我们很大概率是会继续看这个channel的视频的，那么该特征就很好的捕捉到了这一用户行为。 第5个特征#previous impressions则一定程度上引入了exploration的思想，避免同一个视频持续对同一用户进行无效曝光。尽量增加用户没看过的新视频的曝光可能性。 至此，我的第一遍论文阅读就结束了，对Youtube的算法框架有了概念，但总觉得不过如此，没什么太多新颖的地方。。 但如果真这么想，还是太naive了，与上一篇阿里的深度兴趣网络DIN不同的是，你读懂了DIN的attention机制，你就抓住了其论文70%的价值，但这篇文章，如果你只读懂了Youtube的推荐系统架构，你只抓住了30%的价值。那么剩下的70%的价值在哪里呢？ 02 第二次阅读的收获 在重读这篇文章的时候，我从一个工程师的角度，始终绷着“如何实现”这根弦，发现这篇论文的工程价值之前被我大大忽略了。下面我列出十个文中解决的非常有价值的问题： 文中把推荐问题转换成多分类问题，在next watch的场景下，每一个备选video都会是一个分类，因此总共的分类有数百万之巨，这在使用softmax训练时无疑是低效的，这个问题Youtube是如何解决的？ 在candidate generation model的serving过程中，Youtube为什么不直接采用训练时的model进行预测，而是采用了一种最近邻搜索的方法？ Youtube的用户对新视频有偏好，那么在模型构建的过程中如何引入这个feature？ 在对训练集的预处理过程中，Youtube没有采用原始的用户日志，而是对每个用户提取等数量的训练样本，这是为什么？ Youtube为什么不采取类似RNN的Sequence model，而是完全摒弃了用户观看历史的时序特征，把用户最近的浏览历史等同看待，这不会损失有效信息吗？ 在处理测试集的时候，Youtube为什么不采用经典的随机留一法（random holdout），而是一定要把用户最近的一次观看行为作为测试集？ 在确定优化目标的时候，Youtube为什么不采用经典的CTR，或者播放率（Play Rate），而是采用了每次曝光预期播放时间（expected watch time per impression）作为优化目标？ 在进行video embedding的时候，为什么要直接把大量长尾的video直接用0向量代替？ 针对某些特征，比如#previous impressions，为什么要进行开方和平方处理后，当作三个特征输入模型？ 为什么ranking model不采用经典的logistic regression当作输出层，而是采用了weighted logistic regression？ 因为我也是在视频推荐领域工作，所以可以很负责任的说以上的十个问题都是非常有价值的。但今天一口气写到这里，感觉有点气力不足了。。大家如果感兴趣的话可以点个赞，我明天再详细分析一下以上十大问题的答案。 上面问题的解答已经完成啦，大家请参考我的下一篇文章。 好了，这里是王喆的机器学习笔记的第二篇文章，水平有限，欢迎大家吐槽，批评，纠错。 03 参考资料 1. Deep Neural Networks for YouTube Recommendation (https://github.com/wzhe06/Reco-papers/blob/master/Recommendation/Deep%20Neural%20Networks%20for%20YouTube%20Recommendations.pdf) 2. Recommender System Paper List (https://github.com/wzhe06/Reco-papers) 3. 推荐系统中的注意力机制——阿里深度兴趣网络（DIN） (https://zhuanlan.zhihu.com/p/51623339) &nbsp; END 往期回顾之作者王喆 【1】《为什么说算法工程师的面试是一门玄学？》‍ 【2】《从零开始学习自然语言处理（NLP）》 【3】《万物皆Embedding，从经典的word2vec到深度学习》 【4】《干货|一看就懂的卷积神经网络》 【5】《GAN-提升GAN训练的技巧汇总》 【6】《学会用Docker部署深度学习环境》 机器学习算法工程师 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一个用心的公众号 长按，识别，加关注 进群，学习，得帮助 你的关注，我们的热度， 我们一定给你学习最大的帮助 你点的每个赞，我都认真当成了喜欢" />
<link rel="canonical" href="https://mlh.app/2019/01/25/6ac3a6e9a646498170beebe2cfc1d589.html" />
<meta property="og:url" content="https://mlh.app/2019/01/25/6ac3a6e9a646498170beebe2cfc1d589.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-25T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"&nbsp;&nbsp;&nbsp;&nbsp; 作者：王喆&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 编辑：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 前 &nbsp;言 这里是王喆的机器学习笔记，每隔一到两周我会站在算法工程师的角度讲解一些计算广告、推荐系统相关的文章。选择文章必须满足一下三个条件： 一是工程导向的； 二是阿里、facebook、google等一线互联网公司出品的； 三是前沿或者经典的。 这周我们一起讨论一下Youtube的深度推荐系统论文《Deep Neural Networks for YouTube Recommendations》，这是2016年的论文，按照今天的标准来看，已经没有什么新颖的地方，我也是两年前读过这篇文章之后就放下了，但前几天重读这篇文章，竟让发现了诸多亮点，几乎处处是套路，处处是经验，不由惊为神文。这篇神文给我留下的深刻印象有两点： 这毫无疑问是工业界论文的典范，是我非常推崇的工程导向的，算法工程师必读的文章； 我以为毫不起眼的地方，也藏着Youtube工程师宝贵的工程经验，相比上周介绍的阿里的深度兴趣网络DIN，最重要的价值就在于Attention机制，这篇文章你应该精确到句子来体会，这是我惊为神文的原因。 废话不多说，下面就跟大家分享一下两次拜读这篇论文的不同体验和收获。 01 第一次阅读的收获 第一遍读这篇论文的时候，我想所有人都是冲着算法的架构去的，在深度学习推荐系统已经成为各大公司“基本操作”的今天，Youtube在算法架构上并无惊奇之处，我们来快速介绍一下文章中的深度学习推荐系统的算法架构。 Youtube的用户推荐场景自不必多说，作为全球最大的UGC的视频网站，需要在百万量级的视频规模下进行个性化推荐。由于候选视频集合过大，考虑online系统延迟问题，不宜用复杂网络直接进行推荐，所以Youtube采取了两层深度网络完成整个推荐过程： 第一层是Candidate Generation Model完成候选视频的快速筛选，这一步候选视频集合由百万降低到了百的量级。 第二层是用Ranking Model完成几百个候选视频的精排 首先介绍candidate generation模型的架构 Youtube Candidate Generation Model 我们自底而上看这个网络，最底层的输入是用户观看过的video的embedding向量，以及搜索词的embedding向量。至于这个embedding向量是怎么生成的，作者的原话是这样的 Inspired by continuous bag of words language models, we learn high dimensional embeddings for each video in a xed vocabulary and feed these embeddings into a feedforward neural network 所以作者是先用word2vec方法对video和search token做了embedding之后再作为输入的，这也是做embedding的“基本操作”，不用过多介绍；当然，除此之外另一种大家应该也比较熟悉，就是通过加一个embedding层跟上面的DNN一起训练，两种方法孰优孰劣，有什么适用场合，大家可以讨论一下。 特征向量里面还包括了用户的地理位置的embedding，年龄，性别等。然后把所有这些特征concatenate起来，喂给上层的ReLU神经网络。 三层神经网络过后，我们看到了softmax函数。这里Youtube的同学们把这个问题看作为用户推荐next watch的问题，所以输出应该是一个在所有candidate video上的概率分布，自然是一个多分类问题。 好了，这一套深度学习的“基本操作”下来，就构成了Youtube的candidate generation网络，看似平淡无奇，其实还是隐藏着一些问题的，比如 架构图的左上角，为什么在online serving的时候不直接用这套网络进行预测而要使用nearest neighbor search 的方法？ 多分类问题中，Youtube的candidate video有百万之巨，意味着有几百万个分类，这必然会影响训练效果和速度，如何改进？ 这些问题在读第一遍的时候我也没有深想深看，但却是工程实现中必然会遇到的问题，我们随后再深入介绍论文中的解决方法。 既然得到了几百个候选集合，下一步就是利用ranking模型进行精排序，下面是ranking深度学习网络的架构图。 Youtube Ranking Model 乍一看上面的ranking model似乎与candidate generation模型没有什么区别，模型架构还是深度学习的“基本操作”，唯一的区别就是特征工程，那么我们就讲讲特征工程。 事实上原文也明确说明了，引入另一套DNN作为ranking model的目的就是引入更多描述视频、用户以及二者之间关系的特征，达到对候选视频集合准确排序的目的。 During ranking, we have access to many more features describing the video and the user&#39;s relationship to the video because only a few hundred videos are being scored rather than the millions scored in candidate generation. 具体一点，从左至右的特征依次是 impression video ID embedding: 当前要计算的video的embedding watched video IDs average embedding: 用户观看过的最后N个视频embedding的average pooling language embedding: 用户语言的embedding和当前视频语言的embedding time since last watch: 自上次观看同channel视频的时间 #previous impressions: 该视频已经被曝光给该用户的次数 上面五个特征中，我想重点谈谈第4个和第5个。因为这两个很好的引入了对用户行为的观察。 第4个特征背后的思想是 We observe that the most important signals are those that describe a user&#39;s previous interaction with the item itself and other similar items. 有一些引入attention的意思，这里是用了time since last watch这个特征来反应用户看同类视频的间隔时间。从用户的角度想一想，假如我们刚看过“DOTA经典回顾”这个channel的视频，我们很大概率是会继续看这个channel的视频的，那么该特征就很好的捕捉到了这一用户行为。 第5个特征#previous impressions则一定程度上引入了exploration的思想，避免同一个视频持续对同一用户进行无效曝光。尽量增加用户没看过的新视频的曝光可能性。 至此，我的第一遍论文阅读就结束了，对Youtube的算法框架有了概念，但总觉得不过如此，没什么太多新颖的地方。。 但如果真这么想，还是太naive了，与上一篇阿里的深度兴趣网络DIN不同的是，你读懂了DIN的attention机制，你就抓住了其论文70%的价值，但这篇文章，如果你只读懂了Youtube的推荐系统架构，你只抓住了30%的价值。那么剩下的70%的价值在哪里呢？ 02 第二次阅读的收获 在重读这篇文章的时候，我从一个工程师的角度，始终绷着“如何实现”这根弦，发现这篇论文的工程价值之前被我大大忽略了。下面我列出十个文中解决的非常有价值的问题： 文中把推荐问题转换成多分类问题，在next watch的场景下，每一个备选video都会是一个分类，因此总共的分类有数百万之巨，这在使用softmax训练时无疑是低效的，这个问题Youtube是如何解决的？ 在candidate generation model的serving过程中，Youtube为什么不直接采用训练时的model进行预测，而是采用了一种最近邻搜索的方法？ Youtube的用户对新视频有偏好，那么在模型构建的过程中如何引入这个feature？ 在对训练集的预处理过程中，Youtube没有采用原始的用户日志，而是对每个用户提取等数量的训练样本，这是为什么？ Youtube为什么不采取类似RNN的Sequence model，而是完全摒弃了用户观看历史的时序特征，把用户最近的浏览历史等同看待，这不会损失有效信息吗？ 在处理测试集的时候，Youtube为什么不采用经典的随机留一法（random holdout），而是一定要把用户最近的一次观看行为作为测试集？ 在确定优化目标的时候，Youtube为什么不采用经典的CTR，或者播放率（Play Rate），而是采用了每次曝光预期播放时间（expected watch time per impression）作为优化目标？ 在进行video embedding的时候，为什么要直接把大量长尾的video直接用0向量代替？ 针对某些特征，比如#previous impressions，为什么要进行开方和平方处理后，当作三个特征输入模型？ 为什么ranking model不采用经典的logistic regression当作输出层，而是采用了weighted logistic regression？ 因为我也是在视频推荐领域工作，所以可以很负责任的说以上的十个问题都是非常有价值的。但今天一口气写到这里，感觉有点气力不足了。。大家如果感兴趣的话可以点个赞，我明天再详细分析一下以上十大问题的答案。 上面问题的解答已经完成啦，大家请参考我的下一篇文章。 好了，这里是王喆的机器学习笔记的第二篇文章，水平有限，欢迎大家吐槽，批评，纠错。 03 参考资料 1. Deep Neural Networks for YouTube Recommendation (https://github.com/wzhe06/Reco-papers/blob/master/Recommendation/Deep%20Neural%20Networks%20for%20YouTube%20Recommendations.pdf) 2. Recommender System Paper List (https://github.com/wzhe06/Reco-papers) 3. 推荐系统中的注意力机制——阿里深度兴趣网络（DIN） (https://zhuanlan.zhihu.com/p/51623339) &nbsp; END 往期回顾之作者王喆 【1】《为什么说算法工程师的面试是一门玄学？》‍ 【2】《从零开始学习自然语言处理（NLP）》 【3】《万物皆Embedding，从经典的word2vec到深度学习》 【4】《干货|一看就懂的卷积神经网络》 【5】《GAN-提升GAN训练的技巧汇总》 【6】《学会用Docker部署深度学习环境》 机器学习算法工程师 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一个用心的公众号 长按，识别，加关注 进群，学习，得帮助 你的关注，我们的热度， 我们一定给你学习最大的帮助 你点的每个赞，我都认真当成了喜欢","@type":"BlogPosting","url":"https://mlh.app/2019/01/25/6ac3a6e9a646498170beebe2cfc1d589.html","headline":"重读Youtube深度学习推荐系统论文，字字珠玑，惊为神文","dateModified":"2019-01-25T00:00:00+08:00","datePublished":"2019-01-25T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/01/25/6ac3a6e9a646498170beebe2cfc1d589.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>重读Youtube深度学习推荐系统论文，字字珠玑，惊为神文</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="rich_media_content" id="js_content"> 
   <p style="color:rgb(108,105,105);font-size:14px;text-align:left;"><img style="color:rgb(108,105,105);font-size:14px;text-align:left;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/LiaGhAsRNttuXh4oBW56OVg6Wia5gGODPwpcpqq6v5Tia4cyVibRoAbW2gvojzicpWibnOG99Diaic8bX7Mvsor9S6BiaLA/640?wx_fmt=gif" alt="640?wx_fmt=gif"><span style="color:rgb(108,105,105);font-size:14px;text-align:left;">&nbsp;&nbsp;</span>&nbsp;&nbsp;</p>
   <p style="color:rgb(108,105,105);font-size:14px;text-align:right;">作者：王喆&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<br></p>
   <p style="color:rgb(108,105,105);font-size:14px;text-align:right;"><span style="color:rgb(89,89,89);">编辑：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<br></span></p>
   <p><span style="color:rgb(89,89,89);"><br></span></p>
   <p><strong class="135brush">前 &nbsp;言</strong></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">这里是</span><strong><span style="font-size:16px;">王喆的机器学习笔记</span></strong><span style="font-size:16px;">，每隔一到两周我会站在算法工程师的角度讲解一些计算广告、推荐系统相关的文章。选择文章必须满足一下三个条件：</span></p>
   <ul class="list-paddingleft-2">
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">一是工程导向的；</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">二是阿里、facebook、google等一线互联网公司出品的；</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">三是前沿或者经典的。</span></p></li>
   </ul>
   <p style="line-height:1.5em;"><span style="font-size:16px;">这周我们一起讨论一下Youtube的深度推荐系统论文《</span><span style="font-size:16px;">Deep Neural Networks for YouTube Recommendations</span><span style="font-size:16px;">》，这是2016年的论文，按照今天的标准来看，已经没有什么新颖的地方，我也是两年前读过这篇文章之后就放下了，但前几天重读这篇文章，竟让发现了诸多亮点，几乎处处是套路，处处是经验，不由惊为神文。这篇神文给我留下的深刻印象有两点：</span></p>
   <ol class="list-paddingleft-2">
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">这毫无疑问是工业界论文的典范，是我非常推崇的工程导向的，算法工程师必读的文章；</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">我以为毫不起眼的地方，也藏着Youtube工程师宝贵的工程经验，相比上周介绍的</span><span style="font-size:16px;">阿里的深度兴趣网络DIN</span><span style="font-size:16px;">，最重要的价值就在于Attention机制，这篇文章你应该精确到句子来体会，这是我惊为神文的原因。</span></p></li>
   </ol>
   <p class="ztext-empty-paragraph"><br></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">废话不多说，下面就跟大家分享一下两次拜读这篇论文的不同体验和收获。</span></p>
   <p><br></p>
   <p><br></p>
   <p style="min-height:1em;"><strong>01</strong></p>
   <h1 style="letter-spacing:1.5px;line-height:1.75em;text-align:center;"><span style="color:rgb(0,122,170);"><strong><span style="font-size:15px;">第一次阅读的收获</span></strong></span></h1>
   <p style="line-height:1.5em;"><span style="font-size:15px;color:rgb(68,68,68);"></span><span style="font-size:16px;">第一遍读这篇论文的时候，我想所有人都是冲着算法的架构去的，在深度学习推荐系统已经成为各大公司“基本操作”的今天，Youtube在算法架构上并无惊奇之处，我们来快速介绍一下文章中的深度学习推荐系统的算法架构。</span></p>
   <p style="text-align:center;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/iaTa8ut6HiawDtoSj1pFiaQuMHX8g3efrM2xITbZjBmKyEyOb3A1ibTXHmMV50XEia7bAjclkkUkhX7sD8BkxYI2QLQ/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">Youtube的用户推荐场景自不必多说，作为全球最大的UGC的视频网站，需要在百万量级的视频规模下进行个性化推荐。由于候选视频集合过大，考虑online系统延迟问题，不宜用复杂网络直接进行推荐，所以Youtube采取了两层深度网络完成整个推荐过程：</span></p>
   <ol class="list-paddingleft-2">
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">第一层是Candidate Generation Model完成候选视频的快速筛选，这一步候选视频集合由百万降低到了百的量级。</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">第二层是用Ranking Model完成几百个候选视频的精排</span></p></li>
   </ol>
   <p style="line-height:1.5em;"><span style="font-size:16px;">首先介绍candidate generation模型的架构</span></p>
   <p style="line-height:1.5em;text-align:center;"><span style="font-size:16px;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/iaTa8ut6HiawDtoSj1pFiaQuMHX8g3efrM2Qmy2y7voZOTf2lH7LeajYOUVXPB3jbMVkln0mCLvNQm1icpedicQLqqA/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></span></p>
   <p style="text-align:center;"><span style="font-size:12px;">Youtube Candidate Generation Model</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">我们自底而上看这个网络，最底层的输入是用户观看过的video的embedding向量，以及搜索词的embedding向量。至于这个embedding向量是怎么生成的，作者的原话是这样的</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">Inspired by continuous bag of words language models, we learn high dimensional embeddings for each video in a xed vocabulary and feed these embeddings into a feedforward neural network</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;"><br></span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">所以作者是先用word2vec方法对video和search token做了embedding之后再作为输入的，这也是做embedding的“基本操作”，不用过多介绍；当然，除此之外另一种大家应该也比较熟悉，就是通过加一个embedding层跟上面的DNN一起训练，两种方法孰优孰劣，有什么适用场合，大家可以讨论一下。</span></p>
   <p class="ztext-empty-paragraph"><br></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">特征向量里面还包括了用户的地理位置的embedding，年龄，性别等。然后把所有这些特征concatenate起来，喂给上层的ReLU神经网络。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">三层神经网络过后，我们看到了softmax函数。这里Youtube的同学们把这个问题看作为用户推荐next watch的问题，所以输出应该是一个在所有candidate video上的概率分布，自然是一个多分类问题。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">好了，这一套深度学习的“基本操作”下来，就构成了Youtube的candidate generation网络，看似平淡无奇，其实还是隐藏着一些问题的，比如</span></p>
   <ol class="list-paddingleft-2">
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">架构图的左上角，为什么在online serving的时候不直接用这套网络进行预测而要使用nearest neighbor search 的方法？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">多分类问题中，Youtube的candidate video有百万之巨，意味着有几百万个分类，这必然会影响训练效果和速度，如何改进？</span></p></li>
   </ol>
   <p style="line-height:1.5em;"><span style="font-size:16px;">这些问题在读第一遍的时候我也没有深想深看，但却是工程实现中必然会遇到的问题，我们随后再深入介绍论文中的解决方法。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">既然得到了几百个候选集合，下一步就是利用ranking模型进行精排序，下面是ranking深度学习网络的架构图。</span></p>
   <figure>
    <img class="origin_image zh-lightbox-thumb lazy" style="margin-left:auto;" width="1134" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/iaTa8ut6HiawDtoSj1pFiaQuMHX8g3efrM2QbKvtTdrefnBuLduVurenia4ojdmMtW2Yask6528soxSBM87M2NSdibw/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg">
    <p style="text-align:center;"><span style="font-size:12px;">Youtube Ranking Model</span></p>
   </figure>
   <p style="line-height:1.5em;"><span style="font-size:16px;">乍一看上面的ranking model似乎与candidate generation模型没有什么区别，模型架构还是深度学习的“基本操作”，唯一的区别就是特征工程，那么我们就讲讲特征工程。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">事实上原文也明确说明了，引入另一套DNN作为ranking model的目的就是引入更多描述视频、用户以及二者之间关系的特征，达到对候选视频集合准确排序的目的。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">During ranking, we have access to many more features describing the video and the user's relationship to the video because only a few hundred videos are being scored rather than the millions scored in candidate generation.</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">具体一点，从左至右的特征依次是</span></p>
   <ol class="list-paddingleft-2">
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">impression video ID embedding: 当前要计算的video的embedding</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">watched video IDs average embedding: 用户观看过的最后N个视频embedding的average pooling</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">language embedding: 用户语言的embedding和当前视频语言的embedding</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">time since last watch: 自上次观看同channel视频的时间</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">#previous impressions: 该视频已经被曝光给该用户的次数</span></p></li>
   </ol>
   <p style="line-height:1.5em;"><span style="font-size:16px;">上面五个特征中，我想重点谈谈第4个和第5个。因为这两个很好的引入了对用户行为的观察。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">第4个特征背后的思想是</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">We observe that the most important signals are those that describe a user's previous interaction with the item itself and other similar items.</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">有一些引入attention的意思，这里是用了time since last watch这个特征来反应用户看同类视频的间隔时间。从用户的角度想一想，假如我们刚看过“DOTA经典回顾”这个channel的视频，我们很大概率是会继续看这个channel的视频的，那么该特征就很好的捕捉到了这一用户行为。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">第5个特征#previous impressions则一定程度上引入了exploration的思想，避免同一个视频持续对同一用户进行无效曝光。尽量增加用户没看过的新视频的曝光可能性。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">至此，我的第一遍论文阅读就结束了，对Youtube的算法框架有了概念，但总觉得不过如此，没什么太多新颖的地方。。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;"><br></span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">但如果真这么想，还是太naive了，与上一篇</span><span style="font-size:16px;">阿里的深度兴趣网络DIN</span><span style="font-size:16px;">不同的是，你读懂了DIN的attention机制，你就抓住了其论文70%的价值，但这篇文章，如果你只读懂了Youtube的推荐系统架构，你只抓住了30%的价值。那么剩下的70%的价值在哪里呢？</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;"><br></span></p>
   <p style="min-height:1em;"><strong>02</strong></p>
   <h1 style="letter-spacing:1.5px;line-height:1.75em;text-align:center;"><span style="color:rgb(0,122,170);"><strong><span style="font-size:15px;">第二次阅读的收获</span></strong></span></h1>
   <p style="line-height:1.5em;"><span style="font-size:16px;">在重读这篇文章的时候，我从一个工程师的角度，始终绷着“如何实现”这根弦，发现这篇论文的工程价值之前被我大大忽略了。下面我列出十个文中解决的非常有价值的问题：</span></p>
   <ol class="list-paddingleft-2">
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">文中把推荐问题转换成多分类问题，在next watch的场景下，每一个备选video都会是一个分类，因此总共的分类有数百万之巨，这在使用softmax训练时无疑是低效的，这个问题Youtube是如何解决的？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">在candidate generation model的serving过程中，Youtube为什么不直接采用训练时的model进行预测，而是采用了一种最近邻搜索的方法？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">Youtube的用户对新视频有偏好，那么在模型构建的过程中如何引入这个feature？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">在对训练集的预处理过程中，Youtube没有采用原始的用户日志，而是对每个用户提取等数量的训练样本，这是为什么？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">Youtube为什么不采取类似RNN的Sequence model，而是完全摒弃了用户观看历史的时序特征，把用户最近的浏览历史等同看待，这不会损失有效信息吗？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">在处理测试集的时候，Youtube为什么不采用经典的随机留一法（random holdout），而是一定要把用户最近的一次观看行为作为测试集？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">在确定优化目标的时候，Youtube为什么不采用经典的CTR，或者播放率（Play Rate），而是采用了每次曝光预期播放时间（expected watch time per impression）作为优化目标？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">在进行video embedding的时候，为什么要直接把大量长尾的video直接用0向量代替？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">针对某些特征，比如#previous impressions，为什么要进行开方和平方处理后，当作三个特征输入模型？</span></p></li>
    <li><p style="line-height:1.5em;"><span style="font-size:16px;">为什么ranking model不采用经典的logistic regression当作输出层，而是采用了weighted logistic regression？</span></p></li>
   </ol>
   <p class="ztext-empty-paragraph"><br></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">因为我也是在视频推荐领域工作，所以可以很负责任的说以上的十个问题都是非常有价值的。但今天一口气写到这里，感觉有点气力不足了。。大家如果感兴趣的话可以点个赞，我明天再详细分析一下以上十大问题的答案。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">上面问题的解答已经完成啦，大家请参考我的下一篇文章。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;"><br></span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">好了，这里是</span><span style="font-size:16px;">王喆的机器学习笔记</span><span style="font-size:16px;">的第二篇文章，水平有限，欢迎大家吐槽，批评，纠错。</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;"><br></span></p>
   <p style="min-height:1em;"><strong>03</strong></p>
   <h1 style="letter-spacing:1.5px;line-height:1.75em;text-align:center;"><span style="color:rgb(0,122,170);"><strong><span style="font-size:15px;">参考资料</span></strong></span></h1>
   <p style="line-height:1.5em;"><span style="font-size:16px;">1. Deep Neural Networks for YouTube Recommendation</span></p>
   <p style="line-height:1.5em;"><span style="font-size:14px;">(</span><span style="font-size:14px;color:rgb(61,170,214);">https://github.com/wzhe06/Reco-papers/blob/master/Recommendation/Deep%20Neural%20Networks%20for%20YouTube%20Recommendations.pdf</span><span style="font-size:14px;">)</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;"><br></span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">2. Recommender System Paper List</span><br></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">(</span><span style="font-size:16px;color:rgb(61,170,214);">https://github.com/wzhe06/Reco-papers</span><span style="font-size:16px;">)</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;"><br></span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">3. 推荐系统中的注意力机制——阿里深度兴趣网络（DIN）</span></p>
   <p style="line-height:1.5em;"><span style="font-size:16px;">(</span><span style="font-size:16px;color:rgb(61,170,214);">https://zhuanlan.zhihu.com/p/51623339</span><span style="font-size:16px;">)</span></p>
   <p style="min-height:1em;text-align:center;"><strong style="line-height:28px;"><span style="line-height:1.75em;font-size:15px;color:rgb(171,25,66);"><strong style="color:rgb(62,62,62);font-size:16px;line-height:28px;"><span style="line-height:1.75em;color:rgb(63,63,63);font-size:14px;letter-spacing:0px;text-align:justify;"></span></strong></span></strong></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <p style="min-height:1em;text-align:center;"><strong style="line-height:28px;"><span style="line-height:1.75em;font-size:15px;color:rgb(171,25,66);"><strong style="color:rgb(62,62,62);font-size:16px;line-height:28px;"><span style="line-height:1.75em;color:rgb(63,63,63);font-size:14px;letter-spacing:0px;text-align:justify;">&nbsp;</span></strong><span style="color:rgb(63,63,63);font-size:14px;letter-spacing:0px;text-align:justify;"><strong style="text-align:center;color:rgb(62,62,62);font-size:16px;line-height:28px;"><span style="line-height:1.75em;font-size:15px;color:rgb(171,25,66);"><img class="__bg_gif" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/TCHicQEF6XKANicUCsKbWsXv1yJgVCSSRGucMYaHPrsrDRFNbNUVibEic1qJC34XVssCm5k1NiaPULLZZOvuIWHn5eg/640?wx_fmt=gif" alt="640?wx_fmt=gif"></span></strong></span></span></strong></p>
   <p style="text-align:center;"><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong>END</strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p style="min-height:1em;">往期回顾之作者王喆</p>
   <p style="min-height:1em;">【1】《<a href="http://mp.weixin.qq.com/s?__biz=MzUyMjE2MTE0Mw==&amp;mid=2247487346&amp;idx=1&amp;sn=8e5f958d5af9b02aca3f57988961751e&amp;chksm=f9d151eacea6d8fcb68e86c2d738ad7a59a2c7091791380061aa0fdedac9083b5f3372ee2a1e&amp;scene=21#wechat_redirect" rel="nofollow" style="font-size:14px;letter-spacing:1.5px;">为什么说算法工程师的面试是一门玄学？</a>》<span style="line-height:0px;">‍</span></p>
   <p style="min-height:1em;">【2】<a href="http://mp.weixin.qq.com/s?__biz=MzUyMjE2MTE0Mw==&amp;mid=2247487336&amp;idx=1&amp;sn=199e6a3be565fd81bda7a4bf29e873d4&amp;chksm=f9d151f0cea6d8e639ecec9413386cd2ecc25fb771a2a9ebc3a216712838fd2828b03933c909&amp;scene=21#wechat_redirect" rel="nofollow">《从零开始学习自然语言处理（NLP）》</a></p>
   <p style="min-height:1em;text-align:left;">【3】<a href="http://mp.weixin.qq.com/s?__biz=MzUyMjE2MTE0Mw==&amp;mid=2247487329&amp;idx=1&amp;sn=93d559017e3f3637547d7600a3c82df3&amp;chksm=f9d151f9cea6d8efa28cfa92aa25560d6989993de36452a4c12b8108b5f63d5351c7de299f24&amp;scene=21#wechat_redirect" rel="nofollow">《万物皆Embedding，从经典的word2vec到深度学习》</a></p>
   <p style="min-height:1em;">【4】<a href="http://mp.weixin.qq.com/s?__biz=MzUyMjE2MTE0Mw==&amp;mid=2247487327&amp;idx=2&amp;sn=62f75fd674cf7301ef2dced0375b93d2&amp;chksm=f9d151c7cea6d8d12d45fe67c48e1651ec450d59ee43fa0dc4a8bc033b6a2845d186d084f6e6&amp;scene=21#wechat_redirect" rel="nofollow">《干货|一看就懂的卷积神经网络》</a></p>
   <p style="min-height:1em;">【5】<a href="http://mp.weixin.qq.com/s?__biz=MzUyMjE2MTE0Mw==&amp;mid=2247487298&amp;idx=1&amp;sn=15ee936369ec1ea329fda7ebd0aaa7de&amp;chksm=f9d151dacea6d8cc80ec3f1de7b4de9da5c801dcdc9abad577032e83213798447a9aea007361&amp;scene=21#wechat_redirect" rel="nofollow">《GAN-提升GAN训练的技巧汇总》</a></p>
   <p style="min-height:1em;">【6】<a href="http://mp.weixin.qq.com/s?__biz=MzUyMjE2MTE0Mw==&amp;mid=2247487229&amp;idx=2&amp;sn=871f10e7aa2c5bada9e88085b1ebda46&amp;chksm=f9d15065cea6d97388194c580576120b86330835d79b80ab429a9a441b4b7bb6cfc61684e9ba&amp;scene=21#wechat_redirect" rel="nofollow">《学会用Docker部署深度学习环境》</a></p>
   <p style="min-height:1em;"><a href="http://mp.weixin.qq.com/s?__biz=MzUyMjE2MTE0Mw==&amp;mid=2247485704&amp;idx=2&amp;sn=d5ee7dd6fa240c1c1d7226104a3a404d&amp;chksm=f9d15790cea6de86c3d24b448ad1840ed1bdee25adcfa0434e1f72589c62279df55f6a8598a7&amp;scene=21#wechat_redirect" rel="nofollow"></a></p>
   <p style="min-height:1em;"><br></p>
   <br>
   <br>
   <p style="min-height:1em;text-align:center;"><strong style="line-height:28px;"><span style="line-height:1.75em;color:rgb(63,63,63);font-size:14px;letter-spacing:0px;text-align:justify;"><strong style="text-align:center;color:rgb(62,62,62);font-size:16px;line-height:28px;"><span style="line-height:1.75em;font-size:15px;color:rgb(171,25,66);"></span></strong></span></strong><br></p>
   <br>
   <p><br></p>
   <p><br></p>
   <p><br></p>
   <p><br></p>
   <p style="min-height:1em;"><span style="color:rgb(3,3,3);font-size:20px;"><strong>机器学习算法工程师</strong></span></p>
   <hr style="border-color:rgb(33,33,34);">
   <p style="min-height:1em;">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一个用心的公众号</p>
   <p style="text-align:center;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/iaTa8ut6HiawDdZMYspr4Sg6JgNEHRRRaZ7Bjjv4zo9GabzO4PkUILEGkyC7odlWMVEl6rsbfkr9PduYMbnQFZEA/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></p>
   <span style="color:rgb(12,12,12);">长按，识别，加关注<br></span>
   <p style="min-height:1em;"><span style="color:rgb(12,12,12);">进群，学习，得帮助</span></p>
   <p style="min-height:1em;"><span style="color:rgb(12,12,12);"></span>你的关注，我们的热度，</p>
   <p style="min-height:1em;">我们一定给你学习最大的帮助</p>
   <p style="clear:none;min-height:1em;"><br></p>
   <p><br></p>
   <p><br></p>
   <img style="width:20px;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDGYbtuibKFBo6VnucFVutzfOoMhtaKlbLRiaKvAz4APHHLxHoficEoG2oP0Cib6QLXibw9gshAibp1kVAA/640?wx_fmt=png" alt="640?wx_fmt=png">你点的每个赞，我都认真当成了喜欢
   <p><br></p> 
  </div> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
