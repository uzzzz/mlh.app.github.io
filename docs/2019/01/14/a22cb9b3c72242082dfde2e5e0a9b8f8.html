<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>中文自然语言处理——商品评论情感判别 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="中文自然语言处理——商品评论情感判别" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明： https://blog.csdn.net/asialee_bird/article/details/86483835 1、数据集下载 商品（书籍、酒店、计算机、牛奶、手机、热水器）等评论数据 from sklearn.model_selection import train_test_split from gensim.models.word2vec import Word2Vec import numpy as np import pandas as pd import jieba from sklearn.externals import joblib from sklearn.svm import SVC 2、载入数据，做预处理（分词），切分训练集与测试集 #载入数据，做预处理（分词），切分训练集与测试集 def load_file_and_preprocessing(): neg=pd.read_excel(&#39;chinese_data/neg.xls&#39;,header=None,index=None) pos=pd.read_excel(&#39;chinese_data/pos.xls&#39;,header=None,index=None) cw=lambda x:list(jieba.cut(x)) pos[&#39;words&#39;]=pos[0].apply(cw) neg[&#39;words&#39;]=neg[0].apply(cw) # use 1 for positive sentiment,0 for negative y=np.concatenate((np.ones(len(pos)),np.zeros(len(neg)))) #训练集：测试集=8:2 x_train,x_test,y_train,y_test=train_test_split(np.concatenate((pos[&#39;words&#39;],neg[&#39;words&#39;])),y,test_size=0.2) #NumPy提供了多种文件操作函数方便存取数组内容（npy格式以二进制存储数据的） np.save(&#39;pre_data/y_train.npy&#39;,y_train) np.save(&#39;pre_data/y_test.npy&#39;,y_test) return x_train,x_test 3、计算训练集和测试集每条评论数据的向量并存入文件 #对每个句子的所有词向量取均值，来生成一个句子的vector def build_sentence_vector(text,size,w2v_model): vec=np.zeros(size).reshape((1,size)) count=0 for word in text: try: vec+=w2v_model[word].reshape((1,size)) count+=1 except KeyError: continue if count!=0: vec/=count return vec #计算词向量 def get_train_vecs(x_train,x_test): n_dim=300 #词向量维度 #试用Word2Vec建立词向量模型 w2v_model=Word2Vec(size=n_dim,window=5,sg=0,hs=0,negative=5,min_count=10) w2v_model.build_vocab(x_train) #准备模型词汇表 #在评论训练集上建模 w2v_model.train(x_train,total_examples=w2v_model.corpus_count,epochs=w2v_model.iter) #训练词向量 #训练集评论向量集合 train_vecs=np.concatenate([build_sentence_vector(z,n_dim,w2v_model) for z in x_train]) np.save(&#39;pre_data/train_vecs.npy&#39;,train_vecs) #将训练集保存到文件中 print(train_vecs.shape) #输出训练集的维度 #在测试集上训练 w2v_model.train(x_test,total_examples=w2v_model.corpus_count,epochs=w2v_model.iter) w2v_model.save(&#39;pre_data/w2v_model/w2v_model.pkl&#39;) test_vecs=np.concatenate([build_sentence_vector(z,n_dim,w2v_model) for z in x_test]) np.save(&#39;pre_data/test_vecs.npy&#39;,test_vecs) print(test_vecs.shape) 4、获得训练集向量和标签，测试集向量和标签 #获得训练集向量和标签，测试集向量和标签 def get_data(): train_vecs=np.load(&#39;pre_data/train_vecs.npy&#39;) y_train=np.load(&#39;pre_data/y_train.npy&#39;) test_vecs=np.load(&#39;pre_data/test_vecs.npy&#39;) y_test=np.load(&#39;pre_data/y_test.npy&#39;) return train_vecs,y_train,test_vecs,y_test 5、训练SVM模型 #训练SVM模型 def svm_train(train_vecs,y_train,test_vecs,y_test): clf=SVC(kernel=&#39;rbf&#39;,verbose=True) clf.fit(train_vecs,y_train) #根据给定的训练数据拟合SVM模型 joblib.dump(clf,&#39;pre_data/svm_model/model.pkl&#39;) #保存训练好的SVM模型 print(clf.score(test_vecs,y_test)) #输出测试数据的平均准确度 6、构建待遇测句子的向量 #构建待遇测句子的向量 def get_predict_vecs(words): n_dim=300 w2v_model=Word2Vec.load(&#39;pre_data/w2v_model/w2v_model.pkl&#39;) train_vecs=build_sentence_vector(words,n_dim,w2v_model) return train_vecs 7、对单个句子进行情感判断 #对单个句子进行情感判断 def svm_predict(string): words=jieba.lcut(string) words_vecs=get_predict_vecs(words) clf=joblib.load(&#39;pre_data/svm_model/model.pkl&#39;) result=clf.predict(words_vecs) if int(result[0])==1: print(string,&#39;positive&#39;) else: print(string,&#39;negative&#39;) if __name__==&#39;__main__&#39;: #x_train, x_test=load_file_and_preprocessing() #get_train_vecs(x_train, x_test) #train_vecs, y_train, test_vecs, y_test=get_data() #svm_train(train_vecs, y_train, test_vecs, y_test) #对输入句子情感进行判断 string=&#39;电池充完了电连手机都打不开，简直烂的要命，真是金玉其外，败絮其中！连5号电池都不如&#39; #string=&#39;牛逼的手机，从3米高的地方摔下去都没坏，质量非常好&#39; #string=&#39;这款电脑感觉还行，能用，先试用一下，应该不错&#39; svm_predict(string) &nbsp; &nbsp; 中文自然语言处理流程 &nbsp; &nbsp; &nbsp; &nbsp;" />
<meta property="og:description" content="版权声明： https://blog.csdn.net/asialee_bird/article/details/86483835 1、数据集下载 商品（书籍、酒店、计算机、牛奶、手机、热水器）等评论数据 from sklearn.model_selection import train_test_split from gensim.models.word2vec import Word2Vec import numpy as np import pandas as pd import jieba from sklearn.externals import joblib from sklearn.svm import SVC 2、载入数据，做预处理（分词），切分训练集与测试集 #载入数据，做预处理（分词），切分训练集与测试集 def load_file_and_preprocessing(): neg=pd.read_excel(&#39;chinese_data/neg.xls&#39;,header=None,index=None) pos=pd.read_excel(&#39;chinese_data/pos.xls&#39;,header=None,index=None) cw=lambda x:list(jieba.cut(x)) pos[&#39;words&#39;]=pos[0].apply(cw) neg[&#39;words&#39;]=neg[0].apply(cw) # use 1 for positive sentiment,0 for negative y=np.concatenate((np.ones(len(pos)),np.zeros(len(neg)))) #训练集：测试集=8:2 x_train,x_test,y_train,y_test=train_test_split(np.concatenate((pos[&#39;words&#39;],neg[&#39;words&#39;])),y,test_size=0.2) #NumPy提供了多种文件操作函数方便存取数组内容（npy格式以二进制存储数据的） np.save(&#39;pre_data/y_train.npy&#39;,y_train) np.save(&#39;pre_data/y_test.npy&#39;,y_test) return x_train,x_test 3、计算训练集和测试集每条评论数据的向量并存入文件 #对每个句子的所有词向量取均值，来生成一个句子的vector def build_sentence_vector(text,size,w2v_model): vec=np.zeros(size).reshape((1,size)) count=0 for word in text: try: vec+=w2v_model[word].reshape((1,size)) count+=1 except KeyError: continue if count!=0: vec/=count return vec #计算词向量 def get_train_vecs(x_train,x_test): n_dim=300 #词向量维度 #试用Word2Vec建立词向量模型 w2v_model=Word2Vec(size=n_dim,window=5,sg=0,hs=0,negative=5,min_count=10) w2v_model.build_vocab(x_train) #准备模型词汇表 #在评论训练集上建模 w2v_model.train(x_train,total_examples=w2v_model.corpus_count,epochs=w2v_model.iter) #训练词向量 #训练集评论向量集合 train_vecs=np.concatenate([build_sentence_vector(z,n_dim,w2v_model) for z in x_train]) np.save(&#39;pre_data/train_vecs.npy&#39;,train_vecs) #将训练集保存到文件中 print(train_vecs.shape) #输出训练集的维度 #在测试集上训练 w2v_model.train(x_test,total_examples=w2v_model.corpus_count,epochs=w2v_model.iter) w2v_model.save(&#39;pre_data/w2v_model/w2v_model.pkl&#39;) test_vecs=np.concatenate([build_sentence_vector(z,n_dim,w2v_model) for z in x_test]) np.save(&#39;pre_data/test_vecs.npy&#39;,test_vecs) print(test_vecs.shape) 4、获得训练集向量和标签，测试集向量和标签 #获得训练集向量和标签，测试集向量和标签 def get_data(): train_vecs=np.load(&#39;pre_data/train_vecs.npy&#39;) y_train=np.load(&#39;pre_data/y_train.npy&#39;) test_vecs=np.load(&#39;pre_data/test_vecs.npy&#39;) y_test=np.load(&#39;pre_data/y_test.npy&#39;) return train_vecs,y_train,test_vecs,y_test 5、训练SVM模型 #训练SVM模型 def svm_train(train_vecs,y_train,test_vecs,y_test): clf=SVC(kernel=&#39;rbf&#39;,verbose=True) clf.fit(train_vecs,y_train) #根据给定的训练数据拟合SVM模型 joblib.dump(clf,&#39;pre_data/svm_model/model.pkl&#39;) #保存训练好的SVM模型 print(clf.score(test_vecs,y_test)) #输出测试数据的平均准确度 6、构建待遇测句子的向量 #构建待遇测句子的向量 def get_predict_vecs(words): n_dim=300 w2v_model=Word2Vec.load(&#39;pre_data/w2v_model/w2v_model.pkl&#39;) train_vecs=build_sentence_vector(words,n_dim,w2v_model) return train_vecs 7、对单个句子进行情感判断 #对单个句子进行情感判断 def svm_predict(string): words=jieba.lcut(string) words_vecs=get_predict_vecs(words) clf=joblib.load(&#39;pre_data/svm_model/model.pkl&#39;) result=clf.predict(words_vecs) if int(result[0])==1: print(string,&#39;positive&#39;) else: print(string,&#39;negative&#39;) if __name__==&#39;__main__&#39;: #x_train, x_test=load_file_and_preprocessing() #get_train_vecs(x_train, x_test) #train_vecs, y_train, test_vecs, y_test=get_data() #svm_train(train_vecs, y_train, test_vecs, y_test) #对输入句子情感进行判断 string=&#39;电池充完了电连手机都打不开，简直烂的要命，真是金玉其外，败絮其中！连5号电池都不如&#39; #string=&#39;牛逼的手机，从3米高的地方摔下去都没坏，质量非常好&#39; #string=&#39;这款电脑感觉还行，能用，先试用一下，应该不错&#39; svm_predict(string) &nbsp; &nbsp; 中文自然语言处理流程 &nbsp; &nbsp; &nbsp; &nbsp;" />
<link rel="canonical" href="https://mlh.app/2019/01/14/a22cb9b3c72242082dfde2e5e0a9b8f8.html" />
<meta property="og:url" content="https://mlh.app/2019/01/14/a22cb9b3c72242082dfde2e5e0a9b8f8.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-14T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明： https://blog.csdn.net/asialee_bird/article/details/86483835 1、数据集下载 商品（书籍、酒店、计算机、牛奶、手机、热水器）等评论数据 from sklearn.model_selection import train_test_split from gensim.models.word2vec import Word2Vec import numpy as np import pandas as pd import jieba from sklearn.externals import joblib from sklearn.svm import SVC 2、载入数据，做预处理（分词），切分训练集与测试集 #载入数据，做预处理（分词），切分训练集与测试集 def load_file_and_preprocessing(): neg=pd.read_excel(&#39;chinese_data/neg.xls&#39;,header=None,index=None) pos=pd.read_excel(&#39;chinese_data/pos.xls&#39;,header=None,index=None) cw=lambda x:list(jieba.cut(x)) pos[&#39;words&#39;]=pos[0].apply(cw) neg[&#39;words&#39;]=neg[0].apply(cw) # use 1 for positive sentiment,0 for negative y=np.concatenate((np.ones(len(pos)),np.zeros(len(neg)))) #训练集：测试集=8:2 x_train,x_test,y_train,y_test=train_test_split(np.concatenate((pos[&#39;words&#39;],neg[&#39;words&#39;])),y,test_size=0.2) #NumPy提供了多种文件操作函数方便存取数组内容（npy格式以二进制存储数据的） np.save(&#39;pre_data/y_train.npy&#39;,y_train) np.save(&#39;pre_data/y_test.npy&#39;,y_test) return x_train,x_test 3、计算训练集和测试集每条评论数据的向量并存入文件 #对每个句子的所有词向量取均值，来生成一个句子的vector def build_sentence_vector(text,size,w2v_model): vec=np.zeros(size).reshape((1,size)) count=0 for word in text: try: vec+=w2v_model[word].reshape((1,size)) count+=1 except KeyError: continue if count!=0: vec/=count return vec #计算词向量 def get_train_vecs(x_train,x_test): n_dim=300 #词向量维度 #试用Word2Vec建立词向量模型 w2v_model=Word2Vec(size=n_dim,window=5,sg=0,hs=0,negative=5,min_count=10) w2v_model.build_vocab(x_train) #准备模型词汇表 #在评论训练集上建模 w2v_model.train(x_train,total_examples=w2v_model.corpus_count,epochs=w2v_model.iter) #训练词向量 #训练集评论向量集合 train_vecs=np.concatenate([build_sentence_vector(z,n_dim,w2v_model) for z in x_train]) np.save(&#39;pre_data/train_vecs.npy&#39;,train_vecs) #将训练集保存到文件中 print(train_vecs.shape) #输出训练集的维度 #在测试集上训练 w2v_model.train(x_test,total_examples=w2v_model.corpus_count,epochs=w2v_model.iter) w2v_model.save(&#39;pre_data/w2v_model/w2v_model.pkl&#39;) test_vecs=np.concatenate([build_sentence_vector(z,n_dim,w2v_model) for z in x_test]) np.save(&#39;pre_data/test_vecs.npy&#39;,test_vecs) print(test_vecs.shape) 4、获得训练集向量和标签，测试集向量和标签 #获得训练集向量和标签，测试集向量和标签 def get_data(): train_vecs=np.load(&#39;pre_data/train_vecs.npy&#39;) y_train=np.load(&#39;pre_data/y_train.npy&#39;) test_vecs=np.load(&#39;pre_data/test_vecs.npy&#39;) y_test=np.load(&#39;pre_data/y_test.npy&#39;) return train_vecs,y_train,test_vecs,y_test 5、训练SVM模型 #训练SVM模型 def svm_train(train_vecs,y_train,test_vecs,y_test): clf=SVC(kernel=&#39;rbf&#39;,verbose=True) clf.fit(train_vecs,y_train) #根据给定的训练数据拟合SVM模型 joblib.dump(clf,&#39;pre_data/svm_model/model.pkl&#39;) #保存训练好的SVM模型 print(clf.score(test_vecs,y_test)) #输出测试数据的平均准确度 6、构建待遇测句子的向量 #构建待遇测句子的向量 def get_predict_vecs(words): n_dim=300 w2v_model=Word2Vec.load(&#39;pre_data/w2v_model/w2v_model.pkl&#39;) train_vecs=build_sentence_vector(words,n_dim,w2v_model) return train_vecs 7、对单个句子进行情感判断 #对单个句子进行情感判断 def svm_predict(string): words=jieba.lcut(string) words_vecs=get_predict_vecs(words) clf=joblib.load(&#39;pre_data/svm_model/model.pkl&#39;) result=clf.predict(words_vecs) if int(result[0])==1: print(string,&#39;positive&#39;) else: print(string,&#39;negative&#39;) if __name__==&#39;__main__&#39;: #x_train, x_test=load_file_and_preprocessing() #get_train_vecs(x_train, x_test) #train_vecs, y_train, test_vecs, y_test=get_data() #svm_train(train_vecs, y_train, test_vecs, y_test) #对输入句子情感进行判断 string=&#39;电池充完了电连手机都打不开，简直烂的要命，真是金玉其外，败絮其中！连5号电池都不如&#39; #string=&#39;牛逼的手机，从3米高的地方摔下去都没坏，质量非常好&#39; #string=&#39;这款电脑感觉还行，能用，先试用一下，应该不错&#39; svm_predict(string) &nbsp; &nbsp; 中文自然语言处理流程 &nbsp; &nbsp; &nbsp; &nbsp;","@type":"BlogPosting","url":"https://mlh.app/2019/01/14/a22cb9b3c72242082dfde2e5e0a9b8f8.html","headline":"中文自然语言处理——商品评论情感判别","dateModified":"2019-01-14T00:00:00+08:00","datePublished":"2019-01-14T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/01/14/a22cb9b3c72242082dfde2e5e0a9b8f8.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>中文自然语言处理——商品评论情感判别</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明： https://blog.csdn.net/asialee_bird/article/details/86483835 
 </div> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h2><strong>1、数据集下载</strong></h2> 
  <p style="text-indent:50px;"><strong><a href="https://github.com/Asia-Lee/nlp_projects/tree/master/chinese_data" rel="nofollow">商品（书籍、酒店、计算机、牛奶、手机、热水器）等评论数据</a></strong></p> 
  <pre class="has">
<code class="language-python">from sklearn.model_selection import train_test_split
from gensim.models.word2vec import Word2Vec
import numpy as np
import pandas as pd
import jieba
from sklearn.externals import joblib
from sklearn.svm import SVC</code></pre> 
  <h2><strong>2、载入数据，做预处理（分词），切分训练集与测试集</strong></h2> 
  <pre class="has">
<code class="language-python">#载入数据，做预处理（分词），切分训练集与测试集
def load_file_and_preprocessing():
    neg=pd.read_excel('chinese_data/neg.xls',header=None,index=None)
    pos=pd.read_excel('chinese_data/pos.xls',header=None,index=None)
    cw=lambda x:list(jieba.cut(x))
    pos['words']=pos[0].apply(cw)
    neg['words']=neg[0].apply(cw)
    # use 1 for positive sentiment,0 for negative
    y=np.concatenate((np.ones(len(pos)),np.zeros(len(neg))))
    #训练集：测试集=8:2
    x_train,x_test,y_train,y_test=train_test_split(np.concatenate((pos['words'],neg['words'])),y,test_size=0.2)

    #NumPy提供了多种文件操作函数方便存取数组内容（npy格式以二进制存储数据的）
    np.save('pre_data/y_train.npy',y_train)
    np.save('pre_data/y_test.npy',y_test)
    return x_train,x_test</code></pre> 
  <h2><strong>3、计算训练集和测试集每条评论数据的向量并存入文件</strong></h2> 
  <pre class="has">
<code class="language-python">#对每个句子的所有词向量取均值，来生成一个句子的vector
def build_sentence_vector(text,size,w2v_model):
    vec=np.zeros(size).reshape((1,size))
    count=0
    for word in text:
        try:
            vec+=w2v_model[word].reshape((1,size))
            count+=1
        except KeyError:
            continue
    if count!=0:
        vec/=count
    return vec

#计算词向量
def get_train_vecs(x_train,x_test):
    n_dim=300 #词向量维度
    #试用Word2Vec建立词向量模型
    w2v_model=Word2Vec(size=n_dim,window=5,sg=0,hs=0,negative=5,min_count=10)
    w2v_model.build_vocab(x_train) #准备模型词汇表
    #在评论训练集上建模
    w2v_model.train(x_train,total_examples=w2v_model.corpus_count,epochs=w2v_model.iter) #训练词向量

    #训练集评论向量集合
    train_vecs=np.concatenate([build_sentence_vector(z,n_dim,w2v_model) for z in x_train])
    np.save('pre_data/train_vecs.npy',train_vecs) #将训练集保存到文件中
    print(train_vecs.shape)  #输出训练集的维度

    #在测试集上训练
    w2v_model.train(x_test,total_examples=w2v_model.corpus_count,epochs=w2v_model.iter)
    w2v_model.save('pre_data/w2v_model/w2v_model.pkl')
    test_vecs=np.concatenate([build_sentence_vector(z,n_dim,w2v_model) for z in x_test])
    np.save('pre_data/test_vecs.npy',test_vecs)
    print(test_vecs.shape)</code></pre> 
  <h2><strong>4、获得训练集向量和标签，测试集向量和标签</strong></h2> 
  <pre class="has">
<code class="language-python">#获得训练集向量和标签，测试集向量和标签
def get_data():
    train_vecs=np.load('pre_data/train_vecs.npy')
    y_train=np.load('pre_data/y_train.npy')
    test_vecs=np.load('pre_data/test_vecs.npy')
    y_test=np.load('pre_data/y_test.npy')
    return train_vecs,y_train,test_vecs,y_test
</code></pre> 
  <h2><strong>5、训练SVM模型</strong></h2> 
  <pre class="has">
<code class="language-python">#训练SVM模型
def svm_train(train_vecs,y_train,test_vecs,y_test):
    clf=SVC(kernel='rbf',verbose=True)
    clf.fit(train_vecs,y_train)   #根据给定的训练数据拟合SVM模型
    joblib.dump(clf,'pre_data/svm_model/model.pkl')  #保存训练好的SVM模型
    print(clf.score(test_vecs,y_test))   #输出测试数据的平均准确度
</code></pre> 
  <h2><strong>6、构建待遇测句子的向量</strong></h2> 
  <pre class="has">
<code class="language-python">#构建待遇测句子的向量
def get_predict_vecs(words):
    n_dim=300
    w2v_model=Word2Vec.load('pre_data/w2v_model/w2v_model.pkl')
    train_vecs=build_sentence_vector(words,n_dim,w2v_model)
    return train_vecs
</code></pre> 
  <h2><strong>7、对单个句子进行情感判断</strong></h2> 
  <pre class="has">
<code class="language-python">#对单个句子进行情感判断
def svm_predict(string):
    words=jieba.lcut(string)
    words_vecs=get_predict_vecs(words)
    clf=joblib.load('pre_data/svm_model/model.pkl')
    result=clf.predict(words_vecs)

    if int(result[0])==1:
        print(string,'positive')
    else:
        print(string,'negative')
</code></pre> 
  <pre class="has">
<code class="language-python">if __name__=='__main__':
    #x_train, x_test=load_file_and_preprocessing()
    #get_train_vecs(x_train, x_test)

    #train_vecs, y_train, test_vecs, y_test=get_data()
    #svm_train(train_vecs, y_train, test_vecs, y_test)

    #对输入句子情感进行判断
    string='电池充完了电连手机都打不开，简直烂的要命，真是金玉其外，败絮其中！连5号电池都不如'
    #string='牛逼的手机，从3米高的地方摔下去都没坏，质量非常好'
    #string='这款电脑感觉还行，能用，先试用一下，应该不错'
    svm_predict(string)</code></pre> 
  <p><img alt="" class="has" height="92" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190114210429595.png" width="938"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p><strong><a href="https://www.cnblogs.com/pinard/p/6744056.html" rel="nofollow">中文自然语言处理流程</a></strong></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
