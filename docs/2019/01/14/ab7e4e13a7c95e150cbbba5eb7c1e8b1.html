<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Python NLTK学习5（词性标注） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Python NLTK学习5（词性标注）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 本系列博客为学习《用Python进行自然语言处理》一书的学习笔记。 词性标注器 一个词性标注器处理一个词序列，为每个词附加一个词性标记，我们先看一个示例： import nltkwords = nltk.word_tokenize(&#39;And now for something completely different&#39;)print(words)word_tag = nltk.pos_tag(words)print(word_tag) 结果为： [&#39;And&#39;, &#39;now&#39;, &#39;for&#39;, &#39;something&#39;, &#39;completely&#39;, &#39;different&#39;] [(&#39;And&#39;, &#39;CC&#39;), (&#39;now&#39;, &#39;RB&#39;), (&#39;for&#39;, &#39;IN&#39;), (&#39;something&#39;, &#39;NN&#39;), (&#39;completely&#39;, &#39;RB&#39;), (&#39;different&#39;, &#39;JJ&#39;)] nltk.word_tokenize（text）：对指定的句子进行分词，返回单词列表。 nltk.pos_tag(words)：对指定的单词列表进行词性标记，返回标记列表。 从结果我们可以看到something是NN，NN代表名词。 为什么nltk.pos_tag()方法可以对单词进行词性标记？这是因为NLTK预先使用一些语料库训练出了一个词性标注器，这个词性标注器可以对单词列表进行标记。 标注语料库 NLTK中的很多语料库都已经标注了词性，我们之前学习过的布朗语料库就是一个被标注了词性的语料库，每个语料库使用的标记符号可以有所不同。 from nltk.corpus import brownwords_tag = brown.tagged_words(categories=&#39;news&#39;)print(words_tag[:10]) 结果为： [(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), (&#39;County&#39;, &#39;NN-TL&#39;), (&#39;Grand&#39;, &#39;JJ-TL&#39;), (&#39;Jury&#39;, &#39;NN-TL&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;Friday&#39;, &#39;NR&#39;), (&#39;an&#39;, &#39;AT&#39;), (&#39;investigation&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;)] brown可以看作是一个CategorizedTaggedCorpusReader实例对象。 CategorizedTaggedCorpusReader::tagged_words(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的单词列表。 CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的句子列表，句子为单词列表。 tagged_sents = brown.tagged_sents(categories=&#39;news&#39;)print(tagged_sents) 结果为： [[(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), (&#39;County&#39;, &#39;NN-TL&#39;), (&#39;Grand&#39;, &#39;JJ-TL&#39;), (&#39;Jury&#39;, &#39;NN-TL&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;Friday&#39;, &#39;NR&#39;), (&#39;an&#39;, &#39;AT&#39;), (&#39;investigation&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;), (&quot;Atlanta&#39;s&quot;, &#39;NP$&#39;), (&#39;recent&#39;, &#39;JJ&#39;), (&#39;primary&#39;, &#39;NN&#39;), (&#39;election&#39;,&nbsp;&#39;NN&#39;), (&#39;produced&#39;, &#39;VBD&#39;), (&#39;&#39;,&nbsp;&#39;&#39;),&nbsp;(&#39;no&#39;, &#39;AT&#39;), (&#39;evidence&#39;, &#39;NN&#39;), (&quot;&#39;&#39;&quot;, &quot;&#39;&#39;&quot;), (&#39;that&#39;, &#39;CS&#39;), (&#39;any&#39;, &#39;DTI&#39;), (&#39;irregularities&#39;, &#39;NNS&#39;), (&#39;took&#39;, &#39;VBD&#39;), (&#39;place&#39;, &#39;NN&#39;), (&#39;.&#39;, &#39;.&#39;)], [(&#39;The&#39;, &#39;AT&#39;), (&#39;jury&#39;, &#39;NN&#39;), (&#39;further&#39;, &#39;RBR&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;term-end&#39;, &#39;NN&#39;),&nbsp;(&#39;presentments&#39;, &#39;NNS&#39;), (&#39;that&#39;, &#39;CS&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;City&#39;, &#39;NN-TL&#39;), (&#39;Executive&#39;, &#39;JJ-TL&#39;), (&#39;Committee&#39;, &#39;NN-TL&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;which&#39;, &#39;WDT&#39;), (&#39;had&#39;, &#39;HVD&#39;), (&#39;over-all&#39;, &#39;JJ&#39;), (&#39;charge&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;election&#39;, &#39;NN&#39;),&nbsp;(&#39;,&#39;, &#39;,&#39;), (&#39;&#39;,&nbsp;&#39;&#39;),&nbsp;(&#39;deserves&#39;, &#39;VBZ&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;praise&#39;, &#39;NN&#39;), (&#39;and&#39;, &#39;CC&#39;), (&#39;thanks&#39;, &#39;NNS&#39;), (&#39;of&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;City&#39;, &#39;NN-TL&#39;), (&#39;of&#39;, &#39;IN-TL&#39;), (&#39;Atlanta&#39;, &#39;NP-TL&#39;), (&quot;&#39;&#39;&quot;, &quot;&#39;&#39;&quot;), (&#39;for&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;manner&#39;, &#39;NN&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;which&#39;,&nbsp;&#39;WDT&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;election&#39;, &#39;NN&#39;), (&#39;was&#39;, &#39;BEDZ&#39;), (&#39;conducted&#39;, &#39;VBN&#39;), (&#39;.&#39;, &#39;.&#39;)], ...] NLTK中还包含一个中文语料库sinica_treebank，该库使用繁体中文，该库也被标注了词性，我们来看看该库。 from nltk.corpus import sinica_treebankprint(sinica_treebank.fileids()) 结果为： [&#39;parsed&#39;] sinica_treebank可以看做是一个SinicaTreebankCorpusReader实例对象。 SinicaTreebankCorpusReader::words(fileids)：该方法接受文本标识作为参数，返回文本的单词列表。 SinicaTreebankCorpusReader::tagged_words(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的单词列表。 words = sinica_treebank.words(&#39;parsed&#39;)print(words[:40])words_tag = sinica_treebank.tagged_words(&#39;parsed&#39;)print(words_tag[:40]) 结果为： [&#39;一&#39;, &#39;友情&#39;, &#39;嘉珍&#39;, &#39;和&#39;, &#39;我&#39;, &#39;住在&#39;, &#39;同一條&#39;, &#39;巷子&#39;, &#39;我們&#39;, &#39;是&#39;, &#39;鄰居&#39;, &#39;也&#39;, &#39;是&#39;, &#39;同班&#39;, &#39;同學&#39;, &#39;我們&#39;, &#39;常常&#39;, &#39;一起&#39;, &#39;上學&#39;, &#39;一起&#39;, &#39;回家&#39;, &#39;有一天&#39;, &#39;上學&#39;, &#39;時&#39;, &#39;我&#39;, &#39;到&#39;, &#39;她&#39;, &#39;家&#39;, &#39;等候&#39;, &#39;按&#39;, &#39;了&#39;, &#39;門鈴&#39;, &#39;卻&#39;, &#39;沒有&#39;, &#39;任何&#39;, &#39;動靜&#39;, &#39;正當&#39;, &#39;我&#39;, &#39;想&#39;, &#39;離開&#39;] [(&#39;一&#39;, &#39;Neu&#39;), (&#39;友情&#39;, &#39;Nad&#39;), (&#39;嘉珍&#39;, &#39;Nba&#39;), (&#39;和&#39;, &#39;Caa&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;住在&#39;, &#39;VC1&#39;), (&#39;同一條&#39;, &#39;DM&#39;), (&#39;巷子&#39;, &#39;Nab&#39;), (&#39;我們&#39;, &#39;Nhaa&#39;), (&#39;是&#39;, &#39;V_11&#39;), (&#39;鄰居&#39;, &#39;Nab&#39;), (&#39;也&#39;, &#39;Dbb&#39;), (&#39;是&#39;, &#39;V_11&#39;), (&#39;同班&#39;, &#39;Nv3&#39;), (&#39;同學&#39;, &#39;Nab&#39;), (&#39;我們&#39;, &#39;Nhaa&#39;), (&#39;常常&#39;, &#39;Dd&#39;), (&#39;一起&#39;,&nbsp;&#39;Dh&#39;), (&#39;上學&#39;, &#39;VA4&#39;), (&#39;一起&#39;, &#39;Dh&#39;), (&#39;回家&#39;, &#39;VA13&#39;), (&#39;有一天&#39;, &#39;DM&#39;), (&#39;上學&#39;, &#39;VA4&#39;), (&#39;時&#39;, &#39;Ng&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;到&#39;, &#39;P61&#39;), (&#39;她&#39;, &#39;Nhaa&#39;), (&#39;家&#39;, &#39;Ncb&#39;), (&#39;等候&#39;, &#39;VK2&#39;), (&#39;按&#39;, &#39;VC2&#39;), (&#39;了&#39;, &#39;Di&#39;), (&#39;門鈴&#39;, &#39;Nab&#39;), (&#39;卻&#39;, &#39;Dbb&#39;), (&#39;沒有&#39;, &#39;VJ3&#39;), (&#39;任何&#39;, &#39;Neqa&#39;), (&#39;動靜&#39;,&nbsp;&#39;Nad&#39;), (&#39;正當&#39;, &#39;P16&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;想&#39;, &#39;VE2&#39;), (&#39;離開&#39;, &#39;VC2&#39;)] 我们来看看哪些标记是sinica_treebank库中最常见的。 words_tag = sinica_treebank.tagged_words(&#39;parsed&#39;)tag_fd = nltk.FreqDist(tag for (word, tag) in words_tag)tag_fd.tabulate(5) 结果为: Nab DE Nac Nad VH11 9520 7095 4478 3873 3722 我们可以看到Nab标记出现了9520次。 总结 nltk.word_tokenize（text）：对指定的句子进行分词，返回单词列表 nltk.pos_tag(words)：对指定的单词列表进行词性标记，返回标记列表 CategorizedTaggedCorpusReader::tagged_words(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的单词列表 CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的句子列表，句子为单词列表 SinicaTreebankCorpusReader::tagged_words(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的单词列表 SinicaTreebankCorpusReader::tagged_sents(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的句子列表，句子为单词列表 其他章节链接 Python&nbsp;NLTK学习1（Text对象） Python&nbsp;NLTK学习2（FreqDist对象） Python&nbsp;NLTK学习3（语料库） Python&nbsp;NLTK学习4（条件频率分布） Python NLTK学习5（词性标注） Python&nbsp;NLTK学习6（创建词性标注器）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 再分享一下我老师大神的人工智能教程吧。零基础！通俗易懂！风趣幽默！还带黄段子！希望你也加入到我们人工智能的队伍中来！https://blog.csdn.net/jiangjunshow" />
<meta property="og:description" content="&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 本系列博客为学习《用Python进行自然语言处理》一书的学习笔记。 词性标注器 一个词性标注器处理一个词序列，为每个词附加一个词性标记，我们先看一个示例： import nltkwords = nltk.word_tokenize(&#39;And now for something completely different&#39;)print(words)word_tag = nltk.pos_tag(words)print(word_tag) 结果为： [&#39;And&#39;, &#39;now&#39;, &#39;for&#39;, &#39;something&#39;, &#39;completely&#39;, &#39;different&#39;] [(&#39;And&#39;, &#39;CC&#39;), (&#39;now&#39;, &#39;RB&#39;), (&#39;for&#39;, &#39;IN&#39;), (&#39;something&#39;, &#39;NN&#39;), (&#39;completely&#39;, &#39;RB&#39;), (&#39;different&#39;, &#39;JJ&#39;)] nltk.word_tokenize（text）：对指定的句子进行分词，返回单词列表。 nltk.pos_tag(words)：对指定的单词列表进行词性标记，返回标记列表。 从结果我们可以看到something是NN，NN代表名词。 为什么nltk.pos_tag()方法可以对单词进行词性标记？这是因为NLTK预先使用一些语料库训练出了一个词性标注器，这个词性标注器可以对单词列表进行标记。 标注语料库 NLTK中的很多语料库都已经标注了词性，我们之前学习过的布朗语料库就是一个被标注了词性的语料库，每个语料库使用的标记符号可以有所不同。 from nltk.corpus import brownwords_tag = brown.tagged_words(categories=&#39;news&#39;)print(words_tag[:10]) 结果为： [(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), (&#39;County&#39;, &#39;NN-TL&#39;), (&#39;Grand&#39;, &#39;JJ-TL&#39;), (&#39;Jury&#39;, &#39;NN-TL&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;Friday&#39;, &#39;NR&#39;), (&#39;an&#39;, &#39;AT&#39;), (&#39;investigation&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;)] brown可以看作是一个CategorizedTaggedCorpusReader实例对象。 CategorizedTaggedCorpusReader::tagged_words(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的单词列表。 CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的句子列表，句子为单词列表。 tagged_sents = brown.tagged_sents(categories=&#39;news&#39;)print(tagged_sents) 结果为： [[(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), (&#39;County&#39;, &#39;NN-TL&#39;), (&#39;Grand&#39;, &#39;JJ-TL&#39;), (&#39;Jury&#39;, &#39;NN-TL&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;Friday&#39;, &#39;NR&#39;), (&#39;an&#39;, &#39;AT&#39;), (&#39;investigation&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;), (&quot;Atlanta&#39;s&quot;, &#39;NP$&#39;), (&#39;recent&#39;, &#39;JJ&#39;), (&#39;primary&#39;, &#39;NN&#39;), (&#39;election&#39;,&nbsp;&#39;NN&#39;), (&#39;produced&#39;, &#39;VBD&#39;), (&#39;&#39;,&nbsp;&#39;&#39;),&nbsp;(&#39;no&#39;, &#39;AT&#39;), (&#39;evidence&#39;, &#39;NN&#39;), (&quot;&#39;&#39;&quot;, &quot;&#39;&#39;&quot;), (&#39;that&#39;, &#39;CS&#39;), (&#39;any&#39;, &#39;DTI&#39;), (&#39;irregularities&#39;, &#39;NNS&#39;), (&#39;took&#39;, &#39;VBD&#39;), (&#39;place&#39;, &#39;NN&#39;), (&#39;.&#39;, &#39;.&#39;)], [(&#39;The&#39;, &#39;AT&#39;), (&#39;jury&#39;, &#39;NN&#39;), (&#39;further&#39;, &#39;RBR&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;term-end&#39;, &#39;NN&#39;),&nbsp;(&#39;presentments&#39;, &#39;NNS&#39;), (&#39;that&#39;, &#39;CS&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;City&#39;, &#39;NN-TL&#39;), (&#39;Executive&#39;, &#39;JJ-TL&#39;), (&#39;Committee&#39;, &#39;NN-TL&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;which&#39;, &#39;WDT&#39;), (&#39;had&#39;, &#39;HVD&#39;), (&#39;over-all&#39;, &#39;JJ&#39;), (&#39;charge&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;election&#39;, &#39;NN&#39;),&nbsp;(&#39;,&#39;, &#39;,&#39;), (&#39;&#39;,&nbsp;&#39;&#39;),&nbsp;(&#39;deserves&#39;, &#39;VBZ&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;praise&#39;, &#39;NN&#39;), (&#39;and&#39;, &#39;CC&#39;), (&#39;thanks&#39;, &#39;NNS&#39;), (&#39;of&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;City&#39;, &#39;NN-TL&#39;), (&#39;of&#39;, &#39;IN-TL&#39;), (&#39;Atlanta&#39;, &#39;NP-TL&#39;), (&quot;&#39;&#39;&quot;, &quot;&#39;&#39;&quot;), (&#39;for&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;manner&#39;, &#39;NN&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;which&#39;,&nbsp;&#39;WDT&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;election&#39;, &#39;NN&#39;), (&#39;was&#39;, &#39;BEDZ&#39;), (&#39;conducted&#39;, &#39;VBN&#39;), (&#39;.&#39;, &#39;.&#39;)], ...] NLTK中还包含一个中文语料库sinica_treebank，该库使用繁体中文，该库也被标注了词性，我们来看看该库。 from nltk.corpus import sinica_treebankprint(sinica_treebank.fileids()) 结果为： [&#39;parsed&#39;] sinica_treebank可以看做是一个SinicaTreebankCorpusReader实例对象。 SinicaTreebankCorpusReader::words(fileids)：该方法接受文本标识作为参数，返回文本的单词列表。 SinicaTreebankCorpusReader::tagged_words(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的单词列表。 words = sinica_treebank.words(&#39;parsed&#39;)print(words[:40])words_tag = sinica_treebank.tagged_words(&#39;parsed&#39;)print(words_tag[:40]) 结果为： [&#39;一&#39;, &#39;友情&#39;, &#39;嘉珍&#39;, &#39;和&#39;, &#39;我&#39;, &#39;住在&#39;, &#39;同一條&#39;, &#39;巷子&#39;, &#39;我們&#39;, &#39;是&#39;, &#39;鄰居&#39;, &#39;也&#39;, &#39;是&#39;, &#39;同班&#39;, &#39;同學&#39;, &#39;我們&#39;, &#39;常常&#39;, &#39;一起&#39;, &#39;上學&#39;, &#39;一起&#39;, &#39;回家&#39;, &#39;有一天&#39;, &#39;上學&#39;, &#39;時&#39;, &#39;我&#39;, &#39;到&#39;, &#39;她&#39;, &#39;家&#39;, &#39;等候&#39;, &#39;按&#39;, &#39;了&#39;, &#39;門鈴&#39;, &#39;卻&#39;, &#39;沒有&#39;, &#39;任何&#39;, &#39;動靜&#39;, &#39;正當&#39;, &#39;我&#39;, &#39;想&#39;, &#39;離開&#39;] [(&#39;一&#39;, &#39;Neu&#39;), (&#39;友情&#39;, &#39;Nad&#39;), (&#39;嘉珍&#39;, &#39;Nba&#39;), (&#39;和&#39;, &#39;Caa&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;住在&#39;, &#39;VC1&#39;), (&#39;同一條&#39;, &#39;DM&#39;), (&#39;巷子&#39;, &#39;Nab&#39;), (&#39;我們&#39;, &#39;Nhaa&#39;), (&#39;是&#39;, &#39;V_11&#39;), (&#39;鄰居&#39;, &#39;Nab&#39;), (&#39;也&#39;, &#39;Dbb&#39;), (&#39;是&#39;, &#39;V_11&#39;), (&#39;同班&#39;, &#39;Nv3&#39;), (&#39;同學&#39;, &#39;Nab&#39;), (&#39;我們&#39;, &#39;Nhaa&#39;), (&#39;常常&#39;, &#39;Dd&#39;), (&#39;一起&#39;,&nbsp;&#39;Dh&#39;), (&#39;上學&#39;, &#39;VA4&#39;), (&#39;一起&#39;, &#39;Dh&#39;), (&#39;回家&#39;, &#39;VA13&#39;), (&#39;有一天&#39;, &#39;DM&#39;), (&#39;上學&#39;, &#39;VA4&#39;), (&#39;時&#39;, &#39;Ng&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;到&#39;, &#39;P61&#39;), (&#39;她&#39;, &#39;Nhaa&#39;), (&#39;家&#39;, &#39;Ncb&#39;), (&#39;等候&#39;, &#39;VK2&#39;), (&#39;按&#39;, &#39;VC2&#39;), (&#39;了&#39;, &#39;Di&#39;), (&#39;門鈴&#39;, &#39;Nab&#39;), (&#39;卻&#39;, &#39;Dbb&#39;), (&#39;沒有&#39;, &#39;VJ3&#39;), (&#39;任何&#39;, &#39;Neqa&#39;), (&#39;動靜&#39;,&nbsp;&#39;Nad&#39;), (&#39;正當&#39;, &#39;P16&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;想&#39;, &#39;VE2&#39;), (&#39;離開&#39;, &#39;VC2&#39;)] 我们来看看哪些标记是sinica_treebank库中最常见的。 words_tag = sinica_treebank.tagged_words(&#39;parsed&#39;)tag_fd = nltk.FreqDist(tag for (word, tag) in words_tag)tag_fd.tabulate(5) 结果为: Nab DE Nac Nad VH11 9520 7095 4478 3873 3722 我们可以看到Nab标记出现了9520次。 总结 nltk.word_tokenize（text）：对指定的句子进行分词，返回单词列表 nltk.pos_tag(words)：对指定的单词列表进行词性标记，返回标记列表 CategorizedTaggedCorpusReader::tagged_words(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的单词列表 CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的句子列表，句子为单词列表 SinicaTreebankCorpusReader::tagged_words(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的单词列表 SinicaTreebankCorpusReader::tagged_sents(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的句子列表，句子为单词列表 其他章节链接 Python&nbsp;NLTK学习1（Text对象） Python&nbsp;NLTK学习2（FreqDist对象） Python&nbsp;NLTK学习3（语料库） Python&nbsp;NLTK学习4（条件频率分布） Python NLTK学习5（词性标注） Python&nbsp;NLTK学习6（创建词性标注器）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 再分享一下我老师大神的人工智能教程吧。零基础！通俗易懂！风趣幽默！还带黄段子！希望你也加入到我们人工智能的队伍中来！https://blog.csdn.net/jiangjunshow" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-14T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 本系列博客为学习《用Python进行自然语言处理》一书的学习笔记。 词性标注器 一个词性标注器处理一个词序列，为每个词附加一个词性标记，我们先看一个示例： import nltkwords = nltk.word_tokenize(&#39;And now for something completely different&#39;)print(words)word_tag = nltk.pos_tag(words)print(word_tag) 结果为： [&#39;And&#39;, &#39;now&#39;, &#39;for&#39;, &#39;something&#39;, &#39;completely&#39;, &#39;different&#39;] [(&#39;And&#39;, &#39;CC&#39;), (&#39;now&#39;, &#39;RB&#39;), (&#39;for&#39;, &#39;IN&#39;), (&#39;something&#39;, &#39;NN&#39;), (&#39;completely&#39;, &#39;RB&#39;), (&#39;different&#39;, &#39;JJ&#39;)] nltk.word_tokenize（text）：对指定的句子进行分词，返回单词列表。 nltk.pos_tag(words)：对指定的单词列表进行词性标记，返回标记列表。 从结果我们可以看到something是NN，NN代表名词。 为什么nltk.pos_tag()方法可以对单词进行词性标记？这是因为NLTK预先使用一些语料库训练出了一个词性标注器，这个词性标注器可以对单词列表进行标记。 标注语料库 NLTK中的很多语料库都已经标注了词性，我们之前学习过的布朗语料库就是一个被标注了词性的语料库，每个语料库使用的标记符号可以有所不同。 from nltk.corpus import brownwords_tag = brown.tagged_words(categories=&#39;news&#39;)print(words_tag[:10]) 结果为： [(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), (&#39;County&#39;, &#39;NN-TL&#39;), (&#39;Grand&#39;, &#39;JJ-TL&#39;), (&#39;Jury&#39;, &#39;NN-TL&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;Friday&#39;, &#39;NR&#39;), (&#39;an&#39;, &#39;AT&#39;), (&#39;investigation&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;)] brown可以看作是一个CategorizedTaggedCorpusReader实例对象。 CategorizedTaggedCorpusReader::tagged_words(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的单词列表。 CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的句子列表，句子为单词列表。 tagged_sents = brown.tagged_sents(categories=&#39;news&#39;)print(tagged_sents) 结果为： [[(&#39;The&#39;, &#39;AT&#39;), (&#39;Fulton&#39;, &#39;NP-TL&#39;), (&#39;County&#39;, &#39;NN-TL&#39;), (&#39;Grand&#39;, &#39;JJ-TL&#39;), (&#39;Jury&#39;, &#39;NN-TL&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;Friday&#39;, &#39;NR&#39;), (&#39;an&#39;, &#39;AT&#39;), (&#39;investigation&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;), (&quot;Atlanta&#39;s&quot;, &#39;NP$&#39;), (&#39;recent&#39;, &#39;JJ&#39;), (&#39;primary&#39;, &#39;NN&#39;), (&#39;election&#39;,&nbsp;&#39;NN&#39;), (&#39;produced&#39;, &#39;VBD&#39;), (&#39;&#39;,&nbsp;&#39;&#39;),&nbsp;(&#39;no&#39;, &#39;AT&#39;), (&#39;evidence&#39;, &#39;NN&#39;), (&quot;&#39;&#39;&quot;, &quot;&#39;&#39;&quot;), (&#39;that&#39;, &#39;CS&#39;), (&#39;any&#39;, &#39;DTI&#39;), (&#39;irregularities&#39;, &#39;NNS&#39;), (&#39;took&#39;, &#39;VBD&#39;), (&#39;place&#39;, &#39;NN&#39;), (&#39;.&#39;, &#39;.&#39;)], [(&#39;The&#39;, &#39;AT&#39;), (&#39;jury&#39;, &#39;NN&#39;), (&#39;further&#39;, &#39;RBR&#39;), (&#39;said&#39;, &#39;VBD&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;term-end&#39;, &#39;NN&#39;),&nbsp;(&#39;presentments&#39;, &#39;NNS&#39;), (&#39;that&#39;, &#39;CS&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;City&#39;, &#39;NN-TL&#39;), (&#39;Executive&#39;, &#39;JJ-TL&#39;), (&#39;Committee&#39;, &#39;NN-TL&#39;), (&#39;,&#39;, &#39;,&#39;), (&#39;which&#39;, &#39;WDT&#39;), (&#39;had&#39;, &#39;HVD&#39;), (&#39;over-all&#39;, &#39;JJ&#39;), (&#39;charge&#39;, &#39;NN&#39;), (&#39;of&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;election&#39;, &#39;NN&#39;),&nbsp;(&#39;,&#39;, &#39;,&#39;), (&#39;&#39;,&nbsp;&#39;&#39;),&nbsp;(&#39;deserves&#39;, &#39;VBZ&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;praise&#39;, &#39;NN&#39;), (&#39;and&#39;, &#39;CC&#39;), (&#39;thanks&#39;, &#39;NNS&#39;), (&#39;of&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;City&#39;, &#39;NN-TL&#39;), (&#39;of&#39;, &#39;IN-TL&#39;), (&#39;Atlanta&#39;, &#39;NP-TL&#39;), (&quot;&#39;&#39;&quot;, &quot;&#39;&#39;&quot;), (&#39;for&#39;, &#39;IN&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;manner&#39;, &#39;NN&#39;), (&#39;in&#39;, &#39;IN&#39;), (&#39;which&#39;,&nbsp;&#39;WDT&#39;), (&#39;the&#39;, &#39;AT&#39;), (&#39;election&#39;, &#39;NN&#39;), (&#39;was&#39;, &#39;BEDZ&#39;), (&#39;conducted&#39;, &#39;VBN&#39;), (&#39;.&#39;, &#39;.&#39;)], ...] NLTK中还包含一个中文语料库sinica_treebank，该库使用繁体中文，该库也被标注了词性，我们来看看该库。 from nltk.corpus import sinica_treebankprint(sinica_treebank.fileids()) 结果为： [&#39;parsed&#39;] sinica_treebank可以看做是一个SinicaTreebankCorpusReader实例对象。 SinicaTreebankCorpusReader::words(fileids)：该方法接受文本标识作为参数，返回文本的单词列表。 SinicaTreebankCorpusReader::tagged_words(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的单词列表。 words = sinica_treebank.words(&#39;parsed&#39;)print(words[:40])words_tag = sinica_treebank.tagged_words(&#39;parsed&#39;)print(words_tag[:40]) 结果为： [&#39;一&#39;, &#39;友情&#39;, &#39;嘉珍&#39;, &#39;和&#39;, &#39;我&#39;, &#39;住在&#39;, &#39;同一條&#39;, &#39;巷子&#39;, &#39;我們&#39;, &#39;是&#39;, &#39;鄰居&#39;, &#39;也&#39;, &#39;是&#39;, &#39;同班&#39;, &#39;同學&#39;, &#39;我們&#39;, &#39;常常&#39;, &#39;一起&#39;, &#39;上學&#39;, &#39;一起&#39;, &#39;回家&#39;, &#39;有一天&#39;, &#39;上學&#39;, &#39;時&#39;, &#39;我&#39;, &#39;到&#39;, &#39;她&#39;, &#39;家&#39;, &#39;等候&#39;, &#39;按&#39;, &#39;了&#39;, &#39;門鈴&#39;, &#39;卻&#39;, &#39;沒有&#39;, &#39;任何&#39;, &#39;動靜&#39;, &#39;正當&#39;, &#39;我&#39;, &#39;想&#39;, &#39;離開&#39;] [(&#39;一&#39;, &#39;Neu&#39;), (&#39;友情&#39;, &#39;Nad&#39;), (&#39;嘉珍&#39;, &#39;Nba&#39;), (&#39;和&#39;, &#39;Caa&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;住在&#39;, &#39;VC1&#39;), (&#39;同一條&#39;, &#39;DM&#39;), (&#39;巷子&#39;, &#39;Nab&#39;), (&#39;我們&#39;, &#39;Nhaa&#39;), (&#39;是&#39;, &#39;V_11&#39;), (&#39;鄰居&#39;, &#39;Nab&#39;), (&#39;也&#39;, &#39;Dbb&#39;), (&#39;是&#39;, &#39;V_11&#39;), (&#39;同班&#39;, &#39;Nv3&#39;), (&#39;同學&#39;, &#39;Nab&#39;), (&#39;我們&#39;, &#39;Nhaa&#39;), (&#39;常常&#39;, &#39;Dd&#39;), (&#39;一起&#39;,&nbsp;&#39;Dh&#39;), (&#39;上學&#39;, &#39;VA4&#39;), (&#39;一起&#39;, &#39;Dh&#39;), (&#39;回家&#39;, &#39;VA13&#39;), (&#39;有一天&#39;, &#39;DM&#39;), (&#39;上學&#39;, &#39;VA4&#39;), (&#39;時&#39;, &#39;Ng&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;到&#39;, &#39;P61&#39;), (&#39;她&#39;, &#39;Nhaa&#39;), (&#39;家&#39;, &#39;Ncb&#39;), (&#39;等候&#39;, &#39;VK2&#39;), (&#39;按&#39;, &#39;VC2&#39;), (&#39;了&#39;, &#39;Di&#39;), (&#39;門鈴&#39;, &#39;Nab&#39;), (&#39;卻&#39;, &#39;Dbb&#39;), (&#39;沒有&#39;, &#39;VJ3&#39;), (&#39;任何&#39;, &#39;Neqa&#39;), (&#39;動靜&#39;,&nbsp;&#39;Nad&#39;), (&#39;正當&#39;, &#39;P16&#39;), (&#39;我&#39;, &#39;Nhaa&#39;), (&#39;想&#39;, &#39;VE2&#39;), (&#39;離開&#39;, &#39;VC2&#39;)] 我们来看看哪些标记是sinica_treebank库中最常见的。 words_tag = sinica_treebank.tagged_words(&#39;parsed&#39;)tag_fd = nltk.FreqDist(tag for (word, tag) in words_tag)tag_fd.tabulate(5) 结果为: Nab DE Nac Nad VH11 9520 7095 4478 3873 3722 我们可以看到Nab标记出现了9520次。 总结 nltk.word_tokenize（text）：对指定的句子进行分词，返回单词列表 nltk.pos_tag(words)：对指定的单词列表进行词性标记，返回标记列表 CategorizedTaggedCorpusReader::tagged_words(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的单词列表 CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的句子列表，句子为单词列表 SinicaTreebankCorpusReader::tagged_words(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的单词列表 SinicaTreebankCorpusReader::tagged_sents(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的句子列表，句子为单词列表 其他章节链接 Python&nbsp;NLTK学习1（Text对象） Python&nbsp;NLTK学习2（FreqDist对象） Python&nbsp;NLTK学习3（语料库） Python&nbsp;NLTK学习4（条件频率分布） Python NLTK学习5（词性标注） Python&nbsp;NLTK学习6（创建词性标注器）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 再分享一下我老师大神的人工智能教程吧。零基础！通俗易懂！风趣幽默！还带黄段子！希望你也加入到我们人工智能的队伍中来！https://blog.csdn.net/jiangjunshow","@type":"BlogPosting","url":"/2019/01/14/ab7e4e13a7c95e150cbbba5eb7c1e8b1.html","headline":"Python NLTK学习5（词性标注）","dateModified":"2019-01-14T00:00:00+08:00","datePublished":"2019-01-14T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/01/14/ab7e4e13a7c95e150cbbba5eb7c1e8b1.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Python NLTK学习5（词性标注）</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <div class="htmledit_views" id="content_views">
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
   <p>本系列博客为学习《用Python进行自然语言处理》一书的学习笔记。</p>
   <h2>词性标注器</h2>
   <p>一个词性标注器处理一个词序列，为每个词附加一个词性标记，我们先看一个示例：</p>
   <pre class="prettyprint hljs swift"><span class="hljs-keyword">import</span> nltkwords = nltk.word_tokenize('<span class="hljs-type">And</span> now <span class="hljs-keyword">for</span> something completely different')<span class="hljs-built_in">print</span>(words)word_tag = nltk.pos_tag(words)<span class="hljs-built_in">print</span>(word_tag)</pre>
   <p>结果为：</p>
   <p>['And', 'now', 'for', 'something', 'completely', 'different']</p>
   <p>[('And', 'CC'), ('now', 'RB'), ('for', 'IN'), ('something', 'NN'), ('completely', 'RB'), ('different', 'JJ')]</p>
   <p>nltk.word_tokenize（text）：对指定的句子进行分词，返回单词列表。</p>
   <p>nltk.pos_tag(words)：对指定的单词列表进行词性标记，返回标记列表。</p>
   <p>从结果我们可以看到something是NN，NN代表名词。</p>
   <p>为什么nltk.pos_tag()方法可以对单词进行词性标记？这是因为NLTK预先使用一些语料库训练出了一个词性标注器，这个词性标注器可以对单词列表进行标记。</p>
   <h2>标注语料库</h2>
   <p>NLTK中的很多语料库都已经标注了词性，我们之前学习过的布朗语料库就是一个被标注了词性的语料库，每个语料库使用的标记符号可以有所不同。</p>
   <pre><code class="language-python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.corpus <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> brownwords_tag = brown.tagged_words(categories=<span class="hljs-string"><span class="hljs-string">'news'</span></span>)print(words_tag[:<span class="hljs-number"><span class="hljs-number">10</span></span>])</code></pre>
   <p>结果为：</p>
   <p>[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN')]</p>
   <p>brown可以看作是一个CategorizedTaggedCorpusReader实例对象。</p>
   <p>CategorizedTaggedCorpusReader::tagged_words(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的单词列表。</p>
   <p>CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的句子列表，句子为单词列表。</p>
   <pre class="prettyprint hljs lua">tagged_sents = brown.tagged_sents(categories=<span class="hljs-string">'news'</span>)<span class="hljs-built_in">print</span>(tagged_sents)</pre>
   <p>结果为：</p>
   <p class="has-jax">[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), ("Atlanta's", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election',&nbsp;'NN'), ('produced', 'VBD'), ('<span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-1-Frame"><span class="mjx-math" id="MJXc-Node-1"><span class="mjx-mrow" id="MJXc-Node-2"><span class="mjx-mstyle" id="MJXc-Node-3"><span class="mjx-mrow" id="MJXc-Node-4"><span class="mjx-mo" id="MJXc-Node-5"></span></span></span></span></span><span class="MJX_Assistive_MathML"></span></span>',&nbsp;'<span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-2-Frame"><span class="mjx-math" id="MJXc-Node-6"><span class="mjx-mrow" id="MJXc-Node-7"><span class="mjx-mstyle" id="MJXc-Node-8"><span class="mjx-mrow" id="MJXc-Node-9"><span class="mjx-mo" id="MJXc-Node-10"></span></span></span></span></span><span class="MJX_Assistive_MathML"></span></span>'),&nbsp;('no', 'AT'), ('evidence', 'NN'), ("''", "''"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'),&nbsp;('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'),&nbsp;(',', ','), ('<span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-3-Frame"><span class="mjx-math" id="MJXc-Node-11"><span class="mjx-mrow" id="MJXc-Node-12"><span class="mjx-mstyle" id="MJXc-Node-13"><span class="mjx-mrow" id="MJXc-Node-14"><span class="mjx-mo" id="MJXc-Node-15"></span></span></span></span></span><span class="MJX_Assistive_MathML"></span></span>',&nbsp;'<span class="mjx-chtml MathJax_CHTML" id="MathJax-Element-4-Frame"><span class="mjx-math" id="MJXc-Node-16"><span class="mjx-mrow" id="MJXc-Node-17"><span class="mjx-mstyle" id="MJXc-Node-18"><span class="mjx-mrow" id="MJXc-Node-19"><span class="mjx-mo" id="MJXc-Node-20"></span></span></span></span></span><span class="MJX_Assistive_MathML"></span></span>'),&nbsp;('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), ("''", "''"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which',&nbsp;'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]</p>
   <p>NLTK中还包含一个中文语料库sinica_treebank，该库使用繁体中文，该库也被标注了词性，我们来看看该库。</p>
   <pre><code class="language-python hljs"><span class="hljs-keyword"><span class="hljs-keyword">from</span></span> nltk.corpus <span class="hljs-keyword"><span class="hljs-keyword">import</span></span> sinica_treebankprint(sinica_treebank.fileids())</code></pre>
   <p>结果为：</p>
   <p>['parsed']</p>
   <p>sinica_treebank可以看做是一个SinicaTreebankCorpusReader实例对象。</p>
   <p>SinicaTreebankCorpusReader::words(fileids)：该方法接受文本标识作为参数，返回文本的单词列表。</p>
   <p>SinicaTreebankCorpusReader::tagged_words(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的单词列表。</p>
   <pre class="prettyprint hljs lua">words = sinica_treebank.words(<span class="hljs-string">'parsed'</span>)<span class="hljs-built_in">print</span>(words[:<span class="hljs-number">40</span>])words_tag = sinica_treebank.tagged_words(<span class="hljs-string">'parsed'</span>)<span class="hljs-built_in">print</span>(words_tag[:<span class="hljs-number">40</span>])</pre>
   <p>结果为：</p>
   <p>['一', '友情', '嘉珍', '和', '我', '住在', '同一條', '巷子', '我們', '是', '鄰居', '也', '是', '同班', '同學', '我們', '常常', '一起', '上學', '一起', '回家', '有一天', '上學', '時', '我', '到', '她', '家', '等候', '按', '了', '門鈴', '卻', '沒有', '任何', '動靜', '正當', '我', '想', '離開']</p>
   <p>[('一', 'Neu'), ('友情', 'Nad'), ('嘉珍', 'Nba'), ('和', 'Caa'), ('我', 'Nhaa'), ('住在', 'VC1'), ('同一條', 'DM'), ('巷子', 'Nab'), ('我們', 'Nhaa'), ('是', 'V_11'), ('鄰居', 'Nab'), ('也', 'Dbb'), ('是', 'V_11'), ('同班', 'Nv3'), ('同學', 'Nab'), ('我們', 'Nhaa'), ('常常', 'Dd'), ('一起',&nbsp;'Dh'), ('上學', 'VA4'), ('一起', 'Dh'), ('回家', 'VA13'), ('有一天', 'DM'), ('上學', 'VA4'), ('時', 'Ng'), ('我', 'Nhaa'), ('到', 'P61'), ('她', 'Nhaa'), ('家', 'Ncb'), ('等候', 'VK2'), ('按', 'VC2'), ('了', 'Di'), ('門鈴', 'Nab'), ('卻', 'Dbb'), ('沒有', 'VJ3'), ('任何', 'Neqa'), ('動靜',&nbsp;'Nad'), ('正當', 'P16'), ('我', 'Nhaa'), ('想', 'VE2'), ('離開', 'VC2')]</p>
   <p>我们来看看哪些标记是sinica_treebank库中最常见的。</p>
   <pre class="prettyprint hljs vim">words_tag = sinica_treebank.tagged_words(<span class="hljs-string">'parsed'</span>)tag_fd = nltk.FreqDist(<span class="hljs-keyword">tag</span> <span class="hljs-keyword">for</span> (word, <span class="hljs-keyword">tag</span>) in words_tag)tag_fd.tabulate(<span class="hljs-number">5</span>)</pre>
   <p>结果为:</p>
   <p>Nab DE Nac Nad VH11</p>
   <p>9520 7095 4478 3873 3722</p>
   <p>我们可以看到Nab标记出现了9520次。</p>
   <h2>总结</h2>
   <ul>
    <li><p class="no-text-indent">nltk.word_tokenize（text）：对指定的句子进行分词，返回单词列表</p></li>
    <li><p class="no-text-indent">nltk.pos_tag(words)：对指定的单词列表进行词性标记，返回标记列表</p></li>
    <li><p class="no-text-indent">CategorizedTaggedCorpusReader::tagged_words(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的单词列表</p></li>
    <li><p class="no-text-indent">CategorizedTaggedCorpusReader::tagged_sents(fileids, categories)：该方法接受文本标识或者类别标识作为参数，返回这些文本被标注词性后的句子列表，句子为单词列表</p></li>
    <li><p class="no-text-indent">SinicaTreebankCorpusReader::tagged_words(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的单词列表</p></li>
    <li><p class="no-text-indent">SinicaTreebankCorpusReader::tagged_sents(fileids)：该方法接受文本标识作为参数，返回文本被标注词性后的句子列表，句子为单词列表</p></li>
   </ul>
   <h3>其他章节链接</h3>
   <p><a href="http://www.burnelltek.com/blog/8658d836c36111e6841d00163e0c0e36" rel="nofollow" target="_blank">Python&nbsp;NLTK学习1（Text对象）</a></p>
   <p><a href="http://www.burnelltek.com/blog/e21021eec69411e6841d00163e0c0e36" rel="nofollow" target="_blank">Python&nbsp;NLTK学习2（FreqDist对象）</a></p>
   <p><a href="http://www.burnelltek.com/blog/0376c9eac69611e6841d00163e0c0e36" rel="nofollow" target="_blank">Python&nbsp;NLTK学习3（语料库）</a></p>
   <p><a href="http://www.burnelltek.com/blog/e08e0bbecb1811e6841d00163e0c0e36" rel="nofollow" target="_blank">Python&nbsp;NLTK学习4（条件频率分布）</a></p>
   <p>Python NLTK学习5（词性标注）</p>
   <p><a href="http://www.burnelltek.com/blog/60740e24d2f711e6841d00163e0c0e36" rel="nofollow" target="_blank">Python&nbsp;NLTK学习6（创建词性标注器）</a></p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  </div>
  <p>再分享一下我老师大神的人工智能教程吧。零基础！通俗易懂！风趣幽默！还带黄段子！希望你也加入到我们人工智能的队伍中来！<a href="https://blog.csdn.net/jiangjunshow/article/details/77338485" rel="nofollow">https://blog.csdn.net/jiangjunshow</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
