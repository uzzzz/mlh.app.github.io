<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Tensorflow+Keras入门——保存和恢复模型的方法学习 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Tensorflow+Keras入门——保存和恢复模型的方法学习" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="将训练的模型进行保存，或者利用已保存的模型给新模型“赋值”。本文参考Tensorflow官方文档之保存和恢复模型，对官方文档给出的代码进行了实践，并将我的理解加到了注释之中，希望能帮到有需要的人。 代码分成几个部分讲解： 1、导入必要的模块和加载数据集 Tensorflow官方文档依旧使用mnist数据集来进行新手教学，和mnist手写数字识别项目不同的是，此处只使用1000条数据以加快速度，毕竟我们的目的是学习保存和恢复模型。 from __future__ import absolute_import, division, print_function import os import tensorflow as tf from tensorflow import keras # 读取mnist数据集 (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data() # 为了加快速度，只使用1000条数据 train_labels = train_labels[:1000] test_labels = test_labels[:1000] train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0 # reshape中-1代表维数未知 test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0 2、构建并查看模型 自定义create_model()函数来定义模型。如果还没接触过Keras可以看这篇博客：https://blog.csdn.net/umbrellalalalala/article/details/86309633 def create_model(): model = tf.keras.models.Sequential([ keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)), keras.layers.Dropout(0.2), # 随机丢弃20%的神经元防止过拟合 keras.layers.Dense(10, activation=tf.nn.softmax) ]) # 指定优化函数、损失函数、评测方法 model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[&#39;accuracy&#39;]) return model layers.Dropout()用法： 随机丢弃指定比例的神经元以防止过拟合，如果是layers.Dropout(0)就是不丢弃，如果是layers.Dropout(1)则为丢弃全部神经元，会报错。 利用如下代码新建一个模型，并查看模型概况： model = create_model() model.summary() # 打印出模型概况，它实际调用的是keras.utils.print_summary 运行结果： _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 512) 401920 _________________________________________________________________ dropout (Dropout) (None, 512) 0 _________________________________________________________________ dense_1 (Dense) (None, 10) 5130 ================================================================= Total params: 407,050 Trainable params: 407,050 Non-trainable params: 0 _________________________________________________________________ Process finished with exit code 0 3、保存检查点【核心】 以下是官方文档代码的核心部分： ################################ #####以下是保存和恢复模型的部分##### ################################ checkpoint_path = &quot;study_checkpoint/cp.ckpt&quot; # 指定保存模型的文件，含文件的相对目录 checkpoint_dir = os.path.dirname(checkpoint_path) # os.path.dirname()作用是去掉文件名，返回文件目录 # 官网注释是Create checkpoint callback，checkpoint译为&quot;检查点&quot; cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1) # 利用自定义的构建神经网络的函数构建一个新的模型，并训练之 model = create_model() model.fit(train_images, train_labels, epochs = 10, validation_data = (test_images,test_labels), callbacks = [cp_callback]) # pass callback to training 如图，红色横线标注了我创建的源文件和保存模型的目录 点开study_checkpoint文件夹，可以看到模型被保存至以下的文件中： 用如下的代码来验证被保存的模型： # 创建一个新的model用于检测回调点 model = create_model() model.load_weights(checkpoint_path) # 直接从检查点加载权重 loss,acc = model.evaluate(test_images, test_labels) print(&quot;Restored model, loss: %f, accuracy: %.2f&quot; % (loss, 100*acc)) 运行结果： Restored model, loss: 0.430706, accuracy: 87.30 准确率只有87.30%，毕竟只使用了1000条数据，而之前博客达到的98%的正确率是使用了全部60000条数据才达到的。 4、保存整个模型 Keras使用HDF5标准保存整个模型，利用如下代码： model.save(&#39;study_checkpoint/model/my_model.h5&#39;) 运行成功，可以到相应文件夹下找到my_model.h5这个文件。 如果报错： ImportError: `save_model` requires h5py. 解决方法： pip install --upgrade h5py" />
<meta property="og:description" content="将训练的模型进行保存，或者利用已保存的模型给新模型“赋值”。本文参考Tensorflow官方文档之保存和恢复模型，对官方文档给出的代码进行了实践，并将我的理解加到了注释之中，希望能帮到有需要的人。 代码分成几个部分讲解： 1、导入必要的模块和加载数据集 Tensorflow官方文档依旧使用mnist数据集来进行新手教学，和mnist手写数字识别项目不同的是，此处只使用1000条数据以加快速度，毕竟我们的目的是学习保存和恢复模型。 from __future__ import absolute_import, division, print_function import os import tensorflow as tf from tensorflow import keras # 读取mnist数据集 (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data() # 为了加快速度，只使用1000条数据 train_labels = train_labels[:1000] test_labels = test_labels[:1000] train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0 # reshape中-1代表维数未知 test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0 2、构建并查看模型 自定义create_model()函数来定义模型。如果还没接触过Keras可以看这篇博客：https://blog.csdn.net/umbrellalalalala/article/details/86309633 def create_model(): model = tf.keras.models.Sequential([ keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)), keras.layers.Dropout(0.2), # 随机丢弃20%的神经元防止过拟合 keras.layers.Dense(10, activation=tf.nn.softmax) ]) # 指定优化函数、损失函数、评测方法 model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[&#39;accuracy&#39;]) return model layers.Dropout()用法： 随机丢弃指定比例的神经元以防止过拟合，如果是layers.Dropout(0)就是不丢弃，如果是layers.Dropout(1)则为丢弃全部神经元，会报错。 利用如下代码新建一个模型，并查看模型概况： model = create_model() model.summary() # 打印出模型概况，它实际调用的是keras.utils.print_summary 运行结果： _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 512) 401920 _________________________________________________________________ dropout (Dropout) (None, 512) 0 _________________________________________________________________ dense_1 (Dense) (None, 10) 5130 ================================================================= Total params: 407,050 Trainable params: 407,050 Non-trainable params: 0 _________________________________________________________________ Process finished with exit code 0 3、保存检查点【核心】 以下是官方文档代码的核心部分： ################################ #####以下是保存和恢复模型的部分##### ################################ checkpoint_path = &quot;study_checkpoint/cp.ckpt&quot; # 指定保存模型的文件，含文件的相对目录 checkpoint_dir = os.path.dirname(checkpoint_path) # os.path.dirname()作用是去掉文件名，返回文件目录 # 官网注释是Create checkpoint callback，checkpoint译为&quot;检查点&quot; cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1) # 利用自定义的构建神经网络的函数构建一个新的模型，并训练之 model = create_model() model.fit(train_images, train_labels, epochs = 10, validation_data = (test_images,test_labels), callbacks = [cp_callback]) # pass callback to training 如图，红色横线标注了我创建的源文件和保存模型的目录 点开study_checkpoint文件夹，可以看到模型被保存至以下的文件中： 用如下的代码来验证被保存的模型： # 创建一个新的model用于检测回调点 model = create_model() model.load_weights(checkpoint_path) # 直接从检查点加载权重 loss,acc = model.evaluate(test_images, test_labels) print(&quot;Restored model, loss: %f, accuracy: %.2f&quot; % (loss, 100*acc)) 运行结果： Restored model, loss: 0.430706, accuracy: 87.30 准确率只有87.30%，毕竟只使用了1000条数据，而之前博客达到的98%的正确率是使用了全部60000条数据才达到的。 4、保存整个模型 Keras使用HDF5标准保存整个模型，利用如下代码： model.save(&#39;study_checkpoint/model/my_model.h5&#39;) 运行成功，可以到相应文件夹下找到my_model.h5这个文件。 如果报错： ImportError: `save_model` requires h5py. 解决方法： pip install --upgrade h5py" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-14T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"将训练的模型进行保存，或者利用已保存的模型给新模型“赋值”。本文参考Tensorflow官方文档之保存和恢复模型，对官方文档给出的代码进行了实践，并将我的理解加到了注释之中，希望能帮到有需要的人。 代码分成几个部分讲解： 1、导入必要的模块和加载数据集 Tensorflow官方文档依旧使用mnist数据集来进行新手教学，和mnist手写数字识别项目不同的是，此处只使用1000条数据以加快速度，毕竟我们的目的是学习保存和恢复模型。 from __future__ import absolute_import, division, print_function import os import tensorflow as tf from tensorflow import keras # 读取mnist数据集 (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data() # 为了加快速度，只使用1000条数据 train_labels = train_labels[:1000] test_labels = test_labels[:1000] train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0 # reshape中-1代表维数未知 test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0 2、构建并查看模型 自定义create_model()函数来定义模型。如果还没接触过Keras可以看这篇博客：https://blog.csdn.net/umbrellalalalala/article/details/86309633 def create_model(): model = tf.keras.models.Sequential([ keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)), keras.layers.Dropout(0.2), # 随机丢弃20%的神经元防止过拟合 keras.layers.Dense(10, activation=tf.nn.softmax) ]) # 指定优化函数、损失函数、评测方法 model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=[&#39;accuracy&#39;]) return model layers.Dropout()用法： 随机丢弃指定比例的神经元以防止过拟合，如果是layers.Dropout(0)就是不丢弃，如果是layers.Dropout(1)则为丢弃全部神经元，会报错。 利用如下代码新建一个模型，并查看模型概况： model = create_model() model.summary() # 打印出模型概况，它实际调用的是keras.utils.print_summary 运行结果： _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense (Dense) (None, 512) 401920 _________________________________________________________________ dropout (Dropout) (None, 512) 0 _________________________________________________________________ dense_1 (Dense) (None, 10) 5130 ================================================================= Total params: 407,050 Trainable params: 407,050 Non-trainable params: 0 _________________________________________________________________ Process finished with exit code 0 3、保存检查点【核心】 以下是官方文档代码的核心部分： ################################ #####以下是保存和恢复模型的部分##### ################################ checkpoint_path = &quot;study_checkpoint/cp.ckpt&quot; # 指定保存模型的文件，含文件的相对目录 checkpoint_dir = os.path.dirname(checkpoint_path) # os.path.dirname()作用是去掉文件名，返回文件目录 # 官网注释是Create checkpoint callback，checkpoint译为&quot;检查点&quot; cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1) # 利用自定义的构建神经网络的函数构建一个新的模型，并训练之 model = create_model() model.fit(train_images, train_labels, epochs = 10, validation_data = (test_images,test_labels), callbacks = [cp_callback]) # pass callback to training 如图，红色横线标注了我创建的源文件和保存模型的目录 点开study_checkpoint文件夹，可以看到模型被保存至以下的文件中： 用如下的代码来验证被保存的模型： # 创建一个新的model用于检测回调点 model = create_model() model.load_weights(checkpoint_path) # 直接从检查点加载权重 loss,acc = model.evaluate(test_images, test_labels) print(&quot;Restored model, loss: %f, accuracy: %.2f&quot; % (loss, 100*acc)) 运行结果： Restored model, loss: 0.430706, accuracy: 87.30 准确率只有87.30%，毕竟只使用了1000条数据，而之前博客达到的98%的正确率是使用了全部60000条数据才达到的。 4、保存整个模型 Keras使用HDF5标准保存整个模型，利用如下代码： model.save(&#39;study_checkpoint/model/my_model.h5&#39;) 运行成功，可以到相应文件夹下找到my_model.h5这个文件。 如果报错： ImportError: `save_model` requires h5py. 解决方法： pip install --upgrade h5py","@type":"BlogPosting","url":"/2019/01/14/7333c2ed9c4b138e3117fe5c67e50564.html","headline":"Tensorflow+Keras入门——保存和恢复模型的方法学习","dateModified":"2019-01-14T00:00:00+08:00","datePublished":"2019-01-14T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/01/14/7333c2ed9c4b138e3117fe5c67e50564.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Tensorflow+Keras入门——保存和恢复模型的方法学习</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p>将训练的模型进行保存，或者利用已保存的模型给新模型“赋值”。本文参考<a href="https://tensorflow.google.cn/tutorials/keras/save_and_restore_models" rel="nofollow">Tensorflow官方文档之保存和恢复模型</a>，对官方文档给出的代码进行了实践，并将我的理解加到了注释之中，希望能帮到有需要的人。</p> 
  <p>代码分成几个部分讲解：</p> 
  <hr> 
  <h1><a id="1_6"></a>1、导入必要的模块和加载数据集</h1> 
  <p>Tensorflow官方文档依旧使用mnist数据集来进行新手教学，和mnist手写数字识别项目不同的是，此处只使用1000条数据以加快速度，毕竟我们的目的是学习保存和恢复模型。</p> 
  <pre><code>from __future__ import absolute_import, division, print_function

import os

import tensorflow as tf
from tensorflow import keras

# 读取mnist数据集
(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

# 为了加快速度，只使用1000条数据
train_labels = train_labels[:1000]
test_labels = test_labels[:1000]

train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0     # reshape中-1代表维数未知
test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0
</code></pre> 
  <hr> 
  <h1><a id="2_29"></a>2、构建并查看模型</h1> 
  <p>自定义create_model()函数来定义模型。如果还没接触过Keras可以看这篇博客：<a href="https://blog.csdn.net/umbrellalalalala/article/details/86309633" rel="nofollow">https://blog.csdn.net/umbrellalalalala/article/details/86309633</a></p> 
  <pre><code>def create_model():
  model = tf.keras.models.Sequential([
    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)),
    keras.layers.Dropout(0.2),      # 随机丢弃20%的神经元防止过拟合
    keras.layers.Dense(10, activation=tf.nn.softmax)
  ])
  
# 指定优化函数、损失函数、评测方法
  model.compile(optimizer=tf.keras.optimizers.Adam(),
                loss=tf.keras.losses.sparse_categorical_crossentropy,
                metrics=['accuracy'])

  return model
</code></pre> 
  <p><strong>layers.Dropout()用法</strong>：<br> 随机丢弃指定比例的神经元以防止过拟合，如果是<code>layers.Dropout(0)</code>就是不丢弃，如果是<code>layers.Dropout(1)</code>则为丢弃全部神经元，会报错。</p> 
  <p>利用如下代码新建一个模型，并查看模型概况：</p> 
  <pre><code>model = create_model()
model.summary()     # 打印出模型概况，它实际调用的是keras.utils.print_summary
</code></pre> 
  <p>运行结果：</p> 
  <pre><code>_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 512)               401920    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 10)                5130      
=================================================================
Total params: 407,050
Trainable params: 407,050
Non-trainable params: 0
_________________________________________________________________

Process finished with exit code 0
</code></pre> 
  <hr> 
  <h1><a id="3_77"></a>3、保存检查点【核心】</h1> 
  <p>以下是官方文档代码的核心部分：</p> 
  <pre><code>################################
#####以下是保存和恢复模型的部分#####
################################
checkpoint_path = "study_checkpoint/cp.ckpt"    # 指定保存模型的文件，含文件的相对目录
checkpoint_dir = os.path.dirname(checkpoint_path)   # os.path.dirname()作用是去掉文件名，返回文件目录

# 官网注释是Create checkpoint callback，checkpoint译为"检查点"
cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,
                                                 save_weights_only=True,
                                                 verbose=1)

# 利用自定义的构建神经网络的函数构建一个新的模型，并训练之
model = create_model()
model.fit(train_images, train_labels,  epochs = 10,
          validation_data = (test_images,test_labels),
          callbacks = [cp_callback])  # pass callback to training
</code></pre> 
  <p>如图，红色横线标注了我创建的源文件和保存模型的目录<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190114160856175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3VtYnJlbGxhbGFsYWxhbGE=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 点开<code>study_checkpoint</code>文件夹，可以看到模型被保存至以下的文件中：<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190114161008234.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3VtYnJlbGxhbGFsYWxhbGE=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 用如下的代码来验证被保存的模型：</p> 
  <pre><code># 创建一个新的model用于检测回调点
model = create_model()
model.load_weights(checkpoint_path)     # 直接从检查点加载权重
loss,acc = model.evaluate(test_images, test_labels)
print("Restored model, loss: %f, accuracy: %.2f" % (loss, 100*acc))
</code></pre> 
  <p>运行结果：</p> 
  <pre><code>Restored model, loss: 0.430706, accuracy: 87.30
</code></pre> 
  <p>准确率只有87.30%，毕竟只使用了1000条数据，而<a href="https://blog.csdn.net/umbrellalalalala/article/details/86309633" rel="nofollow">之前博客</a>达到的98%的正确率是使用了全部60000条数据才达到的。</p> 
  <hr> 
  <h1><a id="4_119"></a>4、保存整个模型</h1> 
  <p>Keras使用HDF5标准保存整个模型，利用如下代码：</p> 
  <pre><code>model.save('study_checkpoint/model/my_model.h5')
</code></pre> 
  <p>运行成功，可以到相应文件夹下找到<code>my_model.h5</code>这个文件。<br> 如果报错：</p> 
  <pre><code>ImportError: `save_model` requires h5py.
</code></pre> 
  <p>解决方法：</p> 
  <pre><code>pip install --upgrade h5py
</code></pre> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
