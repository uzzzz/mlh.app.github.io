<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>SPP-net详解(金字塔池化）（附代码实现） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="SPP-net详解(金字塔池化）（附代码实现）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：如使用此博客内容，请经过作者同意，谢谢 https://blog.csdn.net/qq_40994943/article/details/86479360 最近想弄透faster rcnn，觉得spp应该是非常重要的，先详细总结下： 为什么会有spp 先看下和传统分类的对比图 解释：可以看到传统的操作是先将原图crop（裁剪/变换，也就是类似resize操作），直接送入卷积层，然后进入全连接分类。那么问题就来了，随便一张图目标物体位置和大小不一样，crop肯定会影响特征的准确性啊，但是不crop成统一大小，提取的特征图大小就不一样，没法送进全连接层，那有没有可能不crop直接得到固定维度的特征图呢？ok，这就是spp作用，加入spp之后就不需要提前crop，直接任意图片送进来，把spp核心放在卷积层和全连接层之间就搞定了！ spp具体结构是咋样的？ 解释： 上图就是spp结构，从下往上看，第一步卷积提取特征图，第二步金字塔池化，第三步将池化结果送入全连接层。第二步具体啥样子，就是把原来的特征图分别分成44=16块，22=4块，11=1块(不变），总共21块，取每块的最大值作为代表，即每张特征图就有21维的参数，总共卷积出来256个特征图，则送入全连接层的维度就是21256。 可能有些人到这里还是不懂，分块啥又变成21维，太抽象了，其实放到代码上来说，就是对特征图进行不同步长的池化而已，分四块取每块的最大值不就是步长大点，让一张图只池化四次，这下懂了吧。 当然这里输出的21维是可变的，改步长等具体参数就好了 spp的代码实现 具体来看下代码实现： # -*- coding: utf-8 -*- import tensorflow as tf import numpy as np import pandas as pd def spp_layer(input_, levels=4, name = &#39;SPP_layer&#39;,pool_type = &#39;max_pool&#39;): &#39;&#39;&#39; Multiple Level SPP layer. Works for levels=[1, 2, 3, 6]. &#39;&#39;&#39; shape = input_.get_shape().as_list() with tf.variable_scope(name): for l in range(levels): #设置池化参数 l = l + 1 ksize = [1, np.ceil(shape[1]/ l + 1).astype(np.int32), np.ceil(shape[2] / l + 1).astype(np.int32), 1] strides = [1, np.floor(shape[1] / l + 1).astype(np.int32), np.floor(shape[2] / l + 1).astype(np.int32), 1] if pool_type == &#39;max_pool&#39;: pool = tf.nn.max_pool(input_, ksize=ksize, strides=strides, padding=&#39;SAME&#39;) pool = tf.reshape(pool,(shape[0],-1),) else : pool = tf.nn.avg_pool(input_, ksize=ksize, strides=strides, padding=&#39;SAME&#39;) pool = tf.reshape(pool,(shape[0],-1)) print(&quot;Pool Level {:}: shape {:}&quot;.format(l, pool.get_shape().as_list())) if l == 1： x_flatten = tf.reshape(pool,(shape[0],-1)) else: x_flatten = tf.concat((x_flatten,pool),axis=1) #四种尺度进行拼接 print(&quot;Pool Level {:}: shape {:}&quot;.format(l, x_flatten.get_shape().as_list())) # pool_outputs.append(tf.reshape(pool, [tf.shape(pool)[1], -1])) return x_flatten #x = tf.ones((4,16,16,3)) #x_sppl = spp_layer(x,4) refer https://www.jianshu.com/p/7f30b5935f3f https://blog.csdn.net/v1_vivian/article/details/73275259" />
<meta property="og:description" content="版权声明：如使用此博客内容，请经过作者同意，谢谢 https://blog.csdn.net/qq_40994943/article/details/86479360 最近想弄透faster rcnn，觉得spp应该是非常重要的，先详细总结下： 为什么会有spp 先看下和传统分类的对比图 解释：可以看到传统的操作是先将原图crop（裁剪/变换，也就是类似resize操作），直接送入卷积层，然后进入全连接分类。那么问题就来了，随便一张图目标物体位置和大小不一样，crop肯定会影响特征的准确性啊，但是不crop成统一大小，提取的特征图大小就不一样，没法送进全连接层，那有没有可能不crop直接得到固定维度的特征图呢？ok，这就是spp作用，加入spp之后就不需要提前crop，直接任意图片送进来，把spp核心放在卷积层和全连接层之间就搞定了！ spp具体结构是咋样的？ 解释： 上图就是spp结构，从下往上看，第一步卷积提取特征图，第二步金字塔池化，第三步将池化结果送入全连接层。第二步具体啥样子，就是把原来的特征图分别分成44=16块，22=4块，11=1块(不变），总共21块，取每块的最大值作为代表，即每张特征图就有21维的参数，总共卷积出来256个特征图，则送入全连接层的维度就是21256。 可能有些人到这里还是不懂，分块啥又变成21维，太抽象了，其实放到代码上来说，就是对特征图进行不同步长的池化而已，分四块取每块的最大值不就是步长大点，让一张图只池化四次，这下懂了吧。 当然这里输出的21维是可变的，改步长等具体参数就好了 spp的代码实现 具体来看下代码实现： # -*- coding: utf-8 -*- import tensorflow as tf import numpy as np import pandas as pd def spp_layer(input_, levels=4, name = &#39;SPP_layer&#39;,pool_type = &#39;max_pool&#39;): &#39;&#39;&#39; Multiple Level SPP layer. Works for levels=[1, 2, 3, 6]. &#39;&#39;&#39; shape = input_.get_shape().as_list() with tf.variable_scope(name): for l in range(levels): #设置池化参数 l = l + 1 ksize = [1, np.ceil(shape[1]/ l + 1).astype(np.int32), np.ceil(shape[2] / l + 1).astype(np.int32), 1] strides = [1, np.floor(shape[1] / l + 1).astype(np.int32), np.floor(shape[2] / l + 1).astype(np.int32), 1] if pool_type == &#39;max_pool&#39;: pool = tf.nn.max_pool(input_, ksize=ksize, strides=strides, padding=&#39;SAME&#39;) pool = tf.reshape(pool,(shape[0],-1),) else : pool = tf.nn.avg_pool(input_, ksize=ksize, strides=strides, padding=&#39;SAME&#39;) pool = tf.reshape(pool,(shape[0],-1)) print(&quot;Pool Level {:}: shape {:}&quot;.format(l, pool.get_shape().as_list())) if l == 1： x_flatten = tf.reshape(pool,(shape[0],-1)) else: x_flatten = tf.concat((x_flatten,pool),axis=1) #四种尺度进行拼接 print(&quot;Pool Level {:}: shape {:}&quot;.format(l, x_flatten.get_shape().as_list())) # pool_outputs.append(tf.reshape(pool, [tf.shape(pool)[1], -1])) return x_flatten #x = tf.ones((4,16,16,3)) #x_sppl = spp_layer(x,4) refer https://www.jianshu.com/p/7f30b5935f3f https://blog.csdn.net/v1_vivian/article/details/73275259" />
<link rel="canonical" href="https://mlh.app/2019/01/14/90552ddf7b9864f22a4a90a5be1a20fd.html" />
<meta property="og:url" content="https://mlh.app/2019/01/14/90552ddf7b9864f22a4a90a5be1a20fd.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-14T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：如使用此博客内容，请经过作者同意，谢谢 https://blog.csdn.net/qq_40994943/article/details/86479360 最近想弄透faster rcnn，觉得spp应该是非常重要的，先详细总结下： 为什么会有spp 先看下和传统分类的对比图 解释：可以看到传统的操作是先将原图crop（裁剪/变换，也就是类似resize操作），直接送入卷积层，然后进入全连接分类。那么问题就来了，随便一张图目标物体位置和大小不一样，crop肯定会影响特征的准确性啊，但是不crop成统一大小，提取的特征图大小就不一样，没法送进全连接层，那有没有可能不crop直接得到固定维度的特征图呢？ok，这就是spp作用，加入spp之后就不需要提前crop，直接任意图片送进来，把spp核心放在卷积层和全连接层之间就搞定了！ spp具体结构是咋样的？ 解释： 上图就是spp结构，从下往上看，第一步卷积提取特征图，第二步金字塔池化，第三步将池化结果送入全连接层。第二步具体啥样子，就是把原来的特征图分别分成44=16块，22=4块，11=1块(不变），总共21块，取每块的最大值作为代表，即每张特征图就有21维的参数，总共卷积出来256个特征图，则送入全连接层的维度就是21256。 可能有些人到这里还是不懂，分块啥又变成21维，太抽象了，其实放到代码上来说，就是对特征图进行不同步长的池化而已，分四块取每块的最大值不就是步长大点，让一张图只池化四次，这下懂了吧。 当然这里输出的21维是可变的，改步长等具体参数就好了 spp的代码实现 具体来看下代码实现： # -*- coding: utf-8 -*- import tensorflow as tf import numpy as np import pandas as pd def spp_layer(input_, levels=4, name = &#39;SPP_layer&#39;,pool_type = &#39;max_pool&#39;): &#39;&#39;&#39; Multiple Level SPP layer. Works for levels=[1, 2, 3, 6]. &#39;&#39;&#39; shape = input_.get_shape().as_list() with tf.variable_scope(name): for l in range(levels): #设置池化参数 l = l + 1 ksize = [1, np.ceil(shape[1]/ l + 1).astype(np.int32), np.ceil(shape[2] / l + 1).astype(np.int32), 1] strides = [1, np.floor(shape[1] / l + 1).astype(np.int32), np.floor(shape[2] / l + 1).astype(np.int32), 1] if pool_type == &#39;max_pool&#39;: pool = tf.nn.max_pool(input_, ksize=ksize, strides=strides, padding=&#39;SAME&#39;) pool = tf.reshape(pool,(shape[0],-1),) else : pool = tf.nn.avg_pool(input_, ksize=ksize, strides=strides, padding=&#39;SAME&#39;) pool = tf.reshape(pool,(shape[0],-1)) print(&quot;Pool Level {:}: shape {:}&quot;.format(l, pool.get_shape().as_list())) if l == 1： x_flatten = tf.reshape(pool,(shape[0],-1)) else: x_flatten = tf.concat((x_flatten,pool),axis=1) #四种尺度进行拼接 print(&quot;Pool Level {:}: shape {:}&quot;.format(l, x_flatten.get_shape().as_list())) # pool_outputs.append(tf.reshape(pool, [tf.shape(pool)[1], -1])) return x_flatten #x = tf.ones((4,16,16,3)) #x_sppl = spp_layer(x,4) refer https://www.jianshu.com/p/7f30b5935f3f https://blog.csdn.net/v1_vivian/article/details/73275259","@type":"BlogPosting","url":"https://mlh.app/2019/01/14/90552ddf7b9864f22a4a90a5be1a20fd.html","headline":"SPP-net详解(金字塔池化）（附代码实现）","dateModified":"2019-01-14T00:00:00+08:00","datePublished":"2019-01-14T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/01/14/90552ddf7b9864f22a4a90a5be1a20fd.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>SPP-net详解(金字塔池化）（附代码实现）</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：如使用此博客内容，请经过作者同意，谢谢 https://blog.csdn.net/qq_40994943/article/details/86479360 
 </div> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p>最近想弄透faster rcnn，觉得spp应该是非常重要的，先详细总结下：</p> 
  <p><strong>为什么会有spp</strong><br> 先看下和传统分类的对比图<br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190114155726135.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTk0OTQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 解释：可以看到传统的操作是先将原图crop（裁剪/变换，也就是类似resize操作），直接送入卷积层，然后进入全连接分类。那么问题就来了，随便一张图目标物体位置和大小不一样，crop肯定会影响特征的准确性啊，但是不crop成统一大小，提取的特征图大小就不一样，没法送进全连接层，那有没有可能不crop直接得到固定维度的特征图呢？ok，这就是spp作用，加入spp之后就不需要提前crop，直接任意图片送进来，把spp核心放在卷积层和全连接层之间就搞定了！</p> 
  <p><strong>spp具体结构是咋样的？</strong><br> <img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190114155553577.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwOTk0OTQz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 解释：<br> 上图就是spp结构，从下往上看，第一步卷积提取特征图，第二步金字塔池化，第三步将池化结果送入全连接层。第二步具体啥样子，就是把原来的特征图分别分成4<em>4=16块，2</em>2=4块，1<em>1=1块(不变），总共21块，取每块的最大值作为代表，即每张特征图就有21维的参数，总共卷积出来256个特征图，则送入全连接层的维度就是21</em>256。</p> 
  <p>可能有些人到这里还是不懂，分块啥又变成21维，太抽象了，其实放到代码上来说，就是对特征图进行不同步长的池化而已，分四块取每块的最大值不就是步长大点，让一张图只池化四次，这下懂了吧。</p> 
  <p>当然这里输出的21维是可变的，改步长等具体参数就好了</p> 
  <p><strong>spp的代码实现</strong><br> 具体来看下代码实现：</p> 
  <pre><code># -*- coding: utf-8 -*-
import tensorflow as tf
import numpy as np
import pandas as pd

def spp_layer(input_, levels=4, name = 'SPP_layer',pool_type = 'max_pool'):

    '''
    Multiple Level SPP layer.
    
    Works for levels=[1, 2, 3, 6].
    '''
    
    shape = input_.get_shape().as_list()
    
    with tf.variable_scope(name):

        for l in range(levels):
        #设置池化参数
            l = l + 1
            ksize = [1, np.ceil(shape[1]/ l + 1).astype(np.int32), np.ceil(shape[2] / l + 1).astype(np.int32), 1]
            strides = [1, np.floor(shape[1] / l + 1).astype(np.int32), np.floor(shape[2] / l + 1).astype(np.int32), 1]
            
            if pool_type == 'max_pool':
                pool = tf.nn.max_pool(input_, ksize=ksize, strides=strides, padding='SAME')
                pool = tf.reshape(pool,(shape[0],-1),)
                
            else :
                pool = tf.nn.avg_pool(input_, ksize=ksize, strides=strides, padding='SAME')
                pool = tf.reshape(pool,(shape[0],-1))
            print("Pool Level {:}: shape {:}".format(l, pool.get_shape().as_list()))
            if l == 1：
                x_flatten = tf.reshape(pool,(shape[0],-1))
            else:
                x_flatten = tf.concat((x_flatten,pool),axis=1) #四种尺度进行拼接
            print("Pool Level {:}: shape {:}".format(l, x_flatten.get_shape().as_list()))
            # pool_outputs.append(tf.reshape(pool, [tf.shape(pool)[1], -1]))
            

    return x_flatten


#x  = tf.ones((4,16,16,3))
#x_sppl = spp_layer(x,4)
</code></pre> 
  <p>refer <a href="https://www.jianshu.com/p/7f30b5935f3f" rel="nofollow">https://www.jianshu.com/p/7f30b5935f3f</a><br> <a href="https://blog.csdn.net/v1_vivian/article/details/73275259" rel="nofollow">https://blog.csdn.net/v1_vivian/article/details/73275259</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-7b4cdcb592.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
