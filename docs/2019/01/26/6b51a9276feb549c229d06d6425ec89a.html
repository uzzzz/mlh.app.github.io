<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>画一棵树，用来决策 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="画一棵树，用来决策" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Linux编程 点击右侧关注，免费入门到精通！ 作者丨程sirhttps://www.jianshu.com/p/5dc68059f2dd #决策树简介# 决策树（Decision Tree）是一种简单但是广泛使用的分类器。通过训练数据构建决策树，可以高效的对未知的数据进行分类。 决策数有两大优点：1）决策树模型可以读性好，具有描述性，有助于人工分析；2）效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。 决策树的主要算法有ID3，C4.5，CART。其中C4.5是对于ID3的优化。本周主要就是学习了ID3算法的过程，基于我自己编的一组数据： #基础概念-信息熵# 信息是个很抽象的概念。人们常常说信息很多，或者信息较少，但却很难说清楚信息到底有多少。比如一本五十万字的中文书到底有多少信息量。 直到1948年，香农提出了“信息熵”的概念，才解决了对信息的量化度量问题。香农从热力学中借用过来的。热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来描述信源的不确定度。 假如事件A的全概率划分是（A1,A2,...,An），每部分发生的概率是(p1,p2,...,pn)，那信息熵定义为： log通常以2为底数，所以信息熵的单位是bit。 #构造决策树-树根# 构造树的基本想法是随着树深度的增加，节点的熵迅速地降低。熵降低的速度越快越好，因为这样得到的树的高度最矮。让熵减小，就是说让确定性增加，也就是越来越能够做出判断。 我们的例子中，最开始如果病人的任何特征都不看，根据历史的数据，知道病人感冒的概率是1/2，过敏的概率1/6，脑震荡概率1/3。此时的熵为： E = -（1/2）×log（1/2）-（1/6）×log（1/6）-（1/3）×log（1/3）= 1.459然后看特征，病人的特征有三个，症状、职业、性别，我们要选择一个作为树根，先把原始6个病人情况做成一张表： 先看症状这个特征： 症状为“打喷嚏”的有3人，2个感冒，1个过敏，因此打喷嚏时，2/3概率感冒，1/3概率过敏，0概率脑震荡，此时熵为： -（2/3）×log（2/3）-（1/3）×log（1/3）= 0.918 症状为“头疼”的有3人，1个感冒，2个脑震荡，因此头疼时，1/3概率感冒，2/3概率脑震荡，0概率过敏，此时熵为： -（1/3）×log（1/3）-（2/3）×log（2/3）= 0.918 从整体看，一共6个人，3个打喷嚏，3个头疼，因此，打喷嚏和头疼的概率都是1/2所以已知特征“症状”的情况，总系统的信息熵为0.918×1/2+0.918×1/2 = 0.918，信息增益Gain（症状）=1.459-0.918= 0.541 再看“职业”这个特征： 职业为“护士”的有1人，1个感冒。因此职业为护士，1概率感冒，0概率其他病，熵为0 职业为“农民”的有1人，1个过敏。因此职业为农民，1概率过敏，0概率其他病，熵为0 职业为“工人”的有2人，1个感冒，1个脑震荡。因此职业为工人，1/2概率感冒，1/2概率脑震荡，0概率过敏，熵： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 职业为“教师”的有2人，1个感冒，1个脑震荡。因此职业为教师，1/2概率感冒，1/2概率脑震荡，0概率过敏，熵： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 从整体看，一共6个人，1护士，1农民，2工人，2教师，因此护士和农民的概率都是1/6，工人和教师概率都是1/3，所以已知特征“职业”的情况，总系统的信息熵为： 1/6 ×0 +1/6×0 +1/3×1+1/3×1=0.667， 信息增益Gain（职业）=1.459-0.667= 0.792 再看“性别”这个特征: 性别为“男”有2人，1过敏，1脑震荡，因此性别为男，1/2概率过敏，1/2概率脑震荡，0概率感冒，熵为： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 性别为“女”有4人，3个感冒，1个脑震荡，因此性别为女，3/4概率感冒，1/4概率脑震荡，熵为： -（3/4）×log（3/4）-（1/4）×log（1/4）= 0.811 从整体看，一共6个人，2男4女，因此男概率1/3，女概率2/3，已知性别的情况下，总系统的信息熵为 1×1/3+0.811×2/3=0.874 信息增益Gain（性别）=1.459-0.874=0.585 可见“职业”让总系统的信息熵下降的更快，决策树的根就是职业，如下图： &nbsp;&nbsp; 在护士和农民分支，刚才已经计算了熵为0，意味着已经没有任何不确定性了（给出的6个病人的数据也能看出来），可以直接判断病情。 #构造决策树-其他枝叶# 构造枝叶的方法和构造树根一样，只是考虑的病人的范围不同。 接下来确定N1，方法类似，现在只需要考虑职业为“工人”的这个子系统，还是列一个表： 刚才已经计算过，职业为工人的系统信息熵为1 先看症状这个特征: 症状为打喷嚏的没有，熵为0 症状为头疼的有2人，1人感冒，1人脑震荡，因此“头疼工人”里，1/2概率感冒，1/2概率脑震荡，熵为： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 总的系统信息熵为1，没有任何变化 再看性别这个特征 性别为男1人，是脑震荡，因此“男工人”里，脑震荡概率1，其他概率0，熵为0 性别为女1人，是感冒，因此“女工人”里，感冒概率1，其他概率0，熵为0 总的系统熵为0，把总系统熵一下降低为0 因此，N1就应该选择性别作为分支，然后分支的熵都为0了，也就都能确定病情了。 接下来确定N2，方法类似，现在只需要考虑职业为“教师”的这个子系统，还是列一个表： 这个表和计算N1的表数值上完全类似，计算过程不再赘述，最终N2选择症状，同时系统的熵降为0 每个分支的熵都为0，总系统的熵也就为0，决策树构造完毕，最终如图： #判定规则# 决策树比较直观，好理解，关键就在于构造完成之后可以演变成一条一条的判定规则。本例中： IF 职业为护士 THEN 感冒 IF 职业为农民 THEN 过敏 IF 职业为工人，性别为男 THEN 脑震荡 …… #其他# 构造过程中，可能发生属性用完还是没有最终判定的情况（也就是叶子节点还是有很多可能性），那么就选择最大可能性的判定作为判定（选判定结果最多的） 连续型数据的属性，ID3没法处理（个人理解也可以预先进行离散化操作，例如分段处理，然后在构造决策树） 决策树还有一个非常重要的问题是过度拟合，因为是100%按照给定的训练数据构造的树，训练数据中的噪音数据等都生成了特定的分支，应用的时候就会发生错误率很高的问题。对于决策树，必须要进行剪枝。 &nbsp;推荐↓↓↓&nbsp; 长 按 关 注 👉【16个技术公众号】都在这里！ 涵盖：程序员大咖、源码共读、程序员共读、数据结构与算法、黑客技术和网络安全、大数据科技、编程前端、Java、Python、Web编程开发、Android、iOS开发、Linux、数据库研发、幽默程序员等。 万水千山总是情，点个 “ 好看” 行不行" />
<meta property="og:description" content="Linux编程 点击右侧关注，免费入门到精通！ 作者丨程sirhttps://www.jianshu.com/p/5dc68059f2dd #决策树简介# 决策树（Decision Tree）是一种简单但是广泛使用的分类器。通过训练数据构建决策树，可以高效的对未知的数据进行分类。 决策数有两大优点：1）决策树模型可以读性好，具有描述性，有助于人工分析；2）效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。 决策树的主要算法有ID3，C4.5，CART。其中C4.5是对于ID3的优化。本周主要就是学习了ID3算法的过程，基于我自己编的一组数据： #基础概念-信息熵# 信息是个很抽象的概念。人们常常说信息很多，或者信息较少，但却很难说清楚信息到底有多少。比如一本五十万字的中文书到底有多少信息量。 直到1948年，香农提出了“信息熵”的概念，才解决了对信息的量化度量问题。香农从热力学中借用过来的。热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来描述信源的不确定度。 假如事件A的全概率划分是（A1,A2,...,An），每部分发生的概率是(p1,p2,...,pn)，那信息熵定义为： log通常以2为底数，所以信息熵的单位是bit。 #构造决策树-树根# 构造树的基本想法是随着树深度的增加，节点的熵迅速地降低。熵降低的速度越快越好，因为这样得到的树的高度最矮。让熵减小，就是说让确定性增加，也就是越来越能够做出判断。 我们的例子中，最开始如果病人的任何特征都不看，根据历史的数据，知道病人感冒的概率是1/2，过敏的概率1/6，脑震荡概率1/3。此时的熵为： E = -（1/2）×log（1/2）-（1/6）×log（1/6）-（1/3）×log（1/3）= 1.459然后看特征，病人的特征有三个，症状、职业、性别，我们要选择一个作为树根，先把原始6个病人情况做成一张表： 先看症状这个特征： 症状为“打喷嚏”的有3人，2个感冒，1个过敏，因此打喷嚏时，2/3概率感冒，1/3概率过敏，0概率脑震荡，此时熵为： -（2/3）×log（2/3）-（1/3）×log（1/3）= 0.918 症状为“头疼”的有3人，1个感冒，2个脑震荡，因此头疼时，1/3概率感冒，2/3概率脑震荡，0概率过敏，此时熵为： -（1/3）×log（1/3）-（2/3）×log（2/3）= 0.918 从整体看，一共6个人，3个打喷嚏，3个头疼，因此，打喷嚏和头疼的概率都是1/2所以已知特征“症状”的情况，总系统的信息熵为0.918×1/2+0.918×1/2 = 0.918，信息增益Gain（症状）=1.459-0.918= 0.541 再看“职业”这个特征： 职业为“护士”的有1人，1个感冒。因此职业为护士，1概率感冒，0概率其他病，熵为0 职业为“农民”的有1人，1个过敏。因此职业为农民，1概率过敏，0概率其他病，熵为0 职业为“工人”的有2人，1个感冒，1个脑震荡。因此职业为工人，1/2概率感冒，1/2概率脑震荡，0概率过敏，熵： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 职业为“教师”的有2人，1个感冒，1个脑震荡。因此职业为教师，1/2概率感冒，1/2概率脑震荡，0概率过敏，熵： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 从整体看，一共6个人，1护士，1农民，2工人，2教师，因此护士和农民的概率都是1/6，工人和教师概率都是1/3，所以已知特征“职业”的情况，总系统的信息熵为： 1/6 ×0 +1/6×0 +1/3×1+1/3×1=0.667， 信息增益Gain（职业）=1.459-0.667= 0.792 再看“性别”这个特征: 性别为“男”有2人，1过敏，1脑震荡，因此性别为男，1/2概率过敏，1/2概率脑震荡，0概率感冒，熵为： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 性别为“女”有4人，3个感冒，1个脑震荡，因此性别为女，3/4概率感冒，1/4概率脑震荡，熵为： -（3/4）×log（3/4）-（1/4）×log（1/4）= 0.811 从整体看，一共6个人，2男4女，因此男概率1/3，女概率2/3，已知性别的情况下，总系统的信息熵为 1×1/3+0.811×2/3=0.874 信息增益Gain（性别）=1.459-0.874=0.585 可见“职业”让总系统的信息熵下降的更快，决策树的根就是职业，如下图： &nbsp;&nbsp; 在护士和农民分支，刚才已经计算了熵为0，意味着已经没有任何不确定性了（给出的6个病人的数据也能看出来），可以直接判断病情。 #构造决策树-其他枝叶# 构造枝叶的方法和构造树根一样，只是考虑的病人的范围不同。 接下来确定N1，方法类似，现在只需要考虑职业为“工人”的这个子系统，还是列一个表： 刚才已经计算过，职业为工人的系统信息熵为1 先看症状这个特征: 症状为打喷嚏的没有，熵为0 症状为头疼的有2人，1人感冒，1人脑震荡，因此“头疼工人”里，1/2概率感冒，1/2概率脑震荡，熵为： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 总的系统信息熵为1，没有任何变化 再看性别这个特征 性别为男1人，是脑震荡，因此“男工人”里，脑震荡概率1，其他概率0，熵为0 性别为女1人，是感冒，因此“女工人”里，感冒概率1，其他概率0，熵为0 总的系统熵为0，把总系统熵一下降低为0 因此，N1就应该选择性别作为分支，然后分支的熵都为0了，也就都能确定病情了。 接下来确定N2，方法类似，现在只需要考虑职业为“教师”的这个子系统，还是列一个表： 这个表和计算N1的表数值上完全类似，计算过程不再赘述，最终N2选择症状，同时系统的熵降为0 每个分支的熵都为0，总系统的熵也就为0，决策树构造完毕，最终如图： #判定规则# 决策树比较直观，好理解，关键就在于构造完成之后可以演变成一条一条的判定规则。本例中： IF 职业为护士 THEN 感冒 IF 职业为农民 THEN 过敏 IF 职业为工人，性别为男 THEN 脑震荡 …… #其他# 构造过程中，可能发生属性用完还是没有最终判定的情况（也就是叶子节点还是有很多可能性），那么就选择最大可能性的判定作为判定（选判定结果最多的） 连续型数据的属性，ID3没法处理（个人理解也可以预先进行离散化操作，例如分段处理，然后在构造决策树） 决策树还有一个非常重要的问题是过度拟合，因为是100%按照给定的训练数据构造的树，训练数据中的噪音数据等都生成了特定的分支，应用的时候就会发生错误率很高的问题。对于决策树，必须要进行剪枝。 &nbsp;推荐↓↓↓&nbsp; 长 按 关 注 👉【16个技术公众号】都在这里！ 涵盖：程序员大咖、源码共读、程序员共读、数据结构与算法、黑客技术和网络安全、大数据科技、编程前端、Java、Python、Web编程开发、Android、iOS开发、Linux、数据库研发、幽默程序员等。 万水千山总是情，点个 “ 好看” 行不行" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-01-26T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"Linux编程 点击右侧关注，免费入门到精通！ 作者丨程sirhttps://www.jianshu.com/p/5dc68059f2dd #决策树简介# 决策树（Decision Tree）是一种简单但是广泛使用的分类器。通过训练数据构建决策树，可以高效的对未知的数据进行分类。 决策数有两大优点：1）决策树模型可以读性好，具有描述性，有助于人工分析；2）效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。 决策树的主要算法有ID3，C4.5，CART。其中C4.5是对于ID3的优化。本周主要就是学习了ID3算法的过程，基于我自己编的一组数据： #基础概念-信息熵# 信息是个很抽象的概念。人们常常说信息很多，或者信息较少，但却很难说清楚信息到底有多少。比如一本五十万字的中文书到底有多少信息量。 直到1948年，香农提出了“信息熵”的概念，才解决了对信息的量化度量问题。香农从热力学中借用过来的。热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来描述信源的不确定度。 假如事件A的全概率划分是（A1,A2,...,An），每部分发生的概率是(p1,p2,...,pn)，那信息熵定义为： log通常以2为底数，所以信息熵的单位是bit。 #构造决策树-树根# 构造树的基本想法是随着树深度的增加，节点的熵迅速地降低。熵降低的速度越快越好，因为这样得到的树的高度最矮。让熵减小，就是说让确定性增加，也就是越来越能够做出判断。 我们的例子中，最开始如果病人的任何特征都不看，根据历史的数据，知道病人感冒的概率是1/2，过敏的概率1/6，脑震荡概率1/3。此时的熵为： E = -（1/2）×log（1/2）-（1/6）×log（1/6）-（1/3）×log（1/3）= 1.459然后看特征，病人的特征有三个，症状、职业、性别，我们要选择一个作为树根，先把原始6个病人情况做成一张表： 先看症状这个特征： 症状为“打喷嚏”的有3人，2个感冒，1个过敏，因此打喷嚏时，2/3概率感冒，1/3概率过敏，0概率脑震荡，此时熵为： -（2/3）×log（2/3）-（1/3）×log（1/3）= 0.918 症状为“头疼”的有3人，1个感冒，2个脑震荡，因此头疼时，1/3概率感冒，2/3概率脑震荡，0概率过敏，此时熵为： -（1/3）×log（1/3）-（2/3）×log（2/3）= 0.918 从整体看，一共6个人，3个打喷嚏，3个头疼，因此，打喷嚏和头疼的概率都是1/2所以已知特征“症状”的情况，总系统的信息熵为0.918×1/2+0.918×1/2 = 0.918，信息增益Gain（症状）=1.459-0.918= 0.541 再看“职业”这个特征： 职业为“护士”的有1人，1个感冒。因此职业为护士，1概率感冒，0概率其他病，熵为0 职业为“农民”的有1人，1个过敏。因此职业为农民，1概率过敏，0概率其他病，熵为0 职业为“工人”的有2人，1个感冒，1个脑震荡。因此职业为工人，1/2概率感冒，1/2概率脑震荡，0概率过敏，熵： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 职业为“教师”的有2人，1个感冒，1个脑震荡。因此职业为教师，1/2概率感冒，1/2概率脑震荡，0概率过敏，熵： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 从整体看，一共6个人，1护士，1农民，2工人，2教师，因此护士和农民的概率都是1/6，工人和教师概率都是1/3，所以已知特征“职业”的情况，总系统的信息熵为： 1/6 ×0 +1/6×0 +1/3×1+1/3×1=0.667， 信息增益Gain（职业）=1.459-0.667= 0.792 再看“性别”这个特征: 性别为“男”有2人，1过敏，1脑震荡，因此性别为男，1/2概率过敏，1/2概率脑震荡，0概率感冒，熵为： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 性别为“女”有4人，3个感冒，1个脑震荡，因此性别为女，3/4概率感冒，1/4概率脑震荡，熵为： -（3/4）×log（3/4）-（1/4）×log（1/4）= 0.811 从整体看，一共6个人，2男4女，因此男概率1/3，女概率2/3，已知性别的情况下，总系统的信息熵为 1×1/3+0.811×2/3=0.874 信息增益Gain（性别）=1.459-0.874=0.585 可见“职业”让总系统的信息熵下降的更快，决策树的根就是职业，如下图： &nbsp;&nbsp; 在护士和农民分支，刚才已经计算了熵为0，意味着已经没有任何不确定性了（给出的6个病人的数据也能看出来），可以直接判断病情。 #构造决策树-其他枝叶# 构造枝叶的方法和构造树根一样，只是考虑的病人的范围不同。 接下来确定N1，方法类似，现在只需要考虑职业为“工人”的这个子系统，还是列一个表： 刚才已经计算过，职业为工人的系统信息熵为1 先看症状这个特征: 症状为打喷嚏的没有，熵为0 症状为头疼的有2人，1人感冒，1人脑震荡，因此“头疼工人”里，1/2概率感冒，1/2概率脑震荡，熵为： -（1/2）×log（1/2）-（1/2）×log（1/2）= 1 总的系统信息熵为1，没有任何变化 再看性别这个特征 性别为男1人，是脑震荡，因此“男工人”里，脑震荡概率1，其他概率0，熵为0 性别为女1人，是感冒，因此“女工人”里，感冒概率1，其他概率0，熵为0 总的系统熵为0，把总系统熵一下降低为0 因此，N1就应该选择性别作为分支，然后分支的熵都为0了，也就都能确定病情了。 接下来确定N2，方法类似，现在只需要考虑职业为“教师”的这个子系统，还是列一个表： 这个表和计算N1的表数值上完全类似，计算过程不再赘述，最终N2选择症状，同时系统的熵降为0 每个分支的熵都为0，总系统的熵也就为0，决策树构造完毕，最终如图： #判定规则# 决策树比较直观，好理解，关键就在于构造完成之后可以演变成一条一条的判定规则。本例中： IF 职业为护士 THEN 感冒 IF 职业为农民 THEN 过敏 IF 职业为工人，性别为男 THEN 脑震荡 …… #其他# 构造过程中，可能发生属性用完还是没有最终判定的情况（也就是叶子节点还是有很多可能性），那么就选择最大可能性的判定作为判定（选判定结果最多的） 连续型数据的属性，ID3没法处理（个人理解也可以预先进行离散化操作，例如分段处理，然后在构造决策树） 决策树还有一个非常重要的问题是过度拟合，因为是100%按照给定的训练数据构造的树，训练数据中的噪音数据等都生成了特定的分支，应用的时候就会发生错误率很高的问题。对于决策树，必须要进行剪枝。 &nbsp;推荐↓↓↓&nbsp; 长 按 关 注 👉【16个技术公众号】都在这里！ 涵盖：程序员大咖、源码共读、程序员共读、数据结构与算法、黑客技术和网络安全、大数据科技、编程前端、Java、Python、Web编程开发、Android、iOS开发、Linux、数据库研发、幽默程序员等。 万水千山总是情，点个 “ 好看” 行不行","@type":"BlogPosting","url":"/2019/01/26/6b51a9276feb549c229d06d6425ec89a.html","headline":"画一棵树，用来决策","dateModified":"2019-01-26T00:00:00+08:00","datePublished":"2019-01-26T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/01/26/6b51a9276feb549c229d06d6425ec89a.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>画一棵树，用来决策</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="rich_media_content" id="js_content"> 
   <p style="text-align:center;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/XUfq62QbuNhyG8Y9IxZUNMLyjv7k7dsq3bia9CRMmdkOM1WyLYEHlib4MFfrqRE97iaUqJ7NwhZEoHu0U8NCXWzsA/640?wx_fmt=gif" alt="640?wx_fmt=gif"></p>
   <p style="min-height:1em;text-align:center;"><a href="https://mp.weixin.qq.com/s?__biz=MzU2MzcxNzgwMg==&amp;mid=2247483650&amp;idx=3&amp;sn=7d8d32410010e2f58a8b0e9b15fa23ec&amp;scene=21#wechat_redirect" rel="nofollow"><span class="js_jump_icon h5_image_link"><img style="letter-spacing:.544px;text-align:justify;color:rgb(62,62,62);width:76px;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/XUfq62QbuNiaFZIbV1icByYIGKRlUcFt6IBMGhWJcyxibORgs6MEmSnJlA3ibibR7ibpudwZAbFZdqISttPaQTBkPPtQ/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></span></a></p>
   <a href="https://mp.weixin.qq.com/s?__biz=MzU2MzcxNzgwMg==&amp;mid=2247483650&amp;idx=3&amp;sn=7d8d32410010e2f58a8b0e9b15fa23ec&amp;scene=21#wechat_redirect" rel="nofollow"><span style="font-family:'宋体', SimSun;"><strong><span style="letter-spacing:.544px;color:rgb(31,73,125);"><strong>Linux编程</strong></span></strong></span></a>
   <span style="font-family:'黑体', SimHei;"><strong><span style="letter-spacing:.544px;color:rgb(31,73,125);"></span></strong><strong><span style="letter-spacing:.544px;color:rgb(31,73,125);"></span></strong><strong><span style="letter-spacing:.544px;color:rgb(31,73,125);"></span></strong></span>
   <a href="https://mp.weixin.qq.com/s?__biz=MzU2MzcxNzgwMg==&amp;mid=2247483650&amp;idx=3&amp;sn=7d8d32410010e2f58a8b0e9b15fa23ec&amp;scene=21#wechat_redirect" rel="nofollow"><span style="letter-spacing:.544px;color:rgb(165,165,165);font-family:'黑体', SimHei;"><span>点击右侧关注，免费入门到精通！</span></span></a>
   <a href="https://mp.weixin.qq.com/s?__biz=MzU2MzcxNzgwMg==&amp;mid=2247483650&amp;idx=3&amp;sn=7d8d32410010e2f58a8b0e9b15fa23ec&amp;scene=21#wechat_redirect" rel="nofollow"><span class="js_jump_icon h5_image_link"><img style="width:56px;" title="1081255447.jpg" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/XUfq62QbuNiaFZIbV1icByYIGKRlUcFt6IldAicZsKdD8KXBZkWQz1eHWULt7Sy2XUdKWbFt8oY6f6nL5deCuF9yg/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></span></a>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:14px;color:rgb(136,136,136);"><span style="font-size:14px;letter-spacing:1px;line-height:34.1333px;">作者丨程sir</span><br style="color:rgb(74,74,74);font-size:16px;letter-spacing:1px;line-height:34.1333px;"><span style="font-size:14px;letter-spacing:1px;line-height:34.1333px;">https://www.jianshu.com/p/5dc68059f2dd</span></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><span style="color:rgb(74,74,74);font-size:16px;letter-spacing:1px;line-height:34.1333px;"><br></span></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">#决策树简介#</span></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">决策树（Decision Tree）是一种简单但是广泛使用的分类器。通过训练数据构建决策树，可以高效的对未知的数据进行分类。</span><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>决策数有两大优点：1）决策树模型可以读性好，具有描述性，有助于人工分析；2）效率高，决策树只需要一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度。</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>决策树的主要算法有ID3，C4.5，CART。其中C4.5是对于ID3的优化。本周主要就是学习了ID3算法的过程，基于我自己编的一组数据：<br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz/LZqrxYJzgib0Ogctsaaf1kntfSNaD0VSXXXCn0J9NGf0Ko6zMVKSAlH8UZSkxuPPpMucibZw6BBfCOI95bIicQllQ/640?wx_fmt=other" alt="640?wx_fmt=other"></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">#基础概念-信息熵#</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>信息是个很抽象的概念。人们常常说信息很多，或者信息较少，但却很难说清楚信息到底有多少。比如一本五十万字的中文书到底有多少信息量。</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>直到1948年，香农提出了“信息熵”的概念，才解决了对信息的量化度量问题。香农从热力学中借用过来的。热力学中的热熵是表示分子状态混乱程度的物理量。香农用信息熵的概念来描述信源的不确定度。</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>假如事件A的全概率划分是（A1,A2,...,An），每部分发生的概率是(p1,p2,...,pn)，那信息熵定义为：<br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz/LZqrxYJzgib0Ogctsaaf1kntfSNaD0VSXiacX09rX4jxC1Nc7rvYKIPChibATFnFulpvnYYvpTQNasrb5EE9YxTHg/640?wx_fmt=other" alt="640?wx_fmt=other"></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">log通常以2为底数，所以信息熵的单位是bit。</span></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">#构造决策树-树根#</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>构造树的基本想法是随着树深度的增加，节点的熵迅速地降低。熵降低的速度越快越好，因为这样得到的树的高度最矮。让熵减小，就是说让确定性增加，也就是越来越能够做出判断。</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>我们的例子中，最开始如果病人的任何特征都不看，根据历史的数据，知道病人感冒的概率是1/2，过敏的概率1/6，脑震荡概率1/3。此时的熵为：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>E = -（1/2）×log（1/2）-（1/6）×log（1/6）-（1/3）×log（1/3）= 1.459<br>然后看特征，病人的特征有三个，症状、职业、性别，我们要选择一个作为树根，先把原始6个病人情况做成一张表：<br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz/LZqrxYJzgib0Ogctsaaf1kntfSNaD0VSXXiadvR4jumtCIAskCiaZ9YcJZPg1UFv1BCkmtBIMSrGLczvrbyeWLDHQ/640?wx_fmt=other" alt="640?wx_fmt=other"></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">先看症状这个特征：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>症状为“打喷嚏”的有3人，2个感冒，1个过敏，因此打喷嚏时，2/3概率感冒，1/3概率过敏，0概率脑震荡，此时熵为：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>-（2/3）×log（2/3）-（1/3）×log（1/3）= 0.918</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>症状为“头疼”的有3人，1个感冒，2个脑震荡，因此头疼时，1/3概率感冒，2/3概率脑震荡，0概率过敏，此时熵为：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>-（1/3）×log（1/3）-（2/3）×log（2/3）= 0.918</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>从整体看，一共6个人，3个打喷嚏，3个头疼，因此，打喷嚏和头疼的概率都是1/2<br>所以已知特征“症状”的情况，总系统的信息熵为0.918×1/2+0.918×1/2 = 0.918，<br>信息增益Gain（症状）=1.459-0.918= 0.541</span></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">再看“职业”这个特征：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>职业为“护士”的有1人，1个感冒。因此职业为护士，1概率感冒，0概率其他病，熵为0</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>职业为“农民”的有1人，1个过敏。因此职业为农民，1概率过敏，0概率其他病，熵为0</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>职业为“工人”的有2人，1个感冒，1个脑震荡。因此职业为工人，1/2概率感冒，1/2概率脑震荡，0概率过敏，熵：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>-（1/2）×log（1/2）-（1/2）×log（1/2）= 1</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>职业为“教师”的有2人，1个感冒，1个脑震荡。因此职业为教师，1/2概率感冒，1/2概率脑震荡，0概率过敏，熵：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>-（1/2）×log（1/2）-（1/2）×log（1/2）= 1</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>从整体看，一共6个人，1护士，1农民，2工人，2教师，因此护士和农民的概率都是1/6，工人和教师概率都是1/3，所以已知特征“职业”的情况，总系统的信息熵为：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>1/6 ×0 +1/6×0 +1/3×1+1/3×1=0.667，</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>信息增益Gain（职业）=1.459-0.667= 0.792</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">再看“性别”这个特征:</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>性别为“男”有2人，1过敏，1脑震荡，因此性别为男，1/2概率过敏，1/2概率脑震荡，0概率感冒，熵为：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>-（1/2）×log（1/2）-（1/2）×log（1/2）= 1</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>性别为“女”有4人，3个感冒，1个脑震荡，因此性别为女，3/4概率感冒，1/4概率脑震荡，熵为：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>-（3/4）×log（3/4）-（1/4）×log（1/4）= 0.811</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>从整体看，一共6个人，2男4女，因此男概率1/3，女概率2/3，已知性别的情况下，总系统的信息熵为</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>1×1/3+0.811×2/3=0.874</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>信息增益Gain（性别）=1.459-0.874=0.585</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">可见“职业”让总系统的信息熵下降的更快，决策树的根就是职业，如下图：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">&nbsp;&nbsp;</span></p>
   <p style="letter-spacing:1px;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz/LZqrxYJzgib0Ogctsaaf1kntfSNaD0VSX84oia8USvWBmgvQGH59dQc0PpibkcCFjdoVOLBGicCuTFAHpLJRg0bh3g/640?wx_fmt=other" alt="640?wx_fmt=other"></p>
   <p style="letter-spacing:1px;"><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">在护士和农民分支，刚才已经计算了熵为0，意味着已经没有任何不确定性了（给出的6个病人的数据也能看出来），可以直接判断病情。</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">#构造决策树-其他枝叶#</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>构造枝叶的方法和构造树根一样，只是考虑的病人的范围不同。</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>接下来确定N1，方法类似，现在只需要考虑职业为“工人”的这个子系统，还是列一个表：<br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz/LZqrxYJzgib0Ogctsaaf1kntfSNaD0VSXKe2X9Fjcs2Dzh9BmvRlibTZXsGmPGos1ba4PR9Zop7dvbq9omZJ68Ng/640?wx_fmt=other" alt="640?wx_fmt=other"></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">刚才已经计算过，职业为工人的系统信息熵为1</span></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">先看症状这个特征:</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>症状为打喷嚏的没有，熵为0</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>症状为头疼的有2人，1人感冒，1人脑震荡，因此“头疼工人”里，1/2概率感冒，1/2概率脑震荡，熵为：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>-（1/2）×log（1/2）-（1/2）×log（1/2）= 1</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>总的系统信息熵为1，没有任何变化</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">再看性别这个特征</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>性别为男1人，是脑震荡，因此“男工人”里，脑震荡概率1，其他概率0，熵为0</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>性别为女1人，是感冒，因此“女工人”里，感冒概率1，其他概率0，熵为0</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>总的系统熵为0，把总系统熵一下降低为0</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">因此，N1就应该选择性别作为分支，然后分支的熵都为0了，也就都能确定病情了。</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">接下来确定N2，方法类似，现在只需要考虑职业为“教师”的这个子系统，还是列一个表：<br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz/LZqrxYJzgib0Ogctsaaf1kntfSNaD0VSXZunzhpnEghdZztcPDgqRlCW4D3gZTl1icCXIDS84Vsj8lCZowfiaIqEw/640?wx_fmt=other" alt="640?wx_fmt=other"></p>
   <p style="letter-spacing:1px;"><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">这个表和计算N1的表数值上完全类似，计算过程不再赘述，最终N2选择症状，同时系统的熵降为0</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>每个分支的熵都为0，总系统的熵也就为0，决策树构造完毕，最终如图：<br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz/LZqrxYJzgib0Ogctsaaf1kntfSNaD0VSX8UgIGAccRMb32ViczVujUXgLzgjWAlr5y6T2LohMIVibntp6fcBmOrrQ/640?wx_fmt=other" alt="640?wx_fmt=other"></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">#判定规则#</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>决策树比较直观，好理解，关键就在于构造完成之后可以演变成一条一条的判定规则。本例中：</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>IF 职业为护士 THEN 感冒</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>IF 职业为农民 THEN 过敏</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>IF 职业为工人，性别为男 THEN 脑震荡</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>……</span></p>
   <p><br></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(0,82,255);"><img class="__bg_gif" style="font-size:8px;color:rgb(0,128,255);font-family:'宋体';text-align:center;vertical-align:middle;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/IwiaNBuWUDUw4OUxv50sClowAsFgibBOT8DicW3x9nlUu6buibjSVPyf3vst4EuG4dZOZcB2P62icZnyEMeP8eqoYog/640?wx_fmt=gif" alt="640?wx_fmt=gif">#其他#</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br>构造过程中，可能发生属性用完还是没有最终判定的情况（也就是叶子节点还是有很多可能性），那么就选择最大可能性的判定作为判定（选判定结果最多的）</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">连续型数据的属性，ID3没法处理（个人理解也可以预先进行离散化操作，例如分段处理，然后在构造决策树）</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);">决策树还有一个非常重要的问题是过度拟合，因为是100%按照给定的训练数据构造的树，训练数据中的噪音数据等都生成了特定的分支，应用的时候就会发生错误率很高的问题。对于决策树，必须要进行剪枝。</span></p>
   <p style="letter-spacing:1px;"><span style="font-size:16px;color:rgb(74,74,74);"><br></span></p>
   <p style="text-align:center;letter-spacing:1.5px;"><span style="color:rgb(255,255,255);"><strong><span style="font-size:20px;">&nbsp;推荐↓↓↓&nbsp;</span></strong></span></p>
   <img style="vertical-align:middle;width:313px;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/IwiaNBuWUDUzX3vMCt57DzWD1FUkicYK3C3VObzhyt4YU3rXujLwMXHoHqpB6B72h44DNib9J9jbQHk3giaxAeABWg/640?wx_fmt=png" alt="640?wx_fmt=png">
   <p><strong>长</strong></p>
   <p><strong>按</strong></p>
   <p><strong>关</strong></p>
   <p><strong>注</strong></p>
   <p style="letter-spacing:0px;"><strong><span style="font-size:18px;">👉</span></strong><span style="font-size:17px;"><strong>【</strong></span><a href="https://mp.weixin.qq.com/s?__biz=MzUzMDc0NzU4Nw==&amp;mid=2247483768&amp;idx=1&amp;sn=4ef4f1510616baa395c507e32bb439d7&amp;scene=21#wechat_redirect" rel="nofollow" style="text-decoration:underline;color:rgb(255,79,121);font-size:17px;"><span style="color:rgb(255,79,121);font-size:17px;"><strong>16个技术公众号</strong></span></a><span style="font-size:17px;"><strong>】都在这里！</strong></span></p>
   <p><span style="color:rgb(136,136,136);font-size:15px;">涵盖：程序员大咖、源码共读、程序员共读、数据结构与算法、黑客技术和网络安全、大数据科技、编程前端、Java、Python、Web编程开发、Android、iOS开发、Linux、数据库研发、幽默程序员等。</span></p>
   <img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/ol72Wnba7fLkfGhCjKwHfZOmHMkVTIomtmHARHGo86u52ZIGicxfPPFBQ85dBUWf3trqDHPUuN7E2e26DpvfJdQ/640?wx_fmt=png" alt="640?wx_fmt=png">万水千山总是情，点个 “
   <strong><span style="color:rgb(0,112,192);">好看</span></strong>” 行不行
  </div> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
