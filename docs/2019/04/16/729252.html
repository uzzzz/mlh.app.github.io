<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>大规模分布式图学习框架Euler | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="大规模分布式图学习框架Euler" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="最近在调研graph embedding图机器学习算法，尝试了DeepWalk在推荐场景应用，碰到构造大规模节点，模型跑不下来问题。 阿里妈妈刚开源大规模分布式图学习框架Euler，其配合TensorFlow或者阿里开源XDL等深度学习工具，支持用户在数十亿点数百亿边的复杂异构图上进行模型训练。为graph embedding在推荐场景落地提供参考。 一、Euler介绍 https://github.com/alibaba/euler 1. 框架 Euler系统分为最底层的分布式图引擎，中间层图语义的算子，高层的图表示学习算法。如下图所示 2. 应用 2.1 大规模图的分布式学习 工业界的图往往具有数十亿节点和数百亿边，有些场景甚至可以到数百亿节点和数千亿边，在这样规模的图上单机训练是不可行的。Euler支持图分割和高效稳定的分布式训练，可以轻松支撑数十亿点、数百亿边的计算规模。 2.2 支持复杂异构图的表征 工业界的图关系大都错综复杂，体现在节点异构、边关系异构，另外节点和边上可能有非常丰富的属性，这使得一些常见的图神经网络很难学到有效的表达。Euler在图结构存储和图计算的抽象上均良好的支持异构点、异构边类型的操作，并支持丰富的异构属性，可以很容易的在图学习算法中进行异构图的表征学习。 2.3 图学习与深度学习的结合 工业界有很多经典场景，例如搜索／推荐／广告场景，传统的深度学习方法有不错效果，如何把图学习和传统方法结合起来，进一步提升模型能力是很值得探索的。Euler支持基于深度学习样本的mini-batch训练，把图表征直接输入到深度学习网络中联合训练。 2.4 分层抽象与灵活扩展 Euler系统抽象为图引擎层、图操作算子层、算法实现层三个层次，可以快速的在高层扩展一个图学习算法。实际上，Euler也内置了大量的算法实现供大家直接使用。 3. 内置算法 名称&nbsp;&nbsp; &nbsp;算法类型&nbsp;&nbsp; &nbsp;是否自研&nbsp;&nbsp; &nbsp;特点 DeepWalk&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;经典的无偏随机游走无监督算法 Node2Vec&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;利用可配置参数在游走时可倾向BFS或DFS LINE&nbsp;&nbsp; &nbsp;其它&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;灵活利用1阶，2阶邻居信息的无监督算法 GCN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;CNN操作类似推广到非欧空间的算法 GraphSAGE&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;GCN改进，提出邻居采样，多种汇聚函数等 GAT&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;将Attention技术用于邻居汇聚 LsHNE&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;异构图中随机游走，利用深度网络编码 LasGNN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;半监督大规模异构图卷积网络学习方法 Scalable-GCN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;加速GCN训练的一种方法 二、Euler安装 1. 编译 Euler的编译和启动依赖libhdfs.so和libjvm.so存在于$LD_LIBRARY_PATH中，因此需要添加环境变量如下 sudo vi ~/.bashrc # 添加环境变量&nbsp; # ${JAVA_HOME}=/opt/modules/jdk1.8.0_172/jre # ${HADOOP_HOME}=/opt/modules/hadoop-2.7.7 &nbsp; export LD_LIBRARY_PATH=/opt/modules/jdk1.8.0_172/jre/lib/server:$LD_LIBRARY_PATH export LIBRARY_PATH=/opt/modules/hadoop-2.7.7/lib/native:$LIBRARY_PATH export LD_LIBRARY_PATH=/opt/modules/hadoop-2.7.7/lib/native:$LD_LIBRARY_PATH export CLASSPATH=$(/opt/modules/hadoop-2.7.7/bin/hadoop classpath --glob):$CLASSPATH 2. Euler安装&nbsp; Euler目前仅支持Python2，可以选择从PyPI或者源码编译安装Euler，推荐PyPI安装。 2.1 PyPI安装 目前PyPI上的wheel基于TensorFlow 1.12编译，仅能与TensorFlow 1.12二进制兼容。如需使用其他版本的TensorFlow需要重新编译。 pip install euler-gl 2.2 源码编译安装 git clone --recursive https://github.com/alibaba/euler.git 递归third_party失败，没有采用该方法安装。 三、GraphSage模型训练 GraphSage是由Stanford提出的一种Inductive的图学习方法，具有GCN模型的良好性质，同时在实际使用中可以扩展到十亿顶点的大规模图。接下来尝试使用Euler和TensorFlow进行GraphSage模型训练。 1. PPI数据 准备Euler引擎可以读取的图数据，这里我们以PPI（Protein-Protein Interactions）为例： curl -k -O https://raw.githubusercontent.com/alibaba/euler/master/examples/ppi_data.py pip install networkx==1.11 sklearn python ppi_data.py 在当前目录下生成一个ppi目录（如下），其中包含构建好的PPI图数据。&nbsp; ppi ├── ppi-class_map.json ├── ppi_data.dat ├── ppi_data.json ├── ppi-feats.npy ├── ppi-G.json ├── ppi-id_map.json ├── ppi_meta.json ├── ppi_test.id ├── ppi_train.id ├── ppi_val.id └── ppi-walks.txt 2. 模型训练 在训练集上训练一个半监督的GraphSage模型： python -m tf_euler \ &nbsp; --data_dir ppi \ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \ &nbsp; --model graphsage_supervised --mode train 在当前目录生成一个ckpt目录（如下），其中包含训练好的TensorFlow模型。 ckpt/ ├── checkpoint ├── events.out.tfevents.1548073220.lee ├── graph.pbtxt ├── model.ckpt-0.data-00000-of-00001 ├── model.ckpt-0.index ├── model.ckpt-0.meta ├── model.ckpt-2220.data-00000-of-00001 ├── model.ckpt-2220.index ├── model.ckpt-2220.meta └── timeline-2209.json 3. 模型评估 在测试集上评估模型的效果： python -m tf_euler \ &nbsp; --data_dir ppi --id_file ppi/ppi_test.id \ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \ &nbsp; --model graphsage_supervised --mode evaluate 使用Euler算法包默认参数训练得到的模型在测试集上的mirco-F1 score大概在0.6左右。&nbsp; 4. embedding输出 导出顶点的embedding python -m tf_euler \ &nbsp; --data_dir ppi \ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \ &nbsp; --model graphsage_supervised --mode save_embedding 在当下目录下的ckpt目录中生成一个embedding.npy文件和一个id.txt文件，分别表示图中所有顶点的embedding和id。 &nbsp;四、GraphSage模型分布式训练 1. 分布式训练 Euler算法包及其底层的图查询引擎支持分布式的模型训练，用户需要在原始的训练命令上加入四个参数--ps_hosts、--worker_hosts、--job_name、--task_index指定分布式角色。如下提供脚本在本机的1998至2001端口上启动两个ps和两个worker进行分布式训练。 #!/usr/bin/env bash NUM_PSES=2 NUM_WORKERS=2 &nbsp; PS_HOSTS=&quot;&quot; for I in $(seq $(($NUM_PSES - 1)) -1 0) do &nbsp; PS_HOST=&quot;localhost:$((1999 - $I))&quot; &nbsp; if [ &quot;$PS_HOSTS&quot; == &quot;&quot; ]; then &nbsp; &nbsp; PS_HOSTS=&quot;$PS_HOST&quot; &nbsp; else &nbsp; &nbsp; PS_HOSTS=&quot;$PS_HOSTS,$PS_HOST&quot; &nbsp; fi done &nbsp; WORKER_HOSTS=&quot;&quot; for I in $(seq 0 $(($NUM_WORKERS - 1))) do &nbsp; WORKER_HOST=&quot;localhost:$((2000 + $I))&quot; &nbsp; if [ &quot;$WORKER_HOSTS&quot; == &quot;&quot; ]; then &nbsp; &nbsp; WORKER_HOSTS=&quot;$WORKER_HOST&quot; &nbsp; else &nbsp; &nbsp; WORKER_HOSTS=&quot;$WORKER_HOSTS,$WORKER_HOST&quot; &nbsp; fi done &nbsp; for I in $(seq 0 $(($NUM_PSES - 1))) do &nbsp; python -m tf_euler \ &nbsp; &nbsp; --ps_hosts=$PS_HOSTS \ &nbsp; &nbsp; --worker_hosts=$WORKER_HOSTS \ &nbsp; &nbsp; --job_name=ps --task_index=$I &amp;&gt; /tmp/log.ps.$I &amp; done &nbsp; for I in $(seq 0 $(($NUM_WORKERS - 1))) do &nbsp; python -m tf_euler \ &nbsp; &nbsp; --ps_hosts=$PS_HOSTS \ &nbsp; &nbsp; --worker_hosts=$WORKER_HOSTS \ &nbsp; &nbsp; --job_name=worker --task_index=$I $@ &amp;&gt; /tmp/log.worker.$I &amp; &nbsp; WORKERS[$I]=$! done &nbsp; trap &#39;kill $(jobs -p) 2&gt; /dev/null; exit&#39; SIGINT SIGTERM &nbsp; wait ${WORKERS[*]} &nbsp; kill $(jobs -p) 2&gt; /dev/null 2. 启动 使用分布式训练时，数据需要放置在HDFS上。 hdfs dfs -mkdir /data hdfs dfs -put ppi /data/ 启动脚本如下，进行分布式训练。 bash scripts/dist_tf_euler.sh \ &nbsp; --data_dir hdfs://lee:8020/data/ppi \ &nbsp; --euler_zk_addr lee:2181 \ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \ &nbsp; --model graphsage_supervised --mode train 参考资料 https://blog.csdn.net/baymax_007/article/details/86093856 https://yq.aliyun.com/articles/625340&nbsp; https://github.com/alibaba/euler &nbsp;" />
<meta property="og:description" content="最近在调研graph embedding图机器学习算法，尝试了DeepWalk在推荐场景应用，碰到构造大规模节点，模型跑不下来问题。 阿里妈妈刚开源大规模分布式图学习框架Euler，其配合TensorFlow或者阿里开源XDL等深度学习工具，支持用户在数十亿点数百亿边的复杂异构图上进行模型训练。为graph embedding在推荐场景落地提供参考。 一、Euler介绍 https://github.com/alibaba/euler 1. 框架 Euler系统分为最底层的分布式图引擎，中间层图语义的算子，高层的图表示学习算法。如下图所示 2. 应用 2.1 大规模图的分布式学习 工业界的图往往具有数十亿节点和数百亿边，有些场景甚至可以到数百亿节点和数千亿边，在这样规模的图上单机训练是不可行的。Euler支持图分割和高效稳定的分布式训练，可以轻松支撑数十亿点、数百亿边的计算规模。 2.2 支持复杂异构图的表征 工业界的图关系大都错综复杂，体现在节点异构、边关系异构，另外节点和边上可能有非常丰富的属性，这使得一些常见的图神经网络很难学到有效的表达。Euler在图结构存储和图计算的抽象上均良好的支持异构点、异构边类型的操作，并支持丰富的异构属性，可以很容易的在图学习算法中进行异构图的表征学习。 2.3 图学习与深度学习的结合 工业界有很多经典场景，例如搜索／推荐／广告场景，传统的深度学习方法有不错效果，如何把图学习和传统方法结合起来，进一步提升模型能力是很值得探索的。Euler支持基于深度学习样本的mini-batch训练，把图表征直接输入到深度学习网络中联合训练。 2.4 分层抽象与灵活扩展 Euler系统抽象为图引擎层、图操作算子层、算法实现层三个层次，可以快速的在高层扩展一个图学习算法。实际上，Euler也内置了大量的算法实现供大家直接使用。 3. 内置算法 名称&nbsp;&nbsp; &nbsp;算法类型&nbsp;&nbsp; &nbsp;是否自研&nbsp;&nbsp; &nbsp;特点 DeepWalk&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;经典的无偏随机游走无监督算法 Node2Vec&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;利用可配置参数在游走时可倾向BFS或DFS LINE&nbsp;&nbsp; &nbsp;其它&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;灵活利用1阶，2阶邻居信息的无监督算法 GCN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;CNN操作类似推广到非欧空间的算法 GraphSAGE&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;GCN改进，提出邻居采样，多种汇聚函数等 GAT&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;将Attention技术用于邻居汇聚 LsHNE&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;异构图中随机游走，利用深度网络编码 LasGNN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;半监督大规模异构图卷积网络学习方法 Scalable-GCN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;加速GCN训练的一种方法 二、Euler安装 1. 编译 Euler的编译和启动依赖libhdfs.so和libjvm.so存在于$LD_LIBRARY_PATH中，因此需要添加环境变量如下 sudo vi ~/.bashrc # 添加环境变量&nbsp; # ${JAVA_HOME}=/opt/modules/jdk1.8.0_172/jre # ${HADOOP_HOME}=/opt/modules/hadoop-2.7.7 &nbsp; export LD_LIBRARY_PATH=/opt/modules/jdk1.8.0_172/jre/lib/server:$LD_LIBRARY_PATH export LIBRARY_PATH=/opt/modules/hadoop-2.7.7/lib/native:$LIBRARY_PATH export LD_LIBRARY_PATH=/opt/modules/hadoop-2.7.7/lib/native:$LD_LIBRARY_PATH export CLASSPATH=$(/opt/modules/hadoop-2.7.7/bin/hadoop classpath --glob):$CLASSPATH 2. Euler安装&nbsp; Euler目前仅支持Python2，可以选择从PyPI或者源码编译安装Euler，推荐PyPI安装。 2.1 PyPI安装 目前PyPI上的wheel基于TensorFlow 1.12编译，仅能与TensorFlow 1.12二进制兼容。如需使用其他版本的TensorFlow需要重新编译。 pip install euler-gl 2.2 源码编译安装 git clone --recursive https://github.com/alibaba/euler.git 递归third_party失败，没有采用该方法安装。 三、GraphSage模型训练 GraphSage是由Stanford提出的一种Inductive的图学习方法，具有GCN模型的良好性质，同时在实际使用中可以扩展到十亿顶点的大规模图。接下来尝试使用Euler和TensorFlow进行GraphSage模型训练。 1. PPI数据 准备Euler引擎可以读取的图数据，这里我们以PPI（Protein-Protein Interactions）为例： curl -k -O https://raw.githubusercontent.com/alibaba/euler/master/examples/ppi_data.py pip install networkx==1.11 sklearn python ppi_data.py 在当前目录下生成一个ppi目录（如下），其中包含构建好的PPI图数据。&nbsp; ppi ├── ppi-class_map.json ├── ppi_data.dat ├── ppi_data.json ├── ppi-feats.npy ├── ppi-G.json ├── ppi-id_map.json ├── ppi_meta.json ├── ppi_test.id ├── ppi_train.id ├── ppi_val.id └── ppi-walks.txt 2. 模型训练 在训练集上训练一个半监督的GraphSage模型： python -m tf_euler \ &nbsp; --data_dir ppi \ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \ &nbsp; --model graphsage_supervised --mode train 在当前目录生成一个ckpt目录（如下），其中包含训练好的TensorFlow模型。 ckpt/ ├── checkpoint ├── events.out.tfevents.1548073220.lee ├── graph.pbtxt ├── model.ckpt-0.data-00000-of-00001 ├── model.ckpt-0.index ├── model.ckpt-0.meta ├── model.ckpt-2220.data-00000-of-00001 ├── model.ckpt-2220.index ├── model.ckpt-2220.meta └── timeline-2209.json 3. 模型评估 在测试集上评估模型的效果： python -m tf_euler \ &nbsp; --data_dir ppi --id_file ppi/ppi_test.id \ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \ &nbsp; --model graphsage_supervised --mode evaluate 使用Euler算法包默认参数训练得到的模型在测试集上的mirco-F1 score大概在0.6左右。&nbsp; 4. embedding输出 导出顶点的embedding python -m tf_euler \ &nbsp; --data_dir ppi \ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \ &nbsp; --model graphsage_supervised --mode save_embedding 在当下目录下的ckpt目录中生成一个embedding.npy文件和一个id.txt文件，分别表示图中所有顶点的embedding和id。 &nbsp;四、GraphSage模型分布式训练 1. 分布式训练 Euler算法包及其底层的图查询引擎支持分布式的模型训练，用户需要在原始的训练命令上加入四个参数--ps_hosts、--worker_hosts、--job_name、--task_index指定分布式角色。如下提供脚本在本机的1998至2001端口上启动两个ps和两个worker进行分布式训练。 #!/usr/bin/env bash NUM_PSES=2 NUM_WORKERS=2 &nbsp; PS_HOSTS=&quot;&quot; for I in $(seq $(($NUM_PSES - 1)) -1 0) do &nbsp; PS_HOST=&quot;localhost:$((1999 - $I))&quot; &nbsp; if [ &quot;$PS_HOSTS&quot; == &quot;&quot; ]; then &nbsp; &nbsp; PS_HOSTS=&quot;$PS_HOST&quot; &nbsp; else &nbsp; &nbsp; PS_HOSTS=&quot;$PS_HOSTS,$PS_HOST&quot; &nbsp; fi done &nbsp; WORKER_HOSTS=&quot;&quot; for I in $(seq 0 $(($NUM_WORKERS - 1))) do &nbsp; WORKER_HOST=&quot;localhost:$((2000 + $I))&quot; &nbsp; if [ &quot;$WORKER_HOSTS&quot; == &quot;&quot; ]; then &nbsp; &nbsp; WORKER_HOSTS=&quot;$WORKER_HOST&quot; &nbsp; else &nbsp; &nbsp; WORKER_HOSTS=&quot;$WORKER_HOSTS,$WORKER_HOST&quot; &nbsp; fi done &nbsp; for I in $(seq 0 $(($NUM_PSES - 1))) do &nbsp; python -m tf_euler \ &nbsp; &nbsp; --ps_hosts=$PS_HOSTS \ &nbsp; &nbsp; --worker_hosts=$WORKER_HOSTS \ &nbsp; &nbsp; --job_name=ps --task_index=$I &amp;&gt; /tmp/log.ps.$I &amp; done &nbsp; for I in $(seq 0 $(($NUM_WORKERS - 1))) do &nbsp; python -m tf_euler \ &nbsp; &nbsp; --ps_hosts=$PS_HOSTS \ &nbsp; &nbsp; --worker_hosts=$WORKER_HOSTS \ &nbsp; &nbsp; --job_name=worker --task_index=$I $@ &amp;&gt; /tmp/log.worker.$I &amp; &nbsp; WORKERS[$I]=$! done &nbsp; trap &#39;kill $(jobs -p) 2&gt; /dev/null; exit&#39; SIGINT SIGTERM &nbsp; wait ${WORKERS[*]} &nbsp; kill $(jobs -p) 2&gt; /dev/null 2. 启动 使用分布式训练时，数据需要放置在HDFS上。 hdfs dfs -mkdir /data hdfs dfs -put ppi /data/ 启动脚本如下，进行分布式训练。 bash scripts/dist_tf_euler.sh \ &nbsp; --data_dir hdfs://lee:8020/data/ppi \ &nbsp; --euler_zk_addr lee:2181 \ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \ &nbsp; --model graphsage_supervised --mode train 参考资料 https://blog.csdn.net/baymax_007/article/details/86093856 https://yq.aliyun.com/articles/625340&nbsp; https://github.com/alibaba/euler &nbsp;" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-16T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"最近在调研graph embedding图机器学习算法，尝试了DeepWalk在推荐场景应用，碰到构造大规模节点，模型跑不下来问题。 阿里妈妈刚开源大规模分布式图学习框架Euler，其配合TensorFlow或者阿里开源XDL等深度学习工具，支持用户在数十亿点数百亿边的复杂异构图上进行模型训练。为graph embedding在推荐场景落地提供参考。 一、Euler介绍 https://github.com/alibaba/euler 1. 框架 Euler系统分为最底层的分布式图引擎，中间层图语义的算子，高层的图表示学习算法。如下图所示 2. 应用 2.1 大规模图的分布式学习 工业界的图往往具有数十亿节点和数百亿边，有些场景甚至可以到数百亿节点和数千亿边，在这样规模的图上单机训练是不可行的。Euler支持图分割和高效稳定的分布式训练，可以轻松支撑数十亿点、数百亿边的计算规模。 2.2 支持复杂异构图的表征 工业界的图关系大都错综复杂，体现在节点异构、边关系异构，另外节点和边上可能有非常丰富的属性，这使得一些常见的图神经网络很难学到有效的表达。Euler在图结构存储和图计算的抽象上均良好的支持异构点、异构边类型的操作，并支持丰富的异构属性，可以很容易的在图学习算法中进行异构图的表征学习。 2.3 图学习与深度学习的结合 工业界有很多经典场景，例如搜索／推荐／广告场景，传统的深度学习方法有不错效果，如何把图学习和传统方法结合起来，进一步提升模型能力是很值得探索的。Euler支持基于深度学习样本的mini-batch训练，把图表征直接输入到深度学习网络中联合训练。 2.4 分层抽象与灵活扩展 Euler系统抽象为图引擎层、图操作算子层、算法实现层三个层次，可以快速的在高层扩展一个图学习算法。实际上，Euler也内置了大量的算法实现供大家直接使用。 3. 内置算法 名称&nbsp;&nbsp; &nbsp;算法类型&nbsp;&nbsp; &nbsp;是否自研&nbsp;&nbsp; &nbsp;特点 DeepWalk&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;经典的无偏随机游走无监督算法 Node2Vec&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;利用可配置参数在游走时可倾向BFS或DFS LINE&nbsp;&nbsp; &nbsp;其它&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;灵活利用1阶，2阶邻居信息的无监督算法 GCN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;CNN操作类似推广到非欧空间的算法 GraphSAGE&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;GCN改进，提出邻居采样，多种汇聚函数等 GAT&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;将Attention技术用于邻居汇聚 LsHNE&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;异构图中随机游走，利用深度网络编码 LasGNN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;半监督大规模异构图卷积网络学习方法 Scalable-GCN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;加速GCN训练的一种方法 二、Euler安装 1. 编译 Euler的编译和启动依赖libhdfs.so和libjvm.so存在于$LD_LIBRARY_PATH中，因此需要添加环境变量如下 sudo vi ~/.bashrc # 添加环境变量&nbsp; # ${JAVA_HOME}=/opt/modules/jdk1.8.0_172/jre # ${HADOOP_HOME}=/opt/modules/hadoop-2.7.7 &nbsp; export LD_LIBRARY_PATH=/opt/modules/jdk1.8.0_172/jre/lib/server:$LD_LIBRARY_PATH export LIBRARY_PATH=/opt/modules/hadoop-2.7.7/lib/native:$LIBRARY_PATH export LD_LIBRARY_PATH=/opt/modules/hadoop-2.7.7/lib/native:$LD_LIBRARY_PATH export CLASSPATH=$(/opt/modules/hadoop-2.7.7/bin/hadoop classpath --glob):$CLASSPATH 2. Euler安装&nbsp; Euler目前仅支持Python2，可以选择从PyPI或者源码编译安装Euler，推荐PyPI安装。 2.1 PyPI安装 目前PyPI上的wheel基于TensorFlow 1.12编译，仅能与TensorFlow 1.12二进制兼容。如需使用其他版本的TensorFlow需要重新编译。 pip install euler-gl 2.2 源码编译安装 git clone --recursive https://github.com/alibaba/euler.git 递归third_party失败，没有采用该方法安装。 三、GraphSage模型训练 GraphSage是由Stanford提出的一种Inductive的图学习方法，具有GCN模型的良好性质，同时在实际使用中可以扩展到十亿顶点的大规模图。接下来尝试使用Euler和TensorFlow进行GraphSage模型训练。 1. PPI数据 准备Euler引擎可以读取的图数据，这里我们以PPI（Protein-Protein Interactions）为例： curl -k -O https://raw.githubusercontent.com/alibaba/euler/master/examples/ppi_data.py pip install networkx==1.11 sklearn python ppi_data.py 在当前目录下生成一个ppi目录（如下），其中包含构建好的PPI图数据。&nbsp; ppi ├── ppi-class_map.json ├── ppi_data.dat ├── ppi_data.json ├── ppi-feats.npy ├── ppi-G.json ├── ppi-id_map.json ├── ppi_meta.json ├── ppi_test.id ├── ppi_train.id ├── ppi_val.id └── ppi-walks.txt 2. 模型训练 在训练集上训练一个半监督的GraphSage模型： python -m tf_euler \\ &nbsp; --data_dir ppi \\ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \\ &nbsp; --model graphsage_supervised --mode train 在当前目录生成一个ckpt目录（如下），其中包含训练好的TensorFlow模型。 ckpt/ ├── checkpoint ├── events.out.tfevents.1548073220.lee ├── graph.pbtxt ├── model.ckpt-0.data-00000-of-00001 ├── model.ckpt-0.index ├── model.ckpt-0.meta ├── model.ckpt-2220.data-00000-of-00001 ├── model.ckpt-2220.index ├── model.ckpt-2220.meta └── timeline-2209.json 3. 模型评估 在测试集上评估模型的效果： python -m tf_euler \\ &nbsp; --data_dir ppi --id_file ppi/ppi_test.id \\ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \\ &nbsp; --model graphsage_supervised --mode evaluate 使用Euler算法包默认参数训练得到的模型在测试集上的mirco-F1 score大概在0.6左右。&nbsp; 4. embedding输出 导出顶点的embedding python -m tf_euler \\ &nbsp; --data_dir ppi \\ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \\ &nbsp; --model graphsage_supervised --mode save_embedding 在当下目录下的ckpt目录中生成一个embedding.npy文件和一个id.txt文件，分别表示图中所有顶点的embedding和id。 &nbsp;四、GraphSage模型分布式训练 1. 分布式训练 Euler算法包及其底层的图查询引擎支持分布式的模型训练，用户需要在原始的训练命令上加入四个参数--ps_hosts、--worker_hosts、--job_name、--task_index指定分布式角色。如下提供脚本在本机的1998至2001端口上启动两个ps和两个worker进行分布式训练。 #!/usr/bin/env bash NUM_PSES=2 NUM_WORKERS=2 &nbsp; PS_HOSTS=&quot;&quot; for I in $(seq $(($NUM_PSES - 1)) -1 0) do &nbsp; PS_HOST=&quot;localhost:$((1999 - $I))&quot; &nbsp; if [ &quot;$PS_HOSTS&quot; == &quot;&quot; ]; then &nbsp; &nbsp; PS_HOSTS=&quot;$PS_HOST&quot; &nbsp; else &nbsp; &nbsp; PS_HOSTS=&quot;$PS_HOSTS,$PS_HOST&quot; &nbsp; fi done &nbsp; WORKER_HOSTS=&quot;&quot; for I in $(seq 0 $(($NUM_WORKERS - 1))) do &nbsp; WORKER_HOST=&quot;localhost:$((2000 + $I))&quot; &nbsp; if [ &quot;$WORKER_HOSTS&quot; == &quot;&quot; ]; then &nbsp; &nbsp; WORKER_HOSTS=&quot;$WORKER_HOST&quot; &nbsp; else &nbsp; &nbsp; WORKER_HOSTS=&quot;$WORKER_HOSTS,$WORKER_HOST&quot; &nbsp; fi done &nbsp; for I in $(seq 0 $(($NUM_PSES - 1))) do &nbsp; python -m tf_euler \\ &nbsp; &nbsp; --ps_hosts=$PS_HOSTS \\ &nbsp; &nbsp; --worker_hosts=$WORKER_HOSTS \\ &nbsp; &nbsp; --job_name=ps --task_index=$I &amp;&gt; /tmp/log.ps.$I &amp; done &nbsp; for I in $(seq 0 $(($NUM_WORKERS - 1))) do &nbsp; python -m tf_euler \\ &nbsp; &nbsp; --ps_hosts=$PS_HOSTS \\ &nbsp; &nbsp; --worker_hosts=$WORKER_HOSTS \\ &nbsp; &nbsp; --job_name=worker --task_index=$I $@ &amp;&gt; /tmp/log.worker.$I &amp; &nbsp; WORKERS[$I]=$! done &nbsp; trap &#39;kill $(jobs -p) 2&gt; /dev/null; exit&#39; SIGINT SIGTERM &nbsp; wait ${WORKERS[*]} &nbsp; kill $(jobs -p) 2&gt; /dev/null 2. 启动 使用分布式训练时，数据需要放置在HDFS上。 hdfs dfs -mkdir /data hdfs dfs -put ppi /data/ 启动脚本如下，进行分布式训练。 bash scripts/dist_tf_euler.sh \\ &nbsp; --data_dir hdfs://lee:8020/data/ppi \\ &nbsp; --euler_zk_addr lee:2181 \\ &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \\ &nbsp; --model graphsage_supervised --mode train 参考资料 https://blog.csdn.net/baymax_007/article/details/86093856 https://yq.aliyun.com/articles/625340&nbsp; https://github.com/alibaba/euler &nbsp;","@type":"BlogPosting","url":"/2019/04/16/729252.html","headline":"大规模分布式图学习框架Euler","dateModified":"2019-04-16T00:00:00+08:00","datePublished":"2019-04-16T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/16/729252.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>大规模分布式图学习框架Euler</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>最近在调研graph embedding图机器学习算法，尝试了DeepWalk在推荐场景应用，碰到构造大规模节点，模型跑不下来问题。</p> 
  <p>阿里妈妈刚开源大规模分布式图学习框架Euler，其配合TensorFlow或者阿里开源XDL等深度学习工具，支持用户在数十亿点数百亿边的复杂异构图上进行模型训练。为graph embedding在推荐场景落地提供参考。</p> 
  <p>一、Euler介绍</p> 
  <p><a href="https://github.com/alibaba/euler" rel="nofollow">https://github.com/alibaba/euler</a><br> 1. 框架<br> Euler系统分为最底层的分布式图引擎，中间层图语义的算子，高层的图表示学习算法。如下图所示</p> 
  <p>2. 应用<br> 2.1 大规模图的分布式学习<br> 工业界的图往往具有数十亿节点和数百亿边，有些场景甚至可以到数百亿节点和数千亿边，在这样规模的图上单机训练是不可行的。Euler支持图分割和高效稳定的分布式训练，可以轻松支撑数十亿点、数百亿边的计算规模。</p> 
  <p>2.2 支持复杂异构图的表征<br> 工业界的图关系大都错综复杂，体现在节点异构、边关系异构，另外节点和边上可能有非常丰富的属性，这使得一些常见的图神经网络很难学到有效的表达。Euler在图结构存储和图计算的抽象上均良好的支持异构点、异构边类型的操作，并支持丰富的异构属性，可以很容易的在图学习算法中进行异构图的表征学习。</p> 
  <p>2.3 图学习与深度学习的结合<br> 工业界有很多经典场景，例如搜索／推荐／广告场景，传统的深度学习方法有不错效果，如何把图学习和传统方法结合起来，进一步提升模型能力是很值得探索的。Euler支持基于深度学习样本的mini-batch训练，把图表征直接输入到深度学习网络中联合训练。</p> 
  <p>2.4 分层抽象与灵活扩展<br> Euler系统抽象为图引擎层、图操作算子层、算法实现层三个层次，可以快速的在高层扩展一个图学习算法。实际上，Euler也内置了大量的算法实现供大家直接使用。</p> 
  <p>3. 内置算法<br> 名称&nbsp;&nbsp; &nbsp;算法类型&nbsp;&nbsp; &nbsp;是否自研&nbsp;&nbsp; &nbsp;特点<br> DeepWalk&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;经典的无偏随机游走无监督算法<br> Node2Vec&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;利用可配置参数在游走时可倾向BFS或DFS<br> LINE&nbsp;&nbsp; &nbsp;其它&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;灵活利用1阶，2阶邻居信息的无监督算法<br> GCN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;CNN操作类似推广到非欧空间的算法<br> GraphSAGE&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;GCN改进，提出邻居采样，多种汇聚函数等<br> GAT&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;否&nbsp;&nbsp; &nbsp;将Attention技术用于邻居汇聚<br> LsHNE&nbsp;&nbsp; &nbsp;随机游走&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;异构图中随机游走，利用深度网络编码<br> LasGNN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;半监督大规模异构图卷积网络学习方法<br> Scalable-GCN&nbsp;&nbsp; &nbsp;邻居汇聚&nbsp;&nbsp; &nbsp;是&nbsp;&nbsp; &nbsp;加速GCN训练的一种方法<br> 二、Euler安装<br> 1. 编译<br> Euler的编译和启动依赖libhdfs.so和libjvm.so存在于$LD_LIBRARY_PATH中，因此需要添加环境变量如下</p> 
  <p>sudo vi ~/.bashrc<br> # 添加环境变量&nbsp;<br> # ${JAVA_HOME}=/opt/modules/jdk1.8.0_172/jre<br> # ${HADOOP_HOME}=/opt/modules/hadoop-2.7.7<br> &nbsp;<br> export LD_LIBRARY_PATH=/opt/modules/jdk1.8.0_172/jre/lib/server:$LD_LIBRARY_PATH<br> export LIBRARY_PATH=/opt/modules/hadoop-2.7.7/lib/native:$LIBRARY_PATH<br> export LD_LIBRARY_PATH=/opt/modules/hadoop-2.7.7/lib/native:$LD_LIBRARY_PATH<br> export CLASSPATH=$(/opt/modules/hadoop-2.7.7/bin/hadoop classpath --glob):$CLASSPATH<br> 2. Euler安装&nbsp;<br> Euler目前仅支持Python2，可以选择从PyPI或者源码编译安装Euler，推荐PyPI安装。</p> 
  <p>2.1 PyPI安装<br> 目前PyPI上的wheel基于TensorFlow 1.12编译，仅能与TensorFlow 1.12二进制兼容。如需使用其他版本的TensorFlow需要重新编译。</p> 
  <p>pip install euler-gl<br> 2.2 源码编译安装<br> git clone --recursive https://github.com/alibaba/euler.git<br> 递归third_party失败，没有采用该方法安装。</p> 
  <p>三、GraphSage模型训练<br> GraphSage是由Stanford提出的一种Inductive的图学习方法，具有GCN模型的良好性质，同时在实际使用中可以扩展到十亿顶点的大规模图。接下来尝试使用Euler和TensorFlow进行GraphSage模型训练。</p> 
  <p>1. PPI数据<br> 准备Euler引擎可以读取的图数据，这里我们以PPI（Protein-Protein Interactions）为例：</p> 
  <p>curl -k -O https://raw.githubusercontent.com/alibaba/euler/master/examples/ppi_data.py<br> pip install networkx==1.11 sklearn<br> python ppi_data.py<br> 在当前目录下生成一个ppi目录（如下），其中包含构建好的PPI图数据。&nbsp;</p> 
  <p>ppi<br> ├── ppi-class_map.json<br> ├── ppi_data.dat<br> ├── ppi_data.json<br> ├── ppi-feats.npy<br> ├── ppi-G.json<br> ├── ppi-id_map.json<br> ├── ppi_meta.json<br> ├── ppi_test.id<br> ├── ppi_train.id<br> ├── ppi_val.id<br> └── ppi-walks.txt</p> 
  <p>2. 模型训练<br> 在训练集上训练一个半监督的GraphSage模型：</p> 
  <p>python -m tf_euler \<br> &nbsp; --data_dir ppi \<br> &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \<br> &nbsp; --model graphsage_supervised --mode train<br> 在当前目录生成一个ckpt目录（如下），其中包含训练好的TensorFlow模型。</p> 
  <p>ckpt/<br> ├── checkpoint<br> ├── events.out.tfevents.1548073220.lee<br> ├── graph.pbtxt<br> ├── model.ckpt-0.data-00000-of-00001<br> ├── model.ckpt-0.index<br> ├── model.ckpt-0.meta<br> ├── model.ckpt-2220.data-00000-of-00001<br> ├── model.ckpt-2220.index<br> ├── model.ckpt-2220.meta<br> └── timeline-2209.json</p> 
  <p>3. 模型评估<br> 在测试集上评估模型的效果：</p> 
  <p>python -m tf_euler \<br> &nbsp; --data_dir ppi --id_file ppi/ppi_test.id \<br> &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \<br> &nbsp; --model graphsage_supervised --mode evaluate<br> 使用Euler算法包默认参数训练得到的模型在测试集上的mirco-F1 score大概在0.6左右。&nbsp;</p> 
  <p>4. embedding输出<br> 导出顶点的embedding</p> 
  <p>python -m tf_euler \<br> &nbsp; --data_dir ppi \<br> &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \<br> &nbsp; --model graphsage_supervised --mode save_embedding<br> 在当下目录下的ckpt目录中生成一个embedding.npy文件和一个id.txt文件，分别表示图中所有顶点的embedding和id。</p> 
  <p><br> &nbsp;四、GraphSage模型分布式训练<br> 1. 分布式训练<br> Euler算法包及其底层的图查询引擎支持分布式的模型训练，用户需要在原始的训练命令上加入四个参数--ps_hosts、--worker_hosts、--job_name、--task_index指定分布式角色。如下提供脚本在本机的1998至2001端口上启动两个ps和两个worker进行分布式训练。</p> 
  <p>#!/usr/bin/env bash<br> NUM_PSES=2<br> NUM_WORKERS=2<br> &nbsp;<br> PS_HOSTS=""<br> for I in $(seq $(($NUM_PSES - 1)) -1 0)<br> do<br> &nbsp; PS_HOST="localhost:$((1999 - $I))"<br> &nbsp; if [ "$PS_HOSTS" == "" ]; then<br> &nbsp; &nbsp; PS_HOSTS="$PS_HOST"<br> &nbsp; else<br> &nbsp; &nbsp; PS_HOSTS="$PS_HOSTS,$PS_HOST"<br> &nbsp; fi<br> done<br> &nbsp;<br> WORKER_HOSTS=""<br> for I in $(seq 0 $(($NUM_WORKERS - 1)))<br> do<br> &nbsp; WORKER_HOST="localhost:$((2000 + $I))"<br> &nbsp; if [ "$WORKER_HOSTS" == "" ]; then<br> &nbsp; &nbsp; WORKER_HOSTS="$WORKER_HOST"<br> &nbsp; else<br> &nbsp; &nbsp; WORKER_HOSTS="$WORKER_HOSTS,$WORKER_HOST"<br> &nbsp; fi<br> done<br> &nbsp;<br> for I in $(seq 0 $(($NUM_PSES - 1)))<br> do<br> &nbsp; python -m tf_euler \<br> &nbsp; &nbsp; --ps_hosts=$PS_HOSTS \<br> &nbsp; &nbsp; --worker_hosts=$WORKER_HOSTS \<br> &nbsp; &nbsp; --job_name=ps --task_index=$I &amp;&gt; /tmp/log.ps.$I &amp;<br> done<br> &nbsp;<br> for I in $(seq 0 $(($NUM_WORKERS - 1)))<br> do<br> &nbsp; python -m tf_euler \<br> &nbsp; &nbsp; --ps_hosts=$PS_HOSTS \<br> &nbsp; &nbsp; --worker_hosts=$WORKER_HOSTS \<br> &nbsp; &nbsp; --job_name=worker --task_index=$I $@ &amp;&gt; /tmp/log.worker.$I &amp;<br> &nbsp; WORKERS[$I]=$!<br> done<br> &nbsp;<br> trap 'kill $(jobs -p) 2&gt; /dev/null; exit' SIGINT SIGTERM<br> &nbsp;<br> wait ${WORKERS[*]}<br> &nbsp;<br> kill $(jobs -p) 2&gt; /dev/null<br> 2. 启动<br> 使用分布式训练时，数据需要放置在HDFS上。</p> 
  <p>hdfs dfs -mkdir /data<br> hdfs dfs -put ppi /data/<br> 启动脚本如下，进行分布式训练。</p> 
  <p>bash scripts/dist_tf_euler.sh \<br> &nbsp; --data_dir hdfs://lee:8020/data/ppi \<br> &nbsp; --euler_zk_addr lee:2181 \<br> &nbsp; --max_id 56944 --feature_idx 1 --feature_dim 50 --label_idx 0 --label_dim 121 \<br> &nbsp; --model graphsage_supervised --mode train<br> 参考资料</p> 
  <p>https://blog.csdn.net/baymax_007/article/details/86093856</p> 
  <p>https://yq.aliyun.com/articles/625340&nbsp;</p> 
  <p><a href="https://github.com/alibaba/euler" rel="nofollow">https://github.com/alibaba/euler</a></p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
