<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>机器学习入门04——糖尿病数据预测 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="机器学习入门04——糖尿病数据预测" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：需要转载请注明来自“逗创科技” https://blog.csdn.net/u014005758/article/details/89331874 利用Logistic回归技术实现糖尿病发病预测 数据说明 数据说明： Pima Indians Diabetes Data Set（皮马印第安人糖尿病数据集） 根据现有的医疗信息预测5年内皮马印第安人糖尿病发作的概率。 数据链接：https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes p.s.: Kaggle也有一个Practice Fusion Diabetes Classification任务，可以试试:) https://www.kaggle.com/c/pf2012-diabetes 1)文件说明 pima-indians-diabetes.csv：数据文件 2)字段说明 数据集共9个字段: pregnants：怀孕次数 Plasma_glucose_concentration：口服葡萄糖耐量试验中2小时后的血浆葡萄糖浓度 blood_pressure：舒张压，单位:mm Hg Triceps_skin_fold_thickness：三头肌皮褶厚度，单位：mm serum_insulin：餐后血清胰岛素，单位:mm BMI：体重指数（体重（公斤）/ 身高（米）^2） Diabetes_pedigree_function：糖尿病家系作用 Age：年龄 Target：标签， 0表示不发病，1表示发病 第一步 特征工程 对于原始数据的处理使用了一下几个方法： 使用中值补充缺失数据 使用StandardScaler()对数据进行标准化处理 保存为csv格式 import numpy as np import pandas as pd #input data train = pd.read_csv(&quot;pima-indians-diabetes.csv&quot;) print(train.head()) #查看缺失值较多的数据统计 NaN_col_names = [&#39;Plasma_glucose_concentration&#39;,&#39;blood_pressure&#39;,&#39;Triceps_skin_fold_thickness&#39;,&#39;serum_insulin&#39;,&#39;BMI&#39;] train[NaN_col_names] = train[NaN_col_names].replace(0, np.NaN) print(train.isnull().sum()) #中值补充确实值 medians = train.median() train = train.fillna(medians) print(train.isnull().sum()) # get labels y_train = train[&#39;Target&#39;] X_train = train.drop([&quot;Target&quot;], axis=1) #用于保存特征工程之后的结果 feat_names = X_train.columns # 数据标准化 from sklearn.preprocessing import StandardScaler # 初始化特征的标准化器 ss_X = StandardScaler() # 分别对训练和测试数据的特征进行标准化处理 X_train = ss_X.fit_transform(X_train) #存为csv格式 X_train = pd.DataFrame(columns = feat_names, data = X_train) train = pd.concat([X_train, y_train], axis = 1) train.to_csv(&#39;FE_pima-indians-diabetes.csv&#39;,index = False,header=True) print(train.head()) 第二步 训练模型 训练模型主要分为以下几个步骤： 导入数据 分别使用L1正则和L2正则训练模型 使用5折交叉验证 使用log似然损失和正确率对模型进行超参数调优 绘制CV误差曲线 # 首先 import 必要的模块 import pandas as pd import numpy as np from sklearn.model_selection import GridSearchCV import matplotlib.pyplot as plt from sklearn.model_selection import GridSearchCV from sklearn.linear_model import LogisticRegression #%matplotlib inline # 读取数据 train = pd.read_csv(&#39;FE_pima-indians-diabetes.csv&#39;) y_train = train[&#39;Target&#39;] X_train = train.drop([&quot;Target&quot;], axis=1) #保存特征名字以备后用（可视化） feat_names = X_train.columns #需要调优的参数 # 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover） penaltys = [&#39;l1&#39;,&#39;l2&#39;] #训练数据多，C可以大一点（更多相信数据） Cs = [0.01, 0.1, 1, 10, 100, 1000, 10000] tuned_parameters = dict(penalty = penaltys, C = Cs)#组合调优参数 lr_penalty= LogisticRegression() #grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring=&#39;neg_log_loss&#39;)#log似然损失 grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring=&#39;accuracy&#39;)#正确率 grid.fit(X_train,y_train) # examine the best model print(-grid.best_score_)#打印模型参数 print(grid.best_params_) #绘制CV误差曲线分析模型 # plot CV误差曲线 test_means = grid.cv_results_[ &#39;mean_test_score&#39; ] test_stds = grid.cv_results_[ &#39;std_test_score&#39; ] train_means = grid.cv_results_[ &#39;mean_train_score&#39; ] train_stds = grid.cv_results_[ &#39;std_train_score&#39; ] # plot results n_Cs = len(Cs) number_penaltys = len(penaltys) test_scores = np.array(test_means).reshape(n_Cs,number_penaltys) train_scores = np.array(train_means).reshape(n_Cs,number_penaltys) test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys) train_stds = np.array(train_stds).reshape(n_Cs,number_penaltys) x_axis = np.log10(Cs) for i, value in enumerate(penaltys): #pyplot.plot(log(Cs), test_scores[i], label= &#39;penalty:&#39; + str(value)) plt.errorbar(x_axis, -test_scores[:,i], yerr=test_stds[:,i] ,label = penaltys[i] +&#39; Test&#39;) #plt.errorbar(x_axis, -train_scores[:,i], yerr=train_stds[:,i] ,label = penaltys[i] +&#39; Train&#39;) plt.legend() plt.xlabel( &#39;log(C)&#39; ) plt.ylabel( &#39;logloss&#39; ) plt.savefig(&#39;LogisticGridSearchCV_C.png&#39; ) plt.show() import cPickle cPickle.dump(grid.best_estimator_, open(&quot;FE_pima-indians-diabetes&quot;, &#39;wb&#39;)) 使用log似然损失对Logistic回归模型的正则超参数调优 参数结果： 0.47602775434873434 {&#39;C&#39;: 1, &#39;penalty&#39;: &#39;l1&#39;} 使用log似然损失对Logistic回归模型的正则超参数调优 参数结果： -0.7747395833333334 {&#39;C&#39;: 0.1, &#39;penalty&#39;: &#39;l2&#39;} 可以看到，使用正确率和l2正则对Logistic回归模型的正则超参数调优可以使损失函数最小 GridSearchCV(）中scoring的值可以选用一下参数： 点击这里可以到官网查看！！！ 项目源代码：糖尿病发病率预测" />
<meta property="og:description" content="版权声明：需要转载请注明来自“逗创科技” https://blog.csdn.net/u014005758/article/details/89331874 利用Logistic回归技术实现糖尿病发病预测 数据说明 数据说明： Pima Indians Diabetes Data Set（皮马印第安人糖尿病数据集） 根据现有的医疗信息预测5年内皮马印第安人糖尿病发作的概率。 数据链接：https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes p.s.: Kaggle也有一个Practice Fusion Diabetes Classification任务，可以试试:) https://www.kaggle.com/c/pf2012-diabetes 1)文件说明 pima-indians-diabetes.csv：数据文件 2)字段说明 数据集共9个字段: pregnants：怀孕次数 Plasma_glucose_concentration：口服葡萄糖耐量试验中2小时后的血浆葡萄糖浓度 blood_pressure：舒张压，单位:mm Hg Triceps_skin_fold_thickness：三头肌皮褶厚度，单位：mm serum_insulin：餐后血清胰岛素，单位:mm BMI：体重指数（体重（公斤）/ 身高（米）^2） Diabetes_pedigree_function：糖尿病家系作用 Age：年龄 Target：标签， 0表示不发病，1表示发病 第一步 特征工程 对于原始数据的处理使用了一下几个方法： 使用中值补充缺失数据 使用StandardScaler()对数据进行标准化处理 保存为csv格式 import numpy as np import pandas as pd #input data train = pd.read_csv(&quot;pima-indians-diabetes.csv&quot;) print(train.head()) #查看缺失值较多的数据统计 NaN_col_names = [&#39;Plasma_glucose_concentration&#39;,&#39;blood_pressure&#39;,&#39;Triceps_skin_fold_thickness&#39;,&#39;serum_insulin&#39;,&#39;BMI&#39;] train[NaN_col_names] = train[NaN_col_names].replace(0, np.NaN) print(train.isnull().sum()) #中值补充确实值 medians = train.median() train = train.fillna(medians) print(train.isnull().sum()) # get labels y_train = train[&#39;Target&#39;] X_train = train.drop([&quot;Target&quot;], axis=1) #用于保存特征工程之后的结果 feat_names = X_train.columns # 数据标准化 from sklearn.preprocessing import StandardScaler # 初始化特征的标准化器 ss_X = StandardScaler() # 分别对训练和测试数据的特征进行标准化处理 X_train = ss_X.fit_transform(X_train) #存为csv格式 X_train = pd.DataFrame(columns = feat_names, data = X_train) train = pd.concat([X_train, y_train], axis = 1) train.to_csv(&#39;FE_pima-indians-diabetes.csv&#39;,index = False,header=True) print(train.head()) 第二步 训练模型 训练模型主要分为以下几个步骤： 导入数据 分别使用L1正则和L2正则训练模型 使用5折交叉验证 使用log似然损失和正确率对模型进行超参数调优 绘制CV误差曲线 # 首先 import 必要的模块 import pandas as pd import numpy as np from sklearn.model_selection import GridSearchCV import matplotlib.pyplot as plt from sklearn.model_selection import GridSearchCV from sklearn.linear_model import LogisticRegression #%matplotlib inline # 读取数据 train = pd.read_csv(&#39;FE_pima-indians-diabetes.csv&#39;) y_train = train[&#39;Target&#39;] X_train = train.drop([&quot;Target&quot;], axis=1) #保存特征名字以备后用（可视化） feat_names = X_train.columns #需要调优的参数 # 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover） penaltys = [&#39;l1&#39;,&#39;l2&#39;] #训练数据多，C可以大一点（更多相信数据） Cs = [0.01, 0.1, 1, 10, 100, 1000, 10000] tuned_parameters = dict(penalty = penaltys, C = Cs)#组合调优参数 lr_penalty= LogisticRegression() #grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring=&#39;neg_log_loss&#39;)#log似然损失 grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring=&#39;accuracy&#39;)#正确率 grid.fit(X_train,y_train) # examine the best model print(-grid.best_score_)#打印模型参数 print(grid.best_params_) #绘制CV误差曲线分析模型 # plot CV误差曲线 test_means = grid.cv_results_[ &#39;mean_test_score&#39; ] test_stds = grid.cv_results_[ &#39;std_test_score&#39; ] train_means = grid.cv_results_[ &#39;mean_train_score&#39; ] train_stds = grid.cv_results_[ &#39;std_train_score&#39; ] # plot results n_Cs = len(Cs) number_penaltys = len(penaltys) test_scores = np.array(test_means).reshape(n_Cs,number_penaltys) train_scores = np.array(train_means).reshape(n_Cs,number_penaltys) test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys) train_stds = np.array(train_stds).reshape(n_Cs,number_penaltys) x_axis = np.log10(Cs) for i, value in enumerate(penaltys): #pyplot.plot(log(Cs), test_scores[i], label= &#39;penalty:&#39; + str(value)) plt.errorbar(x_axis, -test_scores[:,i], yerr=test_stds[:,i] ,label = penaltys[i] +&#39; Test&#39;) #plt.errorbar(x_axis, -train_scores[:,i], yerr=train_stds[:,i] ,label = penaltys[i] +&#39; Train&#39;) plt.legend() plt.xlabel( &#39;log(C)&#39; ) plt.ylabel( &#39;logloss&#39; ) plt.savefig(&#39;LogisticGridSearchCV_C.png&#39; ) plt.show() import cPickle cPickle.dump(grid.best_estimator_, open(&quot;FE_pima-indians-diabetes&quot;, &#39;wb&#39;)) 使用log似然损失对Logistic回归模型的正则超参数调优 参数结果： 0.47602775434873434 {&#39;C&#39;: 1, &#39;penalty&#39;: &#39;l1&#39;} 使用log似然损失对Logistic回归模型的正则超参数调优 参数结果： -0.7747395833333334 {&#39;C&#39;: 0.1, &#39;penalty&#39;: &#39;l2&#39;} 可以看到，使用正确率和l2正则对Logistic回归模型的正则超参数调优可以使损失函数最小 GridSearchCV(）中scoring的值可以选用一下参数： 点击这里可以到官网查看！！！ 项目源代码：糖尿病发病率预测" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-16T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：需要转载请注明来自“逗创科技” https://blog.csdn.net/u014005758/article/details/89331874 利用Logistic回归技术实现糖尿病发病预测 数据说明 数据说明： Pima Indians Diabetes Data Set（皮马印第安人糖尿病数据集） 根据现有的医疗信息预测5年内皮马印第安人糖尿病发作的概率。 数据链接：https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes p.s.: Kaggle也有一个Practice Fusion Diabetes Classification任务，可以试试:) https://www.kaggle.com/c/pf2012-diabetes 1)文件说明 pima-indians-diabetes.csv：数据文件 2)字段说明 数据集共9个字段: pregnants：怀孕次数 Plasma_glucose_concentration：口服葡萄糖耐量试验中2小时后的血浆葡萄糖浓度 blood_pressure：舒张压，单位:mm Hg Triceps_skin_fold_thickness：三头肌皮褶厚度，单位：mm serum_insulin：餐后血清胰岛素，单位:mm BMI：体重指数（体重（公斤）/ 身高（米）^2） Diabetes_pedigree_function：糖尿病家系作用 Age：年龄 Target：标签， 0表示不发病，1表示发病 第一步 特征工程 对于原始数据的处理使用了一下几个方法： 使用中值补充缺失数据 使用StandardScaler()对数据进行标准化处理 保存为csv格式 import numpy as np import pandas as pd #input data train = pd.read_csv(&quot;pima-indians-diabetes.csv&quot;) print(train.head()) #查看缺失值较多的数据统计 NaN_col_names = [&#39;Plasma_glucose_concentration&#39;,&#39;blood_pressure&#39;,&#39;Triceps_skin_fold_thickness&#39;,&#39;serum_insulin&#39;,&#39;BMI&#39;] train[NaN_col_names] = train[NaN_col_names].replace(0, np.NaN) print(train.isnull().sum()) #中值补充确实值 medians = train.median() train = train.fillna(medians) print(train.isnull().sum()) # get labels y_train = train[&#39;Target&#39;] X_train = train.drop([&quot;Target&quot;], axis=1) #用于保存特征工程之后的结果 feat_names = X_train.columns # 数据标准化 from sklearn.preprocessing import StandardScaler # 初始化特征的标准化器 ss_X = StandardScaler() # 分别对训练和测试数据的特征进行标准化处理 X_train = ss_X.fit_transform(X_train) #存为csv格式 X_train = pd.DataFrame(columns = feat_names, data = X_train) train = pd.concat([X_train, y_train], axis = 1) train.to_csv(&#39;FE_pima-indians-diabetes.csv&#39;,index = False,header=True) print(train.head()) 第二步 训练模型 训练模型主要分为以下几个步骤： 导入数据 分别使用L1正则和L2正则训练模型 使用5折交叉验证 使用log似然损失和正确率对模型进行超参数调优 绘制CV误差曲线 # 首先 import 必要的模块 import pandas as pd import numpy as np from sklearn.model_selection import GridSearchCV import matplotlib.pyplot as plt from sklearn.model_selection import GridSearchCV from sklearn.linear_model import LogisticRegression #%matplotlib inline # 读取数据 train = pd.read_csv(&#39;FE_pima-indians-diabetes.csv&#39;) y_train = train[&#39;Target&#39;] X_train = train.drop([&quot;Target&quot;], axis=1) #保存特征名字以备后用（可视化） feat_names = X_train.columns #需要调优的参数 # 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover） penaltys = [&#39;l1&#39;,&#39;l2&#39;] #训练数据多，C可以大一点（更多相信数据） Cs = [0.01, 0.1, 1, 10, 100, 1000, 10000] tuned_parameters = dict(penalty = penaltys, C = Cs)#组合调优参数 lr_penalty= LogisticRegression() #grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring=&#39;neg_log_loss&#39;)#log似然损失 grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring=&#39;accuracy&#39;)#正确率 grid.fit(X_train,y_train) # examine the best model print(-grid.best_score_)#打印模型参数 print(grid.best_params_) #绘制CV误差曲线分析模型 # plot CV误差曲线 test_means = grid.cv_results_[ &#39;mean_test_score&#39; ] test_stds = grid.cv_results_[ &#39;std_test_score&#39; ] train_means = grid.cv_results_[ &#39;mean_train_score&#39; ] train_stds = grid.cv_results_[ &#39;std_train_score&#39; ] # plot results n_Cs = len(Cs) number_penaltys = len(penaltys) test_scores = np.array(test_means).reshape(n_Cs,number_penaltys) train_scores = np.array(train_means).reshape(n_Cs,number_penaltys) test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys) train_stds = np.array(train_stds).reshape(n_Cs,number_penaltys) x_axis = np.log10(Cs) for i, value in enumerate(penaltys): #pyplot.plot(log(Cs), test_scores[i], label= &#39;penalty:&#39; + str(value)) plt.errorbar(x_axis, -test_scores[:,i], yerr=test_stds[:,i] ,label = penaltys[i] +&#39; Test&#39;) #plt.errorbar(x_axis, -train_scores[:,i], yerr=train_stds[:,i] ,label = penaltys[i] +&#39; Train&#39;) plt.legend() plt.xlabel( &#39;log(C)&#39; ) plt.ylabel( &#39;logloss&#39; ) plt.savefig(&#39;LogisticGridSearchCV_C.png&#39; ) plt.show() import cPickle cPickle.dump(grid.best_estimator_, open(&quot;FE_pima-indians-diabetes&quot;, &#39;wb&#39;)) 使用log似然损失对Logistic回归模型的正则超参数调优 参数结果： 0.47602775434873434 {&#39;C&#39;: 1, &#39;penalty&#39;: &#39;l1&#39;} 使用log似然损失对Logistic回归模型的正则超参数调优 参数结果： -0.7747395833333334 {&#39;C&#39;: 0.1, &#39;penalty&#39;: &#39;l2&#39;} 可以看到，使用正确率和l2正则对Logistic回归模型的正则超参数调优可以使损失函数最小 GridSearchCV(）中scoring的值可以选用一下参数： 点击这里可以到官网查看！！！ 项目源代码：糖尿病发病率预测","@type":"BlogPosting","url":"/2019/04/16/728219.html","headline":"机器学习入门04——糖尿病数据预测","dateModified":"2019-04-16T00:00:00+08:00","datePublished":"2019-04-16T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/16/728219.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>机器学习入门04——糖尿病数据预测</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：需要转载请注明来自“逗创科技” https://blog.csdn.net/u014005758/article/details/89331874 
 </div> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h1><a id="Logistic_0"></a>利用Logistic回归技术实现糖尿病发病预测</h1> 
  <h4><a id="_1"></a>数据说明</h4> 
  <p>数据说明： Pima Indians Diabetes Data Set（皮马印第安人糖尿病数据集） 根据现有的医疗信息预测5年内皮马印第安人糖尿病发作的概率。<br> 数据链接：<a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes" rel="nofollow">https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes</a><br> p.s.: Kaggle也有一个Practice Fusion Diabetes Classification任务，可以试试:)<br> <a href="https://www.kaggle.com/c/pf2012-diabetes" rel="nofollow">https://www.kaggle.com/c/pf2012-diabetes</a></p> 
  <h5><a id="1_7"></a>1)文件说明</h5> 
  <p>pima-indians-diabetes.csv：数据文件</p> 
  <h5><a id="2_10"></a>2)字段说明</h5> 
  <p>数据集共9个字段:<br> pregnants：怀孕次数<br> Plasma_glucose_concentration：口服葡萄糖耐量试验中2小时后的血浆葡萄糖浓度<br> blood_pressure：舒张压，单位:mm Hg<br> Triceps_skin_fold_thickness：三头肌皮褶厚度，单位：mm<br> serum_insulin：餐后血清胰岛素，单位:mm<br> BMI：体重指数（体重（公斤）/ 身高（米）^2）<br> Diabetes_pedigree_function：糖尿病家系作用<br> Age：年龄<br> Target：标签， 0表示不发病，1表示发病</p> 
  <h3><a id="__22"></a>第一步 特征工程</h3> 
  <p>对于原始数据的处理使用了一下几个方法：</p> 
  <ul> 
   <li>使用中值补充缺失数据</li> 
   <li>使用StandardScaler()对数据进行标准化处理</li> 
   <li>保存为csv格式</li> 
  </ul> 
  <pre><code>import numpy as np
import pandas as pd
#input data
train = pd.read_csv("pima-indians-diabetes.csv")
print(train.head())

#查看缺失值较多的数据统计
NaN_col_names = ['Plasma_glucose_concentration','blood_pressure','Triceps_skin_fold_thickness','serum_insulin','BMI']
train[NaN_col_names] = train[NaN_col_names].replace(0, np.NaN)
print(train.isnull().sum())


#中值补充确实值
medians = train.median() 
train = train.fillna(medians)

print(train.isnull().sum())


#  get labels
y_train = train['Target']   
X_train = train.drop(["Target"], axis=1)

#用于保存特征工程之后的结果
feat_names = X_train.columns

# 数据标准化
from sklearn.preprocessing import StandardScaler

# 初始化特征的标准化器
ss_X = StandardScaler()

# 分别对训练和测试数据的特征进行标准化处理
X_train = ss_X.fit_transform(X_train)

#存为csv格式
X_train = pd.DataFrame(columns = feat_names, data = X_train)

train = pd.concat([X_train, y_train], axis = 1)

train.to_csv('FE_pima-indians-diabetes.csv',index = False,header=True)

print(train.head())

</code></pre> 
  <h3><a id="__79"></a>第二步 训练模型</h3> 
  <p>训练模型主要分为以下几个步骤：</p> 
  <ul> 
   <li>导入数据</li> 
   <li>分别使用L1正则和L2正则训练模型</li> 
   <li>使用5折交叉验证</li> 
   <li>使用log似然损失和正确率对模型进行超参数调优</li> 
   <li>绘制CV误差曲线</li> 
  </ul> 
  <pre><code># 首先 import 必要的模块
import pandas as pd 
import numpy as np

from sklearn.model_selection import GridSearchCV

import matplotlib.pyplot as plt

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
#%matplotlib inline


# 读取数据

train = pd.read_csv('FE_pima-indians-diabetes.csv')

y_train = train['Target']   
X_train = train.drop(["Target"], axis=1)

#保存特征名字以备后用（可视化）
feat_names = X_train.columns 

#需要调优的参数
# 请尝试将L1正则和L2正则分开，并配合合适的优化求解算法（slover）
penaltys = ['l1','l2']

#训练数据多，C可以大一点（更多相信数据）
Cs = [0.01, 0.1, 1, 10, 100, 1000, 10000]

tuned_parameters = dict(penalty = penaltys, C = Cs)#组合调优参数

lr_penalty= LogisticRegression()
#grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring='neg_log_loss')#log似然损失
grid= GridSearchCV(lr_penalty, tuned_parameters,cv=5, scoring='accuracy')#正确率
grid.fit(X_train,y_train)

# examine the best model
print(-grid.best_score_)#打印模型参数
print(grid.best_params_)


#绘制CV误差曲线分析模型
# plot CV误差曲线
test_means = grid.cv_results_[ 'mean_test_score' ]
test_stds = grid.cv_results_[ 'std_test_score' ]
train_means = grid.cv_results_[ 'mean_train_score' ]
train_stds = grid.cv_results_[ 'std_train_score' ]


# plot results
n_Cs = len(Cs)
number_penaltys = len(penaltys)
test_scores = np.array(test_means).reshape(n_Cs,number_penaltys)
train_scores = np.array(train_means).reshape(n_Cs,number_penaltys)
test_stds = np.array(test_stds).reshape(n_Cs,number_penaltys)
train_stds = np.array(train_stds).reshape(n_Cs,number_penaltys)

x_axis = np.log10(Cs)
for i, value in enumerate(penaltys):
    #pyplot.plot(log(Cs), test_scores[i], label= 'penalty:'   + str(value))
    plt.errorbar(x_axis, -test_scores[:,i], yerr=test_stds[:,i] ,label = penaltys[i] +' Test')
    #plt.errorbar(x_axis, -train_scores[:,i], yerr=train_stds[:,i] ,label = penaltys[i] +' Train')
    
plt.legend()
plt.xlabel( 'log(C)' )                                                                                                      
plt.ylabel( 'logloss' )
plt.savefig('LogisticGridSearchCV_C.png' )

plt.show()

import cPickle

cPickle.dump(grid.best_estimator_, open("FE_pima-indians-diabetes", 'wb'))


</code></pre> 
  <h3><a id="logLogistic_170"></a>使用log似然损失对Logistic回归模型的正则超参数调优</h3> 
  <p>参数结果：</p> 
  <pre><code>0.47602775434873434
{'C': 1, 'penalty': 'l1'}
</code></pre> 
  <p><img src="https://gitee.com/uploads/images/2019/0406/111529_7efac171_4837051.png" alt="输入图片说明" title="QQ浏览器截图20190406111459.png"></p> 
  <h3><a id="logLogistic_181"></a>使用log似然损失对Logistic回归模型的正则超参数调优</h3> 
  <p>参数结果：</p> 
  <pre><code>-0.7747395833333334
{'C': 0.1, 'penalty': 'l2'}
</code></pre> 
  <p><img src="https://gitee.com/uploads/images/2019/0406/111630_1cdf165f_4837051.png" alt="输入图片说明" title="QQ浏览器截图20190406111616.png"></p> 
  <p>可以看到，使用正确率和l2正则对Logistic回归模型的正则超参数调优可以使损失函数最小</p> 
  <h4><a id="GridSearchCVscoring_196"></a>GridSearchCV(）中scoring的值可以选用一下参数：</h4> 
  <p><img src="https://gitee.com/uploads/images/2019/0406/112148_c8aed93b_4837051.png" alt="输入图片说明" title="QQ浏览器截图20190406105652.png"></p> 
  <p><a href="https://scikit-learn.org/stable/modules/model_evaluation.html" rel="nofollow">点击这里可以到官网查看！！！</a></p> 
  <p>项目源代码：<a href="https://gitee.com/huangjiezhou/fifth_week_homework" rel="nofollow">糖尿病发病率预测</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
