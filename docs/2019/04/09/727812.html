<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>《深度学习之PyTorch实战计算机视觉》学习笔记（10） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="《深度学习之PyTorch实战计算机视觉》学习笔记（10）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="这部分是利用pytorch 进行实战，利用迁移vgg16、resnet50 来实现多模型融合，实现猫狗的分类 代码基于python3.7， pytorch 1.0，cuda 10.0 . PyTorch之多模型融合实战 基于PyTorch实现一个多模型的融合，使用的是多模型融合方法中的结果加权平均，其思路是首先构建两个卷积神经网络模型，然后使用我们的训练数据集分别对这两个模型进行训练和对参数进行优化，使用优化后的模型对验证集进行预测，并将各模型的预测结果进行加权平均以作为最后的输出结果，通过对输出结果和真实结果的对比，来完成对融合模型准确率的计算。-------来自《深度学习之PyTorch实战计算机视觉》 import torch import torchvision import os import time import matplotlib.pyplot as plt from torchvision import datasets,models,transforms from torch.autograd import Variable %matplotlib inline # 读取数据集 data_dir = &#39;DogsVSCats&#39; # 数据预处理 data_transform = {x: transforms.Compose([transforms.Resize([224,224]), transforms.ToTensor(), transforms.Normalize(mean = [0.5,0.5,0.5],std = [0.5,0.05,0.5])])for x in [&#39;train&#39;,&#39;valid&#39;]} # 读取数据集 image_datasets = {x: datasets.ImageFolder(root = os.path.join(data_dir,x),transform = data_transform[x])for x in [&#39;train&#39;,&#39;valid&#39;]} # 装载数据集 dataloader = {x: torch.utils.data.DataLoader(dataset = image_datasets[x], batch_size = 16, shuffle = True)for x in [&#39;train&#39;,&#39;valid&#39;]} # 数据预览,注意到由于上面图片的预处理中，图片进行了normaliza,因此不是显示原图 X_example, Y_example = next(iter(dataloader[&#39;train&#39;])) print(u&#39;X_example个数{}&#39;.format(len(X_example))) print(u&#39;Y_example个数{}&#39;.format(len(Y_example))) index_classes = image_datasets[&#39;train&#39;].class_to_idx # 显示类别对应的独热编码 print(index_classes) example_classes = image_datasets[&#39;train&#39;].classes # 将原始图像的类别保存起来 print(example_classes) img = torchvision.utils.make_grid(X_example) img = img.numpy().transpose([1,2,0]) print([example_classes[i] for i in Y_example]) plt.imshow(img) plt.show() Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). X_example个数16 Y_example个数16 {&#39;cat&#39;: 0, &#39;dog&#39;: 1} [&#39;cat&#39;, &#39;dog&#39;] [&#39;dog&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;] # 构建多模型融合结构 model_1 = models.vgg16(pretrained = True) model_2 = models.resnet50(pretrained = True) Use_gpu = torch.cuda.is_available() # 设置模型的参数不需要进行梯度下降 for param in model_1.parameters(): param.requires_grad = False model_1.classifier = torch.nn.Sequential(torch.nn.Linear(25088,4096), torch.nn.ReLU(), torch.nn.Dropout(p = 0.5), torch.nn.Linear(4096,4096), torch.nn.ReLU(), torch.nn.Dropout(p = 0.5), torch.nn.Linear(4096,2)) for param in model_2.parameters(): param.requires_grad = False model_2.fc = torch.nn.Linear(2048,2) print(model_1) print(model_2) VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (avgpool): AdaptiveAvgPool2d(output_size=(7, 7)) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU() (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU() (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=2, bias=True) ) ) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=2048, out_features=2, bias=True) ) # 设置损失函数以及优化方法 if Use_gpu: model_1 = model_1.cuda() model_2 = model_2.cuda() loss_f_1 = torch.nn.CrossEntropyLoss() loss_f_2 = torch.nn.CrossEntropyLoss() optimizer_1 = torch.optim.Adam(model_1.classifier.parameters(), lr = 0.00001) optimizer_2 = torch.optim.Adam(model_2.fc.parameters(),lr = 0.00001) # 设置两个模型融合的权重参数 weight_1 = 0.6 weight_2 = 0.4 epoch_n = 5 # 训练模型 time_open = time.time() for epoch in range(epoch_n): print(&#39;Epoch{}/{}&#39;.format(epoch, epoch_n - 1)) print(&#39;-&#39;*10) for phase in [&#39;train&#39;,&#39;valid&#39;]: if phase == &#39;train&#39;: print(&#39;Training...&#39;) model_1.train(True) model_2.train(True) else: print(&#39;Validing...&#39;) model_1.train(False) model_2.train(False) running_loss_1 = 0.0 running_loss_2 = 0.0 running_corrects_1 = 0.0 running_corrects_2 = 0.0 blending_running_corrects = 0.0 for batch, data in enumerate(dataloader[phase], 1): X,Y = data if Use_gpu: X,Y = Variable(X.cuda()), Variable(Y.cuda()) else: X,Y = Variable(X), Variable(Y) y_pred_1 = model_1(X) y_pred_2 = model_2(X) blending_y_pred = y_pred_1 * weight_1 + y_pred_2 * weight_2 _, pred_1 = torch.max(y_pred_1.data,1) # 找出每一行最大值对应的索引值 _, pred_2 = torch.max(y_pred_2.data,1) _, blending_y_pred = torch.max(blending_y_pred.data,1) optimizer_1.zero_grad() optimizer_2.zero_grad() loss_1 = loss_f_1(y_pred_1,Y) loss_2 = loss_f_2(y_pred_2,Y) if phase == &#39;train&#39;: loss_1.backward() loss_2.backward() optimizer_1.step() optimizer_2.step() running_loss_1 += loss_1.data.item() running_loss_2 += loss_1.data.item() running_corrects_1 += torch.sum(pred_1 == Y.data) running_corrects_2 += torch.sum(pred_2 == Y.data) blending_running_corrects += torch.sum(blending_y_pred == Y.data) if batch % 500 == 0 and phase == &#39;train&#39;: print(&#39;Batch {},Model1 Train Loss:{:.4f},Model1 Train ACC:{:.4f},Model2 Train Loss:{:.4f},Model2 Train ACC:{:.4f},Blending_Model ACC:{:.4f}&#39; .format(batch,running_loss_1/batch,100*running_corrects_1/(16*batch),running_loss_2/batch,100*running_corrects_2/(16*batch),100*blending_running_corrects/(16*batch))) epoch_loss_1 = running_loss_1 * 16/len(image_datasets[phase]) epoch_acc_1 = 100*running_corrects_1/len(image_datasets[phase]) epoch_loss_2 = running_loss_2 * 16/len(image_datasets[phase]) epoch_acc_2 = 100*running_corrects_2/len(image_datasets[phase]) epoch_blending_acc = 100*blending_running_corrects/len(image_datasets[phase]) print(&#39;Epoch, Model1 Loss:{:.4f},Model1 ACC:{:.4f}%,Model2 Loss:{:.4f},Model2 ACC:{:.4f}%,Blending_Model ACC:{:.4f}&#39; .format(epoch_loss_1,epoch_acc_1,epoch_loss_2,epoch_acc_2,epoch_blending_acc)) time_end = time.time() - time_open print(time_end) Epoch0/4 Epoch1/4 Epoch2/4 Epoch3/4 Epoch4/4 Training… Batch 500,Model1 Train Loss:0.1905,Model1 Train ACC:92.0000,Model2 Train Loss:0.1905,Model2 Train ACC:80.0000,Blending_Model ACC:92.0000 Batch 1000,Model1 Train Loss:0.1563,Model1 Train ACC:93.0000,Model2 Train Loss:0.1563,Model2 Train ACC:86.0000,Blending_Model ACC:94.0000 Epoch, Model1 Loss:0.1481,Model1 ACC:94.0000%,Model2 Loss:0.1481,Model2 ACC:87.0000%,Blending_Model ACC:94.0000 206.29394793510437 Validing… Epoch, Model1 Loss:0.1080,Model1 ACC:95.0000%,Model2 Loss:0.1080,Model2 ACC:95.0000%,Blending_Model ACC:96.0000 248.57402753829956 Process finished with exit code 0" />
<meta property="og:description" content="这部分是利用pytorch 进行实战，利用迁移vgg16、resnet50 来实现多模型融合，实现猫狗的分类 代码基于python3.7， pytorch 1.0，cuda 10.0 . PyTorch之多模型融合实战 基于PyTorch实现一个多模型的融合，使用的是多模型融合方法中的结果加权平均，其思路是首先构建两个卷积神经网络模型，然后使用我们的训练数据集分别对这两个模型进行训练和对参数进行优化，使用优化后的模型对验证集进行预测，并将各模型的预测结果进行加权平均以作为最后的输出结果，通过对输出结果和真实结果的对比，来完成对融合模型准确率的计算。-------来自《深度学习之PyTorch实战计算机视觉》 import torch import torchvision import os import time import matplotlib.pyplot as plt from torchvision import datasets,models,transforms from torch.autograd import Variable %matplotlib inline # 读取数据集 data_dir = &#39;DogsVSCats&#39; # 数据预处理 data_transform = {x: transforms.Compose([transforms.Resize([224,224]), transforms.ToTensor(), transforms.Normalize(mean = [0.5,0.5,0.5],std = [0.5,0.05,0.5])])for x in [&#39;train&#39;,&#39;valid&#39;]} # 读取数据集 image_datasets = {x: datasets.ImageFolder(root = os.path.join(data_dir,x),transform = data_transform[x])for x in [&#39;train&#39;,&#39;valid&#39;]} # 装载数据集 dataloader = {x: torch.utils.data.DataLoader(dataset = image_datasets[x], batch_size = 16, shuffle = True)for x in [&#39;train&#39;,&#39;valid&#39;]} # 数据预览,注意到由于上面图片的预处理中，图片进行了normaliza,因此不是显示原图 X_example, Y_example = next(iter(dataloader[&#39;train&#39;])) print(u&#39;X_example个数{}&#39;.format(len(X_example))) print(u&#39;Y_example个数{}&#39;.format(len(Y_example))) index_classes = image_datasets[&#39;train&#39;].class_to_idx # 显示类别对应的独热编码 print(index_classes) example_classes = image_datasets[&#39;train&#39;].classes # 将原始图像的类别保存起来 print(example_classes) img = torchvision.utils.make_grid(X_example) img = img.numpy().transpose([1,2,0]) print([example_classes[i] for i in Y_example]) plt.imshow(img) plt.show() Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). X_example个数16 Y_example个数16 {&#39;cat&#39;: 0, &#39;dog&#39;: 1} [&#39;cat&#39;, &#39;dog&#39;] [&#39;dog&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;] # 构建多模型融合结构 model_1 = models.vgg16(pretrained = True) model_2 = models.resnet50(pretrained = True) Use_gpu = torch.cuda.is_available() # 设置模型的参数不需要进行梯度下降 for param in model_1.parameters(): param.requires_grad = False model_1.classifier = torch.nn.Sequential(torch.nn.Linear(25088,4096), torch.nn.ReLU(), torch.nn.Dropout(p = 0.5), torch.nn.Linear(4096,4096), torch.nn.ReLU(), torch.nn.Dropout(p = 0.5), torch.nn.Linear(4096,2)) for param in model_2.parameters(): param.requires_grad = False model_2.fc = torch.nn.Linear(2048,2) print(model_1) print(model_2) VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (avgpool): AdaptiveAvgPool2d(output_size=(7, 7)) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU() (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU() (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=2, bias=True) ) ) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=2048, out_features=2, bias=True) ) # 设置损失函数以及优化方法 if Use_gpu: model_1 = model_1.cuda() model_2 = model_2.cuda() loss_f_1 = torch.nn.CrossEntropyLoss() loss_f_2 = torch.nn.CrossEntropyLoss() optimizer_1 = torch.optim.Adam(model_1.classifier.parameters(), lr = 0.00001) optimizer_2 = torch.optim.Adam(model_2.fc.parameters(),lr = 0.00001) # 设置两个模型融合的权重参数 weight_1 = 0.6 weight_2 = 0.4 epoch_n = 5 # 训练模型 time_open = time.time() for epoch in range(epoch_n): print(&#39;Epoch{}/{}&#39;.format(epoch, epoch_n - 1)) print(&#39;-&#39;*10) for phase in [&#39;train&#39;,&#39;valid&#39;]: if phase == &#39;train&#39;: print(&#39;Training...&#39;) model_1.train(True) model_2.train(True) else: print(&#39;Validing...&#39;) model_1.train(False) model_2.train(False) running_loss_1 = 0.0 running_loss_2 = 0.0 running_corrects_1 = 0.0 running_corrects_2 = 0.0 blending_running_corrects = 0.0 for batch, data in enumerate(dataloader[phase], 1): X,Y = data if Use_gpu: X,Y = Variable(X.cuda()), Variable(Y.cuda()) else: X,Y = Variable(X), Variable(Y) y_pred_1 = model_1(X) y_pred_2 = model_2(X) blending_y_pred = y_pred_1 * weight_1 + y_pred_2 * weight_2 _, pred_1 = torch.max(y_pred_1.data,1) # 找出每一行最大值对应的索引值 _, pred_2 = torch.max(y_pred_2.data,1) _, blending_y_pred = torch.max(blending_y_pred.data,1) optimizer_1.zero_grad() optimizer_2.zero_grad() loss_1 = loss_f_1(y_pred_1,Y) loss_2 = loss_f_2(y_pred_2,Y) if phase == &#39;train&#39;: loss_1.backward() loss_2.backward() optimizer_1.step() optimizer_2.step() running_loss_1 += loss_1.data.item() running_loss_2 += loss_1.data.item() running_corrects_1 += torch.sum(pred_1 == Y.data) running_corrects_2 += torch.sum(pred_2 == Y.data) blending_running_corrects += torch.sum(blending_y_pred == Y.data) if batch % 500 == 0 and phase == &#39;train&#39;: print(&#39;Batch {},Model1 Train Loss:{:.4f},Model1 Train ACC:{:.4f},Model2 Train Loss:{:.4f},Model2 Train ACC:{:.4f},Blending_Model ACC:{:.4f}&#39; .format(batch,running_loss_1/batch,100*running_corrects_1/(16*batch),running_loss_2/batch,100*running_corrects_2/(16*batch),100*blending_running_corrects/(16*batch))) epoch_loss_1 = running_loss_1 * 16/len(image_datasets[phase]) epoch_acc_1 = 100*running_corrects_1/len(image_datasets[phase]) epoch_loss_2 = running_loss_2 * 16/len(image_datasets[phase]) epoch_acc_2 = 100*running_corrects_2/len(image_datasets[phase]) epoch_blending_acc = 100*blending_running_corrects/len(image_datasets[phase]) print(&#39;Epoch, Model1 Loss:{:.4f},Model1 ACC:{:.4f}%,Model2 Loss:{:.4f},Model2 ACC:{:.4f}%,Blending_Model ACC:{:.4f}&#39; .format(epoch_loss_1,epoch_acc_1,epoch_loss_2,epoch_acc_2,epoch_blending_acc)) time_end = time.time() - time_open print(time_end) Epoch0/4 Epoch1/4 Epoch2/4 Epoch3/4 Epoch4/4 Training… Batch 500,Model1 Train Loss:0.1905,Model1 Train ACC:92.0000,Model2 Train Loss:0.1905,Model2 Train ACC:80.0000,Blending_Model ACC:92.0000 Batch 1000,Model1 Train Loss:0.1563,Model1 Train ACC:93.0000,Model2 Train Loss:0.1563,Model2 Train ACC:86.0000,Blending_Model ACC:94.0000 Epoch, Model1 Loss:0.1481,Model1 ACC:94.0000%,Model2 Loss:0.1481,Model2 ACC:87.0000%,Blending_Model ACC:94.0000 206.29394793510437 Validing… Epoch, Model1 Loss:0.1080,Model1 ACC:95.0000%,Model2 Loss:0.1080,Model2 ACC:95.0000%,Blending_Model ACC:96.0000 248.57402753829956 Process finished with exit code 0" />
<link rel="canonical" href="https://mlh.app/2019/04/09/727812.html" />
<meta property="og:url" content="https://mlh.app/2019/04/09/727812.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-09T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"这部分是利用pytorch 进行实战，利用迁移vgg16、resnet50 来实现多模型融合，实现猫狗的分类 代码基于python3.7， pytorch 1.0，cuda 10.0 . PyTorch之多模型融合实战 基于PyTorch实现一个多模型的融合，使用的是多模型融合方法中的结果加权平均，其思路是首先构建两个卷积神经网络模型，然后使用我们的训练数据集分别对这两个模型进行训练和对参数进行优化，使用优化后的模型对验证集进行预测，并将各模型的预测结果进行加权平均以作为最后的输出结果，通过对输出结果和真实结果的对比，来完成对融合模型准确率的计算。-------来自《深度学习之PyTorch实战计算机视觉》 import torch import torchvision import os import time import matplotlib.pyplot as plt from torchvision import datasets,models,transforms from torch.autograd import Variable %matplotlib inline # 读取数据集 data_dir = &#39;DogsVSCats&#39; # 数据预处理 data_transform = {x: transforms.Compose([transforms.Resize([224,224]), transforms.ToTensor(), transforms.Normalize(mean = [0.5,0.5,0.5],std = [0.5,0.05,0.5])])for x in [&#39;train&#39;,&#39;valid&#39;]} # 读取数据集 image_datasets = {x: datasets.ImageFolder(root = os.path.join(data_dir,x),transform = data_transform[x])for x in [&#39;train&#39;,&#39;valid&#39;]} # 装载数据集 dataloader = {x: torch.utils.data.DataLoader(dataset = image_datasets[x], batch_size = 16, shuffle = True)for x in [&#39;train&#39;,&#39;valid&#39;]} # 数据预览,注意到由于上面图片的预处理中，图片进行了normaliza,因此不是显示原图 X_example, Y_example = next(iter(dataloader[&#39;train&#39;])) print(u&#39;X_example个数{}&#39;.format(len(X_example))) print(u&#39;Y_example个数{}&#39;.format(len(Y_example))) index_classes = image_datasets[&#39;train&#39;].class_to_idx # 显示类别对应的独热编码 print(index_classes) example_classes = image_datasets[&#39;train&#39;].classes # 将原始图像的类别保存起来 print(example_classes) img = torchvision.utils.make_grid(X_example) img = img.numpy().transpose([1,2,0]) print([example_classes[i] for i in Y_example]) plt.imshow(img) plt.show() Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). X_example个数16 Y_example个数16 {&#39;cat&#39;: 0, &#39;dog&#39;: 1} [&#39;cat&#39;, &#39;dog&#39;] [&#39;dog&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;, &#39;cat&#39;, &#39;dog&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;cat&#39;] # 构建多模型融合结构 model_1 = models.vgg16(pretrained = True) model_2 = models.resnet50(pretrained = True) Use_gpu = torch.cuda.is_available() # 设置模型的参数不需要进行梯度下降 for param in model_1.parameters(): param.requires_grad = False model_1.classifier = torch.nn.Sequential(torch.nn.Linear(25088,4096), torch.nn.ReLU(), torch.nn.Dropout(p = 0.5), torch.nn.Linear(4096,4096), torch.nn.ReLU(), torch.nn.Dropout(p = 0.5), torch.nn.Linear(4096,2)) for param in model_2.parameters(): param.requires_grad = False model_2.fc = torch.nn.Linear(2048,2) print(model_1) print(model_2) VGG( (features): Sequential( (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (1): ReLU(inplace) (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (3): ReLU(inplace) (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (6): ReLU(inplace) (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (8): ReLU(inplace) (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (11): ReLU(inplace) (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (13): ReLU(inplace) (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (15): ReLU(inplace) (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (18): ReLU(inplace) (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (20): ReLU(inplace) (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (22): ReLU(inplace) (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (25): ReLU(inplace) (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (27): ReLU(inplace) (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)) (29): ReLU(inplace) (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) ) (avgpool): AdaptiveAvgPool2d(output_size=(7, 7)) (classifier): Sequential( (0): Linear(in_features=25088, out_features=4096, bias=True) (1): ReLU() (2): Dropout(p=0.5) (3): Linear(in_features=4096, out_features=4096, bias=True) (4): ReLU() (5): Dropout(p=0.5) (6): Linear(in_features=4096, out_features=2, bias=True) ) ) ResNet( (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False) (layer1): Sequential( (0): Bottleneck( (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer2): Sequential( (0): Bottleneck( (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer3): Sequential( (0): Bottleneck( (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (3): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (4): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (5): Bottleneck( (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (layer4): Sequential( (0): Bottleneck( (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) (downsample): Sequential( (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False) (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) ) ) (1): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) (2): Bottleneck( (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False) (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False) (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) (relu): ReLU(inplace) ) ) (avgpool): AdaptiveAvgPool2d(output_size=(1, 1)) (fc): Linear(in_features=2048, out_features=2, bias=True) ) # 设置损失函数以及优化方法 if Use_gpu: model_1 = model_1.cuda() model_2 = model_2.cuda() loss_f_1 = torch.nn.CrossEntropyLoss() loss_f_2 = torch.nn.CrossEntropyLoss() optimizer_1 = torch.optim.Adam(model_1.classifier.parameters(), lr = 0.00001) optimizer_2 = torch.optim.Adam(model_2.fc.parameters(),lr = 0.00001) # 设置两个模型融合的权重参数 weight_1 = 0.6 weight_2 = 0.4 epoch_n = 5 # 训练模型 time_open = time.time() for epoch in range(epoch_n): print(&#39;Epoch{}/{}&#39;.format(epoch, epoch_n - 1)) print(&#39;-&#39;*10) for phase in [&#39;train&#39;,&#39;valid&#39;]: if phase == &#39;train&#39;: print(&#39;Training...&#39;) model_1.train(True) model_2.train(True) else: print(&#39;Validing...&#39;) model_1.train(False) model_2.train(False) running_loss_1 = 0.0 running_loss_2 = 0.0 running_corrects_1 = 0.0 running_corrects_2 = 0.0 blending_running_corrects = 0.0 for batch, data in enumerate(dataloader[phase], 1): X,Y = data if Use_gpu: X,Y = Variable(X.cuda()), Variable(Y.cuda()) else: X,Y = Variable(X), Variable(Y) y_pred_1 = model_1(X) y_pred_2 = model_2(X) blending_y_pred = y_pred_1 * weight_1 + y_pred_2 * weight_2 _, pred_1 = torch.max(y_pred_1.data,1) # 找出每一行最大值对应的索引值 _, pred_2 = torch.max(y_pred_2.data,1) _, blending_y_pred = torch.max(blending_y_pred.data,1) optimizer_1.zero_grad() optimizer_2.zero_grad() loss_1 = loss_f_1(y_pred_1,Y) loss_2 = loss_f_2(y_pred_2,Y) if phase == &#39;train&#39;: loss_1.backward() loss_2.backward() optimizer_1.step() optimizer_2.step() running_loss_1 += loss_1.data.item() running_loss_2 += loss_1.data.item() running_corrects_1 += torch.sum(pred_1 == Y.data) running_corrects_2 += torch.sum(pred_2 == Y.data) blending_running_corrects += torch.sum(blending_y_pred == Y.data) if batch % 500 == 0 and phase == &#39;train&#39;: print(&#39;Batch {},Model1 Train Loss:{:.4f},Model1 Train ACC:{:.4f},Model2 Train Loss:{:.4f},Model2 Train ACC:{:.4f},Blending_Model ACC:{:.4f}&#39; .format(batch,running_loss_1/batch,100*running_corrects_1/(16*batch),running_loss_2/batch,100*running_corrects_2/(16*batch),100*blending_running_corrects/(16*batch))) epoch_loss_1 = running_loss_1 * 16/len(image_datasets[phase]) epoch_acc_1 = 100*running_corrects_1/len(image_datasets[phase]) epoch_loss_2 = running_loss_2 * 16/len(image_datasets[phase]) epoch_acc_2 = 100*running_corrects_2/len(image_datasets[phase]) epoch_blending_acc = 100*blending_running_corrects/len(image_datasets[phase]) print(&#39;Epoch, Model1 Loss:{:.4f},Model1 ACC:{:.4f}%,Model2 Loss:{:.4f},Model2 ACC:{:.4f}%,Blending_Model ACC:{:.4f}&#39; .format(epoch_loss_1,epoch_acc_1,epoch_loss_2,epoch_acc_2,epoch_blending_acc)) time_end = time.time() - time_open print(time_end) Epoch0/4 Epoch1/4 Epoch2/4 Epoch3/4 Epoch4/4 Training… Batch 500,Model1 Train Loss:0.1905,Model1 Train ACC:92.0000,Model2 Train Loss:0.1905,Model2 Train ACC:80.0000,Blending_Model ACC:92.0000 Batch 1000,Model1 Train Loss:0.1563,Model1 Train ACC:93.0000,Model2 Train Loss:0.1563,Model2 Train ACC:86.0000,Blending_Model ACC:94.0000 Epoch, Model1 Loss:0.1481,Model1 ACC:94.0000%,Model2 Loss:0.1481,Model2 ACC:87.0000%,Blending_Model ACC:94.0000 206.29394793510437 Validing… Epoch, Model1 Loss:0.1080,Model1 ACC:95.0000%,Model2 Loss:0.1080,Model2 ACC:95.0000%,Blending_Model ACC:96.0000 248.57402753829956 Process finished with exit code 0","@type":"BlogPosting","url":"https://mlh.app/2019/04/09/727812.html","headline":"《深度学习之PyTorch实战计算机视觉》学习笔记（10）","dateModified":"2019-04-09T00:00:00+08:00","datePublished":"2019-04-09T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/04/09/727812.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>《深度学习之PyTorch实战计算机视觉》学习笔记（10）</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p>这部分是利用pytorch 进行实战，利用迁移vgg16、resnet50 来实现多模型融合，实现猫狗的分类<br> 代码基于python3.7， pytorch 1.0，cuda 10.0 .</p> 
  <h2><a id="PyTorch_2"></a>PyTorch之多模型融合实战</h2> 
  <p>基于PyTorch实现一个多模型的融合，使用的是多模型融合方法中的结果加权平均，其思路是首先构建两个卷积神经网络模型，然后使用我们的训练数据集分别对这两个模型进行训练和对参数进行优化，使用优化后的模型对验证集进行预测，并将各模型的预测结果进行加权平均以作为最后的输出结果，通过对输出结果和真实结果的对比，来完成对融合模型准确率的计算。-------来自《深度学习之PyTorch实战计算机视觉》</p> 
  <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> os
<span class="token keyword">import</span> time
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">from</span> torchvision <span class="token keyword">import</span> datasets<span class="token punctuation">,</span>models<span class="token punctuation">,</span>transforms
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token operator">%</span>matplotlib inline
</code></pre> 
  <pre><code class="prism language-python"><span class="token comment"># 读取数据集</span>
data_dir <span class="token operator">=</span> <span class="token string">'DogsVSCats'</span>
<span class="token comment"># 数据预处理</span>
data_transform <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span> transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">224</span><span class="token punctuation">,</span><span class="token number">224</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span>mean <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">,</span>std <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span><span class="token number">0.05</span><span class="token punctuation">,</span><span class="token number">0.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'valid'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
<span class="token comment"># 读取数据集</span>
image_datasets <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span> datasets<span class="token punctuation">.</span>ImageFolder<span class="token punctuation">(</span>root <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span>transform <span class="token operator">=</span> data_transform<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'valid'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
<span class="token comment"># 装载数据集</span>
dataloader <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset <span class="token operator">=</span> image_datasets<span class="token punctuation">[</span>x<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                            batch_size <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">,</span>
                                            shuffle <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span><span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'valid'</span><span class="token punctuation">]</span><span class="token punctuation">}</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token comment"># 数据预览,注意到由于上面图片的预处理中，图片进行了normaliza,因此不是显示原图</span>
X_example<span class="token punctuation">,</span> Y_example <span class="token operator">=</span> <span class="token builtin">next</span><span class="token punctuation">(</span><span class="token builtin">iter</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>u<span class="token string">'X_example个数{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>X_example<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>u<span class="token string">'Y_example个数{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>Y_example<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

index_classes <span class="token operator">=</span> image_datasets<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>class_to_idx   <span class="token comment"># 显示类别对应的独热编码</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>index_classes<span class="token punctuation">)</span>

example_classes <span class="token operator">=</span> image_datasets<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>classes     <span class="token comment"># 将原始图像的类别保存起来</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>example_classes<span class="token punctuation">)</span>

img <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>make_grid<span class="token punctuation">(</span>X_example<span class="token punctuation">)</span>
img <span class="token operator">=</span> img<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token punctuation">[</span>example_classes<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> Y_example<span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span> 
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <pre><code>Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).


X_example个数16
Y_example个数16
{'cat': 0, 'dog': 1}
['cat', 'dog']
['dog', 'dog', 'dog', 'cat', 'dog', 'dog', 'dog', 'cat', 'dog', 'cat', 'cat', 'cat', 'dog', 'dog', 'cat', 'cat']
</code></pre> 
  <p><img src="https://blog.uzzz.org.cn/_p?https://img-blog.csdnimg.cn/20190409181324607.png" alt="png"></p> 
  <pre><code class="prism language-python"><span class="token comment"># 构建多模型融合结构</span>
model_1 <span class="token operator">=</span> models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>pretrained <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
model_2 <span class="token operator">=</span> models<span class="token punctuation">.</span>resnet50<span class="token punctuation">(</span>pretrained <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>

Use_gpu <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 设置模型的参数不需要进行梯度下降</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> model_1<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>
model_1<span class="token punctuation">.</span>classifier <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">25088</span><span class="token punctuation">,</span><span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span><span class="token number">4096</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>p <span class="token operator">=</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                        torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">4096</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> model_2<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>
model_2<span class="token punctuation">.</span>fc <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">2048</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>model_1<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model_2<span class="token punctuation">)</span>
</code></pre> 
  <pre><code>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.5)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU()
    (5): Dropout(p=0.5)
    (6): Linear(in_features=4096, out_features=2, bias=True)
  )
)
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=2, bias=True)
)
</code></pre> 
  <pre><code class="prism language-python"><span class="token comment"># 设置损失函数以及优化方法</span>
<span class="token keyword">if</span> Use_gpu<span class="token punctuation">:</span>
    model_1 <span class="token operator">=</span> model_1<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    model_2 <span class="token operator">=</span> model_2<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
loss_f_1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss_f_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

optimizer_1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model_1<span class="token punctuation">.</span>classifier<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr <span class="token operator">=</span> <span class="token number">0.00001</span><span class="token punctuation">)</span>
optimizer_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model_2<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">0.00001</span><span class="token punctuation">)</span>

<span class="token comment"># 设置两个模型融合的权重参数</span>
weight_1 <span class="token operator">=</span> <span class="token number">0.6</span>
weight_2 <span class="token operator">=</span> <span class="token number">0.4</span>

epoch_n <span class="token operator">=</span> <span class="token number">5</span>
</code></pre> 
  <pre><code class="prism language-python"><span class="token comment"># 训练模型</span>
time_open <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch_n<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch{}/{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> epoch_n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token operator">*</span><span class="token number">10</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> phase <span class="token keyword">in</span> <span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'valid'</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Training...'</span><span class="token punctuation">)</span>
        model_1<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        model_2<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Validing...'</span><span class="token punctuation">)</span>
        model_1<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        model_2<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    
    running_loss_1 <span class="token operator">=</span> <span class="token number">0.0</span>
    running_loss_2 <span class="token operator">=</span> <span class="token number">0.0</span>
    running_corrects_1 <span class="token operator">=</span> <span class="token number">0.0</span>
    running_corrects_2 <span class="token operator">=</span> <span class="token number">0.0</span>
    blending_running_corrects <span class="token operator">=</span> <span class="token number">0.0</span>
    
    <span class="token keyword">for</span> batch<span class="token punctuation">,</span> data <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>dataloader<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        X<span class="token punctuation">,</span>Y <span class="token operator">=</span> data
        <span class="token keyword">if</span> Use_gpu<span class="token punctuation">:</span>
            X<span class="token punctuation">,</span>Y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>X<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>Y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            X<span class="token punctuation">,</span>Y <span class="token operator">=</span> Variable<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
            
        y_pred_1 <span class="token operator">=</span> model_1<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        y_pred_2 <span class="token operator">=</span> model_2<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        blending_y_pred <span class="token operator">=</span> y_pred_1 <span class="token operator">*</span> weight_1 <span class="token operator">+</span> y_pred_2 <span class="token operator">*</span> weight_2
        
        _<span class="token punctuation">,</span> pred_1 <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>y_pred_1<span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token comment"># 找出每一行最大值对应的索引值</span>
        _<span class="token punctuation">,</span> pred_2 <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>y_pred_2<span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        _<span class="token punctuation">,</span> blending_y_pred <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>blending_y_pred<span class="token punctuation">.</span>data<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        
        optimizer_1<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer_2<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        loss_1 <span class="token operator">=</span> loss_f_1<span class="token punctuation">(</span>y_pred_1<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        loss_2 <span class="token operator">=</span> loss_f_2<span class="token punctuation">(</span>y_pred_2<span class="token punctuation">,</span>Y<span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
            loss_1<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            loss_2<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer_1<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer_2<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
        running_loss_1 <span class="token operator">+=</span> loss_1<span class="token punctuation">.</span>data<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        running_loss_2 <span class="token operator">+=</span> loss_1<span class="token punctuation">.</span>data<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        running_corrects_1 <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>pred_1 <span class="token operator">==</span> Y<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
        running_corrects_2 <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>pred_2 <span class="token operator">==</span> Y<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
        blending_running_corrects <span class="token operator">+=</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>blending_y_pred <span class="token operator">==</span> Y<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> batch <span class="token operator">%</span> <span class="token number">500</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">and</span> phase <span class="token operator">==</span> <span class="token string">'train'</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Batch {},Model1 Train Loss:{:.4f},Model1 Train ACC:{:.4f},Model2 Train Loss:{:.4f},Model2 Train ACC:{:.4f},Blending_Model ACC:{:.4f}'</span>
                 <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>batch<span class="token punctuation">,</span>running_loss_1<span class="token operator">/</span>batch<span class="token punctuation">,</span><span class="token number">100</span><span class="token operator">*</span>running_corrects_1<span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span>batch<span class="token punctuation">)</span><span class="token punctuation">,</span>running_loss_2<span class="token operator">/</span>batch<span class="token punctuation">,</span><span class="token number">100</span><span class="token operator">*</span>running_corrects_2<span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span>batch<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token operator">*</span>blending_running_corrects<span class="token operator">/</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token operator">*</span>batch<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    epoch_loss_1 <span class="token operator">=</span> running_loss_1 <span class="token operator">*</span> <span class="token number">16</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">)</span>
    epoch_acc_1 <span class="token operator">=</span> <span class="token number">100</span><span class="token operator">*</span>running_corrects_1<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">)</span>
    epoch_loss_2 <span class="token operator">=</span> running_loss_2 <span class="token operator">*</span> <span class="token number">16</span><span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">)</span>
    epoch_acc_2 <span class="token operator">=</span> <span class="token number">100</span><span class="token operator">*</span>running_corrects_2<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">)</span>
    epoch_blending_acc <span class="token operator">=</span> <span class="token number">100</span><span class="token operator">*</span>blending_running_corrects<span class="token operator">/</span><span class="token builtin">len</span><span class="token punctuation">(</span>image_datasets<span class="token punctuation">[</span>phase<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch, Model1 Loss:{:.4f},Model1 ACC:{:.4f}%,Model2 Loss:{:.4f},Model2 ACC:{:.4f}%,Blending_Model ACC:{:.4f}'</span>
         <span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>epoch_loss_1<span class="token punctuation">,</span>epoch_acc_1<span class="token punctuation">,</span>epoch_loss_2<span class="token punctuation">,</span>epoch_acc_2<span class="token punctuation">,</span>epoch_blending_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>

    time_end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> time_open
    <span class="token keyword">print</span><span class="token punctuation">(</span>time_end<span class="token punctuation">)</span>
</code></pre> 
  <h2><a id="Epoch04_409"></a>Epoch0/4</h2> 
  <h2><a id="Epoch14_411"></a>Epoch1/4</h2> 
  <h2><a id="Epoch24_413"></a>Epoch2/4</h2> 
  <h2><a id="Epoch34_415"></a>Epoch3/4</h2> 
  <h2><a id="Epoch44_417"></a>Epoch4/4</h2> 
  <p>Training…<br> Batch 500,Model1 Train Loss:0.1905,Model1 Train ACC:92.0000,Model2 Train Loss:0.1905,Model2 Train ACC:80.0000,Blending_Model ACC:92.0000<br> Batch 1000,Model1 Train Loss:0.1563,Model1 Train ACC:93.0000,Model2 Train Loss:0.1563,Model2 Train ACC:86.0000,Blending_Model ACC:94.0000<br> Epoch, Model1 Loss:0.1481,Model1 ACC:94.0000%,Model2 Loss:0.1481,Model2 ACC:87.0000%,Blending_Model ACC:94.0000<br> 206.29394793510437<br> Validing…<br> Epoch, Model1 Loss:0.1080,Model1 ACC:95.0000%,Model2 Loss:0.1080,Model2 ACC:95.0000%,Blending_Model ACC:96.0000<br> 248.57402753829956</p> 
  <p>Process finished with exit code 0</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
