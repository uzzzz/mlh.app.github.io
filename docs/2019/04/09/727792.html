<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>OpenCV 深度学习框架的使用 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="OpenCV 深度学习框架的使用" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/flyfish1986/article/details/89157368 OpenCV 深度学习框架的使用 flyfish 版本 4.1.0 这个版本只提供模型使用，不提供训练 官网共包含如下实例 samples/dnn/classification.cpp samples/dnn/colorization.cpp samples/dnn/object_detection.cpp samples/dnn/openpose.cpp samples/dnn/segmentation.cpp samples/dnn/text_detection.cpp Confidence threshold 置信度阈值 Non-maximum suppression threshold非极大值抑制阈值 选择一个计算后端（Choose one of computation backends） 0: automatically (by default) 1: Halide language （http://halide-lang.org/) 2: Intel’s Deep Learning Inference Engine (https://software.intel.com/openvino-toolkit) 3: OpenCV implementation 代码是这样 cv::dnn::DNN_BACKEND_DEFAULT, cv::dnn::DNN_BACKEND_HALIDE, cv::dnn::DNN_BACKEND_INFERENCE_ENGINE, cv::dnn::DNN_BACKEND_OPENCV, cv::dnn::DNN_BACKEND_VKCOM 选择一个目标计算设备（Choose one of target computation devices） 0: CPU target (by default) 1: OpenCL, 2: OpenCL fp16 (half-float precision) 3: VPU 代码是这样 cv::dnn::DNN_TARGET_CPU, cv::dnn::DNN_TARGET_OPENCL, cv::dnn::DNN_TARGET_OPENCL_FP16, cv::dnn::DNN_TARGET_MYRIAD, cv::dnn::DNN_TARGET_VULKAN, cv::dnn::DNN_TARGET_FPGA 假设以目标分类为例 std::vectorstd::string classes 类别，可以在代码里直接硬写入，也可以从文件读取 std::string file = parser.get&lt;String&gt;(&quot;classes&quot;); std::ifstream ifs(file.c_str()); if (!ifs.is_open()) CV_Error(Error::StsError, &quot;File &quot; + file + &quot; not found&quot;); std::string line; while (std::getline(ifs, line)) { classes.push_back(line); } 加载模型 OpenCV支持以下模型 Net cv::dnn::net = readNet Net cv::dnn::readNetFromCaffe Net cv::dnn::readNetFromDarknet Net cv::dnn::readNetFromONNX Net cv::dnn::readNetFromTensorflow Net cv::dnn::readNetFromTorch 文件的扩展名 .caffemodel (Caffe, http://caffe.berkeleyvision.org/) .pb (TensorFlow, https://www.tensorflow.org/) .t7 | *.net (Torch, http://torch.ch/) .weights (Darknet, https://pjreddie.com/darknet/) .bin (DLDT, https://software.intel.com/openvino-toolkit) net.setPreferableBackend(DNN_BACKEND_OPENCV); net.setPreferableTarget(DNN_TARGET_CPU); 从数据帧中创建一个4维的blob Mat frame, blob; Size inpSize(inpWidth &gt; 0 ? inpWidth : frame.cols, inpHeight &gt; 0 ? inpHeight : frame.rows); blobFromImage(frame, blob, scale, inpSize, mean, swapRB, false); 解释重载函数 void cv::dnn::blobFromImage ( InputArray image, OutputArray blob, double scalefactor = 1.0, const Size &amp; size = Size(), const Scalar &amp; mean = Scalar(), bool swapRB = false, bool crop = false, int ddepth = CV_32F ) image 可以是视频帧 blob是输出的数据 scalefactor 图像值的乘法器。 size 图像大小，也就是训练的时候使用图像的大小 mean scalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true. 标量，其平均值是从通道中减去的。 值的顺序为(mean-R、mean-G、mean-B) 如果图像具有BGR顺序，则swapRB为真。 也就是图像通道有的是RGB顺序的，也有的是BGR顺序的，根据swapRB来判断通道顺序 swapRB 图像通道是RGB顺序还是BGR顺序的 if crop is true, input image is resized so one side after resize is equal to corresponding dimension in size and another one is equal or larger. Then, crop from the center is performed. If crop is false, direct resize without cropping and preserving aspect ratio is performed. 如果crop为true，则对输入图像进行大小调整，裁剪图像。如果crop是false的，等比例缩放。 图像的数据类型，支持32F和8U CV_8U unsigned CV_32F float 运行模型 net.setInput(blob); std::vector&lt;Mat&gt; outs; net.forward(outs, outNames); 这里的outNames由 std::vector outNames = net.getUnconnectedOutLayersNames();获取 void cv::dnn::Net::forward ( OutputArrayOfArrays outputBlobs, const std::vector&lt; String &gt; &amp; outBlobNames ) 运行前向传播来计算outBlobNames中列出的层的输出。 如果使用Qt编译 可用如下配置 TEMPLATE = app CONFIG += console c++11 CONFIG -= app_bundle CONFIG -= qt INCLUDEPATH += /usr/local/include \ /usr/local/include/opencv4 \ /usr/local/include/opencv4/opencv2 LIBS += /usr/local/lib/libopencv_calib3d.so \ /usr/local/lib/libopencv_core.so \ /usr/local/lib/libopencv_highgui.so \ /usr/local/lib/libopencv_imgproc.so \ /usr/local/lib/libopencv_imgcodecs.so\ /usr/local/lib/libopencv_objdetect.so\ /usr/local/lib/libopencv_photo.so \ /usr/local/lib/libopencv_dnn.so \ /usr/local/lib/libopencv_features2d.so \ /usr/local/lib/libopencv_stitching.so \ /usr/local/lib/libopencv_flann.so\ /usr/local/lib/libopencv_videoio.so \ /usr/local/lib/libopencv_video.so\ /usr/local/lib/libopencv_ml.so SOURCES += \ main.cpp HEADERS += \ common.hpp" />
<meta property="og:description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/flyfish1986/article/details/89157368 OpenCV 深度学习框架的使用 flyfish 版本 4.1.0 这个版本只提供模型使用，不提供训练 官网共包含如下实例 samples/dnn/classification.cpp samples/dnn/colorization.cpp samples/dnn/object_detection.cpp samples/dnn/openpose.cpp samples/dnn/segmentation.cpp samples/dnn/text_detection.cpp Confidence threshold 置信度阈值 Non-maximum suppression threshold非极大值抑制阈值 选择一个计算后端（Choose one of computation backends） 0: automatically (by default) 1: Halide language （http://halide-lang.org/) 2: Intel’s Deep Learning Inference Engine (https://software.intel.com/openvino-toolkit) 3: OpenCV implementation 代码是这样 cv::dnn::DNN_BACKEND_DEFAULT, cv::dnn::DNN_BACKEND_HALIDE, cv::dnn::DNN_BACKEND_INFERENCE_ENGINE, cv::dnn::DNN_BACKEND_OPENCV, cv::dnn::DNN_BACKEND_VKCOM 选择一个目标计算设备（Choose one of target computation devices） 0: CPU target (by default) 1: OpenCL, 2: OpenCL fp16 (half-float precision) 3: VPU 代码是这样 cv::dnn::DNN_TARGET_CPU, cv::dnn::DNN_TARGET_OPENCL, cv::dnn::DNN_TARGET_OPENCL_FP16, cv::dnn::DNN_TARGET_MYRIAD, cv::dnn::DNN_TARGET_VULKAN, cv::dnn::DNN_TARGET_FPGA 假设以目标分类为例 std::vectorstd::string classes 类别，可以在代码里直接硬写入，也可以从文件读取 std::string file = parser.get&lt;String&gt;(&quot;classes&quot;); std::ifstream ifs(file.c_str()); if (!ifs.is_open()) CV_Error(Error::StsError, &quot;File &quot; + file + &quot; not found&quot;); std::string line; while (std::getline(ifs, line)) { classes.push_back(line); } 加载模型 OpenCV支持以下模型 Net cv::dnn::net = readNet Net cv::dnn::readNetFromCaffe Net cv::dnn::readNetFromDarknet Net cv::dnn::readNetFromONNX Net cv::dnn::readNetFromTensorflow Net cv::dnn::readNetFromTorch 文件的扩展名 .caffemodel (Caffe, http://caffe.berkeleyvision.org/) .pb (TensorFlow, https://www.tensorflow.org/) .t7 | *.net (Torch, http://torch.ch/) .weights (Darknet, https://pjreddie.com/darknet/) .bin (DLDT, https://software.intel.com/openvino-toolkit) net.setPreferableBackend(DNN_BACKEND_OPENCV); net.setPreferableTarget(DNN_TARGET_CPU); 从数据帧中创建一个4维的blob Mat frame, blob; Size inpSize(inpWidth &gt; 0 ? inpWidth : frame.cols, inpHeight &gt; 0 ? inpHeight : frame.rows); blobFromImage(frame, blob, scale, inpSize, mean, swapRB, false); 解释重载函数 void cv::dnn::blobFromImage ( InputArray image, OutputArray blob, double scalefactor = 1.0, const Size &amp; size = Size(), const Scalar &amp; mean = Scalar(), bool swapRB = false, bool crop = false, int ddepth = CV_32F ) image 可以是视频帧 blob是输出的数据 scalefactor 图像值的乘法器。 size 图像大小，也就是训练的时候使用图像的大小 mean scalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true. 标量，其平均值是从通道中减去的。 值的顺序为(mean-R、mean-G、mean-B) 如果图像具有BGR顺序，则swapRB为真。 也就是图像通道有的是RGB顺序的，也有的是BGR顺序的，根据swapRB来判断通道顺序 swapRB 图像通道是RGB顺序还是BGR顺序的 if crop is true, input image is resized so one side after resize is equal to corresponding dimension in size and another one is equal or larger. Then, crop from the center is performed. If crop is false, direct resize without cropping and preserving aspect ratio is performed. 如果crop为true，则对输入图像进行大小调整，裁剪图像。如果crop是false的，等比例缩放。 图像的数据类型，支持32F和8U CV_8U unsigned CV_32F float 运行模型 net.setInput(blob); std::vector&lt;Mat&gt; outs; net.forward(outs, outNames); 这里的outNames由 std::vector outNames = net.getUnconnectedOutLayersNames();获取 void cv::dnn::Net::forward ( OutputArrayOfArrays outputBlobs, const std::vector&lt; String &gt; &amp; outBlobNames ) 运行前向传播来计算outBlobNames中列出的层的输出。 如果使用Qt编译 可用如下配置 TEMPLATE = app CONFIG += console c++11 CONFIG -= app_bundle CONFIG -= qt INCLUDEPATH += /usr/local/include \ /usr/local/include/opencv4 \ /usr/local/include/opencv4/opencv2 LIBS += /usr/local/lib/libopencv_calib3d.so \ /usr/local/lib/libopencv_core.so \ /usr/local/lib/libopencv_highgui.so \ /usr/local/lib/libopencv_imgproc.so \ /usr/local/lib/libopencv_imgcodecs.so\ /usr/local/lib/libopencv_objdetect.so\ /usr/local/lib/libopencv_photo.so \ /usr/local/lib/libopencv_dnn.so \ /usr/local/lib/libopencv_features2d.so \ /usr/local/lib/libopencv_stitching.so \ /usr/local/lib/libopencv_flann.so\ /usr/local/lib/libopencv_videoio.so \ /usr/local/lib/libopencv_video.so\ /usr/local/lib/libopencv_ml.so SOURCES += \ main.cpp HEADERS += \ common.hpp" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-09T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/flyfish1986/article/details/89157368 OpenCV 深度学习框架的使用 flyfish 版本 4.1.0 这个版本只提供模型使用，不提供训练 官网共包含如下实例 samples/dnn/classification.cpp samples/dnn/colorization.cpp samples/dnn/object_detection.cpp samples/dnn/openpose.cpp samples/dnn/segmentation.cpp samples/dnn/text_detection.cpp Confidence threshold 置信度阈值 Non-maximum suppression threshold非极大值抑制阈值 选择一个计算后端（Choose one of computation backends） 0: automatically (by default) 1: Halide language （http://halide-lang.org/) 2: Intel’s Deep Learning Inference Engine (https://software.intel.com/openvino-toolkit) 3: OpenCV implementation 代码是这样 cv::dnn::DNN_BACKEND_DEFAULT, cv::dnn::DNN_BACKEND_HALIDE, cv::dnn::DNN_BACKEND_INFERENCE_ENGINE, cv::dnn::DNN_BACKEND_OPENCV, cv::dnn::DNN_BACKEND_VKCOM 选择一个目标计算设备（Choose one of target computation devices） 0: CPU target (by default) 1: OpenCL, 2: OpenCL fp16 (half-float precision) 3: VPU 代码是这样 cv::dnn::DNN_TARGET_CPU, cv::dnn::DNN_TARGET_OPENCL, cv::dnn::DNN_TARGET_OPENCL_FP16, cv::dnn::DNN_TARGET_MYRIAD, cv::dnn::DNN_TARGET_VULKAN, cv::dnn::DNN_TARGET_FPGA 假设以目标分类为例 std::vectorstd::string classes 类别，可以在代码里直接硬写入，也可以从文件读取 std::string file = parser.get&lt;String&gt;(&quot;classes&quot;); std::ifstream ifs(file.c_str()); if (!ifs.is_open()) CV_Error(Error::StsError, &quot;File &quot; + file + &quot; not found&quot;); std::string line; while (std::getline(ifs, line)) { classes.push_back(line); } 加载模型 OpenCV支持以下模型 Net cv::dnn::net = readNet Net cv::dnn::readNetFromCaffe Net cv::dnn::readNetFromDarknet Net cv::dnn::readNetFromONNX Net cv::dnn::readNetFromTensorflow Net cv::dnn::readNetFromTorch 文件的扩展名 .caffemodel (Caffe, http://caffe.berkeleyvision.org/) .pb (TensorFlow, https://www.tensorflow.org/) .t7 | *.net (Torch, http://torch.ch/) .weights (Darknet, https://pjreddie.com/darknet/) .bin (DLDT, https://software.intel.com/openvino-toolkit) net.setPreferableBackend(DNN_BACKEND_OPENCV); net.setPreferableTarget(DNN_TARGET_CPU); 从数据帧中创建一个4维的blob Mat frame, blob; Size inpSize(inpWidth &gt; 0 ? inpWidth : frame.cols, inpHeight &gt; 0 ? inpHeight : frame.rows); blobFromImage(frame, blob, scale, inpSize, mean, swapRB, false); 解释重载函数 void cv::dnn::blobFromImage ( InputArray image, OutputArray blob, double scalefactor = 1.0, const Size &amp; size = Size(), const Scalar &amp; mean = Scalar(), bool swapRB = false, bool crop = false, int ddepth = CV_32F ) image 可以是视频帧 blob是输出的数据 scalefactor 图像值的乘法器。 size 图像大小，也就是训练的时候使用图像的大小 mean scalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true. 标量，其平均值是从通道中减去的。 值的顺序为(mean-R、mean-G、mean-B) 如果图像具有BGR顺序，则swapRB为真。 也就是图像通道有的是RGB顺序的，也有的是BGR顺序的，根据swapRB来判断通道顺序 swapRB 图像通道是RGB顺序还是BGR顺序的 if crop is true, input image is resized so one side after resize is equal to corresponding dimension in size and another one is equal or larger. Then, crop from the center is performed. If crop is false, direct resize without cropping and preserving aspect ratio is performed. 如果crop为true，则对输入图像进行大小调整，裁剪图像。如果crop是false的，等比例缩放。 图像的数据类型，支持32F和8U CV_8U unsigned CV_32F float 运行模型 net.setInput(blob); std::vector&lt;Mat&gt; outs; net.forward(outs, outNames); 这里的outNames由 std::vector outNames = net.getUnconnectedOutLayersNames();获取 void cv::dnn::Net::forward ( OutputArrayOfArrays outputBlobs, const std::vector&lt; String &gt; &amp; outBlobNames ) 运行前向传播来计算outBlobNames中列出的层的输出。 如果使用Qt编译 可用如下配置 TEMPLATE = app CONFIG += console c++11 CONFIG -= app_bundle CONFIG -= qt INCLUDEPATH += /usr/local/include \\ /usr/local/include/opencv4 \\ /usr/local/include/opencv4/opencv2 LIBS += /usr/local/lib/libopencv_calib3d.so \\ /usr/local/lib/libopencv_core.so \\ /usr/local/lib/libopencv_highgui.so \\ /usr/local/lib/libopencv_imgproc.so \\ /usr/local/lib/libopencv_imgcodecs.so\\ /usr/local/lib/libopencv_objdetect.so\\ /usr/local/lib/libopencv_photo.so \\ /usr/local/lib/libopencv_dnn.so \\ /usr/local/lib/libopencv_features2d.so \\ /usr/local/lib/libopencv_stitching.so \\ /usr/local/lib/libopencv_flann.so\\ /usr/local/lib/libopencv_videoio.so \\ /usr/local/lib/libopencv_video.so\\ /usr/local/lib/libopencv_ml.so SOURCES += \\ main.cpp HEADERS += \\ common.hpp","@type":"BlogPosting","url":"/2019/04/09/727792.html","headline":"OpenCV 深度学习框架的使用","dateModified":"2019-04-09T00:00:00+08:00","datePublished":"2019-04-09T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/09/727792.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>OpenCV 深度学习框架的使用</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/flyfish1986/article/details/89157368 
 </div> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p>OpenCV 深度学习框架的使用</p> 
  <p>flyfish</p> 
  <p>版本 4.1.0<br> 这个版本只提供模型使用，不提供训练<br> 官网共包含如下实例</p> 
  <pre><code>samples/dnn/classification.cpp
samples/dnn/colorization.cpp
samples/dnn/object_detection.cpp
samples/dnn/openpose.cpp
samples/dnn/segmentation.cpp
samples/dnn/text_detection.cpp
</code></pre> 
  <p>Confidence threshold 置信度阈值<br> Non-maximum suppression threshold非极大值抑制阈值</p> 
  <p>选择一个计算后端（Choose one of computation backends）</p> 
  <p>0: automatically (by default)<br> 1: Halide language （<a href="http://halide-lang.org/" rel="nofollow">http://halide-lang.org/</a>)<br> 2: Intel’s Deep Learning Inference Engine (<a href="https://software.intel.com/openvino-toolkit" rel="nofollow">https://software.intel.com/openvino-toolkit</a>)<br> 3: OpenCV implementation</p> 
  <p>代码是这样</p> 
  <pre><code>  cv::dnn::DNN_BACKEND_DEFAULT,
  cv::dnn::DNN_BACKEND_HALIDE,
  cv::dnn::DNN_BACKEND_INFERENCE_ENGINE,
  cv::dnn::DNN_BACKEND_OPENCV,
  cv::dnn::DNN_BACKEND_VKCOM
</code></pre> 
  <p>选择一个目标计算设备（Choose one of target computation devices）</p> 
  <p>0: CPU target (by default)<br> 1: OpenCL,<br> 2: OpenCL fp16 (half-float precision)<br> 3: VPU<br> 代码是这样</p> 
  <pre><code>  cv::dnn::DNN_TARGET_CPU,
  cv::dnn::DNN_TARGET_OPENCL,
  cv::dnn::DNN_TARGET_OPENCL_FP16,
  cv::dnn::DNN_TARGET_MYRIAD,
  cv::dnn::DNN_TARGET_VULKAN,
  cv::dnn::DNN_TARGET_FPGA
</code></pre> 
  <p>假设以目标分类为例</p> 
  <p>std::vector<a>std::string</a> classes<br> 类别，可以在代码里直接硬写入，也可以从文件读取</p> 
  <pre><code>std::string file = parser.get&lt;String&gt;("classes");
std::ifstream ifs(file.c_str());
if (!ifs.is_open())
    CV_Error(Error::StsError, "File " + file + " not found");
std::string line;
while (std::getline(ifs, line))
{
    classes.push_back(line);
}
</code></pre> 
  <p>加载模型 OpenCV支持以下模型</p> 
  <pre><code>Net   cv::dnn::net = readNet
Net   cv::dnn::readNetFromCaffe
Net 	cv::dnn::readNetFromDarknet
Net 	cv::dnn::readNetFromONNX
Net 	cv::dnn::readNetFromTensorflow
Net 	cv::dnn::readNetFromTorch
</code></pre> 
  <p>文件的扩展名<br> .caffemodel (Caffe, <a href="http://caffe.berkeleyvision.org/" rel="nofollow">http://caffe.berkeleyvision.org/</a>)<br> .pb (TensorFlow, <a href="https://www.tensorflow.org/" rel="nofollow">https://www.tensorflow.org/</a>)<br> .t7 | *.net (Torch, <a href="http://torch.ch/" rel="nofollow">http://torch.ch/</a>)<br> .weights (Darknet, <a href="https://pjreddie.com/darknet/" rel="nofollow">https://pjreddie.com/darknet/</a>)<br> .bin (DLDT, <a href="https://software.intel.com/openvino-toolkit" rel="nofollow">https://software.intel.com/openvino-toolkit</a>)</p> 
  <pre><code>net.setPreferableBackend(DNN_BACKEND_OPENCV);
net.setPreferableTarget(DNN_TARGET_CPU);
</code></pre> 
  <p>从数据帧中创建一个4维的blob</p> 
  <pre><code>Mat frame, blob;

        Size inpSize(inpWidth &gt; 0 ? inpWidth : frame.cols,
                     inpHeight &gt; 0 ? inpHeight : frame.rows);
blobFromImage(frame, blob, scale, inpSize, mean, swapRB, false);
</code></pre> 
  <p>解释重载函数</p> 
  <pre><code>void cv::dnn::blobFromImage 	( 	InputArray  	image,
		OutputArray  	blob,
		double  	scalefactor = 1.0,
		const Size &amp;  	size = Size(),
		const Scalar &amp;  	mean = Scalar(),
		bool  	swapRB = false,
		bool  	crop = false,
		int  	ddepth = CV_32F 
	) 	
</code></pre> 
  <p>image 可以是视频帧<br> blob是输出的数据<br> scalefactor 图像值的乘法器。<br> size 图像大小，也就是训练的时候使用图像的大小<br> mean<br> scalar with mean values which are subtracted from channels. Values are intended to be in (mean-R, mean-G, mean-B) order if image has BGR ordering and swapRB is true.<br> 标量，其平均值是从通道中减去的。<br> 值的顺序为(mean-R、mean-G、mean-B)<br> 如果图像具有BGR顺序，则swapRB为真。<br> 也就是图像通道有的是RGB顺序的，也有的是BGR顺序的，根据swapRB来判断通道顺序</p> 
  <p>swapRB 图像通道是RGB顺序还是BGR顺序的</p> 
  <p>if crop is true, input image is resized so one side after resize is equal to corresponding dimension in size and another one is equal or larger. Then, crop from the center is performed. If crop is false, direct resize without cropping and preserving aspect ratio is performed.<br> 如果crop为true，则对输入图像进行大小调整，裁剪图像。如果crop是false的，等比例缩放。</p> 
  <p>图像的数据类型，支持32F和8U<br> CV_8U unsigned<br> CV_32F float</p> 
  <p>运行模型</p> 
  <pre><code>net.setInput(blob);
std::vector&lt;Mat&gt; outs;
net.forward(outs, outNames);
</code></pre> 
  <p>这里的outNames由 std::vector outNames = net.getUnconnectedOutLayersNames();获取</p> 
  <pre><code>void cv::dnn::Net::forward 	( 	OutputArrayOfArrays  	outputBlobs,
		const std::vector&lt; String &gt; &amp;  	outBlobNames 
	) 	
</code></pre> 
  <p>运行前向传播来计算outBlobNames中列出的层的输出。</p> 
  <p>如果使用Qt编译<br> 可用如下配置</p> 
  <pre><code>TEMPLATE = app
CONFIG += console c++11
CONFIG -= app_bundle
CONFIG -= qt

INCLUDEPATH += /usr/local/include \
/usr/local/include/opencv4 \
/usr/local/include/opencv4/opencv2

LIBS += /usr/local/lib/libopencv_calib3d.so \
        /usr/local/lib/libopencv_core.so    \
        /usr/local/lib/libopencv_highgui.so \
        /usr/local/lib/libopencv_imgproc.so \
        /usr/local/lib/libopencv_imgcodecs.so\
        /usr/local/lib/libopencv_objdetect.so\
        /usr/local/lib/libopencv_photo.so \
        /usr/local/lib/libopencv_dnn.so \
        /usr/local/lib/libopencv_features2d.so \
        /usr/local/lib/libopencv_stitching.so \
        /usr/local/lib/libopencv_flann.so\
        /usr/local/lib/libopencv_videoio.so \
        /usr/local/lib/libopencv_video.so\
        /usr/local/lib/libopencv_ml.so

SOURCES += \
        main.cpp

HEADERS += \
    common.hpp
</code></pre> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
