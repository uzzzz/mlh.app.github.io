<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>【Tensorflow】图和模型的保存机制与原理 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="【Tensorflow】图和模型的保存机制与原理" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="核心定义： 主要类：tf.train.Saver类负责保存和还原神经网络 自动保存为三个文件：模型文件列表checkpoint，计算图结构model.ckpt.meta，每个变量的取值model.ckpt。其中前两个自动生成。 加载持久化图：通过tf.train.import_meta_graph(&quot;save/model.ckpt.meta&quot;)加载持久化的图 以下文章转载自：http://blog.csdn.net/lwplwf/article/details/62419087（零尾） ------------------------------------------------------------------------------------------------------------------ &nbsp; 之前的笔记里实现了softmax回归分类、简单的含有一个隐层的神经网络、卷积神经网络等等，但是这些代码在训练完成之后就直接退出了，并没有将训练得到的模型保存下来方便下次直接使用。为了让训练结果可以复用，需要将训练好的神经网络模型持久化，这就是这篇笔记里要写的东西。 TensorFlow提供了一个非常简单的API，即tf.train.Saver类来保存和还原一个神经网络模型。 下面代码给出了保存TensorFlow模型的方法： import tensorflow as tf # 声明两个变量 v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;) v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;) init_op = tf.global_variables_initializer() # 初始化全部变量 saver = tf.train.Saver(write_version=tf.train.SaverDef.V1) # 声明tf.train.Saver类用于保存模型 with tf.Session() as sess: sess.run(init_op) print(&quot;v1:&quot;, sess.run(v1)) # 打印v1、v2的值一会读取之后对比 print(&quot;v2:&quot;, sess.run(v2)) saver_path = saver.save(sess, &quot;save/model.ckpt&quot;) # 将模型保存到save/model.ckpt文件 print(&quot;Model saved in file:&quot;, saver_path) 注：Saver方法已经发生了更改，现在是V2版本，tf.train.Saver(write_version=tf.train.SaverDef.V1)括号里加入该参数可继续使用V1，但会报warning，可忽略。若使用saver = tf.train.Saver()则默认使用当前的版本（V2），保存后在save这个文件夹中会出现4个文件，比V1版多出model.ckpt.data-00000-of-00001这个文件，这点感谢评论里那位朋友指出。至于这个文件的含义到目前我仍不是很清楚，也没查到具体资料，TensorFlow15年底开源到现在很多类啊函数都一直发生着变动，或被更新或被弃用，可能一些代码在当时是没问题的，但过了一大段时间后再跑可能就会报错，在此注明事件时间：2017.4.30 &nbsp; 这段代码中，通过saver.save函数将TensorFlow模型保存到了save/model.ckpt文件中，这里代码中指定路径为&quot;save/model.ckpt&quot;，也就是保存到了当前程序所在文件夹里面的save文件夹中。 TensorFlow模型会保存在后缀为.ckpt的文件中。保存后在save这个文件夹中会出现3个文件，因为TensorFlow会将计算图的结构和图上参数取值分开保存。 checkpoint文件保存了一个目录下所有的模型文件列表，这个文件是tf.train.Saver类自动生成且自动维护的。在&nbsp;checkpoint文件中维护了由一个tf.train.Saver类持久化的所有TensorFlow模型文件的文件名。当某个保存的TensorFlow模型文件被删除时，这个模型所对应的文件名也会从checkpoint文件中删除。checkpoint中内容的格式为CheckpointState Protocol Buffer. model.ckpt.meta文件保存了TensorFlow计算图的结构，可以理解为神经网络的网络结构&nbsp; TensorFlow通过元图（MetaGraph）来记录计算图中节点的信息以及运行计算图中节点所需要的元数据。TensorFlow中元图是由MetaGraphDef Protocol Buffer定义的。MetaGraphDef 中的内容构成了TensorFlow持久化时的第一个文件。保存MetaGraphDef 信息的文件默认以.meta为后缀名，文件model.ckpt.meta中存储的就是元图数据。 model.ckpt文件保存了TensorFlow程序中每一个变量的取值，这个文件是通过SSTable格式存储的，可以大致理解为就是一个（key，value）列表。model.ckpt文件中列表的第一行描述了文件的元信息，比如在这个文件中存储的变量列表。列表剩下的每一行保存了一个变量的片段，变量片段的信息是通过SavedSlice Protocol Buffer定义的。SavedSlice类型中保存了变量的名称、当前片段的信息以及变量取值。TensorFlow提供了tf.train.NewCheckpointReader类来查看model.ckpt文件中保存的变量信息。如何使用tf.train.NewCheckpointReader类这里不做说明，自查。 下面代码给出了加载TensorFlow模型的方法： # 使用和保存模型代码中一样的方式来声明变量v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;) v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;) saver = tf.train.Saver() # 声明tf.train.Saver类用于保存模型 with tf.Session() as sess: saver.restore(sess, &quot;save/model.ckpt&quot;) # 即将固化到硬盘中的Session从保存路径再读取出来 print(&quot;v1:&quot;, sess.run(v1)) # 打印v1、v2的值和之前的进行对比 print(&quot;v2:&quot;, sess.run(v2)) print(&quot;Model Restored&quot;) 可以对比一下v1、v2的值是随机初始化的值还是和之前保存的值是一样的？import tensorflow as tf 运行结果： v1: [[ 0.76705766 1.82217288]] v2: [[-0.98012197 1.2369734 0.5797025 ] [ 2.50458145 0.81897354 0.07858191]] Model Restored 这段加载模型的代码基本上和保存模型的代码是一样的。也是先定义了TensorFlow计算图上所有的运算，并声明了一个tf.train.Saver类。两段唯一的不同是，在加载模型的代码中没有运行变量的初始化过程，而是将变量的值通过已经保存的模型加载进来。&nbsp; 也就是说使用TensorFlow完成了一次模型的保存和读取的操作。 #&nbsp;在重新导入tensorflow的图形之前，先清空它 tf.reset_default_graph() &nbsp; # 持久化导入导出图模型 saver = tf.train.Saver() &nbsp; saver.save(sess, &#39;my-model&#39;) &nbsp; sess = tf.Session() &nbsp; new_saver = tf.train.import_meta_graph(&#39;my-model.meta&#39;) &nbsp; tf.train.export_meta_graph(filename=&#39;my-model.meta&#39;) &nbsp; new_saver = tf.train.import_meta_graph(&#39;my-model.meta&#39;) &nbsp; 如果不希望重复定义图上的运算，也可以直接加载已经持久化的图： import tensorflow as tf # 在下面的代码中，默认加载了TensorFlow计算图上定义的全部变量 # 直接加载持久化的图 saver = tf.train.import_meta_graph(&quot;save/model.ckpt.meta&quot;) with tf.Session() as sess: saver.restore(sess, &quot;save/model.ckpt&quot;) # 通过张量的名称来获取张量 print(sess.run(tf.get_default_graph().get_tensor_by_name(&quot;v1:0&quot;))) 运行程序，输出： &nbsp; [[ 0.76705766 1.82217288]] 有时可能只需要保存或者加载部分变量。&nbsp; 比如，可能有一个之前训练好的5层神经网络模型，但现在想写一个6层的神经网络，那么可以将之前5层神经网络中的参数直接加载到新的模型，而仅仅将最后一层神经网络重新训练。 为了保存或者加载部分变量，在声明tf.train.Saver类时可以提供一个列表来指定需要保存或者加载的变量。比如在加载模型的代码中使用saver = tf.train.Saver([v1])命令来构建tf.train.Saver类，那么只有变量v1会被加载进来。 &nbsp; &nbsp; &nbsp;" />
<meta property="og:description" content="核心定义： 主要类：tf.train.Saver类负责保存和还原神经网络 自动保存为三个文件：模型文件列表checkpoint，计算图结构model.ckpt.meta，每个变量的取值model.ckpt。其中前两个自动生成。 加载持久化图：通过tf.train.import_meta_graph(&quot;save/model.ckpt.meta&quot;)加载持久化的图 以下文章转载自：http://blog.csdn.net/lwplwf/article/details/62419087（零尾） ------------------------------------------------------------------------------------------------------------------ &nbsp; 之前的笔记里实现了softmax回归分类、简单的含有一个隐层的神经网络、卷积神经网络等等，但是这些代码在训练完成之后就直接退出了，并没有将训练得到的模型保存下来方便下次直接使用。为了让训练结果可以复用，需要将训练好的神经网络模型持久化，这就是这篇笔记里要写的东西。 TensorFlow提供了一个非常简单的API，即tf.train.Saver类来保存和还原一个神经网络模型。 下面代码给出了保存TensorFlow模型的方法： import tensorflow as tf # 声明两个变量 v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;) v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;) init_op = tf.global_variables_initializer() # 初始化全部变量 saver = tf.train.Saver(write_version=tf.train.SaverDef.V1) # 声明tf.train.Saver类用于保存模型 with tf.Session() as sess: sess.run(init_op) print(&quot;v1:&quot;, sess.run(v1)) # 打印v1、v2的值一会读取之后对比 print(&quot;v2:&quot;, sess.run(v2)) saver_path = saver.save(sess, &quot;save/model.ckpt&quot;) # 将模型保存到save/model.ckpt文件 print(&quot;Model saved in file:&quot;, saver_path) 注：Saver方法已经发生了更改，现在是V2版本，tf.train.Saver(write_version=tf.train.SaverDef.V1)括号里加入该参数可继续使用V1，但会报warning，可忽略。若使用saver = tf.train.Saver()则默认使用当前的版本（V2），保存后在save这个文件夹中会出现4个文件，比V1版多出model.ckpt.data-00000-of-00001这个文件，这点感谢评论里那位朋友指出。至于这个文件的含义到目前我仍不是很清楚，也没查到具体资料，TensorFlow15年底开源到现在很多类啊函数都一直发生着变动，或被更新或被弃用，可能一些代码在当时是没问题的，但过了一大段时间后再跑可能就会报错，在此注明事件时间：2017.4.30 &nbsp; 这段代码中，通过saver.save函数将TensorFlow模型保存到了save/model.ckpt文件中，这里代码中指定路径为&quot;save/model.ckpt&quot;，也就是保存到了当前程序所在文件夹里面的save文件夹中。 TensorFlow模型会保存在后缀为.ckpt的文件中。保存后在save这个文件夹中会出现3个文件，因为TensorFlow会将计算图的结构和图上参数取值分开保存。 checkpoint文件保存了一个目录下所有的模型文件列表，这个文件是tf.train.Saver类自动生成且自动维护的。在&nbsp;checkpoint文件中维护了由一个tf.train.Saver类持久化的所有TensorFlow模型文件的文件名。当某个保存的TensorFlow模型文件被删除时，这个模型所对应的文件名也会从checkpoint文件中删除。checkpoint中内容的格式为CheckpointState Protocol Buffer. model.ckpt.meta文件保存了TensorFlow计算图的结构，可以理解为神经网络的网络结构&nbsp; TensorFlow通过元图（MetaGraph）来记录计算图中节点的信息以及运行计算图中节点所需要的元数据。TensorFlow中元图是由MetaGraphDef Protocol Buffer定义的。MetaGraphDef 中的内容构成了TensorFlow持久化时的第一个文件。保存MetaGraphDef 信息的文件默认以.meta为后缀名，文件model.ckpt.meta中存储的就是元图数据。 model.ckpt文件保存了TensorFlow程序中每一个变量的取值，这个文件是通过SSTable格式存储的，可以大致理解为就是一个（key，value）列表。model.ckpt文件中列表的第一行描述了文件的元信息，比如在这个文件中存储的变量列表。列表剩下的每一行保存了一个变量的片段，变量片段的信息是通过SavedSlice Protocol Buffer定义的。SavedSlice类型中保存了变量的名称、当前片段的信息以及变量取值。TensorFlow提供了tf.train.NewCheckpointReader类来查看model.ckpt文件中保存的变量信息。如何使用tf.train.NewCheckpointReader类这里不做说明，自查。 下面代码给出了加载TensorFlow模型的方法： # 使用和保存模型代码中一样的方式来声明变量v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;) v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;) saver = tf.train.Saver() # 声明tf.train.Saver类用于保存模型 with tf.Session() as sess: saver.restore(sess, &quot;save/model.ckpt&quot;) # 即将固化到硬盘中的Session从保存路径再读取出来 print(&quot;v1:&quot;, sess.run(v1)) # 打印v1、v2的值和之前的进行对比 print(&quot;v2:&quot;, sess.run(v2)) print(&quot;Model Restored&quot;) 可以对比一下v1、v2的值是随机初始化的值还是和之前保存的值是一样的？import tensorflow as tf 运行结果： v1: [[ 0.76705766 1.82217288]] v2: [[-0.98012197 1.2369734 0.5797025 ] [ 2.50458145 0.81897354 0.07858191]] Model Restored 这段加载模型的代码基本上和保存模型的代码是一样的。也是先定义了TensorFlow计算图上所有的运算，并声明了一个tf.train.Saver类。两段唯一的不同是，在加载模型的代码中没有运行变量的初始化过程，而是将变量的值通过已经保存的模型加载进来。&nbsp; 也就是说使用TensorFlow完成了一次模型的保存和读取的操作。 #&nbsp;在重新导入tensorflow的图形之前，先清空它 tf.reset_default_graph() &nbsp; # 持久化导入导出图模型 saver = tf.train.Saver() &nbsp; saver.save(sess, &#39;my-model&#39;) &nbsp; sess = tf.Session() &nbsp; new_saver = tf.train.import_meta_graph(&#39;my-model.meta&#39;) &nbsp; tf.train.export_meta_graph(filename=&#39;my-model.meta&#39;) &nbsp; new_saver = tf.train.import_meta_graph(&#39;my-model.meta&#39;) &nbsp; 如果不希望重复定义图上的运算，也可以直接加载已经持久化的图： import tensorflow as tf # 在下面的代码中，默认加载了TensorFlow计算图上定义的全部变量 # 直接加载持久化的图 saver = tf.train.import_meta_graph(&quot;save/model.ckpt.meta&quot;) with tf.Session() as sess: saver.restore(sess, &quot;save/model.ckpt&quot;) # 通过张量的名称来获取张量 print(sess.run(tf.get_default_graph().get_tensor_by_name(&quot;v1:0&quot;))) 运行程序，输出： &nbsp; [[ 0.76705766 1.82217288]] 有时可能只需要保存或者加载部分变量。&nbsp; 比如，可能有一个之前训练好的5层神经网络模型，但现在想写一个6层的神经网络，那么可以将之前5层神经网络中的参数直接加载到新的模型，而仅仅将最后一层神经网络重新训练。 为了保存或者加载部分变量，在声明tf.train.Saver类时可以提供一个列表来指定需要保存或者加载的变量。比如在加载模型的代码中使用saver = tf.train.Saver([v1])命令来构建tf.train.Saver类，那么只有变量v1会被加载进来。 &nbsp; &nbsp; &nbsp;" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-09T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"核心定义： 主要类：tf.train.Saver类负责保存和还原神经网络 自动保存为三个文件：模型文件列表checkpoint，计算图结构model.ckpt.meta，每个变量的取值model.ckpt。其中前两个自动生成。 加载持久化图：通过tf.train.import_meta_graph(&quot;save/model.ckpt.meta&quot;)加载持久化的图 以下文章转载自：http://blog.csdn.net/lwplwf/article/details/62419087（零尾） ------------------------------------------------------------------------------------------------------------------ &nbsp; 之前的笔记里实现了softmax回归分类、简单的含有一个隐层的神经网络、卷积神经网络等等，但是这些代码在训练完成之后就直接退出了，并没有将训练得到的模型保存下来方便下次直接使用。为了让训练结果可以复用，需要将训练好的神经网络模型持久化，这就是这篇笔记里要写的东西。 TensorFlow提供了一个非常简单的API，即tf.train.Saver类来保存和还原一个神经网络模型。 下面代码给出了保存TensorFlow模型的方法： import tensorflow as tf # 声明两个变量 v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;) v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;) init_op = tf.global_variables_initializer() # 初始化全部变量 saver = tf.train.Saver(write_version=tf.train.SaverDef.V1) # 声明tf.train.Saver类用于保存模型 with tf.Session() as sess: sess.run(init_op) print(&quot;v1:&quot;, sess.run(v1)) # 打印v1、v2的值一会读取之后对比 print(&quot;v2:&quot;, sess.run(v2)) saver_path = saver.save(sess, &quot;save/model.ckpt&quot;) # 将模型保存到save/model.ckpt文件 print(&quot;Model saved in file:&quot;, saver_path) 注：Saver方法已经发生了更改，现在是V2版本，tf.train.Saver(write_version=tf.train.SaverDef.V1)括号里加入该参数可继续使用V1，但会报warning，可忽略。若使用saver = tf.train.Saver()则默认使用当前的版本（V2），保存后在save这个文件夹中会出现4个文件，比V1版多出model.ckpt.data-00000-of-00001这个文件，这点感谢评论里那位朋友指出。至于这个文件的含义到目前我仍不是很清楚，也没查到具体资料，TensorFlow15年底开源到现在很多类啊函数都一直发生着变动，或被更新或被弃用，可能一些代码在当时是没问题的，但过了一大段时间后再跑可能就会报错，在此注明事件时间：2017.4.30 &nbsp; 这段代码中，通过saver.save函数将TensorFlow模型保存到了save/model.ckpt文件中，这里代码中指定路径为&quot;save/model.ckpt&quot;，也就是保存到了当前程序所在文件夹里面的save文件夹中。 TensorFlow模型会保存在后缀为.ckpt的文件中。保存后在save这个文件夹中会出现3个文件，因为TensorFlow会将计算图的结构和图上参数取值分开保存。 checkpoint文件保存了一个目录下所有的模型文件列表，这个文件是tf.train.Saver类自动生成且自动维护的。在&nbsp;checkpoint文件中维护了由一个tf.train.Saver类持久化的所有TensorFlow模型文件的文件名。当某个保存的TensorFlow模型文件被删除时，这个模型所对应的文件名也会从checkpoint文件中删除。checkpoint中内容的格式为CheckpointState Protocol Buffer. model.ckpt.meta文件保存了TensorFlow计算图的结构，可以理解为神经网络的网络结构&nbsp; TensorFlow通过元图（MetaGraph）来记录计算图中节点的信息以及运行计算图中节点所需要的元数据。TensorFlow中元图是由MetaGraphDef Protocol Buffer定义的。MetaGraphDef 中的内容构成了TensorFlow持久化时的第一个文件。保存MetaGraphDef 信息的文件默认以.meta为后缀名，文件model.ckpt.meta中存储的就是元图数据。 model.ckpt文件保存了TensorFlow程序中每一个变量的取值，这个文件是通过SSTable格式存储的，可以大致理解为就是一个（key，value）列表。model.ckpt文件中列表的第一行描述了文件的元信息，比如在这个文件中存储的变量列表。列表剩下的每一行保存了一个变量的片段，变量片段的信息是通过SavedSlice Protocol Buffer定义的。SavedSlice类型中保存了变量的名称、当前片段的信息以及变量取值。TensorFlow提供了tf.train.NewCheckpointReader类来查看model.ckpt文件中保存的变量信息。如何使用tf.train.NewCheckpointReader类这里不做说明，自查。 下面代码给出了加载TensorFlow模型的方法： # 使用和保存模型代码中一样的方式来声明变量v1 = tf.Variable(tf.random_normal([1, 2]), name=&quot;v1&quot;) v2 = tf.Variable(tf.random_normal([2, 3]), name=&quot;v2&quot;) saver = tf.train.Saver() # 声明tf.train.Saver类用于保存模型 with tf.Session() as sess: saver.restore(sess, &quot;save/model.ckpt&quot;) # 即将固化到硬盘中的Session从保存路径再读取出来 print(&quot;v1:&quot;, sess.run(v1)) # 打印v1、v2的值和之前的进行对比 print(&quot;v2:&quot;, sess.run(v2)) print(&quot;Model Restored&quot;) 可以对比一下v1、v2的值是随机初始化的值还是和之前保存的值是一样的？import tensorflow as tf 运行结果： v1: [[ 0.76705766 1.82217288]] v2: [[-0.98012197 1.2369734 0.5797025 ] [ 2.50458145 0.81897354 0.07858191]] Model Restored 这段加载模型的代码基本上和保存模型的代码是一样的。也是先定义了TensorFlow计算图上所有的运算，并声明了一个tf.train.Saver类。两段唯一的不同是，在加载模型的代码中没有运行变量的初始化过程，而是将变量的值通过已经保存的模型加载进来。&nbsp; 也就是说使用TensorFlow完成了一次模型的保存和读取的操作。 #&nbsp;在重新导入tensorflow的图形之前，先清空它 tf.reset_default_graph() &nbsp; # 持久化导入导出图模型 saver = tf.train.Saver() &nbsp; saver.save(sess, &#39;my-model&#39;) &nbsp; sess = tf.Session() &nbsp; new_saver = tf.train.import_meta_graph(&#39;my-model.meta&#39;) &nbsp; tf.train.export_meta_graph(filename=&#39;my-model.meta&#39;) &nbsp; new_saver = tf.train.import_meta_graph(&#39;my-model.meta&#39;) &nbsp; 如果不希望重复定义图上的运算，也可以直接加载已经持久化的图： import tensorflow as tf # 在下面的代码中，默认加载了TensorFlow计算图上定义的全部变量 # 直接加载持久化的图 saver = tf.train.import_meta_graph(&quot;save/model.ckpt.meta&quot;) with tf.Session() as sess: saver.restore(sess, &quot;save/model.ckpt&quot;) # 通过张量的名称来获取张量 print(sess.run(tf.get_default_graph().get_tensor_by_name(&quot;v1:0&quot;))) 运行程序，输出： &nbsp; [[ 0.76705766 1.82217288]] 有时可能只需要保存或者加载部分变量。&nbsp; 比如，可能有一个之前训练好的5层神经网络模型，但现在想写一个6层的神经网络，那么可以将之前5层神经网络中的参数直接加载到新的模型，而仅仅将最后一层神经网络重新训练。 为了保存或者加载部分变量，在声明tf.train.Saver类时可以提供一个列表来指定需要保存或者加载的变量。比如在加载模型的代码中使用saver = tf.train.Saver([v1])命令来构建tf.train.Saver类，那么只有变量v1会被加载进来。 &nbsp; &nbsp; &nbsp;","@type":"BlogPosting","url":"/2019/04/09/727791.html","headline":"【Tensorflow】图和模型的保存机制与原理","dateModified":"2019-04-09T00:00:00+08:00","datePublished":"2019-04-09T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/09/727791.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>【Tensorflow】图和模型的保存机制与原理</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p><strong>核心定义：</strong></p> 
  <p>主要类：tf.train.Saver类负责保存和还原神经网络</p> 
  <p>自动保存为三个文件：模型文件列表checkpoint，计算图结构model.ckpt.meta，每个变量的取值model.ckpt。其中前两个自动生成。</p> 
  <p>加载持久化图：通过tf.train.import_meta_graph("save/model.ckpt.meta")加载持久化的图</p> 
  <p>以下文章转载自：http://blog.csdn.net/lwplwf/article/details/62419087（零尾）</p> 
  <p>------------------------------------------------------------------------------------------------------------------</p> 
  <p>&nbsp;</p> 
  <p>之前的笔记里实现了softmax回归分类、简单的含有一个隐层的神经网络、卷积神经网络等等，但是这些代码在训练完成之后就直接退出了，并没有将训练得到的模型保存下来方便下次直接使用。为了让训练结果可以复用，需要将训练好的神经网络模型持久化，这就是这篇笔记里要写的东西。</p> 
  <p>TensorFlow提供了一个非常简单的API，即<code>tf.train.Saver</code>类来保存和还原一个神经网络模型。</p> 
  <p><strong>下面代码给出了保存TensorFlow模型的方法：</strong></p> 
  <p>import tensorflow as tf</p> 
  <p># 声明两个变量</p> 
  <p>v1 = tf.Variable(tf.random_normal([1, 2]), name="v1")</p> 
  <p>v2 = tf.Variable(tf.random_normal([2, 3]), name="v2")</p> 
  <p>init_op = tf.global_variables_initializer() # 初始化全部变量</p> 
  <p>saver = tf.train.Saver(write_version=tf.train.SaverDef.V1) # 声明tf.train.Saver类用于保存模型</p> 
  <p>with tf.Session() as sess:</p> 
  <p>sess.run(init_op)</p> 
  <p>print("v1:", sess.run(v1)) # 打印v1、v2的值一会读取之后对比</p> 
  <p>print("v2:", sess.run(v2))</p> 
  <p>saver_path = saver.save(sess, "save/model.ckpt") # 将模型保存到save/model.ckpt文件</p> 
  <p>print("Model saved in file:", saver_path)</p> 
  <p><strong>注：Saver方法已经发生了更改，现在是V2版本，tf.train.Saver(write_version=tf.train.SaverDef.V1)括号里加入该参数可继续使用V1，但会报warning，可忽略。若使用saver = tf.train.Saver()则默认使用当前的版本（V2），保存后在save这个文件夹中会出现4个文件，比V1版多出<code>model.ckpt.data-00000-of-00001</code>这个文件，这点感谢评论里那位朋友指出。至于这个文件的含义到目前我仍不是很清楚，也没查到具体资料，TensorFlow15年底开源到现在很多类啊函数都一直发生着变动，或被更新或被弃用，可能一些代码在当时是没问题的，但过了一大段时间后再跑可能就会报错，在此注明事件时间：2017.4.30</strong></p> 
  <p>&nbsp;</p> 
  <p>这段代码中，通过<code>saver.save</code>函数将TensorFlow模型保存到了save/model.ckpt文件中，这里代码中指定路径为<code>"save/model.ckpt"</code>，也就是保存到了当前程序所在文件夹里面的<code>save</code>文件夹中。</p> 
  <p>TensorFlow模型会保存在后缀为<code>.ckpt</code>的文件中。保存后在save这个文件夹中会出现3个文件，因为TensorFlow会将计算图的结构和图上参数取值分开保存。</p> 
  <ul>
   <li> <p><code>checkpoint</code>文件保存了一个目录下所有的模型文件列表，这个文件是<code>tf.train.Saver</code>类自动生成且自动维护的。在&nbsp;<code>checkpoint</code>文件中维护了由一个<code>tf.train.Saver</code>类持久化的所有TensorFlow模型文件的文件名。当某个保存的TensorFlow模型文件被删除时，这个模型所对应的文件名也会从<code>checkpoint</code>文件中删除。<code>checkpoint</code>中内容的格式为CheckpointState Protocol Buffer.</p> </li> 
   <li> <p><code>model.ckpt.meta</code>文件保存了TensorFlow计算图的结构，可以理解为神经网络的网络结构&nbsp;<br> TensorFlow通过元图（MetaGraph）来记录计算图中节点的信息以及运行计算图中节点所需要的元数据。TensorFlow中元图是由MetaGraphDef Protocol Buffer定义的。MetaGraphDef 中的内容构成了TensorFlow持久化时的第一个文件。保存MetaGraphDef 信息的文件默认以.meta为后缀名，文件<code>model.ckpt.meta</code>中存储的就是元图数据。</p> </li> 
   <li> <p><code>model.ckpt</code>文件保存了TensorFlow程序中每一个变量的取值，这个文件是通过SSTable格式存储的，可以大致理解为就是一个（key，value）列表。<code>model.ckpt</code>文件中列表的第一行描述了文件的元信息，比如在这个文件中存储的变量列表。列表剩下的每一行保存了一个变量的片段，变量片段的信息是通过SavedSlice Protocol Buffer定义的。SavedSlice类型中保存了变量的名称、当前片段的信息以及变量取值。TensorFlow提供了<code>tf.train.NewCheckpointReader</code>类来查看<code>model.ckpt</code>文件中保存的变量信息。如何使用<code>tf.train.NewCheckpointReader</code>类这里不做说明，自查。</p> </li> 
   <li> <p><img alt="这里写图片描述" class="has" height="337" src="https://blog.uzzz.org.cn/_p?https://img-blog.csdn.net/20170430200025228?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbHdwbHdm/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" width="637"></p> </li> 
   <li><strong>下面代码给出了加载TensorFlow</strong><strong>模型的方法：</strong></li> 
   <li># 使用和保存模型代码中一样的方式来声明变量v1 = tf.Variable(tf.random_normal([1, 2]), name="v1")</li> 
   <li>v2 = tf.Variable(tf.random_normal([2, 3]), name="v2")</li> 
   <li>saver = tf.train.Saver() # 声明tf.train.Saver类用于保存模型</li> 
   <li>with tf.Session() as sess:</li> 
   <li>saver.restore(sess, "save/model.ckpt") # 即将固化到硬盘中的Session从保存路径再读取出来</li> 
   <li>print("v1:", sess.run(v1)) # 打印v1、v2的值和之前的进行对比</li> 
   <li>print("v2:", sess.run(v2))</li> 
   <li>print("Model Restored")</li> 
   <li>可以对比一下v1、v2的值是随机初始化的值还是和之前保存的值是一样的？import tensorflow as tf</li> 
  </ul>
  <p>运行结果：</p> 
  <p>v1: [[ 0.76705766 1.82217288]]</p> 
  <p>v2: [[-0.98012197 1.2369734 0.5797025 ]</p> 
  <p>[ 2.50458145 0.81897354 0.07858191]]</p> 
  <p>Model Restored</p> 
  <p>这段加载模型的代码基本上和保存模型的代码是一样的。也是先定义了TensorFlow计算图上所有的运算，并声明了一个<code>tf.train.Saver</code>类。两段唯一的不同是，在加载模型的代码中没有运行变量的初始化过程，而是将变量的值通过已经保存的模型加载进来。&nbsp;<br> 也就是说使用TensorFlow完成了一次模型的保存和读取的操作。</p> 
  <p><strong>#&nbsp;在重新导入tensorflow的图形之前，先清空它</strong></p> 
  <p>tf.reset_default_graph() &nbsp;</p> 
  <p><strong># 持久化导入导出图模型</strong></p> 
  <p>saver = tf.train.Saver() &nbsp;<br> saver.save(sess, 'my-model') &nbsp;<br> sess = tf.Session() &nbsp;<br> new_saver = tf.train.import_meta_graph('my-model.meta') &nbsp;<br><br> tf.train.export_meta_graph(filename='my-model.meta') &nbsp;<br> new_saver = tf.train.import_meta_graph('my-model.meta') &nbsp;</p> 
  <hr>
  <hr>
  <p><strong>如果不希望重复定义图上的运算，也可以直接加载已经持久化的图：</strong></p> 
  <ul>
   <li>import tensorflow as tf</li> 
   <li># 在下面的代码中，默认加载了TensorFlow计算图上定义的全部变量</li> 
   <li># 直接加载持久化的图</li> 
   <li>saver = tf.train.import_meta_graph("save/model.ckpt.meta")</li> 
   <li>with tf.Session() as sess:</li> 
   <li>saver.restore(sess, "save/model.ckpt")</li> 
   <li># 通过张量的名称来获取张量</li> 
   <li>print(sess.run(tf.get_default_graph().get_tensor_by_name("v1:0")))</li> 
  </ul>
  <pre>
运行程序，输出：

&nbsp; [[ 0.76705766 1.82217288]]
</pre> 
  <p><strong>有时可能只需要保存或者加载部分变量。&nbsp;</strong><br> 比如，可能有一个之前训练好的5层神经网络模型，但现在想写一个6层的神经网络，那么可以将之前5层神经网络中的参数直接加载到新的模型，而仅仅将最后一层神经网络重新训练。</p> 
  <p>为了保存或者加载部分变量，在声明<code>tf.train.Saver</code>类时可以提供一个列表来指定需要保存或者加载的变量。比如在加载模型的代码中使用<code>saver = tf.train.Saver([v1])</code>命令来构建<code>tf.train.Saver</code>类，那么只有变量v1会被加载进来。</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
