<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>mapreduce 单词统计 案例 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="mapreduce 单词统计 案例" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="mapreduce 单词统计 案例 一、Hadoop MapReduce 构思体现在如下的三个方面： 1.如何对付大数据处理：分而治之 2.构建抽象模型：Map 和 Reduce Map: 对一组数据元素进行某种重复式的处理； Reduce: 对 Map 的中间结果进行某种进一步的结果整理。 MapReduce 处理的数据类型是&lt;key,value&gt;键值对 3.统一构架，隐藏系统层细节 MapReduce 最大的亮点在于通过抽象模型和计算框架把需要做什么(what need to do)与具体怎么做(how to do)分开了，为程序员提供一个抽象和高层的编 程接口和框架。 二、Mapreduce 框架结构： 一个完整的mapreduce 框架由三个实例进程： 1.MRAppMaster ：负责整个程序的过程调度以及状态协调。 2.MapTask :负责map阶段的整个数据的处理。 3.ReduceTask :负责reduce阶段的整个数据的处理。 三、Mapreduce 的编写规范： （1）用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行 mr 程 序的客户端) Mapper 的输入数据是 KV 对的形式（KV 的类型可自定义） （3）Mapper 的输出数据是 KV 对的形式（KV 的类型可自定义） （4）Mapper 中的业务逻辑写在 map()方法中 （5）map()方法（maptask 进程）对每一个&lt;K,V&gt;调用一次 （6）Reducer 的输入数据类型对应 Mapper 的输出数据类型，也是 KV （7）Reducer 的业务逻辑写在 reduce()方法中 （8）Reducetask 进程对每一组相同 k 的&lt;k,v&gt;组调用一次 reduce()方法 （9）用户自定义的 Mapper 和 Reducer 都要继承各自的父类 （10）整个程序需要一个 Drvier 来进行提交，提交的是一个描述了各种必要信 息的 job 对象 Mapreduce 的wrodcount 小程序： 1.创建maven工程 引入 pom.xml org.apache.hadoop hadoop-common 2.7.4 org.apache.hadoop hadoop-hdfs 2.7.4 org.apache.hadoop hadoop-client 2.7.4 org.apache.hadoop hadoop-mapreduce-client-core 2.7.4 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;cn.itcast.mapreduce.WordCountDriver&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 2.创建一个wrodCountMapper 类 继承Mapper&lt;KEYYIN,VALUEIN,KEYOUT,VALUEOUT&gt; KEYIN:map输入中的key 在默认读取数据的组件下textInputFormat(一行一行读) Key:表示是该行的起始偏移量（就是光标所在的位置值）longwritable Value：表示该行的内容 VALUEIN:map输入kv中的value 在默认读取数据的组件下TextInputFormat(一行一行读) 表明的是内容 （string—&gt;text） KEYOUT:map输出的kv中的key 在我们的需求中 把单词作为输出的key (string --&gt;text) VALUEOUT：map输出kv中的value 在我们的需求中 把单词的次数1作为输出的value （int–&gt;intwritable） 简而言之:keyin 读取文本光标的偏移量，valuein：读取文本时该行文本的内容 相当于map输入中的key.keyout:map输出时的key ;valueout:map输出时的value:数值 intwritable 核心命令： hadoop fs -mkdir -p /wordcount/input hadoop fs -put -p /root/wenben/a.txt /wordcount/input hadoop fs -ls / hadoop fs -cat /wordcount/input/a.txt hadoop fs -rm -r /wordcont/output hadoop jar jar报 ；//hadoop 执行jar包 hdfs: 监控端口 note1:50070 yarn :监控端口 note1:8088 Mapreduce 统计单词数 案例： 创建maven 工程 1.* key:偏移量 没啥用 value:map输入时读取文本文件其中的一行数据 context:mapreduce 封装好的输出对象。 */ public class WrodCountMapper extends Mapper&lt;LongWritable,Text,Text,IntWritable&gt; { @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { String line=value.toString(); String[] words = line.split(&quot; &quot;); for (String word:words ) { context.write(new Text(word),new IntWritable(1)); } } } 2./* key ：就是每个单词 values： 相当于处理后的单词 如：hadoop[1,1,1] context :是mapreduce 封装好的输出对象 */ public class wordCountReduce extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt;{ @Override protected void reduce(Text key, Iterable values, Context context) throws IOException, InterruptedException { int count=0; for (IntWritable value : values) { count +=value.get(); } context.write(key,new IntWritable(count)); } 3.public class WordCountDirver { public static void main(String[] args) throws Exception { Configuration conf= new Configuration(); conf.set(“mapreduce.framework.name”,“yarn”); Job job = Job.getInstance(conf); //指定本次mr程序运行的主类 job.setJarByClass(WordCountDirver.class); //指定本次mr运行程序的mapper 和reducer job.setMapperClass(WrodCountMapper.class); //指定本次Mr程序的reducer job.setReducerClass(wordCountReduce.class); //指定本次mr程序map阶段的输出类型 job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(IntWritable.class); //指定本次mr程序reducer阶段的输出类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); //指定要处理的数据所在位置 FileInputFormat.setInputPaths(job,new Path(&quot;hdfs://note1:9000/wordcount/input&quot;));//此目录hdfs上必须存在 FileOutputFormat.setOutputPath(job,new Path(&quot;hdfs://note1:9000/wordcount/output&quot;));注意此目录必须不存在 //想yarn 集群提交job job.submit(); 这个我们看不到日志 一般不用 用下面job.waitForCompletion(true) true:代表监控并打印输出 job.waitForCompletion(true); } } 遇到的问题： Yarn 网页端口： note1:8088 监控不到 原因： 修改集群配置文件yarn-site.xml，加上如下几句： mapreduce.framework.name yarn 遇到的问题二：结果成功输出 但报 inter… thread wait jion 等问题？ 解决：在driver类中 添加 就是将mapreduce 提交到哪里去 也是yarn-site.xml 配置的 《property》 conf.set(“mapreduce.framework.name”,“yarn”); 同时这是指在yarn集群上运行 但是如果代码有问题，我们有需要重新打包 等一系列操作 太麻烦。 我们可以现在本地上运行，测试有没有bug 本地运行：只需要将conf.set(“mareduce.framework.name”,”local”) 还需要将 读取的文件路径和输出的路径改成windows本地地址即可。 主意输出的目录必须不存在。" />
<meta property="og:description" content="mapreduce 单词统计 案例 一、Hadoop MapReduce 构思体现在如下的三个方面： 1.如何对付大数据处理：分而治之 2.构建抽象模型：Map 和 Reduce Map: 对一组数据元素进行某种重复式的处理； Reduce: 对 Map 的中间结果进行某种进一步的结果整理。 MapReduce 处理的数据类型是&lt;key,value&gt;键值对 3.统一构架，隐藏系统层细节 MapReduce 最大的亮点在于通过抽象模型和计算框架把需要做什么(what need to do)与具体怎么做(how to do)分开了，为程序员提供一个抽象和高层的编 程接口和框架。 二、Mapreduce 框架结构： 一个完整的mapreduce 框架由三个实例进程： 1.MRAppMaster ：负责整个程序的过程调度以及状态协调。 2.MapTask :负责map阶段的整个数据的处理。 3.ReduceTask :负责reduce阶段的整个数据的处理。 三、Mapreduce 的编写规范： （1）用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行 mr 程 序的客户端) Mapper 的输入数据是 KV 对的形式（KV 的类型可自定义） （3）Mapper 的输出数据是 KV 对的形式（KV 的类型可自定义） （4）Mapper 中的业务逻辑写在 map()方法中 （5）map()方法（maptask 进程）对每一个&lt;K,V&gt;调用一次 （6）Reducer 的输入数据类型对应 Mapper 的输出数据类型，也是 KV （7）Reducer 的业务逻辑写在 reduce()方法中 （8）Reducetask 进程对每一组相同 k 的&lt;k,v&gt;组调用一次 reduce()方法 （9）用户自定义的 Mapper 和 Reducer 都要继承各自的父类 （10）整个程序需要一个 Drvier 来进行提交，提交的是一个描述了各种必要信 息的 job 对象 Mapreduce 的wrodcount 小程序： 1.创建maven工程 引入 pom.xml org.apache.hadoop hadoop-common 2.7.4 org.apache.hadoop hadoop-hdfs 2.7.4 org.apache.hadoop hadoop-client 2.7.4 org.apache.hadoop hadoop-mapreduce-client-core 2.7.4 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;cn.itcast.mapreduce.WordCountDriver&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 2.创建一个wrodCountMapper 类 继承Mapper&lt;KEYYIN,VALUEIN,KEYOUT,VALUEOUT&gt; KEYIN:map输入中的key 在默认读取数据的组件下textInputFormat(一行一行读) Key:表示是该行的起始偏移量（就是光标所在的位置值）longwritable Value：表示该行的内容 VALUEIN:map输入kv中的value 在默认读取数据的组件下TextInputFormat(一行一行读) 表明的是内容 （string—&gt;text） KEYOUT:map输出的kv中的key 在我们的需求中 把单词作为输出的key (string --&gt;text) VALUEOUT：map输出kv中的value 在我们的需求中 把单词的次数1作为输出的value （int–&gt;intwritable） 简而言之:keyin 读取文本光标的偏移量，valuein：读取文本时该行文本的内容 相当于map输入中的key.keyout:map输出时的key ;valueout:map输出时的value:数值 intwritable 核心命令： hadoop fs -mkdir -p /wordcount/input hadoop fs -put -p /root/wenben/a.txt /wordcount/input hadoop fs -ls / hadoop fs -cat /wordcount/input/a.txt hadoop fs -rm -r /wordcont/output hadoop jar jar报 ；//hadoop 执行jar包 hdfs: 监控端口 note1:50070 yarn :监控端口 note1:8088 Mapreduce 统计单词数 案例： 创建maven 工程 1.* key:偏移量 没啥用 value:map输入时读取文本文件其中的一行数据 context:mapreduce 封装好的输出对象。 */ public class WrodCountMapper extends Mapper&lt;LongWritable,Text,Text,IntWritable&gt; { @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { String line=value.toString(); String[] words = line.split(&quot; &quot;); for (String word:words ) { context.write(new Text(word),new IntWritable(1)); } } } 2./* key ：就是每个单词 values： 相当于处理后的单词 如：hadoop[1,1,1] context :是mapreduce 封装好的输出对象 */ public class wordCountReduce extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt;{ @Override protected void reduce(Text key, Iterable values, Context context) throws IOException, InterruptedException { int count=0; for (IntWritable value : values) { count +=value.get(); } context.write(key,new IntWritable(count)); } 3.public class WordCountDirver { public static void main(String[] args) throws Exception { Configuration conf= new Configuration(); conf.set(“mapreduce.framework.name”,“yarn”); Job job = Job.getInstance(conf); //指定本次mr程序运行的主类 job.setJarByClass(WordCountDirver.class); //指定本次mr运行程序的mapper 和reducer job.setMapperClass(WrodCountMapper.class); //指定本次Mr程序的reducer job.setReducerClass(wordCountReduce.class); //指定本次mr程序map阶段的输出类型 job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(IntWritable.class); //指定本次mr程序reducer阶段的输出类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); //指定要处理的数据所在位置 FileInputFormat.setInputPaths(job,new Path(&quot;hdfs://note1:9000/wordcount/input&quot;));//此目录hdfs上必须存在 FileOutputFormat.setOutputPath(job,new Path(&quot;hdfs://note1:9000/wordcount/output&quot;));注意此目录必须不存在 //想yarn 集群提交job job.submit(); 这个我们看不到日志 一般不用 用下面job.waitForCompletion(true) true:代表监控并打印输出 job.waitForCompletion(true); } } 遇到的问题： Yarn 网页端口： note1:8088 监控不到 原因： 修改集群配置文件yarn-site.xml，加上如下几句： mapreduce.framework.name yarn 遇到的问题二：结果成功输出 但报 inter… thread wait jion 等问题？ 解决：在driver类中 添加 就是将mapreduce 提交到哪里去 也是yarn-site.xml 配置的 《property》 conf.set(“mapreduce.framework.name”,“yarn”); 同时这是指在yarn集群上运行 但是如果代码有问题，我们有需要重新打包 等一系列操作 太麻烦。 我们可以现在本地上运行，测试有没有bug 本地运行：只需要将conf.set(“mareduce.framework.name”,”local”) 还需要将 读取的文件路径和输出的路径改成windows本地地址即可。 主意输出的目录必须不存在。" />
<link rel="canonical" href="https://mlh.app/2019/04/09/728283.html" />
<meta property="og:url" content="https://mlh.app/2019/04/09/728283.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-09T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"mapreduce 单词统计 案例 一、Hadoop MapReduce 构思体现在如下的三个方面： 1.如何对付大数据处理：分而治之 2.构建抽象模型：Map 和 Reduce Map: 对一组数据元素进行某种重复式的处理； Reduce: 对 Map 的中间结果进行某种进一步的结果整理。 MapReduce 处理的数据类型是&lt;key,value&gt;键值对 3.统一构架，隐藏系统层细节 MapReduce 最大的亮点在于通过抽象模型和计算框架把需要做什么(what need to do)与具体怎么做(how to do)分开了，为程序员提供一个抽象和高层的编 程接口和框架。 二、Mapreduce 框架结构： 一个完整的mapreduce 框架由三个实例进程： 1.MRAppMaster ：负责整个程序的过程调度以及状态协调。 2.MapTask :负责map阶段的整个数据的处理。 3.ReduceTask :负责reduce阶段的整个数据的处理。 三、Mapreduce 的编写规范： （1）用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行 mr 程 序的客户端) Mapper 的输入数据是 KV 对的形式（KV 的类型可自定义） （3）Mapper 的输出数据是 KV 对的形式（KV 的类型可自定义） （4）Mapper 中的业务逻辑写在 map()方法中 （5）map()方法（maptask 进程）对每一个&lt;K,V&gt;调用一次 （6）Reducer 的输入数据类型对应 Mapper 的输出数据类型，也是 KV （7）Reducer 的业务逻辑写在 reduce()方法中 （8）Reducetask 进程对每一组相同 k 的&lt;k,v&gt;组调用一次 reduce()方法 （9）用户自定义的 Mapper 和 Reducer 都要继承各自的父类 （10）整个程序需要一个 Drvier 来进行提交，提交的是一个描述了各种必要信 息的 job 对象 Mapreduce 的wrodcount 小程序： 1.创建maven工程 引入 pom.xml org.apache.hadoop hadoop-common 2.7.4 org.apache.hadoop hadoop-hdfs 2.7.4 org.apache.hadoop hadoop-client 2.7.4 org.apache.hadoop hadoop-mapreduce-client-core 2.7.4 &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;cn.itcast.mapreduce.WordCountDriver&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 2.创建一个wrodCountMapper 类 继承Mapper&lt;KEYYIN,VALUEIN,KEYOUT,VALUEOUT&gt; KEYIN:map输入中的key 在默认读取数据的组件下textInputFormat(一行一行读) Key:表示是该行的起始偏移量（就是光标所在的位置值）longwritable Value：表示该行的内容 VALUEIN:map输入kv中的value 在默认读取数据的组件下TextInputFormat(一行一行读) 表明的是内容 （string—&gt;text） KEYOUT:map输出的kv中的key 在我们的需求中 把单词作为输出的key (string --&gt;text) VALUEOUT：map输出kv中的value 在我们的需求中 把单词的次数1作为输出的value （int–&gt;intwritable） 简而言之:keyin 读取文本光标的偏移量，valuein：读取文本时该行文本的内容 相当于map输入中的key.keyout:map输出时的key ;valueout:map输出时的value:数值 intwritable 核心命令： hadoop fs -mkdir -p /wordcount/input hadoop fs -put -p /root/wenben/a.txt /wordcount/input hadoop fs -ls / hadoop fs -cat /wordcount/input/a.txt hadoop fs -rm -r /wordcont/output hadoop jar jar报 ；//hadoop 执行jar包 hdfs: 监控端口 note1:50070 yarn :监控端口 note1:8088 Mapreduce 统计单词数 案例： 创建maven 工程 1.* key:偏移量 没啥用 value:map输入时读取文本文件其中的一行数据 context:mapreduce 封装好的输出对象。 */ public class WrodCountMapper extends Mapper&lt;LongWritable,Text,Text,IntWritable&gt; { @Override protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException { String line=value.toString(); String[] words = line.split(&quot; &quot;); for (String word:words ) { context.write(new Text(word),new IntWritable(1)); } } } 2./* key ：就是每个单词 values： 相当于处理后的单词 如：hadoop[1,1,1] context :是mapreduce 封装好的输出对象 */ public class wordCountReduce extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt;{ @Override protected void reduce(Text key, Iterable values, Context context) throws IOException, InterruptedException { int count=0; for (IntWritable value : values) { count +=value.get(); } context.write(key,new IntWritable(count)); } 3.public class WordCountDirver { public static void main(String[] args) throws Exception { Configuration conf= new Configuration(); conf.set(“mapreduce.framework.name”,“yarn”); Job job = Job.getInstance(conf); //指定本次mr程序运行的主类 job.setJarByClass(WordCountDirver.class); //指定本次mr运行程序的mapper 和reducer job.setMapperClass(WrodCountMapper.class); //指定本次Mr程序的reducer job.setReducerClass(wordCountReduce.class); //指定本次mr程序map阶段的输出类型 job.setMapOutputKeyClass(Text.class); job.setMapOutputValueClass(IntWritable.class); //指定本次mr程序reducer阶段的输出类型 job.setOutputKeyClass(Text.class); job.setOutputValueClass(IntWritable.class); //指定要处理的数据所在位置 FileInputFormat.setInputPaths(job,new Path(&quot;hdfs://note1:9000/wordcount/input&quot;));//此目录hdfs上必须存在 FileOutputFormat.setOutputPath(job,new Path(&quot;hdfs://note1:9000/wordcount/output&quot;));注意此目录必须不存在 //想yarn 集群提交job job.submit(); 这个我们看不到日志 一般不用 用下面job.waitForCompletion(true) true:代表监控并打印输出 job.waitForCompletion(true); } } 遇到的问题： Yarn 网页端口： note1:8088 监控不到 原因： 修改集群配置文件yarn-site.xml，加上如下几句： mapreduce.framework.name yarn 遇到的问题二：结果成功输出 但报 inter… thread wait jion 等问题？ 解决：在driver类中 添加 就是将mapreduce 提交到哪里去 也是yarn-site.xml 配置的 《property》 conf.set(“mapreduce.framework.name”,“yarn”); 同时这是指在yarn集群上运行 但是如果代码有问题，我们有需要重新打包 等一系列操作 太麻烦。 我们可以现在本地上运行，测试有没有bug 本地运行：只需要将conf.set(“mareduce.framework.name”,”local”) 还需要将 读取的文件路径和输出的路径改成windows本地地址即可。 主意输出的目录必须不存在。","@type":"BlogPosting","url":"https://mlh.app/2019/04/09/728283.html","headline":"mapreduce 单词统计 案例","dateModified":"2019-04-09T00:00:00+08:00","datePublished":"2019-04-09T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/04/09/728283.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>mapreduce 单词统计 案例</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h2><a id="mapreduce___0"></a>mapreduce 单词统计 案例</h2> 
  <p>一、Hadoop MapReduce 构思体现在如下的三个方面：<br> 1.如何对付大数据处理：分而治之<br> 2.构建抽象模型：Map 和 Reduce<br> Map: 对一组数据元素进行某种重复式的处理；<br> Reduce: 对 Map 的中间结果进行某种进一步的结果整理。<br> MapReduce 处理的数据类型是&lt;key,value&gt;键值对<br> 3.统一构架，隐藏系统层细节<br> MapReduce 最大的亮点在于通过抽象模型和计算框架把需要做什么(what<br> need to do)与具体怎么做(how to do)分开了，为程序员提供一个抽象和高层的编<br> 程接口和框架。</p> 
  <p>二、Mapreduce 框架结构：<br> 一个完整的mapreduce 框架由三个实例进程：<br> 1.MRAppMaster ：负责整个程序的过程调度以及状态协调。<br> 2.MapTask :负责map阶段的整个数据的处理。<br> 3.ReduceTask :负责reduce阶段的整个数据的处理。<br> 三、Mapreduce 的编写规范：<br> （1）用户编写的程序分成三个部分：Mapper，Reducer，Driver(提交运行 mr 程<br> 序的客户端)<br> Mapper 的输入数据是 KV 对的形式（KV 的类型可自定义）<br> （3）Mapper 的输出数据是 KV 对的形式（KV 的类型可自定义）<br> （4）Mapper 中的业务逻辑写在 map()方法中<br> （5）map()方法（maptask 进程）对每一个&lt;K,V&gt;调用一次<br> （6）Reducer 的输入数据类型对应 Mapper 的输出数据类型，也是 KV<br> （7）Reducer 的业务逻辑写在 reduce()方法中<br> （8）Reducetask 进程对每一组相同 k 的&lt;k,v&gt;组调用一次 reduce()方法<br> （9）用户自定义的 Mapper 和 Reducer 都要继承各自的父类<br> （10）整个程序需要一个 Drvier 来进行提交，提交的是一个描述了各种必要信<br> 息的 job 对象</p> 
  <p>Mapreduce 的wrodcount 小程序：</p> 
  <p>1.创建maven工程 引入 pom.xml<br> <br> <br> org.apache.hadoop<br> hadoop-common<br> 2.7.4<br> <br> <br> org.apache.hadoop<br> hadoop-hdfs<br> 2.7.4<br> <br> <br> org.apache.hadoop<br> hadoop-client<br> 2.7.4<br> <br> <br> org.apache.hadoop<br> hadoop-mapreduce-client-core<br> 2.7.4<br> <br> </p> 
  <pre><code>  &lt;build&gt;
  		&lt;plugins&gt;
  		&lt;plugin&gt;  
		    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;  
		    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;  
		    &lt;version&gt;2.4&lt;/version&gt;  
		    &lt;configuration&gt;  
		        &lt;archive&gt;  
		            &lt;manifest&gt;  
		                &lt;addClasspath&gt;true&lt;/addClasspath&gt;  
		                &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;  
		                &lt;mainClass&gt;cn.itcast.mapreduce.WordCountDriver&lt;/mainClass&gt;  
		            &lt;/manifest&gt;  
		        &lt;/archive&gt;  
		    &lt;/configuration&gt;  
		&lt;/plugin&gt; 
		&lt;plugin&gt;  
			&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;  
			&lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;  
			&lt;version&gt;3.0&lt;/version&gt;  
			&lt;configuration&gt;  
				&lt;source&gt;1.8&lt;/source&gt;  
				&lt;target&gt;1.8&lt;/target&gt;  
				&lt;encoding&gt;UTF-8&lt;/encoding&gt;  
			&lt;/configuration&gt;  
		&lt;/plugin&gt;  			
  		&lt;/plugins&gt;
  &lt;/build&gt;
</code></pre> 
  <p>2.创建一个wrodCountMapper 类 继承Mapper&lt;KEYYIN,VALUEIN,KEYOUT,VALUEOUT&gt;<br> KEYIN:map输入中的key<br> 在默认读取数据的组件下textInputFormat(一行一行读)<br> Key:表示是该行的起始偏移量（就是光标所在的位置值）longwritable<br> Value：表示该行的内容<br> VALUEIN:map输入kv中的value<br> 在默认读取数据的组件下TextInputFormat(一行一行读)<br> 表明的是内容 （string—&gt;text）<br> KEYOUT:map输出的kv中的key<br> 在我们的需求中 把单词作为输出的key (string --&gt;text)<br> VALUEOUT：map输出kv中的value<br> 在我们的需求中 把单词的次数1作为输出的value （int–&gt;intwritable）<br> 简而言之:keyin 读取文本光标的偏移量，valuein：读取文本时该行文本的内容 相当于map输入中的key.keyout:map输出时的key ;valueout:map输出时的value:数值 intwritable</p> 
  <p>核心命令：<br> hadoop fs -mkdir -p /wordcount/input<br> hadoop fs -put -p /root/wenben/a.txt /wordcount/input<br> hadoop fs -ls /<br> hadoop fs -cat /wordcount/input/a.txt<br> hadoop fs -rm -r /wordcont/output<br> hadoop jar jar报 ；//hadoop 执行jar包<br> hdfs: 监控端口 note1:50070<br> yarn :监控端口 note1:8088</p> 
  <p>Mapreduce 统计单词数 案例：<br> 创建maven 工程</p> 
  <p>1.* key:偏移量 没啥用</p> 
  <ul> 
   <li>value:map输入时读取文本文件其中的一行数据</li> 
   <li>context:mapreduce 封装好的输出对象。</li> 
   <li></li> 
   <li></li> 
   <li></li> 
   <li>*/</li> 
  </ul> 
  <p>public class WrodCountMapper extends Mapper&lt;LongWritable,Text,Text,IntWritable&gt; {<br> @Override<br> protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {<br> String line=value.toString();<br> String[] words = line.split(" ");</p> 
  <pre><code>    for (String word:words
         ) {
        context.write(new Text(word),new IntWritable(1));
    }
   
}
</code></pre> 
  <p>}</p> 
  <p>2./*</p> 
  <ul> 
   <li>key ：就是每个单词</li> 
   <li>values： 相当于处理后的单词 如：hadoop[1,1,1]</li> 
   <li>context :是mapreduce 封装好的输出对象</li> 
   <li>*/</li> 
  </ul> 
  <p>public class wordCountReduce extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt;{<br> @Override<br> protected void reduce(Text key, Iterable values, Context context) throws IOException, InterruptedException {<br> int count=0;</p> 
  <pre><code>    for (IntWritable value :
            values) {
        count +=value.get();
    }
    context.write(key,new IntWritable(count));
    

}
</code></pre> 
  <p>3.public class WordCountDirver {<br> public static void main(String[] args) throws Exception {<br> Configuration conf= new Configuration();<br> conf.set(“<a href="http://mapreduce.framework.name" rel="nofollow">mapreduce.framework.name</a>”,“yarn”);<br> Job job = Job.getInstance(conf);</p> 
  <pre><code>    //指定本次mr程序运行的主类
    job.setJarByClass(WordCountDirver.class);
    //指定本次mr运行程序的mapper 和reducer
    job.setMapperClass(WrodCountMapper.class);
    //指定本次Mr程序的reducer
    job.setReducerClass(wordCountReduce.class);
    //指定本次mr程序map阶段的输出类型
    job.setMapOutputKeyClass(Text.class);
    job.setMapOutputValueClass(IntWritable.class);
    //指定本次mr程序reducer阶段的输出类型
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);

    //指定要处理的数据所在位置
    FileInputFormat.setInputPaths(job,new Path("hdfs://note1:9000/wordcount/input"));//此目录hdfs上必须存在
    FileOutputFormat.setOutputPath(job,new Path("hdfs://note1:9000/wordcount/output"));注意此目录必须不存在
    //想yarn 集群提交job   job.submit(); 这个我们看不到日志 一般不用 用下面job.waitForCompletion(true) true:代表监控并打印输出

    job.waitForCompletion(true);

}
</code></pre> 
  <p>}</p> 
  <p>遇到的问题：<br> Yarn 网页端口： note1:8088 监控不到 原因：<br> 修改集群配置文件yarn-site.xml，加上如下几句：<br> <br> <a href="http://mapreduce.framework.name" rel="nofollow">mapreduce.framework.name</a><br> yarn<br> <br> 遇到的问题二：结果成功输出 但报 inter… thread wait jion 等问题？<br> 解决：在driver类中 添加 就是将mapreduce 提交到哪里去 也是yarn-site.xml 配置的 《property》<br> conf.set(“<a href="http://mapreduce.framework.name" rel="nofollow">mapreduce.framework.name</a>”,“yarn”);<br> <strong>同时这是指在yarn集群上运行</strong><br> 但是如果代码有问题，我们有需要重新打包 等一系列操作 太麻烦。<br> 我们可以现在本地上运行，测试有没有bug<br> <strong>本地运行：只需要将conf.set(“<a href="http://mareduce.framework.name" rel="nofollow">mareduce.framework.name</a>”,”local”)<br> 还需要将 读取的文件路径和输出的路径改成windows本地地址即可。</strong><br> 主意输出的目录必须不存在。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
