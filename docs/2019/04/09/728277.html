<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>分布式集群的常见面试问题 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="分布式集群的常见面试问题" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="为什么一般集群都要用3台服务器来组建 一台机器叫单机，不算分布式 两台机器组成的的集群，当有一台机器出现故障另一台机器并不能及时作出反应，况且两台机器当稳定性不一定要比单机更问题，实际场景中当 只有当有三台服务器是能实现zookeeper容错 &nbsp;LOOKING：当前Server不知道leader是谁，正在搜寻 &nbsp;LEADING：当前Server即为选举出来的leader &nbsp;FOLLOWING：leader已经选举出来，当前Server与之同步 dockerfile的cmd和entrypoint有何异同 CMD 支持三种格式 &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;[&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]&nbsp;使用&nbsp;exec&nbsp;执行，推荐方式； &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;command&nbsp;param1&nbsp;param2&nbsp;在&nbsp;/bin/sh&nbsp;中执行，提供给需要交互的应用； &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;[&quot;param1&quot;,&quot;param2&quot;]&nbsp;提供给&nbsp;ENTRYPOINT&nbsp;的默认参数； 指定启动容器时执行的命令，每个&nbsp;Dockerfile&nbsp;只能有一条&nbsp;CMD&nbsp;命令。如果指定了多条命令，只有最后一条会被执行。 如果用户启动容器时候指定了运行的命令，则会覆盖掉&nbsp;CMD&nbsp;指定的命令 ENTRYPOINT 两种格式： &nbsp;&nbsp;&nbsp;&nbsp;ENTRYPOINT&nbsp;[&quot;executable&quot;,&nbsp;&quot;param1&quot;,&nbsp;&quot;param2&quot;] &nbsp;&nbsp;&nbsp;&nbsp;ENTRYPOINT&nbsp;command&nbsp;param1&nbsp;param2（shell中执行）。 配置容器启动后执行的命令，并且不可被&nbsp;docker&nbsp;run&nbsp;提供的参数覆盖。 每个&nbsp;Dockerfile&nbsp;中只能有一个&nbsp;ENTRYPOINT，当指定多个时，只有最后一个起效。 从上面的说明，我们可以看到有两个共同点： 都可以指定shell或exec函数调用的方式执行命令； 当存在多个CMD指令或ENTRYPOINT指令时，只有最后一个生效； &nbsp; 而它们有如下差异： 差异1：CMD指令指定的容器启动时命令可以被docker&nbsp;run指定的命令覆盖，而ENTRYPOINT指令指定的命令不能被覆盖，而是将docker&nbsp;run指定的参数当做ENTRYPOINT指定命令的参数。 差异2：CMD指令可以为ENTRYPOINT指令设置默认参数，而且可以被docker&nbsp;run指定的参数覆盖； docker如何暴露容器端口 1.使用iptable 获得容器IP //[container_name]为docker容器名称 docker inspect [container_name] | grep IPAddress iptable转发端口 //例：将容器的8000端口映射到宿主机的8001端口 iiptables -t nat -A DOCKER -p tcp -dport 8001 -j DNAT --to-destination 192.169.1.1:8080 2. docker commit -a &quot;shijie32177&quot; -m &quot;centos with redis cluster&quot; centos-redis centos-redis:v1 返回 sha256:c044f4f28a4805823dc30605df2b0d15e06ab00ba122db5d00db434266adbd80 docker run -d -p 1001:7001 -p 1002:7002 -p 1003:7003 -p 1004:7004 -p 1005:7005 -p 1006:7006 shijie32177/centos-redis 返回 b4a4c6d6cc688407aa4c102fc459875bc8e3bacdc4b2b1504daebccab522ea1d - Deployment和ReplicationController的异同 ``` Replication Controller为Kubernetes的一个核心内容，应用托管到Kubernetes之后，需要保证应用能够持续的运行，Replication Controller就是这个保证的key，主要的功能如下： 确保pod数量：它会确保Kubernetes中有指定数量的Pod在运行。如果少于指定数量的pod，Replication Controller会创建新的，反之则会删除掉多余的以保证Pod数量不变。 确保pod健康：当pod不健康，运行出错或者无法提供服务时，Replication Controller也会杀死不健康的pod，重新创建新的。 弹性伸缩 ：在业务高峰或者低峰期的时候，可以通过Replication Controller动态的调整pod的数量来提高资源的利用率。同时，配置相应的监控功能（Hroizontal Pod Autoscaler），会定时自动从监控平台获取Replication Controller关联pod的整体资源使用情况，做到自动伸缩。 滚动升级：滚动升级为一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定，在初始化升级的时候就可以及时发现和解决问题，避免问题不断扩大。 ++++++++++++++++++++++++++++++++++++++++++++++ Deployment同样为Kubernetes的一个核心内容，主要职责同样是为了保证pod的数量和健康，90%的功能与Replication Controller完全一样，可以看做新一代的Replication Controller。但是，它又具备了Replication Controller之外的新特性： Replication Controller全部功能：Deployment继承了上面描述的Replication Controller全部功能。 事件和状态查看：可以查看Deployment的升级详细进度和状态。 回滚：当升级pod镜像或者相关参数的时候发现问题，可以使用回滚操作回滚到上一个稳定的版本或者指定的版本。 版本记录: 每一次对Deployment的操作，都能保存下来，给予后续可能的回滚使用。 暂停和启动：对于每一次升级，都能够随时暂停和启动。 多种升级方案：Recreate：删除所有已存在的pod,重新创建新的; RollingUpdate：滚动升级，逐步替换的策略，同时滚动升级时，支持更多的附加参数，例如设置最大不可用pod数量，最小升级间隔时间等等。 ``` - k8s暴露服务的3种方式(ClusterIP, NodePort, LoadBalancer) ``` ClusterIP 方式 - kubernetes 默认就是这种方式，是集群内部访问的方式 &nbsp; &nbsp; spec: &nbsp; &nbsp; &nbsp; clusterIP: 10.0.0.1 &nbsp; &nbsp; &nbsp; ports: &nbsp; &nbsp; &nbsp; - name: http - NodePort 方式 NodePort方式主要通过节点IP加端口的形式暴露端口&nbsp; 访问方式：protocol://:. heapster &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;10.3.129.117 &nbsp; &lt;nodes&gt; &nbsp; &nbsp; &nbsp; 80:30003/TCP &nbsp; &nbsp;14d apiVersion: v1 kind: Service metadata: &nbsp; annotations: &nbsp; &nbsp; kubectl.kubernetes.io/last-applied-configuration: | &nbsp; &nbsp; &nbsp; {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Service&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;creationTimestamp&quot;:&quot;2017-05-24T06:38:16Z&quot;,&quot;labels&quot;:{&quot;kubernetes.io/name&quot;:&quot;heapster&quot;,&quot;plugin&quot;:&quot;heapster&quot;},&quot;name&quot;:&quot;heapster&quot;,&quot;namespace&quot;:&quot;kube-system&quot;,&quot;resourceVersion&quot;:&quot;173906247&quot;,&quot;selfLink&quot;:&quot;/api/v1/namespaces/kube-system/services/heapster&quot;,&quot;uid&quot;:&quot;91470fbb-404b-11e7-ba41-5254eec04736&quot;},&quot;spec&quot;:{&quot;clusterIP&quot;:&quot;10.3.129.117&quot;,&quot;externalTrafficPolicy&quot;:&quot;Cluster&quot;,&quot;ports&quot;:[{&quot;nodePort&quot;:30003,&quot;port&quot;:80,&quot;protocol&quot;:&quot;TCP&quot;,&quot;targetPort&quot;:8082}],&quot;selector&quot;:{&quot;k8s-app&quot;:&quot;heapster&quot;},&quot;sessionAffinity&quot;:&quot;None&quot;,&quot;type&quot;:&quot;NodePort&quot;},&quot;status&quot;:{&quot;loadBalancer&quot;:{}}} &nbsp; creationTimestamp: 2018-07-25T03:22:01Z &nbsp; labels: &nbsp; &nbsp; kubernetes.io/name: heapster &nbsp; &nbsp; plugin: heapster &nbsp; name: heapster &nbsp; namespace: kube-system &nbsp; resourceVersion: &quot;789489505&quot; &nbsp; selfLink: /api/v1/namespaces/kube-system/services/heapster &nbsp; uid: e56886a2-8fb9-11e8-acd2-5254171bf8db spec: &nbsp; clusterIP: 10.3.129.117 &nbsp; externalTrafficPolicy: Cluster &nbsp; ports: &nbsp; - nodePort: 30003 &nbsp; &nbsp; port: 80 &nbsp; &nbsp; protocol: TCP &nbsp; &nbsp; targetPort: 8082 &nbsp; selector: &nbsp; &nbsp; k8s-app: heapster &nbsp; sessionAffinity: None &nbsp; type: NodePort status: &nbsp; loadBalancer: {} &nbsp;&nbsp; - LoadBalancer 方式 这种方式主要是利用其他第三方的LB暴露服务的，谷歌或者亚马逊的LB等等 kind: Service apiVersion: v1 metadata: &nbsp; name: my-service spec: &nbsp; selector: &nbsp; &nbsp; app: MyApp &nbsp; ports: &nbsp; - protocol: TCP &nbsp; &nbsp; port: 80 &nbsp; &nbsp; targetPort: 9376 &nbsp; clusterIP: 10.0.171.239 &nbsp; loadBalancerIP: 78.11.24.19 &nbsp; type: LoadBalancer status: &nbsp; loadBalancer: &nbsp; &nbsp; ingress: &nbsp; &nbsp; - ip: 146.148.47.155 &nbsp; &nbsp;&nbsp; - ExternalName 方式 这种方式主要是通过CNAME实现的，在kubernetes 1.7.x以及以上才支持这种方式，例如 kind: Service apiVersion: v1 metadata: &nbsp; name: my-service spec: &nbsp; selector: &nbsp; &nbsp; app: MyApp &nbsp; ports: &nbsp; - protocol: TCP &nbsp; &nbsp; port: 80 &nbsp; &nbsp; targetPort: 9376 &nbsp; clusterIP: 10.0.171.239 &nbsp; loadBalancerIP: 78.11.24.19 &nbsp; type: LoadBalancer status: &nbsp; loadBalancer: &nbsp; &nbsp; ingress: &nbsp; &nbsp; - ip: 146.148.47.155 &nbsp; &nbsp;&nbsp; 访问时，kube-dns服务直接解析到指定的Cnamemy.database.example.com这个域名上 ``` &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" />
<meta property="og:description" content="为什么一般集群都要用3台服务器来组建 一台机器叫单机，不算分布式 两台机器组成的的集群，当有一台机器出现故障另一台机器并不能及时作出反应，况且两台机器当稳定性不一定要比单机更问题，实际场景中当 只有当有三台服务器是能实现zookeeper容错 &nbsp;LOOKING：当前Server不知道leader是谁，正在搜寻 &nbsp;LEADING：当前Server即为选举出来的leader &nbsp;FOLLOWING：leader已经选举出来，当前Server与之同步 dockerfile的cmd和entrypoint有何异同 CMD 支持三种格式 &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;[&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]&nbsp;使用&nbsp;exec&nbsp;执行，推荐方式； &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;command&nbsp;param1&nbsp;param2&nbsp;在&nbsp;/bin/sh&nbsp;中执行，提供给需要交互的应用； &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;[&quot;param1&quot;,&quot;param2&quot;]&nbsp;提供给&nbsp;ENTRYPOINT&nbsp;的默认参数； 指定启动容器时执行的命令，每个&nbsp;Dockerfile&nbsp;只能有一条&nbsp;CMD&nbsp;命令。如果指定了多条命令，只有最后一条会被执行。 如果用户启动容器时候指定了运行的命令，则会覆盖掉&nbsp;CMD&nbsp;指定的命令 ENTRYPOINT 两种格式： &nbsp;&nbsp;&nbsp;&nbsp;ENTRYPOINT&nbsp;[&quot;executable&quot;,&nbsp;&quot;param1&quot;,&nbsp;&quot;param2&quot;] &nbsp;&nbsp;&nbsp;&nbsp;ENTRYPOINT&nbsp;command&nbsp;param1&nbsp;param2（shell中执行）。 配置容器启动后执行的命令，并且不可被&nbsp;docker&nbsp;run&nbsp;提供的参数覆盖。 每个&nbsp;Dockerfile&nbsp;中只能有一个&nbsp;ENTRYPOINT，当指定多个时，只有最后一个起效。 从上面的说明，我们可以看到有两个共同点： 都可以指定shell或exec函数调用的方式执行命令； 当存在多个CMD指令或ENTRYPOINT指令时，只有最后一个生效； &nbsp; 而它们有如下差异： 差异1：CMD指令指定的容器启动时命令可以被docker&nbsp;run指定的命令覆盖，而ENTRYPOINT指令指定的命令不能被覆盖，而是将docker&nbsp;run指定的参数当做ENTRYPOINT指定命令的参数。 差异2：CMD指令可以为ENTRYPOINT指令设置默认参数，而且可以被docker&nbsp;run指定的参数覆盖； docker如何暴露容器端口 1.使用iptable 获得容器IP //[container_name]为docker容器名称 docker inspect [container_name] | grep IPAddress iptable转发端口 //例：将容器的8000端口映射到宿主机的8001端口 iiptables -t nat -A DOCKER -p tcp -dport 8001 -j DNAT --to-destination 192.169.1.1:8080 2. docker commit -a &quot;shijie32177&quot; -m &quot;centos with redis cluster&quot; centos-redis centos-redis:v1 返回 sha256:c044f4f28a4805823dc30605df2b0d15e06ab00ba122db5d00db434266adbd80 docker run -d -p 1001:7001 -p 1002:7002 -p 1003:7003 -p 1004:7004 -p 1005:7005 -p 1006:7006 shijie32177/centos-redis 返回 b4a4c6d6cc688407aa4c102fc459875bc8e3bacdc4b2b1504daebccab522ea1d - Deployment和ReplicationController的异同 ``` Replication Controller为Kubernetes的一个核心内容，应用托管到Kubernetes之后，需要保证应用能够持续的运行，Replication Controller就是这个保证的key，主要的功能如下： 确保pod数量：它会确保Kubernetes中有指定数量的Pod在运行。如果少于指定数量的pod，Replication Controller会创建新的，反之则会删除掉多余的以保证Pod数量不变。 确保pod健康：当pod不健康，运行出错或者无法提供服务时，Replication Controller也会杀死不健康的pod，重新创建新的。 弹性伸缩 ：在业务高峰或者低峰期的时候，可以通过Replication Controller动态的调整pod的数量来提高资源的利用率。同时，配置相应的监控功能（Hroizontal Pod Autoscaler），会定时自动从监控平台获取Replication Controller关联pod的整体资源使用情况，做到自动伸缩。 滚动升级：滚动升级为一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定，在初始化升级的时候就可以及时发现和解决问题，避免问题不断扩大。 ++++++++++++++++++++++++++++++++++++++++++++++ Deployment同样为Kubernetes的一个核心内容，主要职责同样是为了保证pod的数量和健康，90%的功能与Replication Controller完全一样，可以看做新一代的Replication Controller。但是，它又具备了Replication Controller之外的新特性： Replication Controller全部功能：Deployment继承了上面描述的Replication Controller全部功能。 事件和状态查看：可以查看Deployment的升级详细进度和状态。 回滚：当升级pod镜像或者相关参数的时候发现问题，可以使用回滚操作回滚到上一个稳定的版本或者指定的版本。 版本记录: 每一次对Deployment的操作，都能保存下来，给予后续可能的回滚使用。 暂停和启动：对于每一次升级，都能够随时暂停和启动。 多种升级方案：Recreate：删除所有已存在的pod,重新创建新的; RollingUpdate：滚动升级，逐步替换的策略，同时滚动升级时，支持更多的附加参数，例如设置最大不可用pod数量，最小升级间隔时间等等。 ``` - k8s暴露服务的3种方式(ClusterIP, NodePort, LoadBalancer) ``` ClusterIP 方式 - kubernetes 默认就是这种方式，是集群内部访问的方式 &nbsp; &nbsp; spec: &nbsp; &nbsp; &nbsp; clusterIP: 10.0.0.1 &nbsp; &nbsp; &nbsp; ports: &nbsp; &nbsp; &nbsp; - name: http - NodePort 方式 NodePort方式主要通过节点IP加端口的形式暴露端口&nbsp; 访问方式：protocol://:. heapster &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;10.3.129.117 &nbsp; &lt;nodes&gt; &nbsp; &nbsp; &nbsp; 80:30003/TCP &nbsp; &nbsp;14d apiVersion: v1 kind: Service metadata: &nbsp; annotations: &nbsp; &nbsp; kubectl.kubernetes.io/last-applied-configuration: | &nbsp; &nbsp; &nbsp; {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Service&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;creationTimestamp&quot;:&quot;2017-05-24T06:38:16Z&quot;,&quot;labels&quot;:{&quot;kubernetes.io/name&quot;:&quot;heapster&quot;,&quot;plugin&quot;:&quot;heapster&quot;},&quot;name&quot;:&quot;heapster&quot;,&quot;namespace&quot;:&quot;kube-system&quot;,&quot;resourceVersion&quot;:&quot;173906247&quot;,&quot;selfLink&quot;:&quot;/api/v1/namespaces/kube-system/services/heapster&quot;,&quot;uid&quot;:&quot;91470fbb-404b-11e7-ba41-5254eec04736&quot;},&quot;spec&quot;:{&quot;clusterIP&quot;:&quot;10.3.129.117&quot;,&quot;externalTrafficPolicy&quot;:&quot;Cluster&quot;,&quot;ports&quot;:[{&quot;nodePort&quot;:30003,&quot;port&quot;:80,&quot;protocol&quot;:&quot;TCP&quot;,&quot;targetPort&quot;:8082}],&quot;selector&quot;:{&quot;k8s-app&quot;:&quot;heapster&quot;},&quot;sessionAffinity&quot;:&quot;None&quot;,&quot;type&quot;:&quot;NodePort&quot;},&quot;status&quot;:{&quot;loadBalancer&quot;:{}}} &nbsp; creationTimestamp: 2018-07-25T03:22:01Z &nbsp; labels: &nbsp; &nbsp; kubernetes.io/name: heapster &nbsp; &nbsp; plugin: heapster &nbsp; name: heapster &nbsp; namespace: kube-system &nbsp; resourceVersion: &quot;789489505&quot; &nbsp; selfLink: /api/v1/namespaces/kube-system/services/heapster &nbsp; uid: e56886a2-8fb9-11e8-acd2-5254171bf8db spec: &nbsp; clusterIP: 10.3.129.117 &nbsp; externalTrafficPolicy: Cluster &nbsp; ports: &nbsp; - nodePort: 30003 &nbsp; &nbsp; port: 80 &nbsp; &nbsp; protocol: TCP &nbsp; &nbsp; targetPort: 8082 &nbsp; selector: &nbsp; &nbsp; k8s-app: heapster &nbsp; sessionAffinity: None &nbsp; type: NodePort status: &nbsp; loadBalancer: {} &nbsp;&nbsp; - LoadBalancer 方式 这种方式主要是利用其他第三方的LB暴露服务的，谷歌或者亚马逊的LB等等 kind: Service apiVersion: v1 metadata: &nbsp; name: my-service spec: &nbsp; selector: &nbsp; &nbsp; app: MyApp &nbsp; ports: &nbsp; - protocol: TCP &nbsp; &nbsp; port: 80 &nbsp; &nbsp; targetPort: 9376 &nbsp; clusterIP: 10.0.171.239 &nbsp; loadBalancerIP: 78.11.24.19 &nbsp; type: LoadBalancer status: &nbsp; loadBalancer: &nbsp; &nbsp; ingress: &nbsp; &nbsp; - ip: 146.148.47.155 &nbsp; &nbsp;&nbsp; - ExternalName 方式 这种方式主要是通过CNAME实现的，在kubernetes 1.7.x以及以上才支持这种方式，例如 kind: Service apiVersion: v1 metadata: &nbsp; name: my-service spec: &nbsp; selector: &nbsp; &nbsp; app: MyApp &nbsp; ports: &nbsp; - protocol: TCP &nbsp; &nbsp; port: 80 &nbsp; &nbsp; targetPort: 9376 &nbsp; clusterIP: 10.0.171.239 &nbsp; loadBalancerIP: 78.11.24.19 &nbsp; type: LoadBalancer status: &nbsp; loadBalancer: &nbsp; &nbsp; ingress: &nbsp; &nbsp; - ip: 146.148.47.155 &nbsp; &nbsp;&nbsp; 访问时，kube-dns服务直接解析到指定的Cnamemy.database.example.com这个域名上 ``` &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-09T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"为什么一般集群都要用3台服务器来组建 一台机器叫单机，不算分布式 两台机器组成的的集群，当有一台机器出现故障另一台机器并不能及时作出反应，况且两台机器当稳定性不一定要比单机更问题，实际场景中当 只有当有三台服务器是能实现zookeeper容错 &nbsp;LOOKING：当前Server不知道leader是谁，正在搜寻 &nbsp;LEADING：当前Server即为选举出来的leader &nbsp;FOLLOWING：leader已经选举出来，当前Server与之同步 dockerfile的cmd和entrypoint有何异同 CMD 支持三种格式 &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;[&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]&nbsp;使用&nbsp;exec&nbsp;执行，推荐方式； &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;command&nbsp;param1&nbsp;param2&nbsp;在&nbsp;/bin/sh&nbsp;中执行，提供给需要交互的应用； &nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;[&quot;param1&quot;,&quot;param2&quot;]&nbsp;提供给&nbsp;ENTRYPOINT&nbsp;的默认参数； 指定启动容器时执行的命令，每个&nbsp;Dockerfile&nbsp;只能有一条&nbsp;CMD&nbsp;命令。如果指定了多条命令，只有最后一条会被执行。 如果用户启动容器时候指定了运行的命令，则会覆盖掉&nbsp;CMD&nbsp;指定的命令 ENTRYPOINT 两种格式： &nbsp;&nbsp;&nbsp;&nbsp;ENTRYPOINT&nbsp;[&quot;executable&quot;,&nbsp;&quot;param1&quot;,&nbsp;&quot;param2&quot;] &nbsp;&nbsp;&nbsp;&nbsp;ENTRYPOINT&nbsp;command&nbsp;param1&nbsp;param2（shell中执行）。 配置容器启动后执行的命令，并且不可被&nbsp;docker&nbsp;run&nbsp;提供的参数覆盖。 每个&nbsp;Dockerfile&nbsp;中只能有一个&nbsp;ENTRYPOINT，当指定多个时，只有最后一个起效。 从上面的说明，我们可以看到有两个共同点： 都可以指定shell或exec函数调用的方式执行命令； 当存在多个CMD指令或ENTRYPOINT指令时，只有最后一个生效； &nbsp; 而它们有如下差异： 差异1：CMD指令指定的容器启动时命令可以被docker&nbsp;run指定的命令覆盖，而ENTRYPOINT指令指定的命令不能被覆盖，而是将docker&nbsp;run指定的参数当做ENTRYPOINT指定命令的参数。 差异2：CMD指令可以为ENTRYPOINT指令设置默认参数，而且可以被docker&nbsp;run指定的参数覆盖； docker如何暴露容器端口 1.使用iptable 获得容器IP //[container_name]为docker容器名称 docker inspect [container_name] | grep IPAddress iptable转发端口 //例：将容器的8000端口映射到宿主机的8001端口 iiptables -t nat -A DOCKER -p tcp -dport 8001 -j DNAT --to-destination 192.169.1.1:8080 2. docker commit -a &quot;shijie32177&quot; -m &quot;centos with redis cluster&quot; centos-redis centos-redis:v1 返回 sha256:c044f4f28a4805823dc30605df2b0d15e06ab00ba122db5d00db434266adbd80 docker run -d -p 1001:7001 -p 1002:7002 -p 1003:7003 -p 1004:7004 -p 1005:7005 -p 1006:7006 shijie32177/centos-redis 返回 b4a4c6d6cc688407aa4c102fc459875bc8e3bacdc4b2b1504daebccab522ea1d - Deployment和ReplicationController的异同 ``` Replication Controller为Kubernetes的一个核心内容，应用托管到Kubernetes之后，需要保证应用能够持续的运行，Replication Controller就是这个保证的key，主要的功能如下： 确保pod数量：它会确保Kubernetes中有指定数量的Pod在运行。如果少于指定数量的pod，Replication Controller会创建新的，反之则会删除掉多余的以保证Pod数量不变。 确保pod健康：当pod不健康，运行出错或者无法提供服务时，Replication Controller也会杀死不健康的pod，重新创建新的。 弹性伸缩 ：在业务高峰或者低峰期的时候，可以通过Replication Controller动态的调整pod的数量来提高资源的利用率。同时，配置相应的监控功能（Hroizontal Pod Autoscaler），会定时自动从监控平台获取Replication Controller关联pod的整体资源使用情况，做到自动伸缩。 滚动升级：滚动升级为一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定，在初始化升级的时候就可以及时发现和解决问题，避免问题不断扩大。 ++++++++++++++++++++++++++++++++++++++++++++++ Deployment同样为Kubernetes的一个核心内容，主要职责同样是为了保证pod的数量和健康，90%的功能与Replication Controller完全一样，可以看做新一代的Replication Controller。但是，它又具备了Replication Controller之外的新特性： Replication Controller全部功能：Deployment继承了上面描述的Replication Controller全部功能。 事件和状态查看：可以查看Deployment的升级详细进度和状态。 回滚：当升级pod镜像或者相关参数的时候发现问题，可以使用回滚操作回滚到上一个稳定的版本或者指定的版本。 版本记录: 每一次对Deployment的操作，都能保存下来，给予后续可能的回滚使用。 暂停和启动：对于每一次升级，都能够随时暂停和启动。 多种升级方案：Recreate：删除所有已存在的pod,重新创建新的; RollingUpdate：滚动升级，逐步替换的策略，同时滚动升级时，支持更多的附加参数，例如设置最大不可用pod数量，最小升级间隔时间等等。 ``` - k8s暴露服务的3种方式(ClusterIP, NodePort, LoadBalancer) ``` ClusterIP 方式 - kubernetes 默认就是这种方式，是集群内部访问的方式 &nbsp; &nbsp; spec: &nbsp; &nbsp; &nbsp; clusterIP: 10.0.0.1 &nbsp; &nbsp; &nbsp; ports: &nbsp; &nbsp; &nbsp; - name: http - NodePort 方式 NodePort方式主要通过节点IP加端口的形式暴露端口&nbsp; 访问方式：protocol://:. heapster &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;10.3.129.117 &nbsp; &lt;nodes&gt; &nbsp; &nbsp; &nbsp; 80:30003/TCP &nbsp; &nbsp;14d apiVersion: v1 kind: Service metadata: &nbsp; annotations: &nbsp; &nbsp; kubectl.kubernetes.io/last-applied-configuration: | &nbsp; &nbsp; &nbsp; {&quot;apiVersion&quot;:&quot;v1&quot;,&quot;kind&quot;:&quot;Service&quot;,&quot;metadata&quot;:{&quot;annotations&quot;:{},&quot;creationTimestamp&quot;:&quot;2017-05-24T06:38:16Z&quot;,&quot;labels&quot;:{&quot;kubernetes.io/name&quot;:&quot;heapster&quot;,&quot;plugin&quot;:&quot;heapster&quot;},&quot;name&quot;:&quot;heapster&quot;,&quot;namespace&quot;:&quot;kube-system&quot;,&quot;resourceVersion&quot;:&quot;173906247&quot;,&quot;selfLink&quot;:&quot;/api/v1/namespaces/kube-system/services/heapster&quot;,&quot;uid&quot;:&quot;91470fbb-404b-11e7-ba41-5254eec04736&quot;},&quot;spec&quot;:{&quot;clusterIP&quot;:&quot;10.3.129.117&quot;,&quot;externalTrafficPolicy&quot;:&quot;Cluster&quot;,&quot;ports&quot;:[{&quot;nodePort&quot;:30003,&quot;port&quot;:80,&quot;protocol&quot;:&quot;TCP&quot;,&quot;targetPort&quot;:8082}],&quot;selector&quot;:{&quot;k8s-app&quot;:&quot;heapster&quot;},&quot;sessionAffinity&quot;:&quot;None&quot;,&quot;type&quot;:&quot;NodePort&quot;},&quot;status&quot;:{&quot;loadBalancer&quot;:{}}} &nbsp; creationTimestamp: 2018-07-25T03:22:01Z &nbsp; labels: &nbsp; &nbsp; kubernetes.io/name: heapster &nbsp; &nbsp; plugin: heapster &nbsp; name: heapster &nbsp; namespace: kube-system &nbsp; resourceVersion: &quot;789489505&quot; &nbsp; selfLink: /api/v1/namespaces/kube-system/services/heapster &nbsp; uid: e56886a2-8fb9-11e8-acd2-5254171bf8db spec: &nbsp; clusterIP: 10.3.129.117 &nbsp; externalTrafficPolicy: Cluster &nbsp; ports: &nbsp; - nodePort: 30003 &nbsp; &nbsp; port: 80 &nbsp; &nbsp; protocol: TCP &nbsp; &nbsp; targetPort: 8082 &nbsp; selector: &nbsp; &nbsp; k8s-app: heapster &nbsp; sessionAffinity: None &nbsp; type: NodePort status: &nbsp; loadBalancer: {} &nbsp;&nbsp; - LoadBalancer 方式 这种方式主要是利用其他第三方的LB暴露服务的，谷歌或者亚马逊的LB等等 kind: Service apiVersion: v1 metadata: &nbsp; name: my-service spec: &nbsp; selector: &nbsp; &nbsp; app: MyApp &nbsp; ports: &nbsp; - protocol: TCP &nbsp; &nbsp; port: 80 &nbsp; &nbsp; targetPort: 9376 &nbsp; clusterIP: 10.0.171.239 &nbsp; loadBalancerIP: 78.11.24.19 &nbsp; type: LoadBalancer status: &nbsp; loadBalancer: &nbsp; &nbsp; ingress: &nbsp; &nbsp; - ip: 146.148.47.155 &nbsp; &nbsp;&nbsp; - ExternalName 方式 这种方式主要是通过CNAME实现的，在kubernetes 1.7.x以及以上才支持这种方式，例如 kind: Service apiVersion: v1 metadata: &nbsp; name: my-service spec: &nbsp; selector: &nbsp; &nbsp; app: MyApp &nbsp; ports: &nbsp; - protocol: TCP &nbsp; &nbsp; port: 80 &nbsp; &nbsp; targetPort: 9376 &nbsp; clusterIP: 10.0.171.239 &nbsp; loadBalancerIP: 78.11.24.19 &nbsp; type: LoadBalancer status: &nbsp; loadBalancer: &nbsp; &nbsp; ingress: &nbsp; &nbsp; - ip: 146.148.47.155 &nbsp; &nbsp;&nbsp; 访问时，kube-dns服务直接解析到指定的Cnamemy.database.example.com这个域名上 ``` &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;","@type":"BlogPosting","url":"/2019/04/09/728277.html","headline":"分布式集群的常见面试问题","dateModified":"2019-04-09T00:00:00+08:00","datePublished":"2019-04-09T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/09/728277.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>分布式集群的常见面试问题</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h2>为什么一般集群都要用3台服务器来组建</h2> 
  <p>一台机器叫单机，不算分布式</p> 
  <p>两台机器组成的的集群，当有一台机器出现故障另一台机器并不能及时作出反应，况且两台机器当稳定性不一定要比单机更问题，实际场景中当</p> 
  <p>只有当有三台服务器是能实现zookeeper容错</p> 
  <p>&nbsp;LOOKING：当前Server不知道leader是谁，正在搜寻<br> &nbsp;LEADING：当前Server即为选举出来的leader<br> &nbsp;FOLLOWING：leader已经选举出来，当前Server与之同步</p> 
  <h2>dockerfile的cmd和entrypoint有何异同</h2> 
  <p><strong>CMD</strong></p> 
  <p>支持三种格式</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;["executable","param1","param2"]&nbsp;使用&nbsp;exec&nbsp;执行，推荐方式；</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;command&nbsp;param1&nbsp;param2&nbsp;在&nbsp;/bin/sh&nbsp;中执行，提供给需要交互的应用；</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;CMD&nbsp;["param1","param2"]&nbsp;提供给&nbsp;ENTRYPOINT&nbsp;的默认参数；</p> 
  <p>指定启动容器时执行的命令，每个&nbsp;Dockerfile&nbsp;只能有一条&nbsp;CMD&nbsp;命令。如果指定了多条命令，只有最后一条会被执行。</p> 
  <p>如果用户启动容器时候指定了运行的命令，则会覆盖掉&nbsp;CMD&nbsp;指定的命令</p> 
  <p><strong>ENTRYPOINT</strong></p> 
  <p>两种格式：</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;ENTRYPOINT&nbsp;["executable",&nbsp;"param1",&nbsp;"param2"]</p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;ENTRYPOINT&nbsp;command&nbsp;param1&nbsp;param2（shell中执行）。</p> 
  <p>配置容器启动后执行的命令，并且不可被&nbsp;docker&nbsp;run&nbsp;提供的参数覆盖。</p> 
  <p>每个&nbsp;Dockerfile&nbsp;中只能有一个&nbsp;ENTRYPOINT，当指定多个时，只有最后一个起效。</p> 
  <p>从上面的说明，我们可以看到有两个共同点：</p> 
  <ol>
   <li><strong>都可以指定shell或exec函数调用的方式执行命令；</strong></li> 
   <li><strong>当存在多个CMD指令或ENTRYPOINT指令时，只有最后一个生效；</strong></li> 
  </ol>
  <p>&nbsp;</p> 
  <p>而它们有如下差异：</p> 
  <p><strong>差异1：CMD指令指定的容器启动时命令可以被docker&nbsp;run指定的命令覆盖，而ENTRYPOINT指令指定的命令不能被覆盖，而是将docker&nbsp;run指定的参数当做ENTRYPOINT指定命令的参数。</strong></p> 
  <p><strong>差异2：CMD指令可以为ENTRYPOINT指令设置默认参数，而且可以被docker&nbsp;run指定的参数覆盖；</strong></p> 
  <h2>docker如何暴露容器端口</h2> 
  <p>1.使用iptable<br> 获得容器IP<br> //[container_name]为docker容器名称</p> 
  <p>docker inspect [container_name] | grep IPAddress</p> 
  <p>iptable转发端口<br> //例：将容器的8000端口映射到宿主机的8001端口</p> 
  <p>iiptables -t nat -A DOCKER -p tcp -dport 8001 -j DNAT --to-destination 192.169.1.1:8080</p> 
  <p><br> 2.<br> docker commit -a "shijie32177" -m "centos with redis cluster" centos-redis centos-redis:v1<br> 返回<br> sha256:c044f4f28a4805823dc30605df2b0d15e06ab00ba122db5d00db434266adbd80<br> docker run -d -p 1001:7001 -p 1002:7002 -p 1003:7003 -p 1004:7004 -p 1005:7005 -p 1006:7006 shijie32177/centos-redis<br> 返回<br> b4a4c6d6cc688407aa4c102fc459875bc8e3bacdc4b2b1504daebccab522ea1d</p> 
  <h2>- Deployment和ReplicationController的异同<br> ```<br> Replication Controller为Kubernetes的一个核心内容，应用托管到Kubernetes之后，需要保证应用能够持续的运行，Replication Controller就是这个保证的key，主要的功能如下：</h2> 
  <p>确保pod数量：它会确保Kubernetes中有指定数量的Pod在运行。如果少于指定数量的pod，Replication Controller会创建新的，反之则会删除掉多余的以保证Pod数量不变。</p> 
  <p>确保pod健康：当pod不健康，运行出错或者无法提供服务时，Replication Controller也会杀死不健康的pod，重新创建新的。</p> 
  <p>弹性伸缩 ：在业务高峰或者低峰期的时候，可以通过Replication Controller动态的调整pod的数量来提高资源的利用率。同时，配置相应的监控功能（Hroizontal Pod Autoscaler），会定时自动从监控平台获取Replication Controller关联pod的整体资源使用情况，做到自动伸缩。</p> 
  <p>滚动升级：滚动升级为一种平滑的升级方式，通过逐步替换的策略，保证整体系统的稳定，在初始化升级的时候就可以及时发现和解决问题，避免问题不断扩大。</p> 
  <p><br> ++++++++++++++++++++++++++++++++++++++++++++++</p> 
  <p>Deployment同样为Kubernetes的一个核心内容，主要职责同样是为了保证pod的数量和健康，90%的功能与Replication Controller完全一样，可以看做新一代的Replication Controller。但是，它又具备了Replication Controller之外的新特性：</p> 
  <p>Replication Controller全部功能：Deployment继承了上面描述的Replication Controller全部功能。</p> 
  <p>事件和状态查看：可以查看Deployment的升级详细进度和状态。</p> 
  <p>回滚：当升级pod镜像或者相关参数的时候发现问题，可以使用回滚操作回滚到上一个稳定的版本或者指定的版本。</p> 
  <p>版本记录: 每一次对Deployment的操作，都能保存下来，给予后续可能的回滚使用。</p> 
  <p>暂停和启动：对于每一次升级，都能够随时暂停和启动。</p> 
  <p>多种升级方案：Recreate：删除所有已存在的pod,重新创建新的; RollingUpdate：滚动升级，逐步替换的策略，同时滚动升级时，支持更多的附加参数，例如设置最大不可用pod数量，最小升级间隔时间等等。</p> 
  <p><br> ```</p> 
  <p>- k8s暴露服务的3种方式(ClusterIP, NodePort, LoadBalancer)<br> ```<br> ClusterIP 方式</p> 
  <p>- kubernetes 默认就是这种方式，是集群内部访问的方式<br> &nbsp; &nbsp; spec:<br> &nbsp; &nbsp; &nbsp; clusterIP: 10.0.0.1<br> &nbsp; &nbsp; &nbsp; ports:<br> &nbsp; &nbsp; &nbsp; - name: http</p> 
  <p><br> - NodePort 方式<br> NodePort方式主要通过节点IP加端口的形式暴露端口&nbsp;<br> 访问方式：protocol://:.</p> 
  <p>heapster &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;10.3.129.117 &nbsp; &lt;nodes&gt; &nbsp; &nbsp; &nbsp; 80:30003/TCP &nbsp; &nbsp;14d</p> 
  <p>apiVersion: v1<br> kind: Service<br> metadata:<br> &nbsp; annotations:<br> &nbsp; &nbsp; kubectl.kubernetes.io/last-applied-configuration: |<br> &nbsp; &nbsp; &nbsp; {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"creationTimestamp":"2017-05-24T06:38:16Z","labels":{"kubernetes.io/name":"heapster","plugin":"heapster"},"name":"heapster","namespace":"kube-system","resourceVersion":"173906247","selfLink":"/api/v1/namespaces/kube-system/services/heapster","uid":"91470fbb-404b-11e7-ba41-5254eec04736"},"spec":{"clusterIP":"10.3.129.117","externalTrafficPolicy":"Cluster","ports":[{"nodePort":30003,"port":80,"protocol":"TCP","targetPort":8082}],"selector":{"k8s-app":"heapster"},"sessionAffinity":"None","type":"NodePort"},"status":{"loadBalancer":{}}}<br> &nbsp; creationTimestamp: 2018-07-25T03:22:01Z<br> &nbsp; labels:<br> &nbsp; &nbsp; kubernetes.io/name: heapster<br> &nbsp; &nbsp; plugin: heapster<br> &nbsp; name: heapster<br> &nbsp; namespace: kube-system<br> &nbsp; resourceVersion: "789489505"<br> &nbsp; selfLink: /api/v1/namespaces/kube-system/services/heapster<br> &nbsp; uid: e56886a2-8fb9-11e8-acd2-5254171bf8db<br> spec:<br> &nbsp; clusterIP: 10.3.129.117<br> &nbsp; externalTrafficPolicy: Cluster<br> &nbsp; ports:<br> &nbsp; - nodePort: 30003<br> &nbsp; &nbsp; port: 80<br> &nbsp; &nbsp; protocol: TCP<br> &nbsp; &nbsp; targetPort: 8082<br> &nbsp; selector:<br> &nbsp; &nbsp; k8s-app: heapster<br> &nbsp; sessionAffinity: None<br> &nbsp; type: NodePort<br> status:<br> &nbsp; loadBalancer: {}<br> &nbsp;&nbsp;<br> - LoadBalancer 方式<br> 这种方式主要是利用其他第三方的LB暴露服务的，谷歌或者亚马逊的LB等等</p> 
  <p>kind: Service<br> apiVersion: v1<br> metadata:<br> &nbsp; name: my-service<br> spec:<br> &nbsp; selector:<br> &nbsp; &nbsp; app: MyApp<br> &nbsp; ports:<br> &nbsp; - protocol: TCP<br> &nbsp; &nbsp; port: 80<br> &nbsp; &nbsp; targetPort: 9376<br> &nbsp; clusterIP: 10.0.171.239<br> &nbsp; loadBalancerIP: 78.11.24.19<br> &nbsp; type: LoadBalancer<br> status:<br> &nbsp; loadBalancer:<br> &nbsp; &nbsp; ingress:<br> &nbsp; &nbsp; - ip: 146.148.47.155<br> &nbsp; &nbsp;&nbsp;<br> - ExternalName 方式<br> 这种方式主要是通过CNAME实现的，在kubernetes 1.7.x以及以上才支持这种方式，例如<br> kind: Service<br> apiVersion: v1<br> metadata:<br> &nbsp; name: my-service<br> spec:<br> &nbsp; selector:<br> &nbsp; &nbsp; app: MyApp<br> &nbsp; ports:<br> &nbsp; - protocol: TCP<br> &nbsp; &nbsp; port: 80<br> &nbsp; &nbsp; targetPort: 9376<br> &nbsp; clusterIP: 10.0.171.239<br> &nbsp; loadBalancerIP: 78.11.24.19<br> &nbsp; type: LoadBalancer<br> status:<br> &nbsp; loadBalancer:<br> &nbsp; &nbsp; ingress:<br> &nbsp; &nbsp; - ip: 146.148.47.155<br> &nbsp; &nbsp;&nbsp;<br> 访问时，kube-dns服务直接解析到指定的Cnamemy.database.example.com这个域名上</p> 
  <p>```</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
