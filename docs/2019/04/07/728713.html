<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>神经网络（Neural Network) | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="神经网络（Neural Network)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="上篇文章讲了《世界观 - 经验事实和哲学性/概念性事实》，很多科学真理和事实是基于复杂的论证过程，进而形成人们的世界观，推演，证明经过很多复杂的往复和推理过程，起初是经由发现，获取更多线索，不断证明，并不断被挑战（可证伪性），最终形成当下的世界观，人脑的思维过程能否被机器替代，今天主要简述下神经网络（Neural Network)。 &nbsp; 01 神经网络（Neural Network) 人的神经网络如上图所示，有点像树，有很多树突和轴突，不同的细胞通过树突和轴突传递信息，他们的基础点叫突触，一个细胞的轴突通过突触将信号传递给另一个细胞的树突。 我们能否设计这样的神经细胞结构，让彼此之间的通过某种方式相互刺激、协同完成信息处理呢？ 最早在1957年Rosenblatt提出了Perceptron（感知器模型）就讲研究领域带入到了神经网络。 &nbsp; 02 神经元 &nbsp; 神经元是神经细胞的基本组成单元，也是将要介绍的神经网络的主要组成部分。 神经网络的神经元主要由两部分组成，”线性模型“和”非线性模型（激励函数）“。 先说线性模型 X是一个一维向量，w0是bias（偏置值），w是权重矩阵，线性部分f(x)是神经元最核心的部分，对X做线性处理。 X可以看做是真理的某种假设，如相对论中，有个”奎因-迪昂论点”， 一些观点的集合，用来证明科学的过程中，可以摒弃（wk=0)或修改(调整wl)，我们的观点并不是单独的，而是作为整体来面对经验的裁判。 有点不好理解，简单来说，判断一个人是不是自己心目中的另一半，可能有多个要求和因素X（年龄，身高，收入，性格，国籍等），那么适不适合是一个综合判定。 得到： f(x)简化为 &nbsp; 03 激励函数（Activation Function） &nbsp; 激励函数相当于在一个神经元当中跟随在f（x）后面加入了一个非线性因素。 常见的激励函数 Wikipedia给出了很多种类的激励函数如下： 为什么需要引入非线性的关系 - 激励函数？ 如何仅仅包含线性函数，那么拟合的结果仅仅包含线性关系。 举个例子，我们需要区分下图中的红绿色 现实中人脑可能是通过人眼区分颜色，然后在判断是什么数字，比如我们体检的时候可能都看过一类图片，然后医生会让我们说出数字，如果仅包含线性关系，对于颜色分类这一pa，就可能会是 过于非黑即白，简单粗暴。现实中，我们需要这样的拟合如下： &nbsp; 04 单层神经网络 &amp; 损失函数 &nbsp; 单层神经网络，简单说来就是前面的模型 问题来了，如何选取W，得到最优的判断结果y？ &nbsp; 实际中，让拟合与真实差异之和最小，在上面例子中让下面公式的值最小， &nbsp; 扩展到整个矩阵 让Loss尽可能的小。 另外几种衡量损失的角度： &nbsp; &nbsp; 05 多层神经网络 &nbsp; 现实中可能需要多个隐藏层，有多个神经元，共同作用来拟合y，如下图。 每一层的输出，作为下一层的输入，实际上就是深度学习的过程。 &nbsp; &nbsp; 06 损失优化 &nbsp; 对于损失函数的计算，如何获取到最小的损失值的W。 直观感受，遍历所有的W基本是不可能的，如何找到W，从斜率衰减（Gradient Descent）的角度，Learning rate就先对是计算效率和精准的一个权衡角度。 选取Gradient Descent需要很多技巧，如何选取真正的最深谷底，还是到达波谷就停止计算？是一个技术活，参考《https://arxiv.org/pdf/1712.09913.pdf》会得到一些启发。 &nbsp; &nbsp; &nbsp; 07 后续 &nbsp; 清明节休息，这两天去了古北水镇，环境很好，挺悠闲，南方小城的感觉。 &nbsp; 参考： https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%B6%93%E5%85%83 https://en.wikipedia.org/wiki/Activation_function https://www.cnblogs.com/subconscious/p/5058741.html https://arxiv.org/pdf/1712.09913.pdf &nbsp; THE END - 晚安 - 图片长按2秒，识别图中二维码，关注订阅号" />
<meta property="og:description" content="上篇文章讲了《世界观 - 经验事实和哲学性/概念性事实》，很多科学真理和事实是基于复杂的论证过程，进而形成人们的世界观，推演，证明经过很多复杂的往复和推理过程，起初是经由发现，获取更多线索，不断证明，并不断被挑战（可证伪性），最终形成当下的世界观，人脑的思维过程能否被机器替代，今天主要简述下神经网络（Neural Network)。 &nbsp; 01 神经网络（Neural Network) 人的神经网络如上图所示，有点像树，有很多树突和轴突，不同的细胞通过树突和轴突传递信息，他们的基础点叫突触，一个细胞的轴突通过突触将信号传递给另一个细胞的树突。 我们能否设计这样的神经细胞结构，让彼此之间的通过某种方式相互刺激、协同完成信息处理呢？ 最早在1957年Rosenblatt提出了Perceptron（感知器模型）就讲研究领域带入到了神经网络。 &nbsp; 02 神经元 &nbsp; 神经元是神经细胞的基本组成单元，也是将要介绍的神经网络的主要组成部分。 神经网络的神经元主要由两部分组成，”线性模型“和”非线性模型（激励函数）“。 先说线性模型 X是一个一维向量，w0是bias（偏置值），w是权重矩阵，线性部分f(x)是神经元最核心的部分，对X做线性处理。 X可以看做是真理的某种假设，如相对论中，有个”奎因-迪昂论点”， 一些观点的集合，用来证明科学的过程中，可以摒弃（wk=0)或修改(调整wl)，我们的观点并不是单独的，而是作为整体来面对经验的裁判。 有点不好理解，简单来说，判断一个人是不是自己心目中的另一半，可能有多个要求和因素X（年龄，身高，收入，性格，国籍等），那么适不适合是一个综合判定。 得到： f(x)简化为 &nbsp; 03 激励函数（Activation Function） &nbsp; 激励函数相当于在一个神经元当中跟随在f（x）后面加入了一个非线性因素。 常见的激励函数 Wikipedia给出了很多种类的激励函数如下： 为什么需要引入非线性的关系 - 激励函数？ 如何仅仅包含线性函数，那么拟合的结果仅仅包含线性关系。 举个例子，我们需要区分下图中的红绿色 现实中人脑可能是通过人眼区分颜色，然后在判断是什么数字，比如我们体检的时候可能都看过一类图片，然后医生会让我们说出数字，如果仅包含线性关系，对于颜色分类这一pa，就可能会是 过于非黑即白，简单粗暴。现实中，我们需要这样的拟合如下： &nbsp; 04 单层神经网络 &amp; 损失函数 &nbsp; 单层神经网络，简单说来就是前面的模型 问题来了，如何选取W，得到最优的判断结果y？ &nbsp; 实际中，让拟合与真实差异之和最小，在上面例子中让下面公式的值最小， &nbsp; 扩展到整个矩阵 让Loss尽可能的小。 另外几种衡量损失的角度： &nbsp; &nbsp; 05 多层神经网络 &nbsp; 现实中可能需要多个隐藏层，有多个神经元，共同作用来拟合y，如下图。 每一层的输出，作为下一层的输入，实际上就是深度学习的过程。 &nbsp; &nbsp; 06 损失优化 &nbsp; 对于损失函数的计算，如何获取到最小的损失值的W。 直观感受，遍历所有的W基本是不可能的，如何找到W，从斜率衰减（Gradient Descent）的角度，Learning rate就先对是计算效率和精准的一个权衡角度。 选取Gradient Descent需要很多技巧，如何选取真正的最深谷底，还是到达波谷就停止计算？是一个技术活，参考《https://arxiv.org/pdf/1712.09913.pdf》会得到一些启发。 &nbsp; &nbsp; &nbsp; 07 后续 &nbsp; 清明节休息，这两天去了古北水镇，环境很好，挺悠闲，南方小城的感觉。 &nbsp; 参考： https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%B6%93%E5%85%83 https://en.wikipedia.org/wiki/Activation_function https://www.cnblogs.com/subconscious/p/5058741.html https://arxiv.org/pdf/1712.09913.pdf &nbsp; THE END - 晚安 - 图片长按2秒，识别图中二维码，关注订阅号" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-07T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"上篇文章讲了《世界观 - 经验事实和哲学性/概念性事实》，很多科学真理和事实是基于复杂的论证过程，进而形成人们的世界观，推演，证明经过很多复杂的往复和推理过程，起初是经由发现，获取更多线索，不断证明，并不断被挑战（可证伪性），最终形成当下的世界观，人脑的思维过程能否被机器替代，今天主要简述下神经网络（Neural Network)。 &nbsp; 01 神经网络（Neural Network) 人的神经网络如上图所示，有点像树，有很多树突和轴突，不同的细胞通过树突和轴突传递信息，他们的基础点叫突触，一个细胞的轴突通过突触将信号传递给另一个细胞的树突。 我们能否设计这样的神经细胞结构，让彼此之间的通过某种方式相互刺激、协同完成信息处理呢？ 最早在1957年Rosenblatt提出了Perceptron（感知器模型）就讲研究领域带入到了神经网络。 &nbsp; 02 神经元 &nbsp; 神经元是神经细胞的基本组成单元，也是将要介绍的神经网络的主要组成部分。 神经网络的神经元主要由两部分组成，”线性模型“和”非线性模型（激励函数）“。 先说线性模型 X是一个一维向量，w0是bias（偏置值），w是权重矩阵，线性部分f(x)是神经元最核心的部分，对X做线性处理。 X可以看做是真理的某种假设，如相对论中，有个”奎因-迪昂论点”， 一些观点的集合，用来证明科学的过程中，可以摒弃（wk=0)或修改(调整wl)，我们的观点并不是单独的，而是作为整体来面对经验的裁判。 有点不好理解，简单来说，判断一个人是不是自己心目中的另一半，可能有多个要求和因素X（年龄，身高，收入，性格，国籍等），那么适不适合是一个综合判定。 得到： f(x)简化为 &nbsp; 03 激励函数（Activation Function） &nbsp; 激励函数相当于在一个神经元当中跟随在f（x）后面加入了一个非线性因素。 常见的激励函数 Wikipedia给出了很多种类的激励函数如下： 为什么需要引入非线性的关系 - 激励函数？ 如何仅仅包含线性函数，那么拟合的结果仅仅包含线性关系。 举个例子，我们需要区分下图中的红绿色 现实中人脑可能是通过人眼区分颜色，然后在判断是什么数字，比如我们体检的时候可能都看过一类图片，然后医生会让我们说出数字，如果仅包含线性关系，对于颜色分类这一pa，就可能会是 过于非黑即白，简单粗暴。现实中，我们需要这样的拟合如下： &nbsp; 04 单层神经网络 &amp; 损失函数 &nbsp; 单层神经网络，简单说来就是前面的模型 问题来了，如何选取W，得到最优的判断结果y？ &nbsp; 实际中，让拟合与真实差异之和最小，在上面例子中让下面公式的值最小， &nbsp; 扩展到整个矩阵 让Loss尽可能的小。 另外几种衡量损失的角度： &nbsp; &nbsp; 05 多层神经网络 &nbsp; 现实中可能需要多个隐藏层，有多个神经元，共同作用来拟合y，如下图。 每一层的输出，作为下一层的输入，实际上就是深度学习的过程。 &nbsp; &nbsp; 06 损失优化 &nbsp; 对于损失函数的计算，如何获取到最小的损失值的W。 直观感受，遍历所有的W基本是不可能的，如何找到W，从斜率衰减（Gradient Descent）的角度，Learning rate就先对是计算效率和精准的一个权衡角度。 选取Gradient Descent需要很多技巧，如何选取真正的最深谷底，还是到达波谷就停止计算？是一个技术活，参考《https://arxiv.org/pdf/1712.09913.pdf》会得到一些启发。 &nbsp; &nbsp; &nbsp; 07 后续 &nbsp; 清明节休息，这两天去了古北水镇，环境很好，挺悠闲，南方小城的感觉。 &nbsp; 参考： https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%B6%93%E5%85%83 https://en.wikipedia.org/wiki/Activation_function https://www.cnblogs.com/subconscious/p/5058741.html https://arxiv.org/pdf/1712.09913.pdf &nbsp; THE END - 晚安 - 图片长按2秒，识别图中二维码，关注订阅号","@type":"BlogPosting","url":"/2019/04/07/728713.html","headline":"神经网络（Neural Network)","dateModified":"2019-04-07T00:00:00+08:00","datePublished":"2019-04-07T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/07/728713.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>神经网络（Neural Network)</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>上篇文章讲了《<a href="http://mp.weixin.qq.com/s?__biz=MzU2Njc3NDYxNw==&amp;mid=2247484176&amp;idx=1&amp;sn=a818c90b1365118ea7b9c723db269d5e&amp;chksm=fca61d26cbd19430d0eb0195aba477aa222fa319ab437eaff0a559feb1723f2b79851b0900de&amp;scene=21#wechat_redirect" rel="nofollow">世界观 - 经验事实和哲学性/概念性事实</a>》，很多科学真理和事实是基于复杂的论证过程，进而形成人们的世界观，推演，证明经过很多复杂的往复和推理过程，起初是经由发现，获取更多线索，不断证明，并不断被挑战（可证伪性），最终形成当下的世界观，人脑的思维过程能否被机器替代，今天主要简述下神经网络（Neural Network)。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxS4Ijw4VY5ouuDcFcauISe45OyqHPlAKOS9D0uJ5WfiaTL3nA2FtIOlw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p><em><strong>01</strong></em></p> 
  <p><strong>神经网络（Neural Network)</strong></p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxlvagSrRL6d6TTcck0O91qknStTHuicv9I9CadkF30tia0CucaSVqJYDQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>人的神经网络如上图所示，有点像树，有很多树突和轴突，不同的细胞通过树突和轴突传递信息，他们的基础点叫突触，一个细胞的轴突通过突触将信号传递给另一个细胞的树突。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxW4JL1fOiaYFvjlXX5qJR7Ke4Euicx7icBhYu9wgJcQlcA3toHauFPHkEQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>我们能否设计这样的神经细胞结构，让彼此之间的通过某种方式相互刺激、协同完成信息处理呢？</p> 
  <p>最早在1957年Rosenblatt提出了Perceptron（感知器模型）就讲研究领域带入到了神经网络。</p> 
  <p>&nbsp;</p> 
  <p><em><strong>02</strong></em></p> 
  <p><strong>神经元</strong></p> 
  <p>&nbsp;</p> 
  <p>神经元是神经细胞的基本组成单元，也是将要介绍的神经网络的主要组成部分。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxiaLYgSYqYtiaLhQcobC8ygum1uFWIxw9RciaRaiaPbEjibaOk2HONibooZvQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>神经网络的神经元主要由两部分组成，”线性模型“和”非线性模型（激励函数）“。</p> 
  <p>先说线性模型</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxQny9oCcUnDr2d2cUFaAxzVmEyzrXqhmp8yaSqibZbc1zdCdQwv9O7icQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>X是一个一维向量，w0是bias（偏置值），w是权重矩阵，线性部分f(x)是神经元最核心的部分，对X做线性处理。</p> 
  <p>X可以看做是真理的某种假设，如相对论中，有个”奎因-迪昂论点”， 一些观点的集合，用来证明科学的过程中，可以摒弃（wk=0)或修改(调整wl)，我们的观点并不是单独的，而是作为整体来面对经验的裁判。</p> 
  <p>有点不好理解，简单来说，判断一个人是不是自己心目中的另一半，可能有多个要求和因素X（年龄，身高，收入，性格，国籍等），那么适不适合是一个综合判定。</p> 
  <p>得到：</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxer0ahEUNbPlpDichUtdv6HOqdtz1LxwSVg4APYHT6BibXg3OlMSricXQA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>f(x)简化为</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxLqrmcBiaUw7l2BkVDaoxjuibYOEOuibF51iaejI3Psm6wxqklicjkvTtK1g/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p><em><strong>03</strong></em></p> 
  <p><strong>激励函数（Activation Function）</strong></p> 
  <p>&nbsp;</p> 
  <p>激励函数相当于在一个神经元当中跟随在f（x）后面加入了一个非线性因素。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxm90x9wKlaABtxlbVzfxgOdozTwbUSJK8DyFwX4BCXBDzQO3FvLhyAg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>常见的激励函数</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMx8PwKnJMgvvPgT7HeqHHh98uA2IkRibnJoR5BR4Nccjj3UnoGKDN15Jg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>Wikipedia给出了很多种类的激励函数如下：</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxrA92sRTGPrQ9FeHWwzQRwzY8FtibklQXGibXU6AyibwHSakRSvCAeseBg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>为什么需要引入非线性的关系 - 激励函数？</p> 
  <p>如何仅仅包含线性函数，那么拟合的结果仅仅包含线性关系。</p> 
  <p>举个例子，我们需要区分下图中的红绿色</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxt7ICQp6LQE0d1qAUPfcfWGU7IevKBiaicZJhxeibJNV7EWywdOEelY6KA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>现实中人脑可能是通过人眼区分颜色，然后在判断是什么数字，比如我们体检的时候可能都看过一类图片，然后医生会让我们说出数字，如果仅包含线性关系，对于颜色分类这一pa，就可能会是</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxZvI0XDSwOUX46PI09auv4xQqtOrVWeVBicncY4eP9fGuM39vUuibHNVQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>过于非黑即白，简单粗暴。现实中，我们需要这样的拟合如下：</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxhupqhZlL4vv98fYWJNmxPKYsJlw6OAuA3Hhrib3QNOiceJGP7dJibHviag/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p><em><strong>04</strong></em></p> 
  <p><strong>单层神经网络 &amp; 损失函数</strong></p> 
  <p>&nbsp;</p> 
  <p>单层神经网络，简单说来就是前面的模型</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxer0ahEUNbPlpDichUtdv6HOqdtz1LxwSVg4APYHT6BibXg3OlMSricXQA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>问题来了，如何选取W，得到最优的判断结果y？</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMx6SyatqiaJfvJZLsWFpMwsP0ic0Ir97xHjNMVwwc3MFjZ4ia6zGPricGoLA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxRtNCFkyEfiaib0riaCjIFQhD76nTloOLXib5VAZEs92aWicpfQxcD4olfTg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxia57ic4WJXlKBvbwHOE1aeltTtJAaRicfC5pgRyDEibm4USfbfMy17U6wg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p>实际中，让拟合与真实差异之和最小，在上面例子中让下面公式的值最小，</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxIuTxGH97Mq9rKkrk7PaK12ukLM2LNMnkkpIgZpds9UZpPwGmYmNaibg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p>扩展到整个矩阵</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMx2yQNDSImVhhl86xbQvyQ7sqEW5pFnrRuiabul0agofdib2IE2NtmrhGA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>让Loss尽可能的小。</p> 
  <p>另外几种衡量损失的角度：</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxUNhRrg8kq6Nu9REHBt2vZ4ZPISAThPhtsJhspCtUYYx7FJJt7MCianQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxMUGAlpZVwWEXX7efZ5B47Clp7WrwN2A0IF425HRpicnia5uKiaffxoobA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p><em><strong>05</strong></em></p> 
  <p><strong>多层神经网络</strong></p> 
  <p>&nbsp;</p> 
  <p>现实中可能需要多个隐藏层，有多个神经元，共同作用来拟合y，如下图。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxIibibvfs6Eego0U7e2mVjVeVwCUibF29am9vibaajaYib5fE2GaiaoJCWQhQ/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>每一层的输出，作为下一层的输入，实际上就是深度学习的过程。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxI4KvrvtibTf9FB9oBAMXdCCagK908y3wf3H9DTfEyoJn5vlialChFVicg/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p><em><strong>06</strong></em></p> 
  <p><strong>损失优化</strong></p> 
  <p>&nbsp;</p> 
  <p>对于损失函数的计算，如何获取到最小的损失值的W。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxqeTeFBCqaf51IwqJWEYlFfxLrNSmH1BEEGuuQsFTXLWsDIq5T8H0vw/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>直观感受，遍历所有的W基本是不可能的，如何找到W，从斜率衰减（Gradient Descent）的角度，Learning rate就先对是计算效率和精准的一个权衡角度。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxkejC3shl0fMQ4g84lFtCm8d1Z2HdY2tDIbFMicia8nfT3jzMrECTrP4w/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>选取Gradient Descent需要很多技巧，如何选取真正的最深谷底，还是到达波谷就停止计算？是一个技术活，参考《https://arxiv.org/pdf/1712.09913.pdf》会得到一些启发。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_png/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxYqm3MgBTAvlSwcJhtnMzfwyOUicLT2cbQfPufibvzwULaWgC0jLmtGTA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p><em><strong>07</strong></em></p> 
  <p><strong>后续</strong></p> 
  <p>&nbsp;</p> 
  <p>清明节休息，这两天去了古北水镇，环境很好，挺悠闲，南方小城的感觉。</p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_jpg/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxfYMKQWibvWBASwrhJjKXKSPLoWu5EY3j3DdxYFWIcBqt4vWMhAbdHicg/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_jpg/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMxvQ8TQt6c5ibiavTOoEkPf6HZFxZu4TPYfUJjyf3UcH6jl7VYBC3VDwgw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_jpg/9o07kOT4y6QcxNmTbrS3yg5Inib1ydQMx1KebBO1dL6OEYSGj9fySE50ONKRb2rjmauRW8VicWe0BMhkITUp38qw/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
  <p>&nbsp;</p> 
  <p>参考：</p> 
  <p>https://zh.wikipedia.org/wiki/%E7%A5%9E%E7%B6%93%E5%85%83</p> 
  <p>https://en.wikipedia.org/wiki/Activation_function</p> 
  <p>https://www.cnblogs.com/subconscious/p/5058741.html</p> 
  <p>https://arxiv.org/pdf/1712.09913.pdf</p> 
  <p>&nbsp;</p> 
  <p>THE END</p> 
  <p>- 晚安 -</p> 
  <p><strong>图片长按2秒，识别图中二维码，关注订阅号</strong></p> 
  <p><img alt="" class="has" src="https://mmbiz.qpic.cn/mmbiz_jpg/9o07kOT4y6RN88qzAIPuRH5AzcpwFlUqaBNJo4kIZ6DHRumJMVicc0CqshtEgDvfmknUDnxDGh7g6LqHgohEYhA/640?wx_fmt=jpeg&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
