<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>CIFAR-10数据集简介 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="CIFAR-10数据集简介" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="CIFAR-10数据集简介 文章目录 **CIFAR-10数据集简介** 1、CIFAR-10数据介绍 2、CIFAR-10官方测试代码 3、tensorboard的使用 1、tf.summary.scalar6+\7 2、tf.summary.histogram 3、tf.summary.distribution 4、tf.summary.text 5、tf.summary.image 6、tf.summary.audio 7、tf.summary.merge_all 8、tf.summary.FileWriter 9、tf.summary.merge 1、CIFAR-10数据介绍 Cifar-10 是由 Hinton 的学生 Alex Krizhevsky、Ilya Sutskever 收集的一个用于普适物体识别的计算机视觉数据集，它包含 60000 张 32 X 32 的 RGB 彩色图片，总共 10 个分类。其中，包括 50000 张用于训练集，10000 张用于测试集。 可视化代码： import pickle as p import numpy as np import matplotlib.pyplot as plt import matplotlib.image as plimg from PIL import Image def load_CIFAR_batch(filename): &quot;&quot;&quot; load single batch of cifar &quot;&quot;&quot; with open(filename, &#39;rb&#39;)as f: datadict = p.load(f,encoding=&#39;latin1&#39;) print(datadict.keys()) X = datadict[&#39;data&#39;] Y = datadict[&#39;labels&#39;] X = X.reshape(10000, 3, 32, 32) Y = np.array(Y) return X, Y if __name__ == &quot;__main__&quot;: imgX, imgY = load_CIFAR_batch(&quot;C:/Users/DaDaDa/Downloads/cifar-10-batches-py/data_batch_1&quot;) for i in range(imgX.shape[0]): imgs = imgX[i - 1] if i &lt; 100:#只循环100张图片,这句注释掉可以便利出所有的图片,图片较多,可能要一定的时间 img0 = imgs[0] img1 = imgs[1] img2 = imgs[2] i0 = Image.fromarray(img0) i1 = Image.fromarray(img1) i2 = Image.fromarray(img2) img = Image.merge(&quot;RGB&quot;,(i0,i1,i2)) name = &quot;img&quot; + str(i) + &quot;.png&quot; img.save(&quot;E:/python/课件/cifar_data/images/&quot;+name,&quot;png&quot;)#文件夹下是RGB融合后的图像 2、CIFAR-10官方测试代码 Tensorflow里面提供了使用CIFAR-10数据集的方法 1、从Tensorflow官网下载models模块，在 【tensorflow-models\tutorials\image\cifar10】 路径下有以下文件： cifar10_download.py 下载数据集 cifar10_input.py 读取cifar-10数据集文件 cifar10.py 建立cifar-10模型 cifar10_train.py 训练cifar-10数据集 cifar10_multi_gpu_train.py 在多GPU上训练cifar-10数据集 cifar10_eval.py 评估cifar-10模型的预测性能 整体框架代码： def inference(images): with tf.variable_scope(&#39;conv1&#39;) as scope: kernel = _variable_with_weight_decay(&#39;weights&#39;, shape=[5, 5, 3, 64], stddev=5e-2, wd=0.0) conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding=&#39;SAME&#39;) biases = _variable_on_cpu(&#39;biases&#39;, [64], tf.constant_initializer(0.0)) pre_activation = tf.nn.bias_add(conv, biases) conv1 = tf.nn.relu(pre_activation, name=scope.name) _activation_summary(conv1) # pool1 pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;, name=&#39;pool1&#39;) # norm1 norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#39;norm1&#39;) # conv2 with tf.variable_scope(&#39;conv2&#39;) as scope: kernel = _variable_with_weight_decay(&#39;weights&#39;, shape=[5, 5, 64, 64], stddev=5e-2, wd=0.0) conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding=&#39;SAME&#39;) biases = _variable_on_cpu(&#39;biases&#39;, [64], tf.constant_initializer(0.1)) pre_activation = tf.nn.bias_add(conv, biases) conv2 = tf.nn.relu(pre_activation, name=scope.name) _activation_summary(conv2) # norm2 norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#39;norm2&#39;) # pool2 pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;, name=&#39;pool2&#39;) # local3 with tf.variable_scope(&#39;local3&#39;) as scope: # Move everything into depth so we can perform a single matrix multiply. reshape = tf.reshape(pool2, [FLAGS.batch_size, -1]) dim = reshape.get_shape()[1].value weights = _variable_with_weight_decay(&#39;weights&#39;, shape=[dim, 384], stddev=0.04, wd=0.004) biases = _variable_on_cpu(&#39;biases&#39;, [384], tf.constant_initializer(0.1)) local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name) _activation_summary(local3) # local4 with tf.variable_scope(&#39;local4&#39;) as scope: weights = _variable_with_weight_decay(&#39;weights&#39;, shape=[384, 192], stddev=0.04, wd=0.004) biases = _variable_on_cpu(&#39;biases&#39;, [192], tf.constant_initializer(0.1)) local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name) _activation_summary(local4) # linear layer(WX + b), # We don&#39;t apply softmax here because # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits # and performs the softmax internally for efficiency. with tf.variable_scope(&#39;softmax_linear&#39;) as scope: weights = _variable_with_weight_decay(&#39;weights&#39;, [192, NUM_CLASSES], stddev=1/192.0, wd=0.0) biases = _variable_on_cpu(&#39;biases&#39;, [NUM_CLASSES], tf.constant_initializer(0.0)) softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name) _activation_summary(softmax_linear) return softmax_linear 3、tensorboard的使用 最近在研究tensorflow自带的例程speech_command,顺便学习tensorflow的一些基本用法。 其中tensorboard 作为一款可视化神器，可以说是学习tensorflow时模型训练以及参数可视化的法宝。 而在训练过程中，主要用到了tf.summary()的各类方法，能够保存训练过程以及参数分布图并在tensorboard显示。 tf.summary有诸多函数： 1、tf.summary.scalar6+\7 用来显示标量信息，其格式为： tf.summary.scalar(tags, values, collections=None, name=None) 例如：tf.summary.scalar(‘mean’, mean) 一般在画loss,accuary时会用到这个函数。 2、tf.summary.histogram 用来显示直方图信息，其格式为： tf.summary.histogram(tags, values, collections=None, name=None) 例如： tf.summary.histogram(‘histogram’, var) 一般用来显示训练过程中变量的分布情况 3、tf.summary.distribution 分布图，一般用于显示weights分布 4、tf.summary.text 可以将文本类型的数据转换为tensor写入summary中： 例如： text = &quot;&quot;&quot;/a/b/c\\_d/f\\_g\\_h\\_2017&quot;&quot;&quot; summary_op0 = tf.summary.text(&#39;text&#39;, tf.convert_to_tensor(text)) 5、tf.summary.image 输出带图像的probuf，汇总数据的图像的的形式如下： ’ tag /image/0’, ’ tag /image/1’…，如：input/image/0等。 格式：tf.summary.image(tag, tensor, max_images=3, collections=None, name=None) 6、tf.summary.audio 展示训练过程中记录的音频 7、tf.summary.merge_all merge_all 可以将所有summary全部保存到磁盘，以便tensorboard显示。如果没有特殊要求，一般用这一句就可一显示训练时的各种信息了。 格式：tf.summaries.merge_all(key=‘summaries’) 8、tf.summary.FileWriter 指定一个文件用来保存图。 格式：tf.summary.FileWritter(path,sess.graph) 可以调用其add_summary（）方法将训练过程数据保存在filewriter指定的文件中 Tensorflow Summary 用法示例: tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge_all() train_writer = tf.summary.FileWriter(dir,sess.graph)#定义一个写入summary的目标文件，dir为写入文件地址 ......(交叉熵、优化器等定义) for step in xrange(training_step): #训练循环 train_summary = sess.run(merge_summary,feed_dict = {...})#调用sess.run运行图，生成一步的训练过程数据 train_writer.add_summary(train_summary,step)#调用train_writer的add_summary方法将训练过程以及训练步数保存 此时开启tensorborad： tensorboard --logdir=/summary_dir 便能看见accuracy曲线了。 另外，如果我不想保存所有定义的summary信息，也可以用tf.summary.merge方法有选择性地保存信息： 9、tf.summary.merge 格式：tf.summary.merge(inputs, collections=None, name=None) 一般选择要保存的信息还需要用到tf.get_collection()函数 示例： tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge([tf.get_collection(tf.GraphKeys.SUMMARIES,&#39;accuracy&#39;),...(其他要显示的信息)]) train_writer = tf.summary.FileWriter(dir,sess.graph)#定义一个写入summary的目标文件，dir为写入文件地址 ......(交叉熵、优化器等定义) for step in xrange(training_step): #训练循环 train_summary = sess.run(merge_summary,feed_dict = {...})#调用sess.run运行图，生成一步的训练过程数据 train_writer.add_summary(train_summary,step)#调用train_writer的add_summary方法将训练过程以及训练步数保存 使用tf.get_collection函数筛选图中summary信息中的accuracy信息，这里的 tf.GraphKeys.SUMMARIES 是summary在collection中的标志。 当然，也可以直接： acc_summary = tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge([acc_summary ,...(其他要显示的信息)]) #这里的[]不可省 如果要在tensorboard中画多个数据图，需定义多个tf.summary.FileWriter并重复上述过程" />
<meta property="og:description" content="CIFAR-10数据集简介 文章目录 **CIFAR-10数据集简介** 1、CIFAR-10数据介绍 2、CIFAR-10官方测试代码 3、tensorboard的使用 1、tf.summary.scalar6+\7 2、tf.summary.histogram 3、tf.summary.distribution 4、tf.summary.text 5、tf.summary.image 6、tf.summary.audio 7、tf.summary.merge_all 8、tf.summary.FileWriter 9、tf.summary.merge 1、CIFAR-10数据介绍 Cifar-10 是由 Hinton 的学生 Alex Krizhevsky、Ilya Sutskever 收集的一个用于普适物体识别的计算机视觉数据集，它包含 60000 张 32 X 32 的 RGB 彩色图片，总共 10 个分类。其中，包括 50000 张用于训练集，10000 张用于测试集。 可视化代码： import pickle as p import numpy as np import matplotlib.pyplot as plt import matplotlib.image as plimg from PIL import Image def load_CIFAR_batch(filename): &quot;&quot;&quot; load single batch of cifar &quot;&quot;&quot; with open(filename, &#39;rb&#39;)as f: datadict = p.load(f,encoding=&#39;latin1&#39;) print(datadict.keys()) X = datadict[&#39;data&#39;] Y = datadict[&#39;labels&#39;] X = X.reshape(10000, 3, 32, 32) Y = np.array(Y) return X, Y if __name__ == &quot;__main__&quot;: imgX, imgY = load_CIFAR_batch(&quot;C:/Users/DaDaDa/Downloads/cifar-10-batches-py/data_batch_1&quot;) for i in range(imgX.shape[0]): imgs = imgX[i - 1] if i &lt; 100:#只循环100张图片,这句注释掉可以便利出所有的图片,图片较多,可能要一定的时间 img0 = imgs[0] img1 = imgs[1] img2 = imgs[2] i0 = Image.fromarray(img0) i1 = Image.fromarray(img1) i2 = Image.fromarray(img2) img = Image.merge(&quot;RGB&quot;,(i0,i1,i2)) name = &quot;img&quot; + str(i) + &quot;.png&quot; img.save(&quot;E:/python/课件/cifar_data/images/&quot;+name,&quot;png&quot;)#文件夹下是RGB融合后的图像 2、CIFAR-10官方测试代码 Tensorflow里面提供了使用CIFAR-10数据集的方法 1、从Tensorflow官网下载models模块，在 【tensorflow-models\tutorials\image\cifar10】 路径下有以下文件： cifar10_download.py 下载数据集 cifar10_input.py 读取cifar-10数据集文件 cifar10.py 建立cifar-10模型 cifar10_train.py 训练cifar-10数据集 cifar10_multi_gpu_train.py 在多GPU上训练cifar-10数据集 cifar10_eval.py 评估cifar-10模型的预测性能 整体框架代码： def inference(images): with tf.variable_scope(&#39;conv1&#39;) as scope: kernel = _variable_with_weight_decay(&#39;weights&#39;, shape=[5, 5, 3, 64], stddev=5e-2, wd=0.0) conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding=&#39;SAME&#39;) biases = _variable_on_cpu(&#39;biases&#39;, [64], tf.constant_initializer(0.0)) pre_activation = tf.nn.bias_add(conv, biases) conv1 = tf.nn.relu(pre_activation, name=scope.name) _activation_summary(conv1) # pool1 pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;, name=&#39;pool1&#39;) # norm1 norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#39;norm1&#39;) # conv2 with tf.variable_scope(&#39;conv2&#39;) as scope: kernel = _variable_with_weight_decay(&#39;weights&#39;, shape=[5, 5, 64, 64], stddev=5e-2, wd=0.0) conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding=&#39;SAME&#39;) biases = _variable_on_cpu(&#39;biases&#39;, [64], tf.constant_initializer(0.1)) pre_activation = tf.nn.bias_add(conv, biases) conv2 = tf.nn.relu(pre_activation, name=scope.name) _activation_summary(conv2) # norm2 norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#39;norm2&#39;) # pool2 pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;, name=&#39;pool2&#39;) # local3 with tf.variable_scope(&#39;local3&#39;) as scope: # Move everything into depth so we can perform a single matrix multiply. reshape = tf.reshape(pool2, [FLAGS.batch_size, -1]) dim = reshape.get_shape()[1].value weights = _variable_with_weight_decay(&#39;weights&#39;, shape=[dim, 384], stddev=0.04, wd=0.004) biases = _variable_on_cpu(&#39;biases&#39;, [384], tf.constant_initializer(0.1)) local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name) _activation_summary(local3) # local4 with tf.variable_scope(&#39;local4&#39;) as scope: weights = _variable_with_weight_decay(&#39;weights&#39;, shape=[384, 192], stddev=0.04, wd=0.004) biases = _variable_on_cpu(&#39;biases&#39;, [192], tf.constant_initializer(0.1)) local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name) _activation_summary(local4) # linear layer(WX + b), # We don&#39;t apply softmax here because # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits # and performs the softmax internally for efficiency. with tf.variable_scope(&#39;softmax_linear&#39;) as scope: weights = _variable_with_weight_decay(&#39;weights&#39;, [192, NUM_CLASSES], stddev=1/192.0, wd=0.0) biases = _variable_on_cpu(&#39;biases&#39;, [NUM_CLASSES], tf.constant_initializer(0.0)) softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name) _activation_summary(softmax_linear) return softmax_linear 3、tensorboard的使用 最近在研究tensorflow自带的例程speech_command,顺便学习tensorflow的一些基本用法。 其中tensorboard 作为一款可视化神器，可以说是学习tensorflow时模型训练以及参数可视化的法宝。 而在训练过程中，主要用到了tf.summary()的各类方法，能够保存训练过程以及参数分布图并在tensorboard显示。 tf.summary有诸多函数： 1、tf.summary.scalar6+\7 用来显示标量信息，其格式为： tf.summary.scalar(tags, values, collections=None, name=None) 例如：tf.summary.scalar(‘mean’, mean) 一般在画loss,accuary时会用到这个函数。 2、tf.summary.histogram 用来显示直方图信息，其格式为： tf.summary.histogram(tags, values, collections=None, name=None) 例如： tf.summary.histogram(‘histogram’, var) 一般用来显示训练过程中变量的分布情况 3、tf.summary.distribution 分布图，一般用于显示weights分布 4、tf.summary.text 可以将文本类型的数据转换为tensor写入summary中： 例如： text = &quot;&quot;&quot;/a/b/c\\_d/f\\_g\\_h\\_2017&quot;&quot;&quot; summary_op0 = tf.summary.text(&#39;text&#39;, tf.convert_to_tensor(text)) 5、tf.summary.image 输出带图像的probuf，汇总数据的图像的的形式如下： ’ tag /image/0’, ’ tag /image/1’…，如：input/image/0等。 格式：tf.summary.image(tag, tensor, max_images=3, collections=None, name=None) 6、tf.summary.audio 展示训练过程中记录的音频 7、tf.summary.merge_all merge_all 可以将所有summary全部保存到磁盘，以便tensorboard显示。如果没有特殊要求，一般用这一句就可一显示训练时的各种信息了。 格式：tf.summaries.merge_all(key=‘summaries’) 8、tf.summary.FileWriter 指定一个文件用来保存图。 格式：tf.summary.FileWritter(path,sess.graph) 可以调用其add_summary（）方法将训练过程数据保存在filewriter指定的文件中 Tensorflow Summary 用法示例: tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge_all() train_writer = tf.summary.FileWriter(dir,sess.graph)#定义一个写入summary的目标文件，dir为写入文件地址 ......(交叉熵、优化器等定义) for step in xrange(training_step): #训练循环 train_summary = sess.run(merge_summary,feed_dict = {...})#调用sess.run运行图，生成一步的训练过程数据 train_writer.add_summary(train_summary,step)#调用train_writer的add_summary方法将训练过程以及训练步数保存 此时开启tensorborad： tensorboard --logdir=/summary_dir 便能看见accuracy曲线了。 另外，如果我不想保存所有定义的summary信息，也可以用tf.summary.merge方法有选择性地保存信息： 9、tf.summary.merge 格式：tf.summary.merge(inputs, collections=None, name=None) 一般选择要保存的信息还需要用到tf.get_collection()函数 示例： tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge([tf.get_collection(tf.GraphKeys.SUMMARIES,&#39;accuracy&#39;),...(其他要显示的信息)]) train_writer = tf.summary.FileWriter(dir,sess.graph)#定义一个写入summary的目标文件，dir为写入文件地址 ......(交叉熵、优化器等定义) for step in xrange(training_step): #训练循环 train_summary = sess.run(merge_summary,feed_dict = {...})#调用sess.run运行图，生成一步的训练过程数据 train_writer.add_summary(train_summary,step)#调用train_writer的add_summary方法将训练过程以及训练步数保存 使用tf.get_collection函数筛选图中summary信息中的accuracy信息，这里的 tf.GraphKeys.SUMMARIES 是summary在collection中的标志。 当然，也可以直接： acc_summary = tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge([acc_summary ,...(其他要显示的信息)]) #这里的[]不可省 如果要在tensorboard中画多个数据图，需定义多个tf.summary.FileWriter并重复上述过程" />
<link rel="canonical" href="https://mlh.app/2019/04/07/728725.html" />
<meta property="og:url" content="https://mlh.app/2019/04/07/728725.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-07T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"CIFAR-10数据集简介 文章目录 **CIFAR-10数据集简介** 1、CIFAR-10数据介绍 2、CIFAR-10官方测试代码 3、tensorboard的使用 1、tf.summary.scalar6+\\7 2、tf.summary.histogram 3、tf.summary.distribution 4、tf.summary.text 5、tf.summary.image 6、tf.summary.audio 7、tf.summary.merge_all 8、tf.summary.FileWriter 9、tf.summary.merge 1、CIFAR-10数据介绍 Cifar-10 是由 Hinton 的学生 Alex Krizhevsky、Ilya Sutskever 收集的一个用于普适物体识别的计算机视觉数据集，它包含 60000 张 32 X 32 的 RGB 彩色图片，总共 10 个分类。其中，包括 50000 张用于训练集，10000 张用于测试集。 可视化代码： import pickle as p import numpy as np import matplotlib.pyplot as plt import matplotlib.image as plimg from PIL import Image def load_CIFAR_batch(filename): &quot;&quot;&quot; load single batch of cifar &quot;&quot;&quot; with open(filename, &#39;rb&#39;)as f: datadict = p.load(f,encoding=&#39;latin1&#39;) print(datadict.keys()) X = datadict[&#39;data&#39;] Y = datadict[&#39;labels&#39;] X = X.reshape(10000, 3, 32, 32) Y = np.array(Y) return X, Y if __name__ == &quot;__main__&quot;: imgX, imgY = load_CIFAR_batch(&quot;C:/Users/DaDaDa/Downloads/cifar-10-batches-py/data_batch_1&quot;) for i in range(imgX.shape[0]): imgs = imgX[i - 1] if i &lt; 100:#只循环100张图片,这句注释掉可以便利出所有的图片,图片较多,可能要一定的时间 img0 = imgs[0] img1 = imgs[1] img2 = imgs[2] i0 = Image.fromarray(img0) i1 = Image.fromarray(img1) i2 = Image.fromarray(img2) img = Image.merge(&quot;RGB&quot;,(i0,i1,i2)) name = &quot;img&quot; + str(i) + &quot;.png&quot; img.save(&quot;E:/python/课件/cifar_data/images/&quot;+name,&quot;png&quot;)#文件夹下是RGB融合后的图像 2、CIFAR-10官方测试代码 Tensorflow里面提供了使用CIFAR-10数据集的方法 1、从Tensorflow官网下载models模块，在 【tensorflow-models\\tutorials\\image\\cifar10】 路径下有以下文件： cifar10_download.py 下载数据集 cifar10_input.py 读取cifar-10数据集文件 cifar10.py 建立cifar-10模型 cifar10_train.py 训练cifar-10数据集 cifar10_multi_gpu_train.py 在多GPU上训练cifar-10数据集 cifar10_eval.py 评估cifar-10模型的预测性能 整体框架代码： def inference(images): with tf.variable_scope(&#39;conv1&#39;) as scope: kernel = _variable_with_weight_decay(&#39;weights&#39;, shape=[5, 5, 3, 64], stddev=5e-2, wd=0.0) conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding=&#39;SAME&#39;) biases = _variable_on_cpu(&#39;biases&#39;, [64], tf.constant_initializer(0.0)) pre_activation = tf.nn.bias_add(conv, biases) conv1 = tf.nn.relu(pre_activation, name=scope.name) _activation_summary(conv1) # pool1 pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;, name=&#39;pool1&#39;) # norm1 norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#39;norm1&#39;) # conv2 with tf.variable_scope(&#39;conv2&#39;) as scope: kernel = _variable_with_weight_decay(&#39;weights&#39;, shape=[5, 5, 64, 64], stddev=5e-2, wd=0.0) conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding=&#39;SAME&#39;) biases = _variable_on_cpu(&#39;biases&#39;, [64], tf.constant_initializer(0.1)) pre_activation = tf.nn.bias_add(conv, biases) conv2 = tf.nn.relu(pre_activation, name=scope.name) _activation_summary(conv2) # norm2 norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=&#39;norm2&#39;) # pool2 pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding=&#39;SAME&#39;, name=&#39;pool2&#39;) # local3 with tf.variable_scope(&#39;local3&#39;) as scope: # Move everything into depth so we can perform a single matrix multiply. reshape = tf.reshape(pool2, [FLAGS.batch_size, -1]) dim = reshape.get_shape()[1].value weights = _variable_with_weight_decay(&#39;weights&#39;, shape=[dim, 384], stddev=0.04, wd=0.004) biases = _variable_on_cpu(&#39;biases&#39;, [384], tf.constant_initializer(0.1)) local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name) _activation_summary(local3) # local4 with tf.variable_scope(&#39;local4&#39;) as scope: weights = _variable_with_weight_decay(&#39;weights&#39;, shape=[384, 192], stddev=0.04, wd=0.004) biases = _variable_on_cpu(&#39;biases&#39;, [192], tf.constant_initializer(0.1)) local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name) _activation_summary(local4) # linear layer(WX + b), # We don&#39;t apply softmax here because # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits # and performs the softmax internally for efficiency. with tf.variable_scope(&#39;softmax_linear&#39;) as scope: weights = _variable_with_weight_decay(&#39;weights&#39;, [192, NUM_CLASSES], stddev=1/192.0, wd=0.0) biases = _variable_on_cpu(&#39;biases&#39;, [NUM_CLASSES], tf.constant_initializer(0.0)) softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name) _activation_summary(softmax_linear) return softmax_linear 3、tensorboard的使用 最近在研究tensorflow自带的例程speech_command,顺便学习tensorflow的一些基本用法。 其中tensorboard 作为一款可视化神器，可以说是学习tensorflow时模型训练以及参数可视化的法宝。 而在训练过程中，主要用到了tf.summary()的各类方法，能够保存训练过程以及参数分布图并在tensorboard显示。 tf.summary有诸多函数： 1、tf.summary.scalar6+\\7 用来显示标量信息，其格式为： tf.summary.scalar(tags, values, collections=None, name=None) 例如：tf.summary.scalar(‘mean’, mean) 一般在画loss,accuary时会用到这个函数。 2、tf.summary.histogram 用来显示直方图信息，其格式为： tf.summary.histogram(tags, values, collections=None, name=None) 例如： tf.summary.histogram(‘histogram’, var) 一般用来显示训练过程中变量的分布情况 3、tf.summary.distribution 分布图，一般用于显示weights分布 4、tf.summary.text 可以将文本类型的数据转换为tensor写入summary中： 例如： text = &quot;&quot;&quot;/a/b/c\\\\_d/f\\\\_g\\\\_h\\\\_2017&quot;&quot;&quot; summary_op0 = tf.summary.text(&#39;text&#39;, tf.convert_to_tensor(text)) 5、tf.summary.image 输出带图像的probuf，汇总数据的图像的的形式如下： ’ tag /image/0’, ’ tag /image/1’…，如：input/image/0等。 格式：tf.summary.image(tag, tensor, max_images=3, collections=None, name=None) 6、tf.summary.audio 展示训练过程中记录的音频 7、tf.summary.merge_all merge_all 可以将所有summary全部保存到磁盘，以便tensorboard显示。如果没有特殊要求，一般用这一句就可一显示训练时的各种信息了。 格式：tf.summaries.merge_all(key=‘summaries’) 8、tf.summary.FileWriter 指定一个文件用来保存图。 格式：tf.summary.FileWritter(path,sess.graph) 可以调用其add_summary（）方法将训练过程数据保存在filewriter指定的文件中 Tensorflow Summary 用法示例: tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge_all() train_writer = tf.summary.FileWriter(dir,sess.graph)#定义一个写入summary的目标文件，dir为写入文件地址 ......(交叉熵、优化器等定义) for step in xrange(training_step): #训练循环 train_summary = sess.run(merge_summary,feed_dict = {...})#调用sess.run运行图，生成一步的训练过程数据 train_writer.add_summary(train_summary,step)#调用train_writer的add_summary方法将训练过程以及训练步数保存 此时开启tensorborad： tensorboard --logdir=/summary_dir 便能看见accuracy曲线了。 另外，如果我不想保存所有定义的summary信息，也可以用tf.summary.merge方法有选择性地保存信息： 9、tf.summary.merge 格式：tf.summary.merge(inputs, collections=None, name=None) 一般选择要保存的信息还需要用到tf.get_collection()函数 示例： tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge([tf.get_collection(tf.GraphKeys.SUMMARIES,&#39;accuracy&#39;),...(其他要显示的信息)]) train_writer = tf.summary.FileWriter(dir,sess.graph)#定义一个写入summary的目标文件，dir为写入文件地址 ......(交叉熵、优化器等定义) for step in xrange(training_step): #训练循环 train_summary = sess.run(merge_summary,feed_dict = {...})#调用sess.run运行图，生成一步的训练过程数据 train_writer.add_summary(train_summary,step)#调用train_writer的add_summary方法将训练过程以及训练步数保存 使用tf.get_collection函数筛选图中summary信息中的accuracy信息，这里的 tf.GraphKeys.SUMMARIES 是summary在collection中的标志。 当然，也可以直接： acc_summary = tf.summary.scalar(&#39;accuracy&#39;,acc) #生成准确率标量图 merge_summary = tf.summary.merge([acc_summary ,...(其他要显示的信息)]) #这里的[]不可省 如果要在tensorboard中画多个数据图，需定义多个tf.summary.FileWriter并重复上述过程","@type":"BlogPosting","url":"https://mlh.app/2019/04/07/728725.html","headline":"CIFAR-10数据集简介","dateModified":"2019-04-07T00:00:00+08:00","datePublished":"2019-04-07T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/04/07/728725.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>CIFAR-10数据集简介</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <h1><a id="CIFAR10_0"></a><strong>CIFAR-10数据集简介</strong></h1> 
  <p></p>
  <div class="toc">
   <h3>文章目录</h3>
   <ul>
    <li><a href="#CIFAR10_0" rel="nofollow">**CIFAR-10数据集简介**</a></li>
    <ul>
     <ul>
      <li><a href="#1CIFAR10_5" rel="nofollow">1、CIFAR-10数据介绍</a></li>
      <li><a href="#2CIFAR10_46" rel="nofollow">2、CIFAR-10官方测试代码</a></li>
      <li><a href="#3tensorboard_144" rel="nofollow">3、tensorboard的使用</a></li>
      <ul>
       <li><a href="#1tfsummaryscalar67_154" rel="nofollow">1、tf.summary.scalar6+\7</a></li>
       <li><a href="#2tfsummaryhistogram_166" rel="nofollow">2、tf.summary.histogram</a></li>
       <li><a href="#3tfsummarydistribution_178" rel="nofollow">3、tf.summary.distribution</a></li>
       <li><a href="#4tfsummarytext_182" rel="nofollow">4、tf.summary.text</a></li>
       <li><a href="#5tfsummaryimage_193" rel="nofollow">5、tf.summary.image</a></li>
       <li><a href="#6tfsummaryaudio_199" rel="nofollow">6、tf.summary.audio</a></li>
       <li><a href="#7tfsummarymerge_all_203" rel="nofollow">7、tf.summary.merge_all</a></li>
       <li><a href="#8tfsummaryFileWriter_209" rel="nofollow">8、tf.summary.FileWriter</a></li>
       <li><a href="#9tfsummarymerge_237" rel="nofollow">9、tf.summary.merge</a></li>
      </ul>
     </ul>
    </ul>
   </ul>
  </div>
  <p></p> 
  <h3><a id="1CIFAR10_5"></a>1、CIFAR-10数据介绍</h3> 
  <p>Cifar-10 是由 Hinton 的学生 Alex Krizhevsky、Ilya Sutskever 收集的一个用于普适物体识别的计算机视觉数据集，它包含 60000 张 32 X 32 的 RGB 彩色图片，总共 10 个分类。其中，包括 50000 张用于训练集，10000 张用于测试集。</p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20161017144207114?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img"></p> 
  <p>可视化代码：</p> 
  <pre><code class="prism language-python"><span class="token keyword">import</span> pickle <span class="token keyword">as</span> p
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>image <span class="token keyword">as</span> plimg
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">def</span> <span class="token function">load_CIFAR_batch</span><span class="token punctuation">(</span>filename<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">""" load single batch of cifar """</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>filename<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span><span class="token keyword">as</span> f<span class="token punctuation">:</span>
        datadict <span class="token operator">=</span> p<span class="token punctuation">.</span>load<span class="token punctuation">(</span>f<span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'latin1'</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>datadict<span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        X <span class="token operator">=</span> datadict<span class="token punctuation">[</span><span class="token string">'data'</span><span class="token punctuation">]</span>
        Y <span class="token operator">=</span> datadict<span class="token punctuation">[</span><span class="token string">'labels'</span><span class="token punctuation">]</span>
        X <span class="token operator">=</span> X<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span>
        Y <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
        <span class="token keyword">return</span> X<span class="token punctuation">,</span> Y

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>
    imgX<span class="token punctuation">,</span> imgY <span class="token operator">=</span> load_CIFAR_batch<span class="token punctuation">(</span><span class="token string">"C:/Users/DaDaDa/Downloads/cifar-10-batches-py/data_batch_1"</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>imgX<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        imgs <span class="token operator">=</span> imgX<span class="token punctuation">[</span>i <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> i <span class="token operator">&lt;</span> <span class="token number">100</span><span class="token punctuation">:</span><span class="token comment">#只循环100张图片,这句注释掉可以便利出所有的图片,图片较多,可能要一定的时间</span>
            img0 <span class="token operator">=</span> imgs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
            img1 <span class="token operator">=</span> imgs<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
            img2 <span class="token operator">=</span> imgs<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>
            i0 <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>img0<span class="token punctuation">)</span>
            i1 <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>img1<span class="token punctuation">)</span>
            i2 <span class="token operator">=</span> Image<span class="token punctuation">.</span>fromarray<span class="token punctuation">(</span>img2<span class="token punctuation">)</span>
            img <span class="token operator">=</span> Image<span class="token punctuation">.</span>merge<span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">,</span><span class="token punctuation">(</span>i0<span class="token punctuation">,</span>i1<span class="token punctuation">,</span>i2<span class="token punctuation">)</span><span class="token punctuation">)</span>
            name <span class="token operator">=</span> <span class="token string">"img"</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">".png"</span>
            img<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"E:/python/课件/cifar_data/images/"</span><span class="token operator">+</span>name<span class="token punctuation">,</span><span class="token string">"png"</span><span class="token punctuation">)</span><span class="token comment">#文件夹下是RGB融合后的图像</span>
</code></pre> 
  <h3><a id="2CIFAR10_46"></a>2、CIFAR-10官方测试代码</h3> 
  <p>Tensorflow里面提供了使用CIFAR-10数据集的方法</p> 
  <p>1、从Tensorflow官网下载models模块，在 【tensorflow-models\tutorials\image\cifar10】 路径下有以下文件：</p> 
  <p><strong>cifar10_download.py</strong> 下载数据集</p> 
  <p><strong>cifar10_input.py</strong> 读取cifar-10数据集文件</p> 
  <p><strong><a href="http://cifar10.py" rel="nofollow">cifar10.py</a></strong> 建立cifar-10模型</p> 
  <p><strong>cifar10_train.py</strong> 训练cifar-10数据集</p> 
  <p><strong>cifar10_multi_gpu_train.py</strong> 在多GPU上训练cifar-10数据集</p> 
  <p><strong>cifar10_eval.py</strong> 评估cifar-10模型的预测性能</p> 
  <p><img src="C:%5CUsers%5CDaDaDa%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1554616500690.png" alt="1554616500690"></p> 
  <p>整体框架代码：</p> 
  <pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">:</span>
  <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'conv1'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>
    kernel <span class="token operator">=</span> _variable_with_weight_decay<span class="token punctuation">(</span><span class="token string">'weights'</span><span class="token punctuation">,</span>
                                         shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                         stddev<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>
                                         wd<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    conv <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>images<span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>
    biases <span class="token operator">=</span> _variable_on_cpu<span class="token punctuation">(</span><span class="token string">'biases'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    pre_activation <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>conv<span class="token punctuation">,</span> biases<span class="token punctuation">)</span>
    conv1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>pre_activation<span class="token punctuation">,</span> name<span class="token operator">=</span>scope<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
    _activation_summary<span class="token punctuation">(</span>conv1<span class="token punctuation">)</span>

  <span class="token comment"># pool1</span>
  pool1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>conv1<span class="token punctuation">,</span> ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'pool1'</span><span class="token punctuation">)</span>
  <span class="token comment"># norm1</span>
  norm1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>lrn<span class="token punctuation">(</span>pool1<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.001</span> <span class="token operator">/</span> <span class="token number">9.0</span><span class="token punctuation">,</span> beta<span class="token operator">=</span><span class="token number">0.75</span><span class="token punctuation">,</span>
                    name<span class="token operator">=</span><span class="token string">'norm1'</span><span class="token punctuation">)</span>

  <span class="token comment"># conv2</span>
  <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'conv2'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>
    kernel <span class="token operator">=</span> _variable_with_weight_decay<span class="token punctuation">(</span><span class="token string">'weights'</span><span class="token punctuation">,</span>
                                         shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                         stddev<span class="token operator">=</span><span class="token number">5e</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span>
                                         wd<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    conv <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>norm1<span class="token punctuation">,</span> kernel<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>
    biases <span class="token operator">=</span> _variable_on_cpu<span class="token punctuation">(</span><span class="token string">'biases'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    pre_activation <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>conv<span class="token punctuation">,</span> biases<span class="token punctuation">)</span>
    conv2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>pre_activation<span class="token punctuation">,</span> name<span class="token operator">=</span>scope<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
    _activation_summary<span class="token punctuation">(</span>conv2<span class="token punctuation">)</span>

  <span class="token comment"># norm2</span>
  norm2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>lrn<span class="token punctuation">(</span>conv2<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> bias<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.001</span> <span class="token operator">/</span> <span class="token number">9.0</span><span class="token punctuation">,</span> beta<span class="token operator">=</span><span class="token number">0.75</span><span class="token punctuation">,</span>
                    name<span class="token operator">=</span><span class="token string">'norm2'</span><span class="token punctuation">)</span>
  <span class="token comment"># pool2</span>
  pool2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>norm2<span class="token punctuation">,</span> ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                         strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'pool2'</span><span class="token punctuation">)</span>

  <span class="token comment"># local3</span>
  <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'local3'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>
    <span class="token comment"># Move everything into depth so we can perform a single matrix multiply.</span>
    reshape <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>pool2<span class="token punctuation">,</span> <span class="token punctuation">[</span>FLAGS<span class="token punctuation">.</span>batch_size<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    dim <span class="token operator">=</span> reshape<span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>value
    weights <span class="token operator">=</span> _variable_with_weight_decay<span class="token punctuation">(</span><span class="token string">'weights'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>dim<span class="token punctuation">,</span> <span class="token number">384</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                          stddev<span class="token operator">=</span><span class="token number">0.04</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.004</span><span class="token punctuation">)</span>
    biases <span class="token operator">=</span> _variable_on_cpu<span class="token punctuation">(</span><span class="token string">'biases'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">384</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    local3 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>reshape<span class="token punctuation">,</span> weights<span class="token punctuation">)</span> <span class="token operator">+</span> biases<span class="token punctuation">,</span> name<span class="token operator">=</span>scope<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
    _activation_summary<span class="token punctuation">(</span>local3<span class="token punctuation">)</span>

  <span class="token comment"># local4</span>
  <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'local4'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>
    weights <span class="token operator">=</span> _variable_with_weight_decay<span class="token punctuation">(</span><span class="token string">'weights'</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">384</span><span class="token punctuation">,</span> <span class="token number">192</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                                          stddev<span class="token operator">=</span><span class="token number">0.04</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.004</span><span class="token punctuation">)</span>
    biases <span class="token operator">=</span> _variable_on_cpu<span class="token punctuation">(</span><span class="token string">'biases'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">192</span><span class="token punctuation">]</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    local4 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>local3<span class="token punctuation">,</span> weights<span class="token punctuation">)</span> <span class="token operator">+</span> biases<span class="token punctuation">,</span> name<span class="token operator">=</span>scope<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
    _activation_summary<span class="token punctuation">(</span>local4<span class="token punctuation">)</span>

  <span class="token comment"># linear layer(WX + b),</span>
  <span class="token comment"># We don't apply softmax here because</span>
  <span class="token comment"># tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits</span>
  <span class="token comment"># and performs the softmax internally for efficiency.</span>
  <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'softmax_linear'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> scope<span class="token punctuation">:</span>
    weights <span class="token operator">=</span> _variable_with_weight_decay<span class="token punctuation">(</span><span class="token string">'weights'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">192</span><span class="token punctuation">,</span> NUM_CLASSES<span class="token punctuation">]</span><span class="token punctuation">,</span>
                                          stddev<span class="token operator">=</span><span class="token number">1</span><span class="token operator">/</span><span class="token number">192.0</span><span class="token punctuation">,</span> wd<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">)</span>
    biases <span class="token operator">=</span> _variable_on_cpu<span class="token punctuation">(</span><span class="token string">'biases'</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>NUM_CLASSES<span class="token punctuation">]</span><span class="token punctuation">,</span>
                              tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    softmax_linear <span class="token operator">=</span> tf<span class="token punctuation">.</span>add<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>local4<span class="token punctuation">,</span> weights<span class="token punctuation">)</span><span class="token punctuation">,</span> biases<span class="token punctuation">,</span> name<span class="token operator">=</span>scope<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
    _activation_summary<span class="token punctuation">(</span>softmax_linear<span class="token punctuation">)</span>

  <span class="token keyword">return</span> softmax_linear

</code></pre> 
  <h3><a id="3tensorboard_144"></a>3、tensorboard的使用</h3> 
  <p>最近在研究tensorflow自带的例程speech_command,顺便学习tensorflow的一些基本用法。</p> 
  <p>其中tensorboard 作为一款可视化神器，可以说是学习tensorflow时模型训练以及参数可视化的法宝。</p> 
  <p>而在训练过程中，主要用到了tf.summary()的各类方法，能够保存训练过程以及参数分布图并在tensorboard显示。</p> 
  <p>tf.summary有诸多函数：</p> 
  <h4><a id="1tfsummaryscalar67_154"></a>1、tf.summary.scalar6+\7</h4> 
  <p>用来显示标量信息，其格式为：</p> 
  <pre><code class="prism language-python">tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span>tags<span class="token punctuation">,</span> values<span class="token punctuation">,</span> collections<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre> 
  <p>例如：tf.summary.scalar(‘mean’, mean)</p> 
  <p>一般在画<strong>loss,accuary</strong>时会用到这个函数。</p> 
  <h4><a id="2tfsummaryhistogram_166"></a>2、tf.summary.histogram</h4> 
  <p>用来显示直方图信息，其格式为：</p> 
  <pre><code class="prism language-python">tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>histogram<span class="token punctuation">(</span>tags<span class="token punctuation">,</span> values<span class="token punctuation">,</span> collections<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span> 
</code></pre> 
  <p>例如： tf.summary.histogram(‘histogram’, var)</p> 
  <p>一般用来显示训练过程中变量的分布情况</p> 
  <h4><a id="3tfsummarydistribution_178"></a>3、tf.summary.distribution</h4> 
  <p>分布图，一般用于显示weights分布</p> 
  <h4><a id="4tfsummarytext_182"></a>4、tf.summary.text</h4> 
  <p>可以将文本类型的数据转换为tensor写入summary中：</p> 
  <p>例如：</p> 
  <pre><code class="prism language-python">text <span class="token operator">=</span> <span class="token triple-quoted-string string">"""/a/b/c\\_d/f\\_g\\_h\\_2017"""</span>
summary_op0 <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>text<span class="token punctuation">(</span><span class="token string">'text'</span><span class="token punctuation">,</span> tf<span class="token punctuation">.</span>convert_to_tensor<span class="token punctuation">(</span>text<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> 
  <h4><a id="5tfsummaryimage_193"></a>5、tf.summary.image</h4> 
  <p>输出带图像的probuf，汇总数据的图像的的形式如下： ’ tag /image/0’, ’ tag /image/1’…，如：input/image/0等。</p> 
  <p>格式：tf.summary.image(tag, tensor, max_images=3, collections=None, name=None)</p> 
  <h4><a id="6tfsummaryaudio_199"></a>6、tf.summary.audio</h4> 
  <p>展示训练过程中记录的音频</p> 
  <h4><a id="7tfsummarymerge_all_203"></a>7、tf.summary.merge_all</h4> 
  <p>merge_all 可以将所有summary全部保存到磁盘，以便tensorboard显示。如果没有特殊要求，一般用这一句就可一显示训练时的各种信息了。</p> 
  <p>格式：tf.summaries.merge_all(key=‘summaries’)</p> 
  <h4><a id="8tfsummaryFileWriter_209"></a>8、tf.summary.FileWriter</h4> 
  <p>指定一个文件用来保存图。</p> 
  <p>格式：tf.summary.FileWritter(path,sess.graph)</p> 
  <p>可以调用其add_summary（）方法将训练过程数据保存在filewriter指定的文件中</p> 
  <p>Tensorflow Summary 用法示例:</p> 
  <pre><code class="prism language-python">tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">,</span>acc<span class="token punctuation">)</span>                   <span class="token comment">#生成准确率标量图 </span>
merge_summary <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>merge_all<span class="token punctuation">(</span><span class="token punctuation">)</span>  
train_writer <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>FileWriter<span class="token punctuation">(</span><span class="token builtin">dir</span><span class="token punctuation">,</span>sess<span class="token punctuation">.</span>graph<span class="token punctuation">)</span><span class="token comment">#定义一个写入summary的目标文件，dir为写入文件地址 </span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">(</span>交叉熵、优化器等定义<span class="token punctuation">)</span>  
<span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">xrange</span><span class="token punctuation">(</span>training_step<span class="token punctuation">)</span><span class="token punctuation">:</span>                  <span class="token comment">#训练循环 </span>
    train_summary <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>merge_summary<span class="token punctuation">,</span>feed_dict <span class="token operator">=</span>  <span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token comment">#调用sess.run运行图，生成一步的训练过程数据 </span>
    train_writer<span class="token punctuation">.</span>add_summary<span class="token punctuation">(</span>train_summary<span class="token punctuation">,</span>step<span class="token punctuation">)</span><span class="token comment">#调用train_writer的add_summary方法将训练过程以及训练步数保存 </span>
</code></pre> 
  <p>此时开启tensorborad：</p> 
  <ol> 
   <li>tensorboard --logdir=/summary_dir</li> 
  </ol> 
  <p>便能看见accuracy曲线了。</p> 
  <p>另外，如果我不想保存所有定义的summary信息，也可以用tf.summary.merge方法有选择性地保存信息：</p> 
  <h4><a id="9tfsummarymerge_237"></a>9、tf.summary.merge</h4> 
  <p>格式：tf.summary.merge(inputs, collections=None, name=None)</p> 
  <p>一般选择要保存的信息还需要用到tf.get_collection()函数</p> 
  <p>示例：</p> 
  <pre><code class="prism language-python">tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">,</span>acc<span class="token punctuation">)</span>                   <span class="token comment">#生成准确率标量图 </span>
merge_summary <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>merge<span class="token punctuation">(</span><span class="token punctuation">[</span>tf<span class="token punctuation">.</span>get_collection<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>GraphKeys<span class="token punctuation">.</span>SUMMARIES<span class="token punctuation">,</span><span class="token string">'accuracy'</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">(</span>其他要显示的信息<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  
train_writer <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>FileWriter<span class="token punctuation">(</span><span class="token builtin">dir</span><span class="token punctuation">,</span>sess<span class="token punctuation">.</span>graph<span class="token punctuation">)</span><span class="token comment">#定义一个写入summary的目标文件，dir为写入文件地址 </span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">(</span>交叉熵、优化器等定义<span class="token punctuation">)</span>  
<span class="token keyword">for</span> step <span class="token keyword">in</span> <span class="token builtin">xrange</span><span class="token punctuation">(</span>training_step<span class="token punctuation">)</span><span class="token punctuation">:</span>                  <span class="token comment">#训练循环 </span>
    train_summary <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>merge_summary<span class="token punctuation">,</span>feed_dict <span class="token operator">=</span>  <span class="token punctuation">{</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token comment">#调用sess.run运行图，生成一步的训练过程数据 </span>
    train_writer<span class="token punctuation">.</span>add_summary<span class="token punctuation">(</span>train_summary<span class="token punctuation">,</span>step<span class="token punctuation">)</span><span class="token comment">#调用train_writer的add_summary方法将训练过程以及训练步数保存 </span>
</code></pre> 
  <p>使用tf.get_collection函数筛选图中summary信息中的accuracy信息，这里的</p> 
  <p>tf.GraphKeys.SUMMARIES 是summary在collection中的标志。</p> 
  <p>当然，也可以直接：</p> 
  <pre><code class="prism language-python">acc_summary <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">'accuracy'</span><span class="token punctuation">,</span>acc<span class="token punctuation">)</span>                   <span class="token comment">#生成准确率标量图 </span>
merge_summary <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>merge<span class="token punctuation">(</span><span class="token punctuation">[</span>acc_summary <span class="token punctuation">,</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">(</span>其他要显示的信息<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>  <span class="token comment">#这里的[]不可省</span>
</code></pre> 
  <p>如果要在tensorboard中画多个数据图，需定义多个tf.summary.FileWriter并重复上述过程</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
