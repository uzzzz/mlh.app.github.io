<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>图像降维之MDS特征抽取方法 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="图像降维之MDS特征抽取方法" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：本文为博主原创文章，更多精彩文章请关注公众号【Jeemy110】 https://blog.csdn.net/l7H9JA4/article/details/89117504 &nbsp; &nbsp;作者：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 编辑：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 前 &nbsp;言 MDS，中文名叫“多维缩放”，是一种经典的降维方法，同时也是数据可视化的一种手段。最早起源于当我们仅能获得物体之间的相似性矩阵时，如何由此来重构它们的欧几里得坐标，如对一个国家的许多城市而言，假如我们不知道它们的经纬度信息，却知道所有城市两两之间的距离，就可以通过MDS方法重现它们的空间信息。MDS的基本思想很简单，要求原始空间中样本之间的距离在低维空间中得到保持。下面我们将对MDS的原理进行学习。章节目录 准备知识 算法推导 算法步骤 实验 总结 01 准备知识 实对称矩阵的特征分解性质 任意的对称矩阵都有N个线性无关的特征向量，并且可以正交单位化。实对称矩阵A可被分解成： 其中Q为正交矩阵，为实对角矩阵。 02 算法推导 给定m个样本的距离矩阵，其中第i行第j列的元素为样本到的距离。目标是获得低维表示，其中，且保持任意两个样本在维空间的欧氏距离不变。 从已知的条件中，我们唯一能够得到降维后的样本与未降维前的样本之间的关系如下(1)式： 为了更清晰地观察、与的关系，将(1)式左边平方，得(2)式： 从(2)式可以看出，与、各自的模以及内积有关，为了能够统一表示这种关系，这里引入内积矩阵，其中，(2)式变换成(3)式： 显然，我们接下来的目标是得到B中任一元素的解析解。在不影响结果正确性的前提下，为了方便后续计算，令降维后的样本Z被中心化，即，可以得到，同理。则由(3)式可以得到式(4)(5)(6)： 同理， 其中表示矩阵的迹(trace)。 由(4)(5)(6)式得，，，。 为了表述清晰，令 联合(3)和(4)(9)式，得(10)式： 至此，已得到B和D的全部关系。接下来便是由B得到最终目标Z。 首先，我们可以判断出B是实对称矩阵，由实对称矩阵性质可知，，其中为特征值构成的对角矩阵，，V是特征向量矩阵。 一般降维任务总是取作为目标维度，所以取d&#39;个最大特征值构成对角矩阵，对应的特征向量矩阵为，则 03 算法步骤 输入：距离矩阵，其元素为样本到的距离；低维空间维数。 过程： 1: 根据(7)(9)式计算，，； 2: 根据(10)式计算内积矩阵B； 3: 对B做特征值分解； 4: 取为个最大特征值所构成的对角矩阵，为相应的特征向量矩阵。 输出： 04 实验 实验代码 &quot;&quot;&quot;MDS&nbsp;:&nbsp;Multi-dimensional&nbsp;ScalingRefercences&nbsp;:[1]周志华.机器学习[M].清华大学出版社,2016:425.[2]http://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.manifold.MDS.htmlAuthor&nbsp;:&nbsp;GgmatchDate&nbsp;:&nbsp;2019/4/7&quot;&quot;&quot;from&nbsp;time&nbsp;import&nbsp;timeimport&nbsp;matplotlib.pyplot&nbsp;as&nbsp;pltfrom&nbsp;mpl_toolkits.mplot3d&nbsp;import&nbsp;Axes3Dfrom&nbsp;matplotlib.ticker&nbsp;import&nbsp;NullFormatterfrom&nbsp;sklearn&nbsp;import&nbsp;manifold,&nbsp;datasets#&nbsp;制造样本n_points&nbsp;=&nbsp;1000X,&nbsp;color&nbsp;=&nbsp;datasets.samples_generator.make_s_curve(n_points,&nbsp;random_state=0)n_neighbors&nbsp;=&nbsp;10fig&nbsp;=&nbsp;plt.figure(figsize=(5,&nbsp;5))&nbsp;&nbsp;#画板gs&nbsp;=&nbsp;fig.add_gridspec(1,2)&nbsp;&nbsp;#共2副子图ax1&nbsp;=&nbsp;fig.add_subplot(gs[0,0],&nbsp;projection=&#39;3d&#39;)&nbsp;&nbsp;#第一幅子图表示原始样本分布ax1.scatter(X[:,&nbsp;0],&nbsp;X[:,&nbsp;1],&nbsp;X[:,&nbsp;2],&nbsp;c=color,&nbsp;cmap=plt.cm.Spectral)#&nbsp;MDS降维n_components&nbsp;=&nbsp;2t0&nbsp;=&nbsp;time()&nbsp;&nbsp;#计时开始mds&nbsp;=&nbsp;manifold.MDS(n_components,&nbsp;max_iter=100,&nbsp;n_init=1)&nbsp;&nbsp;#建立MDS模型Y&nbsp;=&nbsp;mds.fit_transform(X)t1&nbsp;=&nbsp;time()&nbsp;&nbsp;#计时结束ax2&nbsp;=&nbsp;fig.add_subplot(gs[0,1])ax2.scatter(Y[:,&nbsp;0],&nbsp;Y[:,&nbsp;1],&nbsp;c=color,&nbsp;cmap=plt.cm.Spectral)&nbsp;&nbsp;#第2副子图表示降维后样本分布ax2.set_title(&quot;MDS&nbsp;(%.2g&nbsp;sec)&quot;&nbsp;%&nbsp;(t1&nbsp;-&nbsp;t0))ax2.xaxis.set_major_formatter(NullFormatter())ax2.yaxis.set_major_formatter(NullFormatter())plt.show() 实验效果 05 总结 1）高维空间中对两个样本用欧式距离求直线距离，很多时候并不可取（如实验案例取得是流形空间），两点之间应该用“测地线”距离。改进算法为Isomap(Isomatric Mapping)。 2）MDS其实分为Metric MDS与Non-Metric MDS，本文讲述的是Metric MDS，通过样本之间的欧氏距离来近似代表相似度的思路，而Non-Metric MDS是通过点与点之间距离的单调映射来近似原有的距离。实际应用中，样本之间的距离越近，相似度越大，反之亦然。 References: [1]https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3/12522621?fr=aladdin [2]周志华.机器学习[M].清华大学出版社,2016:425. [3]http://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.manifold.MDS.html [4]Cox, T.F., Cox, M.A.A. (2001). Multidimensional Scaling. Chapman and Hall. [5]http://blog.sina.com.cn/s/blog_501162be0102v37l.html &nbsp; END 机器学习算法工程师 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一个用心的公众号 长按，识别，加关注 进群，学习，得帮助 你的关注，我们的热度， 我们一定给你学习最大的帮助" />
<meta property="og:description" content="版权声明：本文为博主原创文章，更多精彩文章请关注公众号【Jeemy110】 https://blog.csdn.net/l7H9JA4/article/details/89117504 &nbsp; &nbsp;作者：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 编辑：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 前 &nbsp;言 MDS，中文名叫“多维缩放”，是一种经典的降维方法，同时也是数据可视化的一种手段。最早起源于当我们仅能获得物体之间的相似性矩阵时，如何由此来重构它们的欧几里得坐标，如对一个国家的许多城市而言，假如我们不知道它们的经纬度信息，却知道所有城市两两之间的距离，就可以通过MDS方法重现它们的空间信息。MDS的基本思想很简单，要求原始空间中样本之间的距离在低维空间中得到保持。下面我们将对MDS的原理进行学习。章节目录 准备知识 算法推导 算法步骤 实验 总结 01 准备知识 实对称矩阵的特征分解性质 任意的对称矩阵都有N个线性无关的特征向量，并且可以正交单位化。实对称矩阵A可被分解成： 其中Q为正交矩阵，为实对角矩阵。 02 算法推导 给定m个样本的距离矩阵，其中第i行第j列的元素为样本到的距离。目标是获得低维表示，其中，且保持任意两个样本在维空间的欧氏距离不变。 从已知的条件中，我们唯一能够得到降维后的样本与未降维前的样本之间的关系如下(1)式： 为了更清晰地观察、与的关系，将(1)式左边平方，得(2)式： 从(2)式可以看出，与、各自的模以及内积有关，为了能够统一表示这种关系，这里引入内积矩阵，其中，(2)式变换成(3)式： 显然，我们接下来的目标是得到B中任一元素的解析解。在不影响结果正确性的前提下，为了方便后续计算，令降维后的样本Z被中心化，即，可以得到，同理。则由(3)式可以得到式(4)(5)(6)： 同理， 其中表示矩阵的迹(trace)。 由(4)(5)(6)式得，，，。 为了表述清晰，令 联合(3)和(4)(9)式，得(10)式： 至此，已得到B和D的全部关系。接下来便是由B得到最终目标Z。 首先，我们可以判断出B是实对称矩阵，由实对称矩阵性质可知，，其中为特征值构成的对角矩阵，，V是特征向量矩阵。 一般降维任务总是取作为目标维度，所以取d&#39;个最大特征值构成对角矩阵，对应的特征向量矩阵为，则 03 算法步骤 输入：距离矩阵，其元素为样本到的距离；低维空间维数。 过程： 1: 根据(7)(9)式计算，，； 2: 根据(10)式计算内积矩阵B； 3: 对B做特征值分解； 4: 取为个最大特征值所构成的对角矩阵，为相应的特征向量矩阵。 输出： 04 实验 实验代码 &quot;&quot;&quot;MDS&nbsp;:&nbsp;Multi-dimensional&nbsp;ScalingRefercences&nbsp;:[1]周志华.机器学习[M].清华大学出版社,2016:425.[2]http://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.manifold.MDS.htmlAuthor&nbsp;:&nbsp;GgmatchDate&nbsp;:&nbsp;2019/4/7&quot;&quot;&quot;from&nbsp;time&nbsp;import&nbsp;timeimport&nbsp;matplotlib.pyplot&nbsp;as&nbsp;pltfrom&nbsp;mpl_toolkits.mplot3d&nbsp;import&nbsp;Axes3Dfrom&nbsp;matplotlib.ticker&nbsp;import&nbsp;NullFormatterfrom&nbsp;sklearn&nbsp;import&nbsp;manifold,&nbsp;datasets#&nbsp;制造样本n_points&nbsp;=&nbsp;1000X,&nbsp;color&nbsp;=&nbsp;datasets.samples_generator.make_s_curve(n_points,&nbsp;random_state=0)n_neighbors&nbsp;=&nbsp;10fig&nbsp;=&nbsp;plt.figure(figsize=(5,&nbsp;5))&nbsp;&nbsp;#画板gs&nbsp;=&nbsp;fig.add_gridspec(1,2)&nbsp;&nbsp;#共2副子图ax1&nbsp;=&nbsp;fig.add_subplot(gs[0,0],&nbsp;projection=&#39;3d&#39;)&nbsp;&nbsp;#第一幅子图表示原始样本分布ax1.scatter(X[:,&nbsp;0],&nbsp;X[:,&nbsp;1],&nbsp;X[:,&nbsp;2],&nbsp;c=color,&nbsp;cmap=plt.cm.Spectral)#&nbsp;MDS降维n_components&nbsp;=&nbsp;2t0&nbsp;=&nbsp;time()&nbsp;&nbsp;#计时开始mds&nbsp;=&nbsp;manifold.MDS(n_components,&nbsp;max_iter=100,&nbsp;n_init=1)&nbsp;&nbsp;#建立MDS模型Y&nbsp;=&nbsp;mds.fit_transform(X)t1&nbsp;=&nbsp;time()&nbsp;&nbsp;#计时结束ax2&nbsp;=&nbsp;fig.add_subplot(gs[0,1])ax2.scatter(Y[:,&nbsp;0],&nbsp;Y[:,&nbsp;1],&nbsp;c=color,&nbsp;cmap=plt.cm.Spectral)&nbsp;&nbsp;#第2副子图表示降维后样本分布ax2.set_title(&quot;MDS&nbsp;(%.2g&nbsp;sec)&quot;&nbsp;%&nbsp;(t1&nbsp;-&nbsp;t0))ax2.xaxis.set_major_formatter(NullFormatter())ax2.yaxis.set_major_formatter(NullFormatter())plt.show() 实验效果 05 总结 1）高维空间中对两个样本用欧式距离求直线距离，很多时候并不可取（如实验案例取得是流形空间），两点之间应该用“测地线”距离。改进算法为Isomap(Isomatric Mapping)。 2）MDS其实分为Metric MDS与Non-Metric MDS，本文讲述的是Metric MDS，通过样本之间的欧氏距离来近似代表相似度的思路，而Non-Metric MDS是通过点与点之间距离的单调映射来近似原有的距离。实际应用中，样本之间的距离越近，相似度越大，反之亦然。 References: [1]https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3/12522621?fr=aladdin [2]周志华.机器学习[M].清华大学出版社,2016:425. [3]http://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.manifold.MDS.html [4]Cox, T.F., Cox, M.A.A. (2001). Multidimensional Scaling. Chapman and Hall. [5]http://blog.sina.com.cn/s/blog_501162be0102v37l.html &nbsp; END 机器学习算法工程师 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一个用心的公众号 长按，识别，加关注 进群，学习，得帮助 你的关注，我们的热度， 我们一定给你学习最大的帮助" />
<link rel="canonical" href="https://mlh.app/2019/04/08/728216.html" />
<meta property="og:url" content="https://mlh.app/2019/04/08/728216.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-08T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：本文为博主原创文章，更多精彩文章请关注公众号【Jeemy110】 https://blog.csdn.net/l7H9JA4/article/details/89117504 &nbsp; &nbsp;作者：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 编辑：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 前 &nbsp;言 MDS，中文名叫“多维缩放”，是一种经典的降维方法，同时也是数据可视化的一种手段。最早起源于当我们仅能获得物体之间的相似性矩阵时，如何由此来重构它们的欧几里得坐标，如对一个国家的许多城市而言，假如我们不知道它们的经纬度信息，却知道所有城市两两之间的距离，就可以通过MDS方法重现它们的空间信息。MDS的基本思想很简单，要求原始空间中样本之间的距离在低维空间中得到保持。下面我们将对MDS的原理进行学习。章节目录 准备知识 算法推导 算法步骤 实验 总结 01 准备知识 实对称矩阵的特征分解性质 任意的对称矩阵都有N个线性无关的特征向量，并且可以正交单位化。实对称矩阵A可被分解成： 其中Q为正交矩阵，为实对角矩阵。 02 算法推导 给定m个样本的距离矩阵，其中第i行第j列的元素为样本到的距离。目标是获得低维表示，其中，且保持任意两个样本在维空间的欧氏距离不变。 从已知的条件中，我们唯一能够得到降维后的样本与未降维前的样本之间的关系如下(1)式： 为了更清晰地观察、与的关系，将(1)式左边平方，得(2)式： 从(2)式可以看出，与、各自的模以及内积有关，为了能够统一表示这种关系，这里引入内积矩阵，其中，(2)式变换成(3)式： 显然，我们接下来的目标是得到B中任一元素的解析解。在不影响结果正确性的前提下，为了方便后续计算，令降维后的样本Z被中心化，即，可以得到，同理。则由(3)式可以得到式(4)(5)(6)： 同理， 其中表示矩阵的迹(trace)。 由(4)(5)(6)式得，，，。 为了表述清晰，令 联合(3)和(4)(9)式，得(10)式： 至此，已得到B和D的全部关系。接下来便是由B得到最终目标Z。 首先，我们可以判断出B是实对称矩阵，由实对称矩阵性质可知，，其中为特征值构成的对角矩阵，，V是特征向量矩阵。 一般降维任务总是取作为目标维度，所以取d&#39;个最大特征值构成对角矩阵，对应的特征向量矩阵为，则 03 算法步骤 输入：距离矩阵，其元素为样本到的距离；低维空间维数。 过程： 1: 根据(7)(9)式计算，，； 2: 根据(10)式计算内积矩阵B； 3: 对B做特征值分解； 4: 取为个最大特征值所构成的对角矩阵，为相应的特征向量矩阵。 输出： 04 实验 实验代码 &quot;&quot;&quot;MDS&nbsp;:&nbsp;Multi-dimensional&nbsp;ScalingRefercences&nbsp;:[1]周志华.机器学习[M].清华大学出版社,2016:425.[2]http://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.manifold.MDS.htmlAuthor&nbsp;:&nbsp;GgmatchDate&nbsp;:&nbsp;2019/4/7&quot;&quot;&quot;from&nbsp;time&nbsp;import&nbsp;timeimport&nbsp;matplotlib.pyplot&nbsp;as&nbsp;pltfrom&nbsp;mpl_toolkits.mplot3d&nbsp;import&nbsp;Axes3Dfrom&nbsp;matplotlib.ticker&nbsp;import&nbsp;NullFormatterfrom&nbsp;sklearn&nbsp;import&nbsp;manifold,&nbsp;datasets#&nbsp;制造样本n_points&nbsp;=&nbsp;1000X,&nbsp;color&nbsp;=&nbsp;datasets.samples_generator.make_s_curve(n_points,&nbsp;random_state=0)n_neighbors&nbsp;=&nbsp;10fig&nbsp;=&nbsp;plt.figure(figsize=(5,&nbsp;5))&nbsp;&nbsp;#画板gs&nbsp;=&nbsp;fig.add_gridspec(1,2)&nbsp;&nbsp;#共2副子图ax1&nbsp;=&nbsp;fig.add_subplot(gs[0,0],&nbsp;projection=&#39;3d&#39;)&nbsp;&nbsp;#第一幅子图表示原始样本分布ax1.scatter(X[:,&nbsp;0],&nbsp;X[:,&nbsp;1],&nbsp;X[:,&nbsp;2],&nbsp;c=color,&nbsp;cmap=plt.cm.Spectral)#&nbsp;MDS降维n_components&nbsp;=&nbsp;2t0&nbsp;=&nbsp;time()&nbsp;&nbsp;#计时开始mds&nbsp;=&nbsp;manifold.MDS(n_components,&nbsp;max_iter=100,&nbsp;n_init=1)&nbsp;&nbsp;#建立MDS模型Y&nbsp;=&nbsp;mds.fit_transform(X)t1&nbsp;=&nbsp;time()&nbsp;&nbsp;#计时结束ax2&nbsp;=&nbsp;fig.add_subplot(gs[0,1])ax2.scatter(Y[:,&nbsp;0],&nbsp;Y[:,&nbsp;1],&nbsp;c=color,&nbsp;cmap=plt.cm.Spectral)&nbsp;&nbsp;#第2副子图表示降维后样本分布ax2.set_title(&quot;MDS&nbsp;(%.2g&nbsp;sec)&quot;&nbsp;%&nbsp;(t1&nbsp;-&nbsp;t0))ax2.xaxis.set_major_formatter(NullFormatter())ax2.yaxis.set_major_formatter(NullFormatter())plt.show() 实验效果 05 总结 1）高维空间中对两个样本用欧式距离求直线距离，很多时候并不可取（如实验案例取得是流形空间），两点之间应该用“测地线”距离。改进算法为Isomap(Isomatric Mapping)。 2）MDS其实分为Metric MDS与Non-Metric MDS，本文讲述的是Metric MDS，通过样本之间的欧氏距离来近似代表相似度的思路，而Non-Metric MDS是通过点与点之间距离的单调映射来近似原有的距离。实际应用中，样本之间的距离越近，相似度越大，反之亦然。 References: [1]https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3/12522621?fr=aladdin [2]周志华.机器学习[M].清华大学出版社,2016:425. [3]http://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.manifold.MDS.html [4]Cox, T.F., Cox, M.A.A. (2001). Multidimensional Scaling. Chapman and Hall. [5]http://blog.sina.com.cn/s/blog_501162be0102v37l.html &nbsp; END 机器学习算法工程师 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一个用心的公众号 长按，识别，加关注 进群，学习，得帮助 你的关注，我们的热度， 我们一定给你学习最大的帮助","@type":"BlogPosting","url":"https://mlh.app/2019/04/08/728216.html","headline":"图像降维之MDS特征抽取方法","dateModified":"2019-04-08T00:00:00+08:00","datePublished":"2019-04-08T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/04/08/728216.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>图像降维之MDS特征抽取方法</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright"> 
  <svg class="icon" title="CSDN认证原创" aria-hidden="true" style="width:53px; height: 18px; vertical-align: -4px;"> 
   <use xlink:href="#CSDN_Cert"></use> 
  </svg> 版权声明：本文为博主原创文章，更多精彩文章请关注公众号【Jeemy110】 https://blog.csdn.net/l7H9JA4/article/details/89117504 
 </div> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <div class="rich_media_content" id="js_content"> 
   <p style="color:rgb(108,105,105);font-size:14px;text-align:right;">&nbsp; &nbsp;作者：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<br></p>
   <p style="color:rgb(108,105,105);font-size:14px;text-align:right;"><span style="color:rgb(89,89,89);">编辑：龚赛&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<br></span></p>
   <p><span style="color:rgb(89,89,89);"><br></span></p>
   <p><strong class="135brush">前 &nbsp;言</strong></p>
   <p style="font-size:16px;border-width:0px;border-style:none;text-align:justify;line-height:1.5em;">MDS，中文名叫“多维缩放”，是一种经典的降维方法，同时也是数据可视化的一种手段。最早起源于当我们仅能获得物体之间的相似性矩阵时，如何由此来重构它们的欧几里得坐标，如对一个国家的许多城市而言，假如我们不知道它们的经纬度信息，却知道所有城市两两之间的距离，就可以通过MDS方法重现它们的空间信息。MDS的基本思想很简单，要求原始空间中样本之间的距离在低维空间中得到保持。下面我们将对MDS的原理进行学习。<br><br><strong>章节目录<br><br></strong></p>
   <ul class="list-paddingleft-2">
    <li><p>准备知识</p></li>
    <li><p>算法推导</p></li>
    <li><p>算法步骤</p></li>
    <li><p>实验</p></li>
    <li><p>总结</p></li>
   </ul>
   <p><br></p>
   <p style="min-height:1em;"><strong>01</strong></p>
   <h1 style="letter-spacing:1.5px;line-height:1.75em;text-align:center;"><span style="color:rgb(0,122,170);"><strong><span style="font-size:15px;">准备知识</span></strong></span></h1>
   <p style="line-height:1.5em;"><span style="font-size:15px;color:rgb(68,68,68);"></span><strong>实对称矩阵的特征分解性质</strong></p>
   <p style="line-height:1.5em;">任意的<img class="rich_pages" style="text-align:center;width:64px;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9iaLCBUHOT6niaKDLlflFmAGakpH2Onu1uXBosAsTPKF93drExr9gOib3A/640?wx_fmt=png" alt="640?wx_fmt=png">对称矩阵都有N个线性无关的特征向量，并且可以正交单位化。实对称矩阵A可被分解成：</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9icEicr6fFQBWQlsP05KrFxVqokeFicKuttkSw2nWxgw50BrGg7yaQKgbQ/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">其中Q为正交矩阵，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY95iaFwQpmP72Ue21rDy6mnQEiaE6tqiaCOLB0E7I1LGnibicd0D3DGFc0k8Q/640?wx_fmt=png" alt="640?wx_fmt=png">为实对角矩阵。</p>
   <p><br></p>
   <p style="min-height:1em;"><strong>02</strong></p>
   <h1 style="letter-spacing:1.5px;line-height:1.75em;text-align:center;"><span style="color:rgb(0,122,170);"><strong><span style="font-size:15px;">算法推导</span></strong></span></h1>
   <p style="line-height:1.5em;">给定m个样本<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9wWCJNH4vhXd3lBGQmlSbCUZVHqMUBnUdOHrAB5AMvqjNI760VoB7KQ/640?wx_fmt=png" alt="640?wx_fmt=png">的距离矩阵<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9ZLosMLyEKKicZgP81cdGGlAklg9bj37ISFFLjPnTLG2zVkicgTdcTcMg/640?wx_fmt=png" alt="640?wx_fmt=png">，其中第i行第j列的元素<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY91nXd0flzOTu2Hjyy7nFOznIfg7dmSV6CaSnibkQPaQJkPpbD3aFOibGA/640?wx_fmt=png" alt="640?wx_fmt=png">为样本<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9PGd22l25Ko2x77Osn5M0m3rwPETU8rjrtibib7WvCKiamicdkhXt2wEyqA/640?wx_fmt=png" alt="640?wx_fmt=png">到<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY97jHQymSFgLVr7fyOfibx3NSBa2GO6gOeavhicufUN5k9wjMKOENeXUMA/640?wx_fmt=png" alt="640?wx_fmt=png">的距离。目标是获得低维表示<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY94DPmBdmjMVHrdicJeoefxYnRLtp0qFx6x5icTzU95ibHaSAiaTNSsa18ww/640?wx_fmt=png" alt="640?wx_fmt=png">，其中<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9icRY5Kx9roJHibsdNIyEqpqCjObjMt2RqP2sP0d6uDmyPtHJnTgeZstA/640?wx_fmt=png" alt="640?wx_fmt=png">，且保持任意两个样本在<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9Y7ZENWu45CnRicAgmF17vLx6gLKoT7wUjbKF1Jyfibr0EEBV2MOHEnGg/640?wx_fmt=png" alt="640?wx_fmt=png">维空间的欧氏距离不变。</p>
   <p style="line-height:1.5em;">从已知的条件中，我们唯一能够得到降维后的样本与未降维前的样本之间的关系如下(1)式：</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9MAfMAJlic2EswCD89ap3C5an0a2bc6Po7biaGWHwgsoicDKM5X6ZiaibGnA/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">为了更清晰地观察<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9fYaHPDKyLQOv4po6uARDjFHX2sxmSGnqhNa1getXv3Jia2AL6EjAMQA/640?wx_fmt=png" alt="640?wx_fmt=png">、<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY94OmKzonOC7ewnCORGKa2csuciaF1icE2Y0HfI3IuAp3HBv9ZojEgDDXw/640?wx_fmt=png" alt="640?wx_fmt=png">与<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9U5UiahBDpwFSEM0FYhqbCP93aHhkKNtgJeELyqeoresacziaqA0bJLbA/640?wx_fmt=png" alt="640?wx_fmt=png">的关系，将(1)式左边平方，得(2)式：</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9cyVa7TgN6zONuqwZq3Oiahbg73ColIVX6vhtgpYialVjf5pbrY4w54qg/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">从(2)式可以看出，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9aMh7wUDqMib8Osrv1JJZVriarVicQa7NDeibiaj4dW91zkLasXPPRZwM9Lw/640?wx_fmt=png" alt="640?wx_fmt=png">与<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9fYaHPDKyLQOv4po6uARDjFHX2sxmSGnqhNa1getXv3Jia2AL6EjAMQA/640?wx_fmt=png" alt="640?wx_fmt=png">、<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY94OmKzonOC7ewnCORGKa2csuciaF1icE2Y0HfI3IuAp3HBv9ZojEgDDXw/640?wx_fmt=png" alt="640?wx_fmt=png">各自的模以及内积有关，为了能够统一表示这种关系，这里引入内积矩阵<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9eicq1cObTcEwnBWAfdltQvXraETLicO08vtaDw061xicZrPbDqfEWAIUg/640?wx_fmt=png" alt="640?wx_fmt=png">，其中<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY98zHSTibzicnGSzCLpKHRHnY8GicAUUCThdcI5nGqHhZGuWP2kAyo4icpKQ/640?wx_fmt=png" alt="640?wx_fmt=png">，(2)式变换成(3)式：</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9ACic60QR5Xwr1tDibxEiaTdA2Ko3gRg7Ln8P4HfIic1lXML8icZlJZBJv3g/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">显然，我们接下来的目标是得到B中任一元素<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9QsPRMBTTyNCmiajXYaajqKGXFVOTyPboQ6gJ7xJPibib0alNIZictUuviaQ/640?wx_fmt=png" alt="640?wx_fmt=png"><span style="text-align:center;"></span>的解析解。在不影响结果正确性的前提下，为了方便后续计算，令降维后的样本Z被中心化，即<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9vS9sicL9PJhDiaA2s3lRF7WibtrJ7I0noAic2TMmfZTGlTPPyyCxAwVczw/640?wx_fmt=png" alt="640?wx_fmt=png">，可以得到<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9p8TvqDoBTtTGpJGM7G1RsL7B0FtOVM0XsZdJuBhZUVn1wFTdkoF0HA/640?wx_fmt=png" alt="640?wx_fmt=png">，同理<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY94uDbPGqBJTgic4dCVpOkm8GV66qfnjNialhtibu2y3YRlqllQm97Qs30w/640?wx_fmt=png" alt="640?wx_fmt=png">。则由(3)式可以得到式(4)(5)(6)：</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9zHCHptbI6icZMncexV8yaFhrUqCxxmibe3kJVf0TOPRvDq01NXsg4icZQ/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">同理，<br></p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY94wBRgYOc0POv6m93YJ3OChZIV8qcXRYwNaNqibgn8NRNXL9mWicTtbhg/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9fsSF3uSFf8qOkEzaOEq0zlAHLA7negrGzGfXGWmxBg9hiaQzk9FEgmw/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">其中<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9dIaahhwmRiafSnNMXlvNib325ibyoOibpTLYbLeR2nDpFf9Y1GP4b4fKiaA/640?wx_fmt=png" alt="640?wx_fmt=png">表示矩阵的迹(trace)。</p>
   <p style="line-height:1.5em;">由(4)(5)(6)式得，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9WHwLxxaY13r8m7rSVRichOx1JsxmCMm1nddRibSZUiawsJOcaqDUKtuwQ/640?wx_fmt=png" alt="640?wx_fmt=png">，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9amHPOg7sUdCGN334xLqw25vAeqZXlzaQnYbclk2QiaFZnvJIyVJstYw/640?wx_fmt=png" alt="640?wx_fmt=png">，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9NY3M5FjUj6CCyNj8cxt5mdAzWpasRsnuJ7A01fn7CBJxIKiaIXHfsvw/640?wx_fmt=png" alt="640?wx_fmt=png">。</p>
   <p style="line-height:1.5em;">为了表述清晰，令</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9jN8sMeCFThD8HjWwMibFjAalWjtnYkaca9T1vxjXSkQ7JazYhOR6UVg/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9fj93ibUiakv5sYV0BGoRsQ9iccGM5U3pBaTP3EVV3Sh0BE4rRTld5KWrA/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9MJia2DLwKKWDzyr8tibb0jfeJIsQj7AfNjnZbfE1w3Gbv8yUzHVBBFnA/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">联合(3)和(4)<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9SXFmrBvhqMLCQqqialkybib7iaPxyHlLUOIVfrsk3YH80hGYmVKwKt4zQ/640?wx_fmt=png" alt="640?wx_fmt=png">(9)式，得(10)式：</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9pGUhHOmhqJsQFczTtyL14kicW1B7iax3FNbC6kVLux3XriakXOoviaq40w/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">至此，已得到B和D的全部关系。接下来便是由B得到最终目标Z。<br></p>
   <p style="line-height:1.5em;">首先，我们可以判断出B是实对称矩阵，由实对称矩阵性质可知，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9LeaQQzI5sSn9SMOqiciaLhfujicU4frIj2TvFb7WCiaiatZM50AnZX2YKtw/640?wx_fmt=png" alt="640?wx_fmt=png">，其中<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9Ubc2rn2XqRiaSds72j7MkVVZe0DTsk7zobHvvgBVXdNLjNpmAl8GGLg/640?wx_fmt=png" alt="640?wx_fmt=png">为特征值构成的对角矩阵，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9uPfKNiaWGB6277j3x8x0L70iclANxMuHXiaAGmIXXbaxCI4S4aBJkXmAQ/640?wx_fmt=png" alt="640?wx_fmt=png">，V是特征向量矩阵。</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9tSp8NtrLFSbuyYBB2a1aKohgkKUBkTMxozrVRXb1ZiaMjCajgrYznUA/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9GlLWEna3IPMcspSGAm9CicniaPeTQVwQfibib6ia8nSh7NKV4vSJV7uE6iaw/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="line-height:1.5em;">一般降维任务总是取<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9uGcVelF8agjSfK9IG7VN01NNdSeU6W8U53N3FiaIjyyTd3BGd5RBnuQ/640?wx_fmt=png" alt="640?wx_fmt=png">作为目标维度，所以取d'个最大特征值构成对角矩阵<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9K21ouSYiae8ZGVjkSKsLHeO5icVOM45vGuseCJGfQ5cdTTKZ319Z6GEQ/640?wx_fmt=png" alt="640?wx_fmt=png">，对应的特征向量矩阵为<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9Yxw52Acf9CxpfU2uGqBnrh9vAVGqsm1IicbW6W41nFDXSKiavohTqE8A/640?wx_fmt=png" alt="640?wx_fmt=png">，则</p>
   <p style="text-align:center;line-height:1.5em;"><img class="rich_pages" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY99RfTZhzPMt9Rx4TAxRU2hRibnAM1cWsTFbunV1QcRqll5TRZrAn1ibibQ/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p><br></p>
   <p style="min-height:1em;"><strong>03</strong></p>
   <h1 style="letter-spacing:1.5px;line-height:1.75em;text-align:center;"><span style="color:rgb(0,122,170);"><strong><span style="font-size:15px;">算法步骤</span></strong></span></h1>
   <p style="line-height:1.5em;"><strong>输入</strong>：距离矩阵<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9lZibK8fhibqEFkDEiaxNr0bqjFWibgjbZ2fyDITkU67wxia7dytiaylzOhFA/640?wx_fmt=png" alt="640?wx_fmt=png">，其元素<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9lE6sdZ28PohWDYiblPuMXnUBuaibudbxw3icGOOSxYWrujrx9eUh6oVcA/640?wx_fmt=png" alt="640?wx_fmt=png">为样本<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9PmSky1e35JVWmib8GIN6BqgoiaMndYEryVEFIvRMHEiaTYMQqbTWckegQ/640?wx_fmt=png" alt="640?wx_fmt=png">到<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9bO9LPjcVmXr4PXBiaszeBMRg3DiaKScT2IboBFPrTMy738rIWQvv7bnA/640?wx_fmt=png" alt="640?wx_fmt=png">的距离；低维空间维数<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9BmMh2ZL9Of16KXhmmL0tNoUfIT2PECI3klXKmCJYHFia2QnmCBsqGBA/640?wx_fmt=png" alt="640?wx_fmt=png">。</p>
   <p style="line-height:1.5em;"><strong>过程</strong>：</p>
   <p style="line-height:1.5em;"><strong>1</strong>: 根据(7)<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9C3m5HJ8YqHnYhY8ibiaZOgK1J0geZ3dHaQ03m2WiaicynoWTTm7KnmDiblA/640?wx_fmt=png" alt="640?wx_fmt=png">(9)式计算<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9ibwYjK53bPiaStX3YeGFoUKIFq60kj4ZPdZcqGriaxh9WG5EYPnW4AQiaQ/640?wx_fmt=png" alt="640?wx_fmt=png">，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9VA2bxDtFbaoAibOHpgoQ4WK2hx93YtOGUzSBDt0ravNOBeZQudicXKgA/640?wx_fmt=png" alt="640?wx_fmt=png">，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9fQCYPTicHscGcUsJsxiaabD13Jcmu5C4oZUwF68smYl6hTujbTRUPknA/640?wx_fmt=png" alt="640?wx_fmt=png">；</p>
   <p style="line-height:1.5em;"><strong>2</strong>: 根据(10)式计算内积矩阵B；</p>
   <p style="line-height:1.5em;"><strong>3</strong>: 对B做特征值分解；</p>
   <p style="line-height:1.5em;"><strong>4</strong>: 取<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9fMvIJoTMSmPC4UGCdqaJnFJtTfkee5aOlaubuwJAibwbjf1bpJFms0A/640?wx_fmt=png" alt="640?wx_fmt=png">为<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9esOOBrkiajb0uCZO0yjicLZeibOTzcvNwaoZJjibSh0gZb1CMLjKQQgTMw/640?wx_fmt=png" alt="640?wx_fmt=png">个最大特征值所构成的对角矩阵，<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9icFD0CjgGBpdUhSpWAnYYTscL5sWibdplicxwic7UTd7EHPDqvVLcUGWVA/640?wx_fmt=png" alt="640?wx_fmt=png">为相应的特征向量矩阵。</p>
   <p style="line-height:1.5em;"><strong>输出</strong>：<img class="rich_pages" style="text-align:center;" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY9aLYSn0S9Wa269aF2xic554V9QYEU4xy1lQibULGYSEtJzE9v5pmDib4WA/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p><br></p>
   <p style="min-height:1em;"><strong>04</strong></p>
   <p style="min-height:1em;letter-spacing:1.5px;line-height:1.75em;text-align:center;"><span style="color:rgb(0,122,170);"><strong><span style="font-size:15px;">实验</span></strong></span></p>
   <p><strong>实验代码</strong></p>
   <pre style="font-size:inherit;color:inherit;line-height:inherit;"><code class="py language-py hljs python" style="margin-left:2px;line-height:18px;font-size:14px;letter-spacing:0px;font-family:Consolas, Inconsolata, Courier, monospace;color:rgb(169,183,198);background:rgb(40,43,46);"><span class="hljs-string" style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">"""<br>MDS&nbsp;:&nbsp;Multi-dimensional&nbsp;Scaling<br>Refercences&nbsp;:<br>[1]周志华.机器学习[M].清华大学出版社,2016:425.<br>[2]http://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.manifold.MDS.html<br><br>Author&nbsp;:&nbsp;Ggmatch<br>Date&nbsp;:&nbsp;2019/4/7<br>"""</span><br><span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">from</span>&nbsp;time&nbsp;<span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">import</span>&nbsp;time<br><br><span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">import</span>&nbsp;matplotlib.pyplot&nbsp;<span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">as</span>&nbsp;plt<br><span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">from</span>&nbsp;mpl_toolkits.mplot3d&nbsp;<span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">import</span>&nbsp;Axes3D<br><span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">from</span>&nbsp;matplotlib.ticker&nbsp;<span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">import</span>&nbsp;NullFormatter<br><br><span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">from</span>&nbsp;sklearn&nbsp;<span class="hljs-keyword" style="font-size:inherit;line-height:inherit;color:rgb(248,35,117);">import</span>&nbsp;manifold,&nbsp;datasets<br><br><span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#&nbsp;制造样本</span><br>n_points&nbsp;=&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">1000</span><br>X,&nbsp;color&nbsp;=&nbsp;datasets.samples_generator.make_s_curve(n_points,&nbsp;random_state=<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">0</span>)<br>n_neighbors&nbsp;=&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">10</span><br><br>fig&nbsp;=&nbsp;plt.figure(figsize=(<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">5</span>,&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">5</span>))&nbsp;&nbsp;<span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#画板</span><br>gs&nbsp;=&nbsp;fig.add_gridspec(<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">1</span>,<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">2</span>)&nbsp;&nbsp;<span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#共2副子图</span><br>ax1&nbsp;=&nbsp;fig.add_subplot(gs[<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">0</span>,<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">0</span>],&nbsp;projection=<span class="hljs-string" style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">'3d'</span>)&nbsp;&nbsp;<span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#第一幅子图表示原始样本分布</span><br>ax1.scatter(X[:,&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">0</span>],&nbsp;X[:,&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">1</span>],&nbsp;X[:,&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">2</span>],&nbsp;c=color,&nbsp;cmap=plt.cm.Spectral)<br><br><span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#&nbsp;MDS降维</span><br>n_components&nbsp;=&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">2</span><br><br>t0&nbsp;=&nbsp;time()&nbsp;&nbsp;<span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#计时开始</span><br>mds&nbsp;=&nbsp;manifold.MDS(n_components,&nbsp;max_iter=<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">100</span>,&nbsp;n_init=<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">1</span>)&nbsp;&nbsp;<span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#建立MDS模型</span><br>Y&nbsp;=&nbsp;mds.fit_transform(X)<br>t1&nbsp;=&nbsp;time()&nbsp;&nbsp;<span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#计时结束</span><br>ax2&nbsp;=&nbsp;fig.add_subplot(gs[<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">0</span>,<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">1</span>])<br>ax2.scatter(Y[:,&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">0</span>],&nbsp;Y[:,&nbsp;<span class="hljs-number" style="font-size:inherit;line-height:inherit;color:rgb(174,135,250);">1</span>],&nbsp;c=color,&nbsp;cmap=plt.cm.Spectral)&nbsp;&nbsp;<span class="hljs-comment" style="font-size:inherit;line-height:inherit;color:rgb(128,128,128);">#第2副子图表示降维后样本分布</span><br>ax2.set_title(<span class="hljs-string" style="font-size:inherit;line-height:inherit;color:rgb(238,220,112);">"MDS&nbsp;(%.2g&nbsp;sec)"</span>&nbsp;%&nbsp;(t1&nbsp;-&nbsp;t0))<br>ax2.xaxis.set_major_formatter(NullFormatter())<br>ax2.yaxis.set_major_formatter(NullFormatter())<br><br>plt.show()<br></code></pre>
   <p><br></p>
   <p><strong>实验效果</strong></p>
   <p style="text-align:center;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_png/iaTa8ut6HiawDSzV2OFzAhwMXyBkYsxeY903v83wOLMojxfVNOXjQibR9kRPGHobwUduLD7Lbr8vt0yWRL6DUspFA/640?wx_fmt=png" alt="640?wx_fmt=png"></p>
   <p style="text-align:left;"><br></p>
   <p style="min-height:1em;"><strong>05</strong></p>
   <p style="min-height:1em;line-height:1.75em;text-align:center;letter-spacing:1.5px;"><span style="color:rgb(0,122,170);"><strong><span style="font-size:15px;">总结</span></strong></span><span style="font-size:15px;color:rgb(68,68,68);"></span></p>
   <p><span style="font-size:15px;color:rgb(68,68,68);"></span></p>
   <p style="line-height:1.5em;">1）高维空间中对两个样本用欧式距离求直线距离，很多时候并不可取（如实验案例取得是流形空间），两点之间应该用“测地线”距离。改进算法为Isomap(Isomatric Mapping)。</p>
   <p style="line-height:1.5em;">2）MDS其实分为Metric MDS与Non-Metric MDS，本文讲述的是Metric MDS，通过样本之间的欧氏距离来近似代表相似度的思路，而Non-Metric MDS是通过点与点之间距离的单调映射来近似原有的距离。实际应用中，样本之间的距离越近，相似度越大，反之亦然。</p>
   <p><br></p>
   <p><br></p>
   <p><span style="font-size:17px;"><strong>References:</strong></span></p>
   <p>[1]https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E5%88%86%E8%A7%A3/12522621?fr=aladdin</p>
   <p>[2]周志华.机器学习[M].清华大学出版社,2016:425.</p>
   <p>[3]http://scikit-learn.sourceforge.net/dev/modules/generated/sklearn.manifold.MDS.html</p>
   <p>[4]Cox, T.F., Cox, M.A.A. (2001). Multidimensional Scaling. Chapman and Hall.</p>
   <p>[5]http://blog.sina.com.cn/s/blog_501162be0102v37l.html</p>
   <p style="min-height:1em;text-align:center;"><span style="font-size:15px;"></span><strong style="line-height:28px;"><span style="line-height:1.75em;font-size:15px;color:rgb(171,25,66);"><strong style="color:rgb(62,62,62);font-size:16px;line-height:28px;"><span style="line-height:1.75em;color:rgb(63,63,63);font-size:14px;letter-spacing:0px;text-align:justify;"></span></strong></span></strong></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <p style="min-height:1em;text-align:center;"><strong style="line-height:28px;"><span style="line-height:1.75em;font-size:15px;color:rgb(171,25,66);"><strong style="color:rgb(62,62,62);font-size:16px;line-height:28px;"><span style="line-height:1.75em;color:rgb(63,63,63);font-size:14px;letter-spacing:0px;text-align:justify;">&nbsp;</span></strong><span style="color:rgb(63,63,63);font-size:14px;letter-spacing:0px;text-align:justify;"><strong style="text-align:center;color:rgb(62,62,62);font-size:16px;line-height:28px;"><span style="line-height:1.75em;font-size:15px;color:rgb(171,25,66);"><img class="__bg_gif" src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_gif/TCHicQEF6XKANicUCsKbWsXv1yJgVCSSRGucMYaHPrsrDRFNbNUVibEic1qJC34XVssCm5k1NiaPULLZZOvuIWHn5eg/640?wx_fmt=gif" alt="640?wx_fmt=gif"></span></strong></span></span></strong></p>
   <p style="text-align:center;"><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong>END</strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p><span style="color:rgb(0,122,170);font-size:18px;letter-spacing:1.5px;"><strong><br></strong></span></p>
   <p style="min-height:1em;text-align:center;"><br></p>
   <br>
   <p><br></p>
   <p><br></p>
   <p><br></p>
   <p><br></p>
   <p><br></p>
   <p style="min-height:1em;"><span style="color:rgb(3,3,3);font-size:20px;"><strong>机器学习算法工程师</strong></span></p>
   <hr style="border-color:rgb(33,33,34);">
   <p style="min-height:1em;">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 一个用心的公众号</p>
   <p style="text-align:center;"><img src="https://ss.csdn.net/p?https://mmbiz.qpic.cn/mmbiz_jpg/iaTa8ut6HiawDdZMYspr4Sg6JgNEHRRRaZ7Bjjv4zo9GabzO4PkUILEGkyC7odlWMVEl6rsbfkr9PduYMbnQFZEA/640?wx_fmt=jpeg" alt="640?wx_fmt=jpeg"></p>
   <span style="color:rgb(12,12,12);">长按，识别，加关注<br></span>
   <p style="min-height:1em;"><span style="color:rgb(12,12,12);">进群，学习，得帮助</span></p>
   <p style="min-height:1em;"><span style="color:rgb(12,12,12);"></span>你的关注，我们的热度，</p>
   <p style="min-height:1em;">我们一定给你学习最大的帮助</p>
   <p style="clear:none;min-height:1em;"><br></p>
   <p><br></p>
   <p><br></p>
   <p><br></p> 
  </div> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
