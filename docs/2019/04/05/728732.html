<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>presto安装部署和连接hive使用 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="presto安装部署和连接hive使用" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="官网教程 https://prestodb.io/docs/current/installation.html&nbsp; http://prestodb-china.com/docs/current/installation/deployment.html （京东版本）&nbsp; https://teradata.github.io/presto/docs/current/overview.html （teradata版本） 环境准备 Presto 有以下几个基本要求：&nbsp; Linux 或者 Mac OS X 系统&nbsp; Java 8，64位 我的环境 操作系统：CentOS release 6.6 (Final)&nbsp; ps:查看系统版本使用命令 lsb_release -a 1 Hadoop集群：CDH 5.13.0, Parcel&nbsp; JDK 版本：java version 1.8.0_131 Presto单节点安装配置 实际使用中一般需要多节点安装配置，为了快速熟悉和尝试Presto，我们可以先尝试安装单节点的Presto服务。&nbsp; 所谓的单节点就是把Presto的coordinator和worker都部署在同一个节点上。 下载 下载链接&nbsp; https://repo1.maven.org/maven2/com/facebook/presto/presto-server/&nbsp; 该链接中有很多版本的presto，目前最新的是0.195版本。&nbsp; 为了方便Presto进行升级，建议在presto安装目录的外面创建一个目录命名为presto。 使用命令创建目录 mkdir presto 1 进入目录使用命令下载&nbsp; cd ./presto&nbsp; wget https://repo1.maven.org/maven2/com/facebook/presto/presto-server/0.195/presto-server-0.195.tar.gz&nbsp; 使用命令解压压缩文件 tar -xf presto-server-0.195.tar.gz 1 配置Presto 在安装目录中创建一个etc目录。 在这个etc目录中放入以下配置信息：&nbsp; 节点属性：每个节点的环境配置信息&nbsp; JVM 配置：JVM的命令行选项&nbsp; 配置属性：Presto server的配置信息&nbsp; Catalog属性：configuration forConnectors（数据源）的配置信息 使用命令&nbsp; cd ./presto-server-0.195&nbsp; mkdir etc&nbsp; Node Properties 节点属性配置文件：etc/node.properties包含针对于每个节点的特定的配置信息。 一个节点就是在一台机器上安装的Presto实例。 这份配置文件一般情况下是在Presto第一次安装的时候，由部署系统创建的。 一个etc/node.properties配置文件至少包含如下配置信息：&nbsp; node.environment=production&nbsp; node.id=ffffffff-ffff-ffff-ffff-ffffffffffff&nbsp; node.data-dir=/var/presto/data&nbsp; 针对上面的配置信息描述如下： node.environment： 集群名称。所有在同一个集群中的Presto节点必须拥有相同的集群名称。&nbsp; node.id： 每个Presto节点的唯一标示。每个节点的node.id都必须是唯一的。在Presto进行重启或者升级过程中每个节点的node.id必须保持不变。如果在一个节点上安装多个Presto实例（例如：在同一台机器上安装多个Presto节点），那么每个Presto节点必须拥有唯一的node.id。&nbsp; node.data-dir： 数据存储目录的位置（操作系统上的路径）。Presto将会把日期和数据存储在这个目录下。 使用命令&nbsp; cd ./etc&nbsp; vim node.properties&nbsp; 输入配置&nbsp; node.environment=production&nbsp; node.id=a0001&nbsp; node.data-dir=/home/zzq/var/presto/data&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 JVM配置 JVM配置文件，etc/jvm.config， 包含一系列在启动JVM的时候需要使用的命令行选项。这份配置文件的格式是：一系列的选项，每行配置一个单独的选项。由于这些选项不在shell命令中使用。 因此即使将每个选项通过空格或者其他的分隔符分开，java程序也不会将这些选项分开，而是作为一个命令行选项处理。（就像下面例子中的OnOutOfMemoryError选项）。&nbsp; 一个典型的etc/jvm.config配置文件如下：&nbsp; -server&nbsp; -Xmx16G&nbsp; -XX:+UseConcMarkSweepGC&nbsp; -XX:+ExplicitGCInvokesConcurrent&nbsp; -XX:+CMSClassUnloadingEnabled&nbsp; -XX:+AggressiveOpts&nbsp; -XX:+HeapDumpOnOutOfMemoryError&nbsp; -XX:OnOutOfMemoryError=kill -9 %p&nbsp; -XX:ReservedCodeCacheSize=150M&nbsp; 由于OutOfMemoryError将会导致JVM处于不一致状态，所以遇到这种错误的时候我们一般的处理措施就是将dump headp中的信息（用于debugging），然后强制终止进程。 Presto会将查询编译成字节码文件，因此Presto会生成很多class，因此我们我们应该增大Perm区的大小（在Perm中主要存储class）并且要允许Jvm class unloading。 使用命令 vim jvm.config 1 因为我的节点内存比较大为126G，所以可以设置的内存也比较大，我设置为32G。&nbsp; 输入配置&nbsp; -server&nbsp; -Xmx32G&nbsp; -XX:+UseConcMarkSweepGC&nbsp; -XX:+ExplicitGCInvokesConcurrent&nbsp; -XX:+CMSClassUnloadingEnabled&nbsp; -XX:+AggressiveOpts&nbsp; -XX:+HeapDumpOnOutOfMemoryError&nbsp; -XX:OnOutOfMemoryError=kill -9 %p&nbsp; -XX:ReservedCodeCacheSize=300M&nbsp; 如图&nbsp; 点击esc，输入:wq回车保存退出。 Config Properties Presto的配置文件：etc/config.properties包含了Presto server的所有配置信息。 每个Presto server既是一个coordinator也是一个worker。 但是在大型集群中，处于性能考虑，建议单独用一台机器作为 coordinator。&nbsp; 一个coordinator的etc/config.properties应该至少包含以下信息：&nbsp; 旧版本&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=false&nbsp; http-server.http.port=8080&nbsp; task.max-memory=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://example.net:8080 新版本&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=true&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://example.net:8080 以下是最基本的worker配置：&nbsp; 旧版本&nbsp; coordinator=false&nbsp; http-server.http.port=8080&nbsp; task.max-memory=1GB&nbsp; discovery.uri=http://example.net:8080 新版本&nbsp; coordinator=false&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery.uri=http://example.net:8080 但是如果你用一台机器进行测试，那么这一台机器将会即作为coordinator，也作为worker。&nbsp; 对配置项解释如下：&nbsp; coordinator：指定是否运维Presto实例作为一个coordinator(接收来自客户端的查询情切管理每个查询的执行过程)。&nbsp; node-scheduler.include-coordinator：是否允许在coordinator服务中进行调度工作(即作为coordinator又作为worker。对于大型的集群，在一个节点上的Presto server即作为coordinator又作为worker将会降低查询性能。因为如果一个服务器作为worker使用，那么大部分的资源都会被worker占用，那么就不会有足够的资源进行关键任务调度、管理和监控查询执行。&nbsp; http-server.http.port：指定HTTP server的端口。Presto 使用 HTTP进行内部和外部的所有通讯。&nbsp; task.max-memory=1GB：一个单独的任务使用的最大内存 (一个查询计划的某个执行部分会在一个特定的节点上执行)。 这个配置参数限制的GROUP BY语句中的Group的数目、JOIN关联中的右关联表的大小、ORDER BY语句中的行数和一个窗口函数中处理的行数。 该参数应该根据并发查询的数量和查询的复杂度进行调整。如果该参数设置的太低，很多查询将不能执行；但是如果设置的太高将会导致JVM把内存耗光。&nbsp; discovery-server.enabled：Presto 通过Discovery 服务来找到集群中所有的节点。为了能够找到集群中所有的节点，每一个Presto实例都会在启动的时候将自己注册到discovery服务。Presto为了简化部署，并且也不想再增加一个新的服务进程，Presto coordinator 可以运行一个内嵌在coordinator 里面的Discovery 服务。这个内嵌的Discovery 服务和Presto共享HTTP server并且使用同样的端口。&nbsp; discovery.uri：Discovery server的URI。由于启用了Presto coordinator内嵌的Discovery 服务，因此这个uri就是Presto coordinator的uri。修改example.net:8080， 根据你的实际环境设置该URI。注意：这个URI一定不能以“/“结尾。 使用命令 vim config.properties 1 因为是单节点，ip为192.168.30.252，所以输入配置如下:&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=true&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://192.168.30.252:8080&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 日志级别 日志配置文件：etc/log.properties。在这个配置文件中允许你根据不同的日志结构设置不同的日志级别。每个logger都有一个名字（通常是使用logger的类的全标示类名）. Loggers通过名字中的“.“来表示层级和集成关系。 (像java里面的包). 如下面的log配置信息：&nbsp; com.facebook.presto=INFO&nbsp; This would set the minimum level to INFO for both com.facebook.presto.server and com.facebook.presto.hive. The default minimum level is INFO (thus the above example does not actually change anything). There are four levels: DEBUG, INFO, WARN and ERROR. 使用命令 vim log.properties 1 因为考虑到info级别的日志输出会占比较多的空间，我们这里只要ERROR级别的错误。&nbsp; 输入配置&nbsp; com.facebook.presto=ERROR&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 Catalog Properties Presto通过connectors访问数据。这些connectors挂载在catalogs上。 connector可以提供一个catalog中所有的schema和表。 例如： Hive connector 将每个hive的database都映射成为一个schema， 所以如果hive connector挂载到了名为hive的catalog， 并且在hive的web有一张名为clicks的表， 那么在Presto中可以通过hive.web.clicks来访问这张表。&nbsp; 通过在etc/catalog目录下创建catalog属性文件来完成catalogs的注册。&nbsp; 例如：&nbsp; 如果要创建jmx数据源的连接器，可以创建一个etc/catalog/jmx.properties文件，文件中的内容如下，完成在jmxcatalog上挂载一个jmxconnector：&nbsp; connector.name=jmx 如果要创建hive数据源的连接器，可以创建一个etc/catalog/hive.properties文件，文件中的内容如下，完成在hivecatalog上挂载一个hiveconnector：&nbsp; connector.name=hive-hadoop2&nbsp; hive.metastore.uri=thrift://example.net:9083&nbsp; hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml 参数说明&nbsp; connector.name为连接器名称，hive的话需要加上版本号例如hive-hadoop2&nbsp; hive.metastore.uri需要与hive的metastore地址和端口对应。&nbsp; 一般配置在/etc/hive/conf/hive-site.xml中。&nbsp; hive.config.resources需要与hadoop集群的配置路径对应。&nbsp; CDH安装的一般都在/etc/hadoop/conf路径下。&nbsp; 如图:&nbsp; 更多信息可以参考&nbsp; hadoop基础—-hadoop实战(十一)—–hadoop管理工具—CDH的目录结构了解 我们这里要连接hive，所以应该配置hive的连接器。&nbsp; 使用命令&nbsp; mkdir catalog&nbsp; cd ./catalog&nbsp; vim hive.properties&nbsp; 输入配置&nbsp; connector.name=hive-hadoop2&nbsp; hive.metastore.uri=thrift://192.168.30.252:9083&nbsp; hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml 更多连接器详细的信息参考&nbsp; https://prestodb.io/docs/current/connector.html 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 配置完毕&nbsp; 最终etc的目录中配置文件如图:&nbsp; 启动运行Presto 在安装目录的bin/launcher文件，就是启动脚本。Presto可以使用如下命令作为一个后台进程启动： cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher start&nbsp; 另外，也可以在前台运行， 日志和相关输出将会写入stdout/stderr（可以使用类似daemontools的工具捕捉这两个数据流）： cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher run&nbsp; 停止&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher stop&nbsp; Presto可以列出支持的命令和命令行选项。&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher --help&nbsp; 另外可以查看服务进程命令&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher status&nbsp; 查看进程： ps -aux|grep PrestoServer 或 jps&nbsp; 启动完之后，日志将会写在var/log目录下，该目录下有如下文件： launcher.log： 这个日志文件由launcher创建，并且server的stdout和stderr都被重定向到了这个日志文件中。 这份日志文件中只会有很少的信息，包括：&nbsp; 在server日志系统初始化的时候产生的日志和JVM产生的诊断和测试信息。&nbsp; server.log： 这个是Presto使用的主要日志文件。一般情况下，该文件中将会包括server初始化失败时产生的相关信息。这份文件会被自动轮转和压缩。&nbsp; http-request.log： 这是HTTP请求的日志文件，包括server收到的每个HTTP请求信息，这份文件会被自动轮转和压缩。 连接hive测试验证 下载 presto-cli-0.100-executable.jar：Presto CLI为用户提供了一个用于查询的可交互终端窗口。CLI是一个 可执行 JAR文件, 这也就意味着你可以像UNIX终端窗口一样来使用CLI ，下载地址(注意版本对应):&nbsp; https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/ 我这里是0.195版本，使用命令 wget https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.195/presto-cli-0.195-executable.jar 1 文件下载后，重名名为 presto，使用命令 mv presto-cli-0.195-executable.jar presto 1 使用 chmod +x 命令设置可执行权限 chmod a+x presto 1 在hive中查一下hive default库中的表&nbsp; hive自带了一个thrift的客户端———-beeline&nbsp; 打开beeline&nbsp; 使用命令 beeline 1 连接hiveserver2&nbsp; 使用命令 !connect jdbc:hive2://host253:10000 1 （host253是hiveserver2所启动的那台主机名，端口默认是10000） 有可能需要输入当前linux用户名和密码。&nbsp; 正常连接上之后会出现&nbsp; 0: jdbc:hive2://host253:10000&gt;&nbsp; 这时可以尝试操作数据库了，使用命令 show tables; 1 结果如下图：&nbsp; ctrl+c退出hive cli，进入presto cli,使用命令如下: ./presto --server 192.168.30.252:8080 --catalog hive --schema default 1 如果要调试，可加 –debug, ip与端口必须与config.properties配置文件中的uri 地址一致，配置的IP就用IP，机器名就用机器名。 使用命令 show tables; 1 结果如图：&nbsp; 与hive中查询的一致，说明presto部署成功可以使用。 退出presto cli使用命令 quit; 1 Presto多节点安装配置 架构和集群分配 我们在配置Presto多集群时，首先就是要规划架构和集群分配。&nbsp; 一般来说 需要一个coordinator和多个worker。&nbsp; 我们的机子如下 则分配如下:&nbsp; hadoop1 (192.169.30.250):coordinator调度节点&nbsp; hadoop2 (192.169.30.251):worker节点&nbsp; hadoop3 (192.169.30.252):worker节点&nbsp; hadoop4 (192.169.30.253):worker节点&nbsp; hadoop5 (192.169.30.217):worker节点 下载解压 根据单点安装时一样的步骤每一台机子进行下载解压。(也可以把单点时配置好的进行打包上传到其他机子解压) 配置修改 根据每个节点的定位进行配置创建和修改。&nbsp; 因为大部分配置一样，所以我们把单点的配置打包下载分别上传到其他节点。&nbsp; 需要修改的配置如下: Node Properties 使用命令 vim etc/node.properties 1 内容如下 node.environment=production node.id=ffffffff-ffff-ffff-ffff-ffffffffffff node.data-dir=/var/presto/data 1 2 3 这里每个节点的node.id需要不一样，比如在后面加上001、002等 Config Properties coordinator调度节点使用命令 vim etc/config.properties 1 内容如下 coordinator=true node-scheduler.include-coordinator=false http-server.http.port=8080 query.max-memory=50GB query.max-memory-per-node=1GB discovery-server.enabled=true discovery.uri=http://192.168.30.217:8080 1 2 3 4 5 6 7 discovery.uri与coordinator调度节点的ip对应。&nbsp; 调度节点只负责调度时node-scheduler.include-coordinator设置为false&nbsp; 调度节点也作为worker时node-scheduler.include-coordinator设置为true worker节点使用命令 vim etc/config.properties 1 内容如下 coordinator=false http-server.http.port=8080 query.max-memory=50GB query.max-memory-per-node=1GB discovery.uri=http://192.168.30.217:8080 1 2 3 4 5 启用与使用 启动方式与单点的一样，每台都启动起来即可使用。 管理 presto提供了Web的管理界面，可以查看多节点的情况。&nbsp; 根据端口来访问，比如8080,则访问&nbsp; http://192.168.30.252:8080/ &nbsp; JDBC 连接 &lt;dependency&gt; &lt;groupId&gt;com.facebook.presto&lt;/groupId&gt; &lt;artifactId&gt;presto-jdbc&lt;/artifactId&gt; &lt;version&gt;0.101&lt;/version&gt; &lt;/dependency&gt; package presto; import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.Statement; public class PrestoTest { public static void main(String[] args) throws Exception{ Class.forName(&quot;com.facebook.presto.jdbc.PrestoDriver&quot;); Connection connection = DriverManager.getConnection(&quot;jdbc:presto://192.168.0.241:7777/hive/newbei&quot;,&quot;root&quot;,null); ; Statement stmt = connection.createStatement(); ResultSet rs = stmt.executeQuery(&quot;select * from newbei_test&quot;); while (rs.next()) { System.out.println(rs.getString(1)); } rs.close(); connection.close(); } } &nbsp;" />
<meta property="og:description" content="官网教程 https://prestodb.io/docs/current/installation.html&nbsp; http://prestodb-china.com/docs/current/installation/deployment.html （京东版本）&nbsp; https://teradata.github.io/presto/docs/current/overview.html （teradata版本） 环境准备 Presto 有以下几个基本要求：&nbsp; Linux 或者 Mac OS X 系统&nbsp; Java 8，64位 我的环境 操作系统：CentOS release 6.6 (Final)&nbsp; ps:查看系统版本使用命令 lsb_release -a 1 Hadoop集群：CDH 5.13.0, Parcel&nbsp; JDK 版本：java version 1.8.0_131 Presto单节点安装配置 实际使用中一般需要多节点安装配置，为了快速熟悉和尝试Presto，我们可以先尝试安装单节点的Presto服务。&nbsp; 所谓的单节点就是把Presto的coordinator和worker都部署在同一个节点上。 下载 下载链接&nbsp; https://repo1.maven.org/maven2/com/facebook/presto/presto-server/&nbsp; 该链接中有很多版本的presto，目前最新的是0.195版本。&nbsp; 为了方便Presto进行升级，建议在presto安装目录的外面创建一个目录命名为presto。 使用命令创建目录 mkdir presto 1 进入目录使用命令下载&nbsp; cd ./presto&nbsp; wget https://repo1.maven.org/maven2/com/facebook/presto/presto-server/0.195/presto-server-0.195.tar.gz&nbsp; 使用命令解压压缩文件 tar -xf presto-server-0.195.tar.gz 1 配置Presto 在安装目录中创建一个etc目录。 在这个etc目录中放入以下配置信息：&nbsp; 节点属性：每个节点的环境配置信息&nbsp; JVM 配置：JVM的命令行选项&nbsp; 配置属性：Presto server的配置信息&nbsp; Catalog属性：configuration forConnectors（数据源）的配置信息 使用命令&nbsp; cd ./presto-server-0.195&nbsp; mkdir etc&nbsp; Node Properties 节点属性配置文件：etc/node.properties包含针对于每个节点的特定的配置信息。 一个节点就是在一台机器上安装的Presto实例。 这份配置文件一般情况下是在Presto第一次安装的时候，由部署系统创建的。 一个etc/node.properties配置文件至少包含如下配置信息：&nbsp; node.environment=production&nbsp; node.id=ffffffff-ffff-ffff-ffff-ffffffffffff&nbsp; node.data-dir=/var/presto/data&nbsp; 针对上面的配置信息描述如下： node.environment： 集群名称。所有在同一个集群中的Presto节点必须拥有相同的集群名称。&nbsp; node.id： 每个Presto节点的唯一标示。每个节点的node.id都必须是唯一的。在Presto进行重启或者升级过程中每个节点的node.id必须保持不变。如果在一个节点上安装多个Presto实例（例如：在同一台机器上安装多个Presto节点），那么每个Presto节点必须拥有唯一的node.id。&nbsp; node.data-dir： 数据存储目录的位置（操作系统上的路径）。Presto将会把日期和数据存储在这个目录下。 使用命令&nbsp; cd ./etc&nbsp; vim node.properties&nbsp; 输入配置&nbsp; node.environment=production&nbsp; node.id=a0001&nbsp; node.data-dir=/home/zzq/var/presto/data&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 JVM配置 JVM配置文件，etc/jvm.config， 包含一系列在启动JVM的时候需要使用的命令行选项。这份配置文件的格式是：一系列的选项，每行配置一个单独的选项。由于这些选项不在shell命令中使用。 因此即使将每个选项通过空格或者其他的分隔符分开，java程序也不会将这些选项分开，而是作为一个命令行选项处理。（就像下面例子中的OnOutOfMemoryError选项）。&nbsp; 一个典型的etc/jvm.config配置文件如下：&nbsp; -server&nbsp; -Xmx16G&nbsp; -XX:+UseConcMarkSweepGC&nbsp; -XX:+ExplicitGCInvokesConcurrent&nbsp; -XX:+CMSClassUnloadingEnabled&nbsp; -XX:+AggressiveOpts&nbsp; -XX:+HeapDumpOnOutOfMemoryError&nbsp; -XX:OnOutOfMemoryError=kill -9 %p&nbsp; -XX:ReservedCodeCacheSize=150M&nbsp; 由于OutOfMemoryError将会导致JVM处于不一致状态，所以遇到这种错误的时候我们一般的处理措施就是将dump headp中的信息（用于debugging），然后强制终止进程。 Presto会将查询编译成字节码文件，因此Presto会生成很多class，因此我们我们应该增大Perm区的大小（在Perm中主要存储class）并且要允许Jvm class unloading。 使用命令 vim jvm.config 1 因为我的节点内存比较大为126G，所以可以设置的内存也比较大，我设置为32G。&nbsp; 输入配置&nbsp; -server&nbsp; -Xmx32G&nbsp; -XX:+UseConcMarkSweepGC&nbsp; -XX:+ExplicitGCInvokesConcurrent&nbsp; -XX:+CMSClassUnloadingEnabled&nbsp; -XX:+AggressiveOpts&nbsp; -XX:+HeapDumpOnOutOfMemoryError&nbsp; -XX:OnOutOfMemoryError=kill -9 %p&nbsp; -XX:ReservedCodeCacheSize=300M&nbsp; 如图&nbsp; 点击esc，输入:wq回车保存退出。 Config Properties Presto的配置文件：etc/config.properties包含了Presto server的所有配置信息。 每个Presto server既是一个coordinator也是一个worker。 但是在大型集群中，处于性能考虑，建议单独用一台机器作为 coordinator。&nbsp; 一个coordinator的etc/config.properties应该至少包含以下信息：&nbsp; 旧版本&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=false&nbsp; http-server.http.port=8080&nbsp; task.max-memory=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://example.net:8080 新版本&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=true&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://example.net:8080 以下是最基本的worker配置：&nbsp; 旧版本&nbsp; coordinator=false&nbsp; http-server.http.port=8080&nbsp; task.max-memory=1GB&nbsp; discovery.uri=http://example.net:8080 新版本&nbsp; coordinator=false&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery.uri=http://example.net:8080 但是如果你用一台机器进行测试，那么这一台机器将会即作为coordinator，也作为worker。&nbsp; 对配置项解释如下：&nbsp; coordinator：指定是否运维Presto实例作为一个coordinator(接收来自客户端的查询情切管理每个查询的执行过程)。&nbsp; node-scheduler.include-coordinator：是否允许在coordinator服务中进行调度工作(即作为coordinator又作为worker。对于大型的集群，在一个节点上的Presto server即作为coordinator又作为worker将会降低查询性能。因为如果一个服务器作为worker使用，那么大部分的资源都会被worker占用，那么就不会有足够的资源进行关键任务调度、管理和监控查询执行。&nbsp; http-server.http.port：指定HTTP server的端口。Presto 使用 HTTP进行内部和外部的所有通讯。&nbsp; task.max-memory=1GB：一个单独的任务使用的最大内存 (一个查询计划的某个执行部分会在一个特定的节点上执行)。 这个配置参数限制的GROUP BY语句中的Group的数目、JOIN关联中的右关联表的大小、ORDER BY语句中的行数和一个窗口函数中处理的行数。 该参数应该根据并发查询的数量和查询的复杂度进行调整。如果该参数设置的太低，很多查询将不能执行；但是如果设置的太高将会导致JVM把内存耗光。&nbsp; discovery-server.enabled：Presto 通过Discovery 服务来找到集群中所有的节点。为了能够找到集群中所有的节点，每一个Presto实例都会在启动的时候将自己注册到discovery服务。Presto为了简化部署，并且也不想再增加一个新的服务进程，Presto coordinator 可以运行一个内嵌在coordinator 里面的Discovery 服务。这个内嵌的Discovery 服务和Presto共享HTTP server并且使用同样的端口。&nbsp; discovery.uri：Discovery server的URI。由于启用了Presto coordinator内嵌的Discovery 服务，因此这个uri就是Presto coordinator的uri。修改example.net:8080， 根据你的实际环境设置该URI。注意：这个URI一定不能以“/“结尾。 使用命令 vim config.properties 1 因为是单节点，ip为192.168.30.252，所以输入配置如下:&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=true&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://192.168.30.252:8080&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 日志级别 日志配置文件：etc/log.properties。在这个配置文件中允许你根据不同的日志结构设置不同的日志级别。每个logger都有一个名字（通常是使用logger的类的全标示类名）. Loggers通过名字中的“.“来表示层级和集成关系。 (像java里面的包). 如下面的log配置信息：&nbsp; com.facebook.presto=INFO&nbsp; This would set the minimum level to INFO for both com.facebook.presto.server and com.facebook.presto.hive. The default minimum level is INFO (thus the above example does not actually change anything). There are four levels: DEBUG, INFO, WARN and ERROR. 使用命令 vim log.properties 1 因为考虑到info级别的日志输出会占比较多的空间，我们这里只要ERROR级别的错误。&nbsp; 输入配置&nbsp; com.facebook.presto=ERROR&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 Catalog Properties Presto通过connectors访问数据。这些connectors挂载在catalogs上。 connector可以提供一个catalog中所有的schema和表。 例如： Hive connector 将每个hive的database都映射成为一个schema， 所以如果hive connector挂载到了名为hive的catalog， 并且在hive的web有一张名为clicks的表， 那么在Presto中可以通过hive.web.clicks来访问这张表。&nbsp; 通过在etc/catalog目录下创建catalog属性文件来完成catalogs的注册。&nbsp; 例如：&nbsp; 如果要创建jmx数据源的连接器，可以创建一个etc/catalog/jmx.properties文件，文件中的内容如下，完成在jmxcatalog上挂载一个jmxconnector：&nbsp; connector.name=jmx 如果要创建hive数据源的连接器，可以创建一个etc/catalog/hive.properties文件，文件中的内容如下，完成在hivecatalog上挂载一个hiveconnector：&nbsp; connector.name=hive-hadoop2&nbsp; hive.metastore.uri=thrift://example.net:9083&nbsp; hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml 参数说明&nbsp; connector.name为连接器名称，hive的话需要加上版本号例如hive-hadoop2&nbsp; hive.metastore.uri需要与hive的metastore地址和端口对应。&nbsp; 一般配置在/etc/hive/conf/hive-site.xml中。&nbsp; hive.config.resources需要与hadoop集群的配置路径对应。&nbsp; CDH安装的一般都在/etc/hadoop/conf路径下。&nbsp; 如图:&nbsp; 更多信息可以参考&nbsp; hadoop基础—-hadoop实战(十一)—–hadoop管理工具—CDH的目录结构了解 我们这里要连接hive，所以应该配置hive的连接器。&nbsp; 使用命令&nbsp; mkdir catalog&nbsp; cd ./catalog&nbsp; vim hive.properties&nbsp; 输入配置&nbsp; connector.name=hive-hadoop2&nbsp; hive.metastore.uri=thrift://192.168.30.252:9083&nbsp; hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml 更多连接器详细的信息参考&nbsp; https://prestodb.io/docs/current/connector.html 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 配置完毕&nbsp; 最终etc的目录中配置文件如图:&nbsp; 启动运行Presto 在安装目录的bin/launcher文件，就是启动脚本。Presto可以使用如下命令作为一个后台进程启动： cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher start&nbsp; 另外，也可以在前台运行， 日志和相关输出将会写入stdout/stderr（可以使用类似daemontools的工具捕捉这两个数据流）： cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher run&nbsp; 停止&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher stop&nbsp; Presto可以列出支持的命令和命令行选项。&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher --help&nbsp; 另外可以查看服务进程命令&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher status&nbsp; 查看进程： ps -aux|grep PrestoServer 或 jps&nbsp; 启动完之后，日志将会写在var/log目录下，该目录下有如下文件： launcher.log： 这个日志文件由launcher创建，并且server的stdout和stderr都被重定向到了这个日志文件中。 这份日志文件中只会有很少的信息，包括：&nbsp; 在server日志系统初始化的时候产生的日志和JVM产生的诊断和测试信息。&nbsp; server.log： 这个是Presto使用的主要日志文件。一般情况下，该文件中将会包括server初始化失败时产生的相关信息。这份文件会被自动轮转和压缩。&nbsp; http-request.log： 这是HTTP请求的日志文件，包括server收到的每个HTTP请求信息，这份文件会被自动轮转和压缩。 连接hive测试验证 下载 presto-cli-0.100-executable.jar：Presto CLI为用户提供了一个用于查询的可交互终端窗口。CLI是一个 可执行 JAR文件, 这也就意味着你可以像UNIX终端窗口一样来使用CLI ，下载地址(注意版本对应):&nbsp; https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/ 我这里是0.195版本，使用命令 wget https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.195/presto-cli-0.195-executable.jar 1 文件下载后，重名名为 presto，使用命令 mv presto-cli-0.195-executable.jar presto 1 使用 chmod +x 命令设置可执行权限 chmod a+x presto 1 在hive中查一下hive default库中的表&nbsp; hive自带了一个thrift的客户端———-beeline&nbsp; 打开beeline&nbsp; 使用命令 beeline 1 连接hiveserver2&nbsp; 使用命令 !connect jdbc:hive2://host253:10000 1 （host253是hiveserver2所启动的那台主机名，端口默认是10000） 有可能需要输入当前linux用户名和密码。&nbsp; 正常连接上之后会出现&nbsp; 0: jdbc:hive2://host253:10000&gt;&nbsp; 这时可以尝试操作数据库了，使用命令 show tables; 1 结果如下图：&nbsp; ctrl+c退出hive cli，进入presto cli,使用命令如下: ./presto --server 192.168.30.252:8080 --catalog hive --schema default 1 如果要调试，可加 –debug, ip与端口必须与config.properties配置文件中的uri 地址一致，配置的IP就用IP，机器名就用机器名。 使用命令 show tables; 1 结果如图：&nbsp; 与hive中查询的一致，说明presto部署成功可以使用。 退出presto cli使用命令 quit; 1 Presto多节点安装配置 架构和集群分配 我们在配置Presto多集群时，首先就是要规划架构和集群分配。&nbsp; 一般来说 需要一个coordinator和多个worker。&nbsp; 我们的机子如下 则分配如下:&nbsp; hadoop1 (192.169.30.250):coordinator调度节点&nbsp; hadoop2 (192.169.30.251):worker节点&nbsp; hadoop3 (192.169.30.252):worker节点&nbsp; hadoop4 (192.169.30.253):worker节点&nbsp; hadoop5 (192.169.30.217):worker节点 下载解压 根据单点安装时一样的步骤每一台机子进行下载解压。(也可以把单点时配置好的进行打包上传到其他机子解压) 配置修改 根据每个节点的定位进行配置创建和修改。&nbsp; 因为大部分配置一样，所以我们把单点的配置打包下载分别上传到其他节点。&nbsp; 需要修改的配置如下: Node Properties 使用命令 vim etc/node.properties 1 内容如下 node.environment=production node.id=ffffffff-ffff-ffff-ffff-ffffffffffff node.data-dir=/var/presto/data 1 2 3 这里每个节点的node.id需要不一样，比如在后面加上001、002等 Config Properties coordinator调度节点使用命令 vim etc/config.properties 1 内容如下 coordinator=true node-scheduler.include-coordinator=false http-server.http.port=8080 query.max-memory=50GB query.max-memory-per-node=1GB discovery-server.enabled=true discovery.uri=http://192.168.30.217:8080 1 2 3 4 5 6 7 discovery.uri与coordinator调度节点的ip对应。&nbsp; 调度节点只负责调度时node-scheduler.include-coordinator设置为false&nbsp; 调度节点也作为worker时node-scheduler.include-coordinator设置为true worker节点使用命令 vim etc/config.properties 1 内容如下 coordinator=false http-server.http.port=8080 query.max-memory=50GB query.max-memory-per-node=1GB discovery.uri=http://192.168.30.217:8080 1 2 3 4 5 启用与使用 启动方式与单点的一样，每台都启动起来即可使用。 管理 presto提供了Web的管理界面，可以查看多节点的情况。&nbsp; 根据端口来访问，比如8080,则访问&nbsp; http://192.168.30.252:8080/ &nbsp; JDBC 连接 &lt;dependency&gt; &lt;groupId&gt;com.facebook.presto&lt;/groupId&gt; &lt;artifactId&gt;presto-jdbc&lt;/artifactId&gt; &lt;version&gt;0.101&lt;/version&gt; &lt;/dependency&gt; package presto; import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.Statement; public class PrestoTest { public static void main(String[] args) throws Exception{ Class.forName(&quot;com.facebook.presto.jdbc.PrestoDriver&quot;); Connection connection = DriverManager.getConnection(&quot;jdbc:presto://192.168.0.241:7777/hive/newbei&quot;,&quot;root&quot;,null); ; Statement stmt = connection.createStatement(); ResultSet rs = stmt.executeQuery(&quot;select * from newbei_test&quot;); while (rs.next()) { System.out.println(rs.getString(1)); } rs.close(); connection.close(); } } &nbsp;" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-05T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"官网教程 https://prestodb.io/docs/current/installation.html&nbsp; http://prestodb-china.com/docs/current/installation/deployment.html （京东版本）&nbsp; https://teradata.github.io/presto/docs/current/overview.html （teradata版本） 环境准备 Presto 有以下几个基本要求：&nbsp; Linux 或者 Mac OS X 系统&nbsp; Java 8，64位 我的环境 操作系统：CentOS release 6.6 (Final)&nbsp; ps:查看系统版本使用命令 lsb_release -a 1 Hadoop集群：CDH 5.13.0, Parcel&nbsp; JDK 版本：java version 1.8.0_131 Presto单节点安装配置 实际使用中一般需要多节点安装配置，为了快速熟悉和尝试Presto，我们可以先尝试安装单节点的Presto服务。&nbsp; 所谓的单节点就是把Presto的coordinator和worker都部署在同一个节点上。 下载 下载链接&nbsp; https://repo1.maven.org/maven2/com/facebook/presto/presto-server/&nbsp; 该链接中有很多版本的presto，目前最新的是0.195版本。&nbsp; 为了方便Presto进行升级，建议在presto安装目录的外面创建一个目录命名为presto。 使用命令创建目录 mkdir presto 1 进入目录使用命令下载&nbsp; cd ./presto&nbsp; wget https://repo1.maven.org/maven2/com/facebook/presto/presto-server/0.195/presto-server-0.195.tar.gz&nbsp; 使用命令解压压缩文件 tar -xf presto-server-0.195.tar.gz 1 配置Presto 在安装目录中创建一个etc目录。 在这个etc目录中放入以下配置信息：&nbsp; 节点属性：每个节点的环境配置信息&nbsp; JVM 配置：JVM的命令行选项&nbsp; 配置属性：Presto server的配置信息&nbsp; Catalog属性：configuration forConnectors（数据源）的配置信息 使用命令&nbsp; cd ./presto-server-0.195&nbsp; mkdir etc&nbsp; Node Properties 节点属性配置文件：etc/node.properties包含针对于每个节点的特定的配置信息。 一个节点就是在一台机器上安装的Presto实例。 这份配置文件一般情况下是在Presto第一次安装的时候，由部署系统创建的。 一个etc/node.properties配置文件至少包含如下配置信息：&nbsp; node.environment=production&nbsp; node.id=ffffffff-ffff-ffff-ffff-ffffffffffff&nbsp; node.data-dir=/var/presto/data&nbsp; 针对上面的配置信息描述如下： node.environment： 集群名称。所有在同一个集群中的Presto节点必须拥有相同的集群名称。&nbsp; node.id： 每个Presto节点的唯一标示。每个节点的node.id都必须是唯一的。在Presto进行重启或者升级过程中每个节点的node.id必须保持不变。如果在一个节点上安装多个Presto实例（例如：在同一台机器上安装多个Presto节点），那么每个Presto节点必须拥有唯一的node.id。&nbsp; node.data-dir： 数据存储目录的位置（操作系统上的路径）。Presto将会把日期和数据存储在这个目录下。 使用命令&nbsp; cd ./etc&nbsp; vim node.properties&nbsp; 输入配置&nbsp; node.environment=production&nbsp; node.id=a0001&nbsp; node.data-dir=/home/zzq/var/presto/data&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 JVM配置 JVM配置文件，etc/jvm.config， 包含一系列在启动JVM的时候需要使用的命令行选项。这份配置文件的格式是：一系列的选项，每行配置一个单独的选项。由于这些选项不在shell命令中使用。 因此即使将每个选项通过空格或者其他的分隔符分开，java程序也不会将这些选项分开，而是作为一个命令行选项处理。（就像下面例子中的OnOutOfMemoryError选项）。&nbsp; 一个典型的etc/jvm.config配置文件如下：&nbsp; -server&nbsp; -Xmx16G&nbsp; -XX:+UseConcMarkSweepGC&nbsp; -XX:+ExplicitGCInvokesConcurrent&nbsp; -XX:+CMSClassUnloadingEnabled&nbsp; -XX:+AggressiveOpts&nbsp; -XX:+HeapDumpOnOutOfMemoryError&nbsp; -XX:OnOutOfMemoryError=kill -9 %p&nbsp; -XX:ReservedCodeCacheSize=150M&nbsp; 由于OutOfMemoryError将会导致JVM处于不一致状态，所以遇到这种错误的时候我们一般的处理措施就是将dump headp中的信息（用于debugging），然后强制终止进程。 Presto会将查询编译成字节码文件，因此Presto会生成很多class，因此我们我们应该增大Perm区的大小（在Perm中主要存储class）并且要允许Jvm class unloading。 使用命令 vim jvm.config 1 因为我的节点内存比较大为126G，所以可以设置的内存也比较大，我设置为32G。&nbsp; 输入配置&nbsp; -server&nbsp; -Xmx32G&nbsp; -XX:+UseConcMarkSweepGC&nbsp; -XX:+ExplicitGCInvokesConcurrent&nbsp; -XX:+CMSClassUnloadingEnabled&nbsp; -XX:+AggressiveOpts&nbsp; -XX:+HeapDumpOnOutOfMemoryError&nbsp; -XX:OnOutOfMemoryError=kill -9 %p&nbsp; -XX:ReservedCodeCacheSize=300M&nbsp; 如图&nbsp; 点击esc，输入:wq回车保存退出。 Config Properties Presto的配置文件：etc/config.properties包含了Presto server的所有配置信息。 每个Presto server既是一个coordinator也是一个worker。 但是在大型集群中，处于性能考虑，建议单独用一台机器作为 coordinator。&nbsp; 一个coordinator的etc/config.properties应该至少包含以下信息：&nbsp; 旧版本&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=false&nbsp; http-server.http.port=8080&nbsp; task.max-memory=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://example.net:8080 新版本&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=true&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://example.net:8080 以下是最基本的worker配置：&nbsp; 旧版本&nbsp; coordinator=false&nbsp; http-server.http.port=8080&nbsp; task.max-memory=1GB&nbsp; discovery.uri=http://example.net:8080 新版本&nbsp; coordinator=false&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery.uri=http://example.net:8080 但是如果你用一台机器进行测试，那么这一台机器将会即作为coordinator，也作为worker。&nbsp; 对配置项解释如下：&nbsp; coordinator：指定是否运维Presto实例作为一个coordinator(接收来自客户端的查询情切管理每个查询的执行过程)。&nbsp; node-scheduler.include-coordinator：是否允许在coordinator服务中进行调度工作(即作为coordinator又作为worker。对于大型的集群，在一个节点上的Presto server即作为coordinator又作为worker将会降低查询性能。因为如果一个服务器作为worker使用，那么大部分的资源都会被worker占用，那么就不会有足够的资源进行关键任务调度、管理和监控查询执行。&nbsp; http-server.http.port：指定HTTP server的端口。Presto 使用 HTTP进行内部和外部的所有通讯。&nbsp; task.max-memory=1GB：一个单独的任务使用的最大内存 (一个查询计划的某个执行部分会在一个特定的节点上执行)。 这个配置参数限制的GROUP BY语句中的Group的数目、JOIN关联中的右关联表的大小、ORDER BY语句中的行数和一个窗口函数中处理的行数。 该参数应该根据并发查询的数量和查询的复杂度进行调整。如果该参数设置的太低，很多查询将不能执行；但是如果设置的太高将会导致JVM把内存耗光。&nbsp; discovery-server.enabled：Presto 通过Discovery 服务来找到集群中所有的节点。为了能够找到集群中所有的节点，每一个Presto实例都会在启动的时候将自己注册到discovery服务。Presto为了简化部署，并且也不想再增加一个新的服务进程，Presto coordinator 可以运行一个内嵌在coordinator 里面的Discovery 服务。这个内嵌的Discovery 服务和Presto共享HTTP server并且使用同样的端口。&nbsp; discovery.uri：Discovery server的URI。由于启用了Presto coordinator内嵌的Discovery 服务，因此这个uri就是Presto coordinator的uri。修改example.net:8080， 根据你的实际环境设置该URI。注意：这个URI一定不能以“/“结尾。 使用命令 vim config.properties 1 因为是单节点，ip为192.168.30.252，所以输入配置如下:&nbsp; coordinator=true&nbsp; node-scheduler.include-coordinator=true&nbsp; http-server.http.port=8080&nbsp; query.max-memory=50GB&nbsp; query.max-memory-per-node=1GB&nbsp; discovery-server.enabled=true&nbsp; discovery.uri=http://192.168.30.252:8080&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 日志级别 日志配置文件：etc/log.properties。在这个配置文件中允许你根据不同的日志结构设置不同的日志级别。每个logger都有一个名字（通常是使用logger的类的全标示类名）. Loggers通过名字中的“.“来表示层级和集成关系。 (像java里面的包). 如下面的log配置信息：&nbsp; com.facebook.presto=INFO&nbsp; This would set the minimum level to INFO for both com.facebook.presto.server and com.facebook.presto.hive. The default minimum level is INFO (thus the above example does not actually change anything). There are four levels: DEBUG, INFO, WARN and ERROR. 使用命令 vim log.properties 1 因为考虑到info级别的日志输出会占比较多的空间，我们这里只要ERROR级别的错误。&nbsp; 输入配置&nbsp; com.facebook.presto=ERROR&nbsp; 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 Catalog Properties Presto通过connectors访问数据。这些connectors挂载在catalogs上。 connector可以提供一个catalog中所有的schema和表。 例如： Hive connector 将每个hive的database都映射成为一个schema， 所以如果hive connector挂载到了名为hive的catalog， 并且在hive的web有一张名为clicks的表， 那么在Presto中可以通过hive.web.clicks来访问这张表。&nbsp; 通过在etc/catalog目录下创建catalog属性文件来完成catalogs的注册。&nbsp; 例如：&nbsp; 如果要创建jmx数据源的连接器，可以创建一个etc/catalog/jmx.properties文件，文件中的内容如下，完成在jmxcatalog上挂载一个jmxconnector：&nbsp; connector.name=jmx 如果要创建hive数据源的连接器，可以创建一个etc/catalog/hive.properties文件，文件中的内容如下，完成在hivecatalog上挂载一个hiveconnector：&nbsp; connector.name=hive-hadoop2&nbsp; hive.metastore.uri=thrift://example.net:9083&nbsp; hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml 参数说明&nbsp; connector.name为连接器名称，hive的话需要加上版本号例如hive-hadoop2&nbsp; hive.metastore.uri需要与hive的metastore地址和端口对应。&nbsp; 一般配置在/etc/hive/conf/hive-site.xml中。&nbsp; hive.config.resources需要与hadoop集群的配置路径对应。&nbsp; CDH安装的一般都在/etc/hadoop/conf路径下。&nbsp; 如图:&nbsp; 更多信息可以参考&nbsp; hadoop基础—-hadoop实战(十一)—–hadoop管理工具—CDH的目录结构了解 我们这里要连接hive，所以应该配置hive的连接器。&nbsp; 使用命令&nbsp; mkdir catalog&nbsp; cd ./catalog&nbsp; vim hive.properties&nbsp; 输入配置&nbsp; connector.name=hive-hadoop2&nbsp; hive.metastore.uri=thrift://192.168.30.252:9083&nbsp; hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml 更多连接器详细的信息参考&nbsp; https://prestodb.io/docs/current/connector.html 如图:&nbsp; &nbsp; 点击esc，输入:wq回车保存退出。 配置完毕&nbsp; 最终etc的目录中配置文件如图:&nbsp; 启动运行Presto 在安装目录的bin/launcher文件，就是启动脚本。Presto可以使用如下命令作为一个后台进程启动： cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher start&nbsp; 另外，也可以在前台运行， 日志和相关输出将会写入stdout/stderr（可以使用类似daemontools的工具捕捉这两个数据流）： cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher run&nbsp; 停止&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher stop&nbsp; Presto可以列出支持的命令和命令行选项。&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher --help&nbsp; 另外可以查看服务进程命令&nbsp; cd /home/zzq/presto/presto-server-0.195&nbsp; bin/launcher status&nbsp; 查看进程： ps -aux|grep PrestoServer 或 jps&nbsp; 启动完之后，日志将会写在var/log目录下，该目录下有如下文件： launcher.log： 这个日志文件由launcher创建，并且server的stdout和stderr都被重定向到了这个日志文件中。 这份日志文件中只会有很少的信息，包括：&nbsp; 在server日志系统初始化的时候产生的日志和JVM产生的诊断和测试信息。&nbsp; server.log： 这个是Presto使用的主要日志文件。一般情况下，该文件中将会包括server初始化失败时产生的相关信息。这份文件会被自动轮转和压缩。&nbsp; http-request.log： 这是HTTP请求的日志文件，包括server收到的每个HTTP请求信息，这份文件会被自动轮转和压缩。 连接hive测试验证 下载 presto-cli-0.100-executable.jar：Presto CLI为用户提供了一个用于查询的可交互终端窗口。CLI是一个 可执行 JAR文件, 这也就意味着你可以像UNIX终端窗口一样来使用CLI ，下载地址(注意版本对应):&nbsp; https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/ 我这里是0.195版本，使用命令 wget https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.195/presto-cli-0.195-executable.jar 1 文件下载后，重名名为 presto，使用命令 mv presto-cli-0.195-executable.jar presto 1 使用 chmod +x 命令设置可执行权限 chmod a+x presto 1 在hive中查一下hive default库中的表&nbsp; hive自带了一个thrift的客户端———-beeline&nbsp; 打开beeline&nbsp; 使用命令 beeline 1 连接hiveserver2&nbsp; 使用命令 !connect jdbc:hive2://host253:10000 1 （host253是hiveserver2所启动的那台主机名，端口默认是10000） 有可能需要输入当前linux用户名和密码。&nbsp; 正常连接上之后会出现&nbsp; 0: jdbc:hive2://host253:10000&gt;&nbsp; 这时可以尝试操作数据库了，使用命令 show tables; 1 结果如下图：&nbsp; ctrl+c退出hive cli，进入presto cli,使用命令如下: ./presto --server 192.168.30.252:8080 --catalog hive --schema default 1 如果要调试，可加 –debug, ip与端口必须与config.properties配置文件中的uri 地址一致，配置的IP就用IP，机器名就用机器名。 使用命令 show tables; 1 结果如图：&nbsp; 与hive中查询的一致，说明presto部署成功可以使用。 退出presto cli使用命令 quit; 1 Presto多节点安装配置 架构和集群分配 我们在配置Presto多集群时，首先就是要规划架构和集群分配。&nbsp; 一般来说 需要一个coordinator和多个worker。&nbsp; 我们的机子如下 则分配如下:&nbsp; hadoop1 (192.169.30.250):coordinator调度节点&nbsp; hadoop2 (192.169.30.251):worker节点&nbsp; hadoop3 (192.169.30.252):worker节点&nbsp; hadoop4 (192.169.30.253):worker节点&nbsp; hadoop5 (192.169.30.217):worker节点 下载解压 根据单点安装时一样的步骤每一台机子进行下载解压。(也可以把单点时配置好的进行打包上传到其他机子解压) 配置修改 根据每个节点的定位进行配置创建和修改。&nbsp; 因为大部分配置一样，所以我们把单点的配置打包下载分别上传到其他节点。&nbsp; 需要修改的配置如下: Node Properties 使用命令 vim etc/node.properties 1 内容如下 node.environment=production node.id=ffffffff-ffff-ffff-ffff-ffffffffffff node.data-dir=/var/presto/data 1 2 3 这里每个节点的node.id需要不一样，比如在后面加上001、002等 Config Properties coordinator调度节点使用命令 vim etc/config.properties 1 内容如下 coordinator=true node-scheduler.include-coordinator=false http-server.http.port=8080 query.max-memory=50GB query.max-memory-per-node=1GB discovery-server.enabled=true discovery.uri=http://192.168.30.217:8080 1 2 3 4 5 6 7 discovery.uri与coordinator调度节点的ip对应。&nbsp; 调度节点只负责调度时node-scheduler.include-coordinator设置为false&nbsp; 调度节点也作为worker时node-scheduler.include-coordinator设置为true worker节点使用命令 vim etc/config.properties 1 内容如下 coordinator=false http-server.http.port=8080 query.max-memory=50GB query.max-memory-per-node=1GB discovery.uri=http://192.168.30.217:8080 1 2 3 4 5 启用与使用 启动方式与单点的一样，每台都启动起来即可使用。 管理 presto提供了Web的管理界面，可以查看多节点的情况。&nbsp; 根据端口来访问，比如8080,则访问&nbsp; http://192.168.30.252:8080/ &nbsp; JDBC 连接 &lt;dependency&gt; &lt;groupId&gt;com.facebook.presto&lt;/groupId&gt; &lt;artifactId&gt;presto-jdbc&lt;/artifactId&gt; &lt;version&gt;0.101&lt;/version&gt; &lt;/dependency&gt; package presto; import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.Statement; public class PrestoTest { public static void main(String[] args) throws Exception{ Class.forName(&quot;com.facebook.presto.jdbc.PrestoDriver&quot;); Connection connection = DriverManager.getConnection(&quot;jdbc:presto://192.168.0.241:7777/hive/newbei&quot;,&quot;root&quot;,null); ; Statement stmt = connection.createStatement(); ResultSet rs = stmt.executeQuery(&quot;select * from newbei_test&quot;); while (rs.next()) { System.out.println(rs.getString(1)); } rs.close(); connection.close(); } } &nbsp;","@type":"BlogPosting","url":"/2019/04/05/728732.html","headline":"presto安装部署和连接hive使用","dateModified":"2019-04-05T00:00:00+08:00","datePublished":"2019-04-05T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/05/728732.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>presto安装部署和连接hive使用</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>官网教程</p> 
  <p>https://prestodb.io/docs/current/installation.html&nbsp;<br> http://prestodb-china.com/docs/current/installation/deployment.html （京东版本）&nbsp;<br> https://teradata.github.io/presto/docs/current/overview.html （teradata版本）</p> 
  <p>环境准备</p> 
  <p>Presto 有以下几个基本要求：&nbsp;<br> Linux 或者 Mac OS X 系统&nbsp;<br> Java 8，64位</p> 
  <p>我的环境</p> 
  <p>操作系统：CentOS release 6.6 (Final)&nbsp;<br> ps:查看系统版本使用命令</p> 
  <p>lsb_release -a<br> 1<br> Hadoop集群：CDH 5.13.0, Parcel&nbsp;<br> JDK 版本：java version 1.8.0_131</p> 
  <p>Presto单节点安装配置</p> 
  <p>实际使用中一般需要多节点安装配置，为了快速熟悉和尝试Presto，我们可以先尝试安装单节点的Presto服务。&nbsp;<br> 所谓的单节点就是把Presto的coordinator和worker都部署在同一个节点上。</p> 
  <p>下载</p> 
  <p>下载链接&nbsp;<br> https://repo1.maven.org/maven2/com/facebook/presto/presto-server/&nbsp;<br> 该链接中有很多版本的presto，目前最新的是0.195版本。&nbsp;<br> 为了方便Presto进行升级，建议在presto安装目录的外面创建一个目录命名为presto。</p> 
  <p>使用命令创建目录</p> 
  <p>mkdir presto<br> 1<br> 进入目录使用命令下载&nbsp;</p> 
  <p>cd ./presto&nbsp;<br> wget https://repo1.maven.org/maven2/com/facebook/presto/presto-server/0.195/presto-server-0.195.tar.gz&nbsp;</p> 
  <p>使用命令解压压缩文件</p> 
  <p>tar -xf presto-server-0.195.tar.gz<br> 1</p> 
  <p><br> 配置Presto</p> 
  <p>在安装目录中创建一个etc目录。 在这个etc目录中放入以下配置信息：&nbsp;<br> 节点属性：每个节点的环境配置信息&nbsp;<br> JVM 配置：JVM的命令行选项&nbsp;<br> 配置属性：Presto server的配置信息&nbsp;<br> Catalog属性：configuration forConnectors（数据源）的配置信息</p> 
  <p>使用命令&nbsp;</p> 
  <p>cd ./presto-server-0.195&nbsp;<br> mkdir etc&nbsp;</p> 
  <p>Node Properties</p> 
  <p>节点属性配置文件：etc/node.properties包含针对于每个节点的特定的配置信息。 一个节点就是在一台机器上安装的Presto实例。 这份配置文件一般情况下是在Presto第一次安装的时候，由部署系统创建的。 一个etc/node.properties配置文件至少包含如下配置信息：&nbsp;</p> 
  <p>node.environment=production&nbsp;<br> node.id=ffffffff-ffff-ffff-ffff-ffffffffffff&nbsp;<br> node.data-dir=/var/presto/data&nbsp;</p> 
  <p>针对上面的配置信息描述如下：</p> 
  <p>node.environment： 集群名称。所有在同一个集群中的Presto节点必须拥有相同的集群名称。&nbsp;<br> node.id： 每个Presto节点的唯一标示。每个节点的node.id都必须是唯一的。在Presto进行重启或者升级过程中每个节点的node.id必须保持不变。如果在一个节点上安装多个Presto实例（例如：在同一台机器上安装多个Presto节点），那么每个Presto节点必须拥有唯一的node.id。&nbsp;<br> node.data-dir： 数据存储目录的位置（操作系统上的路径）。Presto将会把日期和数据存储在这个目录下。</p> 
  <p>使用命令&nbsp;</p> 
  <p>cd ./etc&nbsp;<br> vim node.properties&nbsp;</p> 
  <p>输入配置&nbsp;<br> node.environment=production&nbsp;<br> node.id=a0001&nbsp;<br> node.data-dir=/home/zzq/var/presto/data&nbsp;<br> 如图:&nbsp;<br> &nbsp;<br> 点击esc，输入:wq回车保存退出。</p> 
  <p>JVM配置</p> 
  <p>JVM配置文件，etc/jvm.config， 包含一系列在启动JVM的时候需要使用的命令行选项。这份配置文件的格式是：一系列的选项，每行配置一个单独的选项。由于这些选项不在shell命令中使用。 因此即使将每个选项通过空格或者其他的分隔符分开，java程序也不会将这些选项分开，而是作为一个命令行选项处理。（就像下面例子中的OnOutOfMemoryError选项）。&nbsp;<br> 一个典型的etc/jvm.config配置文件如下：&nbsp;<br> -server&nbsp;<br> -Xmx16G&nbsp;<br> -XX:+UseConcMarkSweepGC&nbsp;<br> -XX:+ExplicitGCInvokesConcurrent&nbsp;<br> -XX:+CMSClassUnloadingEnabled&nbsp;<br> -XX:+AggressiveOpts&nbsp;<br> -XX:+HeapDumpOnOutOfMemoryError&nbsp;<br> -XX:OnOutOfMemoryError=kill -9 %p&nbsp;<br> -XX:ReservedCodeCacheSize=150M&nbsp;<br> 由于OutOfMemoryError将会导致JVM处于不一致状态，所以遇到这种错误的时候我们一般的处理措施就是将dump headp中的信息（用于debugging），然后强制终止进程。</p> 
  <p>Presto会将查询编译成字节码文件，因此Presto会生成很多class，因此我们我们应该增大Perm区的大小（在Perm中主要存储class）并且要允许Jvm class unloading。</p> 
  <p>使用命令</p> 
  <p>vim jvm.config<br> 1<br> 因为我的节点内存比较大为126G，所以可以设置的内存也比较大，我设置为32G。&nbsp;<br> 输入配置&nbsp;<br> -server&nbsp;<br> -Xmx32G&nbsp;<br> -XX:+UseConcMarkSweepGC&nbsp;<br> -XX:+ExplicitGCInvokesConcurrent&nbsp;<br> -XX:+CMSClassUnloadingEnabled&nbsp;<br> -XX:+AggressiveOpts&nbsp;<br> -XX:+HeapDumpOnOutOfMemoryError&nbsp;<br> -XX:OnOutOfMemoryError=kill -9 %p&nbsp;<br> -XX:ReservedCodeCacheSize=300M&nbsp;<br> 如图&nbsp;</p> 
  <p><br> 点击esc，输入:wq回车保存退出。</p> 
  <p>Config Properties</p> 
  <p>Presto的配置文件：etc/config.properties包含了Presto server的所有配置信息。 每个Presto server既是一个coordinator也是一个worker。 但是在大型集群中，处于性能考虑，建议单独用一台机器作为 coordinator。&nbsp;<br> 一个coordinator的etc/config.properties应该至少包含以下信息：&nbsp;<br> 旧版本&nbsp;<br> coordinator=true&nbsp;<br> node-scheduler.include-coordinator=false&nbsp;<br> http-server.http.port=8080&nbsp;<br> task.max-memory=1GB&nbsp;<br> discovery-server.enabled=true&nbsp;<br> discovery.uri=http://example.net:8080</p> 
  <p>新版本&nbsp;<br> coordinator=true&nbsp;<br> node-scheduler.include-coordinator=true&nbsp;<br> http-server.http.port=8080&nbsp;<br> query.max-memory=50GB&nbsp;<br> query.max-memory-per-node=1GB&nbsp;<br> discovery-server.enabled=true&nbsp;<br> discovery.uri=http://example.net:8080</p> 
  <p>以下是最基本的worker配置：&nbsp;<br> 旧版本&nbsp;<br> coordinator=false&nbsp;<br> http-server.http.port=8080&nbsp;<br> task.max-memory=1GB&nbsp;<br> discovery.uri=http://example.net:8080</p> 
  <p>新版本&nbsp;<br> coordinator=false&nbsp;<br> http-server.http.port=8080&nbsp;<br> query.max-memory=50GB&nbsp;<br> query.max-memory-per-node=1GB&nbsp;<br> discovery.uri=http://example.net:8080</p> 
  <p>但是如果你用一台机器进行测试，那么这一台机器将会即作为coordinator，也作为worker。&nbsp;<br> 对配置项解释如下：&nbsp;<br> coordinator：指定是否运维Presto实例作为一个coordinator(接收来自客户端的查询情切管理每个查询的执行过程)。&nbsp;<br> node-scheduler.include-coordinator：是否允许在coordinator服务中进行调度工作(即作为coordinator又作为worker。对于大型的集群，在一个节点上的Presto server即作为coordinator又作为worker将会降低查询性能。因为如果一个服务器作为worker使用，那么大部分的资源都会被worker占用，那么就不会有足够的资源进行关键任务调度、管理和监控查询执行。&nbsp;<br> http-server.http.port：指定HTTP server的端口。Presto 使用 HTTP进行内部和外部的所有通讯。&nbsp;<br> task.max-memory=1GB：一个单独的任务使用的最大内存 (一个查询计划的某个执行部分会在一个特定的节点上执行)。 这个配置参数限制的GROUP BY语句中的Group的数目、JOIN关联中的右关联表的大小、ORDER BY语句中的行数和一个窗口函数中处理的行数。 该参数应该根据并发查询的数量和查询的复杂度进行调整。如果该参数设置的太低，很多查询将不能执行；但是如果设置的太高将会导致JVM把内存耗光。&nbsp;<br> discovery-server.enabled：Presto 通过Discovery 服务来找到集群中所有的节点。为了能够找到集群中所有的节点，每一个Presto实例都会在启动的时候将自己注册到discovery服务。Presto为了简化部署，并且也不想再增加一个新的服务进程，Presto coordinator 可以运行一个内嵌在coordinator 里面的Discovery 服务。这个内嵌的Discovery 服务和Presto共享HTTP server并且使用同样的端口。&nbsp;<br> discovery.uri：Discovery server的URI。由于启用了Presto coordinator内嵌的Discovery 服务，因此这个uri就是Presto coordinator的uri。修改example.net:8080， 根据你的实际环境设置该URI。注意：这个URI一定不能以“/“结尾。</p> 
  <p>使用命令</p> 
  <p>vim config.properties<br> 1<br> 因为是单节点，ip为192.168.30.252，所以输入配置如下:&nbsp;<br> coordinator=true&nbsp;<br> node-scheduler.include-coordinator=true&nbsp;<br> http-server.http.port=8080&nbsp;<br> query.max-memory=50GB&nbsp;<br> query.max-memory-per-node=1GB&nbsp;<br> discovery-server.enabled=true&nbsp;<br> discovery.uri=http://192.168.30.252:8080&nbsp;<br> 如图:&nbsp;<br> &nbsp;<br> 点击esc，输入:wq回车保存退出。</p> 
  <p>日志级别</p> 
  <p>日志配置文件：etc/log.properties。在这个配置文件中允许你根据不同的日志结构设置不同的日志级别。每个logger都有一个名字（通常是使用logger的类的全标示类名）. Loggers通过名字中的“.“来表示层级和集成关系。 (像java里面的包). 如下面的log配置信息：&nbsp;<br> com.facebook.presto=INFO&nbsp;<br> This would set the minimum level to INFO for both com.facebook.presto.server and com.facebook.presto.hive. The default minimum level is INFO (thus the above example does not actually change anything). There are four levels: DEBUG, INFO, WARN and ERROR.</p> 
  <p>使用命令</p> 
  <p>vim log.properties<br> 1<br> 因为考虑到info级别的日志输出会占比较多的空间，我们这里只要ERROR级别的错误。&nbsp;<br> 输入配置&nbsp;<br> com.facebook.presto=ERROR&nbsp;<br> 如图:&nbsp;<br> &nbsp;<br> 点击esc，输入:wq回车保存退出。</p> 
  <p>Catalog Properties</p> 
  <p>Presto通过connectors访问数据。这些connectors挂载在catalogs上。 connector可以提供一个catalog中所有的schema和表。 例如： Hive connector 将每个hive的database都映射成为一个schema， 所以如果hive connector挂载到了名为hive的catalog， 并且在hive的web有一张名为clicks的表， 那么在Presto中可以通过hive.web.clicks来访问这张表。&nbsp;<br> 通过在etc/catalog目录下创建catalog属性文件来完成catalogs的注册。&nbsp;<br> 例如：&nbsp;<br> 如果要创建jmx数据源的连接器，可以创建一个etc/catalog/jmx.properties文件，文件中的内容如下，完成在jmxcatalog上挂载一个jmxconnector：&nbsp;<br> connector.name=jmx</p> 
  <p>如果要创建hive数据源的连接器，可以创建一个etc/catalog/hive.properties文件，文件中的内容如下，完成在hivecatalog上挂载一个hiveconnector：&nbsp;<br> connector.name=hive-hadoop2&nbsp;<br> hive.metastore.uri=thrift://example.net:9083&nbsp;<br> hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</p> 
  <p>参数说明&nbsp;<br> connector.name为连接器名称，hive的话需要加上版本号例如hive-hadoop2&nbsp;<br> hive.metastore.uri需要与hive的metastore地址和端口对应。&nbsp;<br> 一般配置在/etc/hive/conf/hive-site.xml中。&nbsp;</p> 
  <p><br> hive.config.resources需要与hadoop集群的配置路径对应。&nbsp;<br> CDH安装的一般都在/etc/hadoop/conf路径下。&nbsp;<br> 如图:&nbsp;</p> 
  <p>更多信息可以参考&nbsp;<br> hadoop基础—-hadoop实战(十一)—–hadoop管理工具—CDH的目录结构了解</p> 
  <p>我们这里要连接hive，所以应该配置hive的连接器。&nbsp;<br> 使用命令&nbsp;</p> 
  <p>mkdir catalog&nbsp;<br> cd ./catalog&nbsp;<br> vim hive.properties&nbsp;</p> 
  <p>输入配置&nbsp;<br> connector.name=hive-hadoop2&nbsp;<br> hive.metastore.uri=thrift://192.168.30.252:9083&nbsp;<br> hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml</p> 
  <p>更多连接器详细的信息参考&nbsp;<br> https://prestodb.io/docs/current/connector.html</p> 
  <p>如图:&nbsp;<br> &nbsp;<br> 点击esc，输入:wq回车保存退出。</p> 
  <p>配置完毕&nbsp;<br> 最终etc的目录中配置文件如图:&nbsp;</p> 
  <p><br> 启动运行Presto</p> 
  <p>在安装目录的bin/launcher文件，就是启动脚本。Presto可以使用如下命令作为一个后台进程启动：</p> 
  <p><br> cd /home/zzq/presto/presto-server-0.195&nbsp;<br> bin/launcher start&nbsp;</p> 
  <p>另外，也可以在前台运行， 日志和相关输出将会写入stdout/stderr（可以使用类似daemontools的工具捕捉这两个数据流）：</p> 
  <p><br> cd /home/zzq/presto/presto-server-0.195&nbsp;<br> bin/launcher run&nbsp;</p> 
  <p>停止&nbsp;</p> 
  <p>cd /home/zzq/presto/presto-server-0.195&nbsp;<br> bin/launcher stop&nbsp;</p> 
  <p>Presto可以列出支持的命令和命令行选项。&nbsp;</p> 
  <p>cd /home/zzq/presto/presto-server-0.195&nbsp;<br> bin/launcher --help&nbsp;</p> 
  <p>另外可以查看服务进程命令&nbsp;</p> 
  <p>cd /home/zzq/presto/presto-server-0.195&nbsp;<br> bin/launcher status&nbsp;</p> 
  <p>查看进程： ps -aux|grep PrestoServer 或 jps&nbsp;</p> 
  <p><br> 启动完之后，日志将会写在var/log目录下，该目录下有如下文件：</p> 
  <p>launcher.log： 这个日志文件由launcher创建，并且server的stdout和stderr都被重定向到了这个日志文件中。 这份日志文件中只会有很少的信息，包括：&nbsp;<br> 在server日志系统初始化的时候产生的日志和JVM产生的诊断和测试信息。&nbsp;<br> server.log： 这个是Presto使用的主要日志文件。一般情况下，该文件中将会包括server初始化失败时产生的相关信息。这份文件会被自动轮转和压缩。&nbsp;<br> http-request.log： 这是HTTP请求的日志文件，包括server收到的每个HTTP请求信息，这份文件会被自动轮转和压缩。</p> 
  <p>连接hive测试验证</p> 
  <p>下载 presto-cli-0.100-executable.jar：Presto CLI为用户提供了一个用于查询的可交互终端窗口。CLI是一个 可执行 JAR文件, 这也就意味着你可以像UNIX终端窗口一样来使用CLI ，下载地址(注意版本对应):&nbsp;<br> https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/</p> 
  <p>我这里是0.195版本，使用命令</p> 
  <p>wget https://repo1.maven.org/maven2/com/facebook/presto/presto-cli/0.195/presto-cli-0.195-executable.jar<br> 1<br> 文件下载后，重名名为 presto，使用命令</p> 
  <p>mv presto-cli-0.195-executable.jar presto<br> 1<br> 使用 chmod +x 命令设置可执行权限</p> 
  <p>chmod a+x presto<br> 1</p> 
  <p><br> 在hive中查一下hive default库中的表&nbsp;<br> hive自带了一个thrift的客户端———-beeline&nbsp;<br> 打开beeline&nbsp;<br> 使用命令</p> 
  <p>beeline<br> 1<br> 连接hiveserver2&nbsp;<br> 使用命令</p> 
  <p>!connect jdbc:hive2://host253:10000<br> 1<br> （host253是hiveserver2所启动的那台主机名，端口默认是10000）</p> 
  <p>有可能需要输入当前linux用户名和密码。&nbsp;<br> 正常连接上之后会出现&nbsp;<br> 0: jdbc:hive2://host253:10000&gt;&nbsp;<br> 这时可以尝试操作数据库了，使用命令</p> 
  <p>show tables;<br> 1<br> 结果如下图：&nbsp;</p> 
  <p><br> ctrl+c退出hive cli，进入presto cli,使用命令如下:</p> 
  <p>./presto --server 192.168.30.252:8080 --catalog hive --schema default<br> 1<br> 如果要调试，可加 –debug, ip与端口必须与config.properties配置文件中的uri 地址一致，配置的IP就用IP，机器名就用机器名。</p> 
  <p>使用命令</p> 
  <p>show tables;<br> 1<br> 结果如图：&nbsp;</p> 
  <p>与hive中查询的一致，说明presto部署成功可以使用。</p> 
  <p>退出presto cli使用命令</p> 
  <p>quit;<br> 1<br> Presto多节点安装配置</p> 
  <p>架构和集群分配</p> 
  <p>我们在配置Presto多集群时，首先就是要规划架构和集群分配。&nbsp;<br> 一般来说 需要一个coordinator和多个worker。&nbsp;<br> 我们的机子如下</p> 
  <p>则分配如下:&nbsp;<br> hadoop1 (192.169.30.250):coordinator调度节点&nbsp;<br> hadoop2 (192.169.30.251):worker节点&nbsp;<br> hadoop3 (192.169.30.252):worker节点&nbsp;<br> hadoop4 (192.169.30.253):worker节点&nbsp;<br> hadoop5 (192.169.30.217):worker节点</p> 
  <p>下载解压</p> 
  <p>根据单点安装时一样的步骤每一台机子进行下载解压。(也可以把单点时配置好的进行打包上传到其他机子解压)</p> 
  <p>配置修改</p> 
  <p>根据每个节点的定位进行配置创建和修改。&nbsp;<br> 因为大部分配置一样，所以我们把单点的配置打包下载分别上传到其他节点。&nbsp;<br> 需要修改的配置如下:</p> 
  <p>Node Properties</p> 
  <p>使用命令</p> 
  <p>vim etc/node.properties<br> 1<br> 内容如下</p> 
  <p>node.environment=production<br> node.id=ffffffff-ffff-ffff-ffff-ffffffffffff<br> node.data-dir=/var/presto/data<br> 1<br> 2<br> 3<br> 这里每个节点的node.id需要不一样，比如在后面加上001、002等</p> 
  <p>Config Properties</p> 
  <p>coordinator调度节点使用命令</p> 
  <p>vim etc/config.properties<br> 1<br> 内容如下</p> 
  <p>coordinator=true<br> node-scheduler.include-coordinator=false<br> http-server.http.port=8080<br> query.max-memory=50GB<br> query.max-memory-per-node=1GB<br> discovery-server.enabled=true<br> discovery.uri=http://192.168.30.217:8080<br> 1<br> 2<br> 3<br> 4<br> 5<br> 6<br> 7<br> discovery.uri与coordinator调度节点的ip对应。&nbsp;<br> 调度节点只负责调度时node-scheduler.include-coordinator设置为false&nbsp;<br> 调度节点也作为worker时node-scheduler.include-coordinator设置为true</p> 
  <p>worker节点使用命令</p> 
  <p>vim etc/config.properties<br> 1<br> 内容如下</p> 
  <p>coordinator=false<br> http-server.http.port=8080<br> query.max-memory=50GB<br> query.max-memory-per-node=1GB<br> discovery.uri=http://192.168.30.217:8080<br> 1<br> 2<br> 3<br> 4<br> 5<br> 启用与使用</p> 
  <p>启动方式与单点的一样，每台都启动起来即可使用。</p> 
  <p>管理</p> 
  <p>presto提供了Web的管理界面，可以查看多节点的情况。&nbsp;<br> 根据端口来访问，比如8080,则访问&nbsp;<br> http://192.168.30.252:8080/</p> 
  <p>&nbsp;</p> 
  <p>JDBC 连接</p> 
  <pre>
&lt;dependency&gt;
    &lt;groupId&gt;com.facebook.presto&lt;/groupId&gt;
    &lt;artifactId&gt;presto-jdbc&lt;/artifactId&gt;
    &lt;version&gt;0.101&lt;/version&gt;
&lt;/dependency&gt;</pre> 
  <pre>
package presto;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.Statement;

public class PrestoTest {
    public  static  void main(String[] args) throws Exception{
        Class.forName("com.facebook.presto.jdbc.PrestoDriver");
        Connection connection = DriverManager.getConnection("jdbc:presto://192.168.0.241:7777/hive/newbei","root",null);  ;
        Statement stmt = connection.createStatement();
        ResultSet rs = stmt.executeQuery("select * from newbei_test");
        while (rs.next()) {
            System.out.println(rs.getString(1));
        }
        rs.close();
        connection.close();
    }
}</pre> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
