<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>CentOS7搭建Hadoop集群环境 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="CentOS7搭建Hadoop集群环境" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="本文章为云计算课程实验总结。 前言 CentOS7虚拟机搭建hadoop集群，共3个节点：master、slave1、slave2 软件：java1.8 hadoop2.6.0 3台虚拟机都装有CentOS7(最小化安装)系统，一台机命名为 master 作为 namenode，另两台为slave1和slave2，作为 datanode。 虚拟机配置 用户名 Host-IP 网关 HostName（互 ping 时的机器名） 内存 硬盘 HDFS YARN 备注 Master 172.16.24.38 172.16.24.254 master 2GB 40GB NameNode ResourcesManager 集群主节点 Slave1 172.16.24.79 172.16.24.254 slave1 1GB 20GB DataNode NodeManager 计算调度 Slave2 172.16.24.48 172.16.24.254 slave2 1GB 20GB DataNode NodeManager 数据计算节点 注：虚拟机安装及IP地址等信息比较简单，这里不给出。 搭建Hadoop集群环境 （1）设置主机名和 IP 地址分配（/etc/hosts）：修改系统文件需要root权限 master、slave1、slave2三台机器都需要设置，可先在master配置，在复制到slave1、slave2中（也可单独设置）：vi /etc/hosts。 &nbsp; scp /etc/hosts root@slave1:/etc/ #复制/etc/hosts文件到slave1 scp /etc/hosts root@slave2:/etc/ （2）使用root用户为三台虚拟机各自创建一个hadoop账户并为其设置密码，专门负责操作与 hadoop 相关的业务。 useradd hadoop #创建hadoop用户 passwd hadoop #为hadoop设置密码 （3）设置三台机器之间免密码登陆：（使用 hadoop 用户） 在 master 机器上使用 hadoop 用户生成 master 机器节点的 hadoop 账户密钥对：ssh-keygen -t rsa 。 &nbsp; &nbsp; 在 master 机器上为 slave1 和 slave2 生成各自的密钥对。 ssh slave1 ssh-keygen -t rsa ssh slave2 ssh-keygen -t rsa 将所有的公钥文件汇总到master机器上的一个总的授权key文件 authorized_keys 中。 scp hadoop@slave1:~/.ssh/id_rsa.pub ~/.ssh/slave1.pub scp hadoop@slave2:~/.ssh/id_rsa.pub ~/.ssh/slave2.pub cat ~/.ssh/*.pub &gt; /.ssh/authorized_keys 出于安全性考虑，将这个授权 key 文件 authorized_keys 赋予 600 权限 chmod 600 .ssh/authorized_keys 将authorized_keys 认证文件复制到所有节点主机的~/.ssh/目录下，并进行验证互信。 scp ~/.ssh/authorized_keys hadoop@slave1:~/.ssh #将authorized_keys认证文件复制到slave1的hadoop用户家目录的.ssh目录下 scp ~/.ssh/authorized_keys hadoop@slave2:~/.ssh 测试免密码连接 ssh slave1 ssh slave2 （4）安装java 创建统一管理 java 和 hadoop 的父级目录chadoop，位于 hadoop 用户主目录下/home/hadoop mkdir ~/chadoop #父级目录 mkdir ~/chadoop/java #java安装目录 解压 jdk 安装包并把解压内容移至~/chadoop/java目录下 tar zxf jdk-8u201-linux-x64.tar.gz #解压jdk mv jdk1.8.0_201 ~/chadoop/java 修改环境变量（~/.bash_profile）：加入 JAVA_HOME,CLASSPATH 和 PATH 注：HADOOP_HOME 与 HADOOP_CONF_DIR为hadoop环境变量，这里提前配置好(当然，你也可以稍后安装hadoop再配置)。 export JAVA_HOME=~/chadoop/java/jdk1.8.0_201 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export HADOOP_HOME=~/chadoop/hadoop/hadoop-2.6.0 export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 配置后使用 . ~/.bash_profile 立即生效，使用 java –version 命令进行检测 java 是否安装成功。 （5）安装hadoop(与安装java类似) 解压hadoop tar zxf hadoop-2.6.0.tar.gz mkdir ~/chadoop/hadoop mv hadoop-2.6.0 ~/chadoop/hadoop 创建 hadoop 相关的 tmp 目录和 dfs 目录（以及其下的 name 和 data 目录） mkdir ~/chadoop/tmp mkdir -p ~/chadoop/dfs/name ~/chadoop/dfs/data 为 hadoop 配置环境变量（~/.bash_profile） 注：配置java环境时已配置（HADOOP_HOME 与 HADOOP_CONF_DIR） 修改 hadoop 内置文件，配置集群模式。 涉及修改文件：core-site.xml，hdfs-site.xml， mapred-site.xml，yarn-site.xml，hadoop-env.sh， mapred-env.sh，yarn-env.sh 和 slaves（均位于$HADOOP_HOME 下的/etc/hadoop 文件夹下） ①配置core-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;fs.defaultFS&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;hdfs://master:9000&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;file:/home/hadoop/chadoop/tmp&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;io.file.buffer.size&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;131072&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ②配置hdfs-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;/home/hadoop/chadoop/dfs/name&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;namenode 的目录位置&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;/home/hadoop/chadoop/dfs/data&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;datanode 的目录位置&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.replication&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;2&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;hdfs 系统的副本数量&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:9001&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;备份 namenode 的 http 地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;true&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;hdfs 文件系统的 webhdfs 使能标致&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ③配置mapred-site.xml 注mapred-site.xml需要先复制模板生成配置文件后修改内容：cp mapred-site.xml.template mapred-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.framework.name&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;yarn&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;指明 MapRreduce 的调度框架为 yarn&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:10020&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;知名 MapReduce 的作业历史地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:19888&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;指明 MapReduce 的作业历史 web 地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ④配置yarn-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18040&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18030&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18088&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18025&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18141&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;mapreduce_shuffle&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ⑤配置hadoop-env.sh：指明 JAVA_HOME 位置 ⑥配置mapred-env.sh：指明JAVA_HOME 位置，同上。 ⑦配置yarn-env.sh：指明JAVA_HOME 位置，同上。 ⑧配置slaves：加入两个节点的名称。 （6）将 master 主节点以上配置复制到 slave1、slave2 节点。 scp ~/.bash_profile hadoop@slave1:~/ #将.bash_profile文件复制到slave1 scp ~/.bash_profile hadoop@slave2:~/ ​ ssh hadoop@slave1. ~/.bash_profile #使slave1的.bash_profile文件生效 ssh hadoop@slave2. ~/.bash_profile ​ scp -r chadoop/ hadoop@slave1:~ #将chadoop文件夹内容复制到slave1:包括java与hadoop scp -r chadoop/ hadoop@slave2:~ （7）在 master 主节点上格式化 hdfs 文件系统。 hdfs namenode -foramt （8）关闭3台虚拟机的防火墙：需要root权限 systemctl stop firewalld #关闭防火墙 systemctl disable firewalld #禁止开机自启动 ​ #关闭slave机器可通过ssh方式关闭，也可在slave主机关闭 #ssh slave1 #....关闭防火墙 #ssh slave2 #....关闭防火墙 （9）在 master 机器上启动 hadoop，并用 jps 检验 hadoop 进程。 master 主节点有 4 个：ResourceManager，Jps，NameNode，SecondaryNamenode slave1 节点与 slave2 节点各有 3 个：NodeManager，DataNode，Jps start-all.sh #启动hadoop jps #查看hadoop节点信息 stop-all.sh #关闭hadoop &nbsp; 以上，hadoop三节点（master、slave1、slave2）集群环境也搭建完毕。 &nbsp; 更 问题1：为啥集群要关闭防火墙？ 答：不关闭防火墙的话，集群之间操作容易出现错误。 问题2：关闭了防火墙，集群岂不是保障不了安全？ 答：集群其实没什么安全性考虑的。因为都是内网搭建的，对外还有一个服务器的，那个服务器有防火墙，由它来访问内网集群，如果内网内开启防火墙，内网集群之间通信会出现很多问题。" />
<meta property="og:description" content="本文章为云计算课程实验总结。 前言 CentOS7虚拟机搭建hadoop集群，共3个节点：master、slave1、slave2 软件：java1.8 hadoop2.6.0 3台虚拟机都装有CentOS7(最小化安装)系统，一台机命名为 master 作为 namenode，另两台为slave1和slave2，作为 datanode。 虚拟机配置 用户名 Host-IP 网关 HostName（互 ping 时的机器名） 内存 硬盘 HDFS YARN 备注 Master 172.16.24.38 172.16.24.254 master 2GB 40GB NameNode ResourcesManager 集群主节点 Slave1 172.16.24.79 172.16.24.254 slave1 1GB 20GB DataNode NodeManager 计算调度 Slave2 172.16.24.48 172.16.24.254 slave2 1GB 20GB DataNode NodeManager 数据计算节点 注：虚拟机安装及IP地址等信息比较简单，这里不给出。 搭建Hadoop集群环境 （1）设置主机名和 IP 地址分配（/etc/hosts）：修改系统文件需要root权限 master、slave1、slave2三台机器都需要设置，可先在master配置，在复制到slave1、slave2中（也可单独设置）：vi /etc/hosts。 &nbsp; scp /etc/hosts root@slave1:/etc/ #复制/etc/hosts文件到slave1 scp /etc/hosts root@slave2:/etc/ （2）使用root用户为三台虚拟机各自创建一个hadoop账户并为其设置密码，专门负责操作与 hadoop 相关的业务。 useradd hadoop #创建hadoop用户 passwd hadoop #为hadoop设置密码 （3）设置三台机器之间免密码登陆：（使用 hadoop 用户） 在 master 机器上使用 hadoop 用户生成 master 机器节点的 hadoop 账户密钥对：ssh-keygen -t rsa 。 &nbsp; &nbsp; 在 master 机器上为 slave1 和 slave2 生成各自的密钥对。 ssh slave1 ssh-keygen -t rsa ssh slave2 ssh-keygen -t rsa 将所有的公钥文件汇总到master机器上的一个总的授权key文件 authorized_keys 中。 scp hadoop@slave1:~/.ssh/id_rsa.pub ~/.ssh/slave1.pub scp hadoop@slave2:~/.ssh/id_rsa.pub ~/.ssh/slave2.pub cat ~/.ssh/*.pub &gt; /.ssh/authorized_keys 出于安全性考虑，将这个授权 key 文件 authorized_keys 赋予 600 权限 chmod 600 .ssh/authorized_keys 将authorized_keys 认证文件复制到所有节点主机的~/.ssh/目录下，并进行验证互信。 scp ~/.ssh/authorized_keys hadoop@slave1:~/.ssh #将authorized_keys认证文件复制到slave1的hadoop用户家目录的.ssh目录下 scp ~/.ssh/authorized_keys hadoop@slave2:~/.ssh 测试免密码连接 ssh slave1 ssh slave2 （4）安装java 创建统一管理 java 和 hadoop 的父级目录chadoop，位于 hadoop 用户主目录下/home/hadoop mkdir ~/chadoop #父级目录 mkdir ~/chadoop/java #java安装目录 解压 jdk 安装包并把解压内容移至~/chadoop/java目录下 tar zxf jdk-8u201-linux-x64.tar.gz #解压jdk mv jdk1.8.0_201 ~/chadoop/java 修改环境变量（~/.bash_profile）：加入 JAVA_HOME,CLASSPATH 和 PATH 注：HADOOP_HOME 与 HADOOP_CONF_DIR为hadoop环境变量，这里提前配置好(当然，你也可以稍后安装hadoop再配置)。 export JAVA_HOME=~/chadoop/java/jdk1.8.0_201 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export HADOOP_HOME=~/chadoop/hadoop/hadoop-2.6.0 export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 配置后使用 . ~/.bash_profile 立即生效，使用 java –version 命令进行检测 java 是否安装成功。 （5）安装hadoop(与安装java类似) 解压hadoop tar zxf hadoop-2.6.0.tar.gz mkdir ~/chadoop/hadoop mv hadoop-2.6.0 ~/chadoop/hadoop 创建 hadoop 相关的 tmp 目录和 dfs 目录（以及其下的 name 和 data 目录） mkdir ~/chadoop/tmp mkdir -p ~/chadoop/dfs/name ~/chadoop/dfs/data 为 hadoop 配置环境变量（~/.bash_profile） 注：配置java环境时已配置（HADOOP_HOME 与 HADOOP_CONF_DIR） 修改 hadoop 内置文件，配置集群模式。 涉及修改文件：core-site.xml，hdfs-site.xml， mapred-site.xml，yarn-site.xml，hadoop-env.sh， mapred-env.sh，yarn-env.sh 和 slaves（均位于$HADOOP_HOME 下的/etc/hadoop 文件夹下） ①配置core-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;fs.defaultFS&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;hdfs://master:9000&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;file:/home/hadoop/chadoop/tmp&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;io.file.buffer.size&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;131072&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ②配置hdfs-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;/home/hadoop/chadoop/dfs/name&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;namenode 的目录位置&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;/home/hadoop/chadoop/dfs/data&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;datanode 的目录位置&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.replication&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;2&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;hdfs 系统的副本数量&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:9001&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;备份 namenode 的 http 地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;true&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;hdfs 文件系统的 webhdfs 使能标致&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ③配置mapred-site.xml 注mapred-site.xml需要先复制模板生成配置文件后修改内容：cp mapred-site.xml.template mapred-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.framework.name&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;yarn&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;指明 MapRreduce 的调度框架为 yarn&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:10020&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;知名 MapReduce 的作业历史地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:19888&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;指明 MapReduce 的作业历史 web 地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ④配置yarn-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18040&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18030&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18088&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18025&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18141&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;mapreduce_shuffle&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ⑤配置hadoop-env.sh：指明 JAVA_HOME 位置 ⑥配置mapred-env.sh：指明JAVA_HOME 位置，同上。 ⑦配置yarn-env.sh：指明JAVA_HOME 位置，同上。 ⑧配置slaves：加入两个节点的名称。 （6）将 master 主节点以上配置复制到 slave1、slave2 节点。 scp ~/.bash_profile hadoop@slave1:~/ #将.bash_profile文件复制到slave1 scp ~/.bash_profile hadoop@slave2:~/ ​ ssh hadoop@slave1. ~/.bash_profile #使slave1的.bash_profile文件生效 ssh hadoop@slave2. ~/.bash_profile ​ scp -r chadoop/ hadoop@slave1:~ #将chadoop文件夹内容复制到slave1:包括java与hadoop scp -r chadoop/ hadoop@slave2:~ （7）在 master 主节点上格式化 hdfs 文件系统。 hdfs namenode -foramt （8）关闭3台虚拟机的防火墙：需要root权限 systemctl stop firewalld #关闭防火墙 systemctl disable firewalld #禁止开机自启动 ​ #关闭slave机器可通过ssh方式关闭，也可在slave主机关闭 #ssh slave1 #....关闭防火墙 #ssh slave2 #....关闭防火墙 （9）在 master 机器上启动 hadoop，并用 jps 检验 hadoop 进程。 master 主节点有 4 个：ResourceManager，Jps，NameNode，SecondaryNamenode slave1 节点与 slave2 节点各有 3 个：NodeManager，DataNode，Jps start-all.sh #启动hadoop jps #查看hadoop节点信息 stop-all.sh #关闭hadoop &nbsp; 以上，hadoop三节点（master、slave1、slave2）集群环境也搭建完毕。 &nbsp; 更 问题1：为啥集群要关闭防火墙？ 答：不关闭防火墙的话，集群之间操作容易出现错误。 问题2：关闭了防火墙，集群岂不是保障不了安全？ 答：集群其实没什么安全性考虑的。因为都是内网搭建的，对外还有一个服务器的，那个服务器有防火墙，由它来访问内网集群，如果内网内开启防火墙，内网集群之间通信会出现很多问题。" />
<link rel="canonical" href="https://mlh.app/2019/04/05/728742.html" />
<meta property="og:url" content="https://mlh.app/2019/04/05/728742.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-05T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"本文章为云计算课程实验总结。 前言 CentOS7虚拟机搭建hadoop集群，共3个节点：master、slave1、slave2 软件：java1.8 hadoop2.6.0 3台虚拟机都装有CentOS7(最小化安装)系统，一台机命名为 master 作为 namenode，另两台为slave1和slave2，作为 datanode。 虚拟机配置 用户名 Host-IP 网关 HostName（互 ping 时的机器名） 内存 硬盘 HDFS YARN 备注 Master 172.16.24.38 172.16.24.254 master 2GB 40GB NameNode ResourcesManager 集群主节点 Slave1 172.16.24.79 172.16.24.254 slave1 1GB 20GB DataNode NodeManager 计算调度 Slave2 172.16.24.48 172.16.24.254 slave2 1GB 20GB DataNode NodeManager 数据计算节点 注：虚拟机安装及IP地址等信息比较简单，这里不给出。 搭建Hadoop集群环境 （1）设置主机名和 IP 地址分配（/etc/hosts）：修改系统文件需要root权限 master、slave1、slave2三台机器都需要设置，可先在master配置，在复制到slave1、slave2中（也可单独设置）：vi /etc/hosts。 &nbsp; scp /etc/hosts root@slave1:/etc/ #复制/etc/hosts文件到slave1 scp /etc/hosts root@slave2:/etc/ （2）使用root用户为三台虚拟机各自创建一个hadoop账户并为其设置密码，专门负责操作与 hadoop 相关的业务。 useradd hadoop #创建hadoop用户 passwd hadoop #为hadoop设置密码 （3）设置三台机器之间免密码登陆：（使用 hadoop 用户） 在 master 机器上使用 hadoop 用户生成 master 机器节点的 hadoop 账户密钥对：ssh-keygen -t rsa 。 &nbsp; &nbsp; 在 master 机器上为 slave1 和 slave2 生成各自的密钥对。 ssh slave1 ssh-keygen -t rsa ssh slave2 ssh-keygen -t rsa 将所有的公钥文件汇总到master机器上的一个总的授权key文件 authorized_keys 中。 scp hadoop@slave1:~/.ssh/id_rsa.pub ~/.ssh/slave1.pub scp hadoop@slave2:~/.ssh/id_rsa.pub ~/.ssh/slave2.pub cat ~/.ssh/*.pub &gt; /.ssh/authorized_keys 出于安全性考虑，将这个授权 key 文件 authorized_keys 赋予 600 权限 chmod 600 .ssh/authorized_keys 将authorized_keys 认证文件复制到所有节点主机的~/.ssh/目录下，并进行验证互信。 scp ~/.ssh/authorized_keys hadoop@slave1:~/.ssh #将authorized_keys认证文件复制到slave1的hadoop用户家目录的.ssh目录下 scp ~/.ssh/authorized_keys hadoop@slave2:~/.ssh 测试免密码连接 ssh slave1 ssh slave2 （4）安装java 创建统一管理 java 和 hadoop 的父级目录chadoop，位于 hadoop 用户主目录下/home/hadoop mkdir ~/chadoop #父级目录 mkdir ~/chadoop/java #java安装目录 解压 jdk 安装包并把解压内容移至~/chadoop/java目录下 tar zxf jdk-8u201-linux-x64.tar.gz #解压jdk mv jdk1.8.0_201 ~/chadoop/java 修改环境变量（~/.bash_profile）：加入 JAVA_HOME,CLASSPATH 和 PATH 注：HADOOP_HOME 与 HADOOP_CONF_DIR为hadoop环境变量，这里提前配置好(当然，你也可以稍后安装hadoop再配置)。 export JAVA_HOME=~/chadoop/java/jdk1.8.0_201 export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export HADOOP_HOME=~/chadoop/hadoop/hadoop-2.6.0 export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 配置后使用 . ~/.bash_profile 立即生效，使用 java –version 命令进行检测 java 是否安装成功。 （5）安装hadoop(与安装java类似) 解压hadoop tar zxf hadoop-2.6.0.tar.gz mkdir ~/chadoop/hadoop mv hadoop-2.6.0 ~/chadoop/hadoop 创建 hadoop 相关的 tmp 目录和 dfs 目录（以及其下的 name 和 data 目录） mkdir ~/chadoop/tmp mkdir -p ~/chadoop/dfs/name ~/chadoop/dfs/data 为 hadoop 配置环境变量（~/.bash_profile） 注：配置java环境时已配置（HADOOP_HOME 与 HADOOP_CONF_DIR） 修改 hadoop 内置文件，配置集群模式。 涉及修改文件：core-site.xml，hdfs-site.xml， mapred-site.xml，yarn-site.xml，hadoop-env.sh， mapred-env.sh，yarn-env.sh 和 slaves（均位于$HADOOP_HOME 下的/etc/hadoop 文件夹下） ①配置core-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;fs.defaultFS&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;hdfs://master:9000&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;file:/home/hadoop/chadoop/tmp&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;io.file.buffer.size&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;131072&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ②配置hdfs-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;/home/hadoop/chadoop/dfs/name&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;namenode 的目录位置&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;/home/hadoop/chadoop/dfs/data&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;datanode 的目录位置&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.replication&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;2&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;hdfs 系统的副本数量&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:9001&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;备份 namenode 的 http 地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;true&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;hdfs 文件系统的 webhdfs 使能标致&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ③配置mapred-site.xml 注mapred-site.xml需要先复制模板生成配置文件后修改内容：cp mapred-site.xml.template mapred-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.framework.name&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;yarn&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;指明 MapRreduce 的调度框架为 yarn&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:10020&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;知名 MapReduce 的作业历史地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:19888&lt;/value&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;指明 MapReduce 的作业历史 web 地址&lt;/description&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ④配置yarn-site.xml &lt;configuration&gt; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18040&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18030&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18088&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18025&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18141&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;mapreduce_shuffle&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;property&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &nbsp; &nbsp;&lt;/property&gt; &lt;/configuration&gt; ⑤配置hadoop-env.sh：指明 JAVA_HOME 位置 ⑥配置mapred-env.sh：指明JAVA_HOME 位置，同上。 ⑦配置yarn-env.sh：指明JAVA_HOME 位置，同上。 ⑧配置slaves：加入两个节点的名称。 （6）将 master 主节点以上配置复制到 slave1、slave2 节点。 scp ~/.bash_profile hadoop@slave1:~/ #将.bash_profile文件复制到slave1 scp ~/.bash_profile hadoop@slave2:~/ ​ ssh hadoop@slave1. ~/.bash_profile #使slave1的.bash_profile文件生效 ssh hadoop@slave2. ~/.bash_profile ​ scp -r chadoop/ hadoop@slave1:~ #将chadoop文件夹内容复制到slave1:包括java与hadoop scp -r chadoop/ hadoop@slave2:~ （7）在 master 主节点上格式化 hdfs 文件系统。 hdfs namenode -foramt （8）关闭3台虚拟机的防火墙：需要root权限 systemctl stop firewalld #关闭防火墙 systemctl disable firewalld #禁止开机自启动 ​ #关闭slave机器可通过ssh方式关闭，也可在slave主机关闭 #ssh slave1 #....关闭防火墙 #ssh slave2 #....关闭防火墙 （9）在 master 机器上启动 hadoop，并用 jps 检验 hadoop 进程。 master 主节点有 4 个：ResourceManager，Jps，NameNode，SecondaryNamenode slave1 节点与 slave2 节点各有 3 个：NodeManager，DataNode，Jps start-all.sh #启动hadoop jps #查看hadoop节点信息 stop-all.sh #关闭hadoop &nbsp; 以上，hadoop三节点（master、slave1、slave2）集群环境也搭建完毕。 &nbsp; 更 问题1：为啥集群要关闭防火墙？ 答：不关闭防火墙的话，集群之间操作容易出现错误。 问题2：关闭了防火墙，集群岂不是保障不了安全？ 答：集群其实没什么安全性考虑的。因为都是内网搭建的，对外还有一个服务器的，那个服务器有防火墙，由它来访问内网集群，如果内网内开启防火墙，内网集群之间通信会出现很多问题。","@type":"BlogPosting","url":"https://mlh.app/2019/04/05/728742.html","headline":"CentOS7搭建Hadoop集群环境","dateModified":"2019-04-05T00:00:00+08:00","datePublished":"2019-04-05T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/04/05/728742.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>CentOS7搭建Hadoop集群环境</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>本文章为<strong>云计算课程</strong>实验总结。</p> 
  <h2>前言</h2> 
  <ul>
   <li> <p>CentOS7虚拟机搭建hadoop集群，共3个节点：master、slave1、slave2</p> </li> 
   <li> <p>软件：java1.8 hadoop2.6.0</p> </li> 
   <li> <p>3台虚拟机都装有CentOS7(最小化安装)系统，一台机命名为 master 作为 namenode，另两台为slave1和slave2，作为 datanode。</p> </li> 
  </ul>
  <h2>虚拟机配置</h2> 
  <table>
   <thead>
    <tr>
     <th>用户名</th> 
     <th>Host-IP</th> 
     <th>网关</th> 
     <th>HostName（互 ping 时的机器名）</th> 
     <th>内存</th> 
     <th>硬盘</th> 
     <th>HDFS</th> 
     <th>YARN</th> 
     <th>备注</th> 
    </tr>
   </thead>
   <tbody>
    <tr>
     <td>Master</td> 
     <td>172.16.24.38</td> 
     <td>172.16.24.254</td> 
     <td>master</td> 
     <td>2GB</td> 
     <td>40GB</td> 
     <td>NameNode</td> 
     <td>ResourcesManager</td> 
     <td>集群主节点</td> 
    </tr>
    <tr>
     <td>Slave1</td> 
     <td>172.16.24.79</td> 
     <td>172.16.24.254</td> 
     <td>slave1</td> 
     <td>1GB</td> 
     <td>20GB</td> 
     <td>DataNode</td> 
     <td>NodeManager</td> 
     <td>计算调度</td> 
    </tr>
    <tr>
     <td>Slave2</td> 
     <td>172.16.24.48</td> 
     <td>172.16.24.254</td> 
     <td>slave2</td> 
     <td>1GB</td> 
     <td>20GB</td> 
     <td>DataNode</td> 
     <td>NodeManager</td> 
     <td>数据计算节点</td> 
    </tr>
   </tbody>
  </table>
  <p><span style="color:#f33b45;">注：虚拟机安装及IP地址等信息比较简单，这里不给出。</span></p> 
  <h2>搭建Hadoop集群环境</h2> 
  <p><strong>（1）设置主机名和 IP 地址分配（/etc/hosts）：修改系统文件需要root权限</strong></p> 
  <p>master、slave1、slave2三台机器都需要设置，可先在master配置，在复制到slave1、slave2中（也可单独设置）：<code>vi /etc/hosts</code>。</p> 
  <p>&nbsp;</p> 
  <p style="text-align:center;"><img alt="" class="has" height="173" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190405230312738.png" width="694"></p> 
  <pre class="has">
<code class="language-html">scp /etc/hosts root@slave1:/etc/    #复制/etc/hosts文件到slave1
scp /etc/hosts root@slave2:/etc/</code></pre> 
  <p><strong>（2）使用root用户为三台虚拟机各自创建一个hadoop账户并为其设置密码，专门负责操作与 hadoop 相关的业务。</strong></p> 
  <pre class="has">
<code class="language-html">useradd hadoop  #创建hadoop用户
passwd hadoop   #为hadoop设置密码</code></pre> 
  <p><strong>（3）设置三台机器之间免密码登陆：（使用 hadoop 用户）</strong></p> 
  <ol>
   <li> <p>在 master 机器上<strong>使用 hadoop 用户</strong>生成 master 机器节点的 hadoop 账户密钥对：<code>ssh-keygen -t rsa</code> 。</p> <p>&nbsp;</p> <p style="text-align:center;"><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019040523080971.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xfenp3d2Vu,size_16,color_FFFFFF,t_70"></p> <p>&nbsp;</p> </li> 
   <li> <p>在 master 机器上为 slave1 和 slave2 生成各自的密钥对。</p> <pre class="has">
<code class="language-html">ssh slave1 ssh-keygen -t rsa
ssh slave2 ssh-keygen -t rsa</code></pre> </li> 
   <li> <p>将所有的公钥文件汇总到master机器上的一个总的授权key文件 authorized_keys 中。</p> <pre class="has">
<code>scp hadoop@slave1:~/.ssh/id_rsa.pub ~/.ssh/slave1.pub
scp hadoop@slave2:~/.ssh/id_rsa.pub ~/.ssh/slave2.pub
cat ~/.ssh/*.pub &gt; /.ssh/authorized_keys</code></pre> </li> 
   <li> <p>出于安全性考虑，将这个授权 key 文件 authorized_keys 赋予 600 权限</p> <pre class="has">
<code class="language-html">chmod 600 .ssh/authorized_keys</code></pre> </li> 
   <li> <p>将authorized_keys 认证文件复制到所有节点主机的~/.ssh/目录下，并进行验证互信。</p> <pre class="has">
<code class="language-html">scp ~/.ssh/authorized_keys hadoop@slave1:~/.ssh     #将authorized_keys认证文件复制到slave1的hadoop用户家目录的.ssh目录下
scp ~/.ssh/authorized_keys hadoop@slave2:~/.ssh </code></pre> <p>测试免密码连接</p> <pre class="has">
<code class="language-html">ssh slave1
ssh slave2</code></pre> </li> 
  </ol>
  <p><strong>（4）安装java</strong></p> 
  <ol>
   <li> <p>创建统一管理 java 和 hadoop 的父级目录chadoop，位于 hadoop 用户主目录下/home/hadoop</p> <pre class="has">
<code class="language-html">mkdir ~/chadoop         #父级目录
mkdir ~/chadoop/java    #java安装目录</code></pre> </li> 
   <li> <p>解压 jdk 安装包并把解压内容移至~/chadoop/java目录下</p> <pre class="has">
<code class="language-html">tar zxf jdk-8u201-linux-x64.tar.gz      #解压jdk
mv jdk1.8.0_201 ~/chadoop/java          </code></pre> <p><img alt="" class="has" height="139" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190405230851907.png" width="599"></p> </li> 
   <li> <p>修改环境变量（~/.bash_profile）：加入 JAVA_HOME,CLASSPATH 和 PATH</p> <p><span style="color:#f33b45;">注：HADOOP_HOME 与 HADOOP_CONF_DIR为hadoop环境变量，这里提前配置好(当然，你也可以稍后安装hadoop再配置)。</span></p> <pre class="has">
<code>export JAVA_HOME=~/chadoop/java/jdk1.8.0_201 
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export HADOOP_HOME=~/chadoop/hadoop/hadoop-2.6.0
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export PATH=$JAVA_HOME/bin:$JAVA_HOME/jre/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 
</code></pre> <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190405230914589.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xfenp3d2Vu,size_16,color_FFFFFF,t_70"></p> <p>配置后使用 <code>. ~/.bash_profile</code> 立即生效，使用 java –version 命令进行检测 java 是否安装成功。</p> <p><img alt="" class="has" height="137" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190405230936659.png" width="597"></p> </li> 
  </ol>
  <p><strong>（5）安装hadoop(与安装java类似)</strong></p> 
  <ol>
   <li> <p>解压hadoop</p> <pre class="has">
<code class="language-html">tar zxf hadoop-2.6.0.tar.gz
mkdir ~/chadoop/hadoop
mv hadoop-2.6.0 ~/chadoop/hadoop</code></pre> </li> 
   <li> <p>创建 hadoop 相关的 tmp 目录和 dfs 目录（以及其下的 name 和 data 目录）</p> <pre class="has">
<code class="language-html">mkdir ~/chadoop/tmp
mkdir -p ~/chadoop/dfs/name ~/chadoop/dfs/data </code></pre> </li> 
   <li> <p>为 hadoop 配置环境变量（~/.bash_profile）</p> <p><span style="color:#f33b45;">注：配置java环境时已配置（HADOOP_HOME 与 HADOOP_CONF_DIR）</span></p> </li> 
   <li> <p>修改 hadoop 内置文件，配置集群模式。</p> <p>涉及修改文件：<code>core-site.xml</code>，<code>hdfs-site.xml</code>， <code>mapred-site.xml</code>，<code>yarn-site.xml</code>，<code>hadoop-env.sh</code>， <code>mapred-env.sh</code>，<code>yarn-env.sh</code> 和 <code>slaves</code>（均位于$HADOOP_HOME 下的/etc/hadoop 文件夹下）</p> <p><strong>①配置<code>core-site.xml</code></strong></p> <pre class="has">
<code class="language-html">&lt;configuration&gt;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;fs.defaultFS&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;hdfs://master:9000&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;file:/home/hadoop/chadoop/tmp&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;io.file.buffer.size&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;131072&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
&lt;/configuration&gt;</code></pre> <p><strong>②配置<code>hdfs-site.xml</code></strong></p> <pre class="has">
<code class="language-html">&lt;configuration&gt; 
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;/home/hadoop/chadoop/dfs/name&lt;/value&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;namenode 的目录位置&lt;/description&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;/home/hadoop/chadoop/dfs/data&lt;/value&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;datanode 的目录位置&lt;/description&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.replication&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;2&lt;/value&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;hdfs 系统的副本数量&lt;/description&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:9001&lt;/value&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;备份 namenode 的 http 地址&lt;/description&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;true&lt;/value&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;hdfs 文件系统的 webhdfs 使能标致&lt;/description&gt;
 &nbsp; &nbsp;&lt;/property&gt;
&lt;/configuration&gt;</code></pre> <p><strong>③配置<code>mapred-site.xml</code></strong></p> <p><span style="color:#f33b45;">注<code>mapred-site.xml</code>需要先复制模板生成配置文件后修改内容：<code>cp mapred-site.xml.template mapred-site.xml</code></span></p> <pre class="has">
<code class="language-html">&lt;configuration&gt;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;yarn&lt;/value&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;指明 MapRreduce 的调度框架为 yarn&lt;/description&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:10020&lt;/value&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;知名 MapReduce 的作业历史地址&lt;/description&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:19888&lt;/value&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;description&gt;指明 MapReduce 的作业历史 web 地址&lt;/description&gt;
 &nbsp; &nbsp;&lt;/property&gt;
&lt;/configuration&gt; </code></pre> <p><strong>④配置<code>yarn-site.xml</code></strong></p> <pre class="has">
<code class="language-html">&lt;configuration&gt;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.address&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18040&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18030&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18088&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18025&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;master:18141&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
 &nbsp; &nbsp;
 &nbsp; &nbsp;&lt;property&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
 &nbsp; &nbsp; &nbsp; &nbsp;&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
 &nbsp; &nbsp;&lt;/property&gt;
&lt;/configuration&gt;</code></pre> <p><strong>⑤配置<code>hadoop-env.sh</code></strong>：指明 JAVA_HOME 位置</p> <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190405231001731.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xfenp3d2Vu,size_16,color_FFFFFF,t_70"></p> <p><strong>⑥配置<code>mapred-env.sh</code></strong>：指明JAVA_HOME 位置，同上。</p> <p><strong>⑦配置<code>yarn-env.sh</code></strong>：指明JAVA_HOME 位置，同上。</p> <p><strong>⑧配置<code>slaves</code></strong>：加入两个节点的名称。</p> <p><img alt="" class="has" height="153" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190405231020431.png" width="364"></p> </li> 
  </ol>
  <p><strong>（6）将 master 主节点以上配置复制到 slave1、slave2 节点。</strong></p> 
  <pre class="has">
<code class="language-html">scp ~/.bash_profile hadoop@slave1:~/    #将.bash_profile文件复制到slave1
scp ~/.bash_profile hadoop@slave2:~/
​
ssh hadoop@slave1. ~/.bash_profile      #使slave1的.bash_profile文件生效
ssh hadoop@slave2. ~/.bash_profile
​
scp -r chadoop/ hadoop@slave1:~         #将chadoop文件夹内容复制到slave1:包括java与hadoop
scp -r chadoop/ hadoop@slave2:~ </code></pre> 
  <p><strong>（7）在 master 主节点上格式化 hdfs 文件系统。</strong></p> 
  <pre class="has">
<code class="language-html">hdfs namenode -foramt</code></pre> 
  <p><strong>（8）关闭3台虚拟机的防火墙：需要root权限</strong></p> 
  <pre class="has">
<code class="language-html">systemctl stop firewalld        #关闭防火墙
systemctl disable firewalld     #禁止开机自启动
​
#关闭slave机器可通过ssh方式关闭，也可在slave主机关闭
#ssh slave1
#....关闭防火墙
#ssh slave2
#....关闭防火墙</code></pre> 
  <p><strong>（9）在 master 机器上启动 hadoop，并用 jps 检验 hadoop 进程。</strong></p> 
  <ul>
   <li> <p>master 主节点有 4 个：ResourceManager，Jps，NameNode，SecondaryNamenode</p> </li> 
   <li> <p>slave1 节点与 slave2 节点各有 3 个：NodeManager，DataNode，Jps</p> </li> 
  </ul>
  <pre class="has">
<code class="language-html">start-all.sh    #启动hadoop
jps             #查看hadoop节点信息
stop-all.sh     #关闭hadoop</code></pre> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190405231049233.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xfenp3d2Vu,size_16,color_FFFFFF,t_70"></p> 
  <p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190405231058908.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xfenp3d2Vu,size_16,color_FFFFFF,t_70"></p> 
  <p>&nbsp;</p> 
  <p>以上，hadoop三节点（master、slave1、slave2）集群环境也搭建完毕。</p> 
  <p>&nbsp;</p> 
  <p>更</p> 
  <p>问题1：为啥集群要关闭防火墙？</p> 
  <p>答：不关闭防火墙的话，集群之间操作容易出现错误。</p> 
  <p>问题2：关闭了防火墙，集群岂不是保障不了安全？</p> 
  <p>答：集群其实没什么安全性考虑的。因为都是内网搭建的，对外还有一个服务器的，那个服务器有防火墙，由它来访问内网集群，如果内网内开启防火墙，内网集群之间通信会出现很多问题。</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
