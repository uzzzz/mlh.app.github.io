<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>LruCache在美团DSP系统中的应用演进 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="LruCache在美团DSP系统中的应用演进" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="总第317篇 2018年 第109篇 LruCache是一种带有清退机制的缓存结构。用于DSP系统中的广告数据存储来提高广告投放引擎的性能。 美团在线营销DSP团队诚招工程、算法、数据等各方向精英，共同支持百亿级流量的高可靠系统研发与优化。有兴趣的同学可以直接发送简历至cuitao@meituan.com 背景 DSP系统是互联网广告需求方平台，用于承接媒体流量，投放广告。业务特点是并发度高，平均响应低（百毫秒）。 为了能够有效提高DSP系统的性能，美团平台引入了一种带有清退机制的缓存结构LruCache(Least Recently Used Cache)，在目前的DSP系统中，使用LruCache + 键值存储数据库的机制将远端数据变为本地缓存数据，不仅能够降低平均获取信息的耗时，而且通过一定的清退机制，也可以维持服务内存占用在安全区间。 本文将会结合实际应用场景，阐述引入LruCache的原因，并会在高QPS下的挑战与解决方案等方面做详细深入的介绍，希望能对DSP感兴趣的同学有所启发。 LruCache简介 LruCache采用的缓存算法为LRU(Least Recently Used)，即最近最少使用算法。这一算法的核心思想是当缓存数据达到预设上限后，会优先淘汰近期最少使用的缓存对象。 LruCache内部维护一个双向链表和一个映射表。链表按照使用顺序存储缓存数据，越早使用的数据越靠近链表尾部，越晚使用的数据越靠近链表头部；映射表通过Key-Value结构，提供高效的查找操作，通过键值可以判断某一数据是否缓存，如果缓存直接获取缓存数据所属的链表节点，进一步获取缓存数据。LruCache结构图如下所示，上半部分是双向链表，下半部分是映射表（不一定有序）。双向链表中value_1所处位置为链表头部，value_N所处位置为链表尾部。 LruCache读操作，通过键值在映射表中查找缓存数据是否存在。如果数据存在，则将缓存数据所处节点从链表中当前位置取出，移动到链表头部；如果不存在，则返回查找失败，等待新数据写入。下图为通过LruCache查找key_2后LruCache结构的变化。 LruCache没有达到预设上限情况下的写操作，直接将缓存数据加入到链表头部，同时将缓存数据键值与缓存数据所处的双链表节点作为键值对插入到映射表中。下图是LruCache预设上限大于N时，将数据M写入后的数据结构。 LruCache达到预设上限情况下的写操作，首先将链表尾部的缓存数据在映射表中的键值对删除，并删除链表尾部数据，再将新的数据正常写入到缓存中。下图是LruCache预设上限为N时，将数据M写入后的数据结构。 线程安全的LruCache在读写操作中，全部使用锁做临界区保护，确保缓存使用是线程安全的。 LruCache在美团DSP系统的应用场景 在美团DSP系统中广泛应用键值存储数据库，例如使用Redis存储广告信息，服务可以通过广告ID获取广告信息。每次请求都从远端的键值存储数据库中获取广告信息，请求耗时非常长。随着业务发展，QPS呈现巨大的增长趋势，在这种高并发的应用场景下，将广告信息从远端键值存储数据库中迁移到本地以减少查询耗时是常见解决方案。另外服务本身的内存占用要稳定在一个安全的区间内。面对持续增长的广告信息，引入LruCache + 键值存储数据库的机制来达到提高系统性能，维持内存占用安全、稳定的目标。 LruCache + Redis机制的应用演进 在实际应用中，LruCache + Redis机制实践分别经历了引入LruCache、LruCache增加时效清退机制、HashLruCache满足高QPS应用场景以及零拷贝机制四个阶段。各阶段的测试机器是16核16G机器。 演进一：引入LruCache提高美团DSP系统性能 在较低QPS环境下，直接请求Redis获取广告信息，可以满足场景需求。但是随着单机QPS的增加，直接请求Redis获取广告信息，耗时也会增加，无法满足业务场景的需求。 引入LruCache，将远端存放于Redis的信息本地化存储。LruCache可以预设缓存上限，这个上限可以根据服务所在机器内存与服务本身内存占用来确定，确保增加LruCache后，服务本身内存占用在安全范围内；同时可以根据查询操作统计缓存数据在实际使用中的命中率。 下图是增加LruCache结构前后，且增加LruCache后命中率高于95%的情况下，针对持续增长的QPS得出的数据获取平均耗时(ms)对比图： 根据平均耗时图显示可以得出结论： QPS高于250后，直接请求Redis获取数据的平均耗时达到10ms以上，完全无法满足使用的需求。 增加LruCache结构后，耗时下降一个量级。从平均耗时角度看，QPS不高于500的情况下，耗时低于2ms。 下图是增加LruCache结构前后，且增加LruCache后命中率高于95%的情况下，针对持续增长的QPS得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 增加LruCache结构后，Top999耗时比平均耗时增长一个数量级。 即使是较低的QPS下，使用LruCache结构的Top999耗时也是比较高的。 引入LruCache结构，在实际使用中，在一定的QPS范围内，确实可以有效减少数据获取的耗时。但是QPS超出一定范围后，平均耗时和Top999耗时都很高。所以LruCache在更高的QPS下性能还需要进一步优化。 演进二：LruCache增加时效清退机制 在业务场景中，Redis中的广告数据有可能做修改。服务本身作为数据的使用方，无法感知到数据源的变化。当缓存的命中率较高或者部分数据在较长时间内多次命中，可能出现数据失效的情况。即数据源发生了变化，但服务无法及时更新数据。针对这一业务场景，增加了时效清退机制。 时效清退机制的组成部分有三点：设置缓存数据过期时间，缓存数据单元增加时间戳以及查询中的时效性判断。缓存数据单元将数据进入LruCache的时间戳与数据一起缓存下来。缓存过期时间表示缓存单元缓存的时间上限。查询中的时效性判断表示查询时的时间戳与缓存时间戳的差值超过缓存过期时间，则强制将此数据清空，重新请求Redis获取数据做缓存。 在查询中做时效性判断可以最低程度的减少时效判断对服务的中断。当LruCache预设上限较低时，定期做全量数据清理对于服务本身影响较小。但如果LruCache的预设上限非常高，则一次全量数据清理耗时可能达到秒级甚至分钟级，将严重阻断服务本身的运行。所以将时效性判断加入到查询中，只对单一的缓存单元做时效性判断，在服务性能和数据有效性之间做了折中，满足业务需求。 演进三：高QPS下HashLruCache的应用 LruCache引入美团DSP系统后，在一段时间内较好地支持了业务的发展。随着业务的迭代，单机QPS持续上升。在更高QPS下，LruCache的查询耗时有了明显的提高，逐渐无法适应低平响的业务场景。在这种情况下，引入了HashLruCache机制以解决这个问题。 LruCache在高QPS下的耗时增加原因分析 线程安全的LruCache中有锁的存在。每次读写操作之前都有加锁操作，完成读写操作之后还有解锁操作。在低QPS下，锁竞争的耗时基本可以忽略；但是在高QPS下，大量的时间消耗在了等待锁的操作上，导致耗时增长。 HashLruCache适应高QPS场景 针对大量的同步等待操作导致耗时增加的情况，解决方案就是尽量减小临界区。引入Hash机制，对全量数据做分片处理，在原有LruCache的基础上形成HashLruCache，以降低查询耗时。 HashLruCache引入某种哈希算法，将缓存数据分散到N个LruCache上。最简单的哈希算法即使用取模算法，将广告信息按照其ID取模，分散到N个LruCache上。查询时也按照相同的哈希算法，先获取数据可能存在的分片，然后再去对应的分片上查询数据。这样可以增加LruCache的读写操作的并行度，减小同步等待的耗时。 下图是使用16分片的HashLruCache结构前后，且命中率高于95%的情况下，针对持续增长的QPS得出的数据获取平均耗时(ms)对比图： 根据平均耗时图可以得出以下结论： 使用HashLruCache后，平均耗时减少将近一半，效果比较明显。 对比不使用HashLruCache的平均耗时可以发现，使用HashLruCache的平均耗时对QPS的增长不敏感，没有明显增长。 下图是使用16分片的HashLruCache结构前后，且命中率高于95%的情况下，针对持续增长的QPS得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 使用HashLruCache后，Top999耗时减少为未使用时的三分之一左右，效果非常明显。 使用HashLruCache的Top999耗时随QPS增长明显比不使用的情况慢，相对来说对QPS的增长敏感度更低。 引入HashLruCache结构后，在实际使用中，平均耗时和Top999耗时都有非常明显的下降，效果非常显著。 HashLruCache分片数量确定 根据以上分析，进一步提高HashLruCache性能的一个方法是确定最合理的分片数量，增加足够的并行度，减少同步等待消耗。所以分片数量可以与CPU数量一致。由于超线程技术的使用，可以将分片数量进一步提高，增加并行性。 下图是使用HashLruCache机制后，命中率高于95%，不同分片数量在不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，在较高的QPS下，平均耗时并没有随着分片数量的增加而有明显的减少，基本维持稳定的状态。 下图是使用HashLruCache机制后，命中率高于95%，不同分片数量在不同QPS下得出的数据获取Top999耗时(ms)对比图： Top999耗时图显示，QPS为750时，分片数量从8增长到16再增长到24时，Top999耗时有一定的下降，并不显著；QPS为1000时，分片数量从8增长到16有明显下降，但是从16增长到24时，基本维持了稳定状态。明显与实际使用的机器CPU数量有较强的相关性。 HashLruCache机制在实际使用中，可以根据机器性能并结合实际场景的QPS来调节分片数量，以达到最好的性能。 演进四：零拷贝机制 线程安全的LruCache内部维护一套数据。对外提供数据时，将对应的数据完整拷贝一份提供给调用方使用。如果存放结构简单的数据，拷贝操作的代价非常小，这一机制不会成为性能瓶颈。但是美团DSP系统的应用场景中，LruCache中存放的数据结构非常复杂，单次的拷贝操作代价很大，导致这一机制变成了性能瓶颈。 理想的情况是LruCache对外仅仅提供数据地址，即数据指针。使用方在业务需要使用的地方通过数据指针获取数据。这样可以将复杂的数据拷贝操作变为简单的地址拷贝，大量减少拷贝操作的性能消耗，即数据的零拷贝机制。直接的零拷贝机制存在安全隐患，即由于LruCache中的时效清退机制，可能会出现某一数据已经过期被删除，但是使用方仍然通过持有失效的数据指针来获取该数据。 进一步分析可以确定，以上问题的核心是存放于LruCache的数据生命周期对于使用方不透明。解决这一问题的方案是为LruCache中存放的数据添加原子变量的引用计数。使用原子变量不仅确保了引用计数的线程安全，使得各个线程读取的引用计数一致，同时保证了并发状态最小的同步性能开销。不论是LruCache中还是使用方，每次获取数据指针时，即将引用计数加1；同理，不再持有数据指针时，引用计数减1。当引用计数为0时，说明数据没有被任何使用方使用，且数据已经过期从LruCache中被删除。这时删除数据的操作是安全的。 下图是使零拷贝机制后，命中率高于95%，不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，使用零拷贝机制后，平均耗时下降幅度超过60%，效果非常显著。 下图是使零拷贝机制后，命中率高于95%，不同QPS下得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 使用零拷贝后，Top999耗时降幅将近50%，效果非常明显。 在高QPS下，使用零拷贝机制的Top999耗时随QPS增长明显比不使用的情况慢，相对来说对QPS的增长敏感度更低。 引入零拷贝机制后，通过拷贝指针替换拷贝数据，大量降低了获取复杂业务数据的耗时，同时将临界区减小到最小。线程安全的原子变量自增与自减操作，目前在多个基础库中都有实现，例如C++11就提供了内置的整型原子变量，实现线程安全的自增与自减操作。 在HashLruCache中引入零拷贝机制，可以进一步有效降低平均耗时和Top999耗时，且在高QPS下对于稳定Top999耗时有非常好的效果。 总结 下图是一系列优化措施前后，命中率高于95%，不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，优化后的平均耗时仅为优化前的20%以内，性能提升非常明显。优化后平均耗时对于QPS的增长敏感度更低，更好的支持了高QPS的业务场景。 下图是一系列优化措施前后，命中率高于95%，不同QPS下得出的数据获取Top999耗时(ms)对比图： Top999耗时图显示，优化后的Top999耗时仅为优化前的20%以内，对于长尾请求的耗时有非常明显的降低。 LruCache是一个非常常见的数据结构。在美团DSP的高QPS业务场景下，发挥了重要的作用。为了符合业务需要，在原本的清退机制外，补充了时效性强制清退机制。随着业务的发展，针对更高QPS的业务场景，使用HashLruCache机制，降低缓存的查询耗时。针对不同的具体场景，在不同的QPS下，不断尝试更合理的分片数量，不断提高HashLruCache的查询性能。通过引用计数的方案，在HashLruCache中引入零拷贝机制，进一步大幅降低平均耗时和Top999耗时，更好的服务于业务场景的发展。 作者简介 王粲，2018年11月加入美团，任职美团高级工程师，负责美团DSP系统后端基础架构的研发工作。 崔涛，2015年6月加入美团，任职资深广告技术专家，期间一手指导并从0到1搭建美团DSP投放平台，具备丰富的大规模计算引擎的开发和性能优化经验。 霜霜，2015年6月加入美团，任职美团高级工程师，美团DSP系统后端基础架构与机器学习架构负责人，全面负责DSP业务广告召回和排序服务的架构设计与优化。 欢迎加入美团计算广告技术交流群，跟作者零距离交流。进群方式：请加美美同学微信（微信号：MTDPtech02），回复：计算广告，美美会自动拉你进群。 ----------&nbsp; END&nbsp; ---------- 也许你还想看 美团DSP广告策略实践 美团O2O广告营销中的机器学习技术 深度学习在美团搜索广告排序的应用实践" />
<meta property="og:description" content="总第317篇 2018年 第109篇 LruCache是一种带有清退机制的缓存结构。用于DSP系统中的广告数据存储来提高广告投放引擎的性能。 美团在线营销DSP团队诚招工程、算法、数据等各方向精英，共同支持百亿级流量的高可靠系统研发与优化。有兴趣的同学可以直接发送简历至cuitao@meituan.com 背景 DSP系统是互联网广告需求方平台，用于承接媒体流量，投放广告。业务特点是并发度高，平均响应低（百毫秒）。 为了能够有效提高DSP系统的性能，美团平台引入了一种带有清退机制的缓存结构LruCache(Least Recently Used Cache)，在目前的DSP系统中，使用LruCache + 键值存储数据库的机制将远端数据变为本地缓存数据，不仅能够降低平均获取信息的耗时，而且通过一定的清退机制，也可以维持服务内存占用在安全区间。 本文将会结合实际应用场景，阐述引入LruCache的原因，并会在高QPS下的挑战与解决方案等方面做详细深入的介绍，希望能对DSP感兴趣的同学有所启发。 LruCache简介 LruCache采用的缓存算法为LRU(Least Recently Used)，即最近最少使用算法。这一算法的核心思想是当缓存数据达到预设上限后，会优先淘汰近期最少使用的缓存对象。 LruCache内部维护一个双向链表和一个映射表。链表按照使用顺序存储缓存数据，越早使用的数据越靠近链表尾部，越晚使用的数据越靠近链表头部；映射表通过Key-Value结构，提供高效的查找操作，通过键值可以判断某一数据是否缓存，如果缓存直接获取缓存数据所属的链表节点，进一步获取缓存数据。LruCache结构图如下所示，上半部分是双向链表，下半部分是映射表（不一定有序）。双向链表中value_1所处位置为链表头部，value_N所处位置为链表尾部。 LruCache读操作，通过键值在映射表中查找缓存数据是否存在。如果数据存在，则将缓存数据所处节点从链表中当前位置取出，移动到链表头部；如果不存在，则返回查找失败，等待新数据写入。下图为通过LruCache查找key_2后LruCache结构的变化。 LruCache没有达到预设上限情况下的写操作，直接将缓存数据加入到链表头部，同时将缓存数据键值与缓存数据所处的双链表节点作为键值对插入到映射表中。下图是LruCache预设上限大于N时，将数据M写入后的数据结构。 LruCache达到预设上限情况下的写操作，首先将链表尾部的缓存数据在映射表中的键值对删除，并删除链表尾部数据，再将新的数据正常写入到缓存中。下图是LruCache预设上限为N时，将数据M写入后的数据结构。 线程安全的LruCache在读写操作中，全部使用锁做临界区保护，确保缓存使用是线程安全的。 LruCache在美团DSP系统的应用场景 在美团DSP系统中广泛应用键值存储数据库，例如使用Redis存储广告信息，服务可以通过广告ID获取广告信息。每次请求都从远端的键值存储数据库中获取广告信息，请求耗时非常长。随着业务发展，QPS呈现巨大的增长趋势，在这种高并发的应用场景下，将广告信息从远端键值存储数据库中迁移到本地以减少查询耗时是常见解决方案。另外服务本身的内存占用要稳定在一个安全的区间内。面对持续增长的广告信息，引入LruCache + 键值存储数据库的机制来达到提高系统性能，维持内存占用安全、稳定的目标。 LruCache + Redis机制的应用演进 在实际应用中，LruCache + Redis机制实践分别经历了引入LruCache、LruCache增加时效清退机制、HashLruCache满足高QPS应用场景以及零拷贝机制四个阶段。各阶段的测试机器是16核16G机器。 演进一：引入LruCache提高美团DSP系统性能 在较低QPS环境下，直接请求Redis获取广告信息，可以满足场景需求。但是随着单机QPS的增加，直接请求Redis获取广告信息，耗时也会增加，无法满足业务场景的需求。 引入LruCache，将远端存放于Redis的信息本地化存储。LruCache可以预设缓存上限，这个上限可以根据服务所在机器内存与服务本身内存占用来确定，确保增加LruCache后，服务本身内存占用在安全范围内；同时可以根据查询操作统计缓存数据在实际使用中的命中率。 下图是增加LruCache结构前后，且增加LruCache后命中率高于95%的情况下，针对持续增长的QPS得出的数据获取平均耗时(ms)对比图： 根据平均耗时图显示可以得出结论： QPS高于250后，直接请求Redis获取数据的平均耗时达到10ms以上，完全无法满足使用的需求。 增加LruCache结构后，耗时下降一个量级。从平均耗时角度看，QPS不高于500的情况下，耗时低于2ms。 下图是增加LruCache结构前后，且增加LruCache后命中率高于95%的情况下，针对持续增长的QPS得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 增加LruCache结构后，Top999耗时比平均耗时增长一个数量级。 即使是较低的QPS下，使用LruCache结构的Top999耗时也是比较高的。 引入LruCache结构，在实际使用中，在一定的QPS范围内，确实可以有效减少数据获取的耗时。但是QPS超出一定范围后，平均耗时和Top999耗时都很高。所以LruCache在更高的QPS下性能还需要进一步优化。 演进二：LruCache增加时效清退机制 在业务场景中，Redis中的广告数据有可能做修改。服务本身作为数据的使用方，无法感知到数据源的变化。当缓存的命中率较高或者部分数据在较长时间内多次命中，可能出现数据失效的情况。即数据源发生了变化，但服务无法及时更新数据。针对这一业务场景，增加了时效清退机制。 时效清退机制的组成部分有三点：设置缓存数据过期时间，缓存数据单元增加时间戳以及查询中的时效性判断。缓存数据单元将数据进入LruCache的时间戳与数据一起缓存下来。缓存过期时间表示缓存单元缓存的时间上限。查询中的时效性判断表示查询时的时间戳与缓存时间戳的差值超过缓存过期时间，则强制将此数据清空，重新请求Redis获取数据做缓存。 在查询中做时效性判断可以最低程度的减少时效判断对服务的中断。当LruCache预设上限较低时，定期做全量数据清理对于服务本身影响较小。但如果LruCache的预设上限非常高，则一次全量数据清理耗时可能达到秒级甚至分钟级，将严重阻断服务本身的运行。所以将时效性判断加入到查询中，只对单一的缓存单元做时效性判断，在服务性能和数据有效性之间做了折中，满足业务需求。 演进三：高QPS下HashLruCache的应用 LruCache引入美团DSP系统后，在一段时间内较好地支持了业务的发展。随着业务的迭代，单机QPS持续上升。在更高QPS下，LruCache的查询耗时有了明显的提高，逐渐无法适应低平响的业务场景。在这种情况下，引入了HashLruCache机制以解决这个问题。 LruCache在高QPS下的耗时增加原因分析 线程安全的LruCache中有锁的存在。每次读写操作之前都有加锁操作，完成读写操作之后还有解锁操作。在低QPS下，锁竞争的耗时基本可以忽略；但是在高QPS下，大量的时间消耗在了等待锁的操作上，导致耗时增长。 HashLruCache适应高QPS场景 针对大量的同步等待操作导致耗时增加的情况，解决方案就是尽量减小临界区。引入Hash机制，对全量数据做分片处理，在原有LruCache的基础上形成HashLruCache，以降低查询耗时。 HashLruCache引入某种哈希算法，将缓存数据分散到N个LruCache上。最简单的哈希算法即使用取模算法，将广告信息按照其ID取模，分散到N个LruCache上。查询时也按照相同的哈希算法，先获取数据可能存在的分片，然后再去对应的分片上查询数据。这样可以增加LruCache的读写操作的并行度，减小同步等待的耗时。 下图是使用16分片的HashLruCache结构前后，且命中率高于95%的情况下，针对持续增长的QPS得出的数据获取平均耗时(ms)对比图： 根据平均耗时图可以得出以下结论： 使用HashLruCache后，平均耗时减少将近一半，效果比较明显。 对比不使用HashLruCache的平均耗时可以发现，使用HashLruCache的平均耗时对QPS的增长不敏感，没有明显增长。 下图是使用16分片的HashLruCache结构前后，且命中率高于95%的情况下，针对持续增长的QPS得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 使用HashLruCache后，Top999耗时减少为未使用时的三分之一左右，效果非常明显。 使用HashLruCache的Top999耗时随QPS增长明显比不使用的情况慢，相对来说对QPS的增长敏感度更低。 引入HashLruCache结构后，在实际使用中，平均耗时和Top999耗时都有非常明显的下降，效果非常显著。 HashLruCache分片数量确定 根据以上分析，进一步提高HashLruCache性能的一个方法是确定最合理的分片数量，增加足够的并行度，减少同步等待消耗。所以分片数量可以与CPU数量一致。由于超线程技术的使用，可以将分片数量进一步提高，增加并行性。 下图是使用HashLruCache机制后，命中率高于95%，不同分片数量在不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，在较高的QPS下，平均耗时并没有随着分片数量的增加而有明显的减少，基本维持稳定的状态。 下图是使用HashLruCache机制后，命中率高于95%，不同分片数量在不同QPS下得出的数据获取Top999耗时(ms)对比图： Top999耗时图显示，QPS为750时，分片数量从8增长到16再增长到24时，Top999耗时有一定的下降，并不显著；QPS为1000时，分片数量从8增长到16有明显下降，但是从16增长到24时，基本维持了稳定状态。明显与实际使用的机器CPU数量有较强的相关性。 HashLruCache机制在实际使用中，可以根据机器性能并结合实际场景的QPS来调节分片数量，以达到最好的性能。 演进四：零拷贝机制 线程安全的LruCache内部维护一套数据。对外提供数据时，将对应的数据完整拷贝一份提供给调用方使用。如果存放结构简单的数据，拷贝操作的代价非常小，这一机制不会成为性能瓶颈。但是美团DSP系统的应用场景中，LruCache中存放的数据结构非常复杂，单次的拷贝操作代价很大，导致这一机制变成了性能瓶颈。 理想的情况是LruCache对外仅仅提供数据地址，即数据指针。使用方在业务需要使用的地方通过数据指针获取数据。这样可以将复杂的数据拷贝操作变为简单的地址拷贝，大量减少拷贝操作的性能消耗，即数据的零拷贝机制。直接的零拷贝机制存在安全隐患，即由于LruCache中的时效清退机制，可能会出现某一数据已经过期被删除，但是使用方仍然通过持有失效的数据指针来获取该数据。 进一步分析可以确定，以上问题的核心是存放于LruCache的数据生命周期对于使用方不透明。解决这一问题的方案是为LruCache中存放的数据添加原子变量的引用计数。使用原子变量不仅确保了引用计数的线程安全，使得各个线程读取的引用计数一致，同时保证了并发状态最小的同步性能开销。不论是LruCache中还是使用方，每次获取数据指针时，即将引用计数加1；同理，不再持有数据指针时，引用计数减1。当引用计数为0时，说明数据没有被任何使用方使用，且数据已经过期从LruCache中被删除。这时删除数据的操作是安全的。 下图是使零拷贝机制后，命中率高于95%，不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，使用零拷贝机制后，平均耗时下降幅度超过60%，效果非常显著。 下图是使零拷贝机制后，命中率高于95%，不同QPS下得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 使用零拷贝后，Top999耗时降幅将近50%，效果非常明显。 在高QPS下，使用零拷贝机制的Top999耗时随QPS增长明显比不使用的情况慢，相对来说对QPS的增长敏感度更低。 引入零拷贝机制后，通过拷贝指针替换拷贝数据，大量降低了获取复杂业务数据的耗时，同时将临界区减小到最小。线程安全的原子变量自增与自减操作，目前在多个基础库中都有实现，例如C++11就提供了内置的整型原子变量，实现线程安全的自增与自减操作。 在HashLruCache中引入零拷贝机制，可以进一步有效降低平均耗时和Top999耗时，且在高QPS下对于稳定Top999耗时有非常好的效果。 总结 下图是一系列优化措施前后，命中率高于95%，不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，优化后的平均耗时仅为优化前的20%以内，性能提升非常明显。优化后平均耗时对于QPS的增长敏感度更低，更好的支持了高QPS的业务场景。 下图是一系列优化措施前后，命中率高于95%，不同QPS下得出的数据获取Top999耗时(ms)对比图： Top999耗时图显示，优化后的Top999耗时仅为优化前的20%以内，对于长尾请求的耗时有非常明显的降低。 LruCache是一个非常常见的数据结构。在美团DSP的高QPS业务场景下，发挥了重要的作用。为了符合业务需要，在原本的清退机制外，补充了时效性强制清退机制。随着业务的发展，针对更高QPS的业务场景，使用HashLruCache机制，降低缓存的查询耗时。针对不同的具体场景，在不同的QPS下，不断尝试更合理的分片数量，不断提高HashLruCache的查询性能。通过引用计数的方案，在HashLruCache中引入零拷贝机制，进一步大幅降低平均耗时和Top999耗时，更好的服务于业务场景的发展。 作者简介 王粲，2018年11月加入美团，任职美团高级工程师，负责美团DSP系统后端基础架构的研发工作。 崔涛，2015年6月加入美团，任职资深广告技术专家，期间一手指导并从0到1搭建美团DSP投放平台，具备丰富的大规模计算引擎的开发和性能优化经验。 霜霜，2015年6月加入美团，任职美团高级工程师，美团DSP系统后端基础架构与机器学习架构负责人，全面负责DSP业务广告召回和排序服务的架构设计与优化。 欢迎加入美团计算广告技术交流群，跟作者零距离交流。进群方式：请加美美同学微信（微信号：MTDPtech02），回复：计算广告，美美会自动拉你进群。 ----------&nbsp; END&nbsp; ---------- 也许你还想看 美团DSP广告策略实践 美团O2O广告营销中的机器学习技术 深度学习在美团搜索广告排序的应用实践" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-29T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"总第317篇 2018年 第109篇 LruCache是一种带有清退机制的缓存结构。用于DSP系统中的广告数据存储来提高广告投放引擎的性能。 美团在线营销DSP团队诚招工程、算法、数据等各方向精英，共同支持百亿级流量的高可靠系统研发与优化。有兴趣的同学可以直接发送简历至cuitao@meituan.com 背景 DSP系统是互联网广告需求方平台，用于承接媒体流量，投放广告。业务特点是并发度高，平均响应低（百毫秒）。 为了能够有效提高DSP系统的性能，美团平台引入了一种带有清退机制的缓存结构LruCache(Least Recently Used Cache)，在目前的DSP系统中，使用LruCache + 键值存储数据库的机制将远端数据变为本地缓存数据，不仅能够降低平均获取信息的耗时，而且通过一定的清退机制，也可以维持服务内存占用在安全区间。 本文将会结合实际应用场景，阐述引入LruCache的原因，并会在高QPS下的挑战与解决方案等方面做详细深入的介绍，希望能对DSP感兴趣的同学有所启发。 LruCache简介 LruCache采用的缓存算法为LRU(Least Recently Used)，即最近最少使用算法。这一算法的核心思想是当缓存数据达到预设上限后，会优先淘汰近期最少使用的缓存对象。 LruCache内部维护一个双向链表和一个映射表。链表按照使用顺序存储缓存数据，越早使用的数据越靠近链表尾部，越晚使用的数据越靠近链表头部；映射表通过Key-Value结构，提供高效的查找操作，通过键值可以判断某一数据是否缓存，如果缓存直接获取缓存数据所属的链表节点，进一步获取缓存数据。LruCache结构图如下所示，上半部分是双向链表，下半部分是映射表（不一定有序）。双向链表中value_1所处位置为链表头部，value_N所处位置为链表尾部。 LruCache读操作，通过键值在映射表中查找缓存数据是否存在。如果数据存在，则将缓存数据所处节点从链表中当前位置取出，移动到链表头部；如果不存在，则返回查找失败，等待新数据写入。下图为通过LruCache查找key_2后LruCache结构的变化。 LruCache没有达到预设上限情况下的写操作，直接将缓存数据加入到链表头部，同时将缓存数据键值与缓存数据所处的双链表节点作为键值对插入到映射表中。下图是LruCache预设上限大于N时，将数据M写入后的数据结构。 LruCache达到预设上限情况下的写操作，首先将链表尾部的缓存数据在映射表中的键值对删除，并删除链表尾部数据，再将新的数据正常写入到缓存中。下图是LruCache预设上限为N时，将数据M写入后的数据结构。 线程安全的LruCache在读写操作中，全部使用锁做临界区保护，确保缓存使用是线程安全的。 LruCache在美团DSP系统的应用场景 在美团DSP系统中广泛应用键值存储数据库，例如使用Redis存储广告信息，服务可以通过广告ID获取广告信息。每次请求都从远端的键值存储数据库中获取广告信息，请求耗时非常长。随着业务发展，QPS呈现巨大的增长趋势，在这种高并发的应用场景下，将广告信息从远端键值存储数据库中迁移到本地以减少查询耗时是常见解决方案。另外服务本身的内存占用要稳定在一个安全的区间内。面对持续增长的广告信息，引入LruCache + 键值存储数据库的机制来达到提高系统性能，维持内存占用安全、稳定的目标。 LruCache + Redis机制的应用演进 在实际应用中，LruCache + Redis机制实践分别经历了引入LruCache、LruCache增加时效清退机制、HashLruCache满足高QPS应用场景以及零拷贝机制四个阶段。各阶段的测试机器是16核16G机器。 演进一：引入LruCache提高美团DSP系统性能 在较低QPS环境下，直接请求Redis获取广告信息，可以满足场景需求。但是随着单机QPS的增加，直接请求Redis获取广告信息，耗时也会增加，无法满足业务场景的需求。 引入LruCache，将远端存放于Redis的信息本地化存储。LruCache可以预设缓存上限，这个上限可以根据服务所在机器内存与服务本身内存占用来确定，确保增加LruCache后，服务本身内存占用在安全范围内；同时可以根据查询操作统计缓存数据在实际使用中的命中率。 下图是增加LruCache结构前后，且增加LruCache后命中率高于95%的情况下，针对持续增长的QPS得出的数据获取平均耗时(ms)对比图： 根据平均耗时图显示可以得出结论： QPS高于250后，直接请求Redis获取数据的平均耗时达到10ms以上，完全无法满足使用的需求。 增加LruCache结构后，耗时下降一个量级。从平均耗时角度看，QPS不高于500的情况下，耗时低于2ms。 下图是增加LruCache结构前后，且增加LruCache后命中率高于95%的情况下，针对持续增长的QPS得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 增加LruCache结构后，Top999耗时比平均耗时增长一个数量级。 即使是较低的QPS下，使用LruCache结构的Top999耗时也是比较高的。 引入LruCache结构，在实际使用中，在一定的QPS范围内，确实可以有效减少数据获取的耗时。但是QPS超出一定范围后，平均耗时和Top999耗时都很高。所以LruCache在更高的QPS下性能还需要进一步优化。 演进二：LruCache增加时效清退机制 在业务场景中，Redis中的广告数据有可能做修改。服务本身作为数据的使用方，无法感知到数据源的变化。当缓存的命中率较高或者部分数据在较长时间内多次命中，可能出现数据失效的情况。即数据源发生了变化，但服务无法及时更新数据。针对这一业务场景，增加了时效清退机制。 时效清退机制的组成部分有三点：设置缓存数据过期时间，缓存数据单元增加时间戳以及查询中的时效性判断。缓存数据单元将数据进入LruCache的时间戳与数据一起缓存下来。缓存过期时间表示缓存单元缓存的时间上限。查询中的时效性判断表示查询时的时间戳与缓存时间戳的差值超过缓存过期时间，则强制将此数据清空，重新请求Redis获取数据做缓存。 在查询中做时效性判断可以最低程度的减少时效判断对服务的中断。当LruCache预设上限较低时，定期做全量数据清理对于服务本身影响较小。但如果LruCache的预设上限非常高，则一次全量数据清理耗时可能达到秒级甚至分钟级，将严重阻断服务本身的运行。所以将时效性判断加入到查询中，只对单一的缓存单元做时效性判断，在服务性能和数据有效性之间做了折中，满足业务需求。 演进三：高QPS下HashLruCache的应用 LruCache引入美团DSP系统后，在一段时间内较好地支持了业务的发展。随着业务的迭代，单机QPS持续上升。在更高QPS下，LruCache的查询耗时有了明显的提高，逐渐无法适应低平响的业务场景。在这种情况下，引入了HashLruCache机制以解决这个问题。 LruCache在高QPS下的耗时增加原因分析 线程安全的LruCache中有锁的存在。每次读写操作之前都有加锁操作，完成读写操作之后还有解锁操作。在低QPS下，锁竞争的耗时基本可以忽略；但是在高QPS下，大量的时间消耗在了等待锁的操作上，导致耗时增长。 HashLruCache适应高QPS场景 针对大量的同步等待操作导致耗时增加的情况，解决方案就是尽量减小临界区。引入Hash机制，对全量数据做分片处理，在原有LruCache的基础上形成HashLruCache，以降低查询耗时。 HashLruCache引入某种哈希算法，将缓存数据分散到N个LruCache上。最简单的哈希算法即使用取模算法，将广告信息按照其ID取模，分散到N个LruCache上。查询时也按照相同的哈希算法，先获取数据可能存在的分片，然后再去对应的分片上查询数据。这样可以增加LruCache的读写操作的并行度，减小同步等待的耗时。 下图是使用16分片的HashLruCache结构前后，且命中率高于95%的情况下，针对持续增长的QPS得出的数据获取平均耗时(ms)对比图： 根据平均耗时图可以得出以下结论： 使用HashLruCache后，平均耗时减少将近一半，效果比较明显。 对比不使用HashLruCache的平均耗时可以发现，使用HashLruCache的平均耗时对QPS的增长不敏感，没有明显增长。 下图是使用16分片的HashLruCache结构前后，且命中率高于95%的情况下，针对持续增长的QPS得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 使用HashLruCache后，Top999耗时减少为未使用时的三分之一左右，效果非常明显。 使用HashLruCache的Top999耗时随QPS增长明显比不使用的情况慢，相对来说对QPS的增长敏感度更低。 引入HashLruCache结构后，在实际使用中，平均耗时和Top999耗时都有非常明显的下降，效果非常显著。 HashLruCache分片数量确定 根据以上分析，进一步提高HashLruCache性能的一个方法是确定最合理的分片数量，增加足够的并行度，减少同步等待消耗。所以分片数量可以与CPU数量一致。由于超线程技术的使用，可以将分片数量进一步提高，增加并行性。 下图是使用HashLruCache机制后，命中率高于95%，不同分片数量在不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，在较高的QPS下，平均耗时并没有随着分片数量的增加而有明显的减少，基本维持稳定的状态。 下图是使用HashLruCache机制后，命中率高于95%，不同分片数量在不同QPS下得出的数据获取Top999耗时(ms)对比图： Top999耗时图显示，QPS为750时，分片数量从8增长到16再增长到24时，Top999耗时有一定的下降，并不显著；QPS为1000时，分片数量从8增长到16有明显下降，但是从16增长到24时，基本维持了稳定状态。明显与实际使用的机器CPU数量有较强的相关性。 HashLruCache机制在实际使用中，可以根据机器性能并结合实际场景的QPS来调节分片数量，以达到最好的性能。 演进四：零拷贝机制 线程安全的LruCache内部维护一套数据。对外提供数据时，将对应的数据完整拷贝一份提供给调用方使用。如果存放结构简单的数据，拷贝操作的代价非常小，这一机制不会成为性能瓶颈。但是美团DSP系统的应用场景中，LruCache中存放的数据结构非常复杂，单次的拷贝操作代价很大，导致这一机制变成了性能瓶颈。 理想的情况是LruCache对外仅仅提供数据地址，即数据指针。使用方在业务需要使用的地方通过数据指针获取数据。这样可以将复杂的数据拷贝操作变为简单的地址拷贝，大量减少拷贝操作的性能消耗，即数据的零拷贝机制。直接的零拷贝机制存在安全隐患，即由于LruCache中的时效清退机制，可能会出现某一数据已经过期被删除，但是使用方仍然通过持有失效的数据指针来获取该数据。 进一步分析可以确定，以上问题的核心是存放于LruCache的数据生命周期对于使用方不透明。解决这一问题的方案是为LruCache中存放的数据添加原子变量的引用计数。使用原子变量不仅确保了引用计数的线程安全，使得各个线程读取的引用计数一致，同时保证了并发状态最小的同步性能开销。不论是LruCache中还是使用方，每次获取数据指针时，即将引用计数加1；同理，不再持有数据指针时，引用计数减1。当引用计数为0时，说明数据没有被任何使用方使用，且数据已经过期从LruCache中被删除。这时删除数据的操作是安全的。 下图是使零拷贝机制后，命中率高于95%，不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，使用零拷贝机制后，平均耗时下降幅度超过60%，效果非常显著。 下图是使零拷贝机制后，命中率高于95%，不同QPS下得出的数据获取Top999耗时(ms)对比图： 根据Top999耗时图可以得出以下结论： 使用零拷贝后，Top999耗时降幅将近50%，效果非常明显。 在高QPS下，使用零拷贝机制的Top999耗时随QPS增长明显比不使用的情况慢，相对来说对QPS的增长敏感度更低。 引入零拷贝机制后，通过拷贝指针替换拷贝数据，大量降低了获取复杂业务数据的耗时，同时将临界区减小到最小。线程安全的原子变量自增与自减操作，目前在多个基础库中都有实现，例如C++11就提供了内置的整型原子变量，实现线程安全的自增与自减操作。 在HashLruCache中引入零拷贝机制，可以进一步有效降低平均耗时和Top999耗时，且在高QPS下对于稳定Top999耗时有非常好的效果。 总结 下图是一系列优化措施前后，命中率高于95%，不同QPS下得出的数据获取平均耗时(ms)对比图： 平均耗时图显示，优化后的平均耗时仅为优化前的20%以内，性能提升非常明显。优化后平均耗时对于QPS的增长敏感度更低，更好的支持了高QPS的业务场景。 下图是一系列优化措施前后，命中率高于95%，不同QPS下得出的数据获取Top999耗时(ms)对比图： Top999耗时图显示，优化后的Top999耗时仅为优化前的20%以内，对于长尾请求的耗时有非常明显的降低。 LruCache是一个非常常见的数据结构。在美团DSP的高QPS业务场景下，发挥了重要的作用。为了符合业务需要，在原本的清退机制外，补充了时效性强制清退机制。随着业务的发展，针对更高QPS的业务场景，使用HashLruCache机制，降低缓存的查询耗时。针对不同的具体场景，在不同的QPS下，不断尝试更合理的分片数量，不断提高HashLruCache的查询性能。通过引用计数的方案，在HashLruCache中引入零拷贝机制，进一步大幅降低平均耗时和Top999耗时，更好的服务于业务场景的发展。 作者简介 王粲，2018年11月加入美团，任职美团高级工程师，负责美团DSP系统后端基础架构的研发工作。 崔涛，2015年6月加入美团，任职资深广告技术专家，期间一手指导并从0到1搭建美团DSP投放平台，具备丰富的大规模计算引擎的开发和性能优化经验。 霜霜，2015年6月加入美团，任职美团高级工程师，美团DSP系统后端基础架构与机器学习架构负责人，全面负责DSP业务广告召回和排序服务的架构设计与优化。 欢迎加入美团计算广告技术交流群，跟作者零距离交流。进群方式：请加美美同学微信（微信号：MTDPtech02），回复：计算广告，美美会自动拉你进群。 ----------&nbsp; END&nbsp; ---------- 也许你还想看 美团DSP广告策略实践 美团O2O广告营销中的机器学习技术 深度学习在美团搜索广告排序的应用实践","@type":"BlogPosting","url":"/2019/04/29/729109.html","headline":"LruCache在美团DSP系统中的应用演进","dateModified":"2019-04-29T00:00:00+08:00","datePublished":"2019-04-29T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/29/729109.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>LruCache在美团DSP系统中的应用演进</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;" data-mpa-powered-by="yiban.io"><img class="" data-copyright="0" data-ratio="0.10546875" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsV6LYkM3uK5TAnl8DxXwdR4zA3FUoOfW6b1icLsE77CELpkNLzriajHTdibqkqVFYoldIoffibgkOslZA/640?wx_fmt=png" data-type="png" data-w="1280" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsV6LYkM3uK5TAnl8DxXwdR4zA3FUoOfW6b1icLsE77CELpkNLzriajHTdibqkqVFYoldIoffibgkOslZA/640?wx_fmt=png"></p> 
<p style="white-space: normal;text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><strong><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 1px;">总第317篇</span></strong></p> 
<p style="white-space: normal;text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><strong><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 1px;">2018年 第109篇</span></strong></p> 
<p style="white-space: normal;text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<section data-role="outer" label="Powered by 135editor.com" style="font-size:16px;font-family:微软雅黑;"> 
 <section data-role="outer" label="Powered by 135editor.com"> 
  <section class="_135editor" data-tools="135编辑器" data-id="127" style="border-width: 0px;border-style: none;border-color: initial;"> 
   <section class="_135editor" data-tools="135编辑器" data-id="127" style="border-width: 0px;border-style: none;border-color: initial;"> 
    <section style="margin: 60px 16px 16px;border-width: 1px;border-style: solid;border-color: rgb(235, 234, 225);text-align: center;border-radius: 8px;font-weight: inherit;text-decoration: inherit;"> 
     <section style="font-size: 18px;margin-top: -3.3em;margin-right: 5px;margin-left: 5px;color: inherit;"> 
      <section style="border-width: 2px;border-style: solid;border-color: rgb(235, 234, 225);width: 108px;clear: both;margin-right: auto;margin-left: auto;height: 108px;border-radius: 50%;box-shadow: rgb(201, 201, 201) 0px 2px 2px 2px;background-color: rgb(254, 254, 254);"> 
       <img border="0" class="" data-ratio="1" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXJmHS8siaz48xKOxGqQehNLTxRksdCy2Dx2gicW703xibBiaLbsw7PMztZv3Wtz5icy12gOE4CBcYELqg/640?wx_fmt=jpeg" data-type="jpeg" data-w="800" data-width="100%" height="84" opacity="" style="border-radius: 50%;color: inherit;display: inline-block;height: 84px;width: 84px;" title="undefined" width="84" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXJmHS8siaz48xKOxGqQehNLTxRksdCy2Dx2gicW703xibBiaLbsw7PMztZv3Wtz5icy12gOE4CBcYELqg/640?wx_fmt=jpeg"> 
      </section> 
     </section> 
     <section class="135brush" data-brushtype="text" data-style="text-align: left; font-size: 14px; color: inherit;" style="font-size: 18px;margin: 8px 15px;line-height: 1.4;color: inherit;"> 
      <p style="margin-bottom: 10px;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 13px;">LruCache是一种带有清退机制的缓存结构。用于DSP系统中的广告数据存储来提高广告投放引擎的性能。</span></p> 
      <p style="text-align: left;"><span style="font-size: 13px;color: #7f7f7f;">美团在线营销DSP团队诚招工程、算法、数据等各方向精英，共同支持百亿级流量的高可靠系统研发与优化。有兴趣的同学可以直接发送简历至cuitao@meituan.com</span></p> 
     </section> 
    </section> 
   </section> 
  </section> 
 </section> 
</section> 
<p style="white-space: normal;color: rgb(51, 51, 51);margin-left: 0.5em;margin-right: 0.5em;"><span style="color: rgb(136, 136, 136);"></span></p> 
<h2 style="font-size: 18px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;"><span style="color: rgb(37, 183, 167);font-size: 20px;">背景</span></h2> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">DSP系统是互联网广告需求方平台，用于承接媒体流量，投放广告。业务特点是并发度高，平均响应低（<span style="color: rgb(136, 136, 136);">百毫秒</span>）。</p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">为了能够有效提高DSP系统的性能，美团平台引入了一种带有清退机制的缓存结构LruCache(<span style="color: rgb(136, 136, 136);">Least Recently Used Cache</span>)，在目前的DSP系统中，使用LruCache + 键值存储数据库的机制将远端数据变为本地缓存数据，不仅能够降低平均获取信息的耗时，而且通过一定的清退机制，也可以维持服务内存占用在安全区间。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">本文将会结合实际应用场景，阐述引入LruCache的原因，并会在高QPS下的挑战与解决方案等方面做详细深入的介绍，希望能对DSP感兴趣的同学有所启发。</p> 
<h1 style="margin: 30px 0.5em 15px;color: rgb(95, 185, 173);font-size: 20px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;">LruCache简介</h1> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">LruCache采用的缓存算法为LRU(<span style="color: rgb(136, 136, 136);">Least Recently Used</span>)，即最近最少使用算法。这一算法的核心思想是当缓存数据达到预设上限后，会优先淘汰近期最少使用的缓存对象。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache内部维护一个双向链表和一个映射表。链表按照使用顺序存储缓存数据，越早使用的数据越靠近链表尾部，越晚使用的数据越靠近链表头部；映射表通过Key-Value结构，提供高效的查找操作，通过键值可以判断某一数据是否缓存，如果缓存直接获取缓存数据所属的链表节点，进一步获取缓存数据。LruCache结构图如下所示，上半部分是双向链表，下半部分是映射表（<span style="color: rgb(136, 136, 136);">不一定有序</span>）。双向链表中value_1所处位置为链表头部，value_N所处位置为链表尾部。</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.44140625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4au9zqEqKXELHEO72lPY6PCR5TjichpdfYRaTexbu5tLxxHNKoEXFtcjA/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4au9zqEqKXELHEO72lPY6PCR5TjichpdfYRaTexbu5tLxxHNKoEXFtcjA/640?wx_fmt=jpeg"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache读操作，通过键值在映射表中查找缓存数据是否存在。如果数据存在，则将缓存数据所处节点从链表中当前位置取出，移动到链表头部；如果不存在，则返回查找失败，等待新数据写入。下图为通过LruCache查找key_2后LruCache结构的变化。</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.45" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4a1icDoLw3hcG2MXkB2clicqKU2qgqL4RrxBb7f1chmgwftmzmib9m17EfQ/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4a1icDoLw3hcG2MXkB2clicqKU2qgqL4RrxBb7f1chmgwftmzmib9m17EfQ/640?wx_fmt=jpeg"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache没有达到预设上限情况下的写操作，直接将缓存数据加入到链表头部，同时将缓存数据键值与缓存数据所处的双链表节点作为键值对插入到映射表中。下图是LruCache预设上限大于N时，将数据M写入后的数据结构。</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.37578125" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aeFGQk0MV9GUCSlVxcibIHliaG1aZ218LJFouI4n5o4D5iabUIaT4kZk4g/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aeFGQk0MV9GUCSlVxcibIHliaG1aZ218LJFouI4n5o4D5iabUIaT4kZk4g/640?wx_fmt=jpeg"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache达到预设上限情况下的写操作，首先将链表尾部的缓存数据在映射表中的键值对删除，并删除链表尾部数据，再将新的数据正常写入到缓存中。下图是LruCache预设上限为N时，将数据M写入后的数据结构。</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.3609375" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4a9jQx1vFtTcotSbL5leGBbIhjsORsWzbg5FL2IichDuib9S4IKKFuWdWA/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4a9jQx1vFtTcotSbL5leGBbIhjsORsWzbg5FL2IichDuib9S4IKKFuWdWA/640?wx_fmt=jpeg"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">线程安全的LruCache在读写操作中，全部使用锁做临界区保护，确保缓存使用是线程安全的。</p> 
<h1 style="margin-top: 30px;color: rgb(95, 185, 173);font-size: 20px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache在美团DSP系统的应用场景</h1> 
<p style="margin-left: 0.5em;margin-right: 0.5em;margin-top: 15px;"><span style="font-size: 15px;">在美团DSP系统中广泛应用键值存储数据库，例如使用Redis存储广告信息，服务可以通过广告ID获取广告信息。每次请求都从远端的键值存储数据库中获取广告信息，请求耗时非常长。随着业务发展，QPS呈现巨大的增长趋势，在这种高并发的应用场景下，将广告信息从远端键值存储数据库中迁移到本地以减少查询耗时是常见解决方案。另外服务本身的内存占用要稳定在一个安全的区间内。面对持续增长的广告信息，引入LruCache + 键值存储数据库的机制来达到提高系统性能，维持内存占用安全、稳定的目标。</span></p> 
<h1 style="margin-top: 30px;color: rgb(95, 185, 173);font-size: 20px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache + Redis机制的应用演进<br></h1> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">在实际应用中，LruCache + Redis机制实践分别经历了引入LruCache、LruCache增加时效清退机制、HashLruCache满足高QPS应用场景以及零拷贝机制四个阶段。各阶段的测试机器是16核16G机器。</p> 
<h2 style="margin-top: 30px;font-size: 18px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">演进一：引入LruCache提高美团DSP系统性能</h2> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">在较低QPS环境下，直接请求Redis获取广告信息，可以满足场景需求。但是随着单机QPS的增加，直接请求Redis获取广告信息，耗时也会增加，无法满足业务场景的需求。</p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">引入LruCache，将远端存放于Redis的信息本地化存储。LruCache可以预设缓存上限，这个上限可以根据服务所在机器内存与服务本身内存占用来确定，确保增加LruCache后，服务本身内存占用在安全范围内；同时可以根据查询操作统计缓存数据在实际使用中的命中率。</p> 
<p style="margin-left: 0.5em;margin-right: 0.5em;"><span style="color: rgb(51, 51, 51);font-family: Arial, sans-serif;font-size: 15px;white-space: pre-wrap;">下图是增加LruCache结构前后，且增加LruCache后命中率高于95%的情况下，针对持续增长的QPS得出的数据获取平均耗时(</span><span style="font-family: Arial, sans-serif;font-size: 15px;white-space: pre-wrap;color: rgb(136, 136, 136);">ms</span><span style="color: rgb(51, 51, 51);font-family: Arial, sans-serif;font-size: 15px;white-space: pre-wrap;">)对比图：</span><br></p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.4363827549947424" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aF7qPX9wUUt8hmY0QItt9uP2IsdBcdwwEEM8iaYqjHib1XxJa9C6LVtTA/640?wx_fmt=png" data-type="png" data-w="1902" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aF7qPX9wUUt8hmY0QItt9uP2IsdBcdwwEEM8iaYqjHib1XxJa9C6LVtTA/640?wx_fmt=png"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">根据平均耗时图显示可以得出结论：</p> 
<p style="margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<ol style="margin-left: 0.5em;margin-right: 0.5em;" class=" list-paddingleft-2"> 
 <li><p><span style="font-size: 14px;">QPS高于250后，直接请求Redis获取数据的平均耗时达到10ms以上，完全无法满足使用的需求。</span></p></li> 
 <li><p><span style="font-size: 14px;">增加LruCache结构后，耗时下降一个量级。从平均耗时角度看，QPS不高于500的情况下，耗时低于2ms。</span></p></li> 
</ol> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是增加LruCache结构前后，且增加LruCache后命中率高于95%的情况下，针对持续增长的QPS得出的数据获取Top999耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.4369747899159664" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4armdvNAxYAM8jshkQoiaKAAcqXMsXMGZzsMofSA2yyOX9jlweq6YTmeQ/640?wx_fmt=png" data-type="png" data-w="1904" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4armdvNAxYAM8jshkQoiaKAAcqXMsXMGZzsMofSA2yyOX9jlweq6YTmeQ/640?wx_fmt=png"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">根据Top999耗时图可以得出以下结论：</p> 
<p style="margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<ol style="margin-left: 0.5em;margin-right: 0.5em;" class=" list-paddingleft-2"> 
 <li><p><span style="font-size: 14px;">增加LruCache结构后，Top999耗时比平均耗时增长一个数量级。</span></p></li> 
 <li><p><span style="font-size: 14px;">即使是较低的QPS下，使用LruCache结构的Top999耗时也是比较高的。</span></p></li> 
</ol> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">引入LruCache结构，在实际使用中，在一定的QPS范围内，确实可以有效减少数据获取的耗时。但是QPS超出一定范围后，平均耗时和Top999耗时都很高。所以LruCache在更高的QPS下性能还需要进一步优化。</p> 
<h2 style="margin-top: 30px;font-size: 18px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">演进二：LruCache增加时效清退机制</h2> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">在业务场景中，Redis中的广告数据有可能做修改。服务本身作为数据的使用方，无法感知到数据源的变化。当缓存的命中率较高或者部分数据在较长时间内多次命中，可能出现数据失效的情况。即数据源发生了变化，但服务无法及时更新数据。针对这一业务场景，增加了时效清退机制。</p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">时效清退机制的组成部分有三点：设置缓存数据过期时间，缓存数据单元增加时间戳以及查询中的时效性判断。缓存数据单元将数据进入LruCache的时间戳与数据一起缓存下来。缓存过期时间表示缓存单元缓存的时间上限。查询中的时效性判断表示查询时的时间戳与缓存时间戳的差值超过缓存过期时间，则强制将此数据清空，重新请求Redis获取数据做缓存。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">在查询中做时效性判断可以最低程度的减少时效判断对服务的中断。当LruCache预设上限较低时，定期做全量数据清理对于服务本身影响较小。但如果LruCache的预设上限非常高，则一次全量数据清理耗时可能达到秒级甚至分钟级，将严重阻断服务本身的运行。所以将时效性判断加入到查询中，只对单一的缓存单元做时效性判断，在服务性能和数据有效性之间做了折中，满足业务需求。</p> 
<h2 style="margin-top: 30px;font-size: 18px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">演进三：高QPS下HashLruCache的应用</h2> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache引入美团DSP系统后，在一段时间内较好地支持了业务的发展。随着业务的迭代，单机QPS持续上升。在更高QPS下，LruCache的查询耗时有了明显的提高，逐渐无法适应低平响的业务场景。在这种情况下，引入了HashLruCache机制以解决这个问题。</p> 
<h3 style="margin-top: 30px;font-weight: bold;line-height: 1.5;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache在高QPS下的耗时增加原因分析</h3> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">线程安全的LruCache中有锁的存在。每次读写操作之前都有加锁操作，完成读写操作之后还有解锁操作。在低QPS下，锁竞争的耗时基本可以忽略；但是在高QPS下，大量的时间消耗在了等待锁的操作上，导致耗时增长。</p> 
<h3 style="margin-top: 30px;font-weight: bold;line-height: 1.5;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">HashLruCache适应高QPS场景</h3> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">针对大量的同步等待操作导致耗时增加的情况，解决方案就是尽量减小临界区。引入Hash机制，对全量数据做分片处理，在原有LruCache的基础上形成HashLruCache，以降低查询耗时。</p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">HashLruCache引入某种哈希算法，将缓存数据分散到N个LruCache上。最简单的哈希算法即使用取模算法，将广告信息按照其ID取模，分散到N个LruCache上。查询时也按照相同的哈希算法，先获取数据可能存在的分片，然后再去对应的分片上查询数据。这样可以增加LruCache的读写操作的并行度，减小同步等待的耗时。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是使用16分片的HashLruCache结构前后，且命中率高于95%的情况下，针对持续增长的QPS得出的数据获取平均耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.4368421052631579" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aysiatvUesbW1icKXOgUOraOqdqyibhBGQJzs4WibmRTaLwgmIq8dL1ayrQ/640?wx_fmt=png" data-type="png" data-w="1900" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aysiatvUesbW1icKXOgUOraOqdqyibhBGQJzs4WibmRTaLwgmIq8dL1ayrQ/640?wx_fmt=png"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">根据平均耗时图可以得出以下结论：</p> 
<p style="margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<ol style="margin-left: 0.5em;margin-right: 0.5em;" class=" list-paddingleft-2"> 
 <li><p><span style="font-size: 14px;">使用HashLruCache后，平均耗时减少将近一半，效果比较明显。</span></p></li> 
 <li><p><span style="font-size: 14px;">对比不使用HashLruCache的平均耗时可以发现，使用HashLruCache的平均耗时对QPS的增长不敏感，没有明显增长。</span></p></li> 
</ol> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是使用16分片的HashLruCache结构前后，且命中率高于95%的情况下，针对持续增长的QPS得出的数据获取Top999耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.43274244004171014" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aqn1NHPCCiazygADpvUdZ2FOBBLs01prfvjO9f8u0yDftmxJy1QNg5Sg/640?wx_fmt=png" data-type="png" data-w="1918" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aqn1NHPCCiazygADpvUdZ2FOBBLs01prfvjO9f8u0yDftmxJy1QNg5Sg/640?wx_fmt=png"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">根据Top999耗时图可以得出以下结论：</p> 
<p style="margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<ol style="margin-left: 0.5em;margin-right: 0.5em;" class=" list-paddingleft-2"> 
 <li><p><span style="font-size: 14px;">使用HashLruCache后，Top999耗时减少为未使用时的三分之一左右，效果非常明显。</span></p></li> 
 <li><p><span style="font-size: 14px;">使用HashLruCache的Top999耗时随QPS增长明显比不使用的情况慢，相对来说对QPS的增长敏感度更低。</span></p></li> 
</ol> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">引入HashLruCache结构后，在实际使用中，平均耗时和Top999耗时都有非常明显的下降，效果非常显著。</p> 
<h3 style="margin: 30px 0.5em 15px;font-weight: bold;line-height: 1.5;font-family: Arial, sans-serif;white-space: pre-wrap;">HashLruCache分片数量确定</h3> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">根据以上分析，进一步提高HashLruCache性能的一个方法是确定最合理的分片数量，增加足够的并行度，减少同步等待消耗。所以分片数量可以与CPU数量一致。由于超线程技术的使用，可以将分片数量进一步提高，增加并行性。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是使用HashLruCache机制后，命中率高于95%，不同分片数量在不同QPS下得出的数据获取平均耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.4247697031729785" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4ajTY2RKCK0VlZwGntUheO1rp8caic3GkJ00jy6u6YCSkmITNYVkd4gyA/640?wx_fmt=png" data-type="png" data-w="1954" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4ajTY2RKCK0VlZwGntUheO1rp8caic3GkJ00jy6u6YCSkmITNYVkd4gyA/640?wx_fmt=png"></p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">平均耗时图显示，在较高的QPS下，平均耗时并没有随着分片数量的增加而有明显的减少，基本维持稳定的状态。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是使用HashLruCache机制后，命中率高于95%，不同分片数量在不同QPS下得出的数据获取Top999耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.43243243243243246" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4au0Nk7rHL3WFqicGUopFWG7Tt17nZiaMiceOo2tSsaqvCE5GFxbLlOe74w/640?wx_fmt=png" data-type="png" data-w="1924" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4au0Nk7rHL3WFqicGUopFWG7Tt17nZiaMiceOo2tSsaqvCE5GFxbLlOe74w/640?wx_fmt=png"></p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">Top999耗时图显示，QPS为750时，分片数量从8增长到16再增长到24时，Top999耗时有一定的下降，并不显著；QPS为1000时，分片数量从8增长到16有明显下降，但是从16增长到24时，基本维持了稳定状态。明显与实际使用的机器CPU数量有较强的相关性。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">HashLruCache机制在实际使用中，可以根据机器性能并结合实际场景的QPS来调节分片数量，以达到最好的性能。</p> 
<h2 style="margin: 30px 0.5em 15px;font-size: 18px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;">演进四：零拷贝机制</h2> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">线程安全的LruCache内部维护一套数据。对外提供数据时，将对应的数据完整拷贝一份提供给调用方使用。如果存放结构简单的数据，拷贝操作的代价非常小，这一机制不会成为性能瓶颈。但是美团DSP系统的应用场景中，LruCache中存放的数据结构非常复杂，单次的拷贝操作代价很大，导致这一机制变成了性能瓶颈。</p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">理想的情况是LruCache对外仅仅提供数据地址，即数据指针。使用方在业务需要使用的地方通过数据指针获取数据。这样可以将复杂的数据拷贝操作变为简单的地址拷贝，大量减少拷贝操作的性能消耗，即数据的零拷贝机制。直接的零拷贝机制存在安全隐患，即由于LruCache中的时效清退机制，可能会出现某一数据已经过期被删除，但是使用方仍然通过持有失效的数据指针来获取该数据。</p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">进一步分析可以确定，以上问题的核心是存放于LruCache的数据生命周期对于使用方不透明。解决这一问题的方案是为LruCache中存放的数据添加原子变量的引用计数。使用原子变量不仅确保了引用计数的线程安全，使得各个线程读取的引用计数一致，同时保证了并发状态最小的同步性能开销。不论是LruCache中还是使用方，每次获取数据指针时，即将引用计数加1；同理，不再持有数据指针时，引用计数减1。当引用计数为0时，说明数据没有被任何使用方使用，且数据已经过期从LruCache中被删除。这时删除数据的操作是安全的。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是使零拷贝机制后，命中率高于95%，不同QPS下得出的数据获取平均耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.4297435897435897" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4acUWRiacBicdibSJzfHzTTOSkOvQqiaMgKQVqHwRtmkWgPyx8GqMRIrVFQA/640?wx_fmt=png" data-type="png" data-w="1950" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4acUWRiacBicdibSJzfHzTTOSkOvQqiaMgKQVqHwRtmkWgPyx8GqMRIrVFQA/640?wx_fmt=png"></p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">平均耗时图显示，使用零拷贝机制后，平均耗时下降幅度超过60%，效果非常显著。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是使零拷贝机制后，命中率高于95%，不同QPS下得出的数据获取Top999耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.43756558237145854" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aWB6fq26nFU44V4XjbU25RvvB1WV59niaeJooKk55LWgVUxsbPlGrCBg/640?wx_fmt=png" data-type="png" data-w="1906" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aWB6fq26nFU44V4XjbU25RvvB1WV59niaeJooKk55LWgVUxsbPlGrCBg/640?wx_fmt=png"></p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">根据Top999耗时图可以得出以下结论：</p> 
<p style="margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<ol style="margin-left: 0.5em;margin-right: 0.5em;" class=" list-paddingleft-2"> 
 <li><p><span style="font-size: 14px;">使用零拷贝后，Top999耗时降幅将近50%，效果非常明显。</span></p></li> 
 <li><p><span style="font-size: 14px;">在高QPS下，使用零拷贝机制的Top999耗时随QPS增长明显比不使用的情况慢，相对来说对QPS的增长敏感度更低。</span></p></li> 
</ol> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">引入零拷贝机制后，通过拷贝指针替换拷贝数据，大量降低了获取复杂业务数据的耗时，同时将临界区减小到最小。线程安全的原子变量自增与自减操作，目前在多个基础库中都有实现，例如C++11就提供了内置的整型原子变量，实现线程安全的自增与自减操作。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">在HashLruCache中引入零拷贝机制，可以进一步有效降低平均耗时和Top999耗时，且在高QPS下对于稳定Top999耗时有非常好的效果。</p> 
<h1 style="margin-top: 30px;color: rgb(95, 185, 173);font-size: 20px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">总结</h1> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是一系列优化措施前后，命中率高于95%，不同QPS下得出的数据获取平均耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.4287118977384464" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4a33TZK0vye0lEFsrqmO47pW371ycNtVFXOxDkz2A6UUWFYArmVRwkLA/640?wx_fmt=png" data-type="png" data-w="2034" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4a33TZK0vye0lEFsrqmO47pW371ycNtVFXOxDkz2A6UUWFYArmVRwkLA/640?wx_fmt=png"></p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">平均耗时图显示，优化后的平均耗时仅为优化前的20%以内，性能提升非常明显。优化后平均耗时对于QPS的增长敏感度更低，更好的支持了高QPS的业务场景。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">下图是一系列优化措施前后，命中率高于95%，不同QPS下得出的数据获取Top999耗时(<span style="color: rgb(136, 136, 136);">ms</span>)对比图：</p> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.422963689892051" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aa6qD0ibNHqFXZckZPrz6kO0xZjQGpmzWiaJRb0cneZicp1iahYwssNiayZQ/640?wx_fmt=png" data-type="png" data-w="2038" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXQz8Kq5ibuicSEnPJFYFHy4aa6qD0ibNHqFXZckZPrz6kO0xZjQGpmzWiaJRb0cneZicp1iahYwssNiayZQ/640?wx_fmt=png"></p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">Top999耗时图显示，优化后的Top999耗时仅为优化前的20%以内，对于长尾请求的耗时有非常明显的降低。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">LruCache是一个非常常见的数据结构。在美团DSP的高QPS业务场景下，发挥了重要的作用。为了符合业务需要，在原本的清退机制外，补充了时效性强制清退机制。随着业务的发展，针对更高QPS的业务场景，使用HashLruCache机制，降低缓存的查询耗时。针对不同的具体场景，在不同的QPS下，不断尝试更合理的分片数量，不断提高HashLruCache的查询性能。通过引用计数的方案，在HashLruCache中引入零拷贝机制，进一步大幅降低平均耗时和Top999耗时，更好的服务于业务场景的发展。</p> 
<h1 style="margin-top: 30px;color: rgb(95, 185, 173);font-size: 20px;font-weight: bold;line-height: 1.25;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">作者简介</h1> 
<p style="margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">王粲，2018年11月加入美团，任职美团高级工程师，负责美团DSP系统后端基础架构的研发工作。</p> 
<p style="margin: 10px 0.5em 15px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;">崔涛，2015年6月加入美团，任职资深广告技术专家，期间一手指导并从0到1搭建美团DSP投放平台，具备丰富的大规模计算引擎的开发和性能优化经验。</p> 
<p style="margin-top: 10px;font-size: 15px;color: rgb(51, 51, 51);font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;">霜霜，2015年6月加入美团，任职美团高级工程师，美团DSP系统后端基础架构与机器学习架构负责人，全面负责DSP业务广告召回和排序服务的架构设计与优化。</p> 
<p style="margin-top: 10px;font-size: 15px;font-family: Arial, sans-serif;white-space: pre-wrap;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 15px;white-space: pre-wrap;max-width: 100%;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-align: justify;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="color: rgb(136, 136, 136);max-width: 100%;">欢迎加入<strong style="max-width: 100%;color: rgb(51, 51, 51);box-sizing: border-box !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(0, 0, 0);box-sizing: border-box !important;overflow-wrap: break-word !important;">美团计算广告技术交流群</span></strong>，跟作者零距离交流。进群方式：请加美美同学<span style="max-width: 100%;letter-spacing: 0px;box-sizing: border-box !important;overflow-wrap: break-word !important;">微信（微信号：</span></span><span style="max-width: 100%;letter-spacing: 0px;"><strong style="color: rgb(136, 136, 136);max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;">MTDPtech02</strong><strong style="color: rgb(136, 136, 136);max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;">）</strong><span style="color: rgb(136, 136, 136);max-width: 100%;box-sizing: border-box !important;overflow-wrap: break-word !important;">，回复：</span></span></span><span style="font-size: 15px;white-space: pre-wrap;max-width: 100%;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;letter-spacing: 0.544px;text-align: justify;background-color: rgb(255, 255, 255);color: rgb(0, 0, 0);box-sizing: border-box !important;overflow-wrap: break-word !important;"><strong>计算<span style="color:#333333;"><strong>广告</strong></span></strong></span><span style="color: rgb(136, 136, 136);font-size: 15px;letter-spacing: 0px;white-space: pre-wrap;max-width: 100%;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: justify;background-color: rgb(255, 255, 255);box-sizing: border-box !important;overflow-wrap: break-word !important;">，美美会自动拉你进群。</span></p> 
<p style="white-space: normal;color: rgb(51, 51, 51);margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<p style="white-space: normal;color: rgb(51, 51, 51);text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 15px;color: rgb(136, 136, 136);">----------&nbsp; END&nbsp; ----------</span></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 16px;"><strong><span style="color: rgb(49, 188, 173);">也许你还想看</span></strong></span></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651746285&amp;idx=1&amp;sn=63f6eab7f3882d184a211ba80e6317bc&amp;chksm=bd12b6a08a653fb64f000d2dc1b90d21bd75d6c92d64daed46e7732041ebc310adef6e7c8b90&amp;scene=21#wechat_redirect" target="_blank" style="font-size: 14px;text-decoration: underline;" data-linktype="2"><span style="font-size: 14px;">美团DSP广告策略实践</span></a><br></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651748603&amp;idx=1&amp;sn=b09362d81941732e7d9c69f309a9e2e2&amp;chksm=bd12a1b68a6528a04f23782a01e6cd2f9a610261b8c640b1411ffe82e6fea33255ee9c93d95a&amp;scene=21#wechat_redirect" target="_blank" style="font-size: 14px;text-decoration: underline;" data-linktype="2"><span style="font-size: 14px;">美团O2O广告营销中的机器学习技术</span></a><br></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 14px;text-decoration: underline;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651748088&amp;idx=1&amp;sn=2ff120396897b31897a222a2176eea25&amp;chksm=bd12afb58a6526a306529374daaea3fc14edd2f68ebfd1f32ce1250352021a681334ca433428&amp;scene=21#wechat_redirect" target="_blank" style="font-size: 14px;text-decoration: underline;" data-linktype="2">深度学习在美团搜索广告排序的应用实践</a></span></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;text-align: center;"><img class="" data-copyright="0" data-ratio="0.44533333333333336" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsV6LYkM3uK5TAnl8DxXwdR4YOAKWmYSpAtzV3P359bDG3cn3Vr4T6HMkvDSI8icUYsejmDnfa5CdpQ/640?wx_fmt=png" data-type="png" data-w="1875" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsV6LYkM3uK5TAnl8DxXwdR4YOAKWmYSpAtzV3P359bDG3cn3Vr4T6HMkvDSI8icUYsejmDnfa5CdpQ/640?wx_fmt=png"></p>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
