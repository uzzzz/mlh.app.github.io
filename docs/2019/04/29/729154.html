<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>美团深度学习系统的工程实践 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="美团深度学习系统的工程实践" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="总第293篇 2018年 第85篇 背景 深度学习作为AI时代的核心技术，已经被应用于众多场景。在系统设计层面，由于它具有计算密集的特性，所以与传统的机器学习算法在工程实践过程中存在诸多的不同。本文将介绍美团平台在应用深度学习技术的过程中，相关系统设计的一些经验。 本文将首先列举部分深度学习算法所需的计算量，然后再介绍为满足这些计算量，目前业界比较常见的一些解决方案。最后，我们将介绍美团平台在NLU和语音识别两个领域中，设计相关系统的经验。 深度学习的计算量 数据来源上表列举了，ImageNet图像识别中常见算法的模型大小以及单张图片一次训练（One Pass）所需要的计算量。 自2012年，Hinton的学生Alex Krizhevsky提出AlexNet，一举摘下ILSVRC 2012的桂冠后，ILSVRC比赛冠军的准确率越来越高。与此同时，其中使用到的深度学习算法也越来越复杂，所需要的计算量也越来越大。SENet与AlexNet相比，计算量多了近30倍。我们知道，ImageNet大概有120万张图片，以SENet为例，如果要完成100个epoch的完整训练，将需要2.52 * 10^18的计算量。如此庞大的计算量，已经远远超出传统的机器学习算法的范畴。更别说，Google在论文《Revisiting Unreasonable Effectiveness of Data in Deep Learning Era》中提及的、比ImageNet大300倍的数据集。 物理计算性能 面对如此庞大的计算量，那么，我们业界当前常用的计算单元的计算力是多少呢？ CPU 物理核：一般浮点运算能力在10^10 FLOPS量级。一台16 Cores的服务器，大致上有200 GFLOPS的运算能力。实际运行，CPU 大概能用到80%的性能，那就160 GFLOPS的运算能力。完成上述SENet运行，需要182天。 NVIDIA GPGPU： 目前的V100，单精度浮点运算的峰值大概为14 TFLOPS， 实际运行中，我们假设能用到50%的峰值性能，那就是7 TFLOPS，需要4天。 根据以上数据结果可以看出：在深度学习领域，GPU训练数据集所需要耗费的时间，远远少于CPU，这也是当前深度学习训练都是采用GPU的重要原因。 业界的解决方案 从前面的计算可知，即使使用GPU来计算，训练一次ImageNet 也需要4天的时间。但对于算法工程师做实验、调参而言，这种耗时数天的等待是难以忍受的。为此，目前业界针对深度学习训练的加速，提出了各种各样的解决方案。 异构计算的并行方案 数据并行（Data Parallelism） 数据并行，即每个计算单元都保留一份完整的模型拷贝，分别训练不同的数据，经过一个Iteration或若干个Iteration后，把各个计算单元的模型做一次同步。这是最常见的深度学习训练方式，好处在于逻辑简单、代码实现方便。 模型并行（Model Parallelism） 模型并行，即各个计算单元存储同一层模型数据的不同部分，训练相同的数据。相对于数据并行，因为各个运算单元每训练完一层神经网络，就必须要同步一次，频繁的同步通信导致系统不能充分地利用硬件的运算能力，所以更为少见。但是在一些业务场景下，Softmax层需要分类的类别可能会有很多，导致Softmax层太大，单个计算单元无法存储，这时需要把模型切割成若干部分，存储在不同的运算单元。模型并行常见于NLU、推荐、金融等领域。 流式并行（Stream Parallelism） 流式并行，即每个计算单元都存储不同层的模型数据，训练相同的数据。如上图所示，GPU1只负责第一层神经网络的计算，GPU2只负责2~5层神经网络的计算，GPU3只负责第6层的计算。流式并行的好处在于每个运算单元之间的通信和计算重叠（ overlap ），如果配置得当，可以非常充分地利用硬件资源。缺点在于，根据不同的模型，需要平衡好各个计算单元的计算量，如果配置不好，很容易形成“堰塞湖”。如上图所示，很有可能出现GPU1 负责的运算量太少，而GPU2 负责的运算量太多，导致GPU1 和GPU2 之间堵塞住大量的Mini-batch，更常见于线上环境。 混合并行（Hybrid Parallelism） 混合并行，即上面提到的并行方式的混合。如对于一些图像识别任务来说，可能前几层使用数据并行，最后的Softmax层，使用模型并行。 异构计算的硬件解决方案 单机单卡：一个主机内安装上一块GPU运算卡。常见于个人计算机。 单机多卡：一个主机内安装上多块GPU运算卡。常见的有：1机4卡，1机8卡，甚至有1机10卡。一般公司都采取这种硬件方案。 多机多卡：多台主机内安装多块GPU运算卡。常见于公司内部的计算集群，一般多机之间采取Infiniband 来实现网络的快速通信。 定制化：即类似于Google的TPU解决方案。常见于“巨无霸”公司内部。 异构计算的通信解决方案 根据上面的硬件解决方案，我们以ResNet为例：模型的大小为230M，单张图片运算量为11 GFLPOS，Mini-batch假设为128。可以计算出各个硬件模块在深度学习训练中的耗时比较： GPU：对于V100，假设有6 TFLOPS，一次Mini-batch 理论耗时：0.23s。 PCI-E：常见PCI-E 3.0 * 16，速度为10 GB/s，传输一个模型的理论耗时为：0.023s。 网络：假设为10 GB/s的高速网络，传输一个模型的理论耗时：0.023s。 Disk：普通的磁盘，我们假设200M/s的读取速度，读取一次Mini-batch所需要的图片耗时：0.094s。 根据上面的数据结果，我们似乎可以得出一个结论：PCI-E和网络的传输耗时，相对于GPU来说，整整少了一个数量级，所以网络通信同步的时间可以忽略不计。然而问题并没有那么简单，上面例子中的耗时只是单个模型的耗时，但是对于8卡的集群来说，如果使用数据并行，每次同步就需要传输8份模型，这就导致数据传输的时间和GPU的计算时间“旗鼓相当”。这样的话，GPU就得每训练完一个Mini-batch，都得等候很久的一段时间（采取同步更新），这会浪费很多计算资源。因此，网络通信也需要制定对应的解决方案。下面我们以Nvidia NCCL中单机多卡的通信解决方案为例介绍，而多机多卡的通信解决方案其实是类似的。 上图是单机4卡机器，在硬件上是两种不同的通信体系。左边为普通的PCI-E通信，即4个GPU之间组成一个环状。右边为NVLink通信，即两两之间相互连接。 常见的通信类型如下图所示： 对于深度学习训练而言，关键的两种通信类型为：Broadcast和Reduce。Broadcast用于Master分发最新的模型给各个GPU。Reduce 用于各个GPU计算完Mini-batch后，把模型更新值汇总到Master上。以Broadcast为例，最简单的通信方式是Master往各个GPU上发送数据，这样的耗时就是4次模型传输的时间，通信时间就会太长，一种简单的优化方法如下图所示： 即把所需要传输的数据分成若干块，然后通过接力的方式逐个传递，每个GPU都把自己最新的一块数据发送到下一个GPU卡上。这种传输方式能充分利用硬件层面的通信结构，使得需要的耗时大幅缩减。与此类似，Reduce的通信优化也可以采取相同的方式进行提速。 美团的定制化深度学习系统 尽管目前在业界已经推出了很多著名的深度学习训练平台，通用的训练平台如TensorFlow、MxNet等等，还有领域专用的训练平台，如语音识别中的Kaldi，但是我们经过调研后，决定内部自主开发一套深度学习系统，理由如下： 通用的训练平台，缺乏了领域特色的功能。如语音识别中的特征提取模块和算法。 通用的训练平台，通常是基于Data-flow Graph，来对计算图中的每个operator进行建模，所以颗粒度很小，需要调度的单元多，导任务调度复杂。 领域特色的训练平台，如Kaldi，在神经网络训练的时候，性能不足。 线上业务存在很多特殊性，如果使用TensorFlow之类作为训练平台，不太适合线上业务的情景。 NLU线上系统 线上系统的业务特点 我们在设计NLU线上系统时，考虑了NLU业务的一些特性。发现其具备如下的一些特点： 随着业务和技术的变化，算法流程也经常发生变化。 算法流程是多个算法串联组成的，不单纯的只有深度学习算法。如分词等算法就不是DL算法。 为了能够快速响应一些紧急问题，需要经常对模型进行热更新。 更重要的是，我们希望构建一个能以“数据驱动”的自动迭代闭环。 业务多变 NLU任务的算法流程是多层级的，并且业务经常发生变化。如下图所示： 即随着业务要求的变化，NLU系统一开始的算法流程，只需要把一个Query分为两个类，但是到后面，极有可能会变成需要分为三个类别。 热更新 根据业务需求，或者为了紧急处理一些特殊问题，NLU线上系统经常需要做出快速响应，热更新算法模型。如最近的热点词“skr”，几乎是一夜之间，突然火爆起来。如下图所示的微博，如果不能正确理解“skr”的正确语义，可能就不能准确理解这条微博想要表达的意思。 为了避免影响用户体验，我们可能会对NLU系统，马上进行热更新，把新模型紧急进行上线。 数据驱动的自动迭代闭环 对于线上系统而言，构建如上图所示的自动迭代闭环，能更好地利用业务数据来提升服务质量。 NLU线上系统的核心设计 算法流程的抽象 为了适应线上系统串联、多变的算法流程，我们把线上系统的算法进行抽象，如下图所示： 即每一个算法，都依赖于若干个槽位（ Slot ）和资源（ Resource ），一旦槽位和资源就位，就会触发对应的算法执行。算法的执行先通过算法适配器，来适配槽位和资源中的数据，转换成算子的输入格式。然后算子执行算法本身，执行完算子后，再经过算法解析器。算法解析器主要用于解析算法执行的结果，触发对应的槽位。如根据算法的结果，触发Top 3的结果。 多个算法串联起来，就构建成如下结果： 热更新流程的设计 如上图所示，我们把算法的热更新流程设计如上。初试状态为左上角，即多个Query使用同一份模型数据。当遇到模型更新的请求后，系统将会block住新的query（ 右上角状态 ）。然后更新模型完后，新的query使用新的模型，旧query依然使用旧模型（ 右下角状态 ）。最后，当使用旧模型的query结束后，把旧的模型从内存中删除（ 左下角 ），然后系统恢复到初始状态。 声学模型训练系统 因为TensorFlow等通用深度学习训练平台，缺乏了特征提取等业务相关的领域功能，而Kaldi的声学模型训练过程又太慢。所以美团开发了一个声学模型训练系统——Mimir，其具备如下特性： 使用比TensorFlow更粗颗粒度的建模单元，使得任务调度、优化更简单方便易行。 使用数据并行的并行方案，单机多卡可达到近线性加速。（采取同步更新策略下，4卡加速比达到3.8） 移植了Kaldi的一些特有的训练算法。 速度上为Kaldi的6~7倍。（800个小时的训练数据，单机单卡的条件下，Kaldi需要6~7天， Mimir只需20个小时） 业务上，移植了Kaldi的特征提取等领域的相关模块。 参考资料 NCCL: ACCELERATED MULTI-GPU COLLECTIVE COMMUNICATIONS 老师木讲架构：深度学习平台技术演进 作者简介 剑鹏，美团点评算法专家。2017年加入美团，目前作为语音识别团队的声学模型负责人，负责声学模型相关的算法和系统设计与开发。 欢迎加入美团深度学习技术交流群，跟作者零距离交流。请加美美同学的微信（微信号：MTDPtech01），回复：深度学习，美美会自动拉你进群。 1024中奖名单公布 亲爱的读者朋友们，有没有被我们昨天的成长大礼包感动到，是不是一份很中肯的1024礼物。在昨天文章的最后，我们还特别赠送了一份额外大礼包，抽中的小伙伴不要被感动哭哦～ 抽奖结果已揭晓，名单如下： 中奖的读者朋友不要着急，奖品已经在路上，请注意查收，收到之后记得给好评哟！手动笔心～ ----------&nbsp; END&nbsp; ---------- 也许你还想看 基于TensorFlow Serving的深度学习在线预估 深度学习在美团点评推荐平台排序中的运用美团如何基于深度学习实现图像的智能审核？" />
<meta property="og:description" content="总第293篇 2018年 第85篇 背景 深度学习作为AI时代的核心技术，已经被应用于众多场景。在系统设计层面，由于它具有计算密集的特性，所以与传统的机器学习算法在工程实践过程中存在诸多的不同。本文将介绍美团平台在应用深度学习技术的过程中，相关系统设计的一些经验。 本文将首先列举部分深度学习算法所需的计算量，然后再介绍为满足这些计算量，目前业界比较常见的一些解决方案。最后，我们将介绍美团平台在NLU和语音识别两个领域中，设计相关系统的经验。 深度学习的计算量 数据来源上表列举了，ImageNet图像识别中常见算法的模型大小以及单张图片一次训练（One Pass）所需要的计算量。 自2012年，Hinton的学生Alex Krizhevsky提出AlexNet，一举摘下ILSVRC 2012的桂冠后，ILSVRC比赛冠军的准确率越来越高。与此同时，其中使用到的深度学习算法也越来越复杂，所需要的计算量也越来越大。SENet与AlexNet相比，计算量多了近30倍。我们知道，ImageNet大概有120万张图片，以SENet为例，如果要完成100个epoch的完整训练，将需要2.52 * 10^18的计算量。如此庞大的计算量，已经远远超出传统的机器学习算法的范畴。更别说，Google在论文《Revisiting Unreasonable Effectiveness of Data in Deep Learning Era》中提及的、比ImageNet大300倍的数据集。 物理计算性能 面对如此庞大的计算量，那么，我们业界当前常用的计算单元的计算力是多少呢？ CPU 物理核：一般浮点运算能力在10^10 FLOPS量级。一台16 Cores的服务器，大致上有200 GFLOPS的运算能力。实际运行，CPU 大概能用到80%的性能，那就160 GFLOPS的运算能力。完成上述SENet运行，需要182天。 NVIDIA GPGPU： 目前的V100，单精度浮点运算的峰值大概为14 TFLOPS， 实际运行中，我们假设能用到50%的峰值性能，那就是7 TFLOPS，需要4天。 根据以上数据结果可以看出：在深度学习领域，GPU训练数据集所需要耗费的时间，远远少于CPU，这也是当前深度学习训练都是采用GPU的重要原因。 业界的解决方案 从前面的计算可知，即使使用GPU来计算，训练一次ImageNet 也需要4天的时间。但对于算法工程师做实验、调参而言，这种耗时数天的等待是难以忍受的。为此，目前业界针对深度学习训练的加速，提出了各种各样的解决方案。 异构计算的并行方案 数据并行（Data Parallelism） 数据并行，即每个计算单元都保留一份完整的模型拷贝，分别训练不同的数据，经过一个Iteration或若干个Iteration后，把各个计算单元的模型做一次同步。这是最常见的深度学习训练方式，好处在于逻辑简单、代码实现方便。 模型并行（Model Parallelism） 模型并行，即各个计算单元存储同一层模型数据的不同部分，训练相同的数据。相对于数据并行，因为各个运算单元每训练完一层神经网络，就必须要同步一次，频繁的同步通信导致系统不能充分地利用硬件的运算能力，所以更为少见。但是在一些业务场景下，Softmax层需要分类的类别可能会有很多，导致Softmax层太大，单个计算单元无法存储，这时需要把模型切割成若干部分，存储在不同的运算单元。模型并行常见于NLU、推荐、金融等领域。 流式并行（Stream Parallelism） 流式并行，即每个计算单元都存储不同层的模型数据，训练相同的数据。如上图所示，GPU1只负责第一层神经网络的计算，GPU2只负责2~5层神经网络的计算，GPU3只负责第6层的计算。流式并行的好处在于每个运算单元之间的通信和计算重叠（ overlap ），如果配置得当，可以非常充分地利用硬件资源。缺点在于，根据不同的模型，需要平衡好各个计算单元的计算量，如果配置不好，很容易形成“堰塞湖”。如上图所示，很有可能出现GPU1 负责的运算量太少，而GPU2 负责的运算量太多，导致GPU1 和GPU2 之间堵塞住大量的Mini-batch，更常见于线上环境。 混合并行（Hybrid Parallelism） 混合并行，即上面提到的并行方式的混合。如对于一些图像识别任务来说，可能前几层使用数据并行，最后的Softmax层，使用模型并行。 异构计算的硬件解决方案 单机单卡：一个主机内安装上一块GPU运算卡。常见于个人计算机。 单机多卡：一个主机内安装上多块GPU运算卡。常见的有：1机4卡，1机8卡，甚至有1机10卡。一般公司都采取这种硬件方案。 多机多卡：多台主机内安装多块GPU运算卡。常见于公司内部的计算集群，一般多机之间采取Infiniband 来实现网络的快速通信。 定制化：即类似于Google的TPU解决方案。常见于“巨无霸”公司内部。 异构计算的通信解决方案 根据上面的硬件解决方案，我们以ResNet为例：模型的大小为230M，单张图片运算量为11 GFLPOS，Mini-batch假设为128。可以计算出各个硬件模块在深度学习训练中的耗时比较： GPU：对于V100，假设有6 TFLOPS，一次Mini-batch 理论耗时：0.23s。 PCI-E：常见PCI-E 3.0 * 16，速度为10 GB/s，传输一个模型的理论耗时为：0.023s。 网络：假设为10 GB/s的高速网络，传输一个模型的理论耗时：0.023s。 Disk：普通的磁盘，我们假设200M/s的读取速度，读取一次Mini-batch所需要的图片耗时：0.094s。 根据上面的数据结果，我们似乎可以得出一个结论：PCI-E和网络的传输耗时，相对于GPU来说，整整少了一个数量级，所以网络通信同步的时间可以忽略不计。然而问题并没有那么简单，上面例子中的耗时只是单个模型的耗时，但是对于8卡的集群来说，如果使用数据并行，每次同步就需要传输8份模型，这就导致数据传输的时间和GPU的计算时间“旗鼓相当”。这样的话，GPU就得每训练完一个Mini-batch，都得等候很久的一段时间（采取同步更新），这会浪费很多计算资源。因此，网络通信也需要制定对应的解决方案。下面我们以Nvidia NCCL中单机多卡的通信解决方案为例介绍，而多机多卡的通信解决方案其实是类似的。 上图是单机4卡机器，在硬件上是两种不同的通信体系。左边为普通的PCI-E通信，即4个GPU之间组成一个环状。右边为NVLink通信，即两两之间相互连接。 常见的通信类型如下图所示： 对于深度学习训练而言，关键的两种通信类型为：Broadcast和Reduce。Broadcast用于Master分发最新的模型给各个GPU。Reduce 用于各个GPU计算完Mini-batch后，把模型更新值汇总到Master上。以Broadcast为例，最简单的通信方式是Master往各个GPU上发送数据，这样的耗时就是4次模型传输的时间，通信时间就会太长，一种简单的优化方法如下图所示： 即把所需要传输的数据分成若干块，然后通过接力的方式逐个传递，每个GPU都把自己最新的一块数据发送到下一个GPU卡上。这种传输方式能充分利用硬件层面的通信结构，使得需要的耗时大幅缩减。与此类似，Reduce的通信优化也可以采取相同的方式进行提速。 美团的定制化深度学习系统 尽管目前在业界已经推出了很多著名的深度学习训练平台，通用的训练平台如TensorFlow、MxNet等等，还有领域专用的训练平台，如语音识别中的Kaldi，但是我们经过调研后，决定内部自主开发一套深度学习系统，理由如下： 通用的训练平台，缺乏了领域特色的功能。如语音识别中的特征提取模块和算法。 通用的训练平台，通常是基于Data-flow Graph，来对计算图中的每个operator进行建模，所以颗粒度很小，需要调度的单元多，导任务调度复杂。 领域特色的训练平台，如Kaldi，在神经网络训练的时候，性能不足。 线上业务存在很多特殊性，如果使用TensorFlow之类作为训练平台，不太适合线上业务的情景。 NLU线上系统 线上系统的业务特点 我们在设计NLU线上系统时，考虑了NLU业务的一些特性。发现其具备如下的一些特点： 随着业务和技术的变化，算法流程也经常发生变化。 算法流程是多个算法串联组成的，不单纯的只有深度学习算法。如分词等算法就不是DL算法。 为了能够快速响应一些紧急问题，需要经常对模型进行热更新。 更重要的是，我们希望构建一个能以“数据驱动”的自动迭代闭环。 业务多变 NLU任务的算法流程是多层级的，并且业务经常发生变化。如下图所示： 即随着业务要求的变化，NLU系统一开始的算法流程，只需要把一个Query分为两个类，但是到后面，极有可能会变成需要分为三个类别。 热更新 根据业务需求，或者为了紧急处理一些特殊问题，NLU线上系统经常需要做出快速响应，热更新算法模型。如最近的热点词“skr”，几乎是一夜之间，突然火爆起来。如下图所示的微博，如果不能正确理解“skr”的正确语义，可能就不能准确理解这条微博想要表达的意思。 为了避免影响用户体验，我们可能会对NLU系统，马上进行热更新，把新模型紧急进行上线。 数据驱动的自动迭代闭环 对于线上系统而言，构建如上图所示的自动迭代闭环，能更好地利用业务数据来提升服务质量。 NLU线上系统的核心设计 算法流程的抽象 为了适应线上系统串联、多变的算法流程，我们把线上系统的算法进行抽象，如下图所示： 即每一个算法，都依赖于若干个槽位（ Slot ）和资源（ Resource ），一旦槽位和资源就位，就会触发对应的算法执行。算法的执行先通过算法适配器，来适配槽位和资源中的数据，转换成算子的输入格式。然后算子执行算法本身，执行完算子后，再经过算法解析器。算法解析器主要用于解析算法执行的结果，触发对应的槽位。如根据算法的结果，触发Top 3的结果。 多个算法串联起来，就构建成如下结果： 热更新流程的设计 如上图所示，我们把算法的热更新流程设计如上。初试状态为左上角，即多个Query使用同一份模型数据。当遇到模型更新的请求后，系统将会block住新的query（ 右上角状态 ）。然后更新模型完后，新的query使用新的模型，旧query依然使用旧模型（ 右下角状态 ）。最后，当使用旧模型的query结束后，把旧的模型从内存中删除（ 左下角 ），然后系统恢复到初始状态。 声学模型训练系统 因为TensorFlow等通用深度学习训练平台，缺乏了特征提取等业务相关的领域功能，而Kaldi的声学模型训练过程又太慢。所以美团开发了一个声学模型训练系统——Mimir，其具备如下特性： 使用比TensorFlow更粗颗粒度的建模单元，使得任务调度、优化更简单方便易行。 使用数据并行的并行方案，单机多卡可达到近线性加速。（采取同步更新策略下，4卡加速比达到3.8） 移植了Kaldi的一些特有的训练算法。 速度上为Kaldi的6~7倍。（800个小时的训练数据，单机单卡的条件下，Kaldi需要6~7天， Mimir只需20个小时） 业务上，移植了Kaldi的特征提取等领域的相关模块。 参考资料 NCCL: ACCELERATED MULTI-GPU COLLECTIVE COMMUNICATIONS 老师木讲架构：深度学习平台技术演进 作者简介 剑鹏，美团点评算法专家。2017年加入美团，目前作为语音识别团队的声学模型负责人，负责声学模型相关的算法和系统设计与开发。 欢迎加入美团深度学习技术交流群，跟作者零距离交流。请加美美同学的微信（微信号：MTDPtech01），回复：深度学习，美美会自动拉你进群。 1024中奖名单公布 亲爱的读者朋友们，有没有被我们昨天的成长大礼包感动到，是不是一份很中肯的1024礼物。在昨天文章的最后，我们还特别赠送了一份额外大礼包，抽中的小伙伴不要被感动哭哦～ 抽奖结果已揭晓，名单如下： 中奖的读者朋友不要着急，奖品已经在路上，请注意查收，收到之后记得给好评哟！手动笔心～ ----------&nbsp; END&nbsp; ---------- 也许你还想看 基于TensorFlow Serving的深度学习在线预估 深度学习在美团点评推荐平台排序中的运用美团如何基于深度学习实现图像的智能审核？" />
<link rel="canonical" href="https://mlh.app/2019/04/29/729154.html" />
<meta property="og:url" content="https://mlh.app/2019/04/29/729154.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-29T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"总第293篇 2018年 第85篇 背景 深度学习作为AI时代的核心技术，已经被应用于众多场景。在系统设计层面，由于它具有计算密集的特性，所以与传统的机器学习算法在工程实践过程中存在诸多的不同。本文将介绍美团平台在应用深度学习技术的过程中，相关系统设计的一些经验。 本文将首先列举部分深度学习算法所需的计算量，然后再介绍为满足这些计算量，目前业界比较常见的一些解决方案。最后，我们将介绍美团平台在NLU和语音识别两个领域中，设计相关系统的经验。 深度学习的计算量 数据来源上表列举了，ImageNet图像识别中常见算法的模型大小以及单张图片一次训练（One Pass）所需要的计算量。 自2012年，Hinton的学生Alex Krizhevsky提出AlexNet，一举摘下ILSVRC 2012的桂冠后，ILSVRC比赛冠军的准确率越来越高。与此同时，其中使用到的深度学习算法也越来越复杂，所需要的计算量也越来越大。SENet与AlexNet相比，计算量多了近30倍。我们知道，ImageNet大概有120万张图片，以SENet为例，如果要完成100个epoch的完整训练，将需要2.52 * 10^18的计算量。如此庞大的计算量，已经远远超出传统的机器学习算法的范畴。更别说，Google在论文《Revisiting Unreasonable Effectiveness of Data in Deep Learning Era》中提及的、比ImageNet大300倍的数据集。 物理计算性能 面对如此庞大的计算量，那么，我们业界当前常用的计算单元的计算力是多少呢？ CPU 物理核：一般浮点运算能力在10^10 FLOPS量级。一台16 Cores的服务器，大致上有200 GFLOPS的运算能力。实际运行，CPU 大概能用到80%的性能，那就160 GFLOPS的运算能力。完成上述SENet运行，需要182天。 NVIDIA GPGPU： 目前的V100，单精度浮点运算的峰值大概为14 TFLOPS， 实际运行中，我们假设能用到50%的峰值性能，那就是7 TFLOPS，需要4天。 根据以上数据结果可以看出：在深度学习领域，GPU训练数据集所需要耗费的时间，远远少于CPU，这也是当前深度学习训练都是采用GPU的重要原因。 业界的解决方案 从前面的计算可知，即使使用GPU来计算，训练一次ImageNet 也需要4天的时间。但对于算法工程师做实验、调参而言，这种耗时数天的等待是难以忍受的。为此，目前业界针对深度学习训练的加速，提出了各种各样的解决方案。 异构计算的并行方案 数据并行（Data Parallelism） 数据并行，即每个计算单元都保留一份完整的模型拷贝，分别训练不同的数据，经过一个Iteration或若干个Iteration后，把各个计算单元的模型做一次同步。这是最常见的深度学习训练方式，好处在于逻辑简单、代码实现方便。 模型并行（Model Parallelism） 模型并行，即各个计算单元存储同一层模型数据的不同部分，训练相同的数据。相对于数据并行，因为各个运算单元每训练完一层神经网络，就必须要同步一次，频繁的同步通信导致系统不能充分地利用硬件的运算能力，所以更为少见。但是在一些业务场景下，Softmax层需要分类的类别可能会有很多，导致Softmax层太大，单个计算单元无法存储，这时需要把模型切割成若干部分，存储在不同的运算单元。模型并行常见于NLU、推荐、金融等领域。 流式并行（Stream Parallelism） 流式并行，即每个计算单元都存储不同层的模型数据，训练相同的数据。如上图所示，GPU1只负责第一层神经网络的计算，GPU2只负责2~5层神经网络的计算，GPU3只负责第6层的计算。流式并行的好处在于每个运算单元之间的通信和计算重叠（ overlap ），如果配置得当，可以非常充分地利用硬件资源。缺点在于，根据不同的模型，需要平衡好各个计算单元的计算量，如果配置不好，很容易形成“堰塞湖”。如上图所示，很有可能出现GPU1 负责的运算量太少，而GPU2 负责的运算量太多，导致GPU1 和GPU2 之间堵塞住大量的Mini-batch，更常见于线上环境。 混合并行（Hybrid Parallelism） 混合并行，即上面提到的并行方式的混合。如对于一些图像识别任务来说，可能前几层使用数据并行，最后的Softmax层，使用模型并行。 异构计算的硬件解决方案 单机单卡：一个主机内安装上一块GPU运算卡。常见于个人计算机。 单机多卡：一个主机内安装上多块GPU运算卡。常见的有：1机4卡，1机8卡，甚至有1机10卡。一般公司都采取这种硬件方案。 多机多卡：多台主机内安装多块GPU运算卡。常见于公司内部的计算集群，一般多机之间采取Infiniband 来实现网络的快速通信。 定制化：即类似于Google的TPU解决方案。常见于“巨无霸”公司内部。 异构计算的通信解决方案 根据上面的硬件解决方案，我们以ResNet为例：模型的大小为230M，单张图片运算量为11 GFLPOS，Mini-batch假设为128。可以计算出各个硬件模块在深度学习训练中的耗时比较： GPU：对于V100，假设有6 TFLOPS，一次Mini-batch 理论耗时：0.23s。 PCI-E：常见PCI-E 3.0 * 16，速度为10 GB/s，传输一个模型的理论耗时为：0.023s。 网络：假设为10 GB/s的高速网络，传输一个模型的理论耗时：0.023s。 Disk：普通的磁盘，我们假设200M/s的读取速度，读取一次Mini-batch所需要的图片耗时：0.094s。 根据上面的数据结果，我们似乎可以得出一个结论：PCI-E和网络的传输耗时，相对于GPU来说，整整少了一个数量级，所以网络通信同步的时间可以忽略不计。然而问题并没有那么简单，上面例子中的耗时只是单个模型的耗时，但是对于8卡的集群来说，如果使用数据并行，每次同步就需要传输8份模型，这就导致数据传输的时间和GPU的计算时间“旗鼓相当”。这样的话，GPU就得每训练完一个Mini-batch，都得等候很久的一段时间（采取同步更新），这会浪费很多计算资源。因此，网络通信也需要制定对应的解决方案。下面我们以Nvidia NCCL中单机多卡的通信解决方案为例介绍，而多机多卡的通信解决方案其实是类似的。 上图是单机4卡机器，在硬件上是两种不同的通信体系。左边为普通的PCI-E通信，即4个GPU之间组成一个环状。右边为NVLink通信，即两两之间相互连接。 常见的通信类型如下图所示： 对于深度学习训练而言，关键的两种通信类型为：Broadcast和Reduce。Broadcast用于Master分发最新的模型给各个GPU。Reduce 用于各个GPU计算完Mini-batch后，把模型更新值汇总到Master上。以Broadcast为例，最简单的通信方式是Master往各个GPU上发送数据，这样的耗时就是4次模型传输的时间，通信时间就会太长，一种简单的优化方法如下图所示： 即把所需要传输的数据分成若干块，然后通过接力的方式逐个传递，每个GPU都把自己最新的一块数据发送到下一个GPU卡上。这种传输方式能充分利用硬件层面的通信结构，使得需要的耗时大幅缩减。与此类似，Reduce的通信优化也可以采取相同的方式进行提速。 美团的定制化深度学习系统 尽管目前在业界已经推出了很多著名的深度学习训练平台，通用的训练平台如TensorFlow、MxNet等等，还有领域专用的训练平台，如语音识别中的Kaldi，但是我们经过调研后，决定内部自主开发一套深度学习系统，理由如下： 通用的训练平台，缺乏了领域特色的功能。如语音识别中的特征提取模块和算法。 通用的训练平台，通常是基于Data-flow Graph，来对计算图中的每个operator进行建模，所以颗粒度很小，需要调度的单元多，导任务调度复杂。 领域特色的训练平台，如Kaldi，在神经网络训练的时候，性能不足。 线上业务存在很多特殊性，如果使用TensorFlow之类作为训练平台，不太适合线上业务的情景。 NLU线上系统 线上系统的业务特点 我们在设计NLU线上系统时，考虑了NLU业务的一些特性。发现其具备如下的一些特点： 随着业务和技术的变化，算法流程也经常发生变化。 算法流程是多个算法串联组成的，不单纯的只有深度学习算法。如分词等算法就不是DL算法。 为了能够快速响应一些紧急问题，需要经常对模型进行热更新。 更重要的是，我们希望构建一个能以“数据驱动”的自动迭代闭环。 业务多变 NLU任务的算法流程是多层级的，并且业务经常发生变化。如下图所示： 即随着业务要求的变化，NLU系统一开始的算法流程，只需要把一个Query分为两个类，但是到后面，极有可能会变成需要分为三个类别。 热更新 根据业务需求，或者为了紧急处理一些特殊问题，NLU线上系统经常需要做出快速响应，热更新算法模型。如最近的热点词“skr”，几乎是一夜之间，突然火爆起来。如下图所示的微博，如果不能正确理解“skr”的正确语义，可能就不能准确理解这条微博想要表达的意思。 为了避免影响用户体验，我们可能会对NLU系统，马上进行热更新，把新模型紧急进行上线。 数据驱动的自动迭代闭环 对于线上系统而言，构建如上图所示的自动迭代闭环，能更好地利用业务数据来提升服务质量。 NLU线上系统的核心设计 算法流程的抽象 为了适应线上系统串联、多变的算法流程，我们把线上系统的算法进行抽象，如下图所示： 即每一个算法，都依赖于若干个槽位（ Slot ）和资源（ Resource ），一旦槽位和资源就位，就会触发对应的算法执行。算法的执行先通过算法适配器，来适配槽位和资源中的数据，转换成算子的输入格式。然后算子执行算法本身，执行完算子后，再经过算法解析器。算法解析器主要用于解析算法执行的结果，触发对应的槽位。如根据算法的结果，触发Top 3的结果。 多个算法串联起来，就构建成如下结果： 热更新流程的设计 如上图所示，我们把算法的热更新流程设计如上。初试状态为左上角，即多个Query使用同一份模型数据。当遇到模型更新的请求后，系统将会block住新的query（ 右上角状态 ）。然后更新模型完后，新的query使用新的模型，旧query依然使用旧模型（ 右下角状态 ）。最后，当使用旧模型的query结束后，把旧的模型从内存中删除（ 左下角 ），然后系统恢复到初始状态。 声学模型训练系统 因为TensorFlow等通用深度学习训练平台，缺乏了特征提取等业务相关的领域功能，而Kaldi的声学模型训练过程又太慢。所以美团开发了一个声学模型训练系统——Mimir，其具备如下特性： 使用比TensorFlow更粗颗粒度的建模单元，使得任务调度、优化更简单方便易行。 使用数据并行的并行方案，单机多卡可达到近线性加速。（采取同步更新策略下，4卡加速比达到3.8） 移植了Kaldi的一些特有的训练算法。 速度上为Kaldi的6~7倍。（800个小时的训练数据，单机单卡的条件下，Kaldi需要6~7天， Mimir只需20个小时） 业务上，移植了Kaldi的特征提取等领域的相关模块。 参考资料 NCCL: ACCELERATED MULTI-GPU COLLECTIVE COMMUNICATIONS 老师木讲架构：深度学习平台技术演进 作者简介 剑鹏，美团点评算法专家。2017年加入美团，目前作为语音识别团队的声学模型负责人，负责声学模型相关的算法和系统设计与开发。 欢迎加入美团深度学习技术交流群，跟作者零距离交流。请加美美同学的微信（微信号：MTDPtech01），回复：深度学习，美美会自动拉你进群。 1024中奖名单公布 亲爱的读者朋友们，有没有被我们昨天的成长大礼包感动到，是不是一份很中肯的1024礼物。在昨天文章的最后，我们还特别赠送了一份额外大礼包，抽中的小伙伴不要被感动哭哦～ 抽奖结果已揭晓，名单如下： 中奖的读者朋友不要着急，奖品已经在路上，请注意查收，收到之后记得给好评哟！手动笔心～ ----------&nbsp; END&nbsp; ---------- 也许你还想看 基于TensorFlow Serving的深度学习在线预估 深度学习在美团点评推荐平台排序中的运用美团如何基于深度学习实现图像的智能审核？","@type":"BlogPosting","url":"https://mlh.app/2019/04/29/729154.html","headline":"美团深度学习系统的工程实践","dateModified":"2019-04-29T00:00:00+08:00","datePublished":"2019-04-29T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/04/29/729154.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>美团深度学习系统的工程实践</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <section class="xmteditor" style="display:none;" data-tools="新媒体管家" data-label="powered by xmt.cn" data-mpa-powered-by="yiban.io"></section> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.10546875" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsV6LYkM3uK5TAnl8DxXwdR4zA3FUoOfW6b1icLsE77CELpkNLzriajHTdibqkqVFYoldIoffibgkOslZA/640?wx_fmt=png" data-type="png" data-w="1280" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsV6LYkM3uK5TAnl8DxXwdR4zA3FUoOfW6b1icLsE77CELpkNLzriajHTdibqkqVFYoldIoffibgkOslZA/640?wx_fmt=png"></p> 
<p style="white-space: normal;text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><strong><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 1px;">总第293篇</span></strong></p> 
<p style="white-space: normal;text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><strong><span style="color: rgb(136, 136, 136);font-size: 12px;letter-spacing: 1px;">2018年 第85篇</span></strong></p> 
<section class="output_wrapper"> 
 <p><span style="font-size: 15px;"><strong style="white-space: normal;color: rgb(51, 51, 51);font-size: 20px;"><span style="color: rgb(49, 188, 173);">背景</span></strong></span></p> 
 <p><span style="font-size: 15px;"><strong style="white-space: normal;color: rgb(51, 51, 51);font-size: 20px;"><span style="color: rgb(49, 188, 173);"><br></span></strong></span></p> 
 <p><span style="font-size: 15px;">深度学习作为AI时代的核心技术，已经被应用于众多场景。在系统设计层面，由于它具有计算密集的特性，所以与传统的机器学习算法在工程实践过程中存在诸多的不同。本文将介绍美团平台在应用深度学习技术的过程中，相关系统设计的一些经验。</span></p> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;">本文将首先列举部分深度学习算法所需的计算量，然后再介绍为满足这些计算量，目前业界比较常见的一些解决方案。最后，我们将介绍美团平台在NLU和语音识别两个领域中，设计相关系统的经验。</span></p> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;"><strong style="color: rgb(51, 51, 51);font-size: 20px;white-space: normal;"><span style="color: rgb(49, 188, 173);">深度学习的计算量</span></strong></span></p> 
</section> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.7747875354107648" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpwoeNUALqLWvjzfAwvicUTXdDryrtCV5a4IOkjvH9p3FXVCNfywclm3Q/640?wx_fmt=png" data-type="png" data-w="706" style="width: 324px;height: 251px;" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpwoeNUALqLWvjzfAwvicUTXdDryrtCV5a4IOkjvH9p3FXVCNfywclm3Q/640?wx_fmt=png"></p> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <blockquote style="line-height: inherit;padding: 15px 15px 15px 1rem;font-size: 0.9em;margin-top: 1em;margin-bottom: 1em;color: rgb(129, 145, 152);border-left-width: 6px;border-left-color: rgb(220, 230, 240);background: rgb(242, 247, 251);overflow: auto;overflow-wrap: normal;"> 
  <p style="font-size: inherit;color: inherit;line-height: inherit;"><a href="https://github.com/albanie/convnet-burden" style="line-height: inherit;color: rgb(30, 107, 184);font-size: 15px;text-decoration: underline;"><span style="font-size: 15px;">数据来源</span></a><br><span style="font-size: 15px;">上表列举了，ImageNet图像识别中常见算法的模型大小以及单张图片一次训练（One Pass）所需要的计算量。</span></p> 
 </blockquote> 
 <p><span style="font-size: 15px;">自2012年，Hinton的学生Alex Krizhevsky提出AlexNet，一举摘下ILSVRC 2012的桂冠后，ILSVRC比赛冠军的准确率越来越高。与此同时，其中使用到的深度学习算法也越来越复杂，所需要的计算量也越来越大。SENet与AlexNet相比，计算量多了近30倍。我们知道，ImageNet大概有120万张图片，以SENet为例，如果要完成100个epoch的完整训练，将需要2.52 * 10^18的计算量。如此庞大的计算量，已经远远超出传统的机器学习算法的范畴。更别说，Google在论文</span><a href="https://arxiv.org/abs/1707.02968" style="line-height: inherit;color: rgb(30, 107, 184);font-size: 15px;text-decoration: underline;"><span style="font-size: 15px;">《Revisiting Unreasonable Effectiveness of Data in Deep Learning Era》</span></a><span style="font-size: 15px;">中提及的、比ImageNet大300倍的数据集。</span></p> 
 <p><span style="font-size: 15px;"><br></span></p> 
 <h2><span style="font-size: 18px;"><strong>物理计算性能</strong></span></h2> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;">面对如此庞大的计算量，那么，我们业界当前常用的计算单元的计算力是多少呢？</span></p> 
 <ul style="" class=" list-paddingleft-2"> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">CPU 物理核：一般浮点运算能力在10^10 FLOPS量级。一台16 Cores的服务器，大致上有200 GFLOPS的运算能力。实际运行，CPU 大概能用到80%的性能，那就160 GFLOPS的运算能力。完成上述SENet运行，需要182天。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">NVIDIA GPGPU： 目前的V100，单精度浮点运算的峰值大概为14 TFLOPS， 实际运行中，我们假设能用到50%的峰值性能，那就是7 TFLOPS，需要4天。</span></p></li> 
 </ul> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;">根据以上数据结果可以看出：在深度学习领域，GPU训练数据集所需要耗费的时间，远远少于CPU，这也是当前深度学习训练都是采用GPU的重要原因。</span></p> 
 <h1><strong style="color: rgb(51, 51, 51);font-size: 20px;white-space: normal;"><span style="color: rgb(49, 188, 173);">业界的解决方案</span></strong></h1> 
 <p><span style="font-size: 15px;"><br></span></p> 
 <p><span style="font-size: 15px;">从前面的计算可知，即使使用GPU来计算，训练一次ImageNet 也需要4天的时间。但对于算法工程师做实验、调参而言，这种耗时数天的等待是难以忍受的。为此，目前业界针对深度学习训练的加速，提出了各种各样的解决方案。</span></p> 
 <h2><br></h2> 
 <h2><span style="font-size: 18px;"><strong>异构计算的并行方案</strong></span></h2> 
 <h3><strong><br></strong></h3> 
 <h3><strong>数据并行（</strong><span style="color: rgb(136, 136, 136);"><strong>Data Parallelism</strong></span><strong>）</strong></h3> 
 <br> 
 <span style="font-size: 15px;">数据并行，即每个计算单元都保留一份完整的模型拷贝，分别训练不同的数据，经过一个Iteration或若干个Iteration后，把各个计算单元的模型做一次同步。这是最常见的深度学习训练方式，好处在于逻辑简单、代码实现方便。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
 <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.39728453364817" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpkPyJYIypbVibR9DibkzicQibLW6lHUOGlfo4qiaKmeh6I7iaZb9dgbtyZ7lg/640?wx_fmt=png" data-type="png" data-w="1694" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpkPyJYIypbVibR9DibkzicQibLW6lHUOGlfo4qiaKmeh6I7iaZb9dgbtyZ7lg/640?wx_fmt=png"></p> 
 <p style="text-align: center;"><br></p> 
 <h3><strong>模型并行（</strong><span style="color: rgb(136, 136, 136);"><strong>Model Parallelism</strong></span><strong>）</strong></h3> 
 <p><strong><br></strong></p> 
 <figure style="font-size: inherit;color: inherit;line-height: inherit;"> 
  <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.4343090537780803" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpQBIPiaibBCdThToyAZjRWSb7r0dlbdsoRibLHO4icfibq7Rjz0icias0DeyNQ/640?wx_fmt=png" data-type="png" data-w="1469" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpQBIPiaibBCdThToyAZjRWSb7r0dlbdsoRibLHO4icfibq7Rjz0icias0DeyNQ/640?wx_fmt=png"></p> 
 </figure> 
 <br> 
 <span style="font-size: 15px;">模型并行，即各个计算单元存储同一层模型数据的不同部分，训练相同的数据。相对于数据并行，因为各个运算单元每训练完一层神经网络，就必须要同步一次，频繁的同步通信导致系统不能充分地利用硬件的运算能力，所以更为少见。但是在一些业务场景下，Softmax层需要分类的类别可能会有很多，导致Softmax层太大，单个计算单元无法存储，这时需要把模型切割成若干部分，存储在不同的运算单元。模型并行常见于NLU、推荐、金融等领域。</span> 
</section> 
<section class="output_wrapper"> 
 <span style="font-size: 15px;"><br></span> 
 <h3><strong>流式并行（</strong><span style="color: rgb(136, 136, 136);"><strong>Stream Parallelism</strong></span><strong>）</strong></h3> 
 <p><strong><br></strong></p> 
 <figure style="font-size: inherit;color: inherit;line-height: inherit;"> 
  <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5611257695690414" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpyXVtySyPLkIE5np1jW4eEfmcRmJ2hnYHDE5Pw8MCM8w3I5PFIRtYbQ/640?wx_fmt=png" data-type="png" data-w="1137" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpyXVtySyPLkIE5np1jW4eEfmcRmJ2hnYHDE5Pw8MCM8w3I5PFIRtYbQ/640?wx_fmt=png"></p> 
  <figcaption style="line-height: inherit;margin-top: 10px;text-align: center;color: rgb(153, 153, 153);font-size: 0.7em;"> 
   <br> 
  </figcaption> 
 </figure> 
 <span style="font-size: 15px;">流式并行，即每个计算单元都存储不同层的模型数据，训练相同的数据。如上图所示，GPU1只负责第一层神经网络的计算，GPU2只负责2~5层神经网络的计算，GPU3只负责第6层的计算。流式并行的好处在于每个运算单元之间的通信和计算重叠（</span> 
 <span style="font-size: 15px;color: rgb(136, 136, 136);">overlap</span> 
 <span style="font-size: 15px;">），如果配置得当，可以非常充分地利用硬件资源。缺点在于，根据不同的模型，需要平衡好各个计算单元的计算量，如果配置不好，很容易形成“堰塞湖”。如上图所示，很有可能出现GPU1 负责的运算量太少，而GPU2 负责的运算量太多，导致GPU1 和GPU2 之间堵塞住大量的Mini-batch，更常见于线上环境。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
 <h3><strong>混合并行（</strong><span style="color: rgb(136, 136, 136);"><strong>Hybrid Parallelism</strong></span><strong>）</strong></h3> 
 <figure> 
  <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.6152362584378014" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpFzWeylRqibIyRklCdJibPIevvxoD5YwVQLic0PKfCw2yxuG0qloEtWA5w/640?wx_fmt=png" data-type="png" data-w="1037" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpFzWeylRqibIyRklCdJibPIevvxoD5YwVQLic0PKfCw2yxuG0qloEtWA5w/640?wx_fmt=png"></p> 
 </figure> 
 <br> 
 <span style="font-size: 15px;">混合并行，即上面提到的并行方式的混合。如对于一些图像识别任务来说，可能前几层使用数据并行，最后的Softmax层，使用模型并行。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
 <h2><span style="font-size: 18px;"><strong>异构计算的硬件解决方案</strong></span></h2> 
 <p><span style="font-size: 18px;"><strong><br></strong></span></p> 
 <ul style="" class=" list-paddingleft-2"> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">单机单卡：一个主机内安装上一块GPU运算卡。常见于个人计算机。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">单机多卡：一个主机内安装上多块GPU运算卡。常见的有：1机4卡，1机8卡，甚至有1机10卡。一般公司都采取这种硬件方案。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">多机多卡：多台主机内安装多块GPU运算卡。常见于公司内部的计算集群，一般多机之间采取Infiniband 来实现网络的快速通信。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">定制化：即类似于Google的TPU解决方案。常见于“巨无霸”公司内部。</span></p></li> 
 </ul> 
 <h2><span style="font-size: 18px;"><strong><br></strong></span></h2> 
 <h2><span style="font-size: 18px;"><strong>异构计算的通信解决方案</strong></span></h2> 
 <p><span style="font-size: 15px;"><br></span></p> 
 <p><span style="font-size: 15px;">根据上面的硬件解决方案，我们以ResNet为例：模型的大小为230M，单张图片运算量为11 GFLPOS，Mini-batch假设为128。可以计算出各个硬件模块在深度学习训练中的耗时比较：</span></p> 
 <p><span style="font-size: 15px;"><br></span></p> 
 <ul style="" class=" list-paddingleft-2"> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">GPU：对于V100，假设有6 TFLOPS，一次Mini-batch 理论耗时：0.23s。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">PCI-E：常见PCI-E 3.0 * 16，速度为10 GB/s，传输一个模型的理论耗时为：0.023s。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">网络：假设为10 GB/s的高速网络，传输一个模型的理论耗时：0.023s。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">Disk：普通的磁盘，我们假设200M/s的读取速度，读取一次Mini-batch所需要的图片耗时：0.094s。</span></p></li> 
 </ul> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;">根据上面的数据结果，我们似乎可以得出一个结论：PCI-E和网络的传输耗时，相对于GPU来说，整整少了一个数量级，所以网络通信同步的时间可以忽略不计。然而问题并没有那么简单，上面例子中的耗时只是单个模型的耗时，但是对于8卡的集群来说，如果使用数据并行，每次同步就需要传输8份模型，这就导致数据传输的时间和GPU的计算时间“旗鼓相当”。这样的话，GPU就得每训练完一个Mini-batch，都得等候很久的一段时间（</span><span style="font-size: 15px;color: rgb(136, 136, 136);">采取同步更新</span><span style="font-size: 15px;">），这会浪费很多计算资源。因此，网络通信也需要制定对应的解决方案。下面我们以Nvidia NCCL中单机多卡的通信解决方案为例介绍，而多机多卡的通信解决方案其实是类似的。<br></span></p> 
 <figure style="font-size: inherit;color: inherit;line-height: inherit;"> 
  <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5153061224489796" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpCquMicxPyS9lt9PicWAmGv5m2CvpYkEWwEpv2weQC9IH85gyxpIPUOSA/640?wx_fmt=png" data-type="png" data-w="1176" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpCquMicxPyS9lt9PicWAmGv5m2CvpYkEWwEpv2weQC9IH85gyxpIPUOSA/640?wx_fmt=png"></p> 
 </figure> 
 <br> 
 <span style="font-size: 15px;">上图是单机4卡机器，在硬件上是两种不同的通信体系。左边为普通的PCI-E通信，即4个GPU之间组成一个环状。右边为NVLink通信，即两两之间相互连接。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br>常见的通信类型如下图所示：</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
 <figure style="font-size: inherit;color: inherit;line-height: inherit;"> 
  <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.36025732666190136" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficprAuvHOria3Sw1SGwDhfE4GQHqcic4jibkwcBeBFopiaX21qV9zTudWXzicg/640?wx_fmt=png" data-type="png" data-w="1399" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficprAuvHOria3Sw1SGwDhfE4GQHqcic4jibkwcBeBFopiaX21qV9zTudWXzicg/640?wx_fmt=png"></p> 
 </figure> 
 <br> 
 <span style="font-size: 15px;">对于深度学习训练而言，关键的两种通信类型为：Broadcast和Reduce。Broadcast用于Master分发最新的模型给各个GPU。Reduce 用于各个GPU计算完Mini-batch后，把模型更新值汇总到Master上。以Broadcast为例，最简单的通信方式是Master往各个GPU上发送数据，这样的耗时就是4次模型传输的时间，通信时间就会太长，一种简单的优化方法如下图所示：</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
</section> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.42908653846153844" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpSnMziaHVbvibjw5clW2OCH6G0qYsxbxIS9kuHE2z8HeSZJvlNce2Rwhw/640?wx_fmt=png" data-type="png" data-w="1664" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpSnMziaHVbvibjw5clW2OCH6G0qYsxbxIS9kuHE2z8HeSZJvlNce2Rwhw/640?wx_fmt=png"></p> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"></span> 
 <br> 
 <span style="font-size: 15px;">即把所需要传输的数据分成若干块，然后通过接力的方式逐个传递，每个GPU都把自己最新的一块数据发送到下一个GPU卡上。这种传输方式能充分利用硬件层面的通信结构，使得需要的耗时大幅缩减。与此类似，Reduce的通信优化也可以采取相同的方式进行提速。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
 <h1><strong style="color: rgb(51, 51, 51);font-size: 20px;white-space: normal;"><span style="color: rgb(49, 188, 173);">美团的定制化深度学习系统</span></strong></h1> 
 <p><br></p> 
 <p><span style="font-size: 15px;">尽管目前在业界已经推出了很多著名的深度学习训练平台，通用的训练平台如TensorFlow、MxNet等等，还有领域专用的训练平台，如语音识别中的Kaldi，但是我们经过调研后，决定内部自主开发一套深度学习系统，理由如下：</span></p> 
 <p><span style="font-size: 15px;"><br></span></p> 
 <ul style="" class=" list-paddingleft-2"> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">通用的训练平台，缺乏了领域特色的功能。如语音识别中的特征提取模块和算法。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">通用的训练平台，通常是基于Data-flow Graph，来对计算图中的每个operator进行建模，所以颗粒度很小，需要调度的单元多，导任务调度复杂。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">领域特色的训练平台，如Kaldi，在神经网络训练的时候，性能不足。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">线上业务存在很多特殊性，如果使用TensorFlow之类作为训练平台，不太适合线上业务的情景。</span></p></li> 
 </ul> 
 <h2><br></h2> 
 <h2><span style="font-size: 18px;"><strong>NLU线上系统</strong></span></h2> 
 <h3><strong><br></strong></h3> 
 <h3><strong>线上系统的业务特点</strong></h3> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;">我们在设计NLU线上系统时，考虑了NLU业务的一些特性。发现其具备如下的一些特点：</span></p> 
 <ul style="" class=" list-paddingleft-2"> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">随着业务和技术的变化，算法流程也经常发生变化。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">算法流程是多个算法串联组成的，不单纯的只有深度学习算法。如分词等算法就不是DL算法。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">为了能够快速响应一些紧急问题，需要经常对模型进行热更新。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">更重要的是，我们希望构建一个能以“数据驱动”的自动迭代闭环。</span></p></li> 
 </ul> 
 <h4 style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-weight: bold;font-size: 1.2em;"><span style="color: inherit;line-height: inherit;font-size: 15px;">业务多变</span></h4> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;">NLU任务的算法流程是多层级的，并且业务经常发生变化。如下图所示：<br></span></p> 
 <figure style="font-size: inherit;color: inherit;line-height: inherit;"> 
  <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.41013071895424835" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpvyWticqY42WcEAxbq88KHwiaBvl9yeUY93D0yvyjSmk5GnJIXec4aEdg/640?wx_fmt=png" data-type="png" data-w="1224" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpvyWticqY42WcEAxbq88KHwiaBvl9yeUY93D0yvyjSmk5GnJIXec4aEdg/640?wx_fmt=png"></p> 
 </figure> 
 <br> 
 <span style="font-size: 15px;">即随着业务要求的变化，NLU系统一开始的算法流程，只需要把一个Query分为两个类，但是到后面，极有可能会变成需要分为三个类别。</span> 
 <h4 style="color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;font-weight: bold;font-size: 1.2em;"><span style="color: inherit;line-height: inherit;font-size: 15px;">热更新</span></h4> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;">根据业务需求，或者为了紧急处理一些特殊问题，NLU线上系统经常需要做出快速响应，热更新算法模型。如最近的热点词“skr”，几乎是一夜之间，突然火爆起来。如下图所示的微博，如果不能正确理解“skr”的正确语义，可能就不能准确理解这条微博想要表达的意思。</span></p> 
 <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.2359375" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpuD3dr7iaHKXsq5DZZaY157YSKMBrWSJYkej05jukktxjw386GPDCOww/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpuD3dr7iaHKXsq5DZZaY157YSKMBrWSJYkej05jukktxjw386GPDCOww/640?wx_fmt=jpeg"></p> 
 <span style="font-size: 15px;"> 
  <section class="output_wrapper"> 
   <span style="font-size: 15px;"><br></span> 
  </section>为了避免影响用户体验，我们可能会对NLU系统，马上进行热更新，把新模型紧急进行上线。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
 <h4><span style="font-size: 15px;"><strong>数据驱动的自动迭代闭环</strong></span></h4> 
 <br> 
</section> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.5135135135135135" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpva16k7ykd7el1icP6L1V9BeicECmIVqjGoQsoXjJf5ZknD1VupmMOWww/640?wx_fmt=png" data-type="png" data-w="1369" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpva16k7ykd7el1icP6L1V9BeicECmIVqjGoQsoXjJf5ZknD1VupmMOWww/640?wx_fmt=png"></p> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"></span> 
 <br> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;">对于线上系统而言，构建如上图所示的自动迭代闭环，能更好地利用业务数据来提升服务质量。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
 <h3><strong>NLU线上系统的核心设计</strong></h3> 
 <h4><span style="color: inherit;line-height: inherit;font-size: 15px;"><br></span></h4> 
 <h4><strong><span style="color: inherit;line-height: inherit;font-size: 15px;">算法流程的抽象</span></strong></h4> 
 <p style="font-size: inherit;color: inherit;line-height: inherit;margin-top: 1.5em;margin-bottom: 1.5em;"><span style="font-size: 15px;">为了适应线上系统串联、多变的算法流程，我们把线上系统的算法进行抽象，如下图所示：<br></span></p> 
 <figure style="font-size: inherit;color: inherit;line-height: inherit;"> 
  <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.43661971830985913" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpKicr8TyQ3eTRtOUBnSW0h2zlia4WooCmG4KIjcE00J36nQL3qMTic4vAQ/640?wx_fmt=png" data-type="png" data-w="1349" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpKicr8TyQ3eTRtOUBnSW0h2zlia4WooCmG4KIjcE00J36nQL3qMTic4vAQ/640?wx_fmt=png"></p> 
 </figure> 
 <span style="font-size: 15px;">即每一个算法，<span style="">都依赖于若干个槽位</span>（</span> 
 <span style="font-size: 15px;color: rgb(136, 136, 136);">Slot</span> 
 <span style="font-size: 15px;">）和资源（</span> 
 <span style="font-size: 15px;color: rgb(136, 136, 136);">Resource</span> 
 <span style="font-size: 15px;">），一旦槽位和资源就位，就会触发对应的算法执行。算法的执行先通过算法适配器，来适配槽位和资源中的数据，转换成算子的输入格式。然后算子执行算法本身，执行完算子后，再经过算法解析器。算法解析器主要用于解析算法执行的结果，触发对应的槽位。如根据算法的结果，触发Top 3的结果。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br>多个算法串联起来，就构建成如下结果：</span> 
</section> 
<p style="text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.3974727168294084" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficp42dZweeNdunQo5xGonPOHEbrv8jV8fenjibkB25TwJXN4KmdesRYECQ/640?wx_fmt=png" data-type="png" data-w="1741" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficp42dZweeNdunQo5xGonPOHEbrv8jV8fenjibkB25TwJXN4KmdesRYECQ/640?wx_fmt=png"></p> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"></span> 
 <h4><span style="font-size: 15px;"><strong>热更新流程的设计</strong></span></h4> 
 <p><span style="font-size: 15px;"><strong><br></strong></span></p> 
 <p style="text-align: center;"><img class="" data-copyright="0" data-ratio="0.5954545454545455" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpN616lA7eiaYPBD1TTsMMxdvnibodKOzJhhmMv3UFUlurYNXX5NyHd2pg/640?wx_fmt=png" data-type="png" data-w="1100" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpN616lA7eiaYPBD1TTsMMxdvnibodKOzJhhmMv3UFUlurYNXX5NyHd2pg/640?wx_fmt=png"></p> 
 <br> 
 <span style="font-size: 15px;">如上图所示，我们把算法的热更新流程设计如上。初试状态为左上角，即多个Query使用同一份模型数据。当遇到模型更新的请求后，系统将会block住新的query（</span> 
 <span style="font-size: 15px;color: rgb(136, 136, 136);">右上角状态</span> 
 <span style="font-size: 15px;">）。然后更新模型完后，新的query使用新的模型，旧query依然使用旧模型（</span> 
 <span style="font-size: 15px;color: rgb(136, 136, 136);">右下角状态</span> 
 <span style="font-size: 15px;">）。最后，当使用旧模型的query结束后，把旧的模型从内存中删除（</span> 
 <span style="font-size: 15px;color: rgb(136, 136, 136);">左下角</span> 
 <span style="font-size: 15px;">），然后系统恢复到初始状态。</span> 
</section> 
<section class="output_wrapper" style="margin-left: 0.5em;margin-right: 0.5em;"> 
 <span style="font-size: 15px;"><br></span> 
 <h2><span style="font-size: 18px;"><strong>声学模型训练系统</strong></span></h2> 
 <p><strong><br></strong></p> 
 <p><span style="font-size: 15px;">因为TensorFlow等通用深度学习训练平台，缺乏了特征提取等业务相关的领域功能，而Kaldi的声学模型训练过程又太慢。所以美团开发了一个声学模型训练系统——Mimir，其具备如下特性：</span></p> 
 <p><span style="font-size: 15px;"><br></span></p> 
 <ul style="" class=" list-paddingleft-2"> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">使用比TensorFlow更粗颗粒度的建模单元，使得任务调度、优化更简单方便易行。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">使用数据并行的并行方案，单机多卡可达到近线性加速。（</span><span style="line-height: inherit;font-size: 15px;color: rgb(136, 136, 136);">采取同步更新策略下，4卡加速比达到3.8</span><span style="color: inherit;line-height: inherit;font-size: 15px;">）</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">移植了Kaldi的一些特有的训练算法。</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">速度上为Kaldi的6~7倍。（</span><span style="line-height: inherit;font-size: 15px;color: rgb(136, 136, 136);">800个小时的训练数据，单机单卡的条件下，Kaldi需要6~7天， Mimir只需20个小时</span><span style="color: inherit;line-height: inherit;font-size: 15px;">）</span></p></li> 
  <li><p><span style="color: inherit;line-height: inherit;font-size: 15px;">业务上，移植了Kaldi的特征提取等领域的相关模块。</span></p></li> 
 </ul> 
 <h1><br></h1> 
 <h1><strong style="color: rgb(51, 51, 51);font-size: 16px;white-space: normal;"><span style="color: rgb(49, 188, 173);">参考资料</span></strong></h1> 
 <p><strong style="color: rgb(51, 51, 51);font-size: 16px;white-space: normal;"><span style="color: rgb(49, 188, 173);"><br></span></strong></p> 
 <ul style="" class=" list-paddingleft-2"> 
  <li><p><a href="https://images.nvidia.com/events/sc15/pdfs/NCCL-Woolley.pdf" style="line-height: inherit;text-decoration: underline;font-size: 14px;color: rgb(136, 136, 136);"><span style="font-size: 14px;color: rgb(136, 136, 136);">NCCL: ACCELERATED MULTI-GPU COLLECTIVE COMMUNICATIONS</span></a></p></li> 
  <li><p><a href="https://blog.csdn.net/np4rHI455vg29y2/article/details/78958138" style="line-height: inherit;text-decoration: underline;font-size: 14px;color: rgb(136, 136, 136);"><span style="font-size: 14px;color: rgb(136, 136, 136);">老师木讲架构：深度学习平台技术演进</span></a></p></li> 
 </ul> 
 <h1><br></h1> 
 <h1><strong style="color: rgb(51, 51, 51);font-size: 16px;white-space: normal;"><span style="color: rgb(49, 188, 173);">作者简介</span></strong></h1> 
 <p><strong style="color: rgb(51, 51, 51);font-size: 16px;white-space: normal;"><span style="color: rgb(49, 188, 173);"><br></span></strong></p> 
 <p><span style="font-size: 15px;color: rgb(136, 136, 136);">剑鹏，美团点评算法专家。2017年加入美团，目前作为语音识别团队的声学模型负责人，负责声学模型相关的算法和系统设计与开发。</span></p> 
 <p><span style="font-size: 15px;color: rgb(136, 136, 136);"><br></span></p> 
 <p><span style="font-size: 15px;color: rgb(136, 136, 136);"><span style="font-size: 15px;color: rgb(136, 136, 136);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: justify;background-color: rgb(255, 255, 255);">欢迎加入</span><strong style="font-size: 15px;white-space: normal;color: rgb(51, 51, 51);"><span style="font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: justify;background-color: rgb(255, 255, 255);color: rgb(0, 0, 0);">美团深度学习技术交流群</span></strong><span style="font-size: 15px;color: rgb(136, 136, 136);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: justify;background-color: rgb(255, 255, 255);">，跟作者零距离交流。请加美美同学的微信（微信号：<strong>MTDPtech01</strong>），回复：</span><span style="font-size: 15px;font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: justify;background-color: rgb(255, 255, 255);color: rgb(62, 62, 62);"><strong>深度学习</strong></span><span style="font-size: 15px;color: rgb(136, 136, 136);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: justify;background-color: rgb(255, 255, 255);">，美美会自动拉你进群。</span></span></p> 
</section> 
<p style="white-space: normal;color: rgb(51, 51, 51);margin-left: 0.5em;margin-right: 0.5em;"><span style="color: rgb(0, 0, 0);font-size: 15px;"><br></span></p> 
<h1 style="white-space: normal;"><strong style="color: rgb(51, 51, 51);font-size: 20px;"><span style="color: rgb(49, 188, 173);">1024中奖名单公布</span></strong></h1> 
<p style="margin-right: 0.5em;margin-left: 0.5em;white-space: normal;"><br></p> 
<p style="margin-right: 0.5em;margin-left: 0.5em;white-space: normal;"><span style="font-size: 15px;">亲爱的读者朋友们，有没有被我们昨天的</span><a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651749105&amp;idx=1&amp;sn=78361c69df985b3ec247d699204f01ff&amp;chksm=bd12a3bc8a652aaa8fadf82cd04737489f1b4e3d405114697c95b2da831a023a5ca5da233a73&amp;scene=21#wechat_redirect" target="_blank" style="font-size: 15px;text-decoration: underline;"><span style="font-size: 15px;"><strong>成长大礼包</strong></span></a><span style="font-size: 15px;">感动到，是不是一份很中肯的1024礼物。在昨天文章的最后，我们还特别赠送了一份额外大礼包，抽中的小伙伴不要被感动哭哦～</span></p> 
<p style="margin-right: 0.5em;margin-left: 0.5em;white-space: normal;"><br></p> 
<p style="margin-right: 0.5em;margin-left: 0.5em;white-space: normal;"><span style="font-size: 15px;">抽奖结果已揭晓，名单如下：</span></p> 
<p style="text-align: center;"><img class="" data-copyright="0" data-ratio="1.28984375" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpjMDknAs1s53Oicfn9Ribhpcajcel03L90nKsOmxTUMTuMaZrAueHzW7w/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/hEx03cFgUsXFj8vy1UTFvicPG7piaUrficpjMDknAs1s53Oicfn9Ribhpcajcel03L90nKsOmxTUMTuMaZrAueHzW7w/640?wx_fmt=jpeg"></p> 
<p style="margin-right: 0.5em;margin-left: 0.5em;white-space: normal;"><span style="font-size: 15px;">中奖的读者朋友不要着急，奖品已经在路上，请注意查收，收到之后记得给好评哟！手动笔心～</span></p> 
<p style="white-space: normal;color: rgb(51, 51, 51);text-align: center;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 15px;color: rgb(136, 136, 136);">----------&nbsp; END&nbsp; ----------</span></p> 
<p data-source-line="194" style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><br></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 16px;"><strong><span style="color: rgb(49, 188, 173);">也许你还想看</span></strong></span></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style="font-size: 16px;"><strong><span style="color: rgb(49, 188, 173);"><br></span></strong></span></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><span style="color: rgb(49, 188, 173);font-size: 14px;text-decoration: underline;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651748960&amp;idx=2&amp;sn=4c637290b0bd35dc5b541d01d76ce574&amp;chksm=bd12a32d8a652a3b24e159f352c835fd7ff4eedead31dd5b0d0ae2c21da4a0fc587f69a99aef&amp;scene=21#wechat_redirect" target="_blank">基于TensorFlow Serving的深度学习在线预估</a><br></span></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651746611&amp;idx=1&amp;sn=c9bf49b74c52ba3a091051772828fb54&amp;chksm=bd12a87e8a6521689690ea992fe69ab4b37cbb3f77942e2900314033fdda361d9993af6698fa&amp;scene=21#wechat_redirect" target="_blank" style="font-size: 14px;text-decoration: underline;"><span style="font-size: 14px;">深度学习在美团点评推荐平台排序中的运用</span></a><br><a href="http://mp.weixin.qq.com/s?__biz=MjM5NjQ5MTI5OA==&amp;mid=2651748367&amp;idx=3&amp;sn=8b55db4ab7b5e39426103ff1decd37c9&amp;chksm=bd12a1428a652854805fe23766c5d4b19adb6a0691f2371b1d33f9b91b4be14ca03c585e36e7&amp;scene=21#wechat_redirect" target="_blank" style="font-size: 14px;text-decoration: underline;"><span style="font-size: 14px;">美团如何基于深度学习实现图像的智能审核？</span></a><br></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><br><span style="font-size: 15px;"></span></p> 
<p style="white-space: normal;margin-left: 0.5em;margin-right: 0.5em;"><img class="" data-copyright="0" data-ratio="0.44533333333333336" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsV6LYkM3uK5TAnl8DxXwdR4YOAKWmYSpAtzV3P359bDG3cn3Vr4T6HMkvDSI8icUYsejmDnfa5CdpQ/640?wx_fmt=png" data-type="png" data-w="1875" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/hEx03cFgUsV6LYkM3uK5TAnl8DxXwdR4YOAKWmYSpAtzV3P359bDG3cn3Vr4T6HMkvDSI8icUYsejmDnfa5CdpQ/640?wx_fmt=png"></p>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
