<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>hadoop单机安装，小白上手最详细教程-Ali0th | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="hadoop单机安装，小白上手最详细教程-Ali0th" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/u013661799/article/details/89061095 Author : Ali0th Date : 2019-4-6 前言 最近上手大数据，入门一下hadoop，单机部署撸了几天，终于部署起来了，遇到了不少坑。这篇文章把我整个过程码下来了，包括了各个步骤和报错处理。 文章目录 前言 环境 系统服务 hostname 配置 ssh 免密登录 java 安装 hadoop 下载与相关环境配置 hadoop 配置与启动 dfs 启动 全部启动 报错与解决 资料 环境 CentOS release 6.4 openjdk version &quot;1.8.0_201&quot; 系统服务 关闭 iptables # 关闭防火墙： service iptables stop # 从开机启动项中移除防火墙 chkconfig iptables off 关闭selinux服务(重启生效) vim /etc/selinux/config SELINUX=disabled hostname 配置 vim /etc/sysconfig/network 这里默认为 localhost.localdomain ssh 免密登录 ssh-keygen -t dsa -P &#39;&#39; -f ~/.ssh/id_dsa cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys chmod 0600 ~/.ssh/authorized_keys 测试是否成功，执行下面命令，若不用输入密码则成功。 ssh localhost java 安装 使用 yum 安装 # 查看yum包含的jdk版本 yum search java # 安装jdk yum install java-1.8.0-openjdk-devel.x86_64 : OpenJDK Development Environment 查看环境变量 export vi /etc/profile 查看 jvm 目录 ll /usr/lib/jvm/ 输出如下，其中java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 为JAVA_HOME目录。 [root@localhost java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64]# ll /usr/lib/jvm/ total 4 lrwxrwxrwx. 1 root root 26 Apr 3 15:47 java -&gt; /etc/alternatives/java_sdk lrwxrwxrwx. 1 root root 32 Apr 3 15:47 java-1.8.0 -&gt; /etc/alternatives/java_sdk_1.8.0 drwxr-xr-x. 7 root root 4096 Apr 3 15:47 java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 lrwxrwxrwx. 1 root root 48 Apr 3 15:47 java-1.8.0-openjdk.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 lrwxrwxrwx. 1 root root 34 Apr 3 15:47 java-openjdk -&gt; /etc/alternatives/java_sdk_openjdk lrwxrwxrwx. 1 root root 21 Apr 3 15:47 jre -&gt; /etc/alternatives/jre lrwxrwxrwx. 1 root root 27 Apr 3 15:47 jre-1.8.0 -&gt; /etc/alternatives/jre_1.8.0 lrwxrwxrwx. 1 root root 52 Apr 3 15:47 jre-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64/jre lrwxrwxrwx. 1 root root 52 Apr 3 15:47 jre-1.8.0-openjdk.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64/jre lrwxrwxrwx. 1 root root 29 Apr 3 15:47 jre-openjdk -&gt; /etc/alternatives/jre_openjdk 配置全局变量: vim /etc/profile 添加环境配置如下： export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 全局变量立即生效 source /etc/profile hadoop 下载与相关环境配置 创建账户 groupadd hadoop useradd hadoop -g hadoop ll -d /home/hadoop grep hadoop /etc/passwd /etc/shadow /etc/group passwd hadoop # hadoop123 以 root 執行 visudo, 將 hadoop 加入 sudoers，在 root ALL=(ALL) ALL 下加入。 hadoop ALL=(ALL) ALL 下载 hadoop 并解压。 wget http://apache.claz.org/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz tar -xzf hadoop-3.1.2.tar.gz sudo mv hadoop-3.1.2 /usr/local/hadoop 添加启动项。 vim /etc/profile export HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin source /etc/profile 创建数据存储目录： NameNode 数据存放目录： /usr/local/data/hadoop/name SecondaryNameNode 数据存放目录： /usr/local/data/hadoop/secondary DataNode 数据存放目录： /usr/local/data/hadoop/data 临时数据存放目录： /usr/local/data/hadoop/tmp mkdir -p /usr/local/data/hadoop/name mkdir -p /usr/local/data/hadoop/secondary mkdir -p /usr/local/data/hadoop/data mkdir -p /usr/local/data/hadoop/tmp hadoop 配置与启动 配置 hadoop-env.sh、hdfs-site.xml、core-site.xml、mappred-site.xml、yarn-site.xml 进入配置目录： cd /usr/local/hadoop/etc/hadoop/ hadoop-env.sh 添加JAVA_HOME export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 core-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost.localdomain:9000&lt;/value&gt; &lt;description&gt;hdfs内部通讯访问地址&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/data/&lt;/value&gt; &lt;description&gt;hadoop数据存放&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; hdfs-site.xml &lt;!-- # replication 副本数量 # 因为是伪分布式 设置为1 # 新版本的 hadoop 块默认大小为128mb --&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; mapred-site.xml # yran 集群 mv mapred-site.xml.template mapred-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; yarn-site.xml arn.resourcemanager.hostname yarn集群的老大 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;localhost.localdomain&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; dfs 启动 格式化hadoop文件系统 cd /usr/local/hadoop ./bin/hdfs namenode -format 启动 dfs ./sbin/start-dfs.sh 使用 jps 查看服务是否已经启动 [hadoop@localhost hadoop]$ jps 6466 NameNode 6932 Jps 6790 SecondaryNameNode 6584 DataNode 全部启动 ./sbin/start-all.sh 结果截图如下： 报错与解决 问题： localhost: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password). 解决： 如果无法使用ssh无密码连接其他节点的主机,那么在启动hadoop的时候会出现的输入其他主机的密码,即使正确输入也无法认证 问题: localhost: ERROR: Unable to write in /usr/local/hadoop/logs. Aborting. 解决： sudo chmod 777 -R /usr/local/hadoop/ 问题： localhost: /usr/local/hadoop/bin/…/libexec/hadoop-functions.sh: line 1842: /tmp/hadoop-hadoop-namenode.pid: Permission denied localhost: ERROR: Cannot write namenode pid /tmp/hadoop-hadoop-namenode.pid. 解决： 修改 hadoop-env.sh export HADOOP_PID_DIR=/usr/local/hadoop/tmp/pid 问题： [hadoop@localhost hadoop]$ ./sbin/start-dfs.sh Starting namenodes on [localhost] Starting datanodes Starting secondary namenodes [localhost] 2019-04-06 07:26:22,110 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 解决： 这个是 GLIBC 问题，是WARN类型信息，只是警告，可以不解决。 https://stackoverflow.com/questions/19943766/hadoop-unable-to-load-native-hadoop-library-for-your-platform-warning cd /usr/local/hadoop/lib ldd libhadoop.so.1.0.0 ./libhadoop.so.1.0.0: /lib64/libc.so.6: version `GLIBC_2.14&#39; not found (required by ./libhadoop.so.1.0.0) linux-vdso.so.1 =&gt; (0x00007fff901ff000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f8ceda5d000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f8ced83f000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f8ced4ac000) /lib64/ld-linux-x86-64.so.2 (0x00000031c1e00000) # download wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.bz2 wget http://ftp.gnu.org/gnu/glibc/glibc-linuxthreads-2.5.tar.bz2 # 解压 tar -xjvf glibc-2.14.tar.bz2 cd glibc-2.14 tar -xjvf ../glibc-linuxthreads-2.5.tar.bz2 # 加上优化开关，否则会出现错误&#39;#error &quot;glibc cannot be compiled without optimization&quot;&#39; cd ../ export CFLAGS=&quot;-g -O2&quot; glibc-2.14/configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin --disable-sanity-checks make sudo make install 问题: 2019-04-06 13:08:58,376 INFO util.ExitUtil: Exiting with status 1: java.io.IOException: Cannot remove current directory: /usr/local/data/hadoop/tmp/dfs/name/current 解决： 权限问题 sudo chown -R hadoop:hadoop /usr/local/data/hadoop/tmp sudo chmod -R a+w /usr/local/data/hadoop/tmp 资料 https://juejin.im/entry/5a0a898b5188253ee45af559 https://blog.51cto.com/xpleaf/2082861 Ubuntu下搭建hadoop出现Permission denied (publickey,password)的问题" />
<meta property="og:description" content="版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/u013661799/article/details/89061095 Author : Ali0th Date : 2019-4-6 前言 最近上手大数据，入门一下hadoop，单机部署撸了几天，终于部署起来了，遇到了不少坑。这篇文章把我整个过程码下来了，包括了各个步骤和报错处理。 文章目录 前言 环境 系统服务 hostname 配置 ssh 免密登录 java 安装 hadoop 下载与相关环境配置 hadoop 配置与启动 dfs 启动 全部启动 报错与解决 资料 环境 CentOS release 6.4 openjdk version &quot;1.8.0_201&quot; 系统服务 关闭 iptables # 关闭防火墙： service iptables stop # 从开机启动项中移除防火墙 chkconfig iptables off 关闭selinux服务(重启生效) vim /etc/selinux/config SELINUX=disabled hostname 配置 vim /etc/sysconfig/network 这里默认为 localhost.localdomain ssh 免密登录 ssh-keygen -t dsa -P &#39;&#39; -f ~/.ssh/id_dsa cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys chmod 0600 ~/.ssh/authorized_keys 测试是否成功，执行下面命令，若不用输入密码则成功。 ssh localhost java 安装 使用 yum 安装 # 查看yum包含的jdk版本 yum search java # 安装jdk yum install java-1.8.0-openjdk-devel.x86_64 : OpenJDK Development Environment 查看环境变量 export vi /etc/profile 查看 jvm 目录 ll /usr/lib/jvm/ 输出如下，其中java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 为JAVA_HOME目录。 [root@localhost java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64]# ll /usr/lib/jvm/ total 4 lrwxrwxrwx. 1 root root 26 Apr 3 15:47 java -&gt; /etc/alternatives/java_sdk lrwxrwxrwx. 1 root root 32 Apr 3 15:47 java-1.8.0 -&gt; /etc/alternatives/java_sdk_1.8.0 drwxr-xr-x. 7 root root 4096 Apr 3 15:47 java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 lrwxrwxrwx. 1 root root 48 Apr 3 15:47 java-1.8.0-openjdk.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 lrwxrwxrwx. 1 root root 34 Apr 3 15:47 java-openjdk -&gt; /etc/alternatives/java_sdk_openjdk lrwxrwxrwx. 1 root root 21 Apr 3 15:47 jre -&gt; /etc/alternatives/jre lrwxrwxrwx. 1 root root 27 Apr 3 15:47 jre-1.8.0 -&gt; /etc/alternatives/jre_1.8.0 lrwxrwxrwx. 1 root root 52 Apr 3 15:47 jre-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64/jre lrwxrwxrwx. 1 root root 52 Apr 3 15:47 jre-1.8.0-openjdk.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64/jre lrwxrwxrwx. 1 root root 29 Apr 3 15:47 jre-openjdk -&gt; /etc/alternatives/jre_openjdk 配置全局变量: vim /etc/profile 添加环境配置如下： export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 全局变量立即生效 source /etc/profile hadoop 下载与相关环境配置 创建账户 groupadd hadoop useradd hadoop -g hadoop ll -d /home/hadoop grep hadoop /etc/passwd /etc/shadow /etc/group passwd hadoop # hadoop123 以 root 執行 visudo, 將 hadoop 加入 sudoers，在 root ALL=(ALL) ALL 下加入。 hadoop ALL=(ALL) ALL 下载 hadoop 并解压。 wget http://apache.claz.org/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz tar -xzf hadoop-3.1.2.tar.gz sudo mv hadoop-3.1.2 /usr/local/hadoop 添加启动项。 vim /etc/profile export HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin source /etc/profile 创建数据存储目录： NameNode 数据存放目录： /usr/local/data/hadoop/name SecondaryNameNode 数据存放目录： /usr/local/data/hadoop/secondary DataNode 数据存放目录： /usr/local/data/hadoop/data 临时数据存放目录： /usr/local/data/hadoop/tmp mkdir -p /usr/local/data/hadoop/name mkdir -p /usr/local/data/hadoop/secondary mkdir -p /usr/local/data/hadoop/data mkdir -p /usr/local/data/hadoop/tmp hadoop 配置与启动 配置 hadoop-env.sh、hdfs-site.xml、core-site.xml、mappred-site.xml、yarn-site.xml 进入配置目录： cd /usr/local/hadoop/etc/hadoop/ hadoop-env.sh 添加JAVA_HOME export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 core-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost.localdomain:9000&lt;/value&gt; &lt;description&gt;hdfs内部通讯访问地址&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/data/&lt;/value&gt; &lt;description&gt;hadoop数据存放&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; hdfs-site.xml &lt;!-- # replication 副本数量 # 因为是伪分布式 设置为1 # 新版本的 hadoop 块默认大小为128mb --&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; mapred-site.xml # yran 集群 mv mapred-site.xml.template mapred-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; yarn-site.xml arn.resourcemanager.hostname yarn集群的老大 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;localhost.localdomain&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; dfs 启动 格式化hadoop文件系统 cd /usr/local/hadoop ./bin/hdfs namenode -format 启动 dfs ./sbin/start-dfs.sh 使用 jps 查看服务是否已经启动 [hadoop@localhost hadoop]$ jps 6466 NameNode 6932 Jps 6790 SecondaryNameNode 6584 DataNode 全部启动 ./sbin/start-all.sh 结果截图如下： 报错与解决 问题： localhost: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password). 解决： 如果无法使用ssh无密码连接其他节点的主机,那么在启动hadoop的时候会出现的输入其他主机的密码,即使正确输入也无法认证 问题: localhost: ERROR: Unable to write in /usr/local/hadoop/logs. Aborting. 解决： sudo chmod 777 -R /usr/local/hadoop/ 问题： localhost: /usr/local/hadoop/bin/…/libexec/hadoop-functions.sh: line 1842: /tmp/hadoop-hadoop-namenode.pid: Permission denied localhost: ERROR: Cannot write namenode pid /tmp/hadoop-hadoop-namenode.pid. 解决： 修改 hadoop-env.sh export HADOOP_PID_DIR=/usr/local/hadoop/tmp/pid 问题： [hadoop@localhost hadoop]$ ./sbin/start-dfs.sh Starting namenodes on [localhost] Starting datanodes Starting secondary namenodes [localhost] 2019-04-06 07:26:22,110 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 解决： 这个是 GLIBC 问题，是WARN类型信息，只是警告，可以不解决。 https://stackoverflow.com/questions/19943766/hadoop-unable-to-load-native-hadoop-library-for-your-platform-warning cd /usr/local/hadoop/lib ldd libhadoop.so.1.0.0 ./libhadoop.so.1.0.0: /lib64/libc.so.6: version `GLIBC_2.14&#39; not found (required by ./libhadoop.so.1.0.0) linux-vdso.so.1 =&gt; (0x00007fff901ff000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f8ceda5d000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f8ced83f000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f8ced4ac000) /lib64/ld-linux-x86-64.so.2 (0x00000031c1e00000) # download wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.bz2 wget http://ftp.gnu.org/gnu/glibc/glibc-linuxthreads-2.5.tar.bz2 # 解压 tar -xjvf glibc-2.14.tar.bz2 cd glibc-2.14 tar -xjvf ../glibc-linuxthreads-2.5.tar.bz2 # 加上优化开关，否则会出现错误&#39;#error &quot;glibc cannot be compiled without optimization&quot;&#39; cd ../ export CFLAGS=&quot;-g -O2&quot; glibc-2.14/configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin --disable-sanity-checks make sudo make install 问题: 2019-04-06 13:08:58,376 INFO util.ExitUtil: Exiting with status 1: java.io.IOException: Cannot remove current directory: /usr/local/data/hadoop/tmp/dfs/name/current 解决： 权限问题 sudo chown -R hadoop:hadoop /usr/local/data/hadoop/tmp sudo chmod -R a+w /usr/local/data/hadoop/tmp 资料 https://juejin.im/entry/5a0a898b5188253ee45af559 https://blog.51cto.com/xpleaf/2082861 Ubuntu下搭建hadoop出现Permission denied (publickey,password)的问题" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-06T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/u013661799/article/details/89061095 Author : Ali0th Date : 2019-4-6 前言 最近上手大数据，入门一下hadoop，单机部署撸了几天，终于部署起来了，遇到了不少坑。这篇文章把我整个过程码下来了，包括了各个步骤和报错处理。 文章目录 前言 环境 系统服务 hostname 配置 ssh 免密登录 java 安装 hadoop 下载与相关环境配置 hadoop 配置与启动 dfs 启动 全部启动 报错与解决 资料 环境 CentOS release 6.4 openjdk version &quot;1.8.0_201&quot; 系统服务 关闭 iptables # 关闭防火墙： service iptables stop # 从开机启动项中移除防火墙 chkconfig iptables off 关闭selinux服务(重启生效) vim /etc/selinux/config SELINUX=disabled hostname 配置 vim /etc/sysconfig/network 这里默认为 localhost.localdomain ssh 免密登录 ssh-keygen -t dsa -P &#39;&#39; -f ~/.ssh/id_dsa cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys chmod 0600 ~/.ssh/authorized_keys 测试是否成功，执行下面命令，若不用输入密码则成功。 ssh localhost java 安装 使用 yum 安装 # 查看yum包含的jdk版本 yum search java # 安装jdk yum install java-1.8.0-openjdk-devel.x86_64 : OpenJDK Development Environment 查看环境变量 export vi /etc/profile 查看 jvm 目录 ll /usr/lib/jvm/ 输出如下，其中java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 为JAVA_HOME目录。 [root@localhost java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64]# ll /usr/lib/jvm/ total 4 lrwxrwxrwx. 1 root root 26 Apr 3 15:47 java -&gt; /etc/alternatives/java_sdk lrwxrwxrwx. 1 root root 32 Apr 3 15:47 java-1.8.0 -&gt; /etc/alternatives/java_sdk_1.8.0 drwxr-xr-x. 7 root root 4096 Apr 3 15:47 java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 lrwxrwxrwx. 1 root root 48 Apr 3 15:47 java-1.8.0-openjdk.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 lrwxrwxrwx. 1 root root 34 Apr 3 15:47 java-openjdk -&gt; /etc/alternatives/java_sdk_openjdk lrwxrwxrwx. 1 root root 21 Apr 3 15:47 jre -&gt; /etc/alternatives/jre lrwxrwxrwx. 1 root root 27 Apr 3 15:47 jre-1.8.0 -&gt; /etc/alternatives/jre_1.8.0 lrwxrwxrwx. 1 root root 52 Apr 3 15:47 jre-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64/jre lrwxrwxrwx. 1 root root 52 Apr 3 15:47 jre-1.8.0-openjdk.x86_64 -&gt; java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64/jre lrwxrwxrwx. 1 root root 29 Apr 3 15:47 jre-openjdk -&gt; /etc/alternatives/jre_openjdk 配置全局变量: vim /etc/profile 添加环境配置如下： export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export PATH=$PATH:$JAVA_HOME/bin 全局变量立即生效 source /etc/profile hadoop 下载与相关环境配置 创建账户 groupadd hadoop useradd hadoop -g hadoop ll -d /home/hadoop grep hadoop /etc/passwd /etc/shadow /etc/group passwd hadoop # hadoop123 以 root 執行 visudo, 將 hadoop 加入 sudoers，在 root ALL=(ALL) ALL 下加入。 hadoop ALL=(ALL) ALL 下载 hadoop 并解压。 wget http://apache.claz.org/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz tar -xzf hadoop-3.1.2.tar.gz sudo mv hadoop-3.1.2 /usr/local/hadoop 添加启动项。 vim /etc/profile export HADOOP_HOME=/usr/local/hadoop export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin source /etc/profile 创建数据存储目录： NameNode 数据存放目录： /usr/local/data/hadoop/name SecondaryNameNode 数据存放目录： /usr/local/data/hadoop/secondary DataNode 数据存放目录： /usr/local/data/hadoop/data 临时数据存放目录： /usr/local/data/hadoop/tmp mkdir -p /usr/local/data/hadoop/name mkdir -p /usr/local/data/hadoop/secondary mkdir -p /usr/local/data/hadoop/data mkdir -p /usr/local/data/hadoop/tmp hadoop 配置与启动 配置 hadoop-env.sh、hdfs-site.xml、core-site.xml、mappred-site.xml、yarn-site.xml 进入配置目录： cd /usr/local/hadoop/etc/hadoop/ hadoop-env.sh 添加JAVA_HOME export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64 core-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://localhost.localdomain:9000&lt;/value&gt; &lt;description&gt;hdfs内部通讯访问地址&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/hadoop/data/&lt;/value&gt; &lt;description&gt;hadoop数据存放&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; hdfs-site.xml &lt;!-- # replication 副本数量 # 因为是伪分布式 设置为1 # 新版本的 hadoop 块默认大小为128mb --&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; mapred-site.xml # yran 集群 mv mapred-site.xml.template mapred-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; yarn-site.xml arn.resourcemanager.hostname yarn集群的老大 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;localhost.localdomain&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; dfs 启动 格式化hadoop文件系统 cd /usr/local/hadoop ./bin/hdfs namenode -format 启动 dfs ./sbin/start-dfs.sh 使用 jps 查看服务是否已经启动 [hadoop@localhost hadoop]$ jps 6466 NameNode 6932 Jps 6790 SecondaryNameNode 6584 DataNode 全部启动 ./sbin/start-all.sh 结果截图如下： 报错与解决 问题： localhost: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password). 解决： 如果无法使用ssh无密码连接其他节点的主机,那么在启动hadoop的时候会出现的输入其他主机的密码,即使正确输入也无法认证 问题: localhost: ERROR: Unable to write in /usr/local/hadoop/logs. Aborting. 解决： sudo chmod 777 -R /usr/local/hadoop/ 问题： localhost: /usr/local/hadoop/bin/…/libexec/hadoop-functions.sh: line 1842: /tmp/hadoop-hadoop-namenode.pid: Permission denied localhost: ERROR: Cannot write namenode pid /tmp/hadoop-hadoop-namenode.pid. 解决： 修改 hadoop-env.sh export HADOOP_PID_DIR=/usr/local/hadoop/tmp/pid 问题： [hadoop@localhost hadoop]$ ./sbin/start-dfs.sh Starting namenodes on [localhost] Starting datanodes Starting secondary namenodes [localhost] 2019-04-06 07:26:22,110 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 解决： 这个是 GLIBC 问题，是WARN类型信息，只是警告，可以不解决。 https://stackoverflow.com/questions/19943766/hadoop-unable-to-load-native-hadoop-library-for-your-platform-warning cd /usr/local/hadoop/lib ldd libhadoop.so.1.0.0 ./libhadoop.so.1.0.0: /lib64/libc.so.6: version `GLIBC_2.14&#39; not found (required by ./libhadoop.so.1.0.0) linux-vdso.so.1 =&gt; (0x00007fff901ff000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f8ceda5d000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f8ced83f000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f8ced4ac000) /lib64/ld-linux-x86-64.so.2 (0x00000031c1e00000) # download wget http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.bz2 wget http://ftp.gnu.org/gnu/glibc/glibc-linuxthreads-2.5.tar.bz2 # 解压 tar -xjvf glibc-2.14.tar.bz2 cd glibc-2.14 tar -xjvf ../glibc-linuxthreads-2.5.tar.bz2 # 加上优化开关，否则会出现错误&#39;#error &quot;glibc cannot be compiled without optimization&quot;&#39; cd ../ export CFLAGS=&quot;-g -O2&quot; glibc-2.14/configure --prefix=/usr --disable-profile --enable-add-ons --with-headers=/usr/include --with-binutils=/usr/bin --disable-sanity-checks make sudo make install 问题: 2019-04-06 13:08:58,376 INFO util.ExitUtil: Exiting with status 1: java.io.IOException: Cannot remove current directory: /usr/local/data/hadoop/tmp/dfs/name/current 解决： 权限问题 sudo chown -R hadoop:hadoop /usr/local/data/hadoop/tmp sudo chmod -R a+w /usr/local/data/hadoop/tmp 资料 https://juejin.im/entry/5a0a898b5188253ee45af559 https://blog.51cto.com/xpleaf/2082861 Ubuntu下搭建hadoop出现Permission denied (publickey,password)的问题","@type":"BlogPosting","url":"/2019/04/06/728276.html","headline":"hadoop单机安装，小白上手最详细教程-Ali0th","dateModified":"2019-04-06T00:00:00+08:00","datePublished":"2019-04-06T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2019/04/06/728276.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-1');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>hadoop单机安装，小白上手最详细教程-Ali0th</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：本文为博主原创文章，未经博主允许不得转载。 https://blog.csdn.net/u013661799/article/details/89061095 
 </div> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p>Author : Ali0th</p> 
  <p>Date : 2019-4-6</p> 
  <h2><a id="_5"></a>前言</h2> 
  <p>最近上手大数据，入门一下hadoop，单机部署撸了几天，终于部署起来了，遇到了不少坑。这篇文章把我整个过程码下来了，包括了各个步骤和报错处理。</p> 
  <p></p>
  <div class="toc">
   <h3>文章目录</h3>
   <ul>
    <ul>
     <li><a href="#_5" rel="nofollow">前言</a></li>
     <li><a href="#_11" rel="nofollow">环境</a></li>
     <li><a href="#_18" rel="nofollow">系统服务</a></li>
     <li><a href="#hostname__36" rel="nofollow">hostname 配置</a></li>
     <li><a href="#ssh__44" rel="nofollow">ssh 免密登录</a></li>
     <li><a href="#java__58" rel="nofollow">java 安装</a></li>
     <li><a href="#hadoop__122" rel="nofollow">hadoop 下载与相关环境配置</a></li>
     <li><a href="#hadoop__175" rel="nofollow">hadoop 配置与启动</a></li>
     <li><a href="#dfs__269" rel="nofollow">dfs 启动</a></li>
     <li><a href="#_294" rel="nofollow">全部启动</a></li>
     <li><a href="#_305" rel="nofollow">报错与解决</a></li>
     <li><a href="#_397" rel="nofollow">资料</a></li>
    </ul>
   </ul>
  </div>
  <p></p> 
  <h2><a id="_11"></a>环境</h2> 
  <pre><code class="prism language-bash">CentOS release 6.4
openjdk version <span class="token string">"1.8.0_201"</span>
</code></pre> 
  <h2><a id="_18"></a>系统服务</h2> 
  <p>关闭 iptables</p> 
  <pre><code class="prism language-bash"><span class="token comment"># 关闭防火墙：</span>
<span class="token function">service</span> iptables stop
<span class="token comment"># 从开机启动项中移除防火墙</span>
<span class="token function">chkconfig</span> iptables off
</code></pre> 
  <p>关闭selinux服务(重启生效)</p> 
  <pre><code class="prism language-bash">vim /etc/selinux/config
SELINUX<span class="token operator">=</span>disabled
</code></pre> 
  <h2><a id="hostname__36"></a>hostname 配置</h2> 
  <pre><code>vim /etc/sysconfig/network
</code></pre> 
  <p>这里默认为 localhost.localdomain</p> 
  <h2><a id="ssh__44"></a>ssh 免密登录</h2> 
  <pre><code class="prism language-bash">ssh-keygen -t dsa -P <span class="token string">''</span> -f ~/.ssh/id_dsa
<span class="token function">cat</span> ~/.ssh/id_dsa.pub <span class="token operator">&gt;&gt;</span> ~/.ssh/authorized_keys
<span class="token function">chmod</span> 0600 ~/.ssh/authorized_keys
</code></pre> 
  <p>测试是否成功，执行下面命令，若不用输入密码则成功。</p> 
  <pre><code class="prism language-bash"><span class="token function">ssh</span> localhost
</code></pre> 
  <h2><a id="java__58"></a>java 安装</h2> 
  <p>使用 yum 安装</p> 
  <pre><code class="prism language-bash"><span class="token comment"># 查看yum包含的jdk版本</span>
yum search java
<span class="token comment"># 安装jdk</span>
yum <span class="token function">install</span> java-1.8.0-openjdk-devel.x86_64 <span class="token keyword">:</span> OpenJDK Development Environment
</code></pre> 
  <p>查看环境变量</p> 
  <pre><code class="prism language-bash"><span class="token function">export</span>
</code></pre> 
  <pre><code class="prism language-bash"><span class="token function">vi</span> /etc/profile
</code></pre> 
  <p>查看 jvm 目录</p> 
  <pre><code class="prism language-bash">ll /usr/lib/jvm/
</code></pre> 
  <p>输出如下，其中<code>java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64</code> 为<code>JAVA_HOME</code>目录。</p> 
  <pre><code class="prism language-ruby"><span class="token punctuation">[</span>root<span class="token variable">@localhost</span> java<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">-</span>openjdk<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token number">.201</span><span class="token punctuation">.</span>b09<span class="token operator">-</span><span class="token number">2.</span>el6_10<span class="token punctuation">.</span>x86_64<span class="token punctuation">]</span><span class="token comment"># ll /usr/lib/jvm/</span>
total <span class="token number">4</span>
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">26</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> java <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token operator">/</span>etc<span class="token operator">/</span>alternatives<span class="token operator">/</span>java_sdk
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">32</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> java<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token operator">/</span>etc<span class="token operator">/</span>alternatives<span class="token operator">/</span>java_sdk_1<span class="token punctuation">.</span><span class="token number">8.0</span>
drwxr<span class="token operator">-</span>xr<span class="token operator">-</span>x<span class="token punctuation">.</span> <span class="token number">7</span> root root <span class="token number">4096</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> java<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">-</span>openjdk<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token number">.201</span><span class="token punctuation">.</span>b09<span class="token operator">-</span><span class="token number">2.</span>el6_10<span class="token punctuation">.</span>x86_64
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">48</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> java<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">-</span>openjdk<span class="token punctuation">.</span>x86_64 <span class="token operator">-</span><span class="token operator">&gt;</span> java<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">-</span>openjdk<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token number">.201</span><span class="token punctuation">.</span>b09<span class="token operator">-</span><span class="token number">2.</span>el6_10<span class="token punctuation">.</span>x86_64
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">34</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> java<span class="token operator">-</span>openjdk <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token operator">/</span>etc<span class="token operator">/</span>alternatives<span class="token operator">/</span>java_sdk_openjdk
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">21</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> jre <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token operator">/</span>etc<span class="token operator">/</span>alternatives<span class="token operator">/</span>jre
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">27</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> jre<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span> <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token operator">/</span>etc<span class="token operator">/</span>alternatives<span class="token operator">/</span>jre_1<span class="token punctuation">.</span><span class="token number">8.0</span>
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">52</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> jre<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">-</span>openjdk<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token number">.201</span><span class="token punctuation">.</span>b09<span class="token operator">-</span><span class="token number">2.</span>el6_10<span class="token punctuation">.</span>x86_64 <span class="token operator">-</span><span class="token operator">&gt;</span> java<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">-</span>openjdk<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token number">.201</span><span class="token punctuation">.</span>b09<span class="token operator">-</span><span class="token number">2.</span>el6_10<span class="token punctuation">.</span>x86_64<span class="token operator">/</span>jre
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">52</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> jre<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">-</span>openjdk<span class="token punctuation">.</span>x86_64 <span class="token operator">-</span><span class="token operator">&gt;</span> java<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token operator">-</span>openjdk<span class="token operator">-</span><span class="token number">1.8</span><span class="token number">.0</span><span class="token number">.201</span><span class="token punctuation">.</span>b09<span class="token operator">-</span><span class="token number">2.</span>el6_10<span class="token punctuation">.</span>x86_64<span class="token operator">/</span>jre
lrwxrwxrwx<span class="token punctuation">.</span> <span class="token number">1</span> root root   <span class="token number">29</span> <span class="token constant">Apr</span>  <span class="token number">3</span> <span class="token number">15</span><span class="token punctuation">:</span><span class="token number">47</span> jre<span class="token operator">-</span>openjdk <span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token operator">/</span>etc<span class="token operator">/</span>alternatives<span class="token operator">/</span>jre_openjdk
</code></pre> 
  <p>配置全局变量:</p> 
  <pre><code class="prism language-bash">vim /etc/profile
</code></pre> 
  <p>添加环境配置如下：</p> 
  <pre><code class="prism language-bash"><span class="token function">export</span> JAVA_HOME<span class="token operator">=</span>/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64
<span class="token function">export</span> CLASSPATH<span class="token operator">=</span>.:<span class="token variable">$JAVA_HOME</span>/jre/lib/rt.jar:<span class="token variable">$JAVA_HOME</span>/lib/dt.jar:<span class="token variable">$JAVA_HOME</span>/lib/tools.jar
<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$JAVA_HOME</span>/bin
</code></pre> 
  <p>全局变量立即生效</p> 
  <pre><code class="prism language-bash"><span class="token function">source</span> /etc/profile
</code></pre> 
  <h2><a id="hadoop__122"></a>hadoop 下载与相关环境配置</h2> 
  <p>创建账户</p> 
  <pre><code class="prism language-bash"><span class="token function">groupadd</span> hadoop
<span class="token function">useradd</span> hadoop -g hadoop 
ll -d /home/hadoop
<span class="token function">grep</span> hadoop /etc/passwd /etc/shadow /etc/group
<span class="token function">passwd</span> hadoop <span class="token comment"># hadoop123</span>
</code></pre> 
  <p>以 root 執行 visudo, 將 hadoop 加入 sudoers，在 <code>root ALL=(ALL) ALL</code> 下加入。</p> 
  <pre><code class="prism language-bash">hadoop  ALL<span class="token operator">=</span><span class="token punctuation">(</span>ALL<span class="token punctuation">)</span>       ALL
</code></pre> 
  <p>下载 <code>hadoop</code> 并解压。</p> 
  <pre><code class="prism language-bash"><span class="token function">wget</span> http://apache.claz.org/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz
<span class="token function">tar</span> -xzf hadoop-3.1.2.tar.gz
<span class="token function">sudo</span> <span class="token function">mv</span> hadoop-3.1.2 /usr/local/hadoop
</code></pre> 
  <p>添加启动项。</p> 
  <pre><code class="prism language-bash">vim /etc/profile

<span class="token function">export</span> HADOOP_HOME<span class="token operator">=</span>/usr/local/hadoop
<span class="token function">export</span> PATH<span class="token operator">=</span><span class="token variable">$PATH</span><span class="token keyword">:</span><span class="token variable">$HADOOP_HOME</span>/bin:<span class="token variable">$HADOOP_HOME</span>/sbin

<span class="token function">source</span> /etc/profile
</code></pre> 
  <p>创建数据存储目录：</p> 
  <ol> 
   <li>NameNode 数据存放目录： /usr/local/data/hadoop/name</li> 
   <li>SecondaryNameNode 数据存放目录： /usr/local/data/hadoop/secondary</li> 
   <li>DataNode 数据存放目录： /usr/local/data/hadoop/data</li> 
   <li>临时数据存放目录： /usr/local/data/hadoop/tmp</li> 
  </ol> 
  <pre><code class="prism language-bash"><span class="token function">mkdir</span> -p /usr/local/data/hadoop/name
<span class="token function">mkdir</span> -p /usr/local/data/hadoop/secondary
<span class="token function">mkdir</span> -p /usr/local/data/hadoop/data
<span class="token function">mkdir</span> -p /usr/local/data/hadoop/tmp
</code></pre> 
  <h2><a id="hadoop__175"></a>hadoop 配置与启动</h2> 
  <p>配置 <a href="http://hadoop-env.sh" rel="nofollow">hadoop-env.sh</a>、hdfs-site.xml、core-site.xml、mappred-site.xml、yarn-site.xml</p> 
  <p>进入配置目录：</p> 
  <pre><code class="prism language-bash"><span class="token function">cd</span> /usr/local/hadoop/etc/hadoop/
</code></pre> 
  <p><a href="http://hadoop-env.sh" rel="nofollow">hadoop-env.sh</a></p> 
  <p>添加<code>JAVA_HOME</code></p> 
  <pre><code class="prism language-xml">export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.201.b09-2.el6_10.x86_64
</code></pre> 
  <p>core-site.xml</p> 
  <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>fs.defaultFS<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>hdfs://localhost.localdomain:9000<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">&gt;</span></span>hdfs内部通讯访问地址<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>hadoop.tmp.dir<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>/usr/local/hadoop/data/<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">&gt;</span></span>hadoop数据存放<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
  <p>hdfs-site.xml</p> 
  <pre><code class="prism language-xml"><span class="token comment">&lt;!-- # replication 副本数量 # 因为是伪分布式 设置为1 # 新版本的 hadoop 块默认大小为128mb --&gt;</span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>dfs.replication<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>1<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
  <p>mapred-site.xml</p> 
  <pre><code class="prism language-bash"><span class="token comment"># yran 集群</span>
<span class="token function">mv</span> mapred-site.xml.template mapred-site.xml
</code></pre> 
  <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>mapreduce.framework.name<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>yarn<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
  <p>yarn-site.xml</p> 
  <p>arn.resourcemanager.hostname yarn集群的老大</p> 
  <pre><code class="prism language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>configuration</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span>

    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.resourcemanager.hostname<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span>
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>localhost.localdomain<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span>

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">&gt;</span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">&gt;</span></span>yarn.nodemanager.aux-services<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">&gt;</span></span> 
    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">&gt;</span></span>mapreduce_shuffle<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">&gt;</span></span> 
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">&gt;</span></span> 

<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>configuration</span><span class="token punctuation">&gt;</span></span>
</code></pre> 
  <h2><a id="dfs__269"></a>dfs 启动</h2> 
  <p>格式化hadoop文件系统</p> 
  <pre><code class="prism language-bash"><span class="token function">cd</span> /usr/local/hadoop
./bin/hdfs namenode -format
</code></pre> 
  <p>启动 dfs</p> 
  <pre><code class="prism language-bash">./sbin/start-dfs.sh
</code></pre> 
  <p>使用 jps 查看服务是否已经启动</p> 
  <pre><code class="prism language-bash"><span class="token punctuation">[</span>hadoop@localhost hadoop<span class="token punctuation">]</span>$ jps
6466 NameNode
6932 Jps
6790 SecondaryNameNode
6584 DataNode
</code></pre> 
  <h2><a id="_294"></a>全部启动</h2> 
  <pre><code class="prism language-bash">./sbin/start-all.sh
</code></pre> 
  <p>结果截图如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406215311739.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM2NjE3OTk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406215324942.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM2NjE3OTk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406215329140.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTM2NjE3OTk=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <h2><a id="_305"></a>报错与解决</h2> 
  <p>问题：</p> 
  <p>localhost: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).</p> 
  <p>解决：</p> 
  <p>如果无法使用ssh无密码连接其他节点的主机,那么在启动hadoop的时候会出现的输入其他主机的密码,即使正确输入也无法认证</p> 
  <p>问题:</p> 
  <p>localhost: ERROR: Unable to write in /usr/local/hadoop/logs. Aborting.</p> 
  <p>解决：</p> 
  <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">chmod</span> 777 -R /usr/local/hadoop/
</code></pre> 
  <p>问题：</p> 
  <p>localhost: /usr/local/hadoop/bin/…/libexec/hadoop-functions.sh: line 1842: /tmp/hadoop-hadoop-namenode.pid: Permission denied<br> localhost: ERROR: Cannot write namenode pid /tmp/hadoop-hadoop-namenode.pid.</p> 
  <p>解决：</p> 
  <p>修改 <code>hadoop-env.sh</code></p> 
  <pre><code class="prism language-bash"><span class="token function">export</span> HADOOP_PID_DIR<span class="token operator">=</span>/usr/local/hadoop/tmp/pid 
</code></pre> 
  <p>问题：</p> 
  <p>[hadoop@localhost hadoop]$ ./sbin/start-dfs.sh<br> Starting namenodes on [localhost]<br> Starting datanodes<br> Starting secondary namenodes [localhost]<br> 2019-04-06 07:26:22,110 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable</p> 
  <p>解决：</p> 
  <p>这个是 GLIBC 问题，是WARN类型信息，只是警告，可以不解决。</p> 
  <p><a href="https://stackoverflow.com/questions/19943766/hadoop-unable-to-load-native-hadoop-library-for-your-platform-warning" rel="nofollow">https://stackoverflow.com/questions/19943766/hadoop-unable-to-load-native-hadoop-library-for-your-platform-warning</a></p> 
  <pre><code class="prism language-bash"><span class="token function">cd</span> /usr/local/hadoop/lib
ldd libhadoop.so.1.0.0

./libhadoop.so.1.0.0: /lib64/libc.so.6: version `GLIBC_2.14' not found <span class="token punctuation">(</span>required by ./libhadoop.so.1.0.0<span class="token punctuation">)</span>
	linux-vdso.so.1 <span class="token operator">=</span><span class="token operator">&gt;</span>  <span class="token punctuation">(</span>0x00007fff901ff000<span class="token punctuation">)</span>
	libdl.so.2 <span class="token operator">=</span><span class="token operator">&gt;</span> /lib64/libdl.so.2 <span class="token punctuation">(</span>0x00007f8ceda5d000<span class="token punctuation">)</span>
	libpthread.so.0 <span class="token operator">=</span><span class="token operator">&gt;</span> /lib64/libpthread.so.0 <span class="token punctuation">(</span>0x00007f8ced83f000<span class="token punctuation">)</span>
	libc.so.6 <span class="token operator">=</span><span class="token operator">&gt;</span> /lib64/libc.so.6 <span class="token punctuation">(</span>0x00007f8ced4ac000<span class="token punctuation">)</span>
	/lib64/ld-linux-x86-64.so.2 <span class="token punctuation">(</span>0x00000031c1e00000<span class="token punctuation">)</span>
</code></pre> 
  <pre><code class="prism language-bash"><span class="token comment"># download</span>
<span class="token function">wget</span> http://ftp.gnu.org/gnu/glibc/glibc-2.14.tar.bz2
<span class="token function">wget</span> http://ftp.gnu.org/gnu/glibc/glibc-linuxthreads-2.5.tar.bz2

<span class="token comment"># 解压</span>
<span class="token function">tar</span> -xjvf glibc-2.14.tar.bz2
<span class="token function">cd</span> glibc-2.14
<span class="token function">tar</span> -xjvf <span class="token punctuation">..</span>/glibc-linuxthreads-2.5.tar.bz2
<span class="token comment"># 加上优化开关，否则会出现错误'#error "glibc cannot be compiled without optimization"'</span>
<span class="token function">cd</span> <span class="token punctuation">..</span>/
<span class="token function">export</span> CFLAGS<span class="token operator">=</span><span class="token string">"-g -O2"</span>

glibc-2.14/configure --prefix<span class="token operator">=</span>/usr --disable-profile --enable-add-ons --with-headers<span class="token operator">=</span>/usr/include --with-binutils<span class="token operator">=</span>/usr/bin --disable-sanity-checks

<span class="token function">make</span>
<span class="token function">sudo</span> <span class="token function">make</span> <span class="token function">install</span>
</code></pre> 
  <p>问题:</p> 
  <p>2019-04-06 13:08:58,376 INFO util.ExitUtil: Exiting with status 1: java.io.IOException: Cannot remove current directory: /usr/local/data/hadoop/tmp/dfs/name/current</p> 
  <p>解决：</p> 
  <p>权限问题</p> 
  <pre><code class="prism language-bash"><span class="token function">sudo</span> <span class="token function">chown</span> -R hadoop:hadoop /usr/local/data/hadoop/tmp
<span class="token function">sudo</span> <span class="token function">chmod</span> -R a+w /usr/local/data/hadoop/tmp
</code></pre> 
  <h2><a id="_397"></a>资料</h2> 
  <p><a href="https://juejin.im/entry/5a0a898b5188253ee45af559" rel="nofollow">https://juejin.im/entry/5a0a898b5188253ee45af559</a></p> 
  <p><a href="https://blog.51cto.com/xpleaf/2082861" rel="nofollow">https://blog.51cto.com/xpleaf/2082861</a></p> 
  <p><a href="https://blog.csdn.net/situliang/article/details/72904449" rel="nofollow">Ubuntu下搭建hadoop出现Permission denied (publickey,password)的问题</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?ee64533f3c6a7a284cd39a37ee732c8b";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
