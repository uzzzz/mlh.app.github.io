<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>linux环境下kafka安装步骤 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="linux环境下kafka安装步骤" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="版权声明：本文为博主原创文章，未经博主允许请随便转载 https://blog.csdn.net/CSDN_Terence/article/details/89061258 1 安装条件 &nbsp; &nbsp;1.Kafka依赖于zookeeper存活，所以要确保zk已经安装成功，可以正常启动，参考：linux环境下zookeeper安装步骤。 &nbsp; &nbsp;2.kafka安装包下载：Apache官网&nbsp;http://kafka.apache.org/downloads.html ，选择Binary downloads，选择版本进行下载。也可以直接用以下命令下载： wget http://apache.01link.hk/kafka/2.0.0/kafka_2.11-2.0.0.tgz 2 安装kafka 1.&nbsp; &nbsp;进入指定安装目录：cd&nbsp; /usr/local &nbsp; &nbsp; &nbsp;&nbsp;解压安装包：tar -xzf kafka_2.11-2.0.0.tgz &nbsp; &nbsp;&nbsp; &nbsp;进入解压后的目录：cd kafka_2.11-2.0.0 2. 启动kafka，&nbsp;启动kafka首先要启动zk,启动zk有两种方式: &nbsp; &nbsp;第一种使用kafka带的zk:&nbsp; bin/zookeeper-server-start.sh&nbsp; config/zookeeper.properties（不推荐） &nbsp; &nbsp;第二种使用其他zookeeper（可以是本机zk，也可以位于其它地址的zk）,这种情况需要修改/config/sercer.properties里面的zookeeper地址。&nbsp; #########################参数解释############################## broker.id=0 #当前机器在集群中的唯一标识，和zookeeper的myid性质一样 port=9092 #当前kafka对外提供服务的端口默认是9092 host.name=192.168.7.100 #这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。 num.network.threads=3 #这个是borker进行网络处理的线程数 num.io.threads=8 #这个是borker进行I/O处理的线程数 log.dirs=/opt/kafka/kafkalogs/ #消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个 socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能 socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘 socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小 num.partitions=1 #默认的分区数，一个topic默认1个分区数 log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天 message.max.byte=5242880 #消息保存的最大值5M default.replication.factor=2 #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务 replica.fetch.max.bytes=5242880 #取消息的最大直接数 log.segment.bytes=1073741824 #这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件 log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除 log.cleaner.enable=false #是否启用log压缩，一般不用启用，启用的话可以提高性能 zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:1218 #设置zookeeper的连接端口 #########################参数修改############################## broker.id=0 #每台服务器的broker.id都不能相同 host.name=192.168.7.100 #hostname #在log.retention.hours=169下面新增下面三项 message.max.byte=5242880 default.replication.factor=2 replica.fetch.max.bytes=5242880 #设置zookeeper的连接端口 zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:12181 &nbsp; &nbsp; (推荐)启动 kafka,启动kafka和对应的zk集群，进入bin目录下： &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;./kafka-server-start.sh&nbsp; -daemon ../config/server.properties 2.检查kafka是否启动成功： jps &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 3.创建topic，创建一个名为test的topic（一个副本，一个分区） [root@bogon kafka_2.11-2.0.0]#&nbsp;./kafka-topics.sh --zookeeper localhost:2181 --create --topic test --partitions 1 &nbsp;--replication-factor 1 4.查看topic:&nbsp; &nbsp;./kafka-topics.sh &nbsp;--zookeeper localhost:2181 --list 5.查看topic状态：[root@localhost bin]# ./kafka-topics.sh &nbsp;--zookeeper localhost:2181 --topic test --describe &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 6.启动producer并发送消息 &nbsp; &nbsp;[root@bogon kafka_2.11-2.0.0]# bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 启动之后就可以发送消息了,比如test：hello boy 7.启动consumer（另一个终端） &nbsp; &nbsp; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 启动consumer之后就可以在console中看到producer发送的消息了。" />
<meta property="og:description" content="版权声明：本文为博主原创文章，未经博主允许请随便转载 https://blog.csdn.net/CSDN_Terence/article/details/89061258 1 安装条件 &nbsp; &nbsp;1.Kafka依赖于zookeeper存活，所以要确保zk已经安装成功，可以正常启动，参考：linux环境下zookeeper安装步骤。 &nbsp; &nbsp;2.kafka安装包下载：Apache官网&nbsp;http://kafka.apache.org/downloads.html ，选择Binary downloads，选择版本进行下载。也可以直接用以下命令下载： wget http://apache.01link.hk/kafka/2.0.0/kafka_2.11-2.0.0.tgz 2 安装kafka 1.&nbsp; &nbsp;进入指定安装目录：cd&nbsp; /usr/local &nbsp; &nbsp; &nbsp;&nbsp;解压安装包：tar -xzf kafka_2.11-2.0.0.tgz &nbsp; &nbsp;&nbsp; &nbsp;进入解压后的目录：cd kafka_2.11-2.0.0 2. 启动kafka，&nbsp;启动kafka首先要启动zk,启动zk有两种方式: &nbsp; &nbsp;第一种使用kafka带的zk:&nbsp; bin/zookeeper-server-start.sh&nbsp; config/zookeeper.properties（不推荐） &nbsp; &nbsp;第二种使用其他zookeeper（可以是本机zk，也可以位于其它地址的zk）,这种情况需要修改/config/sercer.properties里面的zookeeper地址。&nbsp; #########################参数解释############################## broker.id=0 #当前机器在集群中的唯一标识，和zookeeper的myid性质一样 port=9092 #当前kafka对外提供服务的端口默认是9092 host.name=192.168.7.100 #这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。 num.network.threads=3 #这个是borker进行网络处理的线程数 num.io.threads=8 #这个是borker进行I/O处理的线程数 log.dirs=/opt/kafka/kafkalogs/ #消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个 socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能 socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘 socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小 num.partitions=1 #默认的分区数，一个topic默认1个分区数 log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天 message.max.byte=5242880 #消息保存的最大值5M default.replication.factor=2 #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务 replica.fetch.max.bytes=5242880 #取消息的最大直接数 log.segment.bytes=1073741824 #这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件 log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除 log.cleaner.enable=false #是否启用log压缩，一般不用启用，启用的话可以提高性能 zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:1218 #设置zookeeper的连接端口 #########################参数修改############################## broker.id=0 #每台服务器的broker.id都不能相同 host.name=192.168.7.100 #hostname #在log.retention.hours=169下面新增下面三项 message.max.byte=5242880 default.replication.factor=2 replica.fetch.max.bytes=5242880 #设置zookeeper的连接端口 zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:12181 &nbsp; &nbsp; (推荐)启动 kafka,启动kafka和对应的zk集群，进入bin目录下： &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;./kafka-server-start.sh&nbsp; -daemon ../config/server.properties 2.检查kafka是否启动成功： jps &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 3.创建topic，创建一个名为test的topic（一个副本，一个分区） [root@bogon kafka_2.11-2.0.0]#&nbsp;./kafka-topics.sh --zookeeper localhost:2181 --create --topic test --partitions 1 &nbsp;--replication-factor 1 4.查看topic:&nbsp; &nbsp;./kafka-topics.sh &nbsp;--zookeeper localhost:2181 --list 5.查看topic状态：[root@localhost bin]# ./kafka-topics.sh &nbsp;--zookeeper localhost:2181 --topic test --describe &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 6.启动producer并发送消息 &nbsp; &nbsp;[root@bogon kafka_2.11-2.0.0]# bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 启动之后就可以发送消息了,比如test：hello boy 7.启动consumer（另一个终端） &nbsp; &nbsp; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 启动consumer之后就可以在console中看到producer发送的消息了。" />
<link rel="canonical" href="https://mlh.app/2019/04/06/728332.html" />
<meta property="og:url" content="https://mlh.app/2019/04/06/728332.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-06T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"版权声明：本文为博主原创文章，未经博主允许请随便转载 https://blog.csdn.net/CSDN_Terence/article/details/89061258 1 安装条件 &nbsp; &nbsp;1.Kafka依赖于zookeeper存活，所以要确保zk已经安装成功，可以正常启动，参考：linux环境下zookeeper安装步骤。 &nbsp; &nbsp;2.kafka安装包下载：Apache官网&nbsp;http://kafka.apache.org/downloads.html ，选择Binary downloads，选择版本进行下载。也可以直接用以下命令下载： wget http://apache.01link.hk/kafka/2.0.0/kafka_2.11-2.0.0.tgz 2 安装kafka 1.&nbsp; &nbsp;进入指定安装目录：cd&nbsp; /usr/local &nbsp; &nbsp; &nbsp;&nbsp;解压安装包：tar -xzf kafka_2.11-2.0.0.tgz &nbsp; &nbsp;&nbsp; &nbsp;进入解压后的目录：cd kafka_2.11-2.0.0 2. 启动kafka，&nbsp;启动kafka首先要启动zk,启动zk有两种方式: &nbsp; &nbsp;第一种使用kafka带的zk:&nbsp; bin/zookeeper-server-start.sh&nbsp; config/zookeeper.properties（不推荐） &nbsp; &nbsp;第二种使用其他zookeeper（可以是本机zk，也可以位于其它地址的zk）,这种情况需要修改/config/sercer.properties里面的zookeeper地址。&nbsp; #########################参数解释############################## broker.id=0 #当前机器在集群中的唯一标识，和zookeeper的myid性质一样 port=9092 #当前kafka对外提供服务的端口默认是9092 host.name=192.168.7.100 #这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。 num.network.threads=3 #这个是borker进行网络处理的线程数 num.io.threads=8 #这个是borker进行I/O处理的线程数 log.dirs=/opt/kafka/kafkalogs/ #消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个 socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能 socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘 socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小 num.partitions=1 #默认的分区数，一个topic默认1个分区数 log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天 message.max.byte=5242880 #消息保存的最大值5M default.replication.factor=2 #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务 replica.fetch.max.bytes=5242880 #取消息的最大直接数 log.segment.bytes=1073741824 #这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件 log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除 log.cleaner.enable=false #是否启用log压缩，一般不用启用，启用的话可以提高性能 zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:1218 #设置zookeeper的连接端口 #########################参数修改############################## broker.id=0 #每台服务器的broker.id都不能相同 host.name=192.168.7.100 #hostname #在log.retention.hours=169下面新增下面三项 message.max.byte=5242880 default.replication.factor=2 replica.fetch.max.bytes=5242880 #设置zookeeper的连接端口 zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:12181 &nbsp; &nbsp; (推荐)启动 kafka,启动kafka和对应的zk集群，进入bin目录下： &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;./kafka-server-start.sh&nbsp; -daemon ../config/server.properties 2.检查kafka是否启动成功： jps &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; 3.创建topic，创建一个名为test的topic（一个副本，一个分区） [root@bogon kafka_2.11-2.0.0]#&nbsp;./kafka-topics.sh --zookeeper localhost:2181 --create --topic test --partitions 1 &nbsp;--replication-factor 1 4.查看topic:&nbsp; &nbsp;./kafka-topics.sh &nbsp;--zookeeper localhost:2181 --list 5.查看topic状态：[root@localhost bin]# ./kafka-topics.sh &nbsp;--zookeeper localhost:2181 --topic test --describe &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 6.启动producer并发送消息 &nbsp; &nbsp;[root@bogon kafka_2.11-2.0.0]# bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 启动之后就可以发送消息了,比如test：hello boy 7.启动consumer（另一个终端） &nbsp; &nbsp; bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning 启动consumer之后就可以在console中看到producer发送的消息了。","@type":"BlogPosting","url":"https://mlh.app/2019/04/06/728332.html","headline":"linux环境下kafka安装步骤","dateModified":"2019-04-06T00:00:00+08:00","datePublished":"2019-04-06T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/04/06/728332.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>linux环境下kafka安装步骤</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <div class="article-copyright">
   版权声明：本文为博主原创文章，未经博主允许请随便转载 https://blog.csdn.net/CSDN_Terence/article/details/89061258 
 </div> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h2 style="margin-left:0cm;">1 安装条件</h2> 
  <p style="margin-left:0cm;">&nbsp; &nbsp;1.Kafka依赖于zookeeper存活，所以要确保zk已经安装成功，可以正常启动，参考：<a href="https://blog.csdn.net/CSDN_Terence/article/details/89059315" rel="nofollow">linux环境下zookeeper安装步骤</a>。</p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp;2.kafka安装包下载：Apache官网<a href="%C2%A0http%3A/kafka.apache.org/downloads.html" rel="nofollow">&nbsp;http://kafka.apache.org/downloads.html</a> ，选择Binary downloads，选择版本进行下载。也可以直接用以下命令下载： wget http://apache.01link.hk/kafka/2.0.0/kafka_2.11-2.0.0.tgz</p> 
  <h2 style="margin-left:0cm;">2 安装kafka</h2> 
  <p style="margin-left:0cm;">1.&nbsp; &nbsp;进入指定安装目录：<span style="color:#e579b6;">cd&nbsp; /usr/local</span></p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp; &nbsp;&nbsp;解压安装包：<span style="color:#e579b6;">tar -xzf kafka_2.11-2.0.0.tgz</span></p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp;&nbsp; &nbsp;进入解压后的目录：<span style="color:#e579b6;">cd kafka_2.11-2.0.0</span></p> 
  <p style="margin-left:0cm;">2. 启动kafka，&nbsp;启动kafka首先要启动zk,启动zk有两种方式:</p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp;第一种使用kafka带的zk:&nbsp; bin/zookeeper-server-start.sh&nbsp; config/zookeeper.properties（不推荐）</p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp;第二种使用其他zookeeper（可以是本机zk，也可以位于其它地址的zk）,这种情况需要修改/config/sercer.properties里面的zookeeper地址。&nbsp;</p> 
  <pre class="has">
<code>#########################参数解释##############################
broker.id=0  #当前机器在集群中的唯一标识，和zookeeper的myid性质一样
port=9092 #当前kafka对外提供服务的端口默认是9092
host.name=192.168.7.100 #这个参数默认是关闭的，在0.8.1有个bug，DNS解析问题，失败率的问题。
num.network.threads=3 #这个是borker进行网络处理的线程数
num.io.threads=8 #这个是borker进行I/O处理的线程数
log.dirs=/opt/kafka/kafkalogs/ #消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，上面的num.io.threads要大于这个目录的个数这个目录，如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个
socket.send.buffer.bytes=102400 #发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能
socket.receive.buffer.bytes=102400 #kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘
socket.request.max.bytes=104857600 #这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小
num.partitions=1 #默认的分区数，一个topic默认1个分区数
log.retention.hours=168 #默认消息的最大持久化时间，168小时，7天
message.max.byte=5242880  #消息保存的最大值5M
default.replication.factor=2  #kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务
replica.fetch.max.bytes=5242880  #取消息的最大直接数
log.segment.bytes=1073741824 #这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件
log.retention.check.interval.ms=300000 #每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除
log.cleaner.enable=false #是否启用log压缩，一般不用启用，启用的话可以提高性能
zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:1218 #设置zookeeper的连接端口

#########################参数修改############################## 

broker.id=0  #每台服务器的broker.id都不能相同
host.name=192.168.7.100 #hostname
#在log.retention.hours=169下面新增下面三项
message.max.byte=5242880
default.replication.factor=2
replica.fetch.max.bytes=5242880
#设置zookeeper的连接端口
zookeeper.connect=192.168.7.100:12181,192.168.7.101:12181,192.168.7.107:12181
</code></pre> 
  <p style="margin-left:0cm;">&nbsp; &nbsp; (推荐)<strong>启动 kafka,启动kafka和对应的zk集群，进入bin目录下：</strong></p> 
  <p style="margin-left:0cm;"><strong>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</strong>&nbsp;.<span style="color:#e579b6;">/kafka-server-start.sh&nbsp; -daemon ../config/server.properties</span></p> 
  <p style="margin-left:0cm;"><span>2.检查kafka是否启动成功：</span><span style="color:#e579b6;"> jps</span></p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<img alt="" class="has" height="79" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190407000948271.png" width="197"></p> 
  <p style="margin-left:0cm;">3.创建topic，创建一个名为test的topic（一个副本，一个分区）</p> 
  <p style="margin-left:0cm;">[root@bogon kafka_2.11-2.0.0]#<span style="color:#e579b6;">&nbsp;./kafka-topics.sh --zookeeper localhost:2181 --create --topic test --partitions 1 &nbsp;--replication-factor 1</span></p> 
  <p style="margin-left:0cm;">4.查看topic:&nbsp; &nbsp;<span style="color:#e579b6;">./kafka-topics.sh &nbsp;--zookeeper localhost:2181 --list</span></p> 
  <p style="margin-left:0cm;"><span>5.查</span>看topic状态：<span style="color:#e579b6;">[root@localhost bin]# ./kafka-topics.sh &nbsp;--zookeeper localhost:2181 --topic test --describe</span></p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<img alt="" class="has" height="51" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190407001731560.png" width="649"><br> 6.启动producer并发送消息</p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp;[root@bogon kafka_2.11-2.0.0]# <span style="color:#e579b6;">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic </span><em>test</em><br> 启动之后就可以发送消息了,比如test：hello boy<br> 7.启动consumer（另一个终端）</p> 
  <p style="margin-left:0cm;">&nbsp; &nbsp; <span style="color:#e579b6;">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning</span></p> 
  <p style="margin-left:0cm;">启动consumer之后就可以在console中看到producer发送的消息了。</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
