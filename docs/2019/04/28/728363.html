<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>如何 Get 机器学习必备的算法技能？   技术头条 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="如何 Get 机器学习必备的算法技能？   技术头条" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="本文对常用的三种机器学习优化算法（牛顿法、梯度下降法、最速下降法）进行了介绍和比较，并结合算法的数学原理和实际案例给出了优化算法选择的一些建议。 作者 | Nasir Hemed 编译 | Rachel 出品 | AI科技大本营（id：rgznai100） 基础准备 线性代数 多变量微积分 对凸函数的基本知识 我们都知道，机器学习中最重要的内容之一就是优化问题。因此，找到一个能够对函数做合理优化的算法始终是我们关注的问题。当前，我们使用最多的优化算法之一是梯度下降算法。在本文中，我们会对梯度下降算法以及一些其他的优化算法进行介绍，并尝试从理论角度来理解它们。本文介绍的核心算法包括： 牛顿法（Newton’s Method） 最速下降法（Steep Descent） 梯度下降法（Gradient Descent） 如果想对这些算法有更多了解，你可以阅读斯坦福大学的《凸函数优化—：第三部分》教材。在本文中，我们主要关注二次函数和多项式函数。 对待优化函数的基本假设 一般而言，我们假设我们处理的函数的导数都是连续的（例如，f ∈ C¹）。对于牛顿法，我们还需要假设函数的二阶导数也是连续的（例如， f ∈ C²）。最后，我们还需要假设需要最小化的函数是凸函数。这样一来，如果我们的算法集中到一个点（一般称为局部最小值），我们就可以保证这个值是一个全局最优。 牛顿法 单变量函数的情况 x_n = starting pointx_n1 = x_n - (f&#39;(x_n)/f&#39;&#39;(x_n))while (f(x_n) != f(x_n1)): x_n = x_n1 x_n1 = x_n - (f&#39;(x_n)/f&#39;&#39;(x_n)) 牛顿法的基本思想是，需要优化的函数f在局部可以近似表示为一个二次函数。我们只需要找到这个二次函数的最小值，并将该点的x值记录下来。之后重复这一步骤，直到最小值不再变化为止。 多变量函数的情况 对于单变量的情况，牛顿法比较可靠。但是在实际问题中，我们处理的单变量情形其实很少。大多数时候，我们需要优化的函数都包含很多变量（例如，定义在实数集ℝn的函数）。因此，这里我们需要对多变量的情形进行讨论。 假设x∈ ℝn，则有： x_n = starting_pointx_n1 = x_n - inverse(hessian_matrix) (gradient(x_n))while (f(x_n) != f(x_n1)):x_n = x_n1&nbsp;&nbsp;x_n1&nbsp;=&nbsp;x_n&nbsp;-&nbsp;inverse(hessian_matrix)&nbsp;(gradient(x_n)) 其中，gradient(x_n)是函数位于x_n点时的梯度向量，hessian_matrix是一个尺寸为 nxn 的黑塞矩阵（hessian matrix），其值是函数位于x_n的二阶导数。我们都知道，矩阵转换的算法复杂度是非常高的（O(n³)），因此牛顿法在这种情形下并不常用。 梯度下降 梯度下降是目前为止在机器学习和其他优化问题中使用的最多的优化算法。梯度算法的基本思想是，在每次迭代中向梯度方向走一小步。梯度算法还涉及一个恒定的alpha变量，该变量规定每次跨步的步长。下面是算法示例： alpha = small_constantx_n = starting_pointx_n1 = x_n - alpha * gradient(x_n)while (f(x_n) != f(x_n1)): # May take a long time to converge x_n = x_n1 x_n1 = x_n - alpha * gradient(x_n) 这里，alpha是在每次迭代中更新x_n时都需要使用的变量（一般称为超参数）。下面我们对alpha值的选择进行简单分析。 如果我们选择一个很大的alpha，我们很可能会越过最优点，并离最优点越来越远。事实上，如果alpha的值过大，我们甚至会完全偏离最优点。 当alpha的值过大时，10次迭代后的梯度下降情况 另外，如果我们选择的alpha值过小，则可能需要经过非常多次迭代才能找到最优值。并且，当我们接近最优值时，梯度会接近于0。因此 ，如果alpha的值过小，我们有可能永远都无法到达最优点。 当alpha的值过小时，10次迭代后的梯度下降情况 因此，我们可能需要多尝试一些alpha的值，才能找到最优的选择。如果选择了一个合适的alpha值，我们在迭代时往往能节省很多时间。 当alpha的值合理时，10次迭代后的梯度下降情况 最速下降法 最速下降法和梯度下降法非常相似，但是最速下降法对每次迭代时要求步长的值为最优。下面是最速下降法的算法示例： x_n = starting_pointalpha_k = get_optimizer(f(x_n - alpha * gradient(x_n)))x_n1 = x_n - alpha_n * gradient(x_n)while (f(x_n) != f(x_n1)): x_n = x_n1 alpha_k = get_optimizer(f(x_n - alpha * gradient(x_n))) x_n1 = x_n - alpha_n * gradient(x_n) 其中，x_n和x_n1是ℝn上的向量，是算法的输入，gradient是函数 f 在点x_n的梯度，alpha_k的数学表示如下： 因此，在对原始函数进行优化时，我们需要在每一次迭代中对一个内部函数进行优化。这样做的优点是，这个内部优化函数是一个单变量函数，它的优化不会非常复杂（例如，我们可以使用牛顿法来作为这里的函数）。但是在更多情形下，在每一步中优化这个函数都会带来比较昂贵的花销。 二次式函数的特殊情形 对于均方误差函数： 其中，I&nbsp;是单位矩阵，y=Qw + b&nbsp;。为了简化讨论，这里我们只考虑寻找权重w最优值的情形（假设b是连续的）。将等式 y=Qw + b 带入上式并进行一定整理后，我们可以得到如下等式： 现在我们重新查看一下 g(α)， 我们会发现，如果我们使用点&nbsp;αk&nbsp;处的梯度，由于其为最优值，该梯度应当为0。因此我们有如下等式： 对上式进行简化，并将&nbsp;f&nbsp;的梯度带入后，我们可以得到对于&nbsp;αk&nbsp;的表示如下： 这就是在二次函数情形下&nbsp;αk&nbsp;的值。 对二次函数的收敛性分析 对于定义在 ℝ² 上的二次函数，最速下降法一般用来在非常接近最优值时使用，使用步数不超过十步。 二维中的最速下降在4次迭代后的情形 在上图中，每一次迭代中的改变方向都是垂直的。在3到4次迭代后，我们可以发现导数的变化基本可以忽略不计了。 为什么最速下降法应用很少？ 最速下降法算法远远满足了超参数调优的需求，并且保证能找到局部最小值。但是为什么该算法应用不多呢？最速下降法的问题在于，每一步都需要对 aplha_k 进行优化，这样做的成本相对高昂。 例如，对于二次函数，每次迭代都需要计算多次矩阵乘法以及向量点乘。但对于梯度下降，每一步只需要计算导数并更新值就可以了，这样做的成本远远低于最速下降算法。 最速下降算法的另一个问题是对于非凸函数的优化存在困难。对于非凸函数，aplha_k 可能没有固定的值。 对于梯度下降法和最速下降法的对比 在这一部分，我们对梯度下降法和最速下降法进行对比，并比较它们在时间代价上的差异。首先，我们对比了两种算法的时间花销。我们会创建一个二次函数：f:ℝ²⁰⁰⁰→ℝ&nbsp;（该函数为一个2000x2000的矩阵）。我们将对该函数进行优化，并限制迭代次数为1000次。之后，我们会对两种算法的时间花销进行对比，并查看 x_n 值与最优点的距离。 我们先来看一下最速下降法： 0 Diff: 117727672.56583363 alpha value: 8.032725864804974e-06 100 Diff: 9264.791000127792 alpha value: 1.0176428564615889e-05 200 Diff: 1641.154644548893 alpha value: 1.0236993350903281e-05 300 Diff: 590.5089467763901 alpha value: 1.0254560482036439e-05 400 Diff: 279.2355946302414 alpha value: 1.0263893422517941e-05 500 Diff: 155.43169915676117 alpha value: 1.0270028681773919e-05 600 Diff: 96.61812579631805 alpha value: 1.0274280663010468e-05 700 Diff: 64.87719237804413 alpha value: 1.027728512597358e-05 800 Diff: 46.03102707862854 alpha value: 1.0279461929697766e-05 900 Diff: 34.00975978374481 alpha value: 1.0281092917213468e-05 Optimizer found with x = [-1.68825261 5.31853629 -3.45322318 ... 1.59365232 -2.85114689 5.04026352] and f(x)=-511573479.5792374 in 1000 iterationsTotal time taken: 1min 28s 下面是梯度下降法的情况，其中 alpha = 0.000001： 0 Diff: 26206321.312622845 alpha value: 1e-06 100 Diff: 112613.38076114655 alpha value: 1e-06 200 Diff: 21639.659786581993 alpha value: 1e-06 300 Diff: 7891.810685873032 alpha value: 1e-06 400 Diff: 3793.90934664011 alpha value: 1e-06 500 Diff: 2143.767760157585 alpha value: 1e-06 600 Diff: 1348.4947955012321 alpha value: 1e-06 700 Diff: 914.9099299907684 alpha value: 1e-06 800 Diff: 655.9336211681366 alpha value: 1e-06 900 Diff: 490.05882585048676 alpha value: 1e-06 Optimizer found with x = [-1.80862488 4.66644055 -3.08228401 ... 2.46891076 -2.57581774 5.34672724] and f(x)=-511336392.26658595 in 1000 iterationsTotal time taken: 1min 16s 我们可以发现，梯度下降法的速度比最速下降法略快（几秒或几分钟）。但更重要的是，最速下降法采取的步长比梯度下降法更加合理，尽管梯度下降法的α的值并非最优。在上述示例中， 对于梯度下降算法，f(xprex)&nbsp;和&nbsp;f(curr) 在第900次迭代时的差为450。而最速下降法在很多次迭代前就已经达到这个值了（大约在第300次到第400次迭代之间）。 因此，我们尝试限制最速下降法的迭代次数为300，输出如下： 0 Diff: 118618752.30065191 alpha value: 8.569151292666038e-06 100 Diff: 8281.239207088947 alpha value: 1.1021416896567156e-05 200 Diff: 1463.1741587519646 alpha value: 1.1087402059869253e-05 300 Diff: 526.3014997839928 alpha value: 1.1106776689082503e-05 Optimizer found with x = [-1.33362899 5.89337889 -3.31827817 ... 1.77032789 -2.86779156 4.56444743] and f(x)=-511526291.3367646 in 400 iterationsTime taken: 35.8s 可以发现，最速下降法的速度实际更快。在此情形中，我们在每次迭代使用更少的步数就能逼近最优值。事实上，如果你的目标是估计最优值，最速下降法会比梯度下降法更合适。对于低维度的函数，10步的最速下降法就会比经过1000次迭代的梯度下降法更接近最优值。 下面这个例子中，我们使用了一个定义在&nbsp;ℝ³⁰→ℝ&nbsp;上的二次函数。10步后，最速下降法的得到函数值为 f(x) = -62434.18。而梯度下降法在1000步后得到的函数值为 f(x) = -61596.84。可以发现，最速下降法在10步后的结果就优于梯度下降法在1000步后的结果。 需要记住的是，这种情形仅在处理二次函数的时候适用。整体而言，在每次迭代中都找到 αk的最优值是较为困难的。对函数 g(α) 求最优值并不总能得到 αk 的最优值。通常，我们会使用迭代的算法来对优化函数求最小值。在这种情形下，最速下降法与梯度下降法相比就比较慢了。因此，最速下降法在实际应用中并不常见。 总结 在本文中，我们学习了三种下降算法： 牛顿法（Newton&#39;s method） 牛顿法提供了对函数的二阶近似，并在每一步都对函数进行优化。其最大的问题在于，在优化过程中需要进行矩阵转换，对于多变量情形花销过高（尤其是向量的特征较多的时候）。 梯度下降（Gradient Descent） 梯度下降是最常用的优化算法。由于该算法在每步只对导数进行计算，其花销较低，速度更快。但是在使用该算法时，需要对步长的超参数进行多次的猜测和尝试。 最速下降法（Steepest Descent） 最速下降法在每步都对函数的梯度向量寻找最优步长。它的问题在于，在每次迭代中需要对相关的函数进行优化，这会带来很多花销。对于二次函数的情形，尽管每步都涉及很多矩阵运算，最速下降法的效果仍然更优。 相关笔记可参阅： https://colab.research.google.com/gist/nasirhemed/0026e5e6994d546b4debed8f1ed543c0/a-deeper-look-into-descent-algorithms.ipynb 原文链接： https://towardsdatascience.com/a-deeper-look-at-descent-algorithms-13340b82db49 作为码一代，想教码二代却无从下手： 听说少儿编程很火，可它有哪些好处呢？ 孩子多大开始学习比较好呢？又该如何学习呢？ 最新的编程教育政策又有哪些呢？ 下面给大家介绍CSDN新成员：极客宝宝（ID：geek_baby） 戳他了解更多↓↓↓ &nbsp;热 文&nbsp;推 荐&nbsp; ☞&nbsp;华为效仿苹果卖高价手机？滴滴顺风车开放灰度测试；苹果官微被投诉“攻陷”| 极客头条 ☞&nbsp;Python 爬取吴亦凡的 10 万转发数据，扒一扒流量的真假！ ☞&nbsp;优秀的程序员是如何诞生的？ ☞&nbsp;杨镭访谈：UCloud 的技术价值观 ☞ 普通人也能用AI拍出3D大片？这位清华博士后这么做 ☞ 码二代的出路是什么？ ☞ 小程序的侵权“生死局” ☞ 19岁当老板, 20岁ICO失败, 21岁将项目挂到了eBay, 为何初创公司如此艰难? ☞ 她说：为啥程序员都特想要机械键盘？这答案我服！ System.out.println(&quot;点个在看吧！&quot;);console.log(&quot;点个在看吧！&quot;);print(&quot;点个在看吧！&quot;);printf(&quot;点个在看吧！\n&quot;);cout&nbsp;&lt;&lt;&nbsp;&quot;点个在看吧！&quot;&nbsp;&lt;&lt;&nbsp;endl;Console.WriteLine(&quot;点个在看吧！&quot;);Response.Write(&quot;点个在看吧！&quot;);alert(&quot;点个在看吧！&quot;)echo &quot;点个在看吧！&quot; 你点的每个“在看”，我都认真当成了喜欢" />
<meta property="og:description" content="本文对常用的三种机器学习优化算法（牛顿法、梯度下降法、最速下降法）进行了介绍和比较，并结合算法的数学原理和实际案例给出了优化算法选择的一些建议。 作者 | Nasir Hemed 编译 | Rachel 出品 | AI科技大本营（id：rgznai100） 基础准备 线性代数 多变量微积分 对凸函数的基本知识 我们都知道，机器学习中最重要的内容之一就是优化问题。因此，找到一个能够对函数做合理优化的算法始终是我们关注的问题。当前，我们使用最多的优化算法之一是梯度下降算法。在本文中，我们会对梯度下降算法以及一些其他的优化算法进行介绍，并尝试从理论角度来理解它们。本文介绍的核心算法包括： 牛顿法（Newton’s Method） 最速下降法（Steep Descent） 梯度下降法（Gradient Descent） 如果想对这些算法有更多了解，你可以阅读斯坦福大学的《凸函数优化—：第三部分》教材。在本文中，我们主要关注二次函数和多项式函数。 对待优化函数的基本假设 一般而言，我们假设我们处理的函数的导数都是连续的（例如，f ∈ C¹）。对于牛顿法，我们还需要假设函数的二阶导数也是连续的（例如， f ∈ C²）。最后，我们还需要假设需要最小化的函数是凸函数。这样一来，如果我们的算法集中到一个点（一般称为局部最小值），我们就可以保证这个值是一个全局最优。 牛顿法 单变量函数的情况 x_n = starting pointx_n1 = x_n - (f&#39;(x_n)/f&#39;&#39;(x_n))while (f(x_n) != f(x_n1)): x_n = x_n1 x_n1 = x_n - (f&#39;(x_n)/f&#39;&#39;(x_n)) 牛顿法的基本思想是，需要优化的函数f在局部可以近似表示为一个二次函数。我们只需要找到这个二次函数的最小值，并将该点的x值记录下来。之后重复这一步骤，直到最小值不再变化为止。 多变量函数的情况 对于单变量的情况，牛顿法比较可靠。但是在实际问题中，我们处理的单变量情形其实很少。大多数时候，我们需要优化的函数都包含很多变量（例如，定义在实数集ℝn的函数）。因此，这里我们需要对多变量的情形进行讨论。 假设x∈ ℝn，则有： x_n = starting_pointx_n1 = x_n - inverse(hessian_matrix) (gradient(x_n))while (f(x_n) != f(x_n1)):x_n = x_n1&nbsp;&nbsp;x_n1&nbsp;=&nbsp;x_n&nbsp;-&nbsp;inverse(hessian_matrix)&nbsp;(gradient(x_n)) 其中，gradient(x_n)是函数位于x_n点时的梯度向量，hessian_matrix是一个尺寸为 nxn 的黑塞矩阵（hessian matrix），其值是函数位于x_n的二阶导数。我们都知道，矩阵转换的算法复杂度是非常高的（O(n³)），因此牛顿法在这种情形下并不常用。 梯度下降 梯度下降是目前为止在机器学习和其他优化问题中使用的最多的优化算法。梯度算法的基本思想是，在每次迭代中向梯度方向走一小步。梯度算法还涉及一个恒定的alpha变量，该变量规定每次跨步的步长。下面是算法示例： alpha = small_constantx_n = starting_pointx_n1 = x_n - alpha * gradient(x_n)while (f(x_n) != f(x_n1)): # May take a long time to converge x_n = x_n1 x_n1 = x_n - alpha * gradient(x_n) 这里，alpha是在每次迭代中更新x_n时都需要使用的变量（一般称为超参数）。下面我们对alpha值的选择进行简单分析。 如果我们选择一个很大的alpha，我们很可能会越过最优点，并离最优点越来越远。事实上，如果alpha的值过大，我们甚至会完全偏离最优点。 当alpha的值过大时，10次迭代后的梯度下降情况 另外，如果我们选择的alpha值过小，则可能需要经过非常多次迭代才能找到最优值。并且，当我们接近最优值时，梯度会接近于0。因此 ，如果alpha的值过小，我们有可能永远都无法到达最优点。 当alpha的值过小时，10次迭代后的梯度下降情况 因此，我们可能需要多尝试一些alpha的值，才能找到最优的选择。如果选择了一个合适的alpha值，我们在迭代时往往能节省很多时间。 当alpha的值合理时，10次迭代后的梯度下降情况 最速下降法 最速下降法和梯度下降法非常相似，但是最速下降法对每次迭代时要求步长的值为最优。下面是最速下降法的算法示例： x_n = starting_pointalpha_k = get_optimizer(f(x_n - alpha * gradient(x_n)))x_n1 = x_n - alpha_n * gradient(x_n)while (f(x_n) != f(x_n1)): x_n = x_n1 alpha_k = get_optimizer(f(x_n - alpha * gradient(x_n))) x_n1 = x_n - alpha_n * gradient(x_n) 其中，x_n和x_n1是ℝn上的向量，是算法的输入，gradient是函数 f 在点x_n的梯度，alpha_k的数学表示如下： 因此，在对原始函数进行优化时，我们需要在每一次迭代中对一个内部函数进行优化。这样做的优点是，这个内部优化函数是一个单变量函数，它的优化不会非常复杂（例如，我们可以使用牛顿法来作为这里的函数）。但是在更多情形下，在每一步中优化这个函数都会带来比较昂贵的花销。 二次式函数的特殊情形 对于均方误差函数： 其中，I&nbsp;是单位矩阵，y=Qw + b&nbsp;。为了简化讨论，这里我们只考虑寻找权重w最优值的情形（假设b是连续的）。将等式 y=Qw + b 带入上式并进行一定整理后，我们可以得到如下等式： 现在我们重新查看一下 g(α)， 我们会发现，如果我们使用点&nbsp;αk&nbsp;处的梯度，由于其为最优值，该梯度应当为0。因此我们有如下等式： 对上式进行简化，并将&nbsp;f&nbsp;的梯度带入后，我们可以得到对于&nbsp;αk&nbsp;的表示如下： 这就是在二次函数情形下&nbsp;αk&nbsp;的值。 对二次函数的收敛性分析 对于定义在 ℝ² 上的二次函数，最速下降法一般用来在非常接近最优值时使用，使用步数不超过十步。 二维中的最速下降在4次迭代后的情形 在上图中，每一次迭代中的改变方向都是垂直的。在3到4次迭代后，我们可以发现导数的变化基本可以忽略不计了。 为什么最速下降法应用很少？ 最速下降法算法远远满足了超参数调优的需求，并且保证能找到局部最小值。但是为什么该算法应用不多呢？最速下降法的问题在于，每一步都需要对 aplha_k 进行优化，这样做的成本相对高昂。 例如，对于二次函数，每次迭代都需要计算多次矩阵乘法以及向量点乘。但对于梯度下降，每一步只需要计算导数并更新值就可以了，这样做的成本远远低于最速下降算法。 最速下降算法的另一个问题是对于非凸函数的优化存在困难。对于非凸函数，aplha_k 可能没有固定的值。 对于梯度下降法和最速下降法的对比 在这一部分，我们对梯度下降法和最速下降法进行对比，并比较它们在时间代价上的差异。首先，我们对比了两种算法的时间花销。我们会创建一个二次函数：f:ℝ²⁰⁰⁰→ℝ&nbsp;（该函数为一个2000x2000的矩阵）。我们将对该函数进行优化，并限制迭代次数为1000次。之后，我们会对两种算法的时间花销进行对比，并查看 x_n 值与最优点的距离。 我们先来看一下最速下降法： 0 Diff: 117727672.56583363 alpha value: 8.032725864804974e-06 100 Diff: 9264.791000127792 alpha value: 1.0176428564615889e-05 200 Diff: 1641.154644548893 alpha value: 1.0236993350903281e-05 300 Diff: 590.5089467763901 alpha value: 1.0254560482036439e-05 400 Diff: 279.2355946302414 alpha value: 1.0263893422517941e-05 500 Diff: 155.43169915676117 alpha value: 1.0270028681773919e-05 600 Diff: 96.61812579631805 alpha value: 1.0274280663010468e-05 700 Diff: 64.87719237804413 alpha value: 1.027728512597358e-05 800 Diff: 46.03102707862854 alpha value: 1.0279461929697766e-05 900 Diff: 34.00975978374481 alpha value: 1.0281092917213468e-05 Optimizer found with x = [-1.68825261 5.31853629 -3.45322318 ... 1.59365232 -2.85114689 5.04026352] and f(x)=-511573479.5792374 in 1000 iterationsTotal time taken: 1min 28s 下面是梯度下降法的情况，其中 alpha = 0.000001： 0 Diff: 26206321.312622845 alpha value: 1e-06 100 Diff: 112613.38076114655 alpha value: 1e-06 200 Diff: 21639.659786581993 alpha value: 1e-06 300 Diff: 7891.810685873032 alpha value: 1e-06 400 Diff: 3793.90934664011 alpha value: 1e-06 500 Diff: 2143.767760157585 alpha value: 1e-06 600 Diff: 1348.4947955012321 alpha value: 1e-06 700 Diff: 914.9099299907684 alpha value: 1e-06 800 Diff: 655.9336211681366 alpha value: 1e-06 900 Diff: 490.05882585048676 alpha value: 1e-06 Optimizer found with x = [-1.80862488 4.66644055 -3.08228401 ... 2.46891076 -2.57581774 5.34672724] and f(x)=-511336392.26658595 in 1000 iterationsTotal time taken: 1min 16s 我们可以发现，梯度下降法的速度比最速下降法略快（几秒或几分钟）。但更重要的是，最速下降法采取的步长比梯度下降法更加合理，尽管梯度下降法的α的值并非最优。在上述示例中， 对于梯度下降算法，f(xprex)&nbsp;和&nbsp;f(curr) 在第900次迭代时的差为450。而最速下降法在很多次迭代前就已经达到这个值了（大约在第300次到第400次迭代之间）。 因此，我们尝试限制最速下降法的迭代次数为300，输出如下： 0 Diff: 118618752.30065191 alpha value: 8.569151292666038e-06 100 Diff: 8281.239207088947 alpha value: 1.1021416896567156e-05 200 Diff: 1463.1741587519646 alpha value: 1.1087402059869253e-05 300 Diff: 526.3014997839928 alpha value: 1.1106776689082503e-05 Optimizer found with x = [-1.33362899 5.89337889 -3.31827817 ... 1.77032789 -2.86779156 4.56444743] and f(x)=-511526291.3367646 in 400 iterationsTime taken: 35.8s 可以发现，最速下降法的速度实际更快。在此情形中，我们在每次迭代使用更少的步数就能逼近最优值。事实上，如果你的目标是估计最优值，最速下降法会比梯度下降法更合适。对于低维度的函数，10步的最速下降法就会比经过1000次迭代的梯度下降法更接近最优值。 下面这个例子中，我们使用了一个定义在&nbsp;ℝ³⁰→ℝ&nbsp;上的二次函数。10步后，最速下降法的得到函数值为 f(x) = -62434.18。而梯度下降法在1000步后得到的函数值为 f(x) = -61596.84。可以发现，最速下降法在10步后的结果就优于梯度下降法在1000步后的结果。 需要记住的是，这种情形仅在处理二次函数的时候适用。整体而言，在每次迭代中都找到 αk的最优值是较为困难的。对函数 g(α) 求最优值并不总能得到 αk 的最优值。通常，我们会使用迭代的算法来对优化函数求最小值。在这种情形下，最速下降法与梯度下降法相比就比较慢了。因此，最速下降法在实际应用中并不常见。 总结 在本文中，我们学习了三种下降算法： 牛顿法（Newton&#39;s method） 牛顿法提供了对函数的二阶近似，并在每一步都对函数进行优化。其最大的问题在于，在优化过程中需要进行矩阵转换，对于多变量情形花销过高（尤其是向量的特征较多的时候）。 梯度下降（Gradient Descent） 梯度下降是最常用的优化算法。由于该算法在每步只对导数进行计算，其花销较低，速度更快。但是在使用该算法时，需要对步长的超参数进行多次的猜测和尝试。 最速下降法（Steepest Descent） 最速下降法在每步都对函数的梯度向量寻找最优步长。它的问题在于，在每次迭代中需要对相关的函数进行优化，这会带来很多花销。对于二次函数的情形，尽管每步都涉及很多矩阵运算，最速下降法的效果仍然更优。 相关笔记可参阅： https://colab.research.google.com/gist/nasirhemed/0026e5e6994d546b4debed8f1ed543c0/a-deeper-look-into-descent-algorithms.ipynb 原文链接： https://towardsdatascience.com/a-deeper-look-at-descent-algorithms-13340b82db49 作为码一代，想教码二代却无从下手： 听说少儿编程很火，可它有哪些好处呢？ 孩子多大开始学习比较好呢？又该如何学习呢？ 最新的编程教育政策又有哪些呢？ 下面给大家介绍CSDN新成员：极客宝宝（ID：geek_baby） 戳他了解更多↓↓↓ &nbsp;热 文&nbsp;推 荐&nbsp; ☞&nbsp;华为效仿苹果卖高价手机？滴滴顺风车开放灰度测试；苹果官微被投诉“攻陷”| 极客头条 ☞&nbsp;Python 爬取吴亦凡的 10 万转发数据，扒一扒流量的真假！ ☞&nbsp;优秀的程序员是如何诞生的？ ☞&nbsp;杨镭访谈：UCloud 的技术价值观 ☞ 普通人也能用AI拍出3D大片？这位清华博士后这么做 ☞ 码二代的出路是什么？ ☞ 小程序的侵权“生死局” ☞ 19岁当老板, 20岁ICO失败, 21岁将项目挂到了eBay, 为何初创公司如此艰难? ☞ 她说：为啥程序员都特想要机械键盘？这答案我服！ System.out.println(&quot;点个在看吧！&quot;);console.log(&quot;点个在看吧！&quot;);print(&quot;点个在看吧！&quot;);printf(&quot;点个在看吧！\n&quot;);cout&nbsp;&lt;&lt;&nbsp;&quot;点个在看吧！&quot;&nbsp;&lt;&lt;&nbsp;endl;Console.WriteLine(&quot;点个在看吧！&quot;);Response.Write(&quot;点个在看吧！&quot;);alert(&quot;点个在看吧！&quot;)echo &quot;点个在看吧！&quot; 你点的每个“在看”，我都认真当成了喜欢" />
<link rel="canonical" href="https://mlh.app/2019/04/28/728363.html" />
<meta property="og:url" content="https://mlh.app/2019/04/28/728363.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-04-28T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"本文对常用的三种机器学习优化算法（牛顿法、梯度下降法、最速下降法）进行了介绍和比较，并结合算法的数学原理和实际案例给出了优化算法选择的一些建议。 作者 | Nasir Hemed 编译 | Rachel 出品 | AI科技大本营（id：rgznai100） 基础准备 线性代数 多变量微积分 对凸函数的基本知识 我们都知道，机器学习中最重要的内容之一就是优化问题。因此，找到一个能够对函数做合理优化的算法始终是我们关注的问题。当前，我们使用最多的优化算法之一是梯度下降算法。在本文中，我们会对梯度下降算法以及一些其他的优化算法进行介绍，并尝试从理论角度来理解它们。本文介绍的核心算法包括： 牛顿法（Newton’s Method） 最速下降法（Steep Descent） 梯度下降法（Gradient Descent） 如果想对这些算法有更多了解，你可以阅读斯坦福大学的《凸函数优化—：第三部分》教材。在本文中，我们主要关注二次函数和多项式函数。 对待优化函数的基本假设 一般而言，我们假设我们处理的函数的导数都是连续的（例如，f ∈ C¹）。对于牛顿法，我们还需要假设函数的二阶导数也是连续的（例如， f ∈ C²）。最后，我们还需要假设需要最小化的函数是凸函数。这样一来，如果我们的算法集中到一个点（一般称为局部最小值），我们就可以保证这个值是一个全局最优。 牛顿法 单变量函数的情况 x_n = starting pointx_n1 = x_n - (f&#39;(x_n)/f&#39;&#39;(x_n))while (f(x_n) != f(x_n1)): x_n = x_n1 x_n1 = x_n - (f&#39;(x_n)/f&#39;&#39;(x_n)) 牛顿法的基本思想是，需要优化的函数f在局部可以近似表示为一个二次函数。我们只需要找到这个二次函数的最小值，并将该点的x值记录下来。之后重复这一步骤，直到最小值不再变化为止。 多变量函数的情况 对于单变量的情况，牛顿法比较可靠。但是在实际问题中，我们处理的单变量情形其实很少。大多数时候，我们需要优化的函数都包含很多变量（例如，定义在实数集ℝn的函数）。因此，这里我们需要对多变量的情形进行讨论。 假设x∈ ℝn，则有： x_n = starting_pointx_n1 = x_n - inverse(hessian_matrix) (gradient(x_n))while (f(x_n) != f(x_n1)):x_n = x_n1&nbsp;&nbsp;x_n1&nbsp;=&nbsp;x_n&nbsp;-&nbsp;inverse(hessian_matrix)&nbsp;(gradient(x_n)) 其中，gradient(x_n)是函数位于x_n点时的梯度向量，hessian_matrix是一个尺寸为 nxn 的黑塞矩阵（hessian matrix），其值是函数位于x_n的二阶导数。我们都知道，矩阵转换的算法复杂度是非常高的（O(n³)），因此牛顿法在这种情形下并不常用。 梯度下降 梯度下降是目前为止在机器学习和其他优化问题中使用的最多的优化算法。梯度算法的基本思想是，在每次迭代中向梯度方向走一小步。梯度算法还涉及一个恒定的alpha变量，该变量规定每次跨步的步长。下面是算法示例： alpha = small_constantx_n = starting_pointx_n1 = x_n - alpha * gradient(x_n)while (f(x_n) != f(x_n1)): # May take a long time to converge x_n = x_n1 x_n1 = x_n - alpha * gradient(x_n) 这里，alpha是在每次迭代中更新x_n时都需要使用的变量（一般称为超参数）。下面我们对alpha值的选择进行简单分析。 如果我们选择一个很大的alpha，我们很可能会越过最优点，并离最优点越来越远。事实上，如果alpha的值过大，我们甚至会完全偏离最优点。 当alpha的值过大时，10次迭代后的梯度下降情况 另外，如果我们选择的alpha值过小，则可能需要经过非常多次迭代才能找到最优值。并且，当我们接近最优值时，梯度会接近于0。因此 ，如果alpha的值过小，我们有可能永远都无法到达最优点。 当alpha的值过小时，10次迭代后的梯度下降情况 因此，我们可能需要多尝试一些alpha的值，才能找到最优的选择。如果选择了一个合适的alpha值，我们在迭代时往往能节省很多时间。 当alpha的值合理时，10次迭代后的梯度下降情况 最速下降法 最速下降法和梯度下降法非常相似，但是最速下降法对每次迭代时要求步长的值为最优。下面是最速下降法的算法示例： x_n = starting_pointalpha_k = get_optimizer(f(x_n - alpha * gradient(x_n)))x_n1 = x_n - alpha_n * gradient(x_n)while (f(x_n) != f(x_n1)): x_n = x_n1 alpha_k = get_optimizer(f(x_n - alpha * gradient(x_n))) x_n1 = x_n - alpha_n * gradient(x_n) 其中，x_n和x_n1是ℝn上的向量，是算法的输入，gradient是函数 f 在点x_n的梯度，alpha_k的数学表示如下： 因此，在对原始函数进行优化时，我们需要在每一次迭代中对一个内部函数进行优化。这样做的优点是，这个内部优化函数是一个单变量函数，它的优化不会非常复杂（例如，我们可以使用牛顿法来作为这里的函数）。但是在更多情形下，在每一步中优化这个函数都会带来比较昂贵的花销。 二次式函数的特殊情形 对于均方误差函数： 其中，I&nbsp;是单位矩阵，y=Qw + b&nbsp;。为了简化讨论，这里我们只考虑寻找权重w最优值的情形（假设b是连续的）。将等式 y=Qw + b 带入上式并进行一定整理后，我们可以得到如下等式： 现在我们重新查看一下 g(α)， 我们会发现，如果我们使用点&nbsp;αk&nbsp;处的梯度，由于其为最优值，该梯度应当为0。因此我们有如下等式： 对上式进行简化，并将&nbsp;f&nbsp;的梯度带入后，我们可以得到对于&nbsp;αk&nbsp;的表示如下： 这就是在二次函数情形下&nbsp;αk&nbsp;的值。 对二次函数的收敛性分析 对于定义在 ℝ² 上的二次函数，最速下降法一般用来在非常接近最优值时使用，使用步数不超过十步。 二维中的最速下降在4次迭代后的情形 在上图中，每一次迭代中的改变方向都是垂直的。在3到4次迭代后，我们可以发现导数的变化基本可以忽略不计了。 为什么最速下降法应用很少？ 最速下降法算法远远满足了超参数调优的需求，并且保证能找到局部最小值。但是为什么该算法应用不多呢？最速下降法的问题在于，每一步都需要对 aplha_k 进行优化，这样做的成本相对高昂。 例如，对于二次函数，每次迭代都需要计算多次矩阵乘法以及向量点乘。但对于梯度下降，每一步只需要计算导数并更新值就可以了，这样做的成本远远低于最速下降算法。 最速下降算法的另一个问题是对于非凸函数的优化存在困难。对于非凸函数，aplha_k 可能没有固定的值。 对于梯度下降法和最速下降法的对比 在这一部分，我们对梯度下降法和最速下降法进行对比，并比较它们在时间代价上的差异。首先，我们对比了两种算法的时间花销。我们会创建一个二次函数：f:ℝ²⁰⁰⁰→ℝ&nbsp;（该函数为一个2000x2000的矩阵）。我们将对该函数进行优化，并限制迭代次数为1000次。之后，我们会对两种算法的时间花销进行对比，并查看 x_n 值与最优点的距离。 我们先来看一下最速下降法： 0 Diff: 117727672.56583363 alpha value: 8.032725864804974e-06 100 Diff: 9264.791000127792 alpha value: 1.0176428564615889e-05 200 Diff: 1641.154644548893 alpha value: 1.0236993350903281e-05 300 Diff: 590.5089467763901 alpha value: 1.0254560482036439e-05 400 Diff: 279.2355946302414 alpha value: 1.0263893422517941e-05 500 Diff: 155.43169915676117 alpha value: 1.0270028681773919e-05 600 Diff: 96.61812579631805 alpha value: 1.0274280663010468e-05 700 Diff: 64.87719237804413 alpha value: 1.027728512597358e-05 800 Diff: 46.03102707862854 alpha value: 1.0279461929697766e-05 900 Diff: 34.00975978374481 alpha value: 1.0281092917213468e-05 Optimizer found with x = [-1.68825261 5.31853629 -3.45322318 ... 1.59365232 -2.85114689 5.04026352] and f(x)=-511573479.5792374 in 1000 iterationsTotal time taken: 1min 28s 下面是梯度下降法的情况，其中 alpha = 0.000001： 0 Diff: 26206321.312622845 alpha value: 1e-06 100 Diff: 112613.38076114655 alpha value: 1e-06 200 Diff: 21639.659786581993 alpha value: 1e-06 300 Diff: 7891.810685873032 alpha value: 1e-06 400 Diff: 3793.90934664011 alpha value: 1e-06 500 Diff: 2143.767760157585 alpha value: 1e-06 600 Diff: 1348.4947955012321 alpha value: 1e-06 700 Diff: 914.9099299907684 alpha value: 1e-06 800 Diff: 655.9336211681366 alpha value: 1e-06 900 Diff: 490.05882585048676 alpha value: 1e-06 Optimizer found with x = [-1.80862488 4.66644055 -3.08228401 ... 2.46891076 -2.57581774 5.34672724] and f(x)=-511336392.26658595 in 1000 iterationsTotal time taken: 1min 16s 我们可以发现，梯度下降法的速度比最速下降法略快（几秒或几分钟）。但更重要的是，最速下降法采取的步长比梯度下降法更加合理，尽管梯度下降法的α的值并非最优。在上述示例中， 对于梯度下降算法，f(xprex)&nbsp;和&nbsp;f(curr) 在第900次迭代时的差为450。而最速下降法在很多次迭代前就已经达到这个值了（大约在第300次到第400次迭代之间）。 因此，我们尝试限制最速下降法的迭代次数为300，输出如下： 0 Diff: 118618752.30065191 alpha value: 8.569151292666038e-06 100 Diff: 8281.239207088947 alpha value: 1.1021416896567156e-05 200 Diff: 1463.1741587519646 alpha value: 1.1087402059869253e-05 300 Diff: 526.3014997839928 alpha value: 1.1106776689082503e-05 Optimizer found with x = [-1.33362899 5.89337889 -3.31827817 ... 1.77032789 -2.86779156 4.56444743] and f(x)=-511526291.3367646 in 400 iterationsTime taken: 35.8s 可以发现，最速下降法的速度实际更快。在此情形中，我们在每次迭代使用更少的步数就能逼近最优值。事实上，如果你的目标是估计最优值，最速下降法会比梯度下降法更合适。对于低维度的函数，10步的最速下降法就会比经过1000次迭代的梯度下降法更接近最优值。 下面这个例子中，我们使用了一个定义在&nbsp;ℝ³⁰→ℝ&nbsp;上的二次函数。10步后，最速下降法的得到函数值为 f(x) = -62434.18。而梯度下降法在1000步后得到的函数值为 f(x) = -61596.84。可以发现，最速下降法在10步后的结果就优于梯度下降法在1000步后的结果。 需要记住的是，这种情形仅在处理二次函数的时候适用。整体而言，在每次迭代中都找到 αk的最优值是较为困难的。对函数 g(α) 求最优值并不总能得到 αk 的最优值。通常，我们会使用迭代的算法来对优化函数求最小值。在这种情形下，最速下降法与梯度下降法相比就比较慢了。因此，最速下降法在实际应用中并不常见。 总结 在本文中，我们学习了三种下降算法： 牛顿法（Newton&#39;s method） 牛顿法提供了对函数的二阶近似，并在每一步都对函数进行优化。其最大的问题在于，在优化过程中需要进行矩阵转换，对于多变量情形花销过高（尤其是向量的特征较多的时候）。 梯度下降（Gradient Descent） 梯度下降是最常用的优化算法。由于该算法在每步只对导数进行计算，其花销较低，速度更快。但是在使用该算法时，需要对步长的超参数进行多次的猜测和尝试。 最速下降法（Steepest Descent） 最速下降法在每步都对函数的梯度向量寻找最优步长。它的问题在于，在每次迭代中需要对相关的函数进行优化，这会带来很多花销。对于二次函数的情形，尽管每步都涉及很多矩阵运算，最速下降法的效果仍然更优。 相关笔记可参阅： https://colab.research.google.com/gist/nasirhemed/0026e5e6994d546b4debed8f1ed543c0/a-deeper-look-into-descent-algorithms.ipynb 原文链接： https://towardsdatascience.com/a-deeper-look-at-descent-algorithms-13340b82db49 作为码一代，想教码二代却无从下手： 听说少儿编程很火，可它有哪些好处呢？ 孩子多大开始学习比较好呢？又该如何学习呢？ 最新的编程教育政策又有哪些呢？ 下面给大家介绍CSDN新成员：极客宝宝（ID：geek_baby） 戳他了解更多↓↓↓ &nbsp;热 文&nbsp;推 荐&nbsp; ☞&nbsp;华为效仿苹果卖高价手机？滴滴顺风车开放灰度测试；苹果官微被投诉“攻陷”| 极客头条 ☞&nbsp;Python 爬取吴亦凡的 10 万转发数据，扒一扒流量的真假！ ☞&nbsp;优秀的程序员是如何诞生的？ ☞&nbsp;杨镭访谈：UCloud 的技术价值观 ☞ 普通人也能用AI拍出3D大片？这位清华博士后这么做 ☞ 码二代的出路是什么？ ☞ 小程序的侵权“生死局” ☞ 19岁当老板, 20岁ICO失败, 21岁将项目挂到了eBay, 为何初创公司如此艰难? ☞ 她说：为啥程序员都特想要机械键盘？这答案我服！ System.out.println(&quot;点个在看吧！&quot;);console.log(&quot;点个在看吧！&quot;);print(&quot;点个在看吧！&quot;);printf(&quot;点个在看吧！\\n&quot;);cout&nbsp;&lt;&lt;&nbsp;&quot;点个在看吧！&quot;&nbsp;&lt;&lt;&nbsp;endl;Console.WriteLine(&quot;点个在看吧！&quot;);Response.Write(&quot;点个在看吧！&quot;);alert(&quot;点个在看吧！&quot;)echo &quot;点个在看吧！&quot; 你点的每个“在看”，我都认真当成了喜欢","@type":"BlogPosting","url":"https://mlh.app/2019/04/28/728363.html","headline":"如何 Get 机器学习必备的算法技能？   技术头条","dateModified":"2019-04-28T00:00:00+08:00","datePublished":"2019-04-28T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/04/28/728363.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>如何&nbsp;Get&nbsp;机器学习必备的算法技能？&nbsp;|&nbsp;技术头条</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <p style="text-align: center;"><img class=" __bg_gif" data-copyright="0" data-ratio="0.15644171779141106" data-type="gif" data-w="652" data-src="https://mmbiz.qpic.cn/mmbiz_gif/Pn4Sm0RsAug5zOzy32A3RIVhRwowK5ogg1hJ631uGyu9zOMKfTddDnSrsxicbCQNm59Qeo3lDYCvF70I9ibGvA9g/640?wx_fmt=gif" style="text-align: justify;letter-spacing: 1px;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;width: 652px !important;visibility: visible !important;" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_gif/Pn4Sm0RsAug5zOzy32A3RIVhRwowK5ogg1hJ631uGyu9zOMKfTddDnSrsxicbCQNm59Qeo3lDYCvF70I9ibGvA9g/640?wx_fmt=gif"></p> 
<blockquote class="js_blockquote_wrap" data-type="2" data-url="" data-author-name="" data-content-utf8-length="72" data-source-title=""> 
 <section class="js_blockquote_digest"> 
  <p style="line-height: 1.75em;margin-left: 8px;margin-right: 8px;"><span style="letter-spacing: 1px;">本文对常用的三种机器学习优化算法（牛顿法、梯度下降法、最速下降法）进行了介绍和比较，并结合算法的数学原理和实际案例给出了优化算法选择的一些建议。</span></p> 
 </section> 
</blockquote> 
<p style="text-align: center;margin-left: 8px;margin-right: 8px;"><img class="rich_pages" data-copyright="0" data-ratio="0.66796875" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/Pn4Sm0RsAujEctUibsE50mbCXpVu6PtNAwvicdthcQZrNW1s9ZPiadbwvrXokFibISzPKqjHmYNLNDMMJKtFdaoUbA/640?wx_fmt=jpeg" data-type="jpeg" data-w="1280" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/Pn4Sm0RsAujEctUibsE50mbCXpVu6PtNAwvicdthcQZrNW1s9ZPiadbwvrXokFibISzPKqjHmYNLNDMMJKtFdaoUbA/640?wx_fmt=jpeg"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(136, 136, 136);"></span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.5em;"><span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.5px;">作者 | Nasir Hemed</span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.5em;"><span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.5px;">编译 | Rachel</span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.5em;"><span style="color: rgb(136, 136, 136);font-size: 14px;letter-spacing: 0.5px;">出品 | AI科技大本营（id：rgznai100）</span></p> 
<p style="margin: 15px 8px;white-space: normal;line-height: 1.75em;text-align: center;"><strong><span style="letter-spacing: 1px;font-size: 18px;color: rgb(70, 118, 217);"><br></span></strong></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.1625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LXSAriayI15u06ibNNlXzIcor2tTtgJBKFxkIicJ8tiaRKRaictbrQEssdSg/640?wx_fmt=png" data-type="png" data-w="160" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LXSAriayI15u06ibNNlXzIcor2tTtgJBKFxkIicJ8tiaRKRaictbrQEssdSg/640?wx_fmt=png"></p> 
<p style="text-align: center;"><span style="color: rgb(0, 0, 0);font-size: 18px;"><strong><span style="font-size: 18px;color: rgb(0, 0, 0);letter-spacing: 1px;">基础准备</span></strong></span></p> 
<p style="text-align: center;"><strong><span style="letter-spacing: 1px;font-size: 18px;color: rgb(70, 118, 217);"><br></span></strong></p> 
<p line="lTEg" style="white-space: normal;"><br></p> 
<ul data-list-style="circle" class="ql-long-14573947 list-paddingleft-2" style="margin-left: 8px;margin-right: 8px;"> 
 <li><p style="line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">线性代数</span></p></li> 
</ul> 
<ul data-list-style="circle" class="ql-long-14573947 list-paddingleft-2" style="margin-left: 8px;margin-right: 8px;"> 
 <li><p style="line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">多变量微积分</span></p></li> 
</ul> 
<ul data-list-style="circle" class="ql-long-14573947 list-paddingleft-2" style="margin-left: 8px;margin-right: 8px;"> 
 <li><p style="line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">对凸函数的基本知识</span></p></li> 
</ul> 
<p line="SRBE" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">我们都知道，机器学习中最重要的内容之一就是优化问题。因此，找到一个能够对函数做合理优化的算法始终是我们关注的问题。当前，我们使用最多的优化算法之一是梯度下降算法。在本文中，我们会对梯度下降算法以及一些其他的优化算法进行介绍，并尝试从理论角度来理解它们。本文介绍的核心算法包括：</span></p> 
<p line="Gahi" style="white-space: normal;"><br></p> 
<ul data-list-style="circle" class="ql-long-14573947 list-paddingleft-2" style="margin-left: 8px;margin-right: 8px;"> 
 <li><p style="line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">牛顿法（Newton’s Method）</span></p></li> 
</ul> 
<ul data-list-style="circle" class="ql-long-14573947 list-paddingleft-2" style="margin-left: 8px;margin-right: 8px;"> 
 <li><p style="line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">最速下降法（Steep Descent）</span></p></li> 
</ul> 
<ul data-list-style="circle" class="ql-long-14573947 list-paddingleft-2" style="margin-left: 8px;margin-right: 8px;"> 
 <li><p style="line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">梯度下降法（Gradient Descent）</span></p></li> 
</ul> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">如果想对这些算法有更多了解，你可以阅读斯坦福大学的《凸函数优化—：第三部分》教材。在本文中，我们主要关注二次函数和多项式函数。</span></p> 
<p line="QEzk" style="white-space: normal;"><br></p> 
<p line="QEzk" style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.1625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LwYnW1VvkaHWiaL6W1Mr1yiaNLQpxwhyqice9F1yJzMHticssPX515qyvog/640?wx_fmt=png" data-type="png" data-w="160" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LwYnW1VvkaHWiaL6W1Mr1yiaNLQpxwhyqice9F1yJzMHticssPX515qyvog/640?wx_fmt=png"></p> 
<p style="text-align: center;"><span style="font-size: 18px;color: rgb(0, 0, 0);"><strong><span style="color: rgb(0, 0, 0);font-size: 18px;letter-spacing: 1px;">对待优化函数的基本假设</span></strong></span></p> 
<p line="QKy4" style="white-space: normal;"><br></p> 
<p line="QKy4" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">一般而言，我们假设我们处理的函数的导数都是连续的（例如，f ∈ C¹）。对于牛顿法，我们还需要假设函数的二阶导数也是连续的（例如， f ∈ C²）。最后，我们还需要假设需要最小化的函数是凸函数。这样一来，如果我们的算法集中到一个点（一般称为局部最小值），我们就可以保证这个值是一个全局最优。</span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><br></span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><br></span></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.1625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4Lb4ybNEVGnaAvEDwENKzW27LUKFDGZPKcBneWwTaTpaJyG2C3em7libQ/640?wx_fmt=png" data-type="png" data-w="160" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4Lb4ybNEVGnaAvEDwENKzW27LUKFDGZPKcBneWwTaTpaJyG2C3em7libQ/640?wx_fmt=png"></p> 
<p style="text-align: center;"><span style="color: rgb(0, 0, 0);font-size: 18px;"><strong><span style="font-size: 18px;color: rgb(0, 0, 0);letter-spacing: 1px;">牛顿法</span></strong></span></p> 
<p line="uhF8" style="white-space: normal;"><br></p> 
<p line="uhF8" style="white-space: normal;"><br></p> 
<ul class=" list-paddingleft-2" style="list-style-type: disc;"> 
 <li><p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">单变量函数的情况</span></strong></p></li> 
</ul> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><br></span></strong></p> 
<section class="code-snippet__fix code-snippet__js"> 
 <ul class="code-snippet__line-index code-snippet__js"> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
 </ul> 
 <pre class="code-snippet__js" data-lang="ini"><p style="margin-right: 8px;margin-left: 8px;line-height: 1.75em;"><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">x_n = starting point</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">x_n1 = x_n - (f'(x_n)/f''(x_n))</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">while (f(x_n) != f(x_n1)):</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"> x_n = x_n1 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"> x_n1 = x_n - (f'(x_n)/f''(x_n))</span></code></p></pre> 
</section> 
<p line="xD2B" class="ql-long-14573947" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">牛顿法的基本思想是，需要优化的函数f在局部可以近似表示为一个二次函数。我们只需要找到这个二次函数的最小值，并将该点的x值记录下来。之后重复这一步骤，直到最小值不再变化为止。</span></p> 
<p line="X6IL" style="white-space: normal;"><br></p> 
<ul class=" list-paddingleft-2" style="list-style-type: disc;"> 
 <li><p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">多变量函数的情况</span></strong></p></li> 
</ul> 
<p line="HU0M" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">对于单变量的情况，牛顿法比较可靠。但是在实际问题中，我们处理的单变量情形其实很少。大多数时候，我们需要优化的函数都包含很多变量（例如，定义在实数集ℝn的函数）。因此，这里我们需要对多变量的情形进行讨论。</span></p> 
<p line="V04a" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">假设x∈ ℝn，则有：</span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><br></span></p> 
<section class="code-snippet__fix code-snippet__js"> 
 <ul class="code-snippet__line-index code-snippet__js"> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
 </ul> 
 <pre class="code-snippet__js" data-lang="properties"><p style="margin-right: 8px;margin-left: 8px;line-height: 1.75em;"><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">x_n = starting_point</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">x_n1 = x_n - inverse(hessian_matrix) (gradient(x_n))</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">while (f(x_n) != f(x_n1)):</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">x_n = x_n1</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">&nbsp;&nbsp;x_n1&nbsp;=&nbsp;x_n&nbsp;-&nbsp;inverse(hessian_matrix)&nbsp;(gradient(x_n))</span></code></p></pre> 
</section> 
<pre><br></pre> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">其中，gradient(x_n)是函数位于x_n点时的梯度向量，hessian_matrix是一个尺寸为 nxn 的黑塞矩阵（hessian matrix），其值是函数位于x_n的二阶导数。我们都知道，矩阵转换的算法复杂度是非常高的（<strong style="color: rgba(0, 0, 0, 0.84);font-family: serif;"><em>O</em>(n³)</strong>），因此牛顿法在这种情形下并不常用。</span></p> 
<p style="white-space: normal;"><br></p> 
<p style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.1625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LLqyf6BY4rMfY2LsU81MibFjicKDLjMjib5R23h8uo6GtGDY8OufWJfpEw/640?wx_fmt=png" data-type="png" data-w="160" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LLqyf6BY4rMfY2LsU81MibFjicKDLjMjib5R23h8uo6GtGDY8OufWJfpEw/640?wx_fmt=png"></p> 
<p style="text-align: center;"><span style="color: rgb(0, 0, 0);"><strong><span style="color: rgb(0, 0, 0);letter-spacing: 1px;font-size: 18px;">梯度下降</span></strong></span></p> 
<p line="rhvK" style="white-space: normal;"><br></p> 
<p line="rhvK" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">梯度下降是目前为止在机器学习和其他优化问题中使用的最多的优化算法。梯度算法的基本思想是，在每次迭代中向梯度方向走一小步。梯度算法还涉及一个恒定的alpha变量，该变量规定每次跨步的步长。下面是算法示例：</span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><br></span></p> 
<section class="code-snippet__fix code-snippet__js"> 
 <ul class="code-snippet__line-index code-snippet__js"> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
 </ul> 
 <pre class="code-snippet__js" data-lang="makefile"><code><span class="code-snippet_outer">alpha = small_constant</span></code><code><span class="code-snippet_outer">x_n = starting_point</span></code><code><span class="code-snippet_outer">x_n1 = x_n - alpha * gradient(x_n)</span></code><code><span class="code-snippet_outer">while (f(x_n) != f(x_n1)): <span class="code-snippet__comment"># May take a long time to converge</span></span></code><code><span class="code-snippet_outer"> x_n = x_n1</span></code><code><span class="code-snippet_outer"> x_n1 = x_n - alpha * gradient(x_n)</span></code></pre> 
</section> 
<p style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">这里，alpha是在每次迭代中更新x_n时都需要使用的变量（一般称为超参数）。下面我们对alpha值的选择进行简单分析。</span></p> 
<p line="nioU" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">如果我们选择一个很大的alpha，我们很可能会越过最优点，并离最优点越来越远。事实上，如果alpha的值过大，我们甚至会完全偏离最优点。</span></p> 
<p style="white-space: normal;"><br></p> 
<p style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.6649874055415617" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IJrnRF8gibotkbJxsCwF0B46ckcJhkmrgs79GlOZdpCXcwQJPE35bKUQ/640?wx_fmt=png" data-type="png" data-w="397" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IJrnRF8gibotkbJxsCwF0B46ckcJhkmrgs79GlOZdpCXcwQJPE35bKUQ/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;"><span style="color: rgb(136, 136, 136);letter-spacing: 1px;font-size: 12px;">当alpha的值过大时，10次迭代后的梯度下降情况</span></p> 
<p line="zlnn" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">另外，如果我们选择的alpha值过小，则可能需要经过非常多次迭代才能找到最优值。并且，当我们接近最优值时，梯度会接近于0。因此 ，如果alpha的值过小，我们有可能永远都无法到达最优点。</span></p> 
<p style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.6649874055415617" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1I3amfCVCJQDDFqEylXSwkWuRoI9iamNC2dHqKIeAtwNPSCXmQMsGws1Q/640?wx_fmt=png" data-type="png" data-w="397" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1I3amfCVCJQDDFqEylXSwkWuRoI9iamNC2dHqKIeAtwNPSCXmQMsGws1Q/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;"><span style="font-size: 12px;letter-spacing: 1px;color: rgb(136, 136, 136);">当alpha的值过小时，10次迭代后的梯度下降情况</span></p> 
<p line="ly5E" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">因此，我们可能需要多尝试一些alpha的值，才能找到最优的选择。如果选择了一个合适的alpha值，我们在迭代时往往能节省很多时间。</span></p> 
<p line="Zucn" style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.6649874055415617" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IcV8iaBCkoZ5fc10LiaFeDicAjGMsqh0DMRQia2n4BbsIrgTcLVBfLCYfDA/640?wx_fmt=png" data-type="png" data-w="397" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IcV8iaBCkoZ5fc10LiaFeDicAjGMsqh0DMRQia2n4BbsIrgTcLVBfLCYfDA/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;"><span style="letter-spacing: 1px;font-size: 12px;color: rgb(136, 136, 136);">当alpha的值合理时，10次迭代后的梯度下降情况</span></p> 
<p line="JXnH" style="white-space: normal;"><br></p> 
<p line="JXnH" style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.1625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LzUzfol6q1COlZYpeYXqe0aia45DXyhcTQW8voWvibFJvEjfmkhPvCrEg/640?wx_fmt=png" data-type="png" data-w="160" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LzUzfol6q1COlZYpeYXqe0aia45DXyhcTQW8voWvibFJvEjfmkhPvCrEg/640?wx_fmt=png"></p> 
<p style="text-align: center;"><span style="color: rgb(0, 0, 0);"><strong><span style="color: rgb(0, 0, 0);letter-spacing: 1px;font-size: 18px;">最速下降法</span></strong></span></p> 
<p line="xjID" style="white-space: normal;"><br></p> 
<p line="xjID" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">最速下降法和梯度下降法非常相似，但是最速下降法对每次迭代时要求步长的值为最优。下面是最速下降法的算法示例：</span></p> 
<p line="aF0N" class="ql-long-14573947" style="white-space: normal;"><br></p> 
<section class="code-snippet__fix code-snippet__js"> 
 <ul class="code-snippet__line-index code-snippet__js"> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
 </ul> 
 <pre class="code-snippet__js" data-lang="properties"><code><span class="code-snippet_outer"><span class="code-snippet__attr">x_n</span> = <span class="code-snippet__string">starting_point</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">alpha_k</span> = <span class="code-snippet__string">get_optimizer(f(x_n - alpha * gradient(x_n)))</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">x_n1</span> = <span class="code-snippet__string">x_n - alpha_n * gradient(x_n)</span></span></code><code><span class="code-snippet_outer"><span class="code-snippet__attr">while</span> <span class="code-snippet__string">(f(x_n) != f(x_n1)):</span></span></code><code><span class="code-snippet_outer"> <span class="code-snippet__attr">x_n</span> = <span class="code-snippet__string">x_n1 </span></span></code><code><span class="code-snippet_outer"> <span class="code-snippet__attr">alpha_k</span> = <span class="code-snippet__string">get_optimizer(f(x_n - alpha * gradient(x_n)))</span></span></code><code><span class="code-snippet_outer"> <span class="code-snippet__attr">x_n1</span> = <span class="code-snippet__string">x_n - alpha_n * gradient(x_n)</span></span></code></pre> 
</section> 
<pre><br></pre> 
<p style="margin-left: 8px;margin-right: 8px;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">其中，x_n和x_n1是ℝn上的向量，是算法的输入，gradient是函数 f 在点x_n的梯度，alpha_k的数学表示如下：</span></p> 
<p style="text-align: center;"><img class="rich_pages" data-ratio="0.15151515151515152" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IhP5Fxg50icAvDYoVDBh81HgO02PlFEv2Kq0lkUlPpSX0cRGlKZEoMrw/640?wx_fmt=png" data-type="png" data-w="561" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IhP5Fxg50icAvDYoVDBh81HgO02PlFEv2Kq0lkUlPpSX0cRGlKZEoMrw/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">因此，在对原始函数进行优化时，我们需要在每一次迭代中对一个内部函数进行优化。这样做的优点是，这个内部优化函数是一个单变量函数，它的优化不会非常复杂（例如，我们可以使用牛顿法来作为这里的函数）。但是在更多情形下，在每一步中优化这个函数都会带来比较昂贵的花销。</span></p> 
<p line="5Fs4" class="ql-long-14573947" style="white-space: normal;"><br></p> 
<ul class=" list-paddingleft-2" style="list-style-type: disc;"> 
 <li><p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">二次式函数的特殊情形</span></strong><span style="letter-spacing: 1px;color: rgb(63, 63, 63);font-size: 15px;"><strong style="font-size: 12pt;"></strong></span></p></li> 
</ul> 
<p line="oBm3" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">对于均方误差函数：</span></p> 
<p line="zpMR" style="white-space: normal;"><span style="font-size: 15px;"></span></p> 
<p style="text-align: center;"><img class="rich_pages" data-ratio="0.19274809160305342" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IB08IroH3IZHia1IQ8CbKchhYLvPv7Vt3H1iakvLAJgAkjufMVs1JRTjg/640?wx_fmt=png" data-type="png" data-w="524" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IB08IroH3IZHia1IQ8CbKchhYLvPv7Vt3H1iakvLAJgAkjufMVs1JRTjg/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">其中，<strong><em>I&nbsp;</em></strong>是单位矩阵，<strong><em>y=Qw + b&nbsp;</em></strong>。为了简化讨论，这里我们只考虑寻找权重w最优值的情形（假设b是连续的）。将等式 <strong><em>y=Qw + b</em></strong> 带入上式并进行一定整理后，我们可以得到如下等式：</span></p> 
<p style="text-align: center;"><img class="rich_pages" data-ratio="0.226775956284153" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IdkRK7b6XGRpuy70LXoibSVOkpLUzSDiaCD2ibBYLKR4hJTMObkCslbW5g/640?wx_fmt=png" data-type="png" data-w="366" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IdkRK7b6XGRpuy70LXoibSVOkpLUzSDiaCD2ibBYLKR4hJTMObkCslbW5g/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">现在我们重新查看一下 <strong><em>g(α)</em></strong>， 我们会发现，如果我们使用点<strong><em>&nbsp;αk&nbsp;</em></strong>处的梯度，由于其为最优值，该梯度应当为0。因此我们有如下等式：</span></p> 
<p style="text-align: center;"><img class="rich_pages" data-ratio="0.1111111111111111" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IQ5NOQq5T4XUGHFAIFJm0zBg9DwurfNq3PiaIt5pV2VXbfZ7aroOUUwQ/640?wx_fmt=png" data-type="png" data-w="711" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1IQ5NOQq5T4XUGHFAIFJm0zBg9DwurfNq3PiaIt5pV2VXbfZ7aroOUUwQ/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">对上式进行简化，并将&nbsp;<strong><em>f</em></strong>&nbsp;的梯度带入后，我们可以得到对于<strong><em>&nbsp;αk&nbsp;</em></strong>的表示如下：</span></p> 
<p style="text-align: center;"><img class="rich_pages" data-ratio="0.25956284153005466" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1ICfasncuNUXfYhC1roaZbtDvGFFjS6tIdo1IhkpoAN0N6NCJficwiaNkg/640?wx_fmt=png" data-type="png" data-w="366" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1ICfasncuNUXfYhC1roaZbtDvGFFjS6tIdo1IhkpoAN0N6NCJficwiaNkg/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">这就是在二次函数</span><span style="color: rgb(63, 63, 63);font-size: 15px;letter-spacing: 1px;">情形下&nbsp;</span><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><strong><em>αk&nbsp;</em></strong></span><span style="color: rgb(63, 63, 63);font-size: 15px;letter-spacing: 1px;font-family: serif;">的值。</span></p> 
<p line="V9fy" style="white-space: normal;"><br></p> 
<ul class=" list-paddingleft-2" style="list-style-type: disc;"> 
 <li><p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;"><strong><span style="letter-spacing: 1px;color: rgb(63, 63, 63);">对二次函数的收敛性分析</span></strong><strong><span style="letter-spacing: 1px;color: rgb(63, 63, 63);"></span></strong></span></p></li> 
</ul> 
<p line="Jd6U" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">对于定义在 <strong><em>ℝ²</em></strong> 上的二次函数，最速下降法一般用来在非常接近最优值时使用，使用步数不超过十步。</span><span style="color: rgb(63, 63, 63);font-size: 15px;letter-spacing: 1px;font-family: serif;"></span></p> 
<p line="uXBC" style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.6649874055415617" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1Inar4JqIq2Eq4lKg1wdgC10Fxwiav78skxUlTupcUbicG4wGibEnHye71A/640?wx_fmt=png" data-type="png" data-w="397" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/BnSNEaficFAaMibIoUYV92nVh0Ss9FhK1Inar4JqIq2Eq4lKg1wdgC10Fxwiav78skxUlTupcUbicG4wGibEnHye71A/640?wx_fmt=png"></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: center;"><span style="letter-spacing: 1px;font-size: 12px;color: rgb(136, 136, 136);">二维中的最速下降在4次迭代后的情形</span></p> 
<p line="6e66" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">在上图中，每一次迭代中的改变方向都是垂直的。在3到4次迭代后，我们可以发现导数的变化基本可以忽略不计了。</span></p> 
<p line="FKcE" style="white-space: normal;"><br></p> 
<ul class=" list-paddingleft-2" style="list-style-type: disc;"> 
 <li><p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">为什么最速下降法应用很少？</span></strong><span style="letter-spacing: 1px;color: rgb(63, 63, 63);font-size: 15px;"><strong style="font-size: 12pt;"></strong></span></p></li> 
</ul> 
<p line="GtjI" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">最速下降法算法远远满足了超参数调优的需求，并且保证能找到局部最小值。但是为什么该算法应用不多呢？最速下降法的问题在于，每一步都需要对 aplha_k 进行优化，这样做的成本相对高昂。</span></p> 
<p line="Rzgh" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">例如，对于二次函数，每次迭代都需要计算多次矩阵乘法以及向量点乘。但对于梯度下降，每一步只需要计算导数并更新值就可以了，这样做的成本远远低于最速下降算法。</span></p> 
<p line="9ibZ" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">最速下降算法的另一个问题是对于非凸函数的优化存在困难。对于非凸函数，aplha_k 可能没有固定的值。</span></p> 
<p line="qPuN" style="white-space: normal;"><br></p> 
<p line="qPuN" style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.1625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4L8DRknQu3FB9eZicibvOSlVrgnllB3XcGnsrw4zCk19ic0QjZkTPoqFMWw/640?wx_fmt=png" data-type="png" data-w="160" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4L8DRknQu3FB9eZicibvOSlVrgnllB3XcGnsrw4zCk19ic0QjZkTPoqFMWw/640?wx_fmt=png"></p> 
<p style="text-align: center;"><span style="color: rgb(0, 0, 0);"><strong><span style="color: rgb(0, 0, 0);letter-spacing: 1px;font-size: 18px;">对于梯度下降法和最速下降法的对比</span></strong></span></p> 
<p line="6DPc" style="white-space: normal;"><br></p> 
<p line="6DPc" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">在这一部分，我们对梯度下降法和最速下降法进行对比，并比较它们在时间代价上的差异。首先，我们对比了两种算法的时间花销。我们会创建一个二次函数：<strong><em>f:ℝ²⁰⁰⁰→ℝ&nbsp;</em></strong>（该函数为一个2000x2000的矩阵）。我们将对该函数进行优化，并限制迭代次数为1000次。之后，我们会对两种算法的时间花销进行对比，并查看 x_n 值与最优点的距离。</span><span style="color: rgb(63, 63, 63);font-family: serif;font-size: 15px;letter-spacing: 1px;"></span></p> 
<p line="iy88" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">我们先来看一下最速下降法：</span></p> 
<p style="white-space: normal;"><br></p> 
<section class="code-snippet__fix code-snippet__js"> 
 <ul class="code-snippet__line-index code-snippet__js"> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
 </ul> 
 <pre class="code-snippet__js" data-lang="cs"><p style="margin-right: 8px;margin-left: 8px;line-height: 1.75em;"><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">0 Diff: 117727672.56583363 alpha value: 8.032725864804974e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">100 Diff: 9264.791000127792 alpha value: 1.0176428564615889e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">200 Diff: 1641.154644548893 alpha value: 1.0236993350903281e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">300 Diff: 590.5089467763901 alpha value: 1.0254560482036439e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">400 Diff: 279.2355946302414 alpha value: 1.0263893422517941e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">500 Diff: 155.43169915676117 alpha value: 1.0270028681773919e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">600 Diff: 96.61812579631805 alpha value: 1.0274280663010468e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">700 Diff: 64.87719237804413 alpha value: 1.027728512597358e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">800 Diff: 46.03102707862854 alpha value: 1.0279461929697766e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">900 Diff: 34.00975978374481 alpha value: 1.0281092917213468e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">Optimizer found with x = [-1.68825261 5.31853629 -3.45322318 ... 1.59365232 -2.85114689 5.04026352] and f(x)=-511573479.5792374 in 1000 iterations</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">Total time taken: 1min 28s</span></code></p></pre> 
</section> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><br></span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">下面是梯度下降法的情况，其中 alpha = 0.000001：</span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><br></span></p> 
<section class="code-snippet__fix code-snippet__js"> 
 <ul class="code-snippet__line-index code-snippet__js"> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
 </ul> 
 <pre class="code-snippet__js" data-lang="cs"><p style="margin-right: 8px;margin-left: 8px;line-height: 1.75em;"><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">0 Diff: 26206321.312622845 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">100 Diff: 112613.38076114655 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">200 Diff: 21639.659786581993 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">300 Diff: 7891.810685873032 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">400 Diff: 3793.90934664011 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">500 Diff: 2143.767760157585 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">600 Diff: 1348.4947955012321 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">700 Diff: 914.9099299907684 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">800 Diff: 655.9336211681366 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">900 Diff: 490.05882585048676 alpha value: 1e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">Optimizer found with x = [-1.80862488 4.66644055 -3.08228401 ... 2.46891076 -2.57581774 5.34672724] and f(x)=-511336392.26658595 in 1000 iterations</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">Total time taken: 1min 16s</span></code></p></pre> 
</section> 
<p line="5Fs4" class="ql-long-14573947" style="white-space: normal;"><br></p> 
<p style="white-space: normal;line-height: 1.75em;margin-left: 8px;margin-right: 8px;"><span style="font-size: 15px;color: rgb(63, 63, 63);letter-spacing: 1px;">我们可以发现，梯度下降法的速度比最速下降法略快（几秒或几分钟）。但更重要的是，最速下降法采取的步长比梯度下降法更加合理，尽管梯度下降法的α的值并非最优。在上述示例中， 对于梯度下降算法，</span><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><strong><em>f(xprex)</em></strong></span><span style="font-size: 15px;color: rgb(63, 63, 63);letter-spacing: 1px;">&nbsp;和</span><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"><strong><em>&nbsp;f(curr)</em></strong></span><span style="font-size: 15px;color: rgb(63, 63, 63);letter-spacing: 1px;"> 在第900次迭代时的差为450。而最速下降法在很多次迭代前就已经达到这个值了（大约在第300次到第400次迭代之间）。</span></p> 
<p line="fNaZ" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">因此，我们尝试限制最速下降法的迭代次数为300，输出如下：</span></p> 
<p style="white-space: normal;"><br></p> 
<section class="code-snippet__fix code-snippet__js"> 
 <ul class="code-snippet__line-index code-snippet__js"> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
  <li></li> 
 </ul> 
 <pre class="code-snippet__js" data-lang="cs"><p style="margin-right: 8px;margin-left: 8px;line-height: 1.75em;"><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">0 Diff: 118618752.30065191 alpha value: 8.569151292666038e-06 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">100 Diff: 8281.239207088947 alpha value: 1.1021416896567156e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">200 Diff: 1463.1741587519646 alpha value: 1.1087402059869253e-05 </span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">300 Diff: 526.3014997839928 alpha value: 1.1106776689082503e-05 Optimizer found with x = [-1.33362899 5.89337889 -3.31827817 ... 1.77032789 -2.86779156 4.56444743] and f(x)=-511526291.3367646 in 400 iterations</span></code><code><span class="code-snippet_outer" style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">Time taken: 35.8s</span></code></p></pre> 
</section> 
<p line="5Fs4" class="ql-long-14573947" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">可以发现，最速下降法的速度实际更快。在此情形中，我们在每次迭代使用更少的步数就能逼近最优值。事实上，如果你的目标是估计最优值，最速下降法会比梯度下降法更合适。对于低维度的函数，10步的最速下降法就会比经过1000次迭代的梯度下降法更接近最优值。</span></p> 
<p line="BE5D" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">下面这个例子中，我们使用了一个定义在&nbsp;<strong><em>ℝ³⁰→ℝ&nbsp;</em></strong>上的二次函数。10步后，最速下降法的得到函数值为 f(x) = -62434.18。而梯度下降法在1000步后得到的函数值为 f(x) = -61596.84。可以发现，最速下降法在10步后的结果就优于梯度下降法在1000步后的结果。</span><span style="font-family: serif;font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"></span></p> 
<p line="hiZz" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">需要记住的是，这种情形仅在处理二次函数的时候适用。整体而言，在每次迭代中都找到 αk的最优值是较为困难的。对函数 g(α) 求最优值并不总能得到 αk 的最优值。通常，我们会使用迭代的算法来对优化函数求最小值。在这种情形下，最速下降法与梯度下降法相比就比较慢了。因此，最速下降法在实际应用中并不常见。</span><span style="font-family: serif;font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);"></span></p> 
<p line="ljgj" style="white-space: normal;"><br></p> 
<p line="ljgj" style="white-space: normal;"><br></p> 
<p style="text-align: center;"><img class="rich_pages" data-copyright="0" data-ratio="0.1625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LFV97HltQYlNPKDzX97K1Ll0EicLrBIuWQtgLtQYdFKkkLcWKGUeMTfg/640?wx_fmt=png" data-type="png" data-w="160" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhSvZMAt2zKcxGQN3l1NV4LFV97HltQYlNPKDzX97K1Ll0EicLrBIuWQtgLtQYdFKkkLcWKGUeMTfg/640?wx_fmt=png"></p> 
<p style="text-align: center;"><span style="color: rgb(0, 0, 0);"><strong><span style="color: rgb(0, 0, 0);letter-spacing: 1px;font-size: 18px;">总结</span></strong></span></p> 
<p line="GZB0" style="white-space: normal;"><br></p> 
<p line="GZB0" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">在本文中，我们学习了三种下降算法：</span></p> 
<p line="STxU" style="white-space: normal;"><br></p> 
<ul class=" list-paddingleft-2" style="list-style-type: disc;"> 
 <li><p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">牛顿法（Newton's method）</span></strong></p></li> 
</ul> 
<p line="r5MC" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">牛顿法提供了对函数的二阶近似，并在每一步都对函数进行优化。其最大的问题在于，在优化过程中需要进行矩阵转换，对于多变量情形花销过高（尤其是向量的特征较多的时候）。</span></p> 
<p line="vJmj" style="white-space: normal;"><br></p> 
<ul class=" list-paddingleft-2" style="list-style-type: disc;"> 
 <li><p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">梯度下降（Gradient Descent）</span></strong></p></li> 
</ul> 
<p line="fCp4" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">梯度下降是最常用的优化算法。由于该算法在每步只对导数进行计算，其花销较低，速度更快。但是在使用该算法时，需要对步长的超参数进行多次的猜测和尝试。</span></p> 
<p line="wFry" style="white-space: normal;"><br></p> 
<ul class=" list-paddingleft-2" style="list-style-type: disc;"> 
 <li><p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><strong><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">最速下降法（Steepest Descent）</span></strong></p></li> 
</ul> 
<p line="yz4O" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(63, 63, 63);">最速下降法在每步都对函数的梯度向量寻找最优步长。它的问题在于，在每次迭代中需要对相关的函数进行优化，这会带来很多花销。对于二次函数的情形，尽管每步都涉及很多矩阵运算，最速下降法的效果仍然更优。</span></p> 
<p line="5Fs4" class="ql-long-14573947" style="white-space: normal;"><br></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;"><span style="font-size: 15px;letter-spacing: 1px;color: rgb(136, 136, 136);">相关笔记可参阅：</span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 14px;">https://colab.research.google.com/gist/nasirhemed/0026e5e6994d546b4debed8f1ed543c0/a-deeper-look-into-descent-algorithms.ipynb</span><span style="color: rgb(136, 136, 136);font-size: 15px;"></span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 14px;"><br></span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 14px;">原文链接：</span></p> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 14px;font-family: -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: justify;">https://towardsdatascience.com/a-deeper-look-at-descent-algorithms-13340b82db49</span></p> 
<hr style="border-style: solid;border-width: 1px 0 0;border-color: rgba(0,0,0,0.1);-webkit-transform-origin: 0 0;-webkit-transform: scale(1, 0.5);transform-origin: 0 0;transform: scale(1, 0.5);"> 
<p style="margin-right: 8px;margin-left: 8px;white-space: normal;line-height: 1.75em;text-align: left;"><span style="color: rgb(136, 136, 136);font-size: 14px;font-family: -apple-system-font, BlinkMacSystemFont, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: justify;"></span></p> 
<p style="text-align: center;margin-left: 8px;margin-right: 8px;"><img class="rich_pages" data-copyright="0" data-ratio="0.5482233502538071" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/Pn4Sm0RsAug39yByOmcISc1L0Exsb7CNugP5wV0jXZJO3A5phGZmodPk0Kic8270crj5QPOpzthxcuiaa8EhX8vg/640?wx_fmt=jpeg" data-type="jpeg" data-w="591" style="" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/Pn4Sm0RsAug39yByOmcISc1L0Exsb7CNugP5wV0jXZJO3A5phGZmodPk0Kic8270crj5QPOpzthxcuiaa8EhX8vg/640?wx_fmt=jpeg"></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;text-align: center;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">作为码一代，想教码二代却无从下手：</span><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;text-align: center;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">听说少儿编程很火，可它有哪些好处呢？</span></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;text-align: center;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">孩子多大开始学习比较好呢？又该如何学习呢？</span></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;text-align: center;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">最新的编程教育政策又有哪些呢？</span></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;text-align: center;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">下面给大家介绍CSDN新成员：<strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">极客宝宝（ID：</strong><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">geek_baby）</strong></span></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;letter-spacing: 1px;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;font-size: 14px;color: rgb(0, 82, 255);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">戳他了解更多↓↓↓</span></strong><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);text-align: center;line-height: 1.75em;letter-spacing: 1px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><img class="rich_pages " data-copyright="0" data-cropselx1="180" data-cropselx2="438" data-cropsely1="0" data-cropsely2="258" data-ratio="0.3697916666666667" data-s="300,640" data-type="jpeg" data-w="960" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/Pn4Sm0RsAuh1bcXNq238J3vRKyXya05vbbgCLnCbTPs0mGuVrLHntraYT5MIPrhkqQCmnqobLOf7nkWPh5j6vw/640?wx_fmt=jpeg" style="box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;visibility: visible !important;width: 618px !important;" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_jpg/Pn4Sm0RsAuh1bcXNq238J3vRKyXya05vbbgCLnCbTPs0mGuVrLHntraYT5MIPrhkqQCmnqobLOf7nkWPh5j6vw/640?wx_fmt=jpeg"></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);font-family: -apple-system-font, system-ui, &quot;Helvetica Neue&quot;, &quot;PingFang SC&quot;, &quot;Hiragino Sans GB&quot;, &quot;Microsoft YaHei UI&quot;, &quot;Microsoft YaHei&quot;, Arial, sans-serif;text-align: center;line-height: 1.75em;letter-spacing: 1px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(255, 255, 255);background-color: rgb(60, 142, 216);font-size: 15px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><strong style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">&nbsp;热 文</strong>&nbsp;推 荐&nbsp;</strong></span></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);line-height: normal;letter-spacing: 1px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650718835&amp;idx=3&amp;sn=58fe6c381a51b7072677c44895bff718&amp;chksm=bea6b3a089d13ab66f2f710a6fb5e08de192fe964c10584d448e0c157d5c9cccdd042d49221a&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="11" data-linktype="2" style="color: rgb(0, 82, 255);-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">☞&nbsp;</span></a><a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650718980&amp;idx=1&amp;sn=0e48c38d814b0c1b5652216b0370b708&amp;chksm=bea6b2d789d13bc15b6780455fd7abb538d6198cdeb757226a3e534bcb60e9a5216043af7028&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="0" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">华为效仿苹果卖高价手机？</span><span style="max-width: 100%;color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">滴滴顺风车开放灰度测试；</span><span style="max-width: 100%;color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">苹果官微被投诉“攻陷”| 极客头条</span></a></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);line-height: normal;letter-spacing: 1px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650718835&amp;idx=3&amp;sn=58fe6c381a51b7072677c44895bff718&amp;chksm=bea6b3a089d13ab66f2f710a6fb5e08de192fe964c10584d448e0c157d5c9cccdd042d49221a&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="11" data-linktype="2" style="color: rgb(0, 82, 255);-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">☞&nbsp;</span></a><a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650718980&amp;idx=3&amp;sn=a5214f24dc5662db55882f0592fbc715&amp;chksm=bea6b2d789d13bc1aeef4328662680485460797a773c5d8d6db3c306a36900b5594a66d47c87&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="11" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">Python 爬取吴亦凡的 10 万转发数据，扒一扒流量的真假！</span></a><br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);line-height: normal;letter-spacing: 1px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650718835&amp;idx=3&amp;sn=58fe6c381a51b7072677c44895bff718&amp;chksm=bea6b3a089d13ab66f2f710a6fb5e08de192fe964c10584d448e0c157d5c9cccdd042d49221a&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="11" data-linktype="2" style="color: rgb(0, 82, 255);-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">☞&nbsp;</span></a><a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650718980&amp;idx=4&amp;sn=482e337e17ef32626e02d615db3f200d&amp;chksm=bea6b2d789d13bc1f89145be3d60ef759e604d89f0a57ccb1a8576a85c490b020e5a19b3ca5a&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="0" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">优秀的程序员是如何诞生的？</span></a></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650718955&amp;idx=2&amp;sn=def54730ff2008d88598c03ebca00d18&amp;chksm=bea6b33889d13a2ec66fd04a862fd6801a303c052a586c3f09a4a1b3e5d1d391c5874db3b3dc&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="0" data-linktype="2" style="color: rgb(0, 82, 255);-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">☞</a>&nbsp;</span><a href="http://mp.weixin.qq.com/s?__biz=MjM5MjAwODM4MA==&amp;mid=2650718955&amp;idx=2&amp;sn=def54730ff2008d88598c03ebca00d18&amp;chksm=bea6b33889d13a2ec66fd04a862fd6801a303c052a586c3f09a4a1b3e5d1d391c5874db3b3dc&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="0" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">杨镭访谈：UCloud 的技术价值观</span></a></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=MzI0ODcxODk5OA==&amp;mid=2247504645&amp;idx=1&amp;sn=ab8306ee986e90fc2c806d598bec5482&amp;chksm=e99ee0fcdee969ea0bfb4815f18a7c00a38bfc22405a6aae4216fe89b67283ad9482a1ae5163&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="0" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;">☞ 普通人也能用AI拍出3D大片？这位清华博士后这么做</span></a></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=Mzg3MDA4NDkxMQ==&amp;mid=2247483894&amp;idx=1&amp;sn=65c6f6d62f2f3b8ef44dd01de9c72867&amp;chksm=ce9279b6f9e5f0a0e6a98a9794553cd708b0217d34c921d3e248f3cc8d0119d39e1627672ea7&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="11" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">☞ 码二代的出路是什么？</span></a></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=MzA5MzY4NTQwMA==&amp;mid=2651010496&amp;idx=3&amp;sn=1a45d882bbd6b067c939f43cfd34d6d4&amp;chksm=8bad8637bcda0f2167c451ee0196174587bda300949d7cb8354263812d012d2c5085c4354d28&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="11" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">☞ 小程序的侵权“生死局”</span></a></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=MzU2MTE1NDk2Mg==&amp;mid=2247494653&amp;idx=1&amp;sn=f8a0e8961bf7bc2a219bb4d2d65f88fd&amp;chksm=fc7fb500cb083c1644378d6e811c17126ebadaf1cae004dc39c8319858383cdda0880f8b0019&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="0" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">☞ 19岁当老板, 20岁ICO失败, 21岁将项目挂到了eBay, 为何初创公司如此艰难?</span></a></p> 
<p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;max-width: 100%;min-height: 1em;white-space: normal;background-color: rgb(255, 255, 255);letter-spacing: 1px;line-height: normal;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><a href="http://mp.weixin.qq.com/s?__biz=MzA5MjcxNjc2Ng==&amp;mid=2650559816&amp;idx=1&amp;sn=380cfd3d18fb987c0073bf1b8289155a&amp;chksm=88601ef9bf1797ef9e671113fdeed0dac0e1750691de9c6a594dd46706f72aeafa9028b57fe5&amp;scene=21#wechat_redirect" target="_blank" data-itemshowtype="0" data-linktype="2" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;"><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">☞ 她说：</span><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">为啥程序员都特想要机械键盘？</span><span style="max-width: 100%;-webkit-tap-highlight-color: rgba(0, 0, 0, 0);color: rgb(0, 82, 255);font-size: 14px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">这答案我服！</span></a></p> 
<p style="max-width: 100%;min-height: 1em;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;"><br></p> 
<section style="max-width: 100%;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
 <section class="" style="max-width: 100%;font-size: 16px;color: rgb(62, 62, 62);line-height: 1.6;letter-spacing: 0px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
  <pre style="max-width: 100%;font-size: inherit;color: inherit;line-height: inherit;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><p style="margin-right: 8px;margin-bottom: 15px;margin-left: 8px;padding: 0.5em;max-width: 100%;min-height: 1em;font-size: 14px;font-family: Consolas, Inconsolata, Courier, monospace;border-radius: 0px;background: rgb(34, 34, 34);color: rgb(170, 170, 170);line-height: 1.75em;letter-spacing: 1px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: normal !important;word-break: normal !important;overflow: auto !important;">System.out.println(<span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">"点个在看吧！"</span>);<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">console.log(<span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">"点个<span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">在</span>看吧！"</span>);<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(50, 170, 238);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">print</span>(<span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">"点个<span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">在</span>看吧！"</span>);<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(50, 170, 238);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">printf</span>(<span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">"点个<span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">在</span>看吧！\n"</span>);<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">cout&nbsp;&lt;&lt;&nbsp;<span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">"点个<span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">在</span>看吧！"</span>&nbsp;&lt;&lt;&nbsp;endl;<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">Console.WriteLine(<span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">"点个<span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">在</span>看吧！"</span>);<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">Response.Write(<span class="" style="max-width: 100%;font-size: inherit;line-height: inherit;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">"点个<span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">在</span>看吧！"</span>);<br style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span style="max-width: 100%;font-variant-numeric: normal;line-height: 24.5px;widows: 1;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">alert(</span><span style="max-width: 100%;font-variant-numeric: normal;line-height: 24.5px;widows: 1;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">"点个<span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">在</span>看吧！"</span><span style="max-width: 100%;font-variant-numeric: normal;line-height: 24.5px;widows: 1;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">)</span><br style="max-width: 100%;font-variant-numeric: normal;line-height: 24.5px;widows: 1;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"><span class="" style="max-width: 100%;font-size: inherit;font-variant-numeric: normal;line-height: inherit;widows: 1;color: rgb(50, 170, 238);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: inherit !important;word-break: inherit !important;">echo </span><span style="max-width: 100%;font-variant-numeric: normal;line-height: 24.5px;widows: 1;color: rgb(255, 204, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">"点个<span style="max-width: 100%;box-sizing: border-box !important;word-wrap: break-word !important;">在</span>看吧！"</span></p></pre> 
 </section> 
</section> 
<section class="" data-tools="135编辑器" data-id="94250" style="max-width: 100%;box-sizing: border-box;letter-spacing: 0.544px;white-space: normal;background-color: rgb(255, 255, 255);border-width: 0px;border-style: none;border-color: initial;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
 <section class="" data-tools="135编辑器" data-id="91842" style="max-width: 100%;box-sizing: border-box;border-width: 0px;border-style: none;border-color: initial;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
  <section style="max-width: 100%;text-align: right;width: auto;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
   <section style="max-width: 100%;display: inline-block;clear: both;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
    <section class="" data-brushtype="text" style="padding: 18px 15px 20px 10px;max-width: 100%;box-sizing: border-box;color: rgb(86, 146, 214);background-image: url(&quot;https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhpplm16ibb8iaib7RoGQ5iaHEdy66AHd7QqL7A2s5icSBE0aw4iaKOKPnXGYxQPhG7VMpbbYV6VJprSh7w/640?wx_fmt=png&quot;);background-repeat: no-repeat;text-align: center;background-size: 100% 100%;font-size: 16px;letter-spacing: 1.5px;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
     <section style="max-width: 100%;display: flex;justify-content: center;align-items: center;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
      <section style="margin-left: 2px;max-width: 100%;width: 20px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
       <img class="" data-ratio="0.8936170212765957" data-type="png" data-w="47" data-src="https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhpplm16ibb8iaib7RoGQ5iaHEdvAd0o9e1LlUGA2k0Yib222agOxzweXhahA9GuzJcGBg0dA4DzlibxRqw/640?wx_fmt=png" style="margin-bottom: -6px;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;visibility: visible !important;width: 20px !important;" src="https://uzshare.com/_p?https://mmbiz.qpic.cn/mmbiz_png/Pn4Sm0RsAuhpplm16ibb8iaib7RoGQ5iaHEdvAd0o9e1LlUGA2k0Yib222agOxzweXhahA9GuzJcGBg0dA4DzlibxRqw/640?wx_fmt=png"> 
      </section> 
      <section class="" data-brushtype="text" style="max-width: 100%;font-size: 14px;color: rgb(51, 51, 51);box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;"> 
       <span style="max-width: 100%;font-family: 楷体, 楷体_GB2312, SimKai;box-sizing: border-box !important;word-wrap: break-word !important;overflow-wrap: break-word !important;">你点的每个“在看”，我都认真当成了喜欢</span> 
      </section> 
     </section> 
    </section> 
   </section> 
  </section> 
 </section> 
</section>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
