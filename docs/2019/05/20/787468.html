<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Hadoop学习——–hadoop基础以及完全分布式的搭建 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Hadoop学习——–hadoop基础以及完全分布式的搭建" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="关注与Hadoop解决的问题 Hadoop是Apache专为离线和大规模数据分析而设计的开源软件，是可靠的、分布式的、可伸缩的 Hadoop主要就就是解决存储和计算两个问题（分布式存储和分布式计算）个人理解应该是基于庞大的简便的扩容机制，众多的slave节点同时处理数据。 centos系统下搭建Hadoop完全分布式模式： &nbsp; 1. 启动4台虚拟机，修改主机名分别为centos00,.centos01,centos02,centso03,并且在centos00中配置hosts，分别将centos01，centos02,centos03添加到hosts文件中 其中centos00配为NN(nameNode)3台DN(dataNode) &nbsp;&nbsp;2 配置centos00与其它机的无密登陆，在centos0上生成公私密钥对&nbsp; &nbsp; 首先查看虚拟机有没有sshd守护进程，存在然后执行生成命令 [mc@centos00 /home/mc/.ssh]$ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa &nbsp; 3.执行命令将生成两个密钥文件分别为私钥存于服务器，pub公钥追加到authorized_keys文件并分发到其它机器 [mc@centos00 /home/mc/.ssh]$cat id_rsa.pub &gt;&gt; authorized_keys 4.通过scp 或者 rsync 命令将authorized_keys分别分发到到centos01 02 03的~/.ssh目录下、通过SSH 主机名 连接测试是否成功，（无需输入密码） （备注，如果没成功 需要查看你authorized_keys的权限是否为644，如果不是请将权限改为644 chmod 644 authorized_keys） 5.配置成功之后开始安装Hadoop,去官网下载tar.gz安装包，地址--Hadoop下载地址,点击Binary download，另hadoop需要jdk环境所以保证所有机器都安装有JDK,并配置好全局 6.创建目录 /soft 用于存放Hadoop,下载完成安装包，执行解压命令 [mc@centos00 /soft]$tar -zxvf hadoop-2.7.2.tar.gz /soft/ 7。创建Hadoop软连接&nbsp; [mc@centos00 /soft]$ln -s /soft/hadoop-2.7.2 hadoop 8.编写/etc/profile 配置Hadoop环境变量，执行 hadoop version 显示版本信息为成功 9.Hadoop几大组建 common&nbsp; HDFS MR(mapReduce)&nbsp; yarn 因此要配置几个模块的配置文件 在/soft/hadoop/etc/下分别为core-site.xml。hdfs-site.xml，mapred-site.xml（从template复制一份出来），yarn-site.xml a)编辑core-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://centos00/&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; b)编辑hdfs-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; c)编辑mapred-site.xml 注意:cp mapred-site.xml.template mapred-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; d)编辑yarn-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;centos00&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 10.配置完成之后 将整个soft文件分别分发到centos01 centos02 centos03上 (这里必须要用rsync命令，因为有软连接) [mc@centos00 /$rsync -avzl soft mc@centos01:/ 11 配置完之后，配置hadoop中数据节点，编辑/soft/hadoop/etc/hadoop/slaves 文件 将其它数据节点主机名称写入 12。基本配置就完成了，在启动hadoop之前，先格式化名称节点 [mc@centos00 /$hadoop namenode -format 13。启动所有j进程（或者单独使用start-dfs.sh + start-yarn.sh） [mc@centos00 /$start-all.sh &nbsp;14。查看进程 可以编写简易shell脚本查询 #!/bin/bash param=$@ host=0 for(( host = 0 ;host &lt;= 3 ; host = $host +1 )); do echo ======centos0$host $param======= ssh centos0$host $param done; 15. 执行到这，就算搭建完成了。 过程中如果遇到问题，首先查看权限 以及用户 问题。启动时遇到问题去查看hadoop问下下log日志，启动信息以及错误信息都在日志中有体现 16。web页面验证 访问50070端口 查看是否安装成功（注意防火墙端口限制） 8020是对外的端口 17 查看dataNodes 是否成功连接 admin state状态为In Service则成功（Decommissioned是做了节点退役）Last contact表示心跳检测，数值一般在0-3 大于3则为超时。 &nbsp;" />
<meta property="og:description" content="关注与Hadoop解决的问题 Hadoop是Apache专为离线和大规模数据分析而设计的开源软件，是可靠的、分布式的、可伸缩的 Hadoop主要就就是解决存储和计算两个问题（分布式存储和分布式计算）个人理解应该是基于庞大的简便的扩容机制，众多的slave节点同时处理数据。 centos系统下搭建Hadoop完全分布式模式： &nbsp; 1. 启动4台虚拟机，修改主机名分别为centos00,.centos01,centos02,centso03,并且在centos00中配置hosts，分别将centos01，centos02,centos03添加到hosts文件中 其中centos00配为NN(nameNode)3台DN(dataNode) &nbsp;&nbsp;2 配置centos00与其它机的无密登陆，在centos0上生成公私密钥对&nbsp; &nbsp; 首先查看虚拟机有没有sshd守护进程，存在然后执行生成命令 [mc@centos00 /home/mc/.ssh]$ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa &nbsp; 3.执行命令将生成两个密钥文件分别为私钥存于服务器，pub公钥追加到authorized_keys文件并分发到其它机器 [mc@centos00 /home/mc/.ssh]$cat id_rsa.pub &gt;&gt; authorized_keys 4.通过scp 或者 rsync 命令将authorized_keys分别分发到到centos01 02 03的~/.ssh目录下、通过SSH 主机名 连接测试是否成功，（无需输入密码） （备注，如果没成功 需要查看你authorized_keys的权限是否为644，如果不是请将权限改为644 chmod 644 authorized_keys） 5.配置成功之后开始安装Hadoop,去官网下载tar.gz安装包，地址--Hadoop下载地址,点击Binary download，另hadoop需要jdk环境所以保证所有机器都安装有JDK,并配置好全局 6.创建目录 /soft 用于存放Hadoop,下载完成安装包，执行解压命令 [mc@centos00 /soft]$tar -zxvf hadoop-2.7.2.tar.gz /soft/ 7。创建Hadoop软连接&nbsp; [mc@centos00 /soft]$ln -s /soft/hadoop-2.7.2 hadoop 8.编写/etc/profile 配置Hadoop环境变量，执行 hadoop version 显示版本信息为成功 9.Hadoop几大组建 common&nbsp; HDFS MR(mapReduce)&nbsp; yarn 因此要配置几个模块的配置文件 在/soft/hadoop/etc/下分别为core-site.xml。hdfs-site.xml，mapred-site.xml（从template复制一份出来），yarn-site.xml a)编辑core-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://centos00/&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; b)编辑hdfs-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; c)编辑mapred-site.xml 注意:cp mapred-site.xml.template mapred-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; d)编辑yarn-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;centos00&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 10.配置完成之后 将整个soft文件分别分发到centos01 centos02 centos03上 (这里必须要用rsync命令，因为有软连接) [mc@centos00 /$rsync -avzl soft mc@centos01:/ 11 配置完之后，配置hadoop中数据节点，编辑/soft/hadoop/etc/hadoop/slaves 文件 将其它数据节点主机名称写入 12。基本配置就完成了，在启动hadoop之前，先格式化名称节点 [mc@centos00 /$hadoop namenode -format 13。启动所有j进程（或者单独使用start-dfs.sh + start-yarn.sh） [mc@centos00 /$start-all.sh &nbsp;14。查看进程 可以编写简易shell脚本查询 #!/bin/bash param=$@ host=0 for(( host = 0 ;host &lt;= 3 ; host = $host +1 )); do echo ======centos0$host $param======= ssh centos0$host $param done; 15. 执行到这，就算搭建完成了。 过程中如果遇到问题，首先查看权限 以及用户 问题。启动时遇到问题去查看hadoop问下下log日志，启动信息以及错误信息都在日志中有体现 16。web页面验证 访问50070端口 查看是否安装成功（注意防火墙端口限制） 8020是对外的端口 17 查看dataNodes 是否成功连接 admin state状态为In Service则成功（Decommissioned是做了节点退役）Last contact表示心跳检测，数值一般在0-3 大于3则为超时。 &nbsp;" />
<link rel="canonical" href="https://mlh.app/2019/05/20/787468.html" />
<meta property="og:url" content="https://mlh.app/2019/05/20/787468.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-20T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"关注与Hadoop解决的问题 Hadoop是Apache专为离线和大规模数据分析而设计的开源软件，是可靠的、分布式的、可伸缩的 Hadoop主要就就是解决存储和计算两个问题（分布式存储和分布式计算）个人理解应该是基于庞大的简便的扩容机制，众多的slave节点同时处理数据。 centos系统下搭建Hadoop完全分布式模式： &nbsp; 1. 启动4台虚拟机，修改主机名分别为centos00,.centos01,centos02,centso03,并且在centos00中配置hosts，分别将centos01，centos02,centos03添加到hosts文件中 其中centos00配为NN(nameNode)3台DN(dataNode) &nbsp;&nbsp;2 配置centos00与其它机的无密登陆，在centos0上生成公私密钥对&nbsp; &nbsp; 首先查看虚拟机有没有sshd守护进程，存在然后执行生成命令 [mc@centos00 /home/mc/.ssh]$ssh-keygen -t rsa -P &#39;&#39; -f ~/.ssh/id_rsa &nbsp; 3.执行命令将生成两个密钥文件分别为私钥存于服务器，pub公钥追加到authorized_keys文件并分发到其它机器 [mc@centos00 /home/mc/.ssh]$cat id_rsa.pub &gt;&gt; authorized_keys 4.通过scp 或者 rsync 命令将authorized_keys分别分发到到centos01 02 03的~/.ssh目录下、通过SSH 主机名 连接测试是否成功，（无需输入密码） （备注，如果没成功 需要查看你authorized_keys的权限是否为644，如果不是请将权限改为644 chmod 644 authorized_keys） 5.配置成功之后开始安装Hadoop,去官网下载tar.gz安装包，地址--Hadoop下载地址,点击Binary download，另hadoop需要jdk环境所以保证所有机器都安装有JDK,并配置好全局 6.创建目录 /soft 用于存放Hadoop,下载完成安装包，执行解压命令 [mc@centos00 /soft]$tar -zxvf hadoop-2.7.2.tar.gz /soft/ 7。创建Hadoop软连接&nbsp; [mc@centos00 /soft]$ln -s /soft/hadoop-2.7.2 hadoop 8.编写/etc/profile 配置Hadoop环境变量，执行 hadoop version 显示版本信息为成功 9.Hadoop几大组建 common&nbsp; HDFS MR(mapReduce)&nbsp; yarn 因此要配置几个模块的配置文件 在/soft/hadoop/etc/下分别为core-site.xml。hdfs-site.xml，mapred-site.xml（从template复制一份出来），yarn-site.xml a)编辑core-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://centos00/&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; b)编辑hdfs-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; c)编辑mapred-site.xml 注意:cp mapred-site.xml.template mapred-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; d)编辑yarn-site.xml &lt;?xml version=&quot;1.0&quot;?&gt; &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;centos00&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 10.配置完成之后 将整个soft文件分别分发到centos01 centos02 centos03上 (这里必须要用rsync命令，因为有软连接) [mc@centos00 /$rsync -avzl soft mc@centos01:/ 11 配置完之后，配置hadoop中数据节点，编辑/soft/hadoop/etc/hadoop/slaves 文件 将其它数据节点主机名称写入 12。基本配置就完成了，在启动hadoop之前，先格式化名称节点 [mc@centos00 /$hadoop namenode -format 13。启动所有j进程（或者单独使用start-dfs.sh + start-yarn.sh） [mc@centos00 /$start-all.sh &nbsp;14。查看进程 可以编写简易shell脚本查询 #!/bin/bash param=$@ host=0 for(( host = 0 ;host &lt;= 3 ; host = $host +1 )); do echo ======centos0$host $param======= ssh centos0$host $param done; 15. 执行到这，就算搭建完成了。 过程中如果遇到问题，首先查看权限 以及用户 问题。启动时遇到问题去查看hadoop问下下log日志，启动信息以及错误信息都在日志中有体现 16。web页面验证 访问50070端口 查看是否安装成功（注意防火墙端口限制） 8020是对外的端口 17 查看dataNodes 是否成功连接 admin state状态为In Service则成功（Decommissioned是做了节点退役）Last contact表示心跳检测，数值一般在0-3 大于3则为超时。 &nbsp;","@type":"BlogPosting","url":"https://mlh.app/2019/05/20/787468.html","headline":"Hadoop学习——–hadoop基础以及完全分布式的搭建","dateModified":"2019-05-20T00:00:00+08:00","datePublished":"2019-05-20T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/20/787468.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Hadoop学习--------hadoop基础以及完全分布式的搭建</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h2>关注与Hadoop解决的问题</h2> 
  <p>Hadoop是Apache专为离线和大规模数据分析而设计的开源软件，是可靠的、分布式的、可伸缩的</p> 
  <p>Hadoop主要就就是解决存储和计算两个问题（分布式存储和分布式计算）个人理解应该是基于庞大的简便的扩容机制，众多的slave节点同时处理数据。</p> 
  <h2>centos系统下搭建Hadoop完全分布式模式：</h2> 
  <p>&nbsp; 1. 启动4台虚拟机，修改主机名分别为centos00,.centos01,centos02,centso03,并且在centos00中配置hosts，分别将centos01，centos02,centos03添加到hosts文件中</p> 
  <p>其中centos00配为NN(nameNode)3台DN(dataNode)</p> 
  <p><img alt="" class="has" height="127" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520173045867.png" width="364"></p> 
  <p>&nbsp;&nbsp;2 配置centos00与其它机的无密登陆，在centos0上生成公私密钥对&nbsp;</p> 
  <p>&nbsp; 首先查看虚拟机有没有sshd守护进程，存在然后执行生成命令</p> 
  <p><img alt="" class="has" height="77" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520180203271.png" width="507"></p> 
  <pre class="has">
<code>[mc@centos00 /home/mc/.ssh]$ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa</code></pre> 
  <p>&nbsp; 3.执行命令将生成两个密钥文件分别为私钥存于服务器，pub公钥追加到authorized_keys文件并分发到其它机器</p> 
  <p><img alt="" class="has" height="40" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520171549386.png" width="428"></p> 
  <pre class="has">
<code>[mc@centos00 /home/mc/.ssh]$cat id_rsa.pub &gt;&gt; authorized_keys</code></pre> 
  <p>4.通过scp 或者 rsync 命令将authorized_keys分别分发到到centos01 02 03的~/.ssh目录下、通过SSH 主机名 连接测试是否成功，（无需输入密码）</p> 
  <p><img alt="" class="has" height="229" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520172812335.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RveGljX2d1YW50b3U=,size_16,color_FFFFFF,t_70" width="650"></p> 
  <p>（<u>备注，如果没成功 需要查看你authorized_keys的权限是否为644，如果不是请将权限改为644</u></p> 
  <p><u>chmod 644 authorized_key</u>s）</p> 
  <p>5.配置成功之后开始安装Hadoop,去官网下载tar.gz安装包，地址--<a href="https://hadoop.apache.org/releases.html" rel="nofollow">Hadoop下载地址</a>,点击Binary download，<u>另hadoop需要jdk环境所以保证所有机器都安装有JDK,并配置好全局</u></p> 
  <p>6.创建目录 /soft 用于存放Hadoop,下载完成安装包，执行解压命令</p> 
  <pre class="has">
<code>[mc@centos00 /soft]$tar -zxvf hadoop-2.7.2.tar.gz /soft/</code></pre> 
  <p>7。创建Hadoop软连接&nbsp;</p> 
  <pre class="has">
<code>[mc@centos00 /soft]$ln -s /soft/hadoop-2.7.2  hadoop</code></pre> 
  <p>8.编写/etc/profile 配置Hadoop环境变量，执行 hadoop version 显示版本信息为成功</p> 
  <p><img alt="" class="has" height="167" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520174456454.png" width="438"></p> 
  <p>9.Hadoop几大组建 common&nbsp; HDFS MR(mapReduce)&nbsp; yarn 因此要配置几个模块的配置文件 在/soft/hadoop/etc/下分别为core-site.xml。hdfs-site.xml，mapred-site.xml（从template复制一份出来），yarn-site.xml</p> 
  <pre class="has">
<code class="language-html">a)编辑core-site.xml
	&lt;?xml version="1.0"?&gt;
	&lt;configuration&gt;
		&lt;property&gt;
			&lt;name&gt;fs.defaultFS&lt;/name&gt;
			&lt;value&gt;hdfs://centos00/&lt;/value&gt;
		&lt;/property&gt;
	&lt;/configuration&gt;
b)编辑hdfs-site.xml
	&lt;?xml version="1.0"?&gt;
	&lt;configuration&gt;
		&lt;property&gt;
			&lt;name&gt;dfs.replication&lt;/name&gt;
			&lt;value&gt;3&lt;/value&gt;
		&lt;/property&gt;
	&lt;/configuration&gt;
c)编辑mapred-site.xml
	注意:cp mapred-site.xml.template mapred-site.xml
	&lt;?xml version="1.0"?&gt;
	&lt;configuration&gt;
		&lt;property&gt;
			&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
			&lt;value&gt;yarn&lt;/value&gt;
		&lt;/property&gt;
	&lt;/configuration&gt;
d)编辑yarn-site.xml
	&lt;?xml version="1.0"?&gt;
	&lt;configuration&gt;
		&lt;property&gt;
			&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
			&lt;value&gt;centos00&lt;/value&gt;
		&lt;/property&gt;
		&lt;property&gt;
			&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
			&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
		&lt;/property&gt;
	&lt;/configuration&gt;
</code></pre> 
  <p>10.配置完成之后 将整个soft文件分别分发到centos01 centos02 centos03上 (这里必须要用rsync命令，因为有软连接)</p> 
  <pre class="has">
<code>[mc@centos00 /$rsync -avzl soft mc@centos01:/
</code></pre> 
  <p>11 配置完之后，配置hadoop中数据节点，编辑/soft/hadoop/etc/hadoop/slaves 文件 将其它数据节点主机名称写入</p> 
  <p><img alt="" class="has" height="73" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520175948596.png" width="380"><br> 12。基本配置就完成了，在启动hadoop之前，先格式化名称节点</p> 
  <pre class="has">
<code>[mc@centos00 /$hadoop namenode -format
</code></pre> 
  <p>13。启动所有j进程（或者单独使用start-dfs.sh + start-yarn.sh）</p> 
  <pre class="has">
<code>[mc@centos00 /$start-all.sh</code></pre> 
  <p>&nbsp;14。查看进程 可以编写简易shell脚本查询</p> 
  <pre class="has">
<code>#!/bin/bash

param=$@
host=0
for(( host = 0 ;host &lt;= 3 ; host = $host +1 ));
do 
echo ======centos0$host $param=======
	ssh centos0$host  $param
done;
</code></pre> 
  <p><img alt="" class="has" height="221" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520180739278.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RveGljX2d1YW50b3U=,size_16,color_FFFFFF,t_70" width="362"></p> 
  <p>15. 执行到这，就算搭建完成了。</p> 
  <p><u>过程中如果遇到问题，首先查看权限 以及用户 问题。启动时遇到问题去查看hadoop问下下log日志，启动信息以及错误信息都在日志中有体现</u></p> 
  <p>16。web页面验证 访问50070端口 查看是否安装成功（注意防火墙端口限制） 8020是对外的端口</p> 
  <p><img alt="" class="has" height="971" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520181015729.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RveGljX2d1YW50b3U=,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p>17 查看dataNodes 是否成功连接 admin state状态为In Service则成功（Decommissioned是做了节点退役）Last contact表示心跳检测，数值一般在0-3 大于3则为超时。</p> 
  <p><img alt="" class="has" height="538" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190520181155606.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RveGljX2d1YW50b3U=,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
