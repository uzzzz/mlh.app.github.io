<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>PyTorch实现多层网络 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="PyTorch实现多层网络" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="用PyTorch实现多层网络(给代码截图参考) 引入模块，读取数据 构建计算图（构建网络模型） 损失函数与优化器 开始训练模型 对训练的模型预测结果进行评估 引入模块 import torch import numpy as np from torch import nn from torch.autograd import Variable import torch.nn.functional as F import matplotlib.pyplot as plt import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler %matplotlib inline 数据转化为tensor x_train_tensor=torch.from_numpy(x_train) x_test_tensor=torch.from_numpy(x_test) y_train_numpy=np.array(y_train) y_train_tensor=torch.from_numpy(y_train_numpy) y_test_numpy=np.array(y_test) y_test_tensor=torch.from_numpy(y_test_numpy) x=x_train_tensor.float() y=y_train_tensor.float() 构建网络模型 构建一个六层的网络 class module_net(nn.Module): def __init__(self, num_input, num_hidden, num_output): super(module_net, self).__init__() self.layer1 = nn.Linear(num_input, num_hidden) self.layer2 = nn.Tanh() self.layer3 = nn.Linear(num_hidden, num_hidden) self.layer4 = nn.Tanh() self.layer5 = nn.Linear(num_hidden, num_hidden) self.layer6 = nn.Tanh() def forward(self, x): x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.layer5(x) x = self.layer6(x) return x 损失函数与优化器 criterion=nn.BCEWithLogitsLoss() mo_net = module_net(8, 10, 1) optim = torch.optim.SGD(mo_net.parameters(), 0.01, momentum=0.9) 模型训练 Loss_list = [] #用来装loss值，以便之后画图 Accuracy_list = [] #用来装准确率，以便之后画图 for e in range(10000): out = mo_net.forward(Variable(x)) #这里省略了 mo_net.forward() loss = criterion(out, Variable(y)) Loss_list.append(loss.data[0]) #--------------------用于求准确率-------------------------# out_class=(out[:]&gt;0).float() #将out矩阵中大于0的转化为1，小于0的转化为0，存入a中 right_num=torch.sum(y==out_class).float() #分类对的数值 precision=right_num/out.shape[0] #准确率 #--------------------求准确率结束-------------------------# Accuracy_list.append(precision) optim.zero_grad() loss.backward() optim.step() if (e + 1) % 1000 == 0: print(&#39;epoch: {}, loss: {}，precision{},right_num{}&#39;.format(e+1, loss.data[0],precision,right_num)) plt.plot(x1, Loss_list,c=&#39;red&#39;,label=&#39;loss&#39;) plt.plot(x1, Accuracy_list,c=&#39;blue&#39;,label=&#39;precision&#39;) plt.legend() 结果：" />
<meta property="og:description" content="用PyTorch实现多层网络(给代码截图参考) 引入模块，读取数据 构建计算图（构建网络模型） 损失函数与优化器 开始训练模型 对训练的模型预测结果进行评估 引入模块 import torch import numpy as np from torch import nn from torch.autograd import Variable import torch.nn.functional as F import matplotlib.pyplot as plt import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler %matplotlib inline 数据转化为tensor x_train_tensor=torch.from_numpy(x_train) x_test_tensor=torch.from_numpy(x_test) y_train_numpy=np.array(y_train) y_train_tensor=torch.from_numpy(y_train_numpy) y_test_numpy=np.array(y_test) y_test_tensor=torch.from_numpy(y_test_numpy) x=x_train_tensor.float() y=y_train_tensor.float() 构建网络模型 构建一个六层的网络 class module_net(nn.Module): def __init__(self, num_input, num_hidden, num_output): super(module_net, self).__init__() self.layer1 = nn.Linear(num_input, num_hidden) self.layer2 = nn.Tanh() self.layer3 = nn.Linear(num_hidden, num_hidden) self.layer4 = nn.Tanh() self.layer5 = nn.Linear(num_hidden, num_hidden) self.layer6 = nn.Tanh() def forward(self, x): x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.layer5(x) x = self.layer6(x) return x 损失函数与优化器 criterion=nn.BCEWithLogitsLoss() mo_net = module_net(8, 10, 1) optim = torch.optim.SGD(mo_net.parameters(), 0.01, momentum=0.9) 模型训练 Loss_list = [] #用来装loss值，以便之后画图 Accuracy_list = [] #用来装准确率，以便之后画图 for e in range(10000): out = mo_net.forward(Variable(x)) #这里省略了 mo_net.forward() loss = criterion(out, Variable(y)) Loss_list.append(loss.data[0]) #--------------------用于求准确率-------------------------# out_class=(out[:]&gt;0).float() #将out矩阵中大于0的转化为1，小于0的转化为0，存入a中 right_num=torch.sum(y==out_class).float() #分类对的数值 precision=right_num/out.shape[0] #准确率 #--------------------求准确率结束-------------------------# Accuracy_list.append(precision) optim.zero_grad() loss.backward() optim.step() if (e + 1) % 1000 == 0: print(&#39;epoch: {}, loss: {}，precision{},right_num{}&#39;.format(e+1, loss.data[0],precision,right_num)) plt.plot(x1, Loss_list,c=&#39;red&#39;,label=&#39;loss&#39;) plt.plot(x1, Accuracy_list,c=&#39;blue&#39;,label=&#39;precision&#39;) plt.legend() 结果：" />
<link rel="canonical" href="https://mlh.app/2019/05/19/787208.html" />
<meta property="og:url" content="https://mlh.app/2019/05/19/787208.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-19T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"用PyTorch实现多层网络(给代码截图参考) 引入模块，读取数据 构建计算图（构建网络模型） 损失函数与优化器 开始训练模型 对训练的模型预测结果进行评估 引入模块 import torch import numpy as np from torch import nn from torch.autograd import Variable import torch.nn.functional as F import matplotlib.pyplot as plt import pandas as pd from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler %matplotlib inline 数据转化为tensor x_train_tensor=torch.from_numpy(x_train) x_test_tensor=torch.from_numpy(x_test) y_train_numpy=np.array(y_train) y_train_tensor=torch.from_numpy(y_train_numpy) y_test_numpy=np.array(y_test) y_test_tensor=torch.from_numpy(y_test_numpy) x=x_train_tensor.float() y=y_train_tensor.float() 构建网络模型 构建一个六层的网络 class module_net(nn.Module): def __init__(self, num_input, num_hidden, num_output): super(module_net, self).__init__() self.layer1 = nn.Linear(num_input, num_hidden) self.layer2 = nn.Tanh() self.layer3 = nn.Linear(num_hidden, num_hidden) self.layer4 = nn.Tanh() self.layer5 = nn.Linear(num_hidden, num_hidden) self.layer6 = nn.Tanh() def forward(self, x): x = self.layer1(x) x = self.layer2(x) x = self.layer3(x) x = self.layer4(x) x = self.layer5(x) x = self.layer6(x) return x 损失函数与优化器 criterion=nn.BCEWithLogitsLoss() mo_net = module_net(8, 10, 1) optim = torch.optim.SGD(mo_net.parameters(), 0.01, momentum=0.9) 模型训练 Loss_list = [] #用来装loss值，以便之后画图 Accuracy_list = [] #用来装准确率，以便之后画图 for e in range(10000): out = mo_net.forward(Variable(x)) #这里省略了 mo_net.forward() loss = criterion(out, Variable(y)) Loss_list.append(loss.data[0]) #--------------------用于求准确率-------------------------# out_class=(out[:]&gt;0).float() #将out矩阵中大于0的转化为1，小于0的转化为0，存入a中 right_num=torch.sum(y==out_class).float() #分类对的数值 precision=right_num/out.shape[0] #准确率 #--------------------求准确率结束-------------------------# Accuracy_list.append(precision) optim.zero_grad() loss.backward() optim.step() if (e + 1) % 1000 == 0: print(&#39;epoch: {}, loss: {}，precision{},right_num{}&#39;.format(e+1, loss.data[0],precision,right_num)) plt.plot(x1, Loss_list,c=&#39;red&#39;,label=&#39;loss&#39;) plt.plot(x1, Accuracy_list,c=&#39;blue&#39;,label=&#39;precision&#39;) plt.legend() 结果：","@type":"BlogPosting","url":"https://mlh.app/2019/05/19/787208.html","headline":"PyTorch实现多层网络","dateModified":"2019-05-19T00:00:00+08:00","datePublished":"2019-05-19T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/19/787208.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>PyTorch实现多层网络</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h1><a id="PyTorch_0"></a>用PyTorch实现多层网络(给代码截图参考)</h1> 
  <ol> 
   <li>引入模块，读取数据</li> 
   <li>构建计算图（构建网络模型）</li> 
   <li>损失函数与优化器</li> 
   <li>开始训练模型</li> 
   <li>对训练的模型预测结果进行评估</li> 
  </ol> 
  <h3><a id="_8"></a>引入模块</h3> 
  <pre><code class="prism language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler

<span class="token operator">%</span>matplotlib inline
</code></pre> 
  <h3><a id="tensor_22"></a>数据转化为tensor</h3> 
  <pre><code class="prism language-python"> x_train_tensor<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_train<span class="token punctuation">)</span>
x_test_tensor<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x_test<span class="token punctuation">)</span>
y_train_numpy<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y_train<span class="token punctuation">)</span>
y_train_tensor<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_train_numpy<span class="token punctuation">)</span>
y_test_numpy<span class="token operator">=</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>y_test<span class="token punctuation">)</span>
y_test_tensor<span class="token operator">=</span>torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y_test_numpy<span class="token punctuation">)</span>
x<span class="token operator">=</span>x_train_tensor<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
y<span class="token operator">=</span>y_train_tensor<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <h3><a id="_34"></a>构建网络模型</h3> 
  <p>构建一个六层的网络</p> 
  <pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">module_net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_input<span class="token punctuation">,</span> num_hidden<span class="token punctuation">,</span> num_output<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>module_net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>layer1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_input<span class="token punctuation">,</span> num_hidden<span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>layer2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>layer3 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hidden<span class="token punctuation">,</span> num_hidden<span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>layer4 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>layer5 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hidden<span class="token punctuation">,</span> num_hidden<span class="token punctuation">)</span>
        
        self<span class="token punctuation">.</span>layer6 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
       
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer3<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer4<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer5<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>layer6<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
       <span class="token keyword">return</span> x
</code></pre> 
  <h3><a id="_62"></a>损失函数与优化器</h3> 
  <pre><code class="prism language-python">criterion<span class="token operator">=</span>nn<span class="token punctuation">.</span>BCEWithLogitsLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>    
mo_net <span class="token operator">=</span> module_net<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
optim <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>mo_net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.9</span><span class="token punctuation">)</span>
</code></pre> 
  <h3><a id="_68"></a>模型训练</h3> 
  <pre><code class="prism language-python">Loss_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>   <span class="token comment">#用来装loss值，以便之后画图</span>
Accuracy_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token comment">#用来装准确率，以便之后画图</span>
<span class="token keyword">for</span> e <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    out <span class="token operator">=</span> mo_net<span class="token punctuation">.</span>forward<span class="token punctuation">(</span>Variable<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>   <span class="token comment">#这里省略了 mo_net.forward()</span>
    loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>out<span class="token punctuation">,</span> Variable<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
    Loss_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment">#--------------------用于求准确率-------------------------#</span>
    out_class<span class="token operator">=</span><span class="token punctuation">(</span>out<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token operator">&gt;</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#将out矩阵中大于0的转化为1，小于0的转化为0，存入a中</span>
    right_num<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>y<span class="token operator">==</span>out_class<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#分类对的数值</span>
    precision<span class="token operator">=</span>right_num<span class="token operator">/</span>out<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment">#准确率</span>
    <span class="token comment">#--------------------求准确率结束-------------------------#</span>
    Accuracy_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>precision<span class="token punctuation">)</span>
    optim<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>    
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optim<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>e <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch: {}, loss: {}，precision{},right_num{}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>e<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>precision<span class="token punctuation">,</span>right_num<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x1<span class="token punctuation">,</span> Loss_list<span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'red'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x1<span class="token punctuation">,</span> Accuracy_list<span class="token punctuation">,</span>c<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span>label<span class="token operator">=</span><span class="token string">'precision'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre> 
  <p>结果：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019051920173331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L21pcmV5YWFh,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
