<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>计算机视觉学习12：图像内容分类(KNN算法和稠密SIFT(Dense-SIFT)以及手势识别） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="计算机视觉学习12：图像内容分类(KNN算法和稠密SIFT(Dense-SIFT)以及手势识别）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="KNN算法(K近邻算法） 一、KNN算法概述 kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 二、KNN算法介绍 最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是怎么可能所有测试对象都会找到与之完全匹配的训练对象呢，其次就是存在一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于这些问题呢，就产生了KNN。 KNN是通过测量不同特征值之间的距离进行分类。它的的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。 由此也说明了KNN算法的结果很大程度取决于K的选择。 在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离： 同时，KNN通过依据k个对象中占优的类别进行决策，而不是单一的对象类别决策。这两点就是KNN算法的优势。 接下来对KNN算法的思想总结一下：就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为： 1）计算测试数据与各个训练数据之间的距离； 2）按照距离的递增关系进行排序； 3）选取距离最小的K个点； 4）确定前K个点所在类别的出现频率； 5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。 三、算法实现 from numpy import * class KnnClassifier(object): def __init__(self,labels,samples): &quot;&quot;&quot; Initialize classifier with training data. &quot;&quot;&quot; self.labels = labels self.samples = samples def classify(self,point,k=3): &quot;&quot;&quot; Classify a point against k nearest in the training data, return label. &quot;&quot;&quot; # compute distance to all training points dist = array([L2dist(point,s) for s in self.samples]) # sort them ndx = dist.argsort() # use dictionary to store the k nearest votes = {} for i in range(k): label = self.labels[ndx[i]] votes.setdefault(label,0) votes[label] += 1 return max(votes, key=lambda x: votes.get(x)) def L2dist(p1,p2): return sqrt( sum( (p1-p2)**2) ) def L1dist(v1,v2): return sum(abs(v1-v2)) 四、实验部分 # -*- coding: utf-8 -*- from numpy.random import randn import pickle from pylab import * # create sample data of 2D points n = 200 # two normal distributions class_1 = 0.6 * randn(n, 2) class_2 = 1.2 * randn(n, 2) + array([5, 1]) labels = hstack((ones(n), -ones(n))) # save with Pickle # with open(&#39;points_normal.pkl&#39;, &#39;w&#39;) as f: with open(&#39;points_normal_test.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(class_1, f) pickle.dump(class_2, f) pickle.dump(labels, f) # normal distribution and ring around it print(&quot;save OK!&quot;) class_1 = 0.6 * randn(n, 2) r = 0.8 * randn(n, 1) + 5 angle = 2 * pi * randn(n, 1) class_2 = hstack((r * cos(angle), r * sin(angle))) labels = hstack((ones(n), -ones(n))) # save with Pickle # with open(&#39;points_ring.pkl&#39;, &#39;w&#39;) as f: with open(&#39;points_ring_test.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(class_1, f) pickle.dump(class_2, f) pickle.dump(labels, f) print(&quot;save OK!&quot;) # -*- coding: utf-8 -*- import pickle from pylab import * from PCV.classifiers import knn from PCV.tools import imtools pklist=[&#39;points_normal.pkl&#39;,&#39;points_ring.pkl&#39;] figure() # load 2D points using Pickle for i, pklfile in enumerate(pklist): with open(pklfile, &#39;rb&#39;) as f: class_1 = pickle.load(f) class_2 = pickle.load(f) labels = pickle.load(f) # load test data using Pickle with open(pklfile[:-4]+&#39;_test.pkl&#39;, &#39;rb&#39;) as f: class_1 = pickle.load(f) class_2 = pickle.load(f) labels = pickle.load(f) model = knn.KnnClassifier(labels,vstack((class_1,class_2))) # test on the first point print (model.classify(class_1[0])) #define function for plotting def classify(x,y,model=model): return array([model.classify([xx,yy]) for (xx,yy) in zip(x,y)]) # lot the classification boundary subplot(1,2,i+1) imtools.plot_2D_boundary([-6,6,-6,6],[class_1,class_2],classify,[1,-1]) titlename=pklfile[:-4] title(titlename) savefig(&quot;test1.png&quot;) show() 实验结果 稠密SIFT算法（Dense-SIFT) 一、原理 传统的SIFT算法即Sparse SIFT，不能很好地表征不同类之间的特征差异，达不到所需的分类要求。而Dense SIFT算法，是一种对输入图像进行分块处理，再进行SIFT运算的特征提取过程。Dense SIFT根据可调的参数大小，来适当满足不同分类任务下对图像的特征表征能力。 该算法首先将表达目标的矩形区域分成相同大小的矩形块,计算每一个小块的SIFT特征,再对各个小块的稠密SIFT特征在中心位置进行采样,建模目标的表达.然后度量两个图像区域的不相似性,先计算两个区域对应小块的Bhattacharyya距离,再对各距离加权求和作为两个区域间的距离.因为目标所在区域靠近边缘的部分可能受到背景像素的影响,而区域的内部则更一致,所以越靠近区域中心权函数的值越大.最后提出了能适应目标尺度变化的跟踪算法。 手势识别" />
<meta property="og:description" content="KNN算法(K近邻算法） 一、KNN算法概述 kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 二、KNN算法介绍 最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是怎么可能所有测试对象都会找到与之完全匹配的训练对象呢，其次就是存在一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于这些问题呢，就产生了KNN。 KNN是通过测量不同特征值之间的距离进行分类。它的的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。 由此也说明了KNN算法的结果很大程度取决于K的选择。 在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离： 同时，KNN通过依据k个对象中占优的类别进行决策，而不是单一的对象类别决策。这两点就是KNN算法的优势。 接下来对KNN算法的思想总结一下：就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为： 1）计算测试数据与各个训练数据之间的距离； 2）按照距离的递增关系进行排序； 3）选取距离最小的K个点； 4）确定前K个点所在类别的出现频率； 5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。 三、算法实现 from numpy import * class KnnClassifier(object): def __init__(self,labels,samples): &quot;&quot;&quot; Initialize classifier with training data. &quot;&quot;&quot; self.labels = labels self.samples = samples def classify(self,point,k=3): &quot;&quot;&quot; Classify a point against k nearest in the training data, return label. &quot;&quot;&quot; # compute distance to all training points dist = array([L2dist(point,s) for s in self.samples]) # sort them ndx = dist.argsort() # use dictionary to store the k nearest votes = {} for i in range(k): label = self.labels[ndx[i]] votes.setdefault(label,0) votes[label] += 1 return max(votes, key=lambda x: votes.get(x)) def L2dist(p1,p2): return sqrt( sum( (p1-p2)**2) ) def L1dist(v1,v2): return sum(abs(v1-v2)) 四、实验部分 # -*- coding: utf-8 -*- from numpy.random import randn import pickle from pylab import * # create sample data of 2D points n = 200 # two normal distributions class_1 = 0.6 * randn(n, 2) class_2 = 1.2 * randn(n, 2) + array([5, 1]) labels = hstack((ones(n), -ones(n))) # save with Pickle # with open(&#39;points_normal.pkl&#39;, &#39;w&#39;) as f: with open(&#39;points_normal_test.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(class_1, f) pickle.dump(class_2, f) pickle.dump(labels, f) # normal distribution and ring around it print(&quot;save OK!&quot;) class_1 = 0.6 * randn(n, 2) r = 0.8 * randn(n, 1) + 5 angle = 2 * pi * randn(n, 1) class_2 = hstack((r * cos(angle), r * sin(angle))) labels = hstack((ones(n), -ones(n))) # save with Pickle # with open(&#39;points_ring.pkl&#39;, &#39;w&#39;) as f: with open(&#39;points_ring_test.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(class_1, f) pickle.dump(class_2, f) pickle.dump(labels, f) print(&quot;save OK!&quot;) # -*- coding: utf-8 -*- import pickle from pylab import * from PCV.classifiers import knn from PCV.tools import imtools pklist=[&#39;points_normal.pkl&#39;,&#39;points_ring.pkl&#39;] figure() # load 2D points using Pickle for i, pklfile in enumerate(pklist): with open(pklfile, &#39;rb&#39;) as f: class_1 = pickle.load(f) class_2 = pickle.load(f) labels = pickle.load(f) # load test data using Pickle with open(pklfile[:-4]+&#39;_test.pkl&#39;, &#39;rb&#39;) as f: class_1 = pickle.load(f) class_2 = pickle.load(f) labels = pickle.load(f) model = knn.KnnClassifier(labels,vstack((class_1,class_2))) # test on the first point print (model.classify(class_1[0])) #define function for plotting def classify(x,y,model=model): return array([model.classify([xx,yy]) for (xx,yy) in zip(x,y)]) # lot the classification boundary subplot(1,2,i+1) imtools.plot_2D_boundary([-6,6,-6,6],[class_1,class_2],classify,[1,-1]) titlename=pklfile[:-4] title(titlename) savefig(&quot;test1.png&quot;) show() 实验结果 稠密SIFT算法（Dense-SIFT) 一、原理 传统的SIFT算法即Sparse SIFT，不能很好地表征不同类之间的特征差异，达不到所需的分类要求。而Dense SIFT算法，是一种对输入图像进行分块处理，再进行SIFT运算的特征提取过程。Dense SIFT根据可调的参数大小，来适当满足不同分类任务下对图像的特征表征能力。 该算法首先将表达目标的矩形区域分成相同大小的矩形块,计算每一个小块的SIFT特征,再对各个小块的稠密SIFT特征在中心位置进行采样,建模目标的表达.然后度量两个图像区域的不相似性,先计算两个区域对应小块的Bhattacharyya距离,再对各距离加权求和作为两个区域间的距离.因为目标所在区域靠近边缘的部分可能受到背景像素的影响,而区域的内部则更一致,所以越靠近区域中心权函数的值越大.最后提出了能适应目标尺度变化的跟踪算法。 手势识别" />
<link rel="canonical" href="https://mlh.app/2019/05/17/787127.html" />
<meta property="og:url" content="https://mlh.app/2019/05/17/787127.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"KNN算法(K近邻算法） 一、KNN算法概述 kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 二、KNN算法介绍 最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是怎么可能所有测试对象都会找到与之完全匹配的训练对象呢，其次就是存在一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于这些问题呢，就产生了KNN。 KNN是通过测量不同特征值之间的距离进行分类。它的的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。 由此也说明了KNN算法的结果很大程度取决于K的选择。 在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离： 同时，KNN通过依据k个对象中占优的类别进行决策，而不是单一的对象类别决策。这两点就是KNN算法的优势。 接下来对KNN算法的思想总结一下：就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为： 1）计算测试数据与各个训练数据之间的距离； 2）按照距离的递增关系进行排序； 3）选取距离最小的K个点； 4）确定前K个点所在类别的出现频率； 5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。 三、算法实现 from numpy import * class KnnClassifier(object): def __init__(self,labels,samples): &quot;&quot;&quot; Initialize classifier with training data. &quot;&quot;&quot; self.labels = labels self.samples = samples def classify(self,point,k=3): &quot;&quot;&quot; Classify a point against k nearest in the training data, return label. &quot;&quot;&quot; # compute distance to all training points dist = array([L2dist(point,s) for s in self.samples]) # sort them ndx = dist.argsort() # use dictionary to store the k nearest votes = {} for i in range(k): label = self.labels[ndx[i]] votes.setdefault(label,0) votes[label] += 1 return max(votes, key=lambda x: votes.get(x)) def L2dist(p1,p2): return sqrt( sum( (p1-p2)**2) ) def L1dist(v1,v2): return sum(abs(v1-v2)) 四、实验部分 # -*- coding: utf-8 -*- from numpy.random import randn import pickle from pylab import * # create sample data of 2D points n = 200 # two normal distributions class_1 = 0.6 * randn(n, 2) class_2 = 1.2 * randn(n, 2) + array([5, 1]) labels = hstack((ones(n), -ones(n))) # save with Pickle # with open(&#39;points_normal.pkl&#39;, &#39;w&#39;) as f: with open(&#39;points_normal_test.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(class_1, f) pickle.dump(class_2, f) pickle.dump(labels, f) # normal distribution and ring around it print(&quot;save OK!&quot;) class_1 = 0.6 * randn(n, 2) r = 0.8 * randn(n, 1) + 5 angle = 2 * pi * randn(n, 1) class_2 = hstack((r * cos(angle), r * sin(angle))) labels = hstack((ones(n), -ones(n))) # save with Pickle # with open(&#39;points_ring.pkl&#39;, &#39;w&#39;) as f: with open(&#39;points_ring_test.pkl&#39;, &#39;wb&#39;) as f: pickle.dump(class_1, f) pickle.dump(class_2, f) pickle.dump(labels, f) print(&quot;save OK!&quot;) # -*- coding: utf-8 -*- import pickle from pylab import * from PCV.classifiers import knn from PCV.tools import imtools pklist=[&#39;points_normal.pkl&#39;,&#39;points_ring.pkl&#39;] figure() # load 2D points using Pickle for i, pklfile in enumerate(pklist): with open(pklfile, &#39;rb&#39;) as f: class_1 = pickle.load(f) class_2 = pickle.load(f) labels = pickle.load(f) # load test data using Pickle with open(pklfile[:-4]+&#39;_test.pkl&#39;, &#39;rb&#39;) as f: class_1 = pickle.load(f) class_2 = pickle.load(f) labels = pickle.load(f) model = knn.KnnClassifier(labels,vstack((class_1,class_2))) # test on the first point print (model.classify(class_1[0])) #define function for plotting def classify(x,y,model=model): return array([model.classify([xx,yy]) for (xx,yy) in zip(x,y)]) # lot the classification boundary subplot(1,2,i+1) imtools.plot_2D_boundary([-6,6,-6,6],[class_1,class_2],classify,[1,-1]) titlename=pklfile[:-4] title(titlename) savefig(&quot;test1.png&quot;) show() 实验结果 稠密SIFT算法（Dense-SIFT) 一、原理 传统的SIFT算法即Sparse SIFT，不能很好地表征不同类之间的特征差异，达不到所需的分类要求。而Dense SIFT算法，是一种对输入图像进行分块处理，再进行SIFT运算的特征提取过程。Dense SIFT根据可调的参数大小，来适当满足不同分类任务下对图像的特征表征能力。 该算法首先将表达目标的矩形区域分成相同大小的矩形块,计算每一个小块的SIFT特征,再对各个小块的稠密SIFT特征在中心位置进行采样,建模目标的表达.然后度量两个图像区域的不相似性,先计算两个区域对应小块的Bhattacharyya距离,再对各距离加权求和作为两个区域间的距离.因为目标所在区域靠近边缘的部分可能受到背景像素的影响,而区域的内部则更一致,所以越靠近区域中心权函数的值越大.最后提出了能适应目标尺度变化的跟踪算法。 手势识别","@type":"BlogPosting","url":"https://mlh.app/2019/05/17/787127.html","headline":"计算机视觉学习12：图像内容分类(KNN算法和稠密SIFT(Dense-SIFT)以及手势识别）","dateModified":"2019-05-17T00:00:00+08:00","datePublished":"2019-05-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/17/787127.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>计算机视觉学习12：图像内容分类(KNN算法和稠密SIFT(Dense-SIFT)以及手势识别）</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-light"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h2><a id="KNNK_0"></a>KNN算法(K近邻算法）</h2> 
  <h3><a id="KNN_1"></a>一、KNN算法概述</h3> 
  <p>kNN算法的核心思想是如果一个样本在特征空间中的k个最相邻的样本中的大多数属于某一个类别，则该样本也属于这个类别，并具有这个类别上样本的特性。该方法在确定分类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。</p> 
  <h3><a id="KNN_3"></a>二、KNN算法介绍</h3> 
  <p>最简单最初级的分类器是将全部的训练数据所对应的类别都记录下来，当测试对象的属性和某个训练对象的属性完全匹配时，便可以对其进行分类。但是怎么可能所有测试对象都会找到与之完全匹配的训练对象呢，其次就是存在一个测试对象同时与多个训练对象匹配，导致一个训练对象被分到了多个类的问题，基于这些问题呢，就产生了KNN。 KNN是通过测量不同特征值之间的距离进行分类。它的的思路是：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。K通常是不大于20的整数。KNN算法中，所选择的邻居都是已经正确分类的对象。该方法在定类决策上只依据最邻近的一个或者几个样本的类别来决定待分样本所属的类别。 下面通过一个简单的例子说明一下：如下图，绿色圆要被决定赋予哪个类，是红色三角形还是蓝色四方形？如果K=3，由于红色三角形所占比例为2/3，绿色圆将被赋予红色三角形那个类，如果K=5，由于蓝色四方形比例为3/5，因此绿色圆被赋予蓝色四方形类。<br> <img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/201905172038492.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MDkwNTQx,size_16,color_FFFFFF,t_70"><br> 由此也说明了KNN算法的结果很大程度取决于K的选择。<br> 在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离：<img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190517203920385.png"><br> 同时，KNN通过依据k个对象中占优的类别进行决策，而不是单一的对象类别决策。这两点就是KNN算法的优势。<br> 接下来对KNN算法的思想总结一下：就是在训练集中数据和标签已知的情况下，输入测试数据，将测试数据的特征与训练集中对应的特征进行相互比较，找到训练集中与之最为相似的前K个数据，则该测试数据对应的类别就是K个数据中出现次数最多的那个分类，其算法的描述为：<br> 1）计算测试数据与各个训练数据之间的距离；<br> 2）按照距离的递增关系进行排序；<br> 3）选取距离最小的K个点；<br> 4）确定前K个点所在类别的出现频率；<br> 5）返回前K个点中出现频率最高的类别作为测试数据的预测分类。</p> 
  <h3><a id="_15"></a>三、算法实现</h3> 
  <pre><code>from numpy import * 

class KnnClassifier(object):
    
    def __init__(self,labels,samples):
        """ Initialize classifier with training data. """
        
        self.labels = labels
        self.samples = samples
    
    def classify(self,point,k=3):
        """ Classify a point against k nearest 
            in the training data, return label. """
        
        # compute distance to all training points
        dist = array([L2dist(point,s) for s in self.samples])
        
        # sort them
        ndx = dist.argsort()
        
        # use dictionary to store the k nearest
        votes = {}
        for i in range(k):
            label = self.labels[ndx[i]]
            votes.setdefault(label,0)
            votes[label] += 1
            
        return max(votes, key=lambda x: votes.get(x))


def L2dist(p1,p2):
    return sqrt( sum( (p1-p2)**2) )

def L1dist(v1,v2):
    return sum(abs(v1-v2))
</code></pre> 
  <h3><a id="_54"></a>四、实验部分</h3> 
  <pre><code># -*- coding: utf-8 -*-
from numpy.random import randn
import pickle
from pylab import *

# create sample data of 2D points
n = 200
# two normal distributions
class_1 = 0.6 * randn(n, 2)
class_2 = 1.2 * randn(n, 2) + array([5, 1])
labels = hstack((ones(n), -ones(n)))
# save with Pickle
# with open('points_normal.pkl', 'w') as f:
with open('points_normal_test.pkl', 'wb') as f:
    pickle.dump(class_1, f)
    pickle.dump(class_2, f)
    pickle.dump(labels, f)
# normal distribution and ring around it
print("save OK!")
class_1 = 0.6 * randn(n, 2)
r = 0.8 * randn(n, 1) + 5
angle = 2 * pi * randn(n, 1)
class_2 = hstack((r * cos(angle), r * sin(angle)))
labels = hstack((ones(n), -ones(n)))
# save with Pickle
# with open('points_ring.pkl', 'w') as f:
with open('points_ring_test.pkl', 'wb') as f:
    pickle.dump(class_1, f)
    pickle.dump(class_2, f)
    pickle.dump(labels, f)

print("save OK!")
</code></pre> 
  <pre><code># -*- coding: utf-8 -*-
import pickle
from pylab import *
from PCV.classifiers import knn
from PCV.tools import imtools

pklist=['points_normal.pkl','points_ring.pkl']

figure()

# load 2D points using Pickle
for i, pklfile in enumerate(pklist):
    with open(pklfile, 'rb') as f:
        class_1 = pickle.load(f)
        class_2 = pickle.load(f)
        labels = pickle.load(f)
    # load test data using Pickle
    with open(pklfile[:-4]+'_test.pkl', 'rb') as f:
        class_1 = pickle.load(f)
        class_2 = pickle.load(f)
        labels = pickle.load(f)

    model = knn.KnnClassifier(labels,vstack((class_1,class_2)))
    # test on the first point
    print (model.classify(class_1[0]))

    #define function for plotting
    def classify(x,y,model=model):
        return array([model.classify([xx,yy]) for (xx,yy) in zip(x,y)])

    # lot the classification boundary
    subplot(1,2,i+1)
    imtools.plot_2D_boundary([-6,6,-6,6],[class_1,class_2],classify,[1,-1])
    titlename=pklfile[:-4]
    title(titlename)
    savefig("test1.png")
show()
</code></pre> 
  <h5><a id="_130"></a>实验结果</h5> 
  <p><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190517204457570.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MDkwNTQx,size_16,color_FFFFFF,t_70"></p> 
  <p><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190517205012372.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM4MDkwNTQx,size_16,color_FFFFFF,t_70"></p> 
  <h2><a id="SIFTDenseSIFT_135"></a>稠密SIFT算法（Dense-SIFT)</h2> 
  <h3><a id="_136"></a>一、原理</h3> 
  <p>传统的SIFT算法即Sparse SIFT，不能很好地表征不同类之间的特征差异，达不到所需的分类要求。而Dense SIFT算法，是一种对输入图像进行分块处理，再进行SIFT运算的特征提取过程。Dense SIFT根据可调的参数大小，来适当满足不同分类任务下对图像的特征表征能力。<br> 该算法首先将表达目标的矩形区域分成相同大小的矩形块,计算每一个小块的SIFT特征,再对各个小块的稠密SIFT特征在中心位置进行采样,建模目标的表达.然后度量两个图像区域的不相似性,先计算两个区域对应小块的Bhattacharyya距离,再对各距离加权求和作为两个区域间的距离.因为目标所在区域靠近边缘的部分可能受到背景像素的影响,而区域的内部则更一致,所以越靠近区域中心权函数的值越大.最后提出了能适应目标尺度变化的跟踪算法。</p> 
  <h2><a id="_140"></a>手势识别</h2> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
