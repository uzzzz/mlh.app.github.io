<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Hadoop学习之旅一：Hello Hadoop | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Hadoop学习之旅一：Hello Hadoop" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="学习大数据必先学习Hadoop，因为它是目前世界上最流行的分布式数据处理框架。 Tips：所谓大数据，是指数据量庞大、产生数度快、结构多样的价值密度低的数据。其中，数据量庞大是指数据规模超出了1,2台高性能主机所能处理范围;结构多样性是指除了关系型数据库能够处理的结构化数据还包含半结构化数据(如各类传感设备必如地镑、卫星、GPS设备等产生的纯文本格式的数据，还有良心网站NASA官网公布的txt格式的空间天气数据等成行成列的数据)和非结构化数据(视频、图像等)。这些数据的价值密度普遍较低(和具体的应用范围也有关系，比如NASA的数据，如果想知道某天的太阳射电情况，看当天发布的txt就好了，价值密度很高，但是这就不算大数据了，因为需要采集的数据量很小;如果想知道过去N年太阳射电的极值就需要处理很多数据，这些数据的价值密度就低了)，大数据处理的目的就是从价值密度的数据里把有价值的数据过滤分析出来。 Hadoop概述 Hadoop是一个用于分布式大数据处理的编程框架。同时它也是个大数据处理完整的生态系统，围绕着Hadoop，这个生态系统还包括但不限于： HBase Hive Pig Spark ZooKeeper 希望本系列的写作能够坚持下去，对上述内容都有所涉及吧。 Hadoop能干什么 假设老王在某不知名IT公司工作，由于最近太阳活动异常，引起了领导的外甥的读硕士的同学的关注，领导让老王把山西铁岛太阳射电望远镜观测到的近30年的太阳射电数据下载下来，让老王从里面找到最高的记录。老王毕竟搞挨踢已有多年，虽然技术不行，终日碌碌无为，但多年的直觉告诉老王这个很简单。老王立刻下载了其中一个文件并大致看了文件的机构：数据保存在txt文件里，每行N列，其中包含了时间和数据信息列，大约每0.1s记录一条数据，一个文件记录15分钟的数据，大约有9000条记录，1个小时4个文件，1天96个文件，30年大约1051200个文件，一共大约100亿条数据，这其中还有一些损坏的文件，还有一些用9999表示的未检测到值的占位数据需要特殊照顾。 老王觉得单机处理这些数据耗时太久，于是老王找来一些公司淘汰下来的旧服务器(一般小公司最破的机器都是服务器)，准备每个机器负责一部分，最后把结果汇总，老王在开发的过程中还是遇到了很多问题，比如，如何分配任务，有的机器破，有的机器新，还有的文件大，有的文件小，总是不能保证所有的任务一起完成，先完成任务的机器闲置浪费掉了资源;还有最后把结果通过网络通信汇总起来，如何保证数据不丢失，不覆盖;还有如果某台机器出了问题，如何重新分配任务，这些非核心业务的开发使得老王心力憔悴，还好，老王最后找到了Hadoop这个工具，这个工具给老王提供了一个简单的编程模型，老王在map方法中写了分配的任务的逻辑，在reduce方法中写了合并结果的逻辑，然后Hadoop帮老王完成了其他所有事情，Hadoop就是干这个的。以上故事纯属虚构，如有雷同，实属巧合。 其实上述意淫的例子里的数据量不是很大，如果每天产生上TB级别的数据，就算是速度很快的固态硬盘也需要小时级时间才能读取一遍，速度还是远远跟不上，终归有上限，而且高性能主机价格不菲，不如把数据分开放到一个相对廉价又可扩展的计算机集群中，每个节点上运行一段程序并处理一小块数据，然后在汇总处理结果，使用Hadoop可以让开发者不必把精力放在集群的建设上，采用Hadoop提供的简单的编程模型就可以实现分布式处理。 Hadoop的构造模块 Hadoop集群中运行的守护进程共有5类： NameNode DataNode Secondary NameNode JobTracker TaskTracker Hadoop集群中的机器(节点)分为2类：主节点和从节点，NameNode、JobTracker所在节点为主节点(负责管理)，DataNode和TaskTracker所在节点为从节点(负责干活儿)。 NameNode NameNode节点负责将一个文件分成若干文件块，并记录了HDFS文件系统中的文件块放了在哪些DataNode中(一个数据块被冗余地放到1个或多个DataNode节点中)，一个集群中只有一个NameNode节点(Hadoop2.X中情况有所不同了)，且该节点通常不再运行DataNode和TaskTracker守护进程。 DataNode DataNode实际管理很多NameNode分配给它的很多数据块，当有文件块变动时会通知NameNode，同时也从NameNode接受指令。一个集群中有多个DataNode节点，DataNode之间也会保持联系，复制冗余文件块，这样当一个DataNode出现故障后不会影响到文件的完整性。 Secondary NameNode SNN只与NameNode通信，定时获取HDFS元数据的快照，一个集群只有一个SNN，且SNN所在节点只运行SNN守护进程，不干其它的事情。当NameNode出现故障后，可以人工启用SNN作为NameNode。 JobTracker JobTracker负责分配MapReduce任务给TaskTracker，负责监控任务的执行，如任务失败后重启任务。JobTracker守护进程运行在主节点上，通常该节点不运行DataNode和TaskTracker守护进程。 TaskTracker TaskTracker负责完成JobTracker分配的任务并和JobTranker进行通信，回报情况。TaskTracker守护进程运行在多个子节点上 在这里我还是要推荐下我自己建的大数据学习交流qq裙：522189307 ， 裙 里都是学大数据开发的，如果你正在学习大数据 ，小编欢迎你加入，大家都是软件开发党，不定期分享干货（只有大数据开发相关的），包括我自己整理的一份最新的大数据进阶资料和高级开发教程，欢迎进阶中和进想深入大数据的小伙伴。上述资料加群可以领取" />
<meta property="og:description" content="学习大数据必先学习Hadoop，因为它是目前世界上最流行的分布式数据处理框架。 Tips：所谓大数据，是指数据量庞大、产生数度快、结构多样的价值密度低的数据。其中，数据量庞大是指数据规模超出了1,2台高性能主机所能处理范围;结构多样性是指除了关系型数据库能够处理的结构化数据还包含半结构化数据(如各类传感设备必如地镑、卫星、GPS设备等产生的纯文本格式的数据，还有良心网站NASA官网公布的txt格式的空间天气数据等成行成列的数据)和非结构化数据(视频、图像等)。这些数据的价值密度普遍较低(和具体的应用范围也有关系，比如NASA的数据，如果想知道某天的太阳射电情况，看当天发布的txt就好了，价值密度很高，但是这就不算大数据了，因为需要采集的数据量很小;如果想知道过去N年太阳射电的极值就需要处理很多数据，这些数据的价值密度就低了)，大数据处理的目的就是从价值密度的数据里把有价值的数据过滤分析出来。 Hadoop概述 Hadoop是一个用于分布式大数据处理的编程框架。同时它也是个大数据处理完整的生态系统，围绕着Hadoop，这个生态系统还包括但不限于： HBase Hive Pig Spark ZooKeeper 希望本系列的写作能够坚持下去，对上述内容都有所涉及吧。 Hadoop能干什么 假设老王在某不知名IT公司工作，由于最近太阳活动异常，引起了领导的外甥的读硕士的同学的关注，领导让老王把山西铁岛太阳射电望远镜观测到的近30年的太阳射电数据下载下来，让老王从里面找到最高的记录。老王毕竟搞挨踢已有多年，虽然技术不行，终日碌碌无为，但多年的直觉告诉老王这个很简单。老王立刻下载了其中一个文件并大致看了文件的机构：数据保存在txt文件里，每行N列，其中包含了时间和数据信息列，大约每0.1s记录一条数据，一个文件记录15分钟的数据，大约有9000条记录，1个小时4个文件，1天96个文件，30年大约1051200个文件，一共大约100亿条数据，这其中还有一些损坏的文件，还有一些用9999表示的未检测到值的占位数据需要特殊照顾。 老王觉得单机处理这些数据耗时太久，于是老王找来一些公司淘汰下来的旧服务器(一般小公司最破的机器都是服务器)，准备每个机器负责一部分，最后把结果汇总，老王在开发的过程中还是遇到了很多问题，比如，如何分配任务，有的机器破，有的机器新，还有的文件大，有的文件小，总是不能保证所有的任务一起完成，先完成任务的机器闲置浪费掉了资源;还有最后把结果通过网络通信汇总起来，如何保证数据不丢失，不覆盖;还有如果某台机器出了问题，如何重新分配任务，这些非核心业务的开发使得老王心力憔悴，还好，老王最后找到了Hadoop这个工具，这个工具给老王提供了一个简单的编程模型，老王在map方法中写了分配的任务的逻辑，在reduce方法中写了合并结果的逻辑，然后Hadoop帮老王完成了其他所有事情，Hadoop就是干这个的。以上故事纯属虚构，如有雷同，实属巧合。 其实上述意淫的例子里的数据量不是很大，如果每天产生上TB级别的数据，就算是速度很快的固态硬盘也需要小时级时间才能读取一遍，速度还是远远跟不上，终归有上限，而且高性能主机价格不菲，不如把数据分开放到一个相对廉价又可扩展的计算机集群中，每个节点上运行一段程序并处理一小块数据，然后在汇总处理结果，使用Hadoop可以让开发者不必把精力放在集群的建设上，采用Hadoop提供的简单的编程模型就可以实现分布式处理。 Hadoop的构造模块 Hadoop集群中运行的守护进程共有5类： NameNode DataNode Secondary NameNode JobTracker TaskTracker Hadoop集群中的机器(节点)分为2类：主节点和从节点，NameNode、JobTracker所在节点为主节点(负责管理)，DataNode和TaskTracker所在节点为从节点(负责干活儿)。 NameNode NameNode节点负责将一个文件分成若干文件块，并记录了HDFS文件系统中的文件块放了在哪些DataNode中(一个数据块被冗余地放到1个或多个DataNode节点中)，一个集群中只有一个NameNode节点(Hadoop2.X中情况有所不同了)，且该节点通常不再运行DataNode和TaskTracker守护进程。 DataNode DataNode实际管理很多NameNode分配给它的很多数据块，当有文件块变动时会通知NameNode，同时也从NameNode接受指令。一个集群中有多个DataNode节点，DataNode之间也会保持联系，复制冗余文件块，这样当一个DataNode出现故障后不会影响到文件的完整性。 Secondary NameNode SNN只与NameNode通信，定时获取HDFS元数据的快照，一个集群只有一个SNN，且SNN所在节点只运行SNN守护进程，不干其它的事情。当NameNode出现故障后，可以人工启用SNN作为NameNode。 JobTracker JobTracker负责分配MapReduce任务给TaskTracker，负责监控任务的执行，如任务失败后重启任务。JobTracker守护进程运行在主节点上，通常该节点不运行DataNode和TaskTracker守护进程。 TaskTracker TaskTracker负责完成JobTracker分配的任务并和JobTranker进行通信，回报情况。TaskTracker守护进程运行在多个子节点上 在这里我还是要推荐下我自己建的大数据学习交流qq裙：522189307 ， 裙 里都是学大数据开发的，如果你正在学习大数据 ，小编欢迎你加入，大家都是软件开发党，不定期分享干货（只有大数据开发相关的），包括我自己整理的一份最新的大数据进阶资料和高级开发教程，欢迎进阶中和进想深入大数据的小伙伴。上述资料加群可以领取" />
<link rel="canonical" href="https://mlh.app/2019/05/17/787163.html" />
<meta property="og:url" content="https://mlh.app/2019/05/17/787163.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"学习大数据必先学习Hadoop，因为它是目前世界上最流行的分布式数据处理框架。 Tips：所谓大数据，是指数据量庞大、产生数度快、结构多样的价值密度低的数据。其中，数据量庞大是指数据规模超出了1,2台高性能主机所能处理范围;结构多样性是指除了关系型数据库能够处理的结构化数据还包含半结构化数据(如各类传感设备必如地镑、卫星、GPS设备等产生的纯文本格式的数据，还有良心网站NASA官网公布的txt格式的空间天气数据等成行成列的数据)和非结构化数据(视频、图像等)。这些数据的价值密度普遍较低(和具体的应用范围也有关系，比如NASA的数据，如果想知道某天的太阳射电情况，看当天发布的txt就好了，价值密度很高，但是这就不算大数据了，因为需要采集的数据量很小;如果想知道过去N年太阳射电的极值就需要处理很多数据，这些数据的价值密度就低了)，大数据处理的目的就是从价值密度的数据里把有价值的数据过滤分析出来。 Hadoop概述 Hadoop是一个用于分布式大数据处理的编程框架。同时它也是个大数据处理完整的生态系统，围绕着Hadoop，这个生态系统还包括但不限于： HBase Hive Pig Spark ZooKeeper 希望本系列的写作能够坚持下去，对上述内容都有所涉及吧。 Hadoop能干什么 假设老王在某不知名IT公司工作，由于最近太阳活动异常，引起了领导的外甥的读硕士的同学的关注，领导让老王把山西铁岛太阳射电望远镜观测到的近30年的太阳射电数据下载下来，让老王从里面找到最高的记录。老王毕竟搞挨踢已有多年，虽然技术不行，终日碌碌无为，但多年的直觉告诉老王这个很简单。老王立刻下载了其中一个文件并大致看了文件的机构：数据保存在txt文件里，每行N列，其中包含了时间和数据信息列，大约每0.1s记录一条数据，一个文件记录15分钟的数据，大约有9000条记录，1个小时4个文件，1天96个文件，30年大约1051200个文件，一共大约100亿条数据，这其中还有一些损坏的文件，还有一些用9999表示的未检测到值的占位数据需要特殊照顾。 老王觉得单机处理这些数据耗时太久，于是老王找来一些公司淘汰下来的旧服务器(一般小公司最破的机器都是服务器)，准备每个机器负责一部分，最后把结果汇总，老王在开发的过程中还是遇到了很多问题，比如，如何分配任务，有的机器破，有的机器新，还有的文件大，有的文件小，总是不能保证所有的任务一起完成，先完成任务的机器闲置浪费掉了资源;还有最后把结果通过网络通信汇总起来，如何保证数据不丢失，不覆盖;还有如果某台机器出了问题，如何重新分配任务，这些非核心业务的开发使得老王心力憔悴，还好，老王最后找到了Hadoop这个工具，这个工具给老王提供了一个简单的编程模型，老王在map方法中写了分配的任务的逻辑，在reduce方法中写了合并结果的逻辑，然后Hadoop帮老王完成了其他所有事情，Hadoop就是干这个的。以上故事纯属虚构，如有雷同，实属巧合。 其实上述意淫的例子里的数据量不是很大，如果每天产生上TB级别的数据，就算是速度很快的固态硬盘也需要小时级时间才能读取一遍，速度还是远远跟不上，终归有上限，而且高性能主机价格不菲，不如把数据分开放到一个相对廉价又可扩展的计算机集群中，每个节点上运行一段程序并处理一小块数据，然后在汇总处理结果，使用Hadoop可以让开发者不必把精力放在集群的建设上，采用Hadoop提供的简单的编程模型就可以实现分布式处理。 Hadoop的构造模块 Hadoop集群中运行的守护进程共有5类： NameNode DataNode Secondary NameNode JobTracker TaskTracker Hadoop集群中的机器(节点)分为2类：主节点和从节点，NameNode、JobTracker所在节点为主节点(负责管理)，DataNode和TaskTracker所在节点为从节点(负责干活儿)。 NameNode NameNode节点负责将一个文件分成若干文件块，并记录了HDFS文件系统中的文件块放了在哪些DataNode中(一个数据块被冗余地放到1个或多个DataNode节点中)，一个集群中只有一个NameNode节点(Hadoop2.X中情况有所不同了)，且该节点通常不再运行DataNode和TaskTracker守护进程。 DataNode DataNode实际管理很多NameNode分配给它的很多数据块，当有文件块变动时会通知NameNode，同时也从NameNode接受指令。一个集群中有多个DataNode节点，DataNode之间也会保持联系，复制冗余文件块，这样当一个DataNode出现故障后不会影响到文件的完整性。 Secondary NameNode SNN只与NameNode通信，定时获取HDFS元数据的快照，一个集群只有一个SNN，且SNN所在节点只运行SNN守护进程，不干其它的事情。当NameNode出现故障后，可以人工启用SNN作为NameNode。 JobTracker JobTracker负责分配MapReduce任务给TaskTracker，负责监控任务的执行，如任务失败后重启任务。JobTracker守护进程运行在主节点上，通常该节点不运行DataNode和TaskTracker守护进程。 TaskTracker TaskTracker负责完成JobTracker分配的任务并和JobTranker进行通信，回报情况。TaskTracker守护进程运行在多个子节点上 在这里我还是要推荐下我自己建的大数据学习交流qq裙：522189307 ， 裙 里都是学大数据开发的，如果你正在学习大数据 ，小编欢迎你加入，大家都是软件开发党，不定期分享干货（只有大数据开发相关的），包括我自己整理的一份最新的大数据进阶资料和高级开发教程，欢迎进阶中和进想深入大数据的小伙伴。上述资料加群可以领取","@type":"BlogPosting","url":"https://mlh.app/2019/05/17/787163.html","headline":"Hadoop学习之旅一：Hello Hadoop","dateModified":"2019-05-17T00:00:00+08:00","datePublished":"2019-05-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/17/787163.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Hadoop学习之旅一：Hello Hadoop</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>学习大数据必先学习Hadoop，因为它是目前世界上最流行的分布式数据处理框架。</p> 
  <p>Tips：所谓大数据，是指数据量庞大、产生数度快、结构多样的价值密度低的数据。其中，数据量庞大是指数据规模超出了1,2台高性能主机所能处理范围;结构多样性是指除了关系型数据库能够处理的结构化数据还包含半结构化数据(如各类传感设备必如地镑、卫星、GPS设备等产生的纯文本格式的数据，还有良心网站NASA官网公布的txt格式的空间天气数据等成行成列的数据)和非结构化数据(视频、图像等)。这些数据的价值密度普遍较低(和具体的应用范围也有关系，比如NASA的数据，如果想知道某天的太阳射电情况，看当天发布的txt就好了，价值密度很高，但是这就不算大数据了，因为需要采集的数据量很小;如果想知道过去N年太阳射电的极值就需要处理很多数据，这些数据的价值密度就低了)，大数据处理的目的就是从价值密度的数据里把有价值的数据过滤分析出来。</p> 
  <p>Hadoop概述</p> 
  <p>Hadoop是一个用于分布式大数据处理的编程框架。同时它也是个大数据处理完整的生态系统，围绕着Hadoop，这个生态系统还包括但不限于：</p> 
  <p>HBase<br> Hive<br> Pig<br> Spark</p> 
  <p>ZooKeeper</p> 
  <p>希望本系列的写作能够坚持下去，对上述内容都有所涉及吧。</p> 
  <p>Hadoop能干什么</p> 
  <p>假设老王在某不知名IT公司工作，由于最近太阳活动异常，引起了领导的外甥的读硕士的同学的关注，领导让老王把山西铁岛太阳射电望远镜观测到的近30年的太阳射电数据下载下来，让老王从里面找到最高的记录。老王毕竟搞挨踢已有多年，虽然技术不行，终日碌碌无为，但多年的直觉告诉老王这个很简单。老王立刻下载了其中一个文件并大致看了文件的机构：数据保存在txt文件里，每行N列，其中包含了时间和数据信息列，大约每0.1s记录一条数据，一个文件记录15分钟的数据，大约有9000条记录，1个小时4个文件，1天96个文件，30年大约1051200个文件，一共大约100亿条数据，这其中还有一些损坏的文件，还有一些用9999表示的未检测到值的占位数据需要特殊照顾。</p> 
  <p>老王觉得单机处理这些数据耗时太久，于是老王找来一些公司淘汰下来的旧服务器(一般小公司最破的机器都是服务器)，准备每个机器负责一部分，最后把结果汇总，老王在开发的过程中还是遇到了很多问题，比如，如何分配任务，有的机器破，有的机器新，还有的文件大，有的文件小，总是不能保证所有的任务一起完成，先完成任务的机器闲置浪费掉了资源;还有最后把结果通过网络通信汇总起来，如何保证数据不丢失，不覆盖;还有如果某台机器出了问题，如何重新分配任务，这些非核心业务的开发使得老王心力憔悴，还好，老王最后找到了Hadoop这个工具，这个工具给老王提供了一个简单的编程模型，老王在map方法中写了分配的任务的逻辑，在reduce方法中写了合并结果的逻辑，然后Hadoop帮老王完成了其他所有事情，Hadoop就是干这个的。以上故事纯属虚构，如有雷同，实属巧合。</p> 
  <p>其实上述意淫的例子里的数据量不是很大，如果每天产生上TB级别的数据，就算是速度很快的固态硬盘也需要小时级时间才能读取一遍，速度还是远远跟不上，终归有上限，而且高性能主机价格不菲，不如把数据分开放到一个相对廉价又可扩展的计算机集群中，每个节点上运行一段程序并处理一小块数据，然后在汇总处理结果，使用Hadoop可以让开发者不必把精力放在集群的建设上，采用Hadoop提供的简单的编程模型就可以实现分布式处理。</p> 
  <p>Hadoop的构造模块</p> 
  <p>Hadoop集群中运行的守护进程共有5类：</p> 
  <p>NameNode<br> DataNode<br> Secondary NameNode<br> JobTracker<br> TaskTracker</p> 
  <p>Hadoop集群中的机器(节点)分为2类：主节点和从节点，NameNode、JobTracker所在节点为主节点(负责管理)，DataNode和TaskTracker所在节点为从节点(负责干活儿)。</p> 
  <p>NameNode</p> 
  <p>NameNode节点负责将一个文件分成若干文件块，并记录了HDFS文件系统中的文件块放了在哪些DataNode中(一个数据块被冗余地放到1个或多个DataNode节点中)，一个集群中只有一个NameNode节点(Hadoop2.X中情况有所不同了)，且该节点通常不再运行DataNode和TaskTracker守护进程。</p> 
  <p>DataNode</p> 
  <p>DataNode实际管理很多NameNode分配给它的很多数据块，当有文件块变动时会通知NameNode，同时也从NameNode接受指令。一个集群中有多个DataNode节点，DataNode之间也会保持联系，复制冗余文件块，这样当一个DataNode出现故障后不会影响到文件的完整性。</p> 
  <p>Secondary NameNode</p> 
  <p>SNN只与NameNode通信，定时获取HDFS元数据的快照，一个集群只有一个SNN，且SNN所在节点只运行SNN守护进程，不干其它的事情。当NameNode出现故障后，可以人工启用SNN作为NameNode。</p> 
  <p>JobTracker</p> 
  <p>JobTracker负责分配MapReduce任务给TaskTracker，负责监控任务的执行，如任务失败后重启任务。JobTracker守护进程运行在主节点上，通常该节点不运行DataNode和TaskTracker守护进程。</p> 
  <p>TaskTracker</p> 
  <p>TaskTracker负责完成JobTracker分配的任务并和JobTranker进行通信，回报情况。TaskTracker守护进程运行在多个子节点上</p> 
  <p>在这里我还是要推荐下我自己建的大数据学习交流qq裙：522189307 ， 裙 里都是学大数据开发的，如果你正在学习大数据 ，小编欢迎你加入，大家都是软件开发党，不定期分享干货（只有大数据开发相关的），包括我自己整理的一份最新的大数据进阶资料和高级开发教程，欢迎进阶中和进想深入大数据的小伙伴。上述资料加群可以领取</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
