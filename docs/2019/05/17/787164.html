<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Hadoop大数据生态系统及常用组件简介 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Hadoop大数据生态系统及常用组件简介" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="经过多年信息化建设，我们已经进入一个神奇的“大数据”时代，无论是在通讯社交过程中使用的微信、QQ、电话、短信，还是吃喝玩乐时的用到的团购、电商、移动支付，都不断产生海量信息数据，数据和我们的工作生活密不可分、须臾难离。 什么是大数据 什么是大数据，多大算大，100G算大么?如果是用来存储1080P的高清电影，也就是几部影片的容量。但是如果100G都是文本数据，比如我们的后端kafka里的数据，抽取一条mobileTopic的数据如下：【107，5505323054626937，局域网，局域网，unknown，0，0，09f26f4fd5c9d757b9a3095607f8e1a27fe421c9，1468900733003】，这种数据100G能有多少条，我们可想而知。 &nbsp; &nbsp; 数据之所以为大，不但是因为数据量的巨大，同时各种渠道产生的数据既有IT系统生成的标准数据，还有大量多媒体类的非标准数据，数据类型多种多样，而且大量无用数据充斥其间，给数据的真实性带来很大影响，此外很多数据必须实时处理才最有价值。 一般数据量大(多)或者业务复杂的时候，常规技术无法及时、高效处理如此大量的数据，这时候可以使用Hadoop，它是由Apache基金会所开发的分布式系统基础架构，用户可以在不了解分布式底层细节的情况下，编写和运行分布式应用充分利用集群处理大规模数据。Hadoop可以构建在廉价的机器上，比如我们淘汰的PC Server或者租用的云主机都可以拿来用。 今天，就为大家介绍一下Hadoop生态圈一些常用的组件。 Gartner的一项研究表明，2015年，65%的分析应用程序和先进分析工具都将基于Hadoop平台，作为主流大数据处理技术，Hadoop具有以下特性： 方便：Hadoop运行在由一般商用机器构成的大型集群上，或者云计算服务上障。 可扩展：Hadoop通过增加集群节点，可以线性地扩展以处理更大的数据集。 目前应用Hadoop最多的领域有： 1) 搜索引擎，Doug Cutting设计Hadoop的初衷，就是为了针对大规模的网页快速建立索引。 2) 大数据存储，利用Hadoop的分布式存储能力，例如数据备份、数据仓库等。 3) 大数据处理，利用Hadoop的分布式处理能力，例如数据挖掘、数据分析等。 Hadoop生态系统与基础组 Hadoop2.0的时候引入了HA(高可用)与YARN(资源调度)，这是与1.0的最大差别。Hadoop主要由3部分组成：Mapreduce编程模型，HDFS分布式文件存储，与YARN。 &nbsp; &nbsp; 上图是Hadoop的生态系统，最下面一层是作为数据存储的HDFS，其他组件都是在HDFS的基础上组合或者使用的。HDFS具有高容错性、适合批处理、适合大数据处理、可构建在廉价机器上等优点，缺点是低延迟数据访问、小文件存取、并发写入、文件随机修改。 Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。这个定义里面有几个关键词：软件框架、并行处理、可靠且容错、大规模集群、海量数据集就是MapReduce的特色。 &nbsp; &nbsp; MapReduce经典代码(wordCount) 上面这段代码就是接收一堆文本数据，统计这些文本数据中每个单词出现的次数。MapReduce也是一个计算模型，当数据量很大时，比如10个G，它可以把这10G的数据分成10块，分发到10个节点去执行，然后再汇总，这就是并行计算，计算速度比你一台机器计算要快的多。 HBase Hadoop的主要组件介绍完毕，现在看下HBase，它是一个高可靠、高性能、面向列、可伸缩的分布式存储系统，利用Hbase技术可在廉价PC Server上搭建大规模结构化存储集群。HBase 是Google Bigtable 的开源实现，与Google Bigtable 利用GFS作为其文件存储系统类似，HBase 利用Hadoop HDFS 作为其文件存储系统;Google 运行MapReduce 来处理Bigtable中的海量数据， HBase 同样利用Hadoop MapReduce来处理HBase中的海量数据;Google Bigtable 利用Chubby作为协同服务， HBase 利用Zookeeper作为对应 有人问HBase和HDFS是啥关系，HBase是利用HDFS的存储的，就像MySQL和磁盘， MySQL是应用，磁盘是具体存储介质。HDFS因为自身的特性，不适合随机查找，对更新操作不太友好，比如百度网盘就是拿HDFS构建的，它支持上传和删除，但不会让用户直接在网盘上修改某个文件的内容。 HBase的表有以下特点： 1 ) 大：一个表可以有上亿行，上百万列。 2 ) 面向列：面向列表(簇)的存储和权限控制，列(簇)独立检索。 3 ) 稀疏：对于为空(NULL)的列，并不占用存储空间，因此，表可以设计的非常稀疏。 HBase提供的访问方式有命令行shell方式，java API(最高效和常用的)，Thrift Gateway 支持C ，PHP，Python等多种语言。 &nbsp; &nbsp; HBase在淘宝的应用场景 HBase的使用场景： 需对数据进行随机读操作或者随机写操作; 大数据上高并发操作，比如每秒对PB级数据进行上千次操作; 读写访问均是非常简单的操作，比如历史记录，历史订单查询，三大运营商的流量通话清单的查询。 Hive 之前我们说了MapReduce计算模型，但是只有懂Java的才能撸代码干这个事，不懂Java的想用Hadoop的计算模型是不是就没法搞了呢?比如HDFS里的海量数据，数据分析师想弄点数据出来，咋办?所以就要用到Hive，它提供了SQL式的访问方式供人使用。 Hive是由Facebook 开源，最初用于解决海量结构化的日志数据统计问题的ETL(Extraction-Transformation-Loading) 工具，Hive是构建在Hadoop上的数据仓库平台，设计目标是可以用传统SQL操作Hadoop上的数据，让熟悉SQL编程的人员也能拥抱Hadoop(注意。是数据仓库。不是数据库啊。) 使用HQL作为查询接口 使用HDFS作为底层存储 使用MapReduce作为执行层 所以说Hive就是基于Hadoop的一个数据仓库工具，是为简化MapReduce编程而生的，非常适合数据仓库的统计分析，通过解析SQL转化成MapReduce，组成一个DAG(有向无环图)来执行。 Flume Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(可定制)的能力。 当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng，由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。 &nbsp; &nbsp; Flume就是一个数据管道，支持很多源(source)，sink(目标)，和透视宝的suro很像，比如拉取nginx日志可以拿这个工具简单一配就可用。当然每台nginx服务器上都要配置并启动一个flume. 下面给大家看看配置文件(把kafka的数据写入hdfs的配置),配置很简单.完全免去了自己写一个kafka的consumer再调用hdfs的API写数据的工作量. &nbsp; &nbsp; YARN YARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：一个全局的资源调度器ResourceManager和每个应用程序特有的应用程序管理器ApplicationMaster，该调度器是一个 &quot;纯调度器&quot;，不再参与任何与具体应用程序逻辑相关的工作，而仅根据各个应用程序的资源需求进行分配，资源分配的单位用一个资源抽象概念 &quot;Container&quot; 来表示，Container 封装了内存和 CPU。此外，调度器是一个可插拔的组件，用户可根据自己的需求设计新的调度器，YARN 自身提供了 Fair Scheduler 和 Capacity Scheduler。 应用程序管理器负责管理整个系统中所有应用程序，包括应用程序的提交、与调度器协商资源以启动 ApplicationMaster、监控 ApplicationMaster 运行状态并在失败时重新启动等。 Ambari Ambari是一个集群的安装和管理工具，我们之前用的是Apache的Hadoop，运维同学用源码包安装，一个个配置文件去改，再分发到各个节点，中间哪一步搞错了，整个集群就启动不起来。所以有几个厂商提供Hadoop的这种安装和管理平台，主要是CDH和HDP，国内的很多人都用CDH的，它是Cloudera公司的，如果用它的管理界面安装，集群节点超过一定数量就要收费了。 Ambari是Apache的顶级开源项目，可以免费使用，现在用的人也很多。Ambari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时(比如，节点停机或磁盘剩余空间不足等问题)，系统将向其发送邮件。 ZooKeeper 随着计算节点的增多，集群成员需要彼此同步并了解去哪里访问服务和如何配置，ZooKeeper正是为此而生的。ZooKeeper 顾名思义就是动物园管理员，它是用来管大象(Hadoop) 、蜜蜂(Hive) 和 小猪(Pig) 的管理员， Apache Hbase和 Apache Solr 以及LinkedIn sensei等项目中都采用到了 Zookeeper。ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，以Fast Paxos算法为基础实现同步服务，配置维护和命名服务等分布式应用。 其他组件 以上介绍的都是Hadoop用来计算和查询的比较常用和主流的组件，上面那副生态图中的其他几个组件简单了解一下就好： Pig是一种编程语言，它简化了Hadoop常见的工作任务，Pig为大型数据集处理提供了更高层次的抽象，与MapReduce相比，Pig提供了更丰富的数据结构，一般都是多值和嵌套的数据结构。 Mahout是Hadoop提供做机器学习用的，支持的算法也比较少，但是一些常用的 k-means 聚类、分类还是有的，他是用MapReduce做的，但是MapReduce不太擅长这个东西，所以Mahout的作者也转投spark ML阵营了。 Sqoop是数据库ETL工具，用于将关系型数据库的数据导入到 Hadoop 及其相关的系统中，如 Hive和HBase。Sqoop 的核心设计思想是利用 MapReduce 加快数据传输速度，也就是说 Sqoop 的导入和导出功能是通过 MapReduce 作业实现的，所以它是一种批处理方式进行数据传输，难以实现实时数据的导入和导出。比如很多以前的业务数据都存在MySQL，随着数据量越来越大，要把数据导到Hbase，就可以拿Sqoop直接操作。 本文所介绍的东西都是用于离线计算的，而之前发布的《面临大数据挑战透视宝如何使用Druid实现数据聚合》则是关于实时计算的框架Druid的。大数据常用的流计算框架主要有Storm，Spark Streaming，Flink，Flink虽然是2014年加入Hadoop的，但至今在生产环境上用的人还不多，似乎大家都持观望态度。 说一下流计算(Druid，Spark Streaming)和批处理(MapReduce，Hive)有啥区别，比如电商网站的个性化广告投放，当我们访问了亚马逊搜索笔记本电脑之后，他就会给你推荐很多笔记本电脑链接，你的请求和兴趣爱好被亚马逊服务器实时接收，流计算分析之后当时就会推荐给你可能会购买的东西。如果这个东西拿批处理去做，服务端收集完了，过半个小时才算出你可能要买电脑，这时候再给你推荐电脑明显就不合适了，因为这时候你可能在搜索电炒锅…… &nbsp; &nbsp; 最后再说一下大数据的工作流，比如有两个MapReduce的任务是有依赖的，必须第一个完成了才能执行第二个，这就需要一个调度工具来调度。MapReduce也提供调度的API，但是代码要写很多，上面的代码截图只是一部分，这个依赖我写了大概150行。所以这时候出现了工作流，用工作流来管理我们的各个job，我目前知道的有oozie和azkaban，oozie的配置比较灵活，推荐大家使用。 在这里我还是要推荐下我自己建的大数据学习交流qq裙：522189307 ， 裙 里都是学大数据开发的，如果你正在学习大数据 ，小编欢迎你加入，大家都是软件开发党，不定期分享干货（只有大数据开发相关的），包括我自己整理的一份最新的大数据进阶资料和高级开发教程，欢迎进阶中和进想深入大数据的小伙伴。上述资料加群可以领取" />
<meta property="og:description" content="经过多年信息化建设，我们已经进入一个神奇的“大数据”时代，无论是在通讯社交过程中使用的微信、QQ、电话、短信，还是吃喝玩乐时的用到的团购、电商、移动支付，都不断产生海量信息数据，数据和我们的工作生活密不可分、须臾难离。 什么是大数据 什么是大数据，多大算大，100G算大么?如果是用来存储1080P的高清电影，也就是几部影片的容量。但是如果100G都是文本数据，比如我们的后端kafka里的数据，抽取一条mobileTopic的数据如下：【107，5505323054626937，局域网，局域网，unknown，0，0，09f26f4fd5c9d757b9a3095607f8e1a27fe421c9，1468900733003】，这种数据100G能有多少条，我们可想而知。 &nbsp; &nbsp; 数据之所以为大，不但是因为数据量的巨大，同时各种渠道产生的数据既有IT系统生成的标准数据，还有大量多媒体类的非标准数据，数据类型多种多样，而且大量无用数据充斥其间，给数据的真实性带来很大影响，此外很多数据必须实时处理才最有价值。 一般数据量大(多)或者业务复杂的时候，常规技术无法及时、高效处理如此大量的数据，这时候可以使用Hadoop，它是由Apache基金会所开发的分布式系统基础架构，用户可以在不了解分布式底层细节的情况下，编写和运行分布式应用充分利用集群处理大规模数据。Hadoop可以构建在廉价的机器上，比如我们淘汰的PC Server或者租用的云主机都可以拿来用。 今天，就为大家介绍一下Hadoop生态圈一些常用的组件。 Gartner的一项研究表明，2015年，65%的分析应用程序和先进分析工具都将基于Hadoop平台，作为主流大数据处理技术，Hadoop具有以下特性： 方便：Hadoop运行在由一般商用机器构成的大型集群上，或者云计算服务上障。 可扩展：Hadoop通过增加集群节点，可以线性地扩展以处理更大的数据集。 目前应用Hadoop最多的领域有： 1) 搜索引擎，Doug Cutting设计Hadoop的初衷，就是为了针对大规模的网页快速建立索引。 2) 大数据存储，利用Hadoop的分布式存储能力，例如数据备份、数据仓库等。 3) 大数据处理，利用Hadoop的分布式处理能力，例如数据挖掘、数据分析等。 Hadoop生态系统与基础组 Hadoop2.0的时候引入了HA(高可用)与YARN(资源调度)，这是与1.0的最大差别。Hadoop主要由3部分组成：Mapreduce编程模型，HDFS分布式文件存储，与YARN。 &nbsp; &nbsp; 上图是Hadoop的生态系统，最下面一层是作为数据存储的HDFS，其他组件都是在HDFS的基础上组合或者使用的。HDFS具有高容错性、适合批处理、适合大数据处理、可构建在廉价机器上等优点，缺点是低延迟数据访问、小文件存取、并发写入、文件随机修改。 Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。这个定义里面有几个关键词：软件框架、并行处理、可靠且容错、大规模集群、海量数据集就是MapReduce的特色。 &nbsp; &nbsp; MapReduce经典代码(wordCount) 上面这段代码就是接收一堆文本数据，统计这些文本数据中每个单词出现的次数。MapReduce也是一个计算模型，当数据量很大时，比如10个G，它可以把这10G的数据分成10块，分发到10个节点去执行，然后再汇总，这就是并行计算，计算速度比你一台机器计算要快的多。 HBase Hadoop的主要组件介绍完毕，现在看下HBase，它是一个高可靠、高性能、面向列、可伸缩的分布式存储系统，利用Hbase技术可在廉价PC Server上搭建大规模结构化存储集群。HBase 是Google Bigtable 的开源实现，与Google Bigtable 利用GFS作为其文件存储系统类似，HBase 利用Hadoop HDFS 作为其文件存储系统;Google 运行MapReduce 来处理Bigtable中的海量数据， HBase 同样利用Hadoop MapReduce来处理HBase中的海量数据;Google Bigtable 利用Chubby作为协同服务， HBase 利用Zookeeper作为对应 有人问HBase和HDFS是啥关系，HBase是利用HDFS的存储的，就像MySQL和磁盘， MySQL是应用，磁盘是具体存储介质。HDFS因为自身的特性，不适合随机查找，对更新操作不太友好，比如百度网盘就是拿HDFS构建的，它支持上传和删除，但不会让用户直接在网盘上修改某个文件的内容。 HBase的表有以下特点： 1 ) 大：一个表可以有上亿行，上百万列。 2 ) 面向列：面向列表(簇)的存储和权限控制，列(簇)独立检索。 3 ) 稀疏：对于为空(NULL)的列，并不占用存储空间，因此，表可以设计的非常稀疏。 HBase提供的访问方式有命令行shell方式，java API(最高效和常用的)，Thrift Gateway 支持C ，PHP，Python等多种语言。 &nbsp; &nbsp; HBase在淘宝的应用场景 HBase的使用场景： 需对数据进行随机读操作或者随机写操作; 大数据上高并发操作，比如每秒对PB级数据进行上千次操作; 读写访问均是非常简单的操作，比如历史记录，历史订单查询，三大运营商的流量通话清单的查询。 Hive 之前我们说了MapReduce计算模型，但是只有懂Java的才能撸代码干这个事，不懂Java的想用Hadoop的计算模型是不是就没法搞了呢?比如HDFS里的海量数据，数据分析师想弄点数据出来，咋办?所以就要用到Hive，它提供了SQL式的访问方式供人使用。 Hive是由Facebook 开源，最初用于解决海量结构化的日志数据统计问题的ETL(Extraction-Transformation-Loading) 工具，Hive是构建在Hadoop上的数据仓库平台，设计目标是可以用传统SQL操作Hadoop上的数据，让熟悉SQL编程的人员也能拥抱Hadoop(注意。是数据仓库。不是数据库啊。) 使用HQL作为查询接口 使用HDFS作为底层存储 使用MapReduce作为执行层 所以说Hive就是基于Hadoop的一个数据仓库工具，是为简化MapReduce编程而生的，非常适合数据仓库的统计分析，通过解析SQL转化成MapReduce，组成一个DAG(有向无环图)来执行。 Flume Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(可定制)的能力。 当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng，由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。 &nbsp; &nbsp; Flume就是一个数据管道，支持很多源(source)，sink(目标)，和透视宝的suro很像，比如拉取nginx日志可以拿这个工具简单一配就可用。当然每台nginx服务器上都要配置并启动一个flume. 下面给大家看看配置文件(把kafka的数据写入hdfs的配置),配置很简单.完全免去了自己写一个kafka的consumer再调用hdfs的API写数据的工作量. &nbsp; &nbsp; YARN YARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：一个全局的资源调度器ResourceManager和每个应用程序特有的应用程序管理器ApplicationMaster，该调度器是一个 &quot;纯调度器&quot;，不再参与任何与具体应用程序逻辑相关的工作，而仅根据各个应用程序的资源需求进行分配，资源分配的单位用一个资源抽象概念 &quot;Container&quot; 来表示，Container 封装了内存和 CPU。此外，调度器是一个可插拔的组件，用户可根据自己的需求设计新的调度器，YARN 自身提供了 Fair Scheduler 和 Capacity Scheduler。 应用程序管理器负责管理整个系统中所有应用程序，包括应用程序的提交、与调度器协商资源以启动 ApplicationMaster、监控 ApplicationMaster 运行状态并在失败时重新启动等。 Ambari Ambari是一个集群的安装和管理工具，我们之前用的是Apache的Hadoop，运维同学用源码包安装，一个个配置文件去改，再分发到各个节点，中间哪一步搞错了，整个集群就启动不起来。所以有几个厂商提供Hadoop的这种安装和管理平台，主要是CDH和HDP，国内的很多人都用CDH的，它是Cloudera公司的，如果用它的管理界面安装，集群节点超过一定数量就要收费了。 Ambari是Apache的顶级开源项目，可以免费使用，现在用的人也很多。Ambari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时(比如，节点停机或磁盘剩余空间不足等问题)，系统将向其发送邮件。 ZooKeeper 随着计算节点的增多，集群成员需要彼此同步并了解去哪里访问服务和如何配置，ZooKeeper正是为此而生的。ZooKeeper 顾名思义就是动物园管理员，它是用来管大象(Hadoop) 、蜜蜂(Hive) 和 小猪(Pig) 的管理员， Apache Hbase和 Apache Solr 以及LinkedIn sensei等项目中都采用到了 Zookeeper。ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，以Fast Paxos算法为基础实现同步服务，配置维护和命名服务等分布式应用。 其他组件 以上介绍的都是Hadoop用来计算和查询的比较常用和主流的组件，上面那副生态图中的其他几个组件简单了解一下就好： Pig是一种编程语言，它简化了Hadoop常见的工作任务，Pig为大型数据集处理提供了更高层次的抽象，与MapReduce相比，Pig提供了更丰富的数据结构，一般都是多值和嵌套的数据结构。 Mahout是Hadoop提供做机器学习用的，支持的算法也比较少，但是一些常用的 k-means 聚类、分类还是有的，他是用MapReduce做的，但是MapReduce不太擅长这个东西，所以Mahout的作者也转投spark ML阵营了。 Sqoop是数据库ETL工具，用于将关系型数据库的数据导入到 Hadoop 及其相关的系统中，如 Hive和HBase。Sqoop 的核心设计思想是利用 MapReduce 加快数据传输速度，也就是说 Sqoop 的导入和导出功能是通过 MapReduce 作业实现的，所以它是一种批处理方式进行数据传输，难以实现实时数据的导入和导出。比如很多以前的业务数据都存在MySQL，随着数据量越来越大，要把数据导到Hbase，就可以拿Sqoop直接操作。 本文所介绍的东西都是用于离线计算的，而之前发布的《面临大数据挑战透视宝如何使用Druid实现数据聚合》则是关于实时计算的框架Druid的。大数据常用的流计算框架主要有Storm，Spark Streaming，Flink，Flink虽然是2014年加入Hadoop的，但至今在生产环境上用的人还不多，似乎大家都持观望态度。 说一下流计算(Druid，Spark Streaming)和批处理(MapReduce，Hive)有啥区别，比如电商网站的个性化广告投放，当我们访问了亚马逊搜索笔记本电脑之后，他就会给你推荐很多笔记本电脑链接，你的请求和兴趣爱好被亚马逊服务器实时接收，流计算分析之后当时就会推荐给你可能会购买的东西。如果这个东西拿批处理去做，服务端收集完了，过半个小时才算出你可能要买电脑，这时候再给你推荐电脑明显就不合适了，因为这时候你可能在搜索电炒锅…… &nbsp; &nbsp; 最后再说一下大数据的工作流，比如有两个MapReduce的任务是有依赖的，必须第一个完成了才能执行第二个，这就需要一个调度工具来调度。MapReduce也提供调度的API，但是代码要写很多，上面的代码截图只是一部分，这个依赖我写了大概150行。所以这时候出现了工作流，用工作流来管理我们的各个job，我目前知道的有oozie和azkaban，oozie的配置比较灵活，推荐大家使用。 在这里我还是要推荐下我自己建的大数据学习交流qq裙：522189307 ， 裙 里都是学大数据开发的，如果你正在学习大数据 ，小编欢迎你加入，大家都是软件开发党，不定期分享干货（只有大数据开发相关的），包括我自己整理的一份最新的大数据进阶资料和高级开发教程，欢迎进阶中和进想深入大数据的小伙伴。上述资料加群可以领取" />
<link rel="canonical" href="https://mlh.app/2019/05/17/787164.html" />
<meta property="og:url" content="https://mlh.app/2019/05/17/787164.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"经过多年信息化建设，我们已经进入一个神奇的“大数据”时代，无论是在通讯社交过程中使用的微信、QQ、电话、短信，还是吃喝玩乐时的用到的团购、电商、移动支付，都不断产生海量信息数据，数据和我们的工作生活密不可分、须臾难离。 什么是大数据 什么是大数据，多大算大，100G算大么?如果是用来存储1080P的高清电影，也就是几部影片的容量。但是如果100G都是文本数据，比如我们的后端kafka里的数据，抽取一条mobileTopic的数据如下：【107，5505323054626937，局域网，局域网，unknown，0，0，09f26f4fd5c9d757b9a3095607f8e1a27fe421c9，1468900733003】，这种数据100G能有多少条，我们可想而知。 &nbsp; &nbsp; 数据之所以为大，不但是因为数据量的巨大，同时各种渠道产生的数据既有IT系统生成的标准数据，还有大量多媒体类的非标准数据，数据类型多种多样，而且大量无用数据充斥其间，给数据的真实性带来很大影响，此外很多数据必须实时处理才最有价值。 一般数据量大(多)或者业务复杂的时候，常规技术无法及时、高效处理如此大量的数据，这时候可以使用Hadoop，它是由Apache基金会所开发的分布式系统基础架构，用户可以在不了解分布式底层细节的情况下，编写和运行分布式应用充分利用集群处理大规模数据。Hadoop可以构建在廉价的机器上，比如我们淘汰的PC Server或者租用的云主机都可以拿来用。 今天，就为大家介绍一下Hadoop生态圈一些常用的组件。 Gartner的一项研究表明，2015年，65%的分析应用程序和先进分析工具都将基于Hadoop平台，作为主流大数据处理技术，Hadoop具有以下特性： 方便：Hadoop运行在由一般商用机器构成的大型集群上，或者云计算服务上障。 可扩展：Hadoop通过增加集群节点，可以线性地扩展以处理更大的数据集。 目前应用Hadoop最多的领域有： 1) 搜索引擎，Doug Cutting设计Hadoop的初衷，就是为了针对大规模的网页快速建立索引。 2) 大数据存储，利用Hadoop的分布式存储能力，例如数据备份、数据仓库等。 3) 大数据处理，利用Hadoop的分布式处理能力，例如数据挖掘、数据分析等。 Hadoop生态系统与基础组 Hadoop2.0的时候引入了HA(高可用)与YARN(资源调度)，这是与1.0的最大差别。Hadoop主要由3部分组成：Mapreduce编程模型，HDFS分布式文件存储，与YARN。 &nbsp; &nbsp; 上图是Hadoop的生态系统，最下面一层是作为数据存储的HDFS，其他组件都是在HDFS的基础上组合或者使用的。HDFS具有高容错性、适合批处理、适合大数据处理、可构建在廉价机器上等优点，缺点是低延迟数据访问、小文件存取、并发写入、文件随机修改。 Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。这个定义里面有几个关键词：软件框架、并行处理、可靠且容错、大规模集群、海量数据集就是MapReduce的特色。 &nbsp; &nbsp; MapReduce经典代码(wordCount) 上面这段代码就是接收一堆文本数据，统计这些文本数据中每个单词出现的次数。MapReduce也是一个计算模型，当数据量很大时，比如10个G，它可以把这10G的数据分成10块，分发到10个节点去执行，然后再汇总，这就是并行计算，计算速度比你一台机器计算要快的多。 HBase Hadoop的主要组件介绍完毕，现在看下HBase，它是一个高可靠、高性能、面向列、可伸缩的分布式存储系统，利用Hbase技术可在廉价PC Server上搭建大规模结构化存储集群。HBase 是Google Bigtable 的开源实现，与Google Bigtable 利用GFS作为其文件存储系统类似，HBase 利用Hadoop HDFS 作为其文件存储系统;Google 运行MapReduce 来处理Bigtable中的海量数据， HBase 同样利用Hadoop MapReduce来处理HBase中的海量数据;Google Bigtable 利用Chubby作为协同服务， HBase 利用Zookeeper作为对应 有人问HBase和HDFS是啥关系，HBase是利用HDFS的存储的，就像MySQL和磁盘， MySQL是应用，磁盘是具体存储介质。HDFS因为自身的特性，不适合随机查找，对更新操作不太友好，比如百度网盘就是拿HDFS构建的，它支持上传和删除，但不会让用户直接在网盘上修改某个文件的内容。 HBase的表有以下特点： 1 ) 大：一个表可以有上亿行，上百万列。 2 ) 面向列：面向列表(簇)的存储和权限控制，列(簇)独立检索。 3 ) 稀疏：对于为空(NULL)的列，并不占用存储空间，因此，表可以设计的非常稀疏。 HBase提供的访问方式有命令行shell方式，java API(最高效和常用的)，Thrift Gateway 支持C ，PHP，Python等多种语言。 &nbsp; &nbsp; HBase在淘宝的应用场景 HBase的使用场景： 需对数据进行随机读操作或者随机写操作; 大数据上高并发操作，比如每秒对PB级数据进行上千次操作; 读写访问均是非常简单的操作，比如历史记录，历史订单查询，三大运营商的流量通话清单的查询。 Hive 之前我们说了MapReduce计算模型，但是只有懂Java的才能撸代码干这个事，不懂Java的想用Hadoop的计算模型是不是就没法搞了呢?比如HDFS里的海量数据，数据分析师想弄点数据出来，咋办?所以就要用到Hive，它提供了SQL式的访问方式供人使用。 Hive是由Facebook 开源，最初用于解决海量结构化的日志数据统计问题的ETL(Extraction-Transformation-Loading) 工具，Hive是构建在Hadoop上的数据仓库平台，设计目标是可以用传统SQL操作Hadoop上的数据，让熟悉SQL编程的人员也能拥抱Hadoop(注意。是数据仓库。不是数据库啊。) 使用HQL作为查询接口 使用HDFS作为底层存储 使用MapReduce作为执行层 所以说Hive就是基于Hadoop的一个数据仓库工具，是为简化MapReduce编程而生的，非常适合数据仓库的统计分析，通过解析SQL转化成MapReduce，组成一个DAG(有向无环图)来执行。 Flume Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(可定制)的能力。 当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng，由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。 &nbsp; &nbsp; Flume就是一个数据管道，支持很多源(source)，sink(目标)，和透视宝的suro很像，比如拉取nginx日志可以拿这个工具简单一配就可用。当然每台nginx服务器上都要配置并启动一个flume. 下面给大家看看配置文件(把kafka的数据写入hdfs的配置),配置很简单.完全免去了自己写一个kafka的consumer再调用hdfs的API写数据的工作量. &nbsp; &nbsp; YARN YARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：一个全局的资源调度器ResourceManager和每个应用程序特有的应用程序管理器ApplicationMaster，该调度器是一个 &quot;纯调度器&quot;，不再参与任何与具体应用程序逻辑相关的工作，而仅根据各个应用程序的资源需求进行分配，资源分配的单位用一个资源抽象概念 &quot;Container&quot; 来表示，Container 封装了内存和 CPU。此外，调度器是一个可插拔的组件，用户可根据自己的需求设计新的调度器，YARN 自身提供了 Fair Scheduler 和 Capacity Scheduler。 应用程序管理器负责管理整个系统中所有应用程序，包括应用程序的提交、与调度器协商资源以启动 ApplicationMaster、监控 ApplicationMaster 运行状态并在失败时重新启动等。 Ambari Ambari是一个集群的安装和管理工具，我们之前用的是Apache的Hadoop，运维同学用源码包安装，一个个配置文件去改，再分发到各个节点，中间哪一步搞错了，整个集群就启动不起来。所以有几个厂商提供Hadoop的这种安装和管理平台，主要是CDH和HDP，国内的很多人都用CDH的，它是Cloudera公司的，如果用它的管理界面安装，集群节点超过一定数量就要收费了。 Ambari是Apache的顶级开源项目，可以免费使用，现在用的人也很多。Ambari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时(比如，节点停机或磁盘剩余空间不足等问题)，系统将向其发送邮件。 ZooKeeper 随着计算节点的增多，集群成员需要彼此同步并了解去哪里访问服务和如何配置，ZooKeeper正是为此而生的。ZooKeeper 顾名思义就是动物园管理员，它是用来管大象(Hadoop) 、蜜蜂(Hive) 和 小猪(Pig) 的管理员， Apache Hbase和 Apache Solr 以及LinkedIn sensei等项目中都采用到了 Zookeeper。ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，以Fast Paxos算法为基础实现同步服务，配置维护和命名服务等分布式应用。 其他组件 以上介绍的都是Hadoop用来计算和查询的比较常用和主流的组件，上面那副生态图中的其他几个组件简单了解一下就好： Pig是一种编程语言，它简化了Hadoop常见的工作任务，Pig为大型数据集处理提供了更高层次的抽象，与MapReduce相比，Pig提供了更丰富的数据结构，一般都是多值和嵌套的数据结构。 Mahout是Hadoop提供做机器学习用的，支持的算法也比较少，但是一些常用的 k-means 聚类、分类还是有的，他是用MapReduce做的，但是MapReduce不太擅长这个东西，所以Mahout的作者也转投spark ML阵营了。 Sqoop是数据库ETL工具，用于将关系型数据库的数据导入到 Hadoop 及其相关的系统中，如 Hive和HBase。Sqoop 的核心设计思想是利用 MapReduce 加快数据传输速度，也就是说 Sqoop 的导入和导出功能是通过 MapReduce 作业实现的，所以它是一种批处理方式进行数据传输，难以实现实时数据的导入和导出。比如很多以前的业务数据都存在MySQL，随着数据量越来越大，要把数据导到Hbase，就可以拿Sqoop直接操作。 本文所介绍的东西都是用于离线计算的，而之前发布的《面临大数据挑战透视宝如何使用Druid实现数据聚合》则是关于实时计算的框架Druid的。大数据常用的流计算框架主要有Storm，Spark Streaming，Flink，Flink虽然是2014年加入Hadoop的，但至今在生产环境上用的人还不多，似乎大家都持观望态度。 说一下流计算(Druid，Spark Streaming)和批处理(MapReduce，Hive)有啥区别，比如电商网站的个性化广告投放，当我们访问了亚马逊搜索笔记本电脑之后，他就会给你推荐很多笔记本电脑链接，你的请求和兴趣爱好被亚马逊服务器实时接收，流计算分析之后当时就会推荐给你可能会购买的东西。如果这个东西拿批处理去做，服务端收集完了，过半个小时才算出你可能要买电脑，这时候再给你推荐电脑明显就不合适了，因为这时候你可能在搜索电炒锅…… &nbsp; &nbsp; 最后再说一下大数据的工作流，比如有两个MapReduce的任务是有依赖的，必须第一个完成了才能执行第二个，这就需要一个调度工具来调度。MapReduce也提供调度的API，但是代码要写很多，上面的代码截图只是一部分，这个依赖我写了大概150行。所以这时候出现了工作流，用工作流来管理我们的各个job，我目前知道的有oozie和azkaban，oozie的配置比较灵活，推荐大家使用。 在这里我还是要推荐下我自己建的大数据学习交流qq裙：522189307 ， 裙 里都是学大数据开发的，如果你正在学习大数据 ，小编欢迎你加入，大家都是软件开发党，不定期分享干货（只有大数据开发相关的），包括我自己整理的一份最新的大数据进阶资料和高级开发教程，欢迎进阶中和进想深入大数据的小伙伴。上述资料加群可以领取","@type":"BlogPosting","url":"https://mlh.app/2019/05/17/787164.html","headline":"Hadoop大数据生态系统及常用组件简介","dateModified":"2019-05-17T00:00:00+08:00","datePublished":"2019-05-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/17/787164.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Hadoop大数据生态系统及常用组件简介</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>经过多年信息化建设，我们已经进入一个神奇的<a href="http://www.raincent.com/" rel="nofollow">“大数据”时代</a>，无论是在通讯社交过程中使用的微信、QQ、电话、短信，还是吃喝玩乐时的用到的团购、电商、移动支付，都不断产生海量信息数据，数据和我们的工作生活密不可分、须臾难离。</p> 
  <p><strong>什么是大数据</strong></p> 
  <p>什么是大数据，多大算大，100G算大么?如果是用来存储1080P的高清电影，也就是几部影片的容量。但是如果100G都是文本数据，比如我们的后端kafka里的数据，抽取一条mobileTopic的数据如下：【107，5505323054626937，局域网，局域网，unknown，0，0，09f26f4fd5c9d757b9a3095607f8e1a27fe421c9，1468900733003】，这种数据100G能有多少条，我们可想而知。</p> 
  <p>&nbsp;</p> 
  <p><img alt="Hadoop大数据生态系统及常用组件简介" class="has" height="181" src="http://www.raincent.com/uploadfile/2016/0728/20160728033315602.jpg" width="540"></p> 
  <p>&nbsp;</p> 
  <p>数据之所以为大，不但是因为数据量的巨大，同时各种渠道产生的数据既有IT系统生成的标准数据，还有大量多媒体类的非标准数据，数据类型多种多样，而且大量无用数据充斥其间，给数据的真实性带来很大影响，此外很多数据必须实时处理才最有价值。</p> 
  <p>一般数据量大(多)或者业务复杂的时候，常规技术无法及时、高效处理如此大量的数据，这时候可以使用Hadoop，它是由Apache基金会所开发的分布式系统基础架构，用户可以在不了解分布式底层细节的情况下，编写和运行分布式应用充分利用集群处理大规模数据。Hadoop可以构建在廉价的机器上，比如我们淘汰的PC Server或者租用的云主机都可以拿来用。</p> 
  <p><strong>今天，就为大家介绍一下Hadoop生态圈一些常用的组件。</strong></p> 
  <p>Gartner的一项研究表明，2015年，65%的分析应用程序和先进分析工具都将基于Hadoop平台，作为主流大数据处理技术，Hadoop具有以下特性：</p> 
  <p>方便：Hadoop运行在由一般商用机器构成的大型集群上，或者云计算服务上障。</p> 
  <p>可扩展：Hadoop通过增加集群节点，可以线性地扩展以处理更大的数据集。</p> 
  <p><strong>目前应用Hadoop最多的领域有：</strong></p> 
  <p>1) 搜索引擎，Doug Cutting设计Hadoop的初衷，就是为了针对大规模的网页快速建立索引。</p> 
  <p>2) 大数据存储，利用Hadoop的分布式存储能力，例如数据备份、数据仓库等。</p> 
  <p>3) 大数据处理，利用Hadoop的分布式处理能力，例如数据挖掘、数据分析等。</p> 
  <p><strong>Hadoop生态系统与基础组</strong></p> 
  <p>Hadoop2.0的时候引入了HA(高可用)与YARN(资源调度)，这是与1.0的最大差别。Hadoop主要由3部分组成：Mapreduce编程模型，HDFS分布式文件存储，与YARN。</p> 
  <p>&nbsp;</p> 
  <p><img alt="Hadoop大数据生态系统及常用组件简介" class="has" height="284" src="http://www.raincent.com/uploadfile/2016/0728/20160728033315734.jpg" width="544"></p> 
  <p>&nbsp;</p> 
  <p>上图是Hadoop的生态系统，最下面一层是作为数据存储的HDFS，其他组件都是在HDFS的基础上组合或者使用的。HDFS具有高容错性、适合批处理、适合大数据处理、可构建在廉价机器上等优点，缺点是低延迟数据访问、小文件存取、并发写入、文件随机修改。</p> 
  <p>Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集。这个定义里面有几个关键词：软件框架、并行处理、可靠且容错、大规模集群、海量数据集就是MapReduce的特色。</p> 
  <p>&nbsp;</p> 
  <p><img alt="Hadoop大数据生态系统及常用组件简介" class="has" height="303" src="http://www.raincent.com/uploadfile/2016/0728/20160728033315459.jpg" width="521"></p> 
  <p>&nbsp;</p> 
  <p>MapReduce经典代码(wordCount)</p> 
  <p>上面这段代码就是接收一堆文本数据，统计这些文本数据中每个单词出现的次数。MapReduce也是一个计算模型，当数据量很大时，比如10个G，它可以把这10G的数据分成10块，分发到10个节点去执行，然后再汇总，这就是并行计算，计算速度比你一台机器计算要快的多。</p> 
  <p><strong>HBase</strong></p> 
  <p>Hadoop的主要组件介绍完毕，现在看下HBase，它是一个高可靠、高性能、面向列、可伸缩的分布式存储系统，利用Hbase技术可在廉价PC Server上搭建大规模结构化存储集群。HBase 是Google Bigtable 的开源实现，与Google Bigtable 利用GFS作为其文件存储系统类似，HBase 利用Hadoop HDFS 作为其文件存储系统;Google 运行MapReduce 来处理Bigtable中的海量数据， HBase 同样利用Hadoop MapReduce来处理HBase中的海量数据;Google Bigtable 利用Chubby作为协同服务， HBase 利用Zookeeper作为对应</p> 
  <p>有人问HBase和HDFS是啥关系，HBase是利用HDFS的存储的，就像MySQL和磁盘， MySQL是应用，磁盘是具体存储介质。HDFS因为自身的特性，不适合随机查找，对更新操作不太友好，比如百度网盘就是拿HDFS构建的，它支持上传和删除，但不会让用户直接在网盘上修改某个文件的内容。</p> 
  <p><strong>HBase的表有以下特点：</strong></p> 
  <p>1 ) 大：一个表可以有上亿行，上百万列。</p> 
  <p>2 ) 面向列：面向列表(簇)的存储和权限控制，列(簇)独立检索。</p> 
  <p>3 ) 稀疏：对于为空(NULL)的列，并不占用存储空间，因此，表可以设计的非常稀疏。</p> 
  <p>HBase提供的访问方式有命令行shell方式，java API(最高效和常用的)，Thrift Gateway 支持C ，PHP，Python等多种语言。</p> 
  <p>&nbsp;</p> 
  <p><img alt="Hadoop大数据生态系统及常用组件简介" class="has" height="292" src="http://www.raincent.com/uploadfile/2016/0728/20160728033315737.jpg" width="517"></p> 
  <p>&nbsp;</p> 
  <p>HBase在淘宝的应用场景</p> 
  <p>HBase的使用场景：</p> 
  <p>需对数据进行随机读操作或者随机写操作;<br> 大数据上高并发操作，比如每秒对PB级数据进行上千次操作;<br> 读写访问均是非常简单的操作，比如历史记录，历史订单查询，三大运营商的流量通话清单的查询。</p> 
  <p><strong>Hive</strong></p> 
  <p>之前我们说了MapReduce计算模型，但是只有懂Java的才能撸代码干这个事，不懂Java的想用Hadoop的计算模型是不是就没法搞了呢?比如HDFS里的海量数据，数据分析师想弄点数据出来，咋办?所以就要用到Hive，它提供了SQL式的访问方式供人使用。</p> 
  <p>Hive是由Facebook 开源，最初用于解决海量结构化的日志数据统计问题的ETL(Extraction-Transformation-Loading) 工具，Hive是构建在Hadoop上的数据仓库平台，设计目标是可以用传统SQL操作Hadoop上的数据，让熟悉SQL编程的人员也能拥抱Hadoop(注意。是数据仓库。不是数据库啊。)</p> 
  <p>使用HQL作为查询接口<br> 使用HDFS作为底层存储<br> 使用MapReduce作为执行层</p> 
  <p>所以说Hive就是基于Hadoop的一个数据仓库工具，是为简化MapReduce编程而生的，非常适合数据仓库的统计分析，通过解析SQL转化成MapReduce，组成一个DAG(有向无环图)来执行。</p> 
  <p><strong>Flume</strong></p> 
  <p>Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，Flume支持在日志系统中定制各类数据发送方，用于收集数据;同时，Flume提供对数据进行简单处理，并写到各种数据接受方(可定制)的能力。</p> 
  <p>当前Flume有两个版本Flume 0.9X版本的统称Flume-og，Flume1.X版本的统称Flume-ng，由于Flume-ng经过重大重构，与Flume-og有很大不同，使用时请注意区分。</p> 
  <p>&nbsp;</p> 
  <p><img alt="Hadoop大数据生态系统及常用组件简介" class="has" height="240" src="http://www.raincent.com/uploadfile/2016/0728/20160728033317801.jpg" width="576"></p> 
  <p>&nbsp;</p> 
  <p>Flume就是一个数据管道，支持很多源(source)，sink(目标)，和透视宝的suro很像，比如拉取nginx日志可以拿这个工具简单一配就可用。当然每台nginx服务器上都要配置并启动一个flume.</p> 
  <p>下面给大家看看配置文件(把kafka的数据写入hdfs的配置),配置很简单.完全免去了自己写一个kafka的consumer再调用hdfs的API写数据的工作量.</p> 
  <p>&nbsp;</p> 
  <p><img alt="Hadoop大数据生态系统及常用组件简介" class="has" height="392" src="http://www.raincent.com/uploadfile/2016/0728/20160728033317943.jpg" width="498"></p> 
  <p>&nbsp;</p> 
  <p><strong>YARN</strong></p> 
  <p>YARN是Hadoop 2.0中的资源管理系统，它的基本设计思想是将MRv1中的JobTracker拆分成了两个独立的服务：一个全局的资源调度器ResourceManager和每个应用程序特有的应用程序管理器ApplicationMaster，该调度器是一个 "纯调度器"，不再参与任何与具体应用程序逻辑相关的工作，而仅根据各个应用程序的资源需求进行分配，资源分配的单位用一个资源抽象概念 "Container" 来表示，Container 封装了内存和 CPU。此外，调度器是一个可插拔的组件，用户可根据自己的需求设计新的调度器，YARN 自身提供了 Fair Scheduler 和 Capacity Scheduler。</p> 
  <p>应用程序管理器负责管理整个系统中所有应用程序，包括应用程序的提交、与调度器协商资源以启动 ApplicationMaster、监控 ApplicationMaster 运行状态并在失败时重新启动等。</p> 
  <p><strong>Ambari</strong></p> 
  <p>Ambari是一个集群的安装和管理工具，我们之前用的是Apache的Hadoop，运维同学用源码包安装，一个个配置文件去改，再分发到各个节点，中间哪一步搞错了，整个集群就启动不起来。所以有几个厂商提供Hadoop的这种安装和管理平台，主要是CDH和HDP，国内的很多人都用CDH的，它是Cloudera公司的，如果用它的管理界面安装，集群节点超过一定数量就要收费了。</p> 
  <p>Ambari是Apache的顶级开源项目，可以免费使用，现在用的人也很多。Ambari使用Ganglia收集度量指标，用Nagios支持系统报警，当需要引起管理员的关注时(比如，节点停机或磁盘剩余空间不足等问题)，系统将向其发送邮件。</p> 
  <p><strong>ZooKeeper</strong></p> 
  <p><strong>随着计算节点</strong>的增多，集群成员需要彼此同步并了解去哪里访问服务和如何配置，ZooKeeper正是为此而生的。ZooKeeper 顾名思义就是动物园管理员，它是用来管大象(Hadoop) 、蜜蜂(Hive) 和 小猪(Pig) 的管理员， Apache Hbase和 Apache Solr 以及LinkedIn sensei等项目中都采用到了 Zookeeper。ZooKeeper是一个分布式的，开放源码的分布式应用程序协调服务，以Fast Paxos算法为基础实现同步服务，配置维护和命名服务等分布式应用。</p> 
  <p><strong>其他组件</strong></p> 
  <p>以上介绍的都是Hadoop用来计算和查询的比较常用和主流的组件，上面那副生态图中的其他几个组件简单了解一下就好：</p> 
  <p>Pig是一种编程语言，它简化了Hadoop常见的工作任务，Pig为大型数据集处理提供了更高层次的抽象，与MapReduce相比，Pig提供了更丰富的数据结构，一般都是多值和嵌套的数据结构。</p> 
  <p>Mahout是Hadoop提供做机器学习用的，支持的算法也比较少，但是一些常用的 k-means 聚类、分类还是有的，他是用MapReduce做的，但是MapReduce不太擅长这个东西，所以Mahout的作者也转投spark ML阵营了。</p> 
  <p>Sqoop是数据库ETL工具，用于将关系型数据库的数据导入到 Hadoop 及其相关的系统中，如 Hive和HBase。Sqoop 的核心设计思想是利用 MapReduce 加快数据传输速度，也就是说 Sqoop 的导入和导出功能是通过 MapReduce 作业实现的，所以它是一种批处理方式进行数据传输，难以实现实时数据的导入和导出。比如很多以前的业务数据都存在MySQL，随着数据量越来越大，要把数据导到Hbase，就可以拿Sqoop直接操作。</p> 
  <p>本文所介绍的东西都是用于离线计算的，而之前发布的《面临大数据挑战透视宝如何使用Druid实现数据聚合》则是关于实时计算的框架Druid的。大数据常用的流计算框架主要有Storm，Spark Streaming，Flink，Flink虽然是2014年加入Hadoop的，但至今在生产环境上用的人还不多，似乎大家都持观望态度。</p> 
  <p>说一下流计算(Druid，Spark Streaming)和批处理(MapReduce，Hive)有啥区别，比如电商网站的个性化广告投放，当我们访问了亚马逊搜索笔记本电脑之后，他就会给你推荐很多笔记本电脑链接，你的请求和兴趣爱好被亚马逊服务器实时接收，流计算分析之后当时就会推荐给你可能会购买的东西。如果这个东西拿批处理去做，服务端收集完了，过半个小时才算出你可能要买电脑，这时候再给你推荐电脑明显就不合适了，因为这时候你可能在搜索电炒锅……</p> 
  <p>&nbsp;</p> 
  <p><img alt="Hadoop大数据生态系统及常用组件简介" class="has" height="279" src="http://www.raincent.com/uploadfile/2016/0728/20160728033317270.jpg" width="502"></p> 
  <p>&nbsp;</p> 
  <p>最后再说一下大数据的工作流，比如有两个MapReduce的任务是有依赖的，必须第一个完成了才能执行第二个，这就需要一个调度工具来调度。MapReduce也提供调度的API，但是代码要写很多，上面的代码截图只是一部分，这个依赖我写了大概150行。所以这时候出现了工作流，用工作流来管理我们的各个job，我目前知道的有oozie和azkaban，oozie的配置比较灵活，推荐大家使用。</p> 
  <p>在这里我还是要推荐下我自己建的大数据学习交流qq裙：522189307 ， 裙 里都是学大数据开发的，如果你正在学习大数据 ，小编欢迎你加入，大家都是软件开发党，不定期分享干货（只有大数据开发相关的），包括我自己整理的一份最新的大数据进阶资料和高级开发教程，欢迎进阶中和进想深入大数据的小伙伴。上述资料加群可以领取</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
