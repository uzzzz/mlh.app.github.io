<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>深度学习 Keras入门 一 之基础篇 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="深度学习 Keras入门 一 之基础篇" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.关于Keras 1）简介 Keras是由纯python编写的基于theano/tensorflow的深度学习框架。 Keras是一个高层神经网络API，支持快速实验，能够把你的idea迅速转换为结果，如果有如下需求，可以优先选择Keras： a）简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性） b）支持CNN和RNN，或二者的结合 c）无缝CPU和GPU切换 2）设计原则 a）用户友好：Keras是为人类而不是天顶星人设计的API。用户的使用体验始终是我们考虑的首要和中心内容。Keras遵循减少认知困难的最佳实践：Keras提供一致而简洁的API， 能够极大减少一般应用下用户的工作量，同时，Keras提供清晰和具有实践意义的bug反馈。 b）模块性：模型可理解为一个层的序列或数据的运算图，完全可配置的模块可以用最少的代价自由组合在一起。具体而言，网络层、损失函数、优化器、初始化策略、激活函数、正则化方法都是独立的模块，你可以使用它们来构建自己的模型。 c）易扩展性：添加新模块超级容易，只需要仿照现有的模块编写新的类或函数即可。创建新模块的便利性使得Keras更适合于先进的研究工作。 d）与Python协作：Keras没有单独的模型配置文件类型（作为对比，caffe有），模型由python代码描述，使其更紧凑和更易debug，并提供了扩展的便利性。 如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击这里可以查看教程。 2.Keras的模块结构 &nbsp; &nbsp; &nbsp; 3.使用Keras搭建一个神经网络 &nbsp; 4.主要概念 &nbsp; &nbsp;1）符号计算 &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。符号计算首先定义各种变量，然后建立一个“计算图”,计算图规定了各个变量之间的计算关系。 &nbsp; &nbsp; &nbsp; &nbsp;符号计算也叫数据流图，其过程如下(gif图不好打开，所以用了静态图，数据是按图中黑色带箭头的线流动的)： &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;2）张量 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 张量(tensor)，可以看作是向量、矩阵的自然推广，用来表示广泛的数据类型。张量的阶数也叫维度。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0阶张量,即标量,是一个数。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1阶张量,即向量,一组有序排列的数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2阶张量,即矩阵,一组向量有序的排列起来 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3阶张量，即立方体，一组矩阵上下排列起来 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4阶张量......&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 依次类推 &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 重点：关于维度的理解 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 假如有一个10长度的列表，那么我们横向看有10个数字，也可以叫做10维度，纵向看只能看到1个数字，那么就叫1维度。注意这个区别有助于理解Keras或者神经网络中计算时出现的维度问题。 &nbsp; &nbsp; 3）数据格式(data_format) &nbsp; &nbsp; &nbsp; &nbsp; 目前主要有两种方式来表示张量：&nbsp; &nbsp; &nbsp; &nbsp; a) th模式或channels_first模式，Theano和caffe使用此模式。&nbsp; &nbsp; &nbsp; &nbsp; b）tf模式或channels_last模式，TensorFlow使用此模式。 &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 下面举例说明两种模式的区别：&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;对于100张RGB3通道的16×32（高为16宽为32）彩色图，&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;th表示方式：（100,3,16,32）&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;tf表示方式：（100,16,32,3）&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;唯一的区别就是表示通道个数3的位置不一样。 &nbsp; &nbsp; &nbsp;4）模型 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Keras有两种类型的模型，序贯模型（Sequential）和函数式模型（Model），函数式模型应用更为广泛，序贯模型是函数式模型的一种特殊情况。&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）序贯模型（Sequential):单输入单输出，一条路通到底，层与层之间只有相邻关系，没有跨层连接。这种模型编译速度快，操作也比较简单&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）函数式模型（Model）：多输入多输出，层与层之间任意连接。这种模型编译速度慢。 &nbsp; 5.第一个示例 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 这里也采用介绍神经网络时常用的一个例子：手写数字的识别。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 在写代码之前，基于这个例子介绍一些概念，方便大家理解。 &nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; PS：可能是版本差异的问题，官网中的参数和示例中的参数是不一样的，官网中给出的参数少，并且有些参数支持，有些不支持。所以此例子去掉了不支持的参数，并且只介绍本例中用到的参数。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1）Dense(500,input_shape=(784,)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;a）Dense层属于网络层--&gt;常用层中的一个层 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;b） 500表示输出的维度，完整的输出表示：(*,500)：即输出任意个500维的数据流。但是在参数中只写维度就可以了，比较具体输出多少个是有输入确定的。换个说法，Dense的输出其实是个N×500的矩阵。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; c）input_shape(784,) 表示输入维度是784(28×28，后面具体介绍为什么)，完整的输入表示：(*,784)：即输入N个784维度的数据 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2）Activation(&#39;tanh&#39;) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）Activation：激活层 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）&#39;tanh&#39; ：激活函数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3）Dropout(0.5) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;在训练过程中每次更新参数时随机断开一定百分比（rate）的输入神经元，防止过拟合。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4）数据集 &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;数据集包括60000张28×28的训练集和10000张28×28的测试集及其对应的目标数字。如果完全按照上述数据格式表述，以tensorflow作为后端应该是（60000,28,28,3），因为示例中采用了mnist.load_data()获取数据集，所以已经判断使用了tensorflow作为后端，因此数据集就变成了(60000,28,28),那么input_shape(784,)应该是input_shape(28,28，)才对，但是在这个示例中这么写是不对的，需要转换成(60000,784),才可以。为什么需要转换呢？ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 如上图，训练集(60000,28,28)作为输入，就相当于一个立方体，而输入层从当前角度看就是一个平面，立方体的数据流怎么进入平面的输入层进行计算呢？所以需要进行黄色箭头所示的变换，然后才进入输入层进行后续计算。至于从28*28变换成784之后输入层如何处理，就不需要我们关心了。(喜欢钻研的同学可以去研究下源代码)。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;并且，Keras中输入多为(nb_samples, input_dim)的形式：即(样本数量，输入维度)。 &nbsp; &nbsp; &nbsp; &nbsp; 5）示例代码 from keras.models import Sequential&nbsp; from keras.layers.core import Dense, Dropout, Activation&nbsp; from keras.optimizers import SGD&nbsp; from keras.datasets import mnist&nbsp; import numpy &#39;&#39;&#39;&nbsp;&nbsp;&nbsp; 第一步：选择模型&#39;&#39;&#39;model = Sequential()&#39;&#39;&#39;&nbsp;&nbsp; 第二步：构建网络层&#39;&#39;&#39;model.add(Dense(500,input_shape=(784,))) # 输入层，28*28=784&nbsp; model.add(Activation(&#39;tanh&#39;)) # 激活函数是tanh&nbsp; model.add(Dropout(0.5)) # 采用50%的dropoutmodel.add(Dense(500)) # 隐藏层节点500个&nbsp; model.add(Activation(&#39;tanh&#39;))&nbsp; model.add(Dropout(0.5))model.add(Dense(10)) # 输出结果是10个类别，所以维度是10&nbsp; model.add(Activation(&#39;softmax&#39;)) # 最后一层用softmax作为激活函数&#39;&#39;&#39;&nbsp;&nbsp; 第三步：编译&#39;&#39;&#39;sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) # 优化函数，设定学习率（lr）等参数&nbsp; model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd, class_mode=&#39;categorical&#39;) # 使用交叉熵作为loss函数&#39;&#39;&#39;&nbsp;&nbsp; 第四步：训练&nbsp;&nbsp; .fit的一些参数&nbsp;&nbsp; batch_size：对总的样本数进行分组，每组包含的样本数量&nbsp;&nbsp; epochs ：训练次数&nbsp;&nbsp; shuffle：是否把数据随机打乱之后再进行训练&nbsp;&nbsp; validation_split：拿出百分之多少用来做交叉验证&nbsp;&nbsp; verbose：屏显模式 0：不输出&nbsp; 1：输出进度&nbsp; 2：输出每次的训练结果&#39;&#39;&#39;(X_train, y_train), (X_test, y_test) = mnist.load_data() # 使用Keras自带的mnist工具读取数据（第一次需要联网）# 由于mist的输入数据维度是(num, 28, 28)，这里需要把后面的维度直接拼起来变成784维&nbsp; X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2]) X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])&nbsp; Y_train = (numpy.arange(10) == y_train[:, None]).astype(int) Y_test = (numpy.arange(10) == y_test[:, None]).astype(int)model.fit(X_train,Y_train,batch_size=200,epochs=50,shuffle=True,verbose=0,validation_split=0.3)model.evaluate(X_test, Y_test, batch_size=200, verbose=0)&#39;&#39;&#39;&nbsp;&nbsp;&nbsp; 第五步：输出&#39;&#39;&#39;print(&quot;test set&quot;)scores = model.evaluate(X_test,Y_test,batch_size=200,verbose=0)print(&quot;&quot;)print(&quot;The test loss is %f&quot; % scores)result = model.predict(X_test,batch_size=200,verbose=0)result_max = numpy.argmax(result, axis = 1)test_max = numpy.argmax(Y_test, axis = 1)result_bool = numpy.equal(result_max, test_max)true_num = numpy.sum(result_bool)print(&quot;&quot;)print(&quot;The accuracy of the model is %f&quot; % (true_num/len(result_bool))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;" />
<meta property="og:description" content="&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.关于Keras 1）简介 Keras是由纯python编写的基于theano/tensorflow的深度学习框架。 Keras是一个高层神经网络API，支持快速实验，能够把你的idea迅速转换为结果，如果有如下需求，可以优先选择Keras： a）简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性） b）支持CNN和RNN，或二者的结合 c）无缝CPU和GPU切换 2）设计原则 a）用户友好：Keras是为人类而不是天顶星人设计的API。用户的使用体验始终是我们考虑的首要和中心内容。Keras遵循减少认知困难的最佳实践：Keras提供一致而简洁的API， 能够极大减少一般应用下用户的工作量，同时，Keras提供清晰和具有实践意义的bug反馈。 b）模块性：模型可理解为一个层的序列或数据的运算图，完全可配置的模块可以用最少的代价自由组合在一起。具体而言，网络层、损失函数、优化器、初始化策略、激活函数、正则化方法都是独立的模块，你可以使用它们来构建自己的模型。 c）易扩展性：添加新模块超级容易，只需要仿照现有的模块编写新的类或函数即可。创建新模块的便利性使得Keras更适合于先进的研究工作。 d）与Python协作：Keras没有单独的模型配置文件类型（作为对比，caffe有），模型由python代码描述，使其更紧凑和更易debug，并提供了扩展的便利性。 如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击这里可以查看教程。 2.Keras的模块结构 &nbsp; &nbsp; &nbsp; 3.使用Keras搭建一个神经网络 &nbsp; 4.主要概念 &nbsp; &nbsp;1）符号计算 &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。符号计算首先定义各种变量，然后建立一个“计算图”,计算图规定了各个变量之间的计算关系。 &nbsp; &nbsp; &nbsp; &nbsp;符号计算也叫数据流图，其过程如下(gif图不好打开，所以用了静态图，数据是按图中黑色带箭头的线流动的)： &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;2）张量 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 张量(tensor)，可以看作是向量、矩阵的自然推广，用来表示广泛的数据类型。张量的阶数也叫维度。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0阶张量,即标量,是一个数。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1阶张量,即向量,一组有序排列的数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2阶张量,即矩阵,一组向量有序的排列起来 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3阶张量，即立方体，一组矩阵上下排列起来 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4阶张量......&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 依次类推 &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 重点：关于维度的理解 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 假如有一个10长度的列表，那么我们横向看有10个数字，也可以叫做10维度，纵向看只能看到1个数字，那么就叫1维度。注意这个区别有助于理解Keras或者神经网络中计算时出现的维度问题。 &nbsp; &nbsp; 3）数据格式(data_format) &nbsp; &nbsp; &nbsp; &nbsp; 目前主要有两种方式来表示张量：&nbsp; &nbsp; &nbsp; &nbsp; a) th模式或channels_first模式，Theano和caffe使用此模式。&nbsp; &nbsp; &nbsp; &nbsp; b）tf模式或channels_last模式，TensorFlow使用此模式。 &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 下面举例说明两种模式的区别：&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;对于100张RGB3通道的16×32（高为16宽为32）彩色图，&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;th表示方式：（100,3,16,32）&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;tf表示方式：（100,16,32,3）&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;唯一的区别就是表示通道个数3的位置不一样。 &nbsp; &nbsp; &nbsp;4）模型 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Keras有两种类型的模型，序贯模型（Sequential）和函数式模型（Model），函数式模型应用更为广泛，序贯模型是函数式模型的一种特殊情况。&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）序贯模型（Sequential):单输入单输出，一条路通到底，层与层之间只有相邻关系，没有跨层连接。这种模型编译速度快，操作也比较简单&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）函数式模型（Model）：多输入多输出，层与层之间任意连接。这种模型编译速度慢。 &nbsp; 5.第一个示例 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 这里也采用介绍神经网络时常用的一个例子：手写数字的识别。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 在写代码之前，基于这个例子介绍一些概念，方便大家理解。 &nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; PS：可能是版本差异的问题，官网中的参数和示例中的参数是不一样的，官网中给出的参数少，并且有些参数支持，有些不支持。所以此例子去掉了不支持的参数，并且只介绍本例中用到的参数。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1）Dense(500,input_shape=(784,)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;a）Dense层属于网络层--&gt;常用层中的一个层 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;b） 500表示输出的维度，完整的输出表示：(*,500)：即输出任意个500维的数据流。但是在参数中只写维度就可以了，比较具体输出多少个是有输入确定的。换个说法，Dense的输出其实是个N×500的矩阵。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; c）input_shape(784,) 表示输入维度是784(28×28，后面具体介绍为什么)，完整的输入表示：(*,784)：即输入N个784维度的数据 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2）Activation(&#39;tanh&#39;) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）Activation：激活层 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）&#39;tanh&#39; ：激活函数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3）Dropout(0.5) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;在训练过程中每次更新参数时随机断开一定百分比（rate）的输入神经元，防止过拟合。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4）数据集 &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;数据集包括60000张28×28的训练集和10000张28×28的测试集及其对应的目标数字。如果完全按照上述数据格式表述，以tensorflow作为后端应该是（60000,28,28,3），因为示例中采用了mnist.load_data()获取数据集，所以已经判断使用了tensorflow作为后端，因此数据集就变成了(60000,28,28),那么input_shape(784,)应该是input_shape(28,28，)才对，但是在这个示例中这么写是不对的，需要转换成(60000,784),才可以。为什么需要转换呢？ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 如上图，训练集(60000,28,28)作为输入，就相当于一个立方体，而输入层从当前角度看就是一个平面，立方体的数据流怎么进入平面的输入层进行计算呢？所以需要进行黄色箭头所示的变换，然后才进入输入层进行后续计算。至于从28*28变换成784之后输入层如何处理，就不需要我们关心了。(喜欢钻研的同学可以去研究下源代码)。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;并且，Keras中输入多为(nb_samples, input_dim)的形式：即(样本数量，输入维度)。 &nbsp; &nbsp; &nbsp; &nbsp; 5）示例代码 from keras.models import Sequential&nbsp; from keras.layers.core import Dense, Dropout, Activation&nbsp; from keras.optimizers import SGD&nbsp; from keras.datasets import mnist&nbsp; import numpy &#39;&#39;&#39;&nbsp;&nbsp;&nbsp; 第一步：选择模型&#39;&#39;&#39;model = Sequential()&#39;&#39;&#39;&nbsp;&nbsp; 第二步：构建网络层&#39;&#39;&#39;model.add(Dense(500,input_shape=(784,))) # 输入层，28*28=784&nbsp; model.add(Activation(&#39;tanh&#39;)) # 激活函数是tanh&nbsp; model.add(Dropout(0.5)) # 采用50%的dropoutmodel.add(Dense(500)) # 隐藏层节点500个&nbsp; model.add(Activation(&#39;tanh&#39;))&nbsp; model.add(Dropout(0.5))model.add(Dense(10)) # 输出结果是10个类别，所以维度是10&nbsp; model.add(Activation(&#39;softmax&#39;)) # 最后一层用softmax作为激活函数&#39;&#39;&#39;&nbsp;&nbsp; 第三步：编译&#39;&#39;&#39;sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) # 优化函数，设定学习率（lr）等参数&nbsp; model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd, class_mode=&#39;categorical&#39;) # 使用交叉熵作为loss函数&#39;&#39;&#39;&nbsp;&nbsp; 第四步：训练&nbsp;&nbsp; .fit的一些参数&nbsp;&nbsp; batch_size：对总的样本数进行分组，每组包含的样本数量&nbsp;&nbsp; epochs ：训练次数&nbsp;&nbsp; shuffle：是否把数据随机打乱之后再进行训练&nbsp;&nbsp; validation_split：拿出百分之多少用来做交叉验证&nbsp;&nbsp; verbose：屏显模式 0：不输出&nbsp; 1：输出进度&nbsp; 2：输出每次的训练结果&#39;&#39;&#39;(X_train, y_train), (X_test, y_test) = mnist.load_data() # 使用Keras自带的mnist工具读取数据（第一次需要联网）# 由于mist的输入数据维度是(num, 28, 28)，这里需要把后面的维度直接拼起来变成784维&nbsp; X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2]) X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])&nbsp; Y_train = (numpy.arange(10) == y_train[:, None]).astype(int) Y_test = (numpy.arange(10) == y_test[:, None]).astype(int)model.fit(X_train,Y_train,batch_size=200,epochs=50,shuffle=True,verbose=0,validation_split=0.3)model.evaluate(X_test, Y_test, batch_size=200, verbose=0)&#39;&#39;&#39;&nbsp;&nbsp;&nbsp; 第五步：输出&#39;&#39;&#39;print(&quot;test set&quot;)scores = model.evaluate(X_test,Y_test,batch_size=200,verbose=0)print(&quot;&quot;)print(&quot;The test loss is %f&quot; % scores)result = model.predict(X_test,batch_size=200,verbose=0)result_max = numpy.argmax(result, axis = 1)test_max = numpy.argmax(Y_test, axis = 1)result_bool = numpy.equal(result_max, test_max)true_num = numpy.sum(result_bool)print(&quot;&quot;)print(&quot;The accuracy of the model is %f&quot; % (true_num/len(result_bool))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;" />
<link rel="canonical" href="https://mlh.app/2019/05/17/787104.html" />
<meta property="og:url" content="https://mlh.app/2019/05/17/787104.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.关于Keras 1）简介 Keras是由纯python编写的基于theano/tensorflow的深度学习框架。 Keras是一个高层神经网络API，支持快速实验，能够把你的idea迅速转换为结果，如果有如下需求，可以优先选择Keras： a）简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性） b）支持CNN和RNN，或二者的结合 c）无缝CPU和GPU切换 2）设计原则 a）用户友好：Keras是为人类而不是天顶星人设计的API。用户的使用体验始终是我们考虑的首要和中心内容。Keras遵循减少认知困难的最佳实践：Keras提供一致而简洁的API， 能够极大减少一般应用下用户的工作量，同时，Keras提供清晰和具有实践意义的bug反馈。 b）模块性：模型可理解为一个层的序列或数据的运算图，完全可配置的模块可以用最少的代价自由组合在一起。具体而言，网络层、损失函数、优化器、初始化策略、激活函数、正则化方法都是独立的模块，你可以使用它们来构建自己的模型。 c）易扩展性：添加新模块超级容易，只需要仿照现有的模块编写新的类或函数即可。创建新模块的便利性使得Keras更适合于先进的研究工作。 d）与Python协作：Keras没有单独的模型配置文件类型（作为对比，caffe有），模型由python代码描述，使其更紧凑和更易debug，并提供了扩展的便利性。 如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击这里可以查看教程。 2.Keras的模块结构 &nbsp; &nbsp; &nbsp; 3.使用Keras搭建一个神经网络 &nbsp; 4.主要概念 &nbsp; &nbsp;1）符号计算 &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。符号计算首先定义各种变量，然后建立一个“计算图”,计算图规定了各个变量之间的计算关系。 &nbsp; &nbsp; &nbsp; &nbsp;符号计算也叫数据流图，其过程如下(gif图不好打开，所以用了静态图，数据是按图中黑色带箭头的线流动的)： &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp;2）张量 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 张量(tensor)，可以看作是向量、矩阵的自然推广，用来表示广泛的数据类型。张量的阶数也叫维度。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0阶张量,即标量,是一个数。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1阶张量,即向量,一组有序排列的数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2阶张量,即矩阵,一组向量有序的排列起来 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3阶张量，即立方体，一组矩阵上下排列起来 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4阶张量......&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 依次类推 &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 重点：关于维度的理解 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 假如有一个10长度的列表，那么我们横向看有10个数字，也可以叫做10维度，纵向看只能看到1个数字，那么就叫1维度。注意这个区别有助于理解Keras或者神经网络中计算时出现的维度问题。 &nbsp; &nbsp; 3）数据格式(data_format) &nbsp; &nbsp; &nbsp; &nbsp; 目前主要有两种方式来表示张量：&nbsp; &nbsp; &nbsp; &nbsp; a) th模式或channels_first模式，Theano和caffe使用此模式。&nbsp; &nbsp; &nbsp; &nbsp; b）tf模式或channels_last模式，TensorFlow使用此模式。 &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; 下面举例说明两种模式的区别：&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;对于100张RGB3通道的16×32（高为16宽为32）彩色图，&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;th表示方式：（100,3,16,32）&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;tf表示方式：（100,16,32,3）&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;唯一的区别就是表示通道个数3的位置不一样。 &nbsp; &nbsp; &nbsp;4）模型 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Keras有两种类型的模型，序贯模型（Sequential）和函数式模型（Model），函数式模型应用更为广泛，序贯模型是函数式模型的一种特殊情况。&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）序贯模型（Sequential):单输入单输出，一条路通到底，层与层之间只有相邻关系，没有跨层连接。这种模型编译速度快，操作也比较简单&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）函数式模型（Model）：多输入多输出，层与层之间任意连接。这种模型编译速度慢。 &nbsp; 5.第一个示例 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 这里也采用介绍神经网络时常用的一个例子：手写数字的识别。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 在写代码之前，基于这个例子介绍一些概念，方便大家理解。 &nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; PS：可能是版本差异的问题，官网中的参数和示例中的参数是不一样的，官网中给出的参数少，并且有些参数支持，有些不支持。所以此例子去掉了不支持的参数，并且只介绍本例中用到的参数。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1）Dense(500,input_shape=(784,)) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;a）Dense层属于网络层--&gt;常用层中的一个层 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;b） 500表示输出的维度，完整的输出表示：(*,500)：即输出任意个500维的数据流。但是在参数中只写维度就可以了，比较具体输出多少个是有输入确定的。换个说法，Dense的输出其实是个N×500的矩阵。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; c）input_shape(784,) 表示输入维度是784(28×28，后面具体介绍为什么)，完整的输入表示：(*,784)：即输入N个784维度的数据 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2）Activation(&#39;tanh&#39;) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）Activation：激活层 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）&#39;tanh&#39; ：激活函数 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3）Dropout(0.5) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;在训练过程中每次更新参数时随机断开一定百分比（rate）的输入神经元，防止过拟合。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4）数据集 &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;数据集包括60000张28×28的训练集和10000张28×28的测试集及其对应的目标数字。如果完全按照上述数据格式表述，以tensorflow作为后端应该是（60000,28,28,3），因为示例中采用了mnist.load_data()获取数据集，所以已经判断使用了tensorflow作为后端，因此数据集就变成了(60000,28,28),那么input_shape(784,)应该是input_shape(28,28，)才对，但是在这个示例中这么写是不对的，需要转换成(60000,784),才可以。为什么需要转换呢？ &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 如上图，训练集(60000,28,28)作为输入，就相当于一个立方体，而输入层从当前角度看就是一个平面，立方体的数据流怎么进入平面的输入层进行计算呢？所以需要进行黄色箭头所示的变换，然后才进入输入层进行后续计算。至于从28*28变换成784之后输入层如何处理，就不需要我们关心了。(喜欢钻研的同学可以去研究下源代码)。 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;并且，Keras中输入多为(nb_samples, input_dim)的形式：即(样本数量，输入维度)。 &nbsp; &nbsp; &nbsp; &nbsp; 5）示例代码 from keras.models import Sequential&nbsp; from keras.layers.core import Dense, Dropout, Activation&nbsp; from keras.optimizers import SGD&nbsp; from keras.datasets import mnist&nbsp; import numpy &#39;&#39;&#39;&nbsp;&nbsp;&nbsp; 第一步：选择模型&#39;&#39;&#39;model = Sequential()&#39;&#39;&#39;&nbsp;&nbsp; 第二步：构建网络层&#39;&#39;&#39;model.add(Dense(500,input_shape=(784,))) # 输入层，28*28=784&nbsp; model.add(Activation(&#39;tanh&#39;)) # 激活函数是tanh&nbsp; model.add(Dropout(0.5)) # 采用50%的dropoutmodel.add(Dense(500)) # 隐藏层节点500个&nbsp; model.add(Activation(&#39;tanh&#39;))&nbsp; model.add(Dropout(0.5))model.add(Dense(10)) # 输出结果是10个类别，所以维度是10&nbsp; model.add(Activation(&#39;softmax&#39;)) # 最后一层用softmax作为激活函数&#39;&#39;&#39;&nbsp;&nbsp; 第三步：编译&#39;&#39;&#39;sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) # 优化函数，设定学习率（lr）等参数&nbsp; model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=sgd, class_mode=&#39;categorical&#39;) # 使用交叉熵作为loss函数&#39;&#39;&#39;&nbsp;&nbsp; 第四步：训练&nbsp;&nbsp; .fit的一些参数&nbsp;&nbsp; batch_size：对总的样本数进行分组，每组包含的样本数量&nbsp;&nbsp; epochs ：训练次数&nbsp;&nbsp; shuffle：是否把数据随机打乱之后再进行训练&nbsp;&nbsp; validation_split：拿出百分之多少用来做交叉验证&nbsp;&nbsp; verbose：屏显模式 0：不输出&nbsp; 1：输出进度&nbsp; 2：输出每次的训练结果&#39;&#39;&#39;(X_train, y_train), (X_test, y_test) = mnist.load_data() # 使用Keras自带的mnist工具读取数据（第一次需要联网）# 由于mist的输入数据维度是(num, 28, 28)，这里需要把后面的维度直接拼起来变成784维&nbsp; X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2]) X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])&nbsp; Y_train = (numpy.arange(10) == y_train[:, None]).astype(int) Y_test = (numpy.arange(10) == y_test[:, None]).astype(int)model.fit(X_train,Y_train,batch_size=200,epochs=50,shuffle=True,verbose=0,validation_split=0.3)model.evaluate(X_test, Y_test, batch_size=200, verbose=0)&#39;&#39;&#39;&nbsp;&nbsp;&nbsp; 第五步：输出&#39;&#39;&#39;print(&quot;test set&quot;)scores = model.evaluate(X_test,Y_test,batch_size=200,verbose=0)print(&quot;&quot;)print(&quot;The test loss is %f&quot; % scores)result = model.predict(X_test,batch_size=200,verbose=0)result_max = numpy.argmax(result, axis = 1)test_max = numpy.argmax(Y_test, axis = 1)result_bool = numpy.equal(result_max, test_max)true_num = numpy.sum(result_bool)print(&quot;&quot;)print(&quot;The accuracy of the model is %f&quot; % (true_num/len(result_bool))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;","@type":"BlogPosting","url":"https://mlh.app/2019/05/17/787104.html","headline":"深度学习 Keras入门 一 之基础篇","dateModified":"2019-05-17T00:00:00+08:00","datePublished":"2019-05-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/17/787104.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>深度学习 Keras入门 一 之基础篇</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <div class="markdown_views prism-tomorrow-night" id="content_views">
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
   <!-- flowchart &#31661;&#22836;&#22270;&#26631; &#21247;&#21024; -->&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
   <div class="htmledit_views" id="content_views">
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
    <div class="clear"></div>
    <div class="postBody">
     <div id="cnblogs_post_body">
      <p><span><span>1.关于Keras</span></span></p>
      <p>1）简介 </p>
      <p>Keras是由纯python编写的基于theano/tensorflow的深度学习框架。</p>
      <p>Keras是一个高层神经网络API，支持快速实验，能够把你的idea迅速转换为结果，如果有如下需求，可以优先选择Keras：</p>
      <p> a）简易和快速的原型设计（keras具有高度模块化，极简，和可扩充特性）</p>
      <p>b）支持CNN和RNN，或二者的结合</p>
      <p><span id="__mceDel"></span>c）无缝CPU和GPU切换</p>
      <p>2）设计原则</p>
      <p>a）用户友好：Keras是为人类而不是天顶星人设计的API。用户的使用体验始终是我们考虑的首要和中心内容。Keras遵循减少认知困难的最佳实践：Keras提供一致而简洁的API， 能够极大减少一般应用下用户的工作量，同时，Keras提供清晰和具有实践意义的bug反馈。</p>
      <p>b）模块性：模型可理解为一个层的序列或数据的运算图，完全可配置的模块可以用最少的代价自由组合在一起。具体而言，网络层、损失函数、优化器、初始化策略、激活函数、正则化方法都是独立的模块，你可以使用它们来构建自己的模型。</p>
      <p> c）易扩展性：添加新模块超级容易，只需要仿照现有的模块编写新的类或函数即可。创建新模块的便利性使得Keras更适合于先进的研究工作。</p>
      <p>d）与Python协作：Keras没有单独的模型配置文件类型（作为对比，caffe有），模型由python代码描述，使其更紧凑和更易debug，并提供了扩展的便利性。</p>
     </div>
    </div>
   </div>
   <p>如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击<a href="http://www.captainbed.net/csdn" rel="nofollow" target="_blank">这里</a>可以查看教程。</p>
   <p><span><span>2.Keras的模块结构</span></span></p>
   <p>&nbsp; &nbsp;<img alt="" src="https://uzshare.com/_p?http://images2015.cnblogs.com/blog/1119747/201707/1119747-20170707133635659-888158147.png"></p>
   <p>&nbsp;</p>
   <p>3.<span><span>使用Keras搭建一个神经网络</span></span></p>
   <p><img alt="" src="https://uzshare.com/_p?http://images2015.cnblogs.com/blog/1119747/201707/1119747-20170707133932722-715494711.png"></p>
   <p>&nbsp;</p>
   <p><span><span>4.主要概念</span></span></p>
   <p>&nbsp; &nbsp;1）符号计算</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;Keras的底层库使用Theano或TensorFlow，这两个库也称为Keras的后端。无论是Theano还是TensorFlow，都是一个“符号式”的库。符号计算首先定义各种变量，然后建立一个“计算图”,计算图规定了各个变量之间的计算关系。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp;符号计算也叫数据流图，其过程如下(gif图不好打开，所以用了静态图，数据是按图中黑色带箭头的线流动的)：</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<img alt="" src="https://uzshare.com/_p?http://images2015.cnblogs.com/blog/1119747/201707/1119747-20170707135253581-1586562235.png"></p>
   <p>&nbsp; &nbsp; &nbsp;2）张量</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 张量(tensor)，可以看作是向量、矩阵的自然推广，用来表示广泛的数据类型。张量的阶数也叫维度。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0阶张量,即标量,是一个数。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1阶张量,即向量,一组有序排列的数</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2阶张量,即矩阵,一组向量有序的排列起来</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3阶张量，即立方体，一组矩阵上下排列起来</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4阶张量......<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 依次类推</p>
   <p>&nbsp;&nbsp;<span>&nbsp; &nbsp; &nbsp; &nbsp; 重点：关于维度的理解</span></p>
   <p><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 假如有一个10长度的列表，那么我们横向看有10个数字，也可以叫做10维度，纵向看只能看到1个数字，那么就叫1维度。注意这个区别有助于理解Keras或者神经网络中计算时出现的维度问题。</span></p>
   <p>&nbsp; &nbsp; 3）数据格式(data_format)</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; 目前主要有两种方式来表示张量：<br>&nbsp; &nbsp; &nbsp; &nbsp; a) th模式或channels_first模式，Theano和caffe使用此模式。<br>&nbsp; &nbsp; &nbsp; &nbsp; b）tf模式或channels_last模式，TensorFlow使用此模式。</p>
   <p>&nbsp;<br>&nbsp; &nbsp; &nbsp; &nbsp; 下面举例说明两种模式的区别：<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;对于100张RGB3通道的16×32（高为16宽为32）彩色图，<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;th表示方式：（100,3,16,32）<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;tf表示方式：（100,16,32,3）<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;唯一的区别就是表示通道个数3的位置不一样。</p>
   <p>&nbsp; &nbsp; &nbsp;4）模型</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Keras有两种类型的模型，序贯模型（Sequential）和函数式模型（Model），函数式模型应用更为广泛，序贯模型是函数式模型的一种特殊情况。<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）序贯模型（Sequential):单输入单输出，一条路通到底，层与层之间只有相邻关系，没有跨层连接。这种模型编译速度快，操作也比较简单<br>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）函数式模型（Model）：多输入多输出，层与层之间任意连接。这种模型编译速度慢。</p>
   <p>&nbsp;</p>
   <p><span><span>5.第一个示例</span></span></p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 这里也采用介绍神经网络时常用的一个例子：手写数字的识别。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 在写代码之前，基于这个例子介绍一些概念，方便大家理解。</p>
   <p>&nbsp; &nbsp;<span>&nbsp;&nbsp; &nbsp; &nbsp; PS：可能是版本差异的问题，官网中的参数和示例中的参数是不一样的，官网中给出的参数少，并且有些参数支持，有些不支持。所以此例子去掉了不支持的参数，并且只介绍本例中用到的参数。</span></p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1）Dense(500,input_shape=(784,))</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;a）Dense层属于网络层--&gt;常用层中的一个层</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;b） 500表示输出的维度，完整的输出表示：(*,500)：即输出任意个500维的数据流。但是在参数中只写维度就可以了，比较具体输出多少个是有输入确定的。换个说法，Dense的输出其实是个N×500的矩阵。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; c）input_shape(784,) 表示输入维度是784(28×28，后面具体介绍为什么)，完整的输入表示：(*,784)：即输入N个784维度的数据</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2）Activation('tanh')</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; a）Activation：激活层</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; b）'tanh' ：激活函数</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3）Dropout(0.5)</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;在训练过程中每次更新参数时随机断开一定百分比（rate）的输入神经元，防止过拟合。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4）数据集</p>
   <p>&nbsp;&nbsp;<span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;数据集包括60000张28×28的训练集和10000张28×28的测试集及其对应的目标数字。如果完全按照上述数据格式表述，以tensorflow作为后端应该是（60000,28,28,3），因为示例中采用了mnist.load_data()获取数据集，所以已经判断使用了tensorflow作为后端，因此数据集就变成了(60000,28,28),那么input_shape(784,)应该是input_shape(28,28，)才对，但是在这个示例中这么写是不对的，需要转换成(60000,784),才可以。为什么需要转换呢？</span></p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<img alt="" src="https://uzshare.com/_p?http://images2015.cnblogs.com/blog/1119747/201707/1119747-20170707145150519-637435869.png"></p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 如上图，训练集(60000,28,28)作为输入，就相当于一个立方体，而输入层从当前角度看就是一个平面，立方体的数据流怎么进入平面的输入层进行计算呢？所以需要进行黄色箭头所示的变换，然后才进入输入层进行后续计算。至于从28*28变换成784之后输入层如何处理，就不需要我们关心了。(喜欢钻研的同学可以去研究下源代码)。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;并且，Keras中输入多为(nb_samples, input_dim)的形式：即(样本数量，输入维度)。</p>
   <p>&nbsp; &nbsp; &nbsp; &nbsp; 5）示例代码</p>
   <div class="cnblogs_code">
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><a title="复制代码" target="_blank"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></a></span>
    </div>
    <pre class="prettyprint"><span>from</span> keras.models <span>import</span><span> Sequential&nbsp; </span><span>from</span> keras.layers.core <span>import</span><span> Dense, Dropout, Activation&nbsp; </span><span>from</span> keras.optimizers <span>import</span><span> SGD&nbsp; </span><span>from</span> keras.datasets <span>import</span><span> mnist&nbsp; </span><span>import</span><span> numpy </span><span>'''</span><span>&nbsp;&nbsp;&nbsp; 第一步：选择模型</span><span>'''</span><span>model </span>=<span> Sequential()</span><span>'''</span><span>&nbsp;&nbsp; 第二步：构建网络层</span><span>'''</span><span>model.add(Dense(</span>500,input_shape=(784,))) <span>#</span><span> 输入层，28*28=784&nbsp; </span>model.add(Activation(<span>'</span><span>tanh</span><span>'</span>)) <span>#</span><span> 激活函数是tanh&nbsp; </span>model.add(Dropout(0.5)) <span>#</span><span> 采用50%的dropout</span><span>model.add(Dense(</span>500)) <span>#</span><span> 隐藏层节点500个&nbsp; </span>model.add(Activation(<span>'</span><span>tanh</span><span>'</span><span>))&nbsp; model.add(Dropout(</span>0.5<span>))model.add(Dense(</span>10)) <span>#</span><span> 输出结果是10个类别，所以维度是10&nbsp; </span>model.add(Activation(<span>'</span><span>softmax</span><span>'</span>)) <span>#</span><span> 最后一层用softmax作为激活函数</span><span>'''</span><span>&nbsp;&nbsp; 第三步：编译</span><span>'''</span><span>sgd </span>= SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True) <span>#</span><span> 优化函数，设定学习率（lr）等参数&nbsp; </span>model.compile(loss=<span>'</span><span>categorical_crossentropy</span><span>'</span>, optimizer=sgd, class_mode=<span>'</span><span>categorical</span><span>'</span>) <span>#</span><span> 使用交叉熵作为loss函数</span><span>'''</span><span>&nbsp;&nbsp; 第四步：训练&nbsp;&nbsp; .fit的一些参数&nbsp;&nbsp; batch_size：对总的样本数进行分组，每组包含的样本数量&nbsp;&nbsp; epochs ：训练次数&nbsp;&nbsp; shuffle：是否把数据随机打乱之后再进行训练&nbsp;&nbsp; validation_split：拿出百分之多少用来做交叉验证&nbsp;&nbsp; verbose：屏显模式 0：不输出&nbsp; 1：输出进度&nbsp; 2：输出每次的训练结果</span><span>'''</span><span>(X_train, y_train), (X_test, y_test) </span>= mnist.load_data() <span>#</span><span> 使用Keras自带的mnist工具读取数据（第一次需要联网）</span><span>#</span><span> 由于mist的输入数据维度是(num, 28, 28)，这里需要把后面的维度直接拼起来变成784维&nbsp; </span>X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2<span>]) X_test </span>= X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2<span>])&nbsp; Y_train </span>= (numpy.arange(10) ==<span> y_train[:, None]).astype(int) Y_test </span>= (numpy.arange(10) ==<span> y_test[:, None]).astype(int)model.fit(X_train,Y_train,batch_size</span>=200,epochs=50,shuffle=True,verbose=0,validation_split=0.3<span>)model.evaluate(X_test, Y_test, batch_size</span>=200, verbose=<span>0)</span><span>'''</span><span>&nbsp;&nbsp;&nbsp; 第五步：输出</span><span>'''</span><span>print</span>(<span>"</span><span>test set</span><span>"</span><span>)scores </span>= model.evaluate(X_test,Y_test,batch_size=200,verbose=<span>0)</span><span>print</span>(<span>""</span><span>)</span><span>print</span>(<span>"</span><span>The test loss is %f</span><span>"</span> %<span> scores)result </span>= model.predict(X_test,batch_size=200,verbose=<span>0)result_max </span>= numpy.argmax(result, axis = 1<span>)test_max </span>= numpy.argmax(Y_test, axis = 1<span>)result_bool </span>=<span> numpy.equal(result_max, test_max)true_num </span>=<span> numpy.sum(result_bool)</span><span>print</span>(<span>""</span><span>)</span><span>print</span>(<span>"</span><span>The accuracy of the model is %f</span><span>"</span> % (true_num/len(result_bool)))</pre>
    <div class="cnblogs_code_toolbar">
     <span class="cnblogs_code_copy"><a title="复制代码" target="_blank"><img alt="复制代码" src="http://common.cnblogs.com/images/copycode.gif"></a></span>
    </div>
   </div>
   <p>&nbsp;</p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  </div> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
