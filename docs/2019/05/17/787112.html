<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>数据分析——Glassdoor上各公司员工的评价分析 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="数据分析——Glassdoor上各公司员工的评价分析" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="（参考：小象学院公开课，网络文献） 1、分析目的：通过对美国各科技公司员工的匿名评价，分析员工满意度； 2、数据来源：Glassdoor网站（类似于国内的看准等）； 3、数据大小：37576kb，共67k条数据； 4、使用的分析工具：jupyter notebook 5、使用到的python库：pandas、matplotlib、seaborn、wordcloud 6、分析思路：先通过pandas获取数据后，对数据进行预览；然后对数据进行预处理——如格式转换，去空值等；再通过对数值数据进行处理，绘制图表；最后对于文本数据进行拼接，绘制词云。 一、数据的载入与预览 首先载入相关的库，读取数据： import pandas as pd data_file = &#39;./dataset/employee_reviews.csv&#39; data_df = pd.read_csv(data_file) 对数据进行一个整体的概览： data_df.head() 看到数据导入成功了，接下来看一下整体的数据情况： data_df.info() 可以看到此样本数据共用67529行，16列，其中overall-ratings和helpful-count为数值数据，其他含字符串数据。但是从刚刚的数据预览可以看出从overall-ratings至helpfu-count中间7列应全为数值数据，所以说明中间那5列有干扰数据，需进行处理。 二、数据的预处理 首先，先把文本数据和数值数据进行区分 numeric_data = [&#39;overall-ratings&#39;, &#39;work-balance-stars&#39;, &#39;culture-values-stars&#39;, &#39;carrer-opportunities-stars&#39;, &#39;comp-benefit-stars&#39;, &#39;senior-mangemnet-stars&#39;, &#39;helpful-count&#39;] str_data = [&#39;company&#39;, &#39;location&#39;, &#39;dates&#39;, &#39;job-title&#39;, &#39;summary&#39;, &#39;pros&#39;, &#39;cons&#39;, &#39;advice-to-mgmt&#39;, &#39;link&#39;] 然后使用pandas中的to_numeric方法将numeric_data中的数据进行转换，非数值数据补为NaN值 data_df[numeric_data] = data_df[numeric_data].apply(pd.to_numeric, errors = &#39;coerce&#39;) 预览看一下： data_df.info() 发现之前那5列为object的数据已经变成了float格式，但是其数据的量都小于67529了，最小的只有53983条，可见里面的无用数据很多，为了更加直观再用head预览一下吧； data_df.head(20) 可以看到第15行开始就出现NaN值了。 接下来使用fiilna方法对于NaN进行填充，统一填充为0。 data_df[numeric_data] = data_df[numeric_data].fillna(0) 预览一下： data_df.head(20) 可以看到刚刚为NaN的数据已经变成了0了 三、数据的可视化 首先引入可视化需要的库: import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline #直接在jupyter中展现画布 看一下各个公司总体评论数量的情况，因为数据中有分前员工和现员工的，所以在表格里面新建一列，用于区分员工的状态： data_df[&#39;employee_status&#39;] = &#39; &#39; data_df.loc[data_df[&#39;job-title&#39;].str.contains(&#39;Current&#39;), &#39;employee_status&#39;] = &#39;Current&#39; data_df.loc[data_df[&#39;job-title&#39;].str.contains(&#39;Former&#39;), &#39;employee_status&#39;] = &#39;Former&#39; 然后用sns中的countplot方法绘制计数图： plt.figure(figsize = (8, 5)) sns.countplot(x = &#39;company&#39;, data = data_df, hue = &#39;employee_status&#39;) plt.title(&#39;Records comparison of Current &amp; Former&#39;) plt.show() 效果如下： 这里就可以看出：亚马逊的员工在网上最活跃，facebook和netflix的员工不怎么活跃。 接下来就开始看评分情况了，先看一下总体的评分，也就是overall-ratings这一列，取平均值： plt.figure() data_bar = data_df.groupby(&#39;company&#39;)[&#39;overall-ratings&#39;].mean() companies = pd.unique(data_df[&#39;company&#39;]) plt.title(&#39;Overall-ratings&#39;) plt.xlabel(&#39;company&#39;) plt.ylabel(&#39;ratings&#39;) plt.bar(companies , height = data_bar, width = 0.5, color = [&#39;b&#39;, &#39;g&#39;, &#39;r&#39;, &#39;y&#39;, &#39;m&#39;, &#39;k&#39;]) plt.show() 效果如下： 可以看出facebook最高，但是鉴于facebook的样本量靠后，综合靠前的应该是亚马逊。 当然也可以对其他列的评分进行一个统计分析，我们使用一个for循环来进行： ratings_data = [&#39;overall-ratings&#39;, &#39;work-balance-stars&#39;, &#39;culture-values-stars&#39;, &#39;carrer-opportunities-stars&#39;, &#39;comp-benefit-stars&#39;, &#39;senior-mangemnet-stars&#39;] for ratings_datas in ratings_data: plt.figure() data_figure = data_df.groupby(&#39;company&#39;)[ratings_datas].mean() companies = pd.unique(data_df[&#39;company&#39;]) plt.bar(companies , height = data_bar, width = 0.5, color = [&#39;b&#39;, &#39;g&#39;, &#39;r&#39;, &#39;y&#39;, &#39;m&#39;, &#39;k&#39;]) plt.xlabel(ratings_datas) plt.show() 结果就不展示了，Facebook一枝独秀。 因为刚刚数据里面就区分在职员工和离职员工，接下来看一下他们的评价有什么不同。 通过构建一个新表，进行绘制： results = data_df.groupby([&#39;company&#39;, &#39;employee_status&#39;])[&#39;overall-ratings&#39;].mean() current_mean_ratings = results[:, &#39;Current&#39;] former_mean_ratings = results[:, &#39;Former&#39;] mean_ratings = pd.DataFrame() mean_ratings[&#39;Current Mean Ratings&#39;] = current_mean_ratings mean_ratings[&#39;Former Mean Ratings&#39;] = former_mean_ratings companies = pd.unique(data_df[&#39;company&#39;]) plt.figure(figsize = (10, 6)) ax = plt.subplot(111) ax.set_xticklabels(companies, fontsize = 12) plt.rcParams[&#39;font.sans-serif&#39;] = [&#39;SimHei&#39;] plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.xlabel(&#39;公司名称&#39;,size = 15) plt.ylabel(&#39;评分&#39;,size = 15) plt.title(&#39;各科技公司现员工与前员工评分的对比&#39;, size = 18) plt.bar(companies, height = mean_ratings[&#39;Current Mean Ratings&#39;], width = 0.4, label = &#39;现员工&#39;) f_xlim = [0.5, 1.5, 2.5 ,3.5, 4.5, 5.5] plt.bar(f_xlim, height = mean_ratings[&#39;Former Mean Ratings&#39;], width = 0.4, label = &#39;前员工&#39;) plt.legend(fontsize = 12) plt.show() 在上面的绘制中，增加了中文的显示的部分，效果如下： 此图可以看出，离职的员工的评分都比在职的员工低，这也符合正常的逻辑，如果认为这个公司好怎么还会离职呢？ （这个图中有个瑕疵，x轴的标签没有置中，想了很久没有想到） 下面对于文本进行分析： 首先导入库，然后使用for循环，将不同的公司进行区分，并使用join函数将同一公司的summary进行合并，最后绘制词云进行展示。 from wordcloud import WordCloud companies = pd.unique(data_df[&#39;company&#39;]) #interpolation参数是用于设置边界模糊度 for company in companies: company_df = data_df.loc[data_df[&#39;company&#39;] == company] company_review = &#39; &#39;.join(str(review) for review in company_df[&#39;summary&#39;]) wordcloud = WordCloud().generate(company_review) plt.imshow(wordcloud, interpolation = &#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.title(company) plt.show() 部分效果如下： 可以看到谷歌里面有一些engineer，亚马逊里面有culture等词，可以看出公司一些注重的点，当然此图还是可以进行优化的，如使用jieba库进行分词后，删除一些意义不大的、但是频率高的词汇，这个后面涉及到中文分词的时候再进行练习吧。 四、总结 这一次学习主要是了解怎么样来做数据分析： 1、通过head、info、describe等进行数据的预览，发现异常数据。 2、发现异常数据后进行处理，这是使用了to_numeric方法将含有异常数据的列转变成全为数值类型；然后使用fillna对空值填充为0，具体应该填充什么，应考虑实际的需求，常见的还有dropna还有空值的行进行删除，填充均值，插值等方法。 3、对数据进行可视化，提取信息，这里通过seaborn、pyplot、worldcloud对数据进行可视化，查看各公司员工的满意度。当然还可以使用机器学习相关知识对数据进行分析，提取更多信息，这个还没有学习太多，就不做了。 4、其他技巧，这里学习到了通过构建新的列，来进行数据分析的方法，到现在为止看到的几个案例中，这个技巧还是挺常用的。" />
<meta property="og:description" content="（参考：小象学院公开课，网络文献） 1、分析目的：通过对美国各科技公司员工的匿名评价，分析员工满意度； 2、数据来源：Glassdoor网站（类似于国内的看准等）； 3、数据大小：37576kb，共67k条数据； 4、使用的分析工具：jupyter notebook 5、使用到的python库：pandas、matplotlib、seaborn、wordcloud 6、分析思路：先通过pandas获取数据后，对数据进行预览；然后对数据进行预处理——如格式转换，去空值等；再通过对数值数据进行处理，绘制图表；最后对于文本数据进行拼接，绘制词云。 一、数据的载入与预览 首先载入相关的库，读取数据： import pandas as pd data_file = &#39;./dataset/employee_reviews.csv&#39; data_df = pd.read_csv(data_file) 对数据进行一个整体的概览： data_df.head() 看到数据导入成功了，接下来看一下整体的数据情况： data_df.info() 可以看到此样本数据共用67529行，16列，其中overall-ratings和helpful-count为数值数据，其他含字符串数据。但是从刚刚的数据预览可以看出从overall-ratings至helpfu-count中间7列应全为数值数据，所以说明中间那5列有干扰数据，需进行处理。 二、数据的预处理 首先，先把文本数据和数值数据进行区分 numeric_data = [&#39;overall-ratings&#39;, &#39;work-balance-stars&#39;, &#39;culture-values-stars&#39;, &#39;carrer-opportunities-stars&#39;, &#39;comp-benefit-stars&#39;, &#39;senior-mangemnet-stars&#39;, &#39;helpful-count&#39;] str_data = [&#39;company&#39;, &#39;location&#39;, &#39;dates&#39;, &#39;job-title&#39;, &#39;summary&#39;, &#39;pros&#39;, &#39;cons&#39;, &#39;advice-to-mgmt&#39;, &#39;link&#39;] 然后使用pandas中的to_numeric方法将numeric_data中的数据进行转换，非数值数据补为NaN值 data_df[numeric_data] = data_df[numeric_data].apply(pd.to_numeric, errors = &#39;coerce&#39;) 预览看一下： data_df.info() 发现之前那5列为object的数据已经变成了float格式，但是其数据的量都小于67529了，最小的只有53983条，可见里面的无用数据很多，为了更加直观再用head预览一下吧； data_df.head(20) 可以看到第15行开始就出现NaN值了。 接下来使用fiilna方法对于NaN进行填充，统一填充为0。 data_df[numeric_data] = data_df[numeric_data].fillna(0) 预览一下： data_df.head(20) 可以看到刚刚为NaN的数据已经变成了0了 三、数据的可视化 首先引入可视化需要的库: import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline #直接在jupyter中展现画布 看一下各个公司总体评论数量的情况，因为数据中有分前员工和现员工的，所以在表格里面新建一列，用于区分员工的状态： data_df[&#39;employee_status&#39;] = &#39; &#39; data_df.loc[data_df[&#39;job-title&#39;].str.contains(&#39;Current&#39;), &#39;employee_status&#39;] = &#39;Current&#39; data_df.loc[data_df[&#39;job-title&#39;].str.contains(&#39;Former&#39;), &#39;employee_status&#39;] = &#39;Former&#39; 然后用sns中的countplot方法绘制计数图： plt.figure(figsize = (8, 5)) sns.countplot(x = &#39;company&#39;, data = data_df, hue = &#39;employee_status&#39;) plt.title(&#39;Records comparison of Current &amp; Former&#39;) plt.show() 效果如下： 这里就可以看出：亚马逊的员工在网上最活跃，facebook和netflix的员工不怎么活跃。 接下来就开始看评分情况了，先看一下总体的评分，也就是overall-ratings这一列，取平均值： plt.figure() data_bar = data_df.groupby(&#39;company&#39;)[&#39;overall-ratings&#39;].mean() companies = pd.unique(data_df[&#39;company&#39;]) plt.title(&#39;Overall-ratings&#39;) plt.xlabel(&#39;company&#39;) plt.ylabel(&#39;ratings&#39;) plt.bar(companies , height = data_bar, width = 0.5, color = [&#39;b&#39;, &#39;g&#39;, &#39;r&#39;, &#39;y&#39;, &#39;m&#39;, &#39;k&#39;]) plt.show() 效果如下： 可以看出facebook最高，但是鉴于facebook的样本量靠后，综合靠前的应该是亚马逊。 当然也可以对其他列的评分进行一个统计分析，我们使用一个for循环来进行： ratings_data = [&#39;overall-ratings&#39;, &#39;work-balance-stars&#39;, &#39;culture-values-stars&#39;, &#39;carrer-opportunities-stars&#39;, &#39;comp-benefit-stars&#39;, &#39;senior-mangemnet-stars&#39;] for ratings_datas in ratings_data: plt.figure() data_figure = data_df.groupby(&#39;company&#39;)[ratings_datas].mean() companies = pd.unique(data_df[&#39;company&#39;]) plt.bar(companies , height = data_bar, width = 0.5, color = [&#39;b&#39;, &#39;g&#39;, &#39;r&#39;, &#39;y&#39;, &#39;m&#39;, &#39;k&#39;]) plt.xlabel(ratings_datas) plt.show() 结果就不展示了，Facebook一枝独秀。 因为刚刚数据里面就区分在职员工和离职员工，接下来看一下他们的评价有什么不同。 通过构建一个新表，进行绘制： results = data_df.groupby([&#39;company&#39;, &#39;employee_status&#39;])[&#39;overall-ratings&#39;].mean() current_mean_ratings = results[:, &#39;Current&#39;] former_mean_ratings = results[:, &#39;Former&#39;] mean_ratings = pd.DataFrame() mean_ratings[&#39;Current Mean Ratings&#39;] = current_mean_ratings mean_ratings[&#39;Former Mean Ratings&#39;] = former_mean_ratings companies = pd.unique(data_df[&#39;company&#39;]) plt.figure(figsize = (10, 6)) ax = plt.subplot(111) ax.set_xticklabels(companies, fontsize = 12) plt.rcParams[&#39;font.sans-serif&#39;] = [&#39;SimHei&#39;] plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.xlabel(&#39;公司名称&#39;,size = 15) plt.ylabel(&#39;评分&#39;,size = 15) plt.title(&#39;各科技公司现员工与前员工评分的对比&#39;, size = 18) plt.bar(companies, height = mean_ratings[&#39;Current Mean Ratings&#39;], width = 0.4, label = &#39;现员工&#39;) f_xlim = [0.5, 1.5, 2.5 ,3.5, 4.5, 5.5] plt.bar(f_xlim, height = mean_ratings[&#39;Former Mean Ratings&#39;], width = 0.4, label = &#39;前员工&#39;) plt.legend(fontsize = 12) plt.show() 在上面的绘制中，增加了中文的显示的部分，效果如下： 此图可以看出，离职的员工的评分都比在职的员工低，这也符合正常的逻辑，如果认为这个公司好怎么还会离职呢？ （这个图中有个瑕疵，x轴的标签没有置中，想了很久没有想到） 下面对于文本进行分析： 首先导入库，然后使用for循环，将不同的公司进行区分，并使用join函数将同一公司的summary进行合并，最后绘制词云进行展示。 from wordcloud import WordCloud companies = pd.unique(data_df[&#39;company&#39;]) #interpolation参数是用于设置边界模糊度 for company in companies: company_df = data_df.loc[data_df[&#39;company&#39;] == company] company_review = &#39; &#39;.join(str(review) for review in company_df[&#39;summary&#39;]) wordcloud = WordCloud().generate(company_review) plt.imshow(wordcloud, interpolation = &#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.title(company) plt.show() 部分效果如下： 可以看到谷歌里面有一些engineer，亚马逊里面有culture等词，可以看出公司一些注重的点，当然此图还是可以进行优化的，如使用jieba库进行分词后，删除一些意义不大的、但是频率高的词汇，这个后面涉及到中文分词的时候再进行练习吧。 四、总结 这一次学习主要是了解怎么样来做数据分析： 1、通过head、info、describe等进行数据的预览，发现异常数据。 2、发现异常数据后进行处理，这是使用了to_numeric方法将含有异常数据的列转变成全为数值类型；然后使用fillna对空值填充为0，具体应该填充什么，应考虑实际的需求，常见的还有dropna还有空值的行进行删除，填充均值，插值等方法。 3、对数据进行可视化，提取信息，这里通过seaborn、pyplot、worldcloud对数据进行可视化，查看各公司员工的满意度。当然还可以使用机器学习相关知识对数据进行分析，提取更多信息，这个还没有学习太多，就不做了。 4、其他技巧，这里学习到了通过构建新的列，来进行数据分析的方法，到现在为止看到的几个案例中，这个技巧还是挺常用的。" />
<link rel="canonical" href="https://mlh.app/2019/05/17/787112.html" />
<meta property="og:url" content="https://mlh.app/2019/05/17/787112.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"（参考：小象学院公开课，网络文献） 1、分析目的：通过对美国各科技公司员工的匿名评价，分析员工满意度； 2、数据来源：Glassdoor网站（类似于国内的看准等）； 3、数据大小：37576kb，共67k条数据； 4、使用的分析工具：jupyter notebook 5、使用到的python库：pandas、matplotlib、seaborn、wordcloud 6、分析思路：先通过pandas获取数据后，对数据进行预览；然后对数据进行预处理——如格式转换，去空值等；再通过对数值数据进行处理，绘制图表；最后对于文本数据进行拼接，绘制词云。 一、数据的载入与预览 首先载入相关的库，读取数据： import pandas as pd data_file = &#39;./dataset/employee_reviews.csv&#39; data_df = pd.read_csv(data_file) 对数据进行一个整体的概览： data_df.head() 看到数据导入成功了，接下来看一下整体的数据情况： data_df.info() 可以看到此样本数据共用67529行，16列，其中overall-ratings和helpful-count为数值数据，其他含字符串数据。但是从刚刚的数据预览可以看出从overall-ratings至helpfu-count中间7列应全为数值数据，所以说明中间那5列有干扰数据，需进行处理。 二、数据的预处理 首先，先把文本数据和数值数据进行区分 numeric_data = [&#39;overall-ratings&#39;, &#39;work-balance-stars&#39;, &#39;culture-values-stars&#39;, &#39;carrer-opportunities-stars&#39;, &#39;comp-benefit-stars&#39;, &#39;senior-mangemnet-stars&#39;, &#39;helpful-count&#39;] str_data = [&#39;company&#39;, &#39;location&#39;, &#39;dates&#39;, &#39;job-title&#39;, &#39;summary&#39;, &#39;pros&#39;, &#39;cons&#39;, &#39;advice-to-mgmt&#39;, &#39;link&#39;] 然后使用pandas中的to_numeric方法将numeric_data中的数据进行转换，非数值数据补为NaN值 data_df[numeric_data] = data_df[numeric_data].apply(pd.to_numeric, errors = &#39;coerce&#39;) 预览看一下： data_df.info() 发现之前那5列为object的数据已经变成了float格式，但是其数据的量都小于67529了，最小的只有53983条，可见里面的无用数据很多，为了更加直观再用head预览一下吧； data_df.head(20) 可以看到第15行开始就出现NaN值了。 接下来使用fiilna方法对于NaN进行填充，统一填充为0。 data_df[numeric_data] = data_df[numeric_data].fillna(0) 预览一下： data_df.head(20) 可以看到刚刚为NaN的数据已经变成了0了 三、数据的可视化 首先引入可视化需要的库: import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline #直接在jupyter中展现画布 看一下各个公司总体评论数量的情况，因为数据中有分前员工和现员工的，所以在表格里面新建一列，用于区分员工的状态： data_df[&#39;employee_status&#39;] = &#39; &#39; data_df.loc[data_df[&#39;job-title&#39;].str.contains(&#39;Current&#39;), &#39;employee_status&#39;] = &#39;Current&#39; data_df.loc[data_df[&#39;job-title&#39;].str.contains(&#39;Former&#39;), &#39;employee_status&#39;] = &#39;Former&#39; 然后用sns中的countplot方法绘制计数图： plt.figure(figsize = (8, 5)) sns.countplot(x = &#39;company&#39;, data = data_df, hue = &#39;employee_status&#39;) plt.title(&#39;Records comparison of Current &amp; Former&#39;) plt.show() 效果如下： 这里就可以看出：亚马逊的员工在网上最活跃，facebook和netflix的员工不怎么活跃。 接下来就开始看评分情况了，先看一下总体的评分，也就是overall-ratings这一列，取平均值： plt.figure() data_bar = data_df.groupby(&#39;company&#39;)[&#39;overall-ratings&#39;].mean() companies = pd.unique(data_df[&#39;company&#39;]) plt.title(&#39;Overall-ratings&#39;) plt.xlabel(&#39;company&#39;) plt.ylabel(&#39;ratings&#39;) plt.bar(companies , height = data_bar, width = 0.5, color = [&#39;b&#39;, &#39;g&#39;, &#39;r&#39;, &#39;y&#39;, &#39;m&#39;, &#39;k&#39;]) plt.show() 效果如下： 可以看出facebook最高，但是鉴于facebook的样本量靠后，综合靠前的应该是亚马逊。 当然也可以对其他列的评分进行一个统计分析，我们使用一个for循环来进行： ratings_data = [&#39;overall-ratings&#39;, &#39;work-balance-stars&#39;, &#39;culture-values-stars&#39;, &#39;carrer-opportunities-stars&#39;, &#39;comp-benefit-stars&#39;, &#39;senior-mangemnet-stars&#39;] for ratings_datas in ratings_data: plt.figure() data_figure = data_df.groupby(&#39;company&#39;)[ratings_datas].mean() companies = pd.unique(data_df[&#39;company&#39;]) plt.bar(companies , height = data_bar, width = 0.5, color = [&#39;b&#39;, &#39;g&#39;, &#39;r&#39;, &#39;y&#39;, &#39;m&#39;, &#39;k&#39;]) plt.xlabel(ratings_datas) plt.show() 结果就不展示了，Facebook一枝独秀。 因为刚刚数据里面就区分在职员工和离职员工，接下来看一下他们的评价有什么不同。 通过构建一个新表，进行绘制： results = data_df.groupby([&#39;company&#39;, &#39;employee_status&#39;])[&#39;overall-ratings&#39;].mean() current_mean_ratings = results[:, &#39;Current&#39;] former_mean_ratings = results[:, &#39;Former&#39;] mean_ratings = pd.DataFrame() mean_ratings[&#39;Current Mean Ratings&#39;] = current_mean_ratings mean_ratings[&#39;Former Mean Ratings&#39;] = former_mean_ratings companies = pd.unique(data_df[&#39;company&#39;]) plt.figure(figsize = (10, 6)) ax = plt.subplot(111) ax.set_xticklabels(companies, fontsize = 12) plt.rcParams[&#39;font.sans-serif&#39;] = [&#39;SimHei&#39;] plt.rcParams[&#39;axes.unicode_minus&#39;] = False plt.xlabel(&#39;公司名称&#39;,size = 15) plt.ylabel(&#39;评分&#39;,size = 15) plt.title(&#39;各科技公司现员工与前员工评分的对比&#39;, size = 18) plt.bar(companies, height = mean_ratings[&#39;Current Mean Ratings&#39;], width = 0.4, label = &#39;现员工&#39;) f_xlim = [0.5, 1.5, 2.5 ,3.5, 4.5, 5.5] plt.bar(f_xlim, height = mean_ratings[&#39;Former Mean Ratings&#39;], width = 0.4, label = &#39;前员工&#39;) plt.legend(fontsize = 12) plt.show() 在上面的绘制中，增加了中文的显示的部分，效果如下： 此图可以看出，离职的员工的评分都比在职的员工低，这也符合正常的逻辑，如果认为这个公司好怎么还会离职呢？ （这个图中有个瑕疵，x轴的标签没有置中，想了很久没有想到） 下面对于文本进行分析： 首先导入库，然后使用for循环，将不同的公司进行区分，并使用join函数将同一公司的summary进行合并，最后绘制词云进行展示。 from wordcloud import WordCloud companies = pd.unique(data_df[&#39;company&#39;]) #interpolation参数是用于设置边界模糊度 for company in companies: company_df = data_df.loc[data_df[&#39;company&#39;] == company] company_review = &#39; &#39;.join(str(review) for review in company_df[&#39;summary&#39;]) wordcloud = WordCloud().generate(company_review) plt.imshow(wordcloud, interpolation = &#39;bilinear&#39;) plt.axis(&#39;off&#39;) plt.title(company) plt.show() 部分效果如下： 可以看到谷歌里面有一些engineer，亚马逊里面有culture等词，可以看出公司一些注重的点，当然此图还是可以进行优化的，如使用jieba库进行分词后，删除一些意义不大的、但是频率高的词汇，这个后面涉及到中文分词的时候再进行练习吧。 四、总结 这一次学习主要是了解怎么样来做数据分析： 1、通过head、info、describe等进行数据的预览，发现异常数据。 2、发现异常数据后进行处理，这是使用了to_numeric方法将含有异常数据的列转变成全为数值类型；然后使用fillna对空值填充为0，具体应该填充什么，应考虑实际的需求，常见的还有dropna还有空值的行进行删除，填充均值，插值等方法。 3、对数据进行可视化，提取信息，这里通过seaborn、pyplot、worldcloud对数据进行可视化，查看各公司员工的满意度。当然还可以使用机器学习相关知识对数据进行分析，提取更多信息，这个还没有学习太多，就不做了。 4、其他技巧，这里学习到了通过构建新的列，来进行数据分析的方法，到现在为止看到的几个案例中，这个技巧还是挺常用的。","@type":"BlogPosting","url":"https://mlh.app/2019/05/17/787112.html","headline":"数据分析——Glassdoor上各公司员工的评价分析","dateModified":"2019-05-17T00:00:00+08:00","datePublished":"2019-05-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/17/787112.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>数据分析——Glassdoor上各公司员工的评价分析</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <p>（参考：小象学院公开课，网络文献）<br> 1、分析目的：通过对美国各科技公司员工的匿名评价，分析员工满意度；<br> 2、数据来源：Glassdoor网站（类似于国内的看准等）；<br> 3、数据大小：37576kb，共67k条数据；<br> 4、使用的分析工具：jupyter notebook<br> 5、使用到的python库：pandas、matplotlib、seaborn、wordcloud<br> 6、分析思路：先通过pandas获取数据后，对数据进行预览；然后对数据进行预处理——如格式转换，去空值等；再通过对数值数据进行处理，绘制图表；最后对于文本数据进行拼接，绘制词云。</p> 
  <p><strong>一、数据的载入与预览</strong><br> 首先载入相关的库，读取数据：</p> 
  <pre><code>import pandas as pd
data_file = './dataset/employee_reviews.csv'
data_df = pd.read_csv(data_file)
</code></pre> 
  <p>对数据进行一个整体的概览：</p> 
  <pre><code>data_df.head()
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410211143871.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 看到数据导入成功了，接下来看一下整体的数据情况：</p> 
  <pre><code>data_df.info()
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410211423359.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 可以看到此样本数据共用67529行，16列，其中overall-ratings和helpful-count为数值数据，其他含字符串数据。但是从刚刚的数据预览可以看出从overall-ratings至helpfu-count中间7列应全为数值数据，所以说明中间那5列有干扰数据，需进行处理。</p> 
  <p><strong>二、数据的预处理</strong><br> 首先，先把文本数据和数值数据进行区分</p> 
  <pre><code>numeric_data = ['overall-ratings', 'work-balance-stars', 'culture-values-stars', 'carrer-opportunities-stars', 'comp-benefit-stars', 'senior-mangemnet-stars', 'helpful-count']
str_data = ['company', 'location', 'dates', 'job-title', 'summary', 'pros', 'cons', 'advice-to-mgmt', 'link']
</code></pre> 
  <p>然后使用pandas中的to_numeric方法将numeric_data中的数据进行转换，非数值数据补为NaN值</p> 
  <pre><code>data_df[numeric_data] = data_df[numeric_data].apply(pd.to_numeric, errors = 'coerce')
</code></pre> 
  <p>预览看一下：</p> 
  <pre><code>data_df.info()
</code></pre> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410215227218.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 发现之前那5列为object的数据已经变成了float格式，但是其数据的量都小于67529了，最小的只有53983条，可见里面的无用数据很多，为了更加直观再用head预览一下吧；</p> 
  <pre><code>data_df.head(20)
</code></pre> 
  <p>可以看到第15行开始就出现NaN值了。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410215644639.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">接下来使用fiilna方法对于NaN进行填充，统一填充为0。</p> 
  <pre><code>data_df[numeric_data] = data_df[numeric_data].fillna(0)
</code></pre> 
  <p>预览一下：</p> 
  <pre><code>data_df.head(20)
</code></pre> 
  <p>可以看到刚刚为NaN的数据已经变成了0了</p> 
  <p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410215942173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述">三、数据的可视化<br> 首先引入可视化需要的库:</p> 
  <pre><code>import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline   
#直接在jupyter中展现画布
</code></pre> 
  <p>看一下各个公司总体评论数量的情况，因为数据中有分前员工和现员工的，所以在表格里面新建一列，用于区分员工的状态：</p> 
  <pre><code>data_df['employee_status'] = ' '
data_df.loc[data_df['job-title'].str.contains('Current'), 'employee_status'] = 'Current'
data_df.loc[data_df['job-title'].str.contains('Former'), 'employee_status'] = 'Former'
</code></pre> 
  <p>然后用sns中的countplot方法绘制计数图：</p> 
  <pre><code>plt.figure(figsize = (8, 5))
sns.countplot(x = 'company', data = data_df, hue = 'employee_status')
plt.title('Records comparison of Current &amp; Former')
plt.show()
</code></pre> 
  <p>效果如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410220921889.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 这里就可以看出：亚马逊的员工在网上最活跃，facebook和netflix的员工不怎么活跃。</p> 
  <p>接下来就开始看评分情况了，先看一下总体的评分，也就是overall-ratings这一列，取平均值：</p> 
  <pre><code>plt.figure()
data_bar = data_df.groupby('company')['overall-ratings'].mean()
companies = pd.unique(data_df['company'])
plt.title('Overall-ratings')
plt.xlabel('company')
plt.ylabel('ratings')
plt.bar(companies , height = data_bar, width = 0.5, color = ['b', 'g', 'r', 'y', 'm', 'k'])
plt.show()
</code></pre> 
  <p>效果如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410221534415.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 可以看出facebook最高，但是鉴于facebook的样本量靠后，综合靠前的应该是亚马逊。<br> 当然也可以对其他列的评分进行一个统计分析，我们使用一个for循环来进行：</p> 
  <pre><code>ratings_data = ['overall-ratings', 'work-balance-stars', 'culture-values-stars', 'carrer-opportunities-stars', 'comp-benefit-stars', 'senior-mangemnet-stars']
for ratings_datas in ratings_data:
    plt.figure()
    data_figure = data_df.groupby('company')[ratings_datas].mean()
    companies = pd.unique(data_df['company'])
    plt.bar(companies , height = data_bar, width = 0.5, color = ['b', 'g', 'r', 'y', 'm', 'k'])
    plt.xlabel(ratings_datas)
    plt.show()
</code></pre> 
  <p>结果就不展示了，Facebook一枝独秀。</p> 
  <p>因为刚刚数据里面就区分在职员工和离职员工，接下来看一下他们的评价有什么不同。<br> 通过构建一个新表，进行绘制：</p> 
  <pre><code>results = data_df.groupby(['company', 'employee_status'])['overall-ratings'].mean()
current_mean_ratings = results[:, 'Current']
former_mean_ratings = results[:, 'Former']
mean_ratings = pd.DataFrame()
mean_ratings['Current Mean Ratings'] = current_mean_ratings
mean_ratings['Former Mean Ratings'] = former_mean_ratings
companies = pd.unique(data_df['company'])
plt.figure(figsize = (10, 6))
ax = plt.subplot(111)
ax.set_xticklabels(companies, fontsize = 12)
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.xlabel('公司名称',size = 15)
plt.ylabel('评分',size = 15)
plt.title('各科技公司现员工与前员工评分的对比', size = 18)
plt.bar(companies, height = mean_ratings['Current Mean Ratings'], width = 0.4, label = '现员工')
f_xlim = [0.5, 1.5, 2.5 ,3.5, 4.5, 5.5]
plt.bar(f_xlim, height = mean_ratings['Former Mean Ratings'], width = 0.4, label = '前员工')
plt.legend(fontsize = 12)
plt.show()
</code></pre> 
  <p>在上面的绘制中，增加了中文的显示的部分，效果如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410222323710.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 此图可以看出，离职的员工的评分都比在职的员工低，这也符合正常的逻辑，如果认为这个公司好怎么还会离职呢？<br> （这个图中有个瑕疵，x轴的标签没有置中，想了很久没有想到）</p> 
  <p>下面对于文本进行分析：<br> 首先导入库，然后使用for循环，将不同的公司进行区分，并使用join函数将同一公司的summary进行合并，最后绘制词云进行展示。</p> 
  <pre><code>from wordcloud import WordCloud
companies = pd.unique(data_df['company'])
#interpolation参数是用于设置边界模糊度
for company in companies:
    company_df = data_df.loc[data_df['company'] == company]
    company_review = ' '.join(str(review) for review in company_df['summary'])
    wordcloud = WordCloud().generate(company_review)
    plt.imshow(wordcloud, interpolation = 'bilinear')
    plt.axis('off')
    plt.title(company)
    plt.show()
</code></pre> 
  <p>部分效果如下：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190410222854807.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzA0ODI1,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 可以看到谷歌里面有一些engineer，亚马逊里面有culture等词，可以看出公司一些注重的点，当然此图还是可以进行优化的，如使用jieba库进行分词后，删除一些意义不大的、但是频率高的词汇，这个后面涉及到中文分词的时候再进行练习吧。</p> 
  <p>四、总结<br> 这一次学习主要是了解怎么样来做数据分析：<br> 1、通过head、info、describe等进行数据的预览，发现异常数据。<br> 2、发现异常数据后进行处理，这是使用了to_numeric方法将含有异常数据的列转变成全为数值类型；然后使用fillna对空值填充为0，具体应该填充什么，应考虑实际的需求，常见的还有dropna还有空值的行进行删除，填充均值，插值等方法。<br> 3、对数据进行可视化，提取信息，这里通过seaborn、pyplot、worldcloud对数据进行可视化，查看各公司员工的满意度。当然还可以使用机器学习相关知识对数据进行分析，提取更多信息，这个还没有学习太多，就不做了。<br> 4、其他技巧，这里学习到了通过构建新的列，来进行数据分析的方法，到现在为止看到的几个案例中，这个技巧还是挺常用的。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
