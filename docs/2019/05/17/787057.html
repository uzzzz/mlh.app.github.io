<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Python TensorFlow框架 实现手写数字识别系统 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Python TensorFlow框架 实现手写数字识别系统" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 手写数字识别算法的设计与实现 本文使用python基于TensorFlow设计手写数字识别算法，并编程实现GUI界面，构建手写数字识别系统。这是本人的本科毕业论文课题，当然，这个也是机器学习的基本问题。本博文不会以论文的形式展现，而是以编程实战完成机器学习项目的角度去描述。 项目要求：本文主要解决的问题是手写数字识别，最终要完成一个识别系统。 设计识别率高的算法，实现快速识别的系统。 1 LeNet-5模型的介绍 本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5，如下图所示：这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。 如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击这里可以查看教程。 LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。 LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。 第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。 S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。 S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。 S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。 C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。 F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。 卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。 2 手写数字识别算法模型的构建 2.1 各层设计 有了第一节的基础知识，在这基础上，进行完善和改进。 输入层设计 输入为28×28的矩阵，而不是向量。 激活函数的选取 Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。因此，本文设计的网络使用ReLU函数作为激活函数。 ReLU的表达式： 卷积层设计 本文设计卷积神经网络采取的是离散卷积，卷积步长为1，即水平和垂直方向每次运算完，移动一个像素。卷积核大小为5×5。 降采样层 本文降采样层的pooling方式是max-pooling，大小为2×2。 输出层设计 输出层设置为10个神经网络节点。数字0~9的目标向量如下表所示： 2.2 网络模型的总体结构 其实，本文网络的构建，参考自TensorFlow的手写数字识别的官方教程的，读者有兴趣也可以详细阅读。 2.3 编程实现算法 本文使用Python，调用TensorFlow的api完成手写数字识别的算法。注：本文程序运行环境是：Win10,python3.5.2。当然，也可以在Linux下运行，由于TensorFlow对py2和py3兼容得比较好，在Linux下可以在python2.7中运行。 #!/usr/bin/env python2# -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Fri Feb 17 19:50:49 2017@author: Yonghao Huang&quot;&quot;&quot;#import modulesimport numpy as npimport matplotlib.pyplot as pltimport tensorflow as tfimport timefrom datetime import timedeltaimport mathfrom tensorflow.examples.tutorials.mnist import input_datadef new_weights(shape):&nbsp;&nbsp;&nbsp; return tf.Variable(tf.truncated_normal(shape,stddev=0.05))def new_biases(length):&nbsp;&nbsp;&nbsp; return tf.Variable(tf.constant(0.1,shape=length))def conv2d(x,W):&nbsp;&nbsp;&nbsp; return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=&#39;SAME&#39;)def max_pool_2x2(inputx):&nbsp;&nbsp;&nbsp; return tf.nn.max_pool(inputx,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#39;SAME&#39;)#import datadata = input_data.read_data_sets(&quot;./data&quot;, one_hot=True)&nbsp; # one_hot means [0 0 1 0 0 0 0 0 0 0] stands for 2print(&quot;Size of:&quot;)print(&quot;--Training-set:\t\t{}&quot;.format(len(data.train.labels)))print(&quot;--Testing-set:\t\t{}&quot;.format(len(data.test.labels)))print(&quot;--Validation-set:\t\t{}&quot;.format(len(data.validation.labels)))data.test.cls = np.argmax(data.test.labels,axis=1)&nbsp;&nbsp; # show the real test labels:&nbsp; [7 2 1 ..., 4 5 6], 10000valuesx = tf.placeholder(&quot;float&quot;,shape=[None,784],name=&#39;x&#39;)x_image = tf.reshape(x,[-1,28,28,1])y_true = tf.placeholder(&quot;float&quot;,shape=[None,10],name=&#39;y_true&#39;)y_true_cls = tf.argmax(y_true,dimension=1)# Conv 1layer_conv1 = {&quot;weights&quot;:new_weights([5,5,1,32]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([32])}h_conv1 = tf.nn.relu(conv2d(x_image,layer_conv1[&quot;weights&quot;])+layer_conv1[&quot;biases&quot;])h_pool1 = max_pool_2x2(h_conv1)# Conv 2layer_conv2 = {&quot;weights&quot;:new_weights([5,5,32,64]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([64])}h_conv2 = tf.nn.relu(conv2d(h_pool1,layer_conv2[&quot;weights&quot;])+layer_conv2[&quot;biases&quot;])h_pool2 = max_pool_2x2(h_conv2)# Full-connected layer 1fc1_layer = {&quot;weights&quot;:new_weights([7*7*64,1024]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([1024])}h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,fc1_layer[&quot;weights&quot;])+fc1_layer[&quot;biases&quot;])# Droupout Layerkeep_prob = tf.placeholder(&quot;float&quot;)h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)# Full-connected layer 2fc2_layer = {&quot;weights&quot;:new_weights([1024,10]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_weights([10])}# Predicted classy_pred = tf.nn.softmax(tf.matmul(h_fc1_drop,fc2_layer[&quot;weights&quot;])+fc2_layer[&quot;biases&quot;])&nbsp; # The output is like [0 0 1 0 0 0 0 0 0 0]y_pred_cls = tf.argmax(y_pred,dimension=1)&nbsp; # Show the real predict number like &#39;2&#39;# cost function to be optimizedcross_entropy = -tf.reduce_mean(y_true*tf.log(y_pred))optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)# Performance Measurescorrect_prediction = tf.equal(y_pred_cls,y_true_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;))with tf.Session() as sess:&nbsp;&nbsp;&nbsp; init = tf.global_variables_initializer()&nbsp;&nbsp;&nbsp; sess.run(init)&nbsp;&nbsp;&nbsp; train_batch_size = 50&nbsp;&nbsp;&nbsp; def optimize(num_iterations):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total_iterations=0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; start_time = time.time()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for i in range(total_iterations,total_iterations+num_iterations):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x_batch,y_true_batch = data.train.next_batch(train_batch_size)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict_train_op = {x:x_batch,y_true:y_true_batch,keep_prob:0.5}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict_train = {x:x_batch,y_true:y_true_batch,keep_prob:1.0}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sess.run(optimizer,feed_dict=feed_dict_train_op)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print status every 100 iterations.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if i%100==0:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Calculate the accuracy on the training-set.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; acc = sess.run(accuracy,feed_dict=feed_dict_train)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Message for printing.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; msg = &quot;Optimization Iteration:{0:&gt;6}, Training Accuracy: {1:&gt;6.1%}&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print it.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(msg.format(i+1,acc))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Update the total number of iterations performed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total_iterations += num_iterations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Ending time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; end_time = time.time()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Difference between start and end_times.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; time_dif = end_time-start_time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print the time-usage&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(&quot;Time usage:&quot;+str(timedelta(seconds=int(round(time_dif)))))&nbsp;&nbsp;&nbsp; test_batch_size = 256&nbsp;&nbsp;&nbsp; def print_test_accuracy():&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Number of images in the test-set.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; num_test = len(data.test.images)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_pred = np.zeros(shape=num_test,dtype=np.int)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i = 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while i &lt; num_test:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # The ending index for the next batch is denoted j.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; j = min(i+test_batch_size,num_test)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Get the images from the test-set between index i and j&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; images = data.test.images[i:j, :]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Get the associated labels&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; labels = data.test.labels[i:j, :]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Create a feed-dict with these images and labels.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict={x:images,y_true:labels,keep_prob:1.0}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Calculate the predicted class using Tensorflow.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_pred[i:j] = sess.run(y_pred_cls,feed_dict=feed_dict)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Set the start-index for the next batch to the&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # end-index of the current batch&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i = j&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_true = data.test.cls&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correct = (cls_true==cls_pred)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correct_sum = correct.sum()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; acc = float(correct_sum) / num_test&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print the accuracy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; msg = &quot;Accuracy on Test-Set: {0:.1%} ({1}/{2})&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(msg.format(acc,correct_sum,num_test))&nbsp;&nbsp;&nbsp; # Performance after 10000 optimization iterations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 运行结果显示：测试集中准确率大概为99.2%。我还写了一些辅助函数，可以查看部分识别错误的图片，还可以查看混淆矩阵， 2.3 实现手写识别系统 最后，将训练好的参数保存，封装进一个GUI界面中，形成一个手写识别系统。系统中还添加了一点图像预处理的操作，比如灰度化，图像信息的归一化等，更贴近实际应用。系统可进行快速识别，如下图： 3 总结 本文实现的系统其实是基于卷积神经网络的手写数字识别系统。该系统能快速实现手写数字识别，成功识别率高。缺点：只能正确识别单个数字，图像预处理还不够，没有进行图像分割，读者也可以自行添加，进行完善。 4 收获 本人之前的本科期间，虽然努力学习高数、线性代数和概率论，但是没有认真学习过机器学习，本人是2017年才开始系统学习机器学习相关知识，而且本科毕业论文也选择了相关的课题，虽然比较基础，但是认真完成后，有一种学以致用的满足感，同时也激励着我进行更深入的理论学习和实践探讨，与所有读者共勉。 ==================================2018年5月13日更新 源码分享链接：链接: https://pan.baidu.com/s/1BItkfd1bW-hJQaXzzQ3sVQ 提取码: spbv========================================2018年6月6日更新更新！！ python(TensorFlow)实现手写字符识别 此处的“手写字符”，其实指的是notMNIST数据库中的手写字符，其实和MNIST数据库是一样的。这里实现手写字符识别，主要是展示TensorFlow框架的可拓展性很强，具体来说，就是可以通过改动少部分的代码，从而实现一个新的识别功能。 NotMnist数据库 这个数据库和MNIST数据库基本一样，只是把10个数字换成了10个字母，即：A,B,C,D,E,F,G,H,I,J,K当然，这个数据库的识别难度大一些，因为数据噪声更多一些，详情读者可以搜一搜了解一下。 实战 将NotMNIST数据库下载以后，放在本博文上述的网络中，基本不需要修改代码，直接训练，即可得到一个能识别字符的网络模型。最后在测试集中的准确率，比MNIST的会低一些，大概为96%左右。本文也将训练好的网络模型封装在和上述系统相似的GUI系统中， 识别效果还可以！同样，将卷积卷积层可视化。 结语 TensorFlow框架可拓展性很强，只要设计好了网络，就能很容易的实现出来；同时，使用基本的CNN识别整体架构也是大同小异的，很多识别任务是通用的。当然，在具体的实践中需要得到接近完美的效果，还是要下很大功夫的！努力学习吧，加油！（如果你/您有什么有趣的想法，可以在下面留言，如果我也感兴趣同时又有时间的话，我会尝试做一做，_）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;" />
<meta property="og:description" content="&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 手写数字识别算法的设计与实现 本文使用python基于TensorFlow设计手写数字识别算法，并编程实现GUI界面，构建手写数字识别系统。这是本人的本科毕业论文课题，当然，这个也是机器学习的基本问题。本博文不会以论文的形式展现，而是以编程实战完成机器学习项目的角度去描述。 项目要求：本文主要解决的问题是手写数字识别，最终要完成一个识别系统。 设计识别率高的算法，实现快速识别的系统。 1 LeNet-5模型的介绍 本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5，如下图所示：这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。 如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击这里可以查看教程。 LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。 LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。 第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。 S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。 S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。 S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。 C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。 F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。 卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。 2 手写数字识别算法模型的构建 2.1 各层设计 有了第一节的基础知识，在这基础上，进行完善和改进。 输入层设计 输入为28×28的矩阵，而不是向量。 激活函数的选取 Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。因此，本文设计的网络使用ReLU函数作为激活函数。 ReLU的表达式： 卷积层设计 本文设计卷积神经网络采取的是离散卷积，卷积步长为1，即水平和垂直方向每次运算完，移动一个像素。卷积核大小为5×5。 降采样层 本文降采样层的pooling方式是max-pooling，大小为2×2。 输出层设计 输出层设置为10个神经网络节点。数字0~9的目标向量如下表所示： 2.2 网络模型的总体结构 其实，本文网络的构建，参考自TensorFlow的手写数字识别的官方教程的，读者有兴趣也可以详细阅读。 2.3 编程实现算法 本文使用Python，调用TensorFlow的api完成手写数字识别的算法。注：本文程序运行环境是：Win10,python3.5.2。当然，也可以在Linux下运行，由于TensorFlow对py2和py3兼容得比较好，在Linux下可以在python2.7中运行。 #!/usr/bin/env python2# -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Fri Feb 17 19:50:49 2017@author: Yonghao Huang&quot;&quot;&quot;#import modulesimport numpy as npimport matplotlib.pyplot as pltimport tensorflow as tfimport timefrom datetime import timedeltaimport mathfrom tensorflow.examples.tutorials.mnist import input_datadef new_weights(shape):&nbsp;&nbsp;&nbsp; return tf.Variable(tf.truncated_normal(shape,stddev=0.05))def new_biases(length):&nbsp;&nbsp;&nbsp; return tf.Variable(tf.constant(0.1,shape=length))def conv2d(x,W):&nbsp;&nbsp;&nbsp; return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=&#39;SAME&#39;)def max_pool_2x2(inputx):&nbsp;&nbsp;&nbsp; return tf.nn.max_pool(inputx,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#39;SAME&#39;)#import datadata = input_data.read_data_sets(&quot;./data&quot;, one_hot=True)&nbsp; # one_hot means [0 0 1 0 0 0 0 0 0 0] stands for 2print(&quot;Size of:&quot;)print(&quot;--Training-set:\t\t{}&quot;.format(len(data.train.labels)))print(&quot;--Testing-set:\t\t{}&quot;.format(len(data.test.labels)))print(&quot;--Validation-set:\t\t{}&quot;.format(len(data.validation.labels)))data.test.cls = np.argmax(data.test.labels,axis=1)&nbsp;&nbsp; # show the real test labels:&nbsp; [7 2 1 ..., 4 5 6], 10000valuesx = tf.placeholder(&quot;float&quot;,shape=[None,784],name=&#39;x&#39;)x_image = tf.reshape(x,[-1,28,28,1])y_true = tf.placeholder(&quot;float&quot;,shape=[None,10],name=&#39;y_true&#39;)y_true_cls = tf.argmax(y_true,dimension=1)# Conv 1layer_conv1 = {&quot;weights&quot;:new_weights([5,5,1,32]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([32])}h_conv1 = tf.nn.relu(conv2d(x_image,layer_conv1[&quot;weights&quot;])+layer_conv1[&quot;biases&quot;])h_pool1 = max_pool_2x2(h_conv1)# Conv 2layer_conv2 = {&quot;weights&quot;:new_weights([5,5,32,64]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([64])}h_conv2 = tf.nn.relu(conv2d(h_pool1,layer_conv2[&quot;weights&quot;])+layer_conv2[&quot;biases&quot;])h_pool2 = max_pool_2x2(h_conv2)# Full-connected layer 1fc1_layer = {&quot;weights&quot;:new_weights([7*7*64,1024]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([1024])}h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,fc1_layer[&quot;weights&quot;])+fc1_layer[&quot;biases&quot;])# Droupout Layerkeep_prob = tf.placeholder(&quot;float&quot;)h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)# Full-connected layer 2fc2_layer = {&quot;weights&quot;:new_weights([1024,10]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_weights([10])}# Predicted classy_pred = tf.nn.softmax(tf.matmul(h_fc1_drop,fc2_layer[&quot;weights&quot;])+fc2_layer[&quot;biases&quot;])&nbsp; # The output is like [0 0 1 0 0 0 0 0 0 0]y_pred_cls = tf.argmax(y_pred,dimension=1)&nbsp; # Show the real predict number like &#39;2&#39;# cost function to be optimizedcross_entropy = -tf.reduce_mean(y_true*tf.log(y_pred))optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)# Performance Measurescorrect_prediction = tf.equal(y_pred_cls,y_true_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;))with tf.Session() as sess:&nbsp;&nbsp;&nbsp; init = tf.global_variables_initializer()&nbsp;&nbsp;&nbsp; sess.run(init)&nbsp;&nbsp;&nbsp; train_batch_size = 50&nbsp;&nbsp;&nbsp; def optimize(num_iterations):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total_iterations=0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; start_time = time.time()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for i in range(total_iterations,total_iterations+num_iterations):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x_batch,y_true_batch = data.train.next_batch(train_batch_size)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict_train_op = {x:x_batch,y_true:y_true_batch,keep_prob:0.5}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict_train = {x:x_batch,y_true:y_true_batch,keep_prob:1.0}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sess.run(optimizer,feed_dict=feed_dict_train_op)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print status every 100 iterations.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if i%100==0:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Calculate the accuracy on the training-set.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; acc = sess.run(accuracy,feed_dict=feed_dict_train)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Message for printing.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; msg = &quot;Optimization Iteration:{0:&gt;6}, Training Accuracy: {1:&gt;6.1%}&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print it.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(msg.format(i+1,acc))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Update the total number of iterations performed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total_iterations += num_iterations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Ending time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; end_time = time.time()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Difference between start and end_times.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; time_dif = end_time-start_time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print the time-usage&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(&quot;Time usage:&quot;+str(timedelta(seconds=int(round(time_dif)))))&nbsp;&nbsp;&nbsp; test_batch_size = 256&nbsp;&nbsp;&nbsp; def print_test_accuracy():&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Number of images in the test-set.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; num_test = len(data.test.images)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_pred = np.zeros(shape=num_test,dtype=np.int)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i = 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while i &lt; num_test:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # The ending index for the next batch is denoted j.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; j = min(i+test_batch_size,num_test)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Get the images from the test-set between index i and j&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; images = data.test.images[i:j, :]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Get the associated labels&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; labels = data.test.labels[i:j, :]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Create a feed-dict with these images and labels.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict={x:images,y_true:labels,keep_prob:1.0}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Calculate the predicted class using Tensorflow.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_pred[i:j] = sess.run(y_pred_cls,feed_dict=feed_dict)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Set the start-index for the next batch to the&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # end-index of the current batch&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i = j&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_true = data.test.cls&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correct = (cls_true==cls_pred)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correct_sum = correct.sum()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; acc = float(correct_sum) / num_test&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print the accuracy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; msg = &quot;Accuracy on Test-Set: {0:.1%} ({1}/{2})&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(msg.format(acc,correct_sum,num_test))&nbsp;&nbsp;&nbsp; # Performance after 10000 optimization iterations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 运行结果显示：测试集中准确率大概为99.2%。我还写了一些辅助函数，可以查看部分识别错误的图片，还可以查看混淆矩阵， 2.3 实现手写识别系统 最后，将训练好的参数保存，封装进一个GUI界面中，形成一个手写识别系统。系统中还添加了一点图像预处理的操作，比如灰度化，图像信息的归一化等，更贴近实际应用。系统可进行快速识别，如下图： 3 总结 本文实现的系统其实是基于卷积神经网络的手写数字识别系统。该系统能快速实现手写数字识别，成功识别率高。缺点：只能正确识别单个数字，图像预处理还不够，没有进行图像分割，读者也可以自行添加，进行完善。 4 收获 本人之前的本科期间，虽然努力学习高数、线性代数和概率论，但是没有认真学习过机器学习，本人是2017年才开始系统学习机器学习相关知识，而且本科毕业论文也选择了相关的课题，虽然比较基础，但是认真完成后，有一种学以致用的满足感，同时也激励着我进行更深入的理论学习和实践探讨，与所有读者共勉。 ==================================2018年5月13日更新 源码分享链接：链接: https://pan.baidu.com/s/1BItkfd1bW-hJQaXzzQ3sVQ 提取码: spbv========================================2018年6月6日更新更新！！ python(TensorFlow)实现手写字符识别 此处的“手写字符”，其实指的是notMNIST数据库中的手写字符，其实和MNIST数据库是一样的。这里实现手写字符识别，主要是展示TensorFlow框架的可拓展性很强，具体来说，就是可以通过改动少部分的代码，从而实现一个新的识别功能。 NotMnist数据库 这个数据库和MNIST数据库基本一样，只是把10个数字换成了10个字母，即：A,B,C,D,E,F,G,H,I,J,K当然，这个数据库的识别难度大一些，因为数据噪声更多一些，详情读者可以搜一搜了解一下。 实战 将NotMNIST数据库下载以后，放在本博文上述的网络中，基本不需要修改代码，直接训练，即可得到一个能识别字符的网络模型。最后在测试集中的准确率，比MNIST的会低一些，大概为96%左右。本文也将训练好的网络模型封装在和上述系统相似的GUI系统中， 识别效果还可以！同样，将卷积卷积层可视化。 结语 TensorFlow框架可拓展性很强，只要设计好了网络，就能很容易的实现出来；同时，使用基本的CNN识别整体架构也是大同小异的，很多识别任务是通用的。当然，在具体的实践中需要得到接近完美的效果，还是要下很大功夫的！努力学习吧，加油！（如果你/您有什么有趣的想法，可以在下面留言，如果我也感兴趣同时又有时间的话，我会尝试做一做，_）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;" />
<link rel="canonical" href="https://mlh.app/2019/05/17/787057.html" />
<meta property="og:url" content="https://mlh.app/2019/05/17/787057.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 手写数字识别算法的设计与实现 本文使用python基于TensorFlow设计手写数字识别算法，并编程实现GUI界面，构建手写数字识别系统。这是本人的本科毕业论文课题，当然，这个也是机器学习的基本问题。本博文不会以论文的形式展现，而是以编程实战完成机器学习项目的角度去描述。 项目要求：本文主要解决的问题是手写数字识别，最终要完成一个识别系统。 设计识别率高的算法，实现快速识别的系统。 1 LeNet-5模型的介绍 本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5，如下图所示：这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。 如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击这里可以查看教程。 LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。 LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。 第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。 S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。 S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。 S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。 C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。 F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。 卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。 2 手写数字识别算法模型的构建 2.1 各层设计 有了第一节的基础知识，在这基础上，进行完善和改进。 输入层设计 输入为28×28的矩阵，而不是向量。 激活函数的选取 Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。因此，本文设计的网络使用ReLU函数作为激活函数。 ReLU的表达式： 卷积层设计 本文设计卷积神经网络采取的是离散卷积，卷积步长为1，即水平和垂直方向每次运算完，移动一个像素。卷积核大小为5×5。 降采样层 本文降采样层的pooling方式是max-pooling，大小为2×2。 输出层设计 输出层设置为10个神经网络节点。数字0~9的目标向量如下表所示： 2.2 网络模型的总体结构 其实，本文网络的构建，参考自TensorFlow的手写数字识别的官方教程的，读者有兴趣也可以详细阅读。 2.3 编程实现算法 本文使用Python，调用TensorFlow的api完成手写数字识别的算法。注：本文程序运行环境是：Win10,python3.5.2。当然，也可以在Linux下运行，由于TensorFlow对py2和py3兼容得比较好，在Linux下可以在python2.7中运行。 #!/usr/bin/env python2# -*- coding: utf-8 -*-&quot;&quot;&quot;Created on Fri Feb 17 19:50:49 2017@author: Yonghao Huang&quot;&quot;&quot;#import modulesimport numpy as npimport matplotlib.pyplot as pltimport tensorflow as tfimport timefrom datetime import timedeltaimport mathfrom tensorflow.examples.tutorials.mnist import input_datadef new_weights(shape):&nbsp;&nbsp;&nbsp; return tf.Variable(tf.truncated_normal(shape,stddev=0.05))def new_biases(length):&nbsp;&nbsp;&nbsp; return tf.Variable(tf.constant(0.1,shape=length))def conv2d(x,W):&nbsp;&nbsp;&nbsp; return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=&#39;SAME&#39;)def max_pool_2x2(inputx):&nbsp;&nbsp;&nbsp; return tf.nn.max_pool(inputx,ksize=[1,2,2,1],strides=[1,2,2,1],padding=&#39;SAME&#39;)#import datadata = input_data.read_data_sets(&quot;./data&quot;, one_hot=True)&nbsp; # one_hot means [0 0 1 0 0 0 0 0 0 0] stands for 2print(&quot;Size of:&quot;)print(&quot;--Training-set:\\t\\t{}&quot;.format(len(data.train.labels)))print(&quot;--Testing-set:\\t\\t{}&quot;.format(len(data.test.labels)))print(&quot;--Validation-set:\\t\\t{}&quot;.format(len(data.validation.labels)))data.test.cls = np.argmax(data.test.labels,axis=1)&nbsp;&nbsp; # show the real test labels:&nbsp; [7 2 1 ..., 4 5 6], 10000valuesx = tf.placeholder(&quot;float&quot;,shape=[None,784],name=&#39;x&#39;)x_image = tf.reshape(x,[-1,28,28,1])y_true = tf.placeholder(&quot;float&quot;,shape=[None,10],name=&#39;y_true&#39;)y_true_cls = tf.argmax(y_true,dimension=1)# Conv 1layer_conv1 = {&quot;weights&quot;:new_weights([5,5,1,32]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([32])}h_conv1 = tf.nn.relu(conv2d(x_image,layer_conv1[&quot;weights&quot;])+layer_conv1[&quot;biases&quot;])h_pool1 = max_pool_2x2(h_conv1)# Conv 2layer_conv2 = {&quot;weights&quot;:new_weights([5,5,32,64]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([64])}h_conv2 = tf.nn.relu(conv2d(h_pool1,layer_conv2[&quot;weights&quot;])+layer_conv2[&quot;biases&quot;])h_pool2 = max_pool_2x2(h_conv2)# Full-connected layer 1fc1_layer = {&quot;weights&quot;:new_weights([7*7*64,1024]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_biases([1024])}h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,fc1_layer[&quot;weights&quot;])+fc1_layer[&quot;biases&quot;])# Droupout Layerkeep_prob = tf.placeholder(&quot;float&quot;)h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)# Full-connected layer 2fc2_layer = {&quot;weights&quot;:new_weights([1024,10]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;biases&quot;:new_weights([10])}# Predicted classy_pred = tf.nn.softmax(tf.matmul(h_fc1_drop,fc2_layer[&quot;weights&quot;])+fc2_layer[&quot;biases&quot;])&nbsp; # The output is like [0 0 1 0 0 0 0 0 0 0]y_pred_cls = tf.argmax(y_pred,dimension=1)&nbsp; # Show the real predict number like &#39;2&#39;# cost function to be optimizedcross_entropy = -tf.reduce_mean(y_true*tf.log(y_pred))optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)# Performance Measurescorrect_prediction = tf.equal(y_pred_cls,y_true_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction,&quot;float&quot;))with tf.Session() as sess:&nbsp;&nbsp;&nbsp; init = tf.global_variables_initializer()&nbsp;&nbsp;&nbsp; sess.run(init)&nbsp;&nbsp;&nbsp; train_batch_size = 50&nbsp;&nbsp;&nbsp; def optimize(num_iterations):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total_iterations=0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; start_time = time.time()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for i in range(total_iterations,total_iterations+num_iterations):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x_batch,y_true_batch = data.train.next_batch(train_batch_size)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict_train_op = {x:x_batch,y_true:y_true_batch,keep_prob:0.5}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict_train = {x:x_batch,y_true:y_true_batch,keep_prob:1.0}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sess.run(optimizer,feed_dict=feed_dict_train_op)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print status every 100 iterations.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if i%100==0:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Calculate the accuracy on the training-set.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; acc = sess.run(accuracy,feed_dict=feed_dict_train)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Message for printing.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; msg = &quot;Optimization Iteration:{0:&gt;6}, Training Accuracy: {1:&gt;6.1%}&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print it.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(msg.format(i+1,acc))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Update the total number of iterations performed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total_iterations += num_iterations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Ending time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; end_time = time.time()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Difference between start and end_times.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; time_dif = end_time-start_time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print the time-usage&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(&quot;Time usage:&quot;+str(timedelta(seconds=int(round(time_dif)))))&nbsp;&nbsp;&nbsp; test_batch_size = 256&nbsp;&nbsp;&nbsp; def print_test_accuracy():&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Number of images in the test-set.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; num_test = len(data.test.images)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_pred = np.zeros(shape=num_test,dtype=np.int)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i = 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while i &lt; num_test:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # The ending index for the next batch is denoted j.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; j = min(i+test_batch_size,num_test)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Get the images from the test-set between index i and j&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; images = data.test.images[i:j, :]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Get the associated labels&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; labels = data.test.labels[i:j, :]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Create a feed-dict with these images and labels.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict={x:images,y_true:labels,keep_prob:1.0}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Calculate the predicted class using Tensorflow.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_pred[i:j] = sess.run(y_pred_cls,feed_dict=feed_dict)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Set the start-index for the next batch to the&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # end-index of the current batch&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i = j&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_true = data.test.cls&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correct = (cls_true==cls_pred)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correct_sum = correct.sum()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; acc = float(correct_sum) / num_test&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print the accuracy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; msg = &quot;Accuracy on Test-Set: {0:.1%} ({1}/{2})&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(msg.format(acc,correct_sum,num_test))&nbsp;&nbsp;&nbsp; # Performance after 10000 optimization iterations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 运行结果显示：测试集中准确率大概为99.2%。我还写了一些辅助函数，可以查看部分识别错误的图片，还可以查看混淆矩阵， 2.3 实现手写识别系统 最后，将训练好的参数保存，封装进一个GUI界面中，形成一个手写识别系统。系统中还添加了一点图像预处理的操作，比如灰度化，图像信息的归一化等，更贴近实际应用。系统可进行快速识别，如下图： 3 总结 本文实现的系统其实是基于卷积神经网络的手写数字识别系统。该系统能快速实现手写数字识别，成功识别率高。缺点：只能正确识别单个数字，图像预处理还不够，没有进行图像分割，读者也可以自行添加，进行完善。 4 收获 本人之前的本科期间，虽然努力学习高数、线性代数和概率论，但是没有认真学习过机器学习，本人是2017年才开始系统学习机器学习相关知识，而且本科毕业论文也选择了相关的课题，虽然比较基础，但是认真完成后，有一种学以致用的满足感，同时也激励着我进行更深入的理论学习和实践探讨，与所有读者共勉。 ==================================2018年5月13日更新 源码分享链接：链接: https://pan.baidu.com/s/1BItkfd1bW-hJQaXzzQ3sVQ 提取码: spbv========================================2018年6月6日更新更新！！ python(TensorFlow)实现手写字符识别 此处的“手写字符”，其实指的是notMNIST数据库中的手写字符，其实和MNIST数据库是一样的。这里实现手写字符识别，主要是展示TensorFlow框架的可拓展性很强，具体来说，就是可以通过改动少部分的代码，从而实现一个新的识别功能。 NotMnist数据库 这个数据库和MNIST数据库基本一样，只是把10个数字换成了10个字母，即：A,B,C,D,E,F,G,H,I,J,K当然，这个数据库的识别难度大一些，因为数据噪声更多一些，详情读者可以搜一搜了解一下。 实战 将NotMNIST数据库下载以后，放在本博文上述的网络中，基本不需要修改代码，直接训练，即可得到一个能识别字符的网络模型。最后在测试集中的准确率，比MNIST的会低一些，大概为96%左右。本文也将训练好的网络模型封装在和上述系统相似的GUI系统中， 识别效果还可以！同样，将卷积卷积层可视化。 结语 TensorFlow框架可拓展性很强，只要设计好了网络，就能很容易的实现出来；同时，使用基本的CNN识别整体架构也是大同小异的，很多识别任务是通用的。当然，在具体的实践中需要得到接近完美的效果，还是要下很大功夫的！努力学习吧，加油！（如果你/您有什么有趣的想法，可以在下面留言，如果我也感兴趣同时又有时间的话，我会尝试做一做，_）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;","@type":"BlogPosting","url":"https://mlh.app/2019/05/17/787057.html","headline":"Python TensorFlow框架 实现手写数字识别系统","dateModified":"2019-05-17T00:00:00+08:00","datePublished":"2019-05-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/17/787057.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Python TensorFlow框架 实现手写数字识别系统</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <div class="markdown_views prism-tomorrow-night" id="content_views">
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
   <!-- flowchart &#31661;&#22836;&#22270;&#26631; &#21247;&#21024; -->&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
   <div class="markdown_views prism-atom-one-dark" id="content_views">
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
    <!-- flowchart &amp;#31661;&amp;#22836;&amp;#22270;&amp;#26631; &amp;#21247;&amp;#21024; --> 
    <h2><a></a><a target="_blank"></a><a id="font_face_0" target="_blank"></a><font face="微软雅黑"><strong>手写数字识别算法的设计与实现</strong></font></h2>
    <p><strong>本文使用python基于TensorFlow设计手写数字识别算法，并编程实现GUI界面，构建手写数字识别系统。这是本人的本科毕业论文课题，当然，这个也是机器学习的基本问题。本博文不会以论文的形式展现，而是以编程实战完成机器学习项目的角度去描述。</strong></p>
    <hr>
    <p>项目要求：本文主要解决的问题是手写数字识别，最终要完成一个识别系统。</p>
    <p>设计识别率高的算法，实现快速识别的系统。</p>
    <h3><a></a><a target="_blank"></a><a id="1_LeNet5_9" target="_blank"></a><strong>1 LeNet-5模型的介绍</strong></h3>
    <p>本文实现手写数字识别，使用的是卷积神经网络，建模思想来自LeNet-5，如下图所示：<br><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205724826.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70"><br>这是原始的应用于手写数字识别的网络，我认为这也是最简单的深度网络。</p>
   </div>
   <p>如果你觉得这篇文章看起来稍微还有些吃力，或者想要系统地学习人工智能，那么推荐你去看床长人工智能教程。非常棒的大神之作，教程不仅通俗易懂，而且很风趣幽默。点击<a href="http://www.captainbed.net/csdn" rel="nofollow" target="_blank">这里</a>可以查看教程。</p>
   <p>LeNet-5不包括输入，一共7层，较低层由卷积层和最大池化层交替构成，更高层则是全连接和高斯连接。</p>
   <p>LeNet-5的输入与BP神经网路的不一样。这里假设图像是黑白的，那么LeNet-5的输入是一个32*32的二维矩阵。同时，输入与下一层并不是全连接的，而是进行稀疏连接。本层每个神经元的输入来自于前一层神经元的局部区域(5×5)，卷积核对原始图像卷积的结果加上相应的阈值，得出的结果再经过激活函数处理，输出即形成卷积层（C层）。卷积层中的每个特征映射都各自共享权重和阈值，这样能大大减少训练开销。降采样层（S层）为减少数据量同时保存有用信息，进行亚抽样。</p>
   <p>第一个卷积层（C1层）由6个特征映射构成，每个特征映射是一个28×28的神经元阵列，其中每个神经元负责从5×5的区域通过卷积滤波器提取局部特征。一般情况下，滤波器数量越多，就会得出越多的特征映射，反映越多的原始图像的特征。本层训练参数共6×(5×5+1)=156个，每个像素点都是由上层5×5=25个像素点和1个阈值连接计算所得，共28×28×156=122304个连接。</p>
   <p>S2层是对应上述6个特征映射的降采样层（pooling层）。pooling层的实现方法有两种，分别是max-pooling和mean-pooling，LeNet-5采用的是mean-pooling，即取n×n区域内像素的均值。C1通过2×2的窗口区域像素求均值再加上本层的阈值，然后经过激活函数的处理，得到S2层。pooling的实现，在保存图片信息的基础上，减少了权重参数，降低了计算成本，还能控制过拟合。本层学习参数共有1*6+6=12个，S2中的每个像素都与C1层中的2×2个像素和1个阈值相连，共6×(2×2+1)×14×14=5880个连接。</p>
   <p>S2层和C3层的连接比较复杂。C3卷积层是由16个大小为10×10的特征映射组成的，当中的每个特征映射与S2层的若干个特征映射的局部感受野（大小为5×5）相连。其中，前6个特征映射与S2层连续3个特征映射相连，后面接着的6个映射与S2层的连续的4个特征映射相连，然后的3个特征映射与S2层不连续的4个特征映射相连，最后一个映射与S2层的所有特征映射相连。此处卷积核大小为5×5，所以学习参数共有6×(3×5×5+1)+9×(4×5×5+1)+1×(6×5×5+1)=1516个参数。而图像大小为28×28，因此共有151600个连接。</p>
   <p>S4层是对C3层进行的降采样，与S2同理，学习参数有16×1+16=32个，同时共有16×(2×2+1)×5×5=2000个连接。</p>
   <p>C5层是由120个大小为1×1的特征映射组成的卷积层，而且S4层与C5层是全连接的，因此学习参数总个数为120×(16×25+1)=48120个。</p>
   <p>F6是与C5全连接的84个神经元，所以共有84×(120+1)=10164个学习参数。<br></p>
   <p>卷积神经网络通过通过稀疏连接和共享权重和阈值，大大减少了计算的开销，同时，pooling的实现，一定程度上减少了过拟合问题的出现，非常适合用于图像的处理和识别。<br></p>
   <h3><a></a><a target="_blank"></a><a id="2__32" target="_blank"></a><strong>2 手写数字识别算法模型的构建</strong></h3>
   <h4><a id="21__33" target="_blank"></a><strong>2.1 各层设计</strong></h4>
   <p>有了第一节的基础知识，在这基础上，进行完善和改进。</p>
   <blockquote>
    <p><strong>输入层设计</strong></p>
   </blockquote>
   <p>输入为28×28的矩阵，而不是向量。</p>
   <blockquote>
    <p><strong>激活函数的选取</strong></p>
   </blockquote>
   <p>Sigmoid函数具有光滑性、鲁棒性和其导数可用自身表示的优点，但其运算涉及指数运算，反向传播求误差梯度时，求导又涉及乘除运算，计算量相对较大。同时，针对本文构建的含有两层卷积层和降采样层，由于sgmoid函数自身的特性，在反向传播时，很容易出现梯度消失的情况，从而难以完成网络的训练。因此，本文设计的网络使用ReLU函数作为激活函数。</p>
   <p>ReLU的表达式：<br><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205840158.png"></p>
   <blockquote>
    <p><strong>卷积层设计</strong></p>
   </blockquote>
   <p>本文设计卷积神经网络采取的是离散卷积，卷积步长为1，即水平和垂直方向每次运算完，移动一个像素。卷积核大小为5×5。</p>
   <blockquote>
    <p><strong>降采样层</strong></p>
   </blockquote>
   <p>本文降采样层的pooling方式是max-pooling，大小为2×2。</p>
   <blockquote>
    <p><strong>输出层设计</strong></p>
   </blockquote>
   <p>输出层设置为10个神经网络节点。数字0~9的目标向量如下表所示：<br><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205913456.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70"></p>
   <h4><a id="22__55" target="_blank"></a><strong>2.2 网络模型的总体结构</strong></h4>
   <p><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205931959.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70"><br>其实，本文网络的构建，参考自TensorFlow的手写数字识别的官方教程的，读者有兴趣也可以详细阅读。</p>
   <h4><a id="23__58" target="_blank"></a><strong>2.3 编程实现算法</strong></h4>
   <p>本文使用Python，调用TensorFlow的api完成手写数字识别的算法。<br>注：本文程序运行环境是：Win10,python3.5.2。当然，也可以在Linux下运行，由于TensorFlow对py2和py3兼容得比较好，在Linux下可以在python2.7中运行。</p>
   <pre class="prettyprint"><code class="has-numbering">#!/usr/bin/env python2# -*- coding: utf-8 -*-"""Created on Fri Feb 17 19:50:49 2017@author: Yonghao Huang"""#import modulesimport numpy as npimport matplotlib.pyplot as pltimport tensorflow as tfimport timefrom datetime import timedeltaimport mathfrom tensorflow.examples.tutorials.mnist import input_datadef new_weights(shape):&nbsp;&nbsp;&nbsp; return tf.Variable(tf.truncated_normal(shape,stddev=0.05))def new_biases(length):&nbsp;&nbsp;&nbsp; return tf.Variable(tf.constant(0.1,shape=length))def conv2d(x,W):&nbsp;&nbsp;&nbsp; return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')def max_pool_2x2(inputx):&nbsp;&nbsp;&nbsp; return tf.nn.max_pool(inputx,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')#import datadata = input_data.read_data_sets("./data", one_hot=True)&nbsp; # one_hot means [0 0 1 0 0 0 0 0 0 0] stands for 2print("Size of:")print("--Training-set:\t\t{}".format(len(data.train.labels)))print("--Testing-set:\t\t{}".format(len(data.test.labels)))print("--Validation-set:\t\t{}".format(len(data.validation.labels)))data.test.cls = np.argmax(data.test.labels,axis=1)&nbsp;&nbsp; # show the real test labels:&nbsp; [7 2 1 ..., 4 5 6], 10000valuesx = tf.placeholder("float",shape=[None,784],name='x')x_image = tf.reshape(x,[-1,28,28,1])y_true = tf.placeholder("float",shape=[None,10],name='y_true')y_true_cls = tf.argmax(y_true,dimension=1)# Conv 1layer_conv1 = {"weights":new_weights([5,5,1,32]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "biases":new_biases([32])}h_conv1 = tf.nn.relu(conv2d(x_image,layer_conv1["weights"])+layer_conv1["biases"])h_pool1 = max_pool_2x2(h_conv1)# Conv 2layer_conv2 = {"weights":new_weights([5,5,32,64]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "biases":new_biases([64])}h_conv2 = tf.nn.relu(conv2d(h_pool1,layer_conv2["weights"])+layer_conv2["biases"])h_pool2 = max_pool_2x2(h_conv2)# Full-connected layer 1fc1_layer = {"weights":new_weights([7*7*64,1024]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "biases":new_biases([1024])}h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,fc1_layer["weights"])+fc1_layer["biases"])# Droupout Layerkeep_prob = tf.placeholder("float")h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)# Full-connected layer 2fc2_layer = {"weights":new_weights([1024,10]),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; "biases":new_weights([10])}# Predicted classy_pred = tf.nn.softmax(tf.matmul(h_fc1_drop,fc2_layer["weights"])+fc2_layer["biases"])&nbsp; # The output is like [0 0 1 0 0 0 0 0 0 0]y_pred_cls = tf.argmax(y_pred,dimension=1)&nbsp; # Show the real predict number like '2'# cost function to be optimizedcross_entropy = -tf.reduce_mean(y_true*tf.log(y_pred))optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cross_entropy)# Performance Measurescorrect_prediction = tf.equal(y_pred_cls,y_true_cls)accuracy = tf.reduce_mean(tf.cast(correct_prediction,"float"))with tf.Session() as sess:&nbsp;&nbsp;&nbsp; init = tf.global_variables_initializer()&nbsp;&nbsp;&nbsp; sess.run(init)&nbsp;&nbsp;&nbsp; train_batch_size = 50&nbsp;&nbsp;&nbsp; def optimize(num_iterations):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total_iterations=0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; start_time = time.time()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for i in range(total_iterations,total_iterations+num_iterations):&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; x_batch,y_true_batch = data.train.next_batch(train_batch_size)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict_train_op = {x:x_batch,y_true:y_true_batch,keep_prob:0.5}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict_train = {x:x_batch,y_true:y_true_batch,keep_prob:1.0}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sess.run(optimizer,feed_dict=feed_dict_train_op)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print status every 100 iterations.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if i%100==0:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Calculate the accuracy on the training-set.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; acc = sess.run(accuracy,feed_dict=feed_dict_train)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Message for printing.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; msg = "Optimization Iteration:{0:&gt;6}, Training Accuracy: {1:&gt;6.1%}"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print it.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(msg.format(i+1,acc))&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Update the total number of iterations performed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; total_iterations += num_iterations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Ending time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; end_time = time.time()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Difference between start and end_times.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; time_dif = end_time-start_time&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print the time-usage&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print("Time usage:"+str(timedelta(seconds=int(round(time_dif)))))&nbsp;&nbsp;&nbsp; test_batch_size = 256&nbsp;&nbsp;&nbsp; def print_test_accuracy():&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Number of images in the test-set.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; num_test = len(data.test.images)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_pred = np.zeros(shape=num_test,dtype=np.int)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i = 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while i &lt; num_test:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # The ending index for the next batch is denoted j.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; j = min(i+test_batch_size,num_test)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Get the images from the test-set between index i and j&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; images = data.test.images[i:j, :]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Get the associated labels&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; labels = data.test.labels[i:j, :]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Create a feed-dict with these images and labels.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; feed_dict={x:images,y_true:labels,keep_prob:1.0}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Calculate the predicted class using Tensorflow.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_pred[i:j] = sess.run(y_pred_cls,feed_dict=feed_dict)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Set the start-index for the next batch to the&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # end-index of the current batch&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; i = j&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cls_true = data.test.cls&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correct = (cls_true==cls_pred)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; correct_sum = correct.sum()&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; acc = float(correct_sum) / num_test&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; # Print the accuracy&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; msg = "Accuracy on Test-Set: {0:.1%} ({1}/{2})"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; print(msg.format(acc,correct_sum,num_test))&nbsp;&nbsp;&nbsp; # Performance after 10000 optimization iterations&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </code>
    <div class="hljs-button {2}"></div>
    <ul class="pre-numbering">
     <li>1</li>
     <li>2</li>
     <li>3</li>
     <li>4</li>
     <li>5</li>
     <li>6</li>
     <li>7</li>
     <li>8</li>
     <li>9</li>
     <li>10</li>
     <li>11</li>
     <li>12</li>
     <li>13</li>
     <li>14</li>
     <li>15</li>
     <li>16</li>
     <li>17</li>
     <li>18</li>
     <li>19</li>
     <li>20</li>
     <li>21</li>
     <li>22</li>
     <li>23</li>
     <li>24</li>
     <li>25</li>
     <li>26</li>
     <li>27</li>
     <li>28</li>
     <li>29</li>
     <li>30</li>
     <li>31</li>
     <li>32</li>
     <li>33</li>
     <li>34</li>
     <li>35</li>
     <li>36</li>
     <li>37</li>
     <li>38</li>
     <li>39</li>
     <li>40</li>
     <li>41</li>
     <li>42</li>
     <li>43</li>
     <li>44</li>
     <li>45</li>
     <li>46</li>
     <li>47</li>
     <li>48</li>
     <li>49</li>
     <li>50</li>
     <li>51</li>
     <li>52</li>
     <li>53</li>
     <li>54</li>
     <li>55</li>
     <li>56</li>
     <li>57</li>
     <li>58</li>
     <li>59</li>
     <li>60</li>
     <li>61</li>
     <li>62</li>
     <li>63</li>
     <li>64</li>
     <li>65</li>
     <li>66</li>
     <li>67</li>
     <li>68</li>
     <li>69</li>
     <li>70</li>
     <li>71</li>
     <li>72</li>
     <li>73</li>
     <li>74</li>
     <li>75</li>
     <li>76</li>
     <li>77</li>
     <li>78</li>
     <li>79</li>
     <li>80</li>
     <li>81</li>
     <li>82</li>
     <li>83</li>
     <li>84</li>
     <li>85</li>
     <li>86</li>
     <li>87</li>
     <li>88</li>
     <li>89</li>
     <li>90</li>
     <li>91</li>
     <li>92</li>
     <li>93</li>
     <li>94</li>
     <li>95</li>
     <li>96</li>
     <li>97</li>
     <li>98</li>
     <li>99</li>
     <li>100</li>
     <li>101</li>
     <li>102</li>
     <li>103</li>
     <li>104</li>
     <li>105</li>
     <li>106</li>
     <li>107</li>
     <li>108</li>
     <li>109</li>
     <li>110</li>
     <li>111</li>
     <li>112</li>
     <li>113</li>
     <li>114</li>
     <li>115</li>
     <li>116</li>
     <li>117</li>
     <li>118</li>
     <li>119</li>
     <li>120</li>
     <li>121</li>
     <li>122</li>
     <li>123</li>
     <li>124</li>
     <li>125</li>
     <li>126</li>
     <li>127</li>
     <li>128</li>
     <li>129</li>
     <li>130</li>
    </ul>
    <ul class="pre-numbering"></ul></pre>
   <p>运行结果显示：测试集中准确率大概为99.2%。<br>我还写了一些辅助函数，可以查看部分识别错误的图片，<br><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406205953982.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70"><br>还可以查看混淆矩阵，<br><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406210009831.png"></p>
   <h4><a id="23__200" target="_blank"></a>2.3 实现手写识别系统</h4>
   <p>最后，将训练好的参数保存，封装进一个GUI界面中，形成一个手写识别系统。<br><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406210022405.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2xvdWlzaGFv,size_16,color_FFFFFF,t_70"><br>系统中还添加了一点图像预处理的操作，比如灰度化，图像信息的归一化等，更贴近实际应用。<br>系统可进行快速识别，如下图：<br><img alt="在这里插入图片描述" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190406210051874.png"></p>
   <h3><a></a><a target="_blank"></a><a id="3__206" target="_blank"></a><strong>3 总结</strong></h3>
   <p>本文实现的系统其实是基于卷积神经网络的手写数字识别系统。该系统能快速实现手写数字识别，成功识别率高。缺点：只能正确识别单个数字，图像预处理还不够，没有进行图像分割，读者也可以自行添加，进行完善。</p>
   <h3><a></a><a target="_blank"></a><a id="4__208" target="_blank"></a><strong>4 收获</strong></h3>
   <p>本人之前的本科期间，虽然努力学习高数、线性代数和概率论，但是没有认真学习过机器学习，本人是2017年才开始系统学习机器学习相关知识，而且本科毕业论文也选择了相关的课题，虽然比较基础，但是认真完成后，有一种学以致用的满足感，同时也激励着我进行更深入的理论学习和实践探讨，与所有读者共勉。</p>
   <p>==================================<br><br>2018年5月13日更新<br></p>
   <p>源码分享链接：链接: <a href="https://pan.baidu.com/s/1BItkfd1bW-hJQaXzzQ3sVQ" rel="nofollow" target="_blank">https://pan.baidu.com/s/1BItkfd1bW-hJQaXzzQ3sVQ</a> 提取码: spbv<br><br><br>========================================<br><br>2018年6月6日更新更新！！</p>
   <h3><a></a><a target="_blank"></a><a id="pythonTensorFlow_219" target="_blank"></a>python(TensorFlow)实现手写字符识别</h3>
   <br>
   <p>此处的“手写字符”，其实指的是notMNIST数据库中的手写字符，其实和MNIST数据库是一样的。这里实现手写字符识别，主要是展示TensorFlow框架的可拓展性很强，具体来说，就是可以通过改动少部分的代码，从而实现一个新的识别功能。<br><br></p>
   <h3><a></a><a target="_blank"></a><a id="NotMnist_226" target="_blank"></a>NotMnist数据库</h3>
   <p>这个数据库和MNIST数据库基本一样，只是把10个数字换成了10个字母，即：A,B,C,D,E,F,G,H,I,J,K<br>当然，这个数据库的识别难度大一些，因为数据噪声更多一些，详情读者可以搜一搜了解一下。</p>
   <h3><a></a><a target="_blank"></a><a id="_230" target="_blank"></a>实战</h3>
   <p>将NotMNIST数据库下载以后，放在本博文上述的网络中，基本不需要修改代码，直接训练，即可得到一个能识别字符的网络模型。<br><br>最后在测试集中的准确率，比MNIST的会低一些，大概为96%左右。<br><br>本文也将训练好的网络模型封装在和上述系统相似的GUI系统中，<br></p>
   <p><img alt="" src="https://i.imgur.com/59M3NlD.png"><br><br>识别效果还可以！<br><br>同样，将卷积卷积层可视化。<br><br><img alt="" src="https://i.imgur.com/4awe7NY.png"><br></p>
   <h3><a></a><a target="_blank"></a><a id="_241" target="_blank"></a>结语</h3>
   <p>TensorFlow框架可拓展性很强，只要设计好了网络，就能很容易的实现出来；同时，使用基本的CNN识别整体架构也是大同小异的，很多识别任务是通用的。当然，在具体的实践中需要得到接近完美的效果，还是要下很大功夫的！努力学习吧，加油！<br>（如果你/您有什么有趣的想法，可以在下面留言，如果我也感兴趣同时又有时间的话，我会尝试做一做，<sup>_</sup>）</p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
  </div> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
