<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>kafka 什么情况下会丢失消息以及如何保证可靠的数据传递 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="kafka 什么情况下会丢失消息以及如何保证可靠的数据传递" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="主要三个部分会造成消息丢失 broke 端消息丢失 生产者端消息丢失 消费者端消息丢失 &nbsp; &nbsp;一 broke端消费丢失 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker端的消息不丢失，其实就是用partition副本机制来保证。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; broker 端有三个重要的参数来保证消息可靠 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 1.复制系数&nbsp;&nbsp;主题级别配置参数是&nbsp;&nbsp;replication.factor ；broker 级别可以通过default.replication.factor 来配置自动创建的主题; &nbsp; &nbsp; &nbsp; &nbsp;该参数表示每个分区(或者该分区)会被复制几份、kafka的设计中备份会存放在不同的broker中所以极大程度保证消息的不丢失； &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 2.不完全的首领选举 unclean.leader.election 只能再broker级别设置&nbsp;&nbsp;默认为true&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 该参数配置决定在分区首领不可用时、非同步副本是否可以被选举为首领副本;如果设置为true 则予许不同步的副本成为首领，但我们将面临丢失消息的风险、如果设置为false 就需要等待原先的首领副本重新上线 从而降低了可用性。&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 换个角度说就是:该参数配置为true时 且分区发生重新选举选举出的首领分区为不完全分区时 可能就会发生消息丢失 &nbsp; &nbsp; &nbsp; &nbsp; 3.最小同步副本&nbsp;&nbsp;在主题级别和broker级别上 min.insync.replicas &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;该参数是为了避免在发生不完全选举时数据的写入和读取出现非预期的行为 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;假如设置成3 那么至少要存在三个同步副本才能向分区写入数据(注意是 同步副本),如果同步副本数量小于3时broker就会停止接收所有生产者的消息、尝试发送消息的的生产者会受到NotEnoughReplicasException异常，消费者仍然可以读取已有数据、变成只读状态 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 如果“所有副本”只包含一个同步副本，那么在这个副本变为不可用时,数据就可能会丢失。 &nbsp; 二 &nbsp;生产者端消息丢失 产生数据丢失的两种情况： &nbsp; 1）同步模式：有3种状态保证消息被安全生产，但是在配置为1（只保证写入leader成功）的话，如果刚好leader partition挂了，数据就会丢失。 &nbsp; 2）异步模式：当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉。 &nbsp; 1. acks acks = 0&nbsp;生产者只负责发送数据 acks = 1&nbsp;某个partition的leader收到数据给出响应 acks = all &nbsp;&nbsp;某个partition的所有副本都收到数据后给出响应 2 buffer.memory&nbsp; &nbsp; 3 retries = MAX 无限重试，直到你意识到出现了问题 &nbsp; 4 max.in.flight.requests.per.connection = 1 限制客户端在单个连接上能够发送的未响应请求的个数。设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求。注意：设置此参数是为了避免消息乱序 使用KafkaProducer.send(record, callback)而不是send(record)方法 &nbsp; 自定义回调逻辑处理消息发送失败，比如记录在日志中，用定时脚本扫描重处理 callback逻辑中最好显式关闭producer：close(0) 注意：设置此参数是为了避免消息乱序（仅仅因为一条消息发送没收到反馈就关闭生产者，感觉代价很大） unclean.leader.election.enable=false &nbsp; 关闭unclean leader选举，即不允许非ISR中的副本被选举为leader，以避免数据丢失 replication.factor &gt;= 3 &nbsp; 这个完全是个人建议了，参考了Hadoop及业界通用的三备份原则 min.insync.replicas &gt; 1 消息至少要被写入到这么多副本才算成功，也是提升数据持久性的一个参数。与acks配合使用 保证replication.factor &gt; min.insync.replicas &nbsp;如果两者相等，当一个副本挂掉了分区也就没法正常工作了。通常设置replication.factor = min.insync.replicas + 1即可 &nbsp; 三 消费者端消息丢失 consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失 为了避免数据丢失，现给出两点建议： enable.auto.commit=false&nbsp;&nbsp;关闭自动提交位移 在消息被完整处理之后再手动提交位移" />
<meta property="og:description" content="主要三个部分会造成消息丢失 broke 端消息丢失 生产者端消息丢失 消费者端消息丢失 &nbsp; &nbsp;一 broke端消费丢失 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker端的消息不丢失，其实就是用partition副本机制来保证。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; broker 端有三个重要的参数来保证消息可靠 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 1.复制系数&nbsp;&nbsp;主题级别配置参数是&nbsp;&nbsp;replication.factor ；broker 级别可以通过default.replication.factor 来配置自动创建的主题; &nbsp; &nbsp; &nbsp; &nbsp;该参数表示每个分区(或者该分区)会被复制几份、kafka的设计中备份会存放在不同的broker中所以极大程度保证消息的不丢失； &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 2.不完全的首领选举 unclean.leader.election 只能再broker级别设置&nbsp;&nbsp;默认为true&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 该参数配置决定在分区首领不可用时、非同步副本是否可以被选举为首领副本;如果设置为true 则予许不同步的副本成为首领，但我们将面临丢失消息的风险、如果设置为false 就需要等待原先的首领副本重新上线 从而降低了可用性。&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 换个角度说就是:该参数配置为true时 且分区发生重新选举选举出的首领分区为不完全分区时 可能就会发生消息丢失 &nbsp; &nbsp; &nbsp; &nbsp; 3.最小同步副本&nbsp;&nbsp;在主题级别和broker级别上 min.insync.replicas &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;该参数是为了避免在发生不完全选举时数据的写入和读取出现非预期的行为 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;假如设置成3 那么至少要存在三个同步副本才能向分区写入数据(注意是 同步副本),如果同步副本数量小于3时broker就会停止接收所有生产者的消息、尝试发送消息的的生产者会受到NotEnoughReplicasException异常，消费者仍然可以读取已有数据、变成只读状态 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 如果“所有副本”只包含一个同步副本，那么在这个副本变为不可用时,数据就可能会丢失。 &nbsp; 二 &nbsp;生产者端消息丢失 产生数据丢失的两种情况： &nbsp; 1）同步模式：有3种状态保证消息被安全生产，但是在配置为1（只保证写入leader成功）的话，如果刚好leader partition挂了，数据就会丢失。 &nbsp; 2）异步模式：当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉。 &nbsp; 1. acks acks = 0&nbsp;生产者只负责发送数据 acks = 1&nbsp;某个partition的leader收到数据给出响应 acks = all &nbsp;&nbsp;某个partition的所有副本都收到数据后给出响应 2 buffer.memory&nbsp; &nbsp; 3 retries = MAX 无限重试，直到你意识到出现了问题 &nbsp; 4 max.in.flight.requests.per.connection = 1 限制客户端在单个连接上能够发送的未响应请求的个数。设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求。注意：设置此参数是为了避免消息乱序 使用KafkaProducer.send(record, callback)而不是send(record)方法 &nbsp; 自定义回调逻辑处理消息发送失败，比如记录在日志中，用定时脚本扫描重处理 callback逻辑中最好显式关闭producer：close(0) 注意：设置此参数是为了避免消息乱序（仅仅因为一条消息发送没收到反馈就关闭生产者，感觉代价很大） unclean.leader.election.enable=false &nbsp; 关闭unclean leader选举，即不允许非ISR中的副本被选举为leader，以避免数据丢失 replication.factor &gt;= 3 &nbsp; 这个完全是个人建议了，参考了Hadoop及业界通用的三备份原则 min.insync.replicas &gt; 1 消息至少要被写入到这么多副本才算成功，也是提升数据持久性的一个参数。与acks配合使用 保证replication.factor &gt; min.insync.replicas &nbsp;如果两者相等，当一个副本挂掉了分区也就没法正常工作了。通常设置replication.factor = min.insync.replicas + 1即可 &nbsp; 三 消费者端消息丢失 consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失 为了避免数据丢失，现给出两点建议： enable.auto.commit=false&nbsp;&nbsp;关闭自动提交位移 在消息被完整处理之后再手动提交位移" />
<link rel="canonical" href="https://mlh.app/2019/05/17/787735.html" />
<meta property="og:url" content="https://mlh.app/2019/05/17/787735.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-17T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"主要三个部分会造成消息丢失 broke 端消息丢失 生产者端消息丢失 消费者端消息丢失 &nbsp; &nbsp;一 broke端消费丢失 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker端的消息不丢失，其实就是用partition副本机制来保证。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; broker 端有三个重要的参数来保证消息可靠 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 1.复制系数&nbsp;&nbsp;主题级别配置参数是&nbsp;&nbsp;replication.factor ；broker 级别可以通过default.replication.factor 来配置自动创建的主题; &nbsp; &nbsp; &nbsp; &nbsp;该参数表示每个分区(或者该分区)会被复制几份、kafka的设计中备份会存放在不同的broker中所以极大程度保证消息的不丢失； &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 2.不完全的首领选举 unclean.leader.election 只能再broker级别设置&nbsp;&nbsp;默认为true&nbsp;&nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 该参数配置决定在分区首领不可用时、非同步副本是否可以被选举为首领副本;如果设置为true 则予许不同步的副本成为首领，但我们将面临丢失消息的风险、如果设置为false 就需要等待原先的首领副本重新上线 从而降低了可用性。&nbsp; &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 换个角度说就是:该参数配置为true时 且分区发生重新选举选举出的首领分区为不完全分区时 可能就会发生消息丢失 &nbsp; &nbsp; &nbsp; &nbsp; 3.最小同步副本&nbsp;&nbsp;在主题级别和broker级别上 min.insync.replicas &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;该参数是为了避免在发生不完全选举时数据的写入和读取出现非预期的行为 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;假如设置成3 那么至少要存在三个同步副本才能向分区写入数据(注意是 同步副本),如果同步副本数量小于3时broker就会停止接收所有生产者的消息、尝试发送消息的的生产者会受到NotEnoughReplicasException异常，消费者仍然可以读取已有数据、变成只读状态 &nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 如果“所有副本”只包含一个同步副本，那么在这个副本变为不可用时,数据就可能会丢失。 &nbsp; 二 &nbsp;生产者端消息丢失 产生数据丢失的两种情况： &nbsp; 1）同步模式：有3种状态保证消息被安全生产，但是在配置为1（只保证写入leader成功）的话，如果刚好leader partition挂了，数据就会丢失。 &nbsp; 2）异步模式：当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉。 &nbsp; 1. acks acks = 0&nbsp;生产者只负责发送数据 acks = 1&nbsp;某个partition的leader收到数据给出响应 acks = all &nbsp;&nbsp;某个partition的所有副本都收到数据后给出响应 2 buffer.memory&nbsp; &nbsp; 3 retries = MAX 无限重试，直到你意识到出现了问题 &nbsp; 4 max.in.flight.requests.per.connection = 1 限制客户端在单个连接上能够发送的未响应请求的个数。设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求。注意：设置此参数是为了避免消息乱序 使用KafkaProducer.send(record, callback)而不是send(record)方法 &nbsp; 自定义回调逻辑处理消息发送失败，比如记录在日志中，用定时脚本扫描重处理 callback逻辑中最好显式关闭producer：close(0) 注意：设置此参数是为了避免消息乱序（仅仅因为一条消息发送没收到反馈就关闭生产者，感觉代价很大） unclean.leader.election.enable=false &nbsp; 关闭unclean leader选举，即不允许非ISR中的副本被选举为leader，以避免数据丢失 replication.factor &gt;= 3 &nbsp; 这个完全是个人建议了，参考了Hadoop及业界通用的三备份原则 min.insync.replicas &gt; 1 消息至少要被写入到这么多副本才算成功，也是提升数据持久性的一个参数。与acks配合使用 保证replication.factor &gt; min.insync.replicas &nbsp;如果两者相等，当一个副本挂掉了分区也就没法正常工作了。通常设置replication.factor = min.insync.replicas + 1即可 &nbsp; 三 消费者端消息丢失 consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失 为了避免数据丢失，现给出两点建议： enable.auto.commit=false&nbsp;&nbsp;关闭自动提交位移 在消息被完整处理之后再手动提交位移","@type":"BlogPosting","url":"https://mlh.app/2019/05/17/787735.html","headline":"kafka 什么情况下会丢失消息以及如何保证可靠的数据传递","dateModified":"2019-05-17T00:00:00+08:00","datePublished":"2019-05-17T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/17/787735.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>kafka 什么情况下会丢失消息以及如何保证可靠的数据传递</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p>主要三个部分会造成消息丢失</p> 
  <ol>
   <li> <p>broke 端消息丢失</p> </li> 
   <li> <p>生产者端消息丢失</p> </li> 
   <li> <p>消费者端消息丢失</p> </li> 
  </ol>
  <p>&nbsp;</p> 
  <p>&nbsp;一 broke端消费丢失</p> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker端的消息不丢失，其实就是用partition副本机制来保证。</p> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;</p> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp; broker 端有三个重要的参数来保证消息可靠</p> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 1.<span style="color:#4a4a4a;">复制系数&nbsp;&nbsp;主题级别配置参数是&nbsp;&nbsp;replication.factor ；<span style="color:#4a4a4a;">broker 级别可以通过default.replication.factor 来配置自动创建的主题;</span></span></p> 
  <p><span style="color:#4a4a4a;"><span style="color:#4a4a4a;">&nbsp; &nbsp; &nbsp; &nbsp;该参数表示每个分区(或者该分区)会被复制几份、kafka的设计中备份会存放在不同的broker中所以极大程度保证消息的不丢失；</span></span></p> 
  <p><span style="color:#4a4a4a;"><span style="color:#4a4a4a;">&nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 2.<span style="color:#4a4a4a;">不完全的首领选举 unclean.leader.election 只能再broker级别设置&nbsp;&nbsp;默认为true&nbsp;</span>&nbsp;&nbsp;&nbsp;</span></span></p> 
  <p><span style="color:#4a4a4a;"><span style="color:#4a4a4a;"><span style="color:#4a4a4a;">&nbsp; &nbsp; &nbsp; &nbsp; 该参数配置决定在分区首领不可用时、<strong>非同步副本</strong>是否可以被选举为首领副本;<span style="color:#4a4a4a;">如果设置为true 则予许不同步的副本成为首领，但我们将面临丢失消息的风险、如果设置为false 就需要等待原先的首领副本重新上线 从而降低了可用性。</span><strong>&nbsp;</strong></span></span></span></p> 
  <p><span style="color:#4a4a4a;"><span style="color:#4a4a4a;"><span style="color:#4a4a4a;"><strong>&nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 换个角度说就是:该参数配置为true时 且分区发生重新选举选举出的首领分区为不完全分区时 可能就会发生消息丢失</strong></span></span></span></p> 
  <p><span style="color:#4a4a4a;"><span style="color:#4a4a4a;"><span style="color:#4a4a4a;"><strong>&nbsp; &nbsp; &nbsp; &nbsp;</strong> 3.<span style="color:#4a4a4a;">最小同步副本&nbsp;&nbsp;在主题级别和broker级别上 min.insync.replicas</span></span></span></span></p> 
  <p><span style="color:#656565;">&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;该参数是为了避</span><span style="color:#878787;">免在发生</span><span style="color:#656565;">不完全选举时数据的写入和读取出现非预期的行为</span></p> 
  <p><span style="color:#4a4a4a;">&nbsp;&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;<span style="color:#4a4a4a;">假如设置成3 那么至少要存在三个</span><span style="color:#4a4a4a;"><strong>同步</strong></span><span style="color:#4a4a4a;">副本才能向分区写入数据(注意是 同步副本),如果同步副本数量小于3时broker就会停止接收所有生产者的消息、尝试发送消息的的生产者会受到<span style="color:#656565;">N</span><span style="color:#444444;">otEnoughReplicasException</span><span style="color:#656565;">异常，消费者仍然可以读取已有数据、变成只读状态</span></span></span></p> 
  <p><span style="color:#4a4a4a;">&nbsp;&nbsp; &nbsp;&nbsp; &nbsp; 如果</span><span style="color:#404040;">“所有副本”只包含一个同步副本，那么在这个副本变为不可用时,<strong>数据就可能会丢失</strong>。</span></p> 
  <p>&nbsp;</p> 
  <p><span style="color:#404040;">二 &nbsp;<span style="color:#404040;">生产者端消息丢失</span></span></p> 
  <h3><span style="color:#404040;">产生数据丢失的两种情况：</span></h3> 
  <p>&nbsp;</p> 
  <p>1）同步模式：有3种状态保证消息被安全生产，但是在配置为1（只保证写入leader成功）的话，如果刚好leader partition挂了，数据就会丢失。</p> 
  <p>&nbsp;</p> 
  <p>2）异步模式：当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉。</p> 
  <p>&nbsp;</p> 
  <p><span style="color:#4c4c4c;">1.</span> <span style="color:#3a3a3a;">acks</span></p> 
  <p><span style="color:#4f4f4f;"><span style="color:#4f4f4f;">acks = 0&nbsp;<span style="color:#4f4f4f;">生产者只负责发送数据</span></span></span></p> 
  <p><span style="color:#4f4f4f;"><span style="color:#4f4f4f;">acks = 1&nbsp;<span style="color:#4f4f4f;">某个</span><span style="color:#4f4f4f;">partition</span><span style="color:#4f4f4f;">的</span><span style="color:#4f4f4f;">leader</span><span style="color:#4f4f4f;">收到数据给出响应</span></span></span></p> 
  <p><span style="color:#4f4f4f;"><span style="color:#4f4f4f;">acks = all &nbsp;</span>&nbsp;某个partition的所有副本都收到数据后给出响应</span></p> 
  <p><span style="color:#4a4a4a;"><span style="color:#646464;">2 buff</span><span style="color:#484848;">er</span><span style="color:#767676;">.m</span><span style="color:#484848;">e</span><span style="color:#646464;">m</span><span style="color:#484848;">ory&nbsp;</span></span></p> 
  <p>&nbsp;</p> 
  <p><span style="color:#333333;">3 retries = MAX 无限重试，直到你意识到出现了问题</span></p> 
  <hr>
  <p>&nbsp;</p> 
  <p><span style="color:#333333;">4 max.in.flight.requests.per.connection = 1 限制客户端在单个连接上能够发送的未响应请求的个数。设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求。注意：设置此参数是为了避免消息乱序</span></p> 
  <p><span style="color:#333333;">使用KafkaProducer.send(record, callback)而不是send(record)方法 &nbsp; 自定义回调逻辑处理消息发送失败，比如记录在日志中，用定时脚本扫描重处理</span></p> 
  <p><span style="color:#333333;">callback逻辑中最好显式关闭producer：close(0) 注意：设置此参数是为了避免消息乱序（仅仅因为一条消息发送没收到反馈就关闭生产者，感觉代价很大）</span></p> 
  <p><span style="color:#333333;">unclean.leader.election.enable=false &nbsp; 关闭unclean leader选举，即不允许非ISR中的副本被选举为leader，以避免数据丢失</span></p> 
  <p><span style="color:#333333;">replication.factor &gt;= 3 &nbsp; 这个完全是个人建议了，参考了Hadoop及业界通用的三备份原则</span></p> 
  <p><span style="color:#333333;">min.insync.replicas &gt; 1 消息至少要被写入到这么多副本才算成功，也是提升数据持久性的一个参数。与acks配合使用</span></p> 
  <p><span style="color:#333333;">保证replication.factor &gt; min.insync.replicas &nbsp;如果两者相等，当一个副本挂掉了分区也就没法正常工作了。通常设置replication.factor = min.insync.replicas + 1即可</span></p> 
  <hr>
  <p>&nbsp;</p> 
  <p><span style="color:#484848;">三 消费者端消息丢失</span></p> 
  <p><br><span style="color:#333333;">consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失</span></p> 
  <p><span style="color:#333333;">为了避免数据丢失，现给出两点建议：</span></p> 
  <p><span style="color:#333333;"><a href="" rel="nofollow">enable.auto.commit=false</a>&nbsp;&nbsp;关闭自动提交位移</span></p> 
  <p><span style="color:#333333;">在消息被完整处理之后再手动提交位移</span></p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
