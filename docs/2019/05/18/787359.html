<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Spark SQL 可调参数汇总 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Spark SQL 可调参数汇总" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="写在前面的话：因为本人在职，所以没有充分的时间写博客，所以经常是写好整个框架，再陆陆续续的补充修改。所以如果发现什么错误请留言。 本文主要是日常工作的积累，主要是简单罗列了常见的spark SQL的参数及其含义。 #Job ID /Name spark.app.name=clsfd_ad_attr_map_w_mvca_ins #yarn 进行调度，也可以是mesos，yarn，以及standalone #一个spark application，是一个spark应用。一个应用对应且仅对应一个sparkContext。每一个应用，运行一组独立的executor processes。一个应用，可以以多线程的方式提交多个作业job。spark可以运行在多种集群管理器上如：mesos，yarn，以及standalone，每种集群管理器都会提供跨应用的资源调度策略。 spark.master=yarn #激活外部shuffle服务。服务维护executor写的文件，因而executor可以被安全移除。 #需要设置spark.dynamicAllocation.enabled 为true，同事指定外部shuffle服务。 #对shuffle来说，executor现将自己的map输出写入到磁盘，然后，自己作为一个server，向其他executor提供这些map输出文件的数据。而动态资源调度将executor返还给集群后，这个shuffle数据服务就没有了。因此，如果要使用动态资源策略，解决这个问题的办法就是，将保持shuffle文件作为一个外部服务，始终运行在spark集群的每个节点上，独立于应用和executor spark.shuffle.service.enabled=true #在默认情况下，三种集群管理器均不使用动态资源调度模式。所以要使用动态资源调度需要提前配置。 spark.dynamicAllocation.enabled=true # 如果所有的executor都移除了，重新请求时启动的初始executor数 spark.dynamicAllocation.initialExecutors=20 # 最少保留的executor数 spark.dynamicAllocation.minExecutors=10 # 最多使用的executor数，默认为你申请的最大executor数 spark.dynamicAllocation.maxExecutors=100 # 可以是cluster也可以是Client spark.submit.deployMode=cluster # 指定提交到Yarn的资源池 spark.yarn.queue=hdlq-data-batch-low # 在yarn-cluster模式下，申请Yarn App Master（包括Driver）所用的内存。 spark.driver.memory=8g # excutor的核心数 spark.executor.cores=16 # 一个Executor对应一个JVM进程。Executor占用的内存分为两部分：ExecutorMemory和MemoryOverhead spark.executor.memory=32g spark.yarn.executor.memoryOverhead=2g # shuffle分区数100，根据数据量进行调控，这儿配置了Join时shuffle的分区数和聚合数据时的分区数。 spark.sql.shuffle.partitions=100 # 如果用户没有指定并行度，下面这个参数将是RDD中的分区数，它是由join,reducebykey和parallelize # 这个参数只适用于未加工的RDD不适用于dataframe # 没有join和聚合计算操作，这个参数将是无效设置 spark.default.parallelism # 打包传入一个分区的最大字节，在读取文件的时候。 spark.sql.files.maxPartitionBytes=128MB # 用相同时间内可以扫描的数据的大小来衡量打开一个文件的开销。当将多个文件写入同一个分区的时候该参数有用。 # 该值设置大一点有好处，有小文件的分区会比大文件分区处理速度更快（优先调度）。 spark.sql.files.openCostInBytes=4MB # Spark 事件总线是SparkListenerEvent事件的阻塞队列大小 spark.scheduler.listenerbus.eventqueue.size=100000 # 是否启动推测机制 spark.speculation=false # 开启spark的推测机制，开启推测机制后如果某一台机器的几个task特别慢，推测机制会将任务分配到其他机器执行，最后Spark会选取最快的作为最终结果。 # 2表示比其他task慢两倍时，启动推测机制 spark.speculation.multiplier=2 # 推测机制的检测周期 spark.speculation.interval=5000ms # 完成task的百分比时启动推测 spark.speculation.quantile=0.6 # 最多允许失败的Executor数量。 spark.task.maxFailures=10 # spark序列化 对于优化&lt;网络性能&gt;极为重要，将RDD以序列化格式来保存减少内存占用. spark.serializer=org.apache.spark.serializer.KryoSerializer # 因为spark是基于内存的机制，所以默认是开启RDD的压缩 spark.rdd.compress=true # Spark的安全管理 #https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SecurityManager.scala spark.ui.view.acls=* spark.ui.view.acls.groups=* # 表示配置GC线程数为3 spark.executor.extraJavaOptions=&quot;-XX:ParallelGCThreads=3&quot; # 最大广播表的大小。设置为-1可以禁止该功能。当前统计信息仅支持Hive Metastore表。这里设置的是10MB spark.sql.autoBroadcastJoinThreshold=104857600 # 广播等待超时，这里单位是秒 spark.sql.broadcastTimeout=300 # 心跳检测间隔 spark.yarn.scheduler.heartbeat.interval-ms=10000 spark.sql.broadcastTimeout #缓存表问题 #spark2.+采用： #spark.catalog.cacheTable(&quot;tableName&quot;)缓存表，spark.catalog.uncacheTable(&quot;tableName&quot;)解除缓存。 #spark 1.+采用： #sqlContext.cacheTable(&quot;tableName&quot;)缓存，sqlContext.uncacheTable(&quot;tableName&quot;) 解除缓存 #Sparksql仅仅会缓存必要的列，并且自动调整压缩算法来减少内存和GC压力。 #假如设置为true，SparkSql会根据统计信息自动的为每个列选择压缩方式进行压缩。 spark.sql.inMemoryColumnarStorage.compressed=true #控制列缓存的批量大小。批次大有助于改善内存使用和压缩，但是缓存数据会有OOM的风险 spark.sql.inMemoryColumnarStorage.batchSize=10000 参考： http://spark.apache.org/docs/latest/configuration.html" />
<meta property="og:description" content="写在前面的话：因为本人在职，所以没有充分的时间写博客，所以经常是写好整个框架，再陆陆续续的补充修改。所以如果发现什么错误请留言。 本文主要是日常工作的积累，主要是简单罗列了常见的spark SQL的参数及其含义。 #Job ID /Name spark.app.name=clsfd_ad_attr_map_w_mvca_ins #yarn 进行调度，也可以是mesos，yarn，以及standalone #一个spark application，是一个spark应用。一个应用对应且仅对应一个sparkContext。每一个应用，运行一组独立的executor processes。一个应用，可以以多线程的方式提交多个作业job。spark可以运行在多种集群管理器上如：mesos，yarn，以及standalone，每种集群管理器都会提供跨应用的资源调度策略。 spark.master=yarn #激活外部shuffle服务。服务维护executor写的文件，因而executor可以被安全移除。 #需要设置spark.dynamicAllocation.enabled 为true，同事指定外部shuffle服务。 #对shuffle来说，executor现将自己的map输出写入到磁盘，然后，自己作为一个server，向其他executor提供这些map输出文件的数据。而动态资源调度将executor返还给集群后，这个shuffle数据服务就没有了。因此，如果要使用动态资源策略，解决这个问题的办法就是，将保持shuffle文件作为一个外部服务，始终运行在spark集群的每个节点上，独立于应用和executor spark.shuffle.service.enabled=true #在默认情况下，三种集群管理器均不使用动态资源调度模式。所以要使用动态资源调度需要提前配置。 spark.dynamicAllocation.enabled=true # 如果所有的executor都移除了，重新请求时启动的初始executor数 spark.dynamicAllocation.initialExecutors=20 # 最少保留的executor数 spark.dynamicAllocation.minExecutors=10 # 最多使用的executor数，默认为你申请的最大executor数 spark.dynamicAllocation.maxExecutors=100 # 可以是cluster也可以是Client spark.submit.deployMode=cluster # 指定提交到Yarn的资源池 spark.yarn.queue=hdlq-data-batch-low # 在yarn-cluster模式下，申请Yarn App Master（包括Driver）所用的内存。 spark.driver.memory=8g # excutor的核心数 spark.executor.cores=16 # 一个Executor对应一个JVM进程。Executor占用的内存分为两部分：ExecutorMemory和MemoryOverhead spark.executor.memory=32g spark.yarn.executor.memoryOverhead=2g # shuffle分区数100，根据数据量进行调控，这儿配置了Join时shuffle的分区数和聚合数据时的分区数。 spark.sql.shuffle.partitions=100 # 如果用户没有指定并行度，下面这个参数将是RDD中的分区数，它是由join,reducebykey和parallelize # 这个参数只适用于未加工的RDD不适用于dataframe # 没有join和聚合计算操作，这个参数将是无效设置 spark.default.parallelism # 打包传入一个分区的最大字节，在读取文件的时候。 spark.sql.files.maxPartitionBytes=128MB # 用相同时间内可以扫描的数据的大小来衡量打开一个文件的开销。当将多个文件写入同一个分区的时候该参数有用。 # 该值设置大一点有好处，有小文件的分区会比大文件分区处理速度更快（优先调度）。 spark.sql.files.openCostInBytes=4MB # Spark 事件总线是SparkListenerEvent事件的阻塞队列大小 spark.scheduler.listenerbus.eventqueue.size=100000 # 是否启动推测机制 spark.speculation=false # 开启spark的推测机制，开启推测机制后如果某一台机器的几个task特别慢，推测机制会将任务分配到其他机器执行，最后Spark会选取最快的作为最终结果。 # 2表示比其他task慢两倍时，启动推测机制 spark.speculation.multiplier=2 # 推测机制的检测周期 spark.speculation.interval=5000ms # 完成task的百分比时启动推测 spark.speculation.quantile=0.6 # 最多允许失败的Executor数量。 spark.task.maxFailures=10 # spark序列化 对于优化&lt;网络性能&gt;极为重要，将RDD以序列化格式来保存减少内存占用. spark.serializer=org.apache.spark.serializer.KryoSerializer # 因为spark是基于内存的机制，所以默认是开启RDD的压缩 spark.rdd.compress=true # Spark的安全管理 #https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SecurityManager.scala spark.ui.view.acls=* spark.ui.view.acls.groups=* # 表示配置GC线程数为3 spark.executor.extraJavaOptions=&quot;-XX:ParallelGCThreads=3&quot; # 最大广播表的大小。设置为-1可以禁止该功能。当前统计信息仅支持Hive Metastore表。这里设置的是10MB spark.sql.autoBroadcastJoinThreshold=104857600 # 广播等待超时，这里单位是秒 spark.sql.broadcastTimeout=300 # 心跳检测间隔 spark.yarn.scheduler.heartbeat.interval-ms=10000 spark.sql.broadcastTimeout #缓存表问题 #spark2.+采用： #spark.catalog.cacheTable(&quot;tableName&quot;)缓存表，spark.catalog.uncacheTable(&quot;tableName&quot;)解除缓存。 #spark 1.+采用： #sqlContext.cacheTable(&quot;tableName&quot;)缓存，sqlContext.uncacheTable(&quot;tableName&quot;) 解除缓存 #Sparksql仅仅会缓存必要的列，并且自动调整压缩算法来减少内存和GC压力。 #假如设置为true，SparkSql会根据统计信息自动的为每个列选择压缩方式进行压缩。 spark.sql.inMemoryColumnarStorage.compressed=true #控制列缓存的批量大小。批次大有助于改善内存使用和压缩，但是缓存数据会有OOM的风险 spark.sql.inMemoryColumnarStorage.batchSize=10000 参考： http://spark.apache.org/docs/latest/configuration.html" />
<link rel="canonical" href="https://mlh.app/2019/05/18/787359.html" />
<meta property="og:url" content="https://mlh.app/2019/05/18/787359.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-18T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"写在前面的话：因为本人在职，所以没有充分的时间写博客，所以经常是写好整个框架，再陆陆续续的补充修改。所以如果发现什么错误请留言。 本文主要是日常工作的积累，主要是简单罗列了常见的spark SQL的参数及其含义。 #Job ID /Name spark.app.name=clsfd_ad_attr_map_w_mvca_ins #yarn 进行调度，也可以是mesos，yarn，以及standalone #一个spark application，是一个spark应用。一个应用对应且仅对应一个sparkContext。每一个应用，运行一组独立的executor processes。一个应用，可以以多线程的方式提交多个作业job。spark可以运行在多种集群管理器上如：mesos，yarn，以及standalone，每种集群管理器都会提供跨应用的资源调度策略。 spark.master=yarn #激活外部shuffle服务。服务维护executor写的文件，因而executor可以被安全移除。 #需要设置spark.dynamicAllocation.enabled 为true，同事指定外部shuffle服务。 #对shuffle来说，executor现将自己的map输出写入到磁盘，然后，自己作为一个server，向其他executor提供这些map输出文件的数据。而动态资源调度将executor返还给集群后，这个shuffle数据服务就没有了。因此，如果要使用动态资源策略，解决这个问题的办法就是，将保持shuffle文件作为一个外部服务，始终运行在spark集群的每个节点上，独立于应用和executor spark.shuffle.service.enabled=true #在默认情况下，三种集群管理器均不使用动态资源调度模式。所以要使用动态资源调度需要提前配置。 spark.dynamicAllocation.enabled=true # 如果所有的executor都移除了，重新请求时启动的初始executor数 spark.dynamicAllocation.initialExecutors=20 # 最少保留的executor数 spark.dynamicAllocation.minExecutors=10 # 最多使用的executor数，默认为你申请的最大executor数 spark.dynamicAllocation.maxExecutors=100 # 可以是cluster也可以是Client spark.submit.deployMode=cluster # 指定提交到Yarn的资源池 spark.yarn.queue=hdlq-data-batch-low # 在yarn-cluster模式下，申请Yarn App Master（包括Driver）所用的内存。 spark.driver.memory=8g # excutor的核心数 spark.executor.cores=16 # 一个Executor对应一个JVM进程。Executor占用的内存分为两部分：ExecutorMemory和MemoryOverhead spark.executor.memory=32g spark.yarn.executor.memoryOverhead=2g # shuffle分区数100，根据数据量进行调控，这儿配置了Join时shuffle的分区数和聚合数据时的分区数。 spark.sql.shuffle.partitions=100 # 如果用户没有指定并行度，下面这个参数将是RDD中的分区数，它是由join,reducebykey和parallelize # 这个参数只适用于未加工的RDD不适用于dataframe # 没有join和聚合计算操作，这个参数将是无效设置 spark.default.parallelism # 打包传入一个分区的最大字节，在读取文件的时候。 spark.sql.files.maxPartitionBytes=128MB # 用相同时间内可以扫描的数据的大小来衡量打开一个文件的开销。当将多个文件写入同一个分区的时候该参数有用。 # 该值设置大一点有好处，有小文件的分区会比大文件分区处理速度更快（优先调度）。 spark.sql.files.openCostInBytes=4MB # Spark 事件总线是SparkListenerEvent事件的阻塞队列大小 spark.scheduler.listenerbus.eventqueue.size=100000 # 是否启动推测机制 spark.speculation=false # 开启spark的推测机制，开启推测机制后如果某一台机器的几个task特别慢，推测机制会将任务分配到其他机器执行，最后Spark会选取最快的作为最终结果。 # 2表示比其他task慢两倍时，启动推测机制 spark.speculation.multiplier=2 # 推测机制的检测周期 spark.speculation.interval=5000ms # 完成task的百分比时启动推测 spark.speculation.quantile=0.6 # 最多允许失败的Executor数量。 spark.task.maxFailures=10 # spark序列化 对于优化&lt;网络性能&gt;极为重要，将RDD以序列化格式来保存减少内存占用. spark.serializer=org.apache.spark.serializer.KryoSerializer # 因为spark是基于内存的机制，所以默认是开启RDD的压缩 spark.rdd.compress=true # Spark的安全管理 #https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SecurityManager.scala spark.ui.view.acls=* spark.ui.view.acls.groups=* # 表示配置GC线程数为3 spark.executor.extraJavaOptions=&quot;-XX:ParallelGCThreads=3&quot; # 最大广播表的大小。设置为-1可以禁止该功能。当前统计信息仅支持Hive Metastore表。这里设置的是10MB spark.sql.autoBroadcastJoinThreshold=104857600 # 广播等待超时，这里单位是秒 spark.sql.broadcastTimeout=300 # 心跳检测间隔 spark.yarn.scheduler.heartbeat.interval-ms=10000 spark.sql.broadcastTimeout #缓存表问题 #spark2.+采用： #spark.catalog.cacheTable(&quot;tableName&quot;)缓存表，spark.catalog.uncacheTable(&quot;tableName&quot;)解除缓存。 #spark 1.+采用： #sqlContext.cacheTable(&quot;tableName&quot;)缓存，sqlContext.uncacheTable(&quot;tableName&quot;) 解除缓存 #Sparksql仅仅会缓存必要的列，并且自动调整压缩算法来减少内存和GC压力。 #假如设置为true，SparkSql会根据统计信息自动的为每个列选择压缩方式进行压缩。 spark.sql.inMemoryColumnarStorage.compressed=true #控制列缓存的批量大小。批次大有助于改善内存使用和压缩，但是缓存数据会有OOM的风险 spark.sql.inMemoryColumnarStorage.batchSize=10000 参考： http://spark.apache.org/docs/latest/configuration.html","@type":"BlogPosting","url":"https://mlh.app/2019/05/18/787359.html","headline":"Spark SQL 可调参数汇总","dateModified":"2019-05-18T00:00:00+08:00","datePublished":"2019-05-18T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/18/787359.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Spark SQL 可调参数汇总</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-tomorrow-night-eighties"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h2><a id="_0"></a>写在前面的话：因为本人在职，所以没有充分的时间写博客，所以经常是写好整个框架，再陆陆续续的补充修改。所以如果发现什么错误请留言。</h2> 
  <p>本文主要是日常工作的积累，主要是简单罗列了常见的spark SQL的参数及其含义。</p> 
  <pre><code class="prism language-shell"><span class="token comment">#Job ID /Name</span>
spark.app.name<span class="token operator">=</span>clsfd_ad_attr_map_w_mvca_ins

<span class="token comment">#yarn 进行调度，也可以是mesos，yarn，以及standalone</span>

<span class="token comment">#一个spark application，是一个spark应用。一个应用对应且仅对应一个sparkContext。每一个应用，运行一组独立的executor processes。一个应用，可以以多线程的方式提交多个作业job。spark可以运行在多种集群管理器上如：mesos，yarn，以及standalone，每种集群管理器都会提供跨应用的资源调度策略。</span>
spark.master<span class="token operator">=</span>yarn

<span class="token comment">#激活外部shuffle服务。服务维护executor写的文件，因而executor可以被安全移除。</span>
<span class="token comment">#需要设置spark.dynamicAllocation.enabled 为true，同事指定外部shuffle服务。</span>
<span class="token comment">#对shuffle来说，executor现将自己的map输出写入到磁盘，然后，自己作为一个server，向其他executor提供这些map输出文件的数据。而动态资源调度将executor返还给集群后，这个shuffle数据服务就没有了。因此，如果要使用动态资源策略，解决这个问题的办法就是，将保持shuffle文件作为一个外部服务，始终运行在spark集群的每个节点上，独立于应用和executor</span>
spark.shuffle.service.enabled<span class="token operator">=</span>true

<span class="token comment">#在默认情况下，三种集群管理器均不使用动态资源调度模式。所以要使用动态资源调度需要提前配置。</span>
spark.dynamicAllocation.enabled<span class="token operator">=</span>true

<span class="token comment"># 如果所有的executor都移除了，重新请求时启动的初始executor数</span>
spark.dynamicAllocation.initialExecutors<span class="token operator">=</span>20

<span class="token comment"># 最少保留的executor数</span>
spark.dynamicAllocation.minExecutors<span class="token operator">=</span>10

<span class="token comment"># 最多使用的executor数，默认为你申请的最大executor数</span>
spark.dynamicAllocation.maxExecutors<span class="token operator">=</span>100

<span class="token comment"># 可以是cluster也可以是Client</span>
spark.submit.deployMode<span class="token operator">=</span>cluster

<span class="token comment"># 指定提交到Yarn的资源池</span>
spark.yarn.queue<span class="token operator">=</span>hdlq-data-batch-low

<span class="token comment"># 在yarn-cluster模式下，申请Yarn App Master（包括Driver）所用的内存。</span>
spark.driver.memory<span class="token operator">=</span>8g
<span class="token comment"># excutor的核心数</span>
spark.executor.cores<span class="token operator">=</span>16
<span class="token comment"># 一个Executor对应一个JVM进程。Executor占用的内存分为两部分：ExecutorMemory和MemoryOverhead</span>
spark.executor.memory<span class="token operator">=</span>32g
spark.yarn.executor.memoryOverhead<span class="token operator">=</span>2g

<span class="token comment"># shuffle分区数100，根据数据量进行调控，这儿配置了Join时shuffle的分区数和聚合数据时的分区数。</span>
spark.sql.shuffle.partitions<span class="token operator">=</span>100

<span class="token comment"># 如果用户没有指定并行度，下面这个参数将是RDD中的分区数，它是由join,reducebykey和parallelize </span>
<span class="token comment"># 这个参数只适用于未加工的RDD不适用于dataframe</span>
<span class="token comment"># 没有join和聚合计算操作，这个参数将是无效设置</span>
spark.default.parallelism

<span class="token comment"># 打包传入一个分区的最大字节，在读取文件的时候。</span>
spark.sql.files.maxPartitionBytes<span class="token operator">=</span>128MB

<span class="token comment"># 用相同时间内可以扫描的数据的大小来衡量打开一个文件的开销。当将多个文件写入同一个分区的时候该参数有用。</span>
<span class="token comment"># 该值设置大一点有好处，有小文件的分区会比大文件分区处理速度更快（优先调度）。</span>
spark.sql.files.openCostInBytes<span class="token operator">=</span>4MB

<span class="token comment"># Spark 事件总线是SparkListenerEvent事件的阻塞队列大小</span>
spark.scheduler.listenerbus.eventqueue.size<span class="token operator">=</span>100000

<span class="token comment"># 是否启动推测机制</span>
spark.speculation<span class="token operator">=</span>false

<span class="token comment"># 开启spark的推测机制，开启推测机制后如果某一台机器的几个task特别慢，推测机制会将任务分配到其他机器执行，最后Spark会选取最快的作为最终结果。</span>
<span class="token comment"># 2表示比其他task慢两倍时，启动推测机制</span>
spark.speculation.multiplier<span class="token operator">=</span>2

<span class="token comment"># 推测机制的检测周期</span>
spark.speculation.interval<span class="token operator">=</span>5000ms

<span class="token comment"># 完成task的百分比时启动推测</span>
spark.speculation.quantile<span class="token operator">=</span>0.6

<span class="token comment"># 最多允许失败的Executor数量。</span>
spark.task.maxFailures<span class="token operator">=</span>10

<span class="token comment"># spark序列化 对于优化&lt;网络性能&gt;极为重要，将RDD以序列化格式来保存减少内存占用.</span>
spark.serializer<span class="token operator">=</span>org.apache.spark.serializer.KryoSerializer

<span class="token comment"># 因为spark是基于内存的机制，所以默认是开启RDD的压缩</span>
spark.rdd.compress<span class="token operator">=</span>true

<span class="token comment"># Spark的安全管理</span>
<span class="token comment">#https://github.com/apache/spark/blob/master/core/src/main/scala/org/apache/spark/SecurityManager.scala</span>
spark.ui.view.acls<span class="token operator">=</span>*
spark.ui.view.acls.groups<span class="token operator">=</span>*

<span class="token comment"># 表示配置GC线程数为3</span>
spark.executor.extraJavaOptions<span class="token operator">=</span><span class="token string">"-XX:ParallelGCThreads=3"</span>

<span class="token comment"># 最大广播表的大小。设置为-1可以禁止该功能。当前统计信息仅支持Hive Metastore表。这里设置的是10MB</span>
spark.sql.autoBroadcastJoinThreshold<span class="token operator">=</span>104857600

<span class="token comment"># 广播等待超时，这里单位是秒</span>
spark.sql.broadcastTimeout<span class="token operator">=</span>300

<span class="token comment"># 心跳检测间隔</span>
spark.yarn.scheduler.heartbeat.interval-ms<span class="token operator">=</span>10000

spark.sql.broadcastTimeout

<span class="token comment">#缓存表问题</span>
<span class="token comment">#spark2.+采用：</span>
<span class="token comment">#spark.catalog.cacheTable("tableName")缓存表，spark.catalog.uncacheTable("tableName")解除缓存。</span>
<span class="token comment">#spark 1.+采用：</span>
<span class="token comment">#sqlContext.cacheTable("tableName")缓存，sqlContext.uncacheTable("tableName") 解除缓存</span>
<span class="token comment">#Sparksql仅仅会缓存必要的列，并且自动调整压缩算法来减少内存和GC压力。</span>

<span class="token comment">#假如设置为true，SparkSql会根据统计信息自动的为每个列选择压缩方式进行压缩。</span>
spark.sql.inMemoryColumnarStorage.compressed<span class="token operator">=</span>true

<span class="token comment">#控制列缓存的批量大小。批次大有助于改善内存使用和压缩，但是缓存数据会有OOM的风险</span>
spark.sql.inMemoryColumnarStorage.batchSize<span class="token operator">=</span>10000

</code></pre> 
  <p>参考：<br> <a href="http://spark.apache.org/docs/latest/configuration.html" rel="nofollow">http://spark.apache.org/docs/latest/configuration.html</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
