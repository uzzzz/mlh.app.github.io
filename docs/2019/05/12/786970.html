<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>计算机视觉–基于BOW的图像检索 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="计算机视觉–基于BOW的图像检索" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Bag Of Word原理简述 Bag Of Word模型，是现在一种用于图像检索的一种方法。它最早用于对于文章内容的检索，原理是将文本看作是单词的集合，不考虑其中的语法，上下文等等。通过建立词典，对每个单词出现次数进行统计，以便得到文本内容的分类。计算机视觉的专家从中获得灵感，将其用于图像的检索中，就有了Bag Of Features。 Bag Of Features实现图像检索的简单步骤 1.特征提取 2.学习“视觉词典” 3.针对输入特征集，根据视觉词典进行量化 4.把输入图像，根据TF-IDF转化成视觉单词的频率直方图 5.构造特征到图像的倒排表，通过倒排表快速 索引相关图像 6.根据索引结果进行直方图匹配 1.特征提取 之前的课程之中学习了关于特征提取的几个方式，例如sift，Harris脚点。这里我们通过sift来提取图像的特征点。类似BOW，我们将图像看成一个由各种图像块组成的集合，通过特征提取，获得图像的关键图像特征。 2.学习“视觉词典” 通过步骤1，我们获得了多张图像的特征点。这些特征提取出来，并没有通过分类处理，其中有的特征点之间是极其相似，所以这一步骤通过K-means聚类算法，将我们提取出来的特征点进行分类处理。 算法的简单流程： 随机初始化 K 个聚类中心 重复下述步骤直至算法收敛: 对应每个特征，根据距离关系赋值给某个中心/类别 对每个类别，根据其对应的特征集重新计算聚类中心 聚类是学习视觉词典的重点操作。将聚类出来的聚类中心称为视觉单词。而将视觉单词组成的集合称为视觉词典/码本。 这里我们需要注意一个问题，关于码本的大小。 如果我们做出来的码本规模太小， 就会出现，我们的视觉单词不能包括所有可能的情况。 相反的，如果我们做出来的码本规模过大，会使得计算量增加，且有过拟合现象出现。 3.针对输入特征集，根据视觉词典进行量化 这一步骤将我们输入的特征集合，映射到上一步做来的码本之中。通过计算输入特征到视觉单词的距离，然后将其映射到距离最近的视觉单词中，并计数。 4.把输入图像，根据TF-IDF转化成视觉单词的频率直方图 这一步骤通过对图像特征提取，然后将提取出来的特征点。 5.构造特征到图像的倒排表，通过倒排表快速 索引相关图像 倒排表是一种逆向的查找方式，在BOW中大体的思路是通过已经提取出来的词汇，反向查找出现过这个词汇的文章。如图，查找多个词汇，就形成了一个倒排表。 BOF中倒排表也是同理。通过对视觉词汇的反向查找，就会得到拥有同一视觉词汇的图像集合，反复多次就能得到一张倒排表。倒排表可以快速的得到新的图像与数据库里相似的图像。 6.根据索引结果进行直方图匹配 当我们做完上面的步骤，就需要对直方图进行匹配。直方图的匹配给出输入图像的频率直方图，在数据库中查找K个最近邻的图像，根据这K个近邻来投票图像的分类结果。 代码： #-- coding: utf-8 -- import pickle from PCV.imagesearch import vocabulary from PCV.tools.imtools import get_imlist from PCV.localdescriptors import sift #获取图像列表 imlist = get_imlist(‘E:/BaiduNetdiskDownload/PCV-book-data/data/first1000/’) nbr_images = len(imlist) #获取特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #提取文件夹下图像的sift特征 for i in range(nbr_images): sift.process_image(imlist[i], featlist[i]) #生成词汇 voc = vocabulary.Vocabulary(‘ukbenchtest’) voc.train(featlist, 1000, 10) #保存词汇 #saving vocabulary with open(‘E:/BaiduNetdiskDownload/PCV-book-data/data/first1000/vocabulary.pkl’, ‘wb’) as f: pickle.dump(voc, f) print ‘vocabulary is:’, voc.name, voc.nbr_words #-- coding: utf-8 -- import pickle from PCV.imagesearch import imagesearch from PCV.localdescriptors import sift from sqlite3 import dbapi2 as sqlite from PCV.tools.imtools import get_imlist #获取图像列表 imlist = get_imlist(’./first1000/’) nbr_images = len(imlist) #获取特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #load vocabulary #载入词汇 with open(’./first1000/vocabulary.pkl’, ‘rb’) as f: voc = pickle.load(f) #创建索引 indx = imagesearch.Indexer(‘testImaAdd.db’,voc) indx.create_tables() #go through all images, project features on vocabulary and insert #遍历所有的图像，并将它们的特征投影到词汇上 for i in range(nbr_images)[:500]: locs,descr = sift.read_features_from_file(featlist[i]) indx.add_to_index(imlist[i],descr) #commit to database #提交到数据库 indx.db_commit() con = sqlite.connect(‘testImaAdd.db’) print con.execute(‘select count (filename) from imlist’).fetchone() print con.execute(‘select * from imlist’).fetchone() #-- coding: utf-8 -- import pickle from PCV.localdescriptors import sift from PCV.imagesearch import imagesearch from PCV.geometry import homography from PCV.tools.imtools import get_imlist #load image list and vocabulary #载入图像列表 imlist = get_imlist(’./first1000/’) nbr_images = len(imlist) #载入特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #载入词汇 with open(’./first1000/vocabulary.pkl’, ‘rb’) as f: voc = pickle.load(f) src = imagesearch.Searcher(‘testImaAdd.db’,voc) #index of query image and number of results to return #查询图像索引和查询返回的图像数 q_ind = 0 nbr_results = 20 #regular query #常规查询(按欧式距离对结果排序) res_reg = [w[1] for w in src.query(imlist[q_ind])[:nbr_results]] print(‘top matches (regular):’, res_reg) #load image features for query image #载入查询图像特征 q_locs,q_descr = sift.read_features_from_file(featlist[q_ind]) fp = homography.make_homog(q_locs[:,:2].T) #RANSAC model for homography fitting #用单应性进行拟合建立RANSAC模型 model = homography.RansacModel() rank = {} #load image features for result #载入候选图像的特征 for ndx in res_reg[1:]: locs,descr = sift.read_features_from_file(featlist[ndx]) # because ‘ndx’ is a rowid of the DB that starts at 1 # get matches matches = sift.match(q_descr,descr) ind = matches.nonzero()[0] ind2 = matches[ind] tp = homography.make_homog(locs[:,:2].T) # compute homography, count inliers. if not enough matches return empty list try: H,inliers = homography.H_from_ransac(fp[:,ind],tp[:,ind2],model,match_theshold=4) except: inliers = [] # store inlier count rank[ndx] = len(inliers) #sort dictionary to get the most inliers first sorted_rank = sorted(rank.items(), key=lambda t: t[1], reverse=True) res_geom = [res_reg[0]]+[s[0] for s in sorted_rank] print(‘top matches (homography):’, res_geom) #显示查询结果 imagesearch.plot_results(src,res_reg[:8]) #常规查询 imagesearch.plot_results(src,res_geom[:8]) #重排后的结果 实验结果：" />
<meta property="og:description" content="Bag Of Word原理简述 Bag Of Word模型，是现在一种用于图像检索的一种方法。它最早用于对于文章内容的检索，原理是将文本看作是单词的集合，不考虑其中的语法，上下文等等。通过建立词典，对每个单词出现次数进行统计，以便得到文本内容的分类。计算机视觉的专家从中获得灵感，将其用于图像的检索中，就有了Bag Of Features。 Bag Of Features实现图像检索的简单步骤 1.特征提取 2.学习“视觉词典” 3.针对输入特征集，根据视觉词典进行量化 4.把输入图像，根据TF-IDF转化成视觉单词的频率直方图 5.构造特征到图像的倒排表，通过倒排表快速 索引相关图像 6.根据索引结果进行直方图匹配 1.特征提取 之前的课程之中学习了关于特征提取的几个方式，例如sift，Harris脚点。这里我们通过sift来提取图像的特征点。类似BOW，我们将图像看成一个由各种图像块组成的集合，通过特征提取，获得图像的关键图像特征。 2.学习“视觉词典” 通过步骤1，我们获得了多张图像的特征点。这些特征提取出来，并没有通过分类处理，其中有的特征点之间是极其相似，所以这一步骤通过K-means聚类算法，将我们提取出来的特征点进行分类处理。 算法的简单流程： 随机初始化 K 个聚类中心 重复下述步骤直至算法收敛: 对应每个特征，根据距离关系赋值给某个中心/类别 对每个类别，根据其对应的特征集重新计算聚类中心 聚类是学习视觉词典的重点操作。将聚类出来的聚类中心称为视觉单词。而将视觉单词组成的集合称为视觉词典/码本。 这里我们需要注意一个问题，关于码本的大小。 如果我们做出来的码本规模太小， 就会出现，我们的视觉单词不能包括所有可能的情况。 相反的，如果我们做出来的码本规模过大，会使得计算量增加，且有过拟合现象出现。 3.针对输入特征集，根据视觉词典进行量化 这一步骤将我们输入的特征集合，映射到上一步做来的码本之中。通过计算输入特征到视觉单词的距离，然后将其映射到距离最近的视觉单词中，并计数。 4.把输入图像，根据TF-IDF转化成视觉单词的频率直方图 这一步骤通过对图像特征提取，然后将提取出来的特征点。 5.构造特征到图像的倒排表，通过倒排表快速 索引相关图像 倒排表是一种逆向的查找方式，在BOW中大体的思路是通过已经提取出来的词汇，反向查找出现过这个词汇的文章。如图，查找多个词汇，就形成了一个倒排表。 BOF中倒排表也是同理。通过对视觉词汇的反向查找，就会得到拥有同一视觉词汇的图像集合，反复多次就能得到一张倒排表。倒排表可以快速的得到新的图像与数据库里相似的图像。 6.根据索引结果进行直方图匹配 当我们做完上面的步骤，就需要对直方图进行匹配。直方图的匹配给出输入图像的频率直方图，在数据库中查找K个最近邻的图像，根据这K个近邻来投票图像的分类结果。 代码： #-- coding: utf-8 -- import pickle from PCV.imagesearch import vocabulary from PCV.tools.imtools import get_imlist from PCV.localdescriptors import sift #获取图像列表 imlist = get_imlist(‘E:/BaiduNetdiskDownload/PCV-book-data/data/first1000/’) nbr_images = len(imlist) #获取特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #提取文件夹下图像的sift特征 for i in range(nbr_images): sift.process_image(imlist[i], featlist[i]) #生成词汇 voc = vocabulary.Vocabulary(‘ukbenchtest’) voc.train(featlist, 1000, 10) #保存词汇 #saving vocabulary with open(‘E:/BaiduNetdiskDownload/PCV-book-data/data/first1000/vocabulary.pkl’, ‘wb’) as f: pickle.dump(voc, f) print ‘vocabulary is:’, voc.name, voc.nbr_words #-- coding: utf-8 -- import pickle from PCV.imagesearch import imagesearch from PCV.localdescriptors import sift from sqlite3 import dbapi2 as sqlite from PCV.tools.imtools import get_imlist #获取图像列表 imlist = get_imlist(’./first1000/’) nbr_images = len(imlist) #获取特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #load vocabulary #载入词汇 with open(’./first1000/vocabulary.pkl’, ‘rb’) as f: voc = pickle.load(f) #创建索引 indx = imagesearch.Indexer(‘testImaAdd.db’,voc) indx.create_tables() #go through all images, project features on vocabulary and insert #遍历所有的图像，并将它们的特征投影到词汇上 for i in range(nbr_images)[:500]: locs,descr = sift.read_features_from_file(featlist[i]) indx.add_to_index(imlist[i],descr) #commit to database #提交到数据库 indx.db_commit() con = sqlite.connect(‘testImaAdd.db’) print con.execute(‘select count (filename) from imlist’).fetchone() print con.execute(‘select * from imlist’).fetchone() #-- coding: utf-8 -- import pickle from PCV.localdescriptors import sift from PCV.imagesearch import imagesearch from PCV.geometry import homography from PCV.tools.imtools import get_imlist #load image list and vocabulary #载入图像列表 imlist = get_imlist(’./first1000/’) nbr_images = len(imlist) #载入特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #载入词汇 with open(’./first1000/vocabulary.pkl’, ‘rb’) as f: voc = pickle.load(f) src = imagesearch.Searcher(‘testImaAdd.db’,voc) #index of query image and number of results to return #查询图像索引和查询返回的图像数 q_ind = 0 nbr_results = 20 #regular query #常规查询(按欧式距离对结果排序) res_reg = [w[1] for w in src.query(imlist[q_ind])[:nbr_results]] print(‘top matches (regular):’, res_reg) #load image features for query image #载入查询图像特征 q_locs,q_descr = sift.read_features_from_file(featlist[q_ind]) fp = homography.make_homog(q_locs[:,:2].T) #RANSAC model for homography fitting #用单应性进行拟合建立RANSAC模型 model = homography.RansacModel() rank = {} #load image features for result #载入候选图像的特征 for ndx in res_reg[1:]: locs,descr = sift.read_features_from_file(featlist[ndx]) # because ‘ndx’ is a rowid of the DB that starts at 1 # get matches matches = sift.match(q_descr,descr) ind = matches.nonzero()[0] ind2 = matches[ind] tp = homography.make_homog(locs[:,:2].T) # compute homography, count inliers. if not enough matches return empty list try: H,inliers = homography.H_from_ransac(fp[:,ind],tp[:,ind2],model,match_theshold=4) except: inliers = [] # store inlier count rank[ndx] = len(inliers) #sort dictionary to get the most inliers first sorted_rank = sorted(rank.items(), key=lambda t: t[1], reverse=True) res_geom = [res_reg[0]]+[s[0] for s in sorted_rank] print(‘top matches (homography):’, res_geom) #显示查询结果 imagesearch.plot_results(src,res_reg[:8]) #常规查询 imagesearch.plot_results(src,res_geom[:8]) #重排后的结果 实验结果：" />
<link rel="canonical" href="https://mlh.app/2019/05/12/786970.html" />
<meta property="og:url" content="https://mlh.app/2019/05/12/786970.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-12T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"Bag Of Word原理简述 Bag Of Word模型，是现在一种用于图像检索的一种方法。它最早用于对于文章内容的检索，原理是将文本看作是单词的集合，不考虑其中的语法，上下文等等。通过建立词典，对每个单词出现次数进行统计，以便得到文本内容的分类。计算机视觉的专家从中获得灵感，将其用于图像的检索中，就有了Bag Of Features。 Bag Of Features实现图像检索的简单步骤 1.特征提取 2.学习“视觉词典” 3.针对输入特征集，根据视觉词典进行量化 4.把输入图像，根据TF-IDF转化成视觉单词的频率直方图 5.构造特征到图像的倒排表，通过倒排表快速 索引相关图像 6.根据索引结果进行直方图匹配 1.特征提取 之前的课程之中学习了关于特征提取的几个方式，例如sift，Harris脚点。这里我们通过sift来提取图像的特征点。类似BOW，我们将图像看成一个由各种图像块组成的集合，通过特征提取，获得图像的关键图像特征。 2.学习“视觉词典” 通过步骤1，我们获得了多张图像的特征点。这些特征提取出来，并没有通过分类处理，其中有的特征点之间是极其相似，所以这一步骤通过K-means聚类算法，将我们提取出来的特征点进行分类处理。 算法的简单流程： 随机初始化 K 个聚类中心 重复下述步骤直至算法收敛: 对应每个特征，根据距离关系赋值给某个中心/类别 对每个类别，根据其对应的特征集重新计算聚类中心 聚类是学习视觉词典的重点操作。将聚类出来的聚类中心称为视觉单词。而将视觉单词组成的集合称为视觉词典/码本。 这里我们需要注意一个问题，关于码本的大小。 如果我们做出来的码本规模太小， 就会出现，我们的视觉单词不能包括所有可能的情况。 相反的，如果我们做出来的码本规模过大，会使得计算量增加，且有过拟合现象出现。 3.针对输入特征集，根据视觉词典进行量化 这一步骤将我们输入的特征集合，映射到上一步做来的码本之中。通过计算输入特征到视觉单词的距离，然后将其映射到距离最近的视觉单词中，并计数。 4.把输入图像，根据TF-IDF转化成视觉单词的频率直方图 这一步骤通过对图像特征提取，然后将提取出来的特征点。 5.构造特征到图像的倒排表，通过倒排表快速 索引相关图像 倒排表是一种逆向的查找方式，在BOW中大体的思路是通过已经提取出来的词汇，反向查找出现过这个词汇的文章。如图，查找多个词汇，就形成了一个倒排表。 BOF中倒排表也是同理。通过对视觉词汇的反向查找，就会得到拥有同一视觉词汇的图像集合，反复多次就能得到一张倒排表。倒排表可以快速的得到新的图像与数据库里相似的图像。 6.根据索引结果进行直方图匹配 当我们做完上面的步骤，就需要对直方图进行匹配。直方图的匹配给出输入图像的频率直方图，在数据库中查找K个最近邻的图像，根据这K个近邻来投票图像的分类结果。 代码： #-- coding: utf-8 -- import pickle from PCV.imagesearch import vocabulary from PCV.tools.imtools import get_imlist from PCV.localdescriptors import sift #获取图像列表 imlist = get_imlist(‘E:/BaiduNetdiskDownload/PCV-book-data/data/first1000/’) nbr_images = len(imlist) #获取特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #提取文件夹下图像的sift特征 for i in range(nbr_images): sift.process_image(imlist[i], featlist[i]) #生成词汇 voc = vocabulary.Vocabulary(‘ukbenchtest’) voc.train(featlist, 1000, 10) #保存词汇 #saving vocabulary with open(‘E:/BaiduNetdiskDownload/PCV-book-data/data/first1000/vocabulary.pkl’, ‘wb’) as f: pickle.dump(voc, f) print ‘vocabulary is:’, voc.name, voc.nbr_words #-- coding: utf-8 -- import pickle from PCV.imagesearch import imagesearch from PCV.localdescriptors import sift from sqlite3 import dbapi2 as sqlite from PCV.tools.imtools import get_imlist #获取图像列表 imlist = get_imlist(’./first1000/’) nbr_images = len(imlist) #获取特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #load vocabulary #载入词汇 with open(’./first1000/vocabulary.pkl’, ‘rb’) as f: voc = pickle.load(f) #创建索引 indx = imagesearch.Indexer(‘testImaAdd.db’,voc) indx.create_tables() #go through all images, project features on vocabulary and insert #遍历所有的图像，并将它们的特征投影到词汇上 for i in range(nbr_images)[:500]: locs,descr = sift.read_features_from_file(featlist[i]) indx.add_to_index(imlist[i],descr) #commit to database #提交到数据库 indx.db_commit() con = sqlite.connect(‘testImaAdd.db’) print con.execute(‘select count (filename) from imlist’).fetchone() print con.execute(‘select * from imlist’).fetchone() #-- coding: utf-8 -- import pickle from PCV.localdescriptors import sift from PCV.imagesearch import imagesearch from PCV.geometry import homography from PCV.tools.imtools import get_imlist #load image list and vocabulary #载入图像列表 imlist = get_imlist(’./first1000/’) nbr_images = len(imlist) #载入特征列表 featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)] #载入词汇 with open(’./first1000/vocabulary.pkl’, ‘rb’) as f: voc = pickle.load(f) src = imagesearch.Searcher(‘testImaAdd.db’,voc) #index of query image and number of results to return #查询图像索引和查询返回的图像数 q_ind = 0 nbr_results = 20 #regular query #常规查询(按欧式距离对结果排序) res_reg = [w[1] for w in src.query(imlist[q_ind])[:nbr_results]] print(‘top matches (regular):’, res_reg) #load image features for query image #载入查询图像特征 q_locs,q_descr = sift.read_features_from_file(featlist[q_ind]) fp = homography.make_homog(q_locs[:,:2].T) #RANSAC model for homography fitting #用单应性进行拟合建立RANSAC模型 model = homography.RansacModel() rank = {} #load image features for result #载入候选图像的特征 for ndx in res_reg[1:]: locs,descr = sift.read_features_from_file(featlist[ndx]) # because ‘ndx’ is a rowid of the DB that starts at 1 # get matches matches = sift.match(q_descr,descr) ind = matches.nonzero()[0] ind2 = matches[ind] tp = homography.make_homog(locs[:,:2].T) # compute homography, count inliers. if not enough matches return empty list try: H,inliers = homography.H_from_ransac(fp[:,ind],tp[:,ind2],model,match_theshold=4) except: inliers = [] # store inlier count rank[ndx] = len(inliers) #sort dictionary to get the most inliers first sorted_rank = sorted(rank.items(), key=lambda t: t[1], reverse=True) res_geom = [res_reg[0]]+[s[0] for s in sorted_rank] print(‘top matches (homography):’, res_geom) #显示查询结果 imagesearch.plot_results(src,res_reg[:8]) #常规查询 imagesearch.plot_results(src,res_geom[:8]) #重排后的结果 实验结果：","@type":"BlogPosting","url":"https://mlh.app/2019/05/12/786970.html","headline":"计算机视觉–基于BOW的图像检索","dateModified":"2019-05-12T00:00:00+08:00","datePublished":"2019-05-12T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/12/786970.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>计算机视觉--基于BOW的图像检索</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;"> 
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path> 
  </svg> 
  <h3><a id="Bag_Of_Word_0"></a>Bag Of Word原理简述</h3> 
  <p>Bag Of Word模型，是现在一种用于图像检索的一种方法。它最早用于对于文章内容的检索，原理是将文本看作是单词的集合，不考虑其中的语法，上下文等等。通过建立词典，对每个单词出现次数进行统计，以便得到文本内容的分类。计算机视觉的专家从中获得灵感，将其用于图像的检索中，就有了Bag Of Features。</p> 
  <h3><a id="Bag_Of_Features_3"></a>Bag Of Features实现图像检索的简单步骤</h3> 
  <p>1.特征提取<br> 2.学习“视觉词典”<br> 3.针对输入特征集，根据视觉词典进行量化<br> 4.把输入图像，根据TF-IDF转化成视觉单词的频率直方图<br> 5.构造特征到图像的倒排表，通过倒排表快速 索引相关图像<br> 6.根据索引结果进行直方图匹配</p> 
  <h3><a id="1_11"></a>1.特征提取</h3> 
  <p>之前的课程之中学习了关于特征提取的几个方式，例如sift，Harris脚点。这里我们通过sift来提取图像的特征点。类似BOW，我们将图像看成一个由各种图像块组成的集合，通过特征提取，获得图像的关键图像特征。</p> 
  <h3><a id="2_14"></a>2.学习“视觉词典”</h3> 
  <p>通过步骤1，我们获得了多张图像的特征点。这些特征提取出来，并没有通过分类处理，其中有的特征点之间是极其相似，所以这一步骤通过K-means聚类算法，将我们提取出来的特征点进行分类处理。<br> 算法的简单流程：</p> 
  <p>随机初始化 K 个聚类中心<br> 重复下述步骤直至算法收敛:<br> 对应每个特征，根据距离关系赋值给某个中心/类别<br> 对每个类别，根据其对应的特征集重新计算聚类中心<br> 聚类是学习视觉词典的重点操作。将聚类出来的聚类中心称为视觉单词。而将视觉单词组成的集合称为视觉词典/码本。<br> 这里我们需要注意一个问题，关于码本的大小。</p> 
  <p>如果我们做出来的码本规模太小， 就会出现，我们的视觉单词不能包括所有可能的情况。<br> 相反的，如果我们做出来的码本规模过大，会使得计算量增加，且有过拟合现象出现。</p> 
  <h3><a id="3_27"></a>3.针对输入特征集，根据视觉词典进行量化</h3> 
  <p>这一步骤将我们输入的特征集合，映射到上一步做来的码本之中。通过计算输入特征到视觉单词的距离，然后将其映射到距离最近的视觉单词中，并计数。</p> 
  <h3><a id="4TFIDF_30"></a>4.把输入图像，根据TF-IDF转化成视觉单词的频率直方图</h3> 
  <p>这一步骤通过对图像特征提取，然后将提取出来的特征点。</p> 
  <h3><a id="5__33"></a>5.构造特征到图像的倒排表，通过倒排表快速 索引相关图像</h3> 
  <p>倒排表是一种逆向的查找方式，在BOW中大体的思路是通过已经提取出来的词汇，反向查找出现过这个词汇的文章。如图，查找多个词汇，就形成了一个倒排表。</p> 
  <p>BOF中倒排表也是同理。通过对视觉词汇的反向查找，就会得到拥有同一视觉词汇的图像集合，反复多次就能得到一张倒排表。倒排表可以快速的得到新的图像与数据库里相似的图像。</p> 
  <h3><a id="6_38"></a>6.根据索引结果进行直方图匹配</h3> 
  <p>当我们做完上面的步骤，就需要对直方图进行匹配。直方图的匹配给出输入图像的频率直方图，在数据库中查找K个最近邻的图像，根据这K个近邻来投票图像的分类结果。<br> 代码：<br> #-<em>- coding: utf-8 -</em>-<br> import pickle<br> from PCV.imagesearch import vocabulary<br> from PCV.tools.imtools import get_imlist<br> from PCV.localdescriptors import sift</p> 
  <p>#获取图像列表<br> imlist = get_imlist(‘E:/BaiduNetdiskDownload/PCV-book-data/data/first1000/’)<br> nbr_images = len(imlist)<br> #获取特征列表<br> featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)]</p> 
  <p>#提取文件夹下图像的sift特征<br> for i in range(nbr_images):<br> sift.process_image(imlist[i], featlist[i])</p> 
  <p>#生成词汇<br> voc = vocabulary.Vocabulary(‘ukbenchtest’)<br> voc.train(featlist, 1000, 10)<br> #保存词汇<br> #saving vocabulary<br> with open(‘E:/BaiduNetdiskDownload/PCV-book-data/data/first1000/vocabulary.pkl’, ‘wb’) as f:<br> pickle.dump(voc, f)<br> print ‘vocabulary is:’, <a href="http://voc.name" rel="nofollow">voc.name</a>, voc.nbr_words<br> #-<em>- coding: utf-8 -</em>-<br> import pickle<br> from PCV.imagesearch import imagesearch<br> from PCV.localdescriptors import sift<br> from sqlite3 import dbapi2 as sqlite<br> from PCV.tools.imtools import get_imlist</p> 
  <p>#获取图像列表<br> imlist = get_imlist(’./first1000/’)<br> nbr_images = len(imlist)<br> #获取特征列表<br> featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)]</p> 
  <p>#load vocabulary<br> #载入词汇<br> with open(’./first1000/vocabulary.pkl’, ‘rb’) as f:<br> voc = pickle.load(f)<br> #创建索引<br> indx = imagesearch.Indexer(‘testImaAdd.db’,voc)<br> indx.create_tables()<br> #go through all images, project features on vocabulary and insert<br> #遍历所有的图像，并将它们的特征投影到词汇上<br> for i in range(nbr_images)[:500]:<br> locs,descr = sift.read_features_from_file(featlist[i])<br> indx.add_to_index(imlist[i],descr)<br> #commit to database<br> #提交到数据库<br> indx.db_commit()</p> 
  <p>con = sqlite.connect(‘testImaAdd.db’)<br> print con.execute(‘select count (filename) from imlist’).fetchone()<br> print con.execute(‘select * from imlist’).fetchone()<br> #-<em>- coding: utf-8 -</em>-<br> import pickle<br> from PCV.localdescriptors import sift<br> from PCV.imagesearch import imagesearch<br> from PCV.geometry import homography<br> from PCV.tools.imtools import get_imlist</p> 
  <p>#load image list and vocabulary<br> #载入图像列表<br> imlist = get_imlist(’./first1000/’)<br> nbr_images = len(imlist)<br> #载入特征列表<br> featlist = [imlist[i][:-3]+‘sift’ for i in range(nbr_images)]</p> 
  <p>#载入词汇<br> with open(’./first1000/vocabulary.pkl’, ‘rb’) as f:<br> voc = pickle.load(f)</p> 
  <p>src = imagesearch.Searcher(‘testImaAdd.db’,voc)</p> 
  <p>#index of query image and number of results to return<br> #查询图像索引和查询返回的图像数<br> q_ind = 0<br> nbr_results = 20</p> 
  <p>#regular query<br> #常规查询(按欧式距离对结果排序)<br> res_reg = [w[1] for w in src.query(imlist[q_ind])[:nbr_results]]<br> print(‘top matches (regular):’, res_reg)</p> 
  <p>#load image features for query image<br> #载入查询图像特征<br> q_locs,q_descr = sift.read_features_from_file(featlist[q_ind])<br> fp = homography.make_homog(q_locs[:,:2].T)</p> 
  <p>#RANSAC model for homography fitting<br> #用单应性进行拟合建立RANSAC模型<br> model = homography.RansacModel()<br> rank = {}</p> 
  <p>#load image features for result<br> #载入候选图像的特征<br> for ndx in res_reg[1:]:<br> locs,descr = sift.read_features_from_file(featlist[ndx]) # because ‘ndx’ is a rowid of the DB that starts at 1<br> # get matches<br> matches = sift.match(q_descr,descr)<br> ind = matches.nonzero()[0]<br> ind2 = matches[ind]<br> tp = homography.make_homog(locs[:,:2].T)<br> # compute homography, count inliers. if not enough matches return empty list<br> try:<br> H,inliers = homography.H_from_ransac(fp[:,ind],tp[:,ind2],model,match_theshold=4)<br> except:<br> inliers = []<br> # store inlier count<br> rank[ndx] = len(inliers)</p> 
  <p>#sort dictionary to get the most inliers first<br> sorted_rank = sorted(rank.items(), key=lambda t: t[1], reverse=True)<br> res_geom = [res_reg[0]]+[s[0] for s in sorted_rank]<br> print(‘top matches (homography):’, res_geom)</p> 
  <p>#显示查询结果<br> imagesearch.plot_results(src,res_reg[:8]) #常规查询<br> imagesearch.plot_results(src,res_geom[:8]) #重排后的结果</p> 
  <p>实验结果：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512215038837.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RoZWJsYWNrc3VtbWVy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190512215110248.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3RoZWJsYWNrc3VtbWVy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
