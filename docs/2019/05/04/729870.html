<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>大数据技术之_19_Spark学习_06_Spark 源码解析 + Spark 通信架构、脚本解析、standalone 模式启动、提交流程 + Spark Shuffle 过程 + Spark 内存 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="大数据技术之_19_Spark学习_06_Spark 源码解析 + Spark 通信架构、脚本解析、standalone 模式启动、提交流程 + Spark Shuffle 过程 + Spark 内存" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="https://www.cnblogs.com/chenmingjun/p/10803261.html 文章目录 第1章 Spark 整体概述 1.1 整体概念 1.2 RDD 抽象 1.3 计算抽象 1.4 集群模式 1.5 RPC 网络通信抽象 1.6 启动 Standalone 集群 1.7 核心组件 1.8 核心组件交互流程 1.9 Block 管理 1.10整体应用 第2章 Spark 通信架构 2.1 通信组件概览 2.2 Endpoint 启动过程 2.3 Endpoint Send&amp;Ask 流程 2.4 Endpoint Receive 流程 2.5 Endpoint Inbox 处理流程 2.6 Endpoint 画像 第3章 脚本解析 3.1 start-daemon.sh 3.2 spark-class 3.3 start-master.sh 3.4 start-slaves.sh 3.5 start-all.sh 3.6 spark-submit 第4章 Master 节点启动 4.1 脚本概览 4.2 启动流程 4.3 OnStart 监听事件 4.4 RpcMessage 处理 (receiveAndReply) 4.5 OneWayMessage 处理 (receive) 4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑 第5章 Worker 节点启动 5.1 脚本概览 5.2 启动流程 5.3 OnStart 监听事件 5.4 RpcMessage 处理 (receiveAndReply) 5.5 OneWayMessage 处理 (receive) 第6章 Client 启动流程 6.1 脚本概览 6.2 SparkSubmit 启动流程 6.3 Client 启动流程 6.4 Client 的 OnStart 监听事件 6.5 RpcMessage 处理 (receiveAndReply) 6.6 OneWayMessage 处理(receive) 第7章 Driver 和 DriverRunner 7.1 Master 对 Driver 资源分配 7.2 Worker 运行 DriverRunner 7.3 DriverRunner 创建并运行 DriverWrapper 第8章 SparkContext 解析 8.1 SparkContext 解析 8.2 SparkContext 创建过程 8.3 SparkContext 简易结构与交互关系 8.4 Master 对 Application 资源分配 8.5 Worker 创建 Executor 第9章 Job 提交和 Task 的拆分 9.1 整体预览 9.2 Code 转化为初始 RDDs 9.3 RDD 分解为待执行任务集合（TaskSet） 9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver 9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor 第10章 Task 执行和回馈 10.1 Task 的执行流程 10.2 Task 的回馈流程 10.3 Task 的迭代流程 10.4 精彩图解 第11章 Spark 的数据存储 11.1 存储子系统概览 11.2 启动过程分析 11.3 通信层 11.4 存储层 11.5 数据写入过程分析 11.6 数据读取过程分析 11.7 Partition 如何转化为 Block 11.8 partition 和 block 的对应关系 第12章 Spark Shuffle 过程 12.1 MapReduce 的 Shuffle 过程介绍 12.2 HashShuffle 过程介绍 12.3 SortShuffle 过程介绍 12.4 TungstenShuffle 过程介绍 12.5 MapReduce 与 Spark 过程对比 第13章 Spark 内存管理 13.1 堆内和堆外内存规划 13.2 内存空间分配 13.3 存储内存管理 13.4 执行内存管理 第14章 部署模式解析 14.1 部署模式概述 14.2 standalone 框架 14.3 yarn 集群模式 14.4 mesos 集群模式 14.5 spark 三种部署模式的区别 14.6 异常场景分析 第15章 wordcount 程序运行原理窥探 15.1 spark 之 scala 实现 wordcount 15.2 原理窥探 &nbsp; 第1章 Spark 整体概述1.1 整体概念1.2 RDD 抽象1.3 计算抽象1.4 集群模式1.5 RPC 网络通信抽象1.6 启动 Standalone 集群1.7 核心组件1.8 核心组件交互流程1.9 Block 管理1.10整体应用第2章 Spark 通信架构2.1 通信组件概览2.2 Endpoint 启动过程2.3 Endpoint Send&amp;Ask 流程2.4 Endpoint Receive 流程2.5 Endpoint Inbox 处理流程2.6 Endpoint 画像第3章 脚本解析3.1 start-daemon.sh3.2 spark-class3.3 start-master.sh3.4 start-slaves.sh3.5 start-all.sh3.6 spark-submit第4章 Master 节点启动4.1 脚本概览4.2 启动流程4.3 OnStart 监听事件4.4 RpcMessage 处理 (receiveAndReply)4.5 OneWayMessage 处理 (receive)4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑第5章 Worker 节点启动5.1 脚本概览5.2 启动流程5.3 OnStart 监听事件5.4 RpcMessage 处理 (receiveAndReply)5.5 OneWayMessage 处理 (receive)第6章 Client 启动流程6.1 脚本概览6.2 SparkSubmit 启动流程6.3 Client 启动流程6.4 Client 的 OnStart 监听事件6.5 RpcMessage 处理 (receiveAndReply)6.6 OneWayMessage 处理(receive)第7章 Driver 和 DriverRunner7.1 Master 对 Driver 资源分配7.2 Worker 运行 DriverRunner7.3 DriverRunner 创建并运行 DriverWrapper第8章 SparkContext 解析8.1 SparkContext 解析8.2 SparkContext 创建过程8.3 SparkContext 简易结构与交互关系8.4 Master 对 Application 资源分配8.5 Worker 创建 Executor第9章 Job 提交和 Task 的拆分9.1 整体预览9.2 Code 转化为初始 RDDs9.3 RDD 分解为待执行任务集合（TaskSet）9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor第10章 Task 执行和回馈10.1 Task 的执行流程10.2 Task 的回馈流程10.3 Task 的迭代流程10.4 精彩图解第11章 Spark 的数据存储11.1 存储子系统概览11.2 启动过程分析11.3 通信层11.4 存储层11.4.1 Disk Store11.4.2 Memory Store11.5 数据写入过程分析11.5.1 序列化与否11.6 数据读取过程分析11.6.1 本地读取11.6.2 远程读取11.7 Partition 如何转化为 Block11.8 partition 和 block 的对应关系第12章 Spark Shuffle 过程12.1 MapReduce 的 Shuffle 过程介绍12.1.1 Spill 过程(刷写过程)12.1.2 Merge12.1.3 Copy12.1.4 Merge Sort12.2 HashShuffle 过程介绍12.3 SortShuffle 过程介绍12.4 TungstenShuffle 过程介绍12.5 MapReduce 与 Spark 过程对比第13章 Spark 内存管理13.1 堆内和堆外内存规划13.1.1 堆内内存13.1.2 堆外内存13.1.3 内存管理接口13.2 内存空间分配13.2.1 静态内存管理13.2.2 统一内存管理13.3 存储内存管理13.3.1 RDD 的持久化机制13.3.2 RDD 缓存的过程13.3.3 淘汰和落盘13.4 执行内存管理13.4.1 多任务间内存分配13.4.2 Shuffle 的内存占用第14章 部署模式解析14.1 部署模式概述14.2 standalone 框架14.2.1 Standalone 模式下任务运行过程14.2.2 总结14.3 yarn 集群模式14.4 mesos 集群模式14.5 spark 三种部署模式的区别14.6 异常场景分析14.6.1 异常分析1：Worker 异常退出14.6.2 异常分析2：Executor 异常退出14.6.3 异常分析3：Master 异常退出第15章 wordcount 程序运行原理窥探15.1 spark 之 scala 实现 wordcount15.2 原理窥探 回到顶部 第1章 Spark 整体概述 1.1 整体概念   Apache Spark 是一个开源的通用集群计算系统，它提供了 High-level 编程 API，支持 Scala、Java 和 Python 三种编程语言。Spark 内核使用 Scala 语言编写，通过基于 Scala 的函数式编程特性，在不同的计算层面进行抽象，代码设计非常优秀。 1.2 RDD 抽象   RDD（Resilient Distributed Datasets），弹性分布式数据集，它是对分布式数据集的一种内存抽象，通过受限的共享内存方式来提供容错性，同时这种内存模型使得计算比传统的数据流模型要高效。RDD 具有 5 个重要的特性，如下图所示： 上图展示了 2 个 RDD 进行 JOIN 操作，体现了 RDD 所具备的 5 个主要特性，如下所示：   • 1）一组分区   • 2）计算每一个数据分片的函数   • 3）RDD 上的一组依赖   • 4）可选，对于键值对 RDD，有一个 Partitioner（通常是 HashPartitioner）   • 5）可选，一组 Preferred location 信息（例如，HDFS 文件的 Block 所在 location 信息） 有了上述特性，能够非常好地通过 RDD 来表达分布式数据集，并作为构建 DAG 图的基础：首先抽象一个分布式计算任务的逻辑表示，最终将任务在实际的物理计算环境中进行处理执行。 &nbsp; 1.3 计算抽象 在描述 Spark 中的计算抽象，我们首先需要了解如下几个概念： 1）Application   • 用户编写的 Spark 程序，完成一个计算任务的处理。它是由一个 Driver 程序和一组运行于 Spark 集群上的 Executor 组成。 2）Job   • 用户程序中，每次调用 Action 时，逻辑上会生成一个 Job，一个 Job 包含了多个 Stage 。 3）Stage   • Stage 包括两类：ShuffleMapStage 和 ResultStage，如果用户程序中调用了需要进行 Shuffle 计算的 Operator，如 groupByKey 等，就会以 Shuffle 为边界分成 ShuffleMapStage 和 ResultStage。 4）TaskSet   • 基于 Stage 可以直接映射为 TaskSet，一个 TaskSet 封装了一次需要运算的、具有相同处理逻辑的 Task，这些 Task 可以并行计算，粗粒度的调度是以 TaskSet 为单位的。 5）Task   • Task 是在物理节点上运行的基本单位，Task 包含两类：ShuffleMapTask 和 ResultTask，分别对应于 Stage 中 ShuffleMapStage 和 ResultStage 中的一个执行基本单元。 下面，我们看一下，上面这些基本概念之间的关系，如下图所示：   上图，为了简单，每个 Job 假设都很简单，并且只需要进行一次 Shuffle 处理，所以都对应 2 个 Stage。实际应用中，一个 Job 可能包含若干个 Stage，或者是一个相对复杂的 Stage DAG。 在 Standalone 模式下，默认使用的是 FIFO 这种简单的调度策略，在进行调度的过程中，大概流程如下图所示：   从用户提交 Spark 程序，最终生成 TaskSet，而在调度时，通过 TaskSetManager 来管理一个 TaskSet（包含一组可在物理节点上执行的 Task），这里面 TaskSet 必须要按照顺序执行才能保证计算结果的正确性，因为 TaskSet 之间是有序依赖的（上溯到 ShuffleMapStage 和 ResultStage），只有一个 TaskSet 中的所有 Task 都运行完成后，才能调度下一个 TaskSet 中的 Task 去执行。 &nbsp; 1.4 集群模式   Spark 集群在设计的时候，并没有在资源管理的设计上对外封闭，而是充分考虑了未来对接一些更强大的资源管理系统，如 YARN、Mesos 等，所以 Spark 架构设计将资源管理单独抽象出一层，通过这种抽象能够构建一种适合企业当前技术栈的插件式资源管理模块，从而为不同的计算场景提供不同的资源分配与调度策略。Spark 集群模式架构，如下图所示： 上图中，Spark集群Cluster Manager目前支持如下三种模式： 1）Standalone 模式   • Standalone 模式是 Spark 内部默认实现的一种集群管理模式，这种模式是通过集群中的 Master 来统一管理资源，而与 Master 进行资源请求协商的是 Driver 内部的 StandaloneSchedulerBackend（实际上是其内部的 StandaloneAppClient 真正与 Master 通信），后面会详细说明。 2）YARN 模式   • YARN 模式下，可以将资源的管理统一交给 YARN 集群的 ResourceManager 去管理，选择这种模式，可以更大限度的适应企业内部已有的技术栈，如果企业内部已经在使用 Hadoop 技术构建大数据处理平台。 3）Mesos 模式   • 随着 Apache Mesos 的不断成熟，一些企业已经在尝试使用 Mesos 构建数据中心的操作系统（DCOS），Spark 构建在 Mesos 之上，能够支持细粒度、粗粒度的资源调度策略（Mesos 的优势），也可以更好地适应企业内部已有技术栈。   • 那么，Spark 中是怎么考虑满足这一重要的设计决策的呢？也就是说，如何能够保证 Spark 非常容易的让第三方资源管理系统轻松地接入进来。我们深入到类设计的层面看一下，如下类图所示：   • 可以看出，Task 调度直接依赖 SchedulerBackend，SchedulerBackend 与实际资源管理模块交互实现资源请求。这里面，CoarseGrainedSchedulerBackend 是 Spark 中与资源调度相关的最重要的抽象，它需要抽象出与 TaskScheduler 通信的逻辑，同时还要能够与各种不同的第三方资源管理系统无缝地交互。实际上，CoarseGrainedSchedulerBackend 内部采用了一种 ResourceOffer 的方式来处理资源请求。 &nbsp; 1.5 RPC 网络通信抽象   Spark RPC 层是基于优秀的网络通信框架 Netty 设计开发的，但是 Spark 提供了一种很好地抽象方式，将底层的通信细节屏蔽起来，而且也能够基于此来设计满足扩展性，比如，如果有其他不基于 Netty 的网络通信框架的新的RPC接入需求，可以很好地扩展而不影响上层的设计。RPC 层设计，如下图类图所示：   任何两个 Endpoint 只能通过消息进行通信，可以实现一个 RpcEndpoint 和一个 RpcEndpointRef。想要与 RpcEndpoint 通信，需要获取到该 RpcEndpoint 对应的 RpcEndpointRef 即可，而且管理 RpcEndpoint 和 RpcEndpointRef 创建及其通信的逻辑，统一在 RpcEnv 对象中管理。 &nbsp; 1.6 启动 Standalone 集群   Standalone 模式下，Spark 集群采用了简单的 Master-Slave 架构模式，Master 统一管理所有的 Worker，这种模式很常见，我们简单地看下 Spark Standalone 集群启动的基本流程，如下图所示： 可以看到，Spark 集群采用的消息的模式进行通信，也就是 EDA 架构模式，借助于 RPC 层的优雅设计，任何两个 Endpoint 想要通信，发送消息并携带数据即可。上图的流程描述如下所示：   • 1）Master 启动时首先创一个 RpcEnv 对象，负责管理所有通信逻辑。   • 2）Master 通过 RpcEnv 对象创建一个 Endpoint，Master 就是一个 Endpoint，Worker 可以与其进行通信。   • 3）Worker 启动时也是创一个 RpcEnv 对象。   • 4）Worker 通过 RpcEnv 对象创建一个 Endpoint。   • 5）Worker 通过 RpcEnv 对，建立到 Master 的连接，获取到一个 RpcEndpointRef 对象，通过该对象可以与 Master 通信。   • 6）Worker 向 Master 注册，注册内容包括主机名、端口、CPU Core 数量、内存数量。   • 7）Master 接收到 Worker 的注册，将注册信息维护在内存中的 Table 中，其中还包含了一个到 Worker 的 RpcEndpointRef 对象引用。   • 8）Master 回复 Worker 已经接收到注册，告知 Worker 已经注册成功。   • 9）此时如果有用户提交 Spark 程序，Master 需要协调启动 Driver；而 Worker 端收到成功注册响应后，开始周期性向 Master 发送心跳。 &nbsp; 1.7 核心组件   集群处理计算任务的运行时（即用户提交了 Spark 程序），最核心的顶层组件就是 Driver 和 Executor，它们内部管理很多重要的组件来协同完成计算任务，核心组件栈如下图所示：   Driver 和 Executor 都是运行时创建的组件，一旦用户程序运行结束，他们都会释放资源，等待下一个用户程序提交到集群而进行后续调度。上图，我们列出了大多数组件，其中 SparkEnv 是一个重量级组件，他们内部包含计算过程中需要的主要组件，而且，Driver 和 Executor 共同需要的组件在 SparkEnv 中也包含了很多。这里，我们不做过多详述，后面交互流程等处会说明大部分组件负责的功能。 &nbsp; 1.8 核心组件交互流程   在 Standalone 模式下，Spark 中各个组件之间交互还是比较复杂的，但是对于一个通用的分布式计算系统来说，这些都是非常重要而且比较基础的交互。首先，为了理解组件之间的主要交互流程，我们给出一些基本要点：   • 一个 Application 会启动一个 Driver   • 一个 Driver 负责跟踪管理该 Application 运行过程中所有的资源状态和任务状态   • 一个 Driver 会管理一组 Executor   • 一个 Executor 只执行属于一个 Driver 的 Task 核心组件之间的主要交互流程，如下图所示： 上图中，通过不同颜色或类型的线条，给出了如下 6 个核心的交互流程，我们会详细说明：橙色：提交用户 Spark 程序 用户提交一个 Spark 程序，主要的流程如下所示：   •1）用户 spark-submit 脚本提交一个 Spark 程序，会创建一个 ClientEndpoint 对象，该对象负责与 Master 通信交互   •2）ClientEndpoint 向 Master 发送一个 RequestSubmitDriver 消息，表示提交用户程序   •3）Master 收到 RequestSubmitDriver 消息，向 ClientEndpoint 回复 SubmitDriverResponse，表示用户程序已经完成注册   •4）ClientEndpoint 向 Master 发送 RequestDriverStatus 消息，请求 Driver 状态   •5）如果当前用户程序对应的 Driver 已经启动，则 ClientEndpoint 直接退出，完成提交用户程序紫色：启动 Driver 进程 当用户提交用户 Spark 程序后，需要启动 Driver 来处理用户程序的计算逻辑，完成计算任务，这时 Master 协调需要启动一个 Driver，具体流程如下所示：   •1）Maser 内存中维护着用户提交计算的任务 Application，每次内存结构变更都会触发调度，向 Worker 发送 LaunchDriver 请求   •2）Worker 收到 LaunchDriver 消息，会启动一个 DriverRunner 线程去执行 LaunchDriver 的任务   •3）DriverRunner 线程在 Worker 上启动一个新的 JVM 实例，该 JVM 实例内运行一个 Driver 进程，该 Driver 会创建 SparkContext 对象红色：注册 Application Dirver 启动以后，它会创建 SparkContext 对象，初始化计算过程中必需的基本组件，并向 Master 注册 Application，流程描述如下：   •1）创建 SparkEnv 对象，创建并管理一些数基本组件   •2）创建 TaskScheduler，负责 Task 调度   •3）创建 StandaloneSchedulerBackend，负责与 ClusterManager 进行资源协商   •4）创建 DriverEndpoint，其它组件可以与 Driver 进行通信   •5）在 StandaloneSchedulerBackend 内部创建一个 StandaloneAppClient，负责处理与 Master 的通信交互   •6）StandaloneAppClient 创建一个 ClientEndpoint，实际负责与 Master 通信   •7）ClientEndpoint 向 Master 发送 RegisterApplication 消息，注册 Application   •8）Master 收到 RegisterApplication 请求后，回复 ClientEndpoint 一个 RegisteredApplication 消息，表示已经注册成功蓝色：启动 Executor 进程   •1）Master 向 Worker 发送 LaunchExecutor 消息，请求启动 Executor；同时 Master 会向 Driver 发送 ExecutorAdded 消息，表示 Master 已经新增了一个 Executor（此时还未启动）   •2）Worker 收到 LaunchExecutor 消息，会启动一个 ExecutorRunner 线程去执行 LaunchExecutor 的任务   •3）Worker 向 Master 发送 ExecutorStageChanged 消息，通知 Executor 状态已发生变化   •4）Master 向 Driver 发送 ExecutorUpdated 消息，此时 Executor 已经启动粉色：启动 Task 执行   •1）StandaloneSchedulerBackend 启动一个 DriverEndpoint   •2）DriverEndpoint 启动后，会周期性地检查 Driver 维护的 Executor 的状态，如果有空闲的 Executor 便会调度任务执行   •3）DriverEndpoint 向 TaskScheduler 发送 Resource Offer 请求   •4）如果有可用资源启动 Task，则 DriverEndpoint 向 Executor 发送 LaunchTask 请求   •5）Executor 进程内部的 CoarseGrainedExecutorBackend 调用内部的 Executor 线程的 launchTask 方法启动 Task   •6）Executor 线程内部维护一个线程池，创建一个 TaskRunner 线程并提交到线程池执行绿色：Task 运行完成   •1）Executor 进程内部的 Executor 线程通知 CoarseGrainedExecutorBackend，Task 运行完成   •2）CoarseGrainedExecutorBackend 向 DriverEndpoint 发送 StatusUpdated 消息，通知 Driver 运行的 Task 状态发生变更   •3）StandaloneSchedulerBackend 调用T askScheduler 的 updateStatus 方法更新 Task 状态   •4）StandaloneSchedulerBackend 继续调用 TaskScheduler 的 resourceOffers 方法，调度其他任务运行 &nbsp; 1.9 Block 管理   Block 管理，主要是为 Spark 提供的 Broadcast 机制提供服务支撑的。Spark 中内置采用 TorrentBroadcast 实现，该 Broadcast 变量对应的数据（Task 数据）或数据集（如 RDD），默认会被切分成若干 4M 大小的 Block，Task 运行过程中读取到该 Broadcast 变量，会以 4M 为单位的 Block 为拉取数据的最小单位，最后将所有的 Block 合并成 Broadcast 变量对应的完整数据或数据集。将数据切分成 4M 大小的 Block，Task 从多个 Executor 拉取 Block，可以非常好地均衡网络传输负载，提高整个计算集群的稳定性。   通常，用户程序在编写过程中，会对某个变量进行 Broadcast，该变量称为 Broadcast 变量。在实际物理节点的 Executor 上执行 Task 时，需要读取 Broadcast 变量对应的数据集，那么此时会根据需要拉取 DAG 执行流上游已经生成的数据集。采用 Broadcast 机制，可以有效地降低数据在计算集群环境中传输的开销。具体地，如果一个用户对应的程序中的 Broadcast 变量，对应着一个数据集，它在计算过程中需要拉取对应的数据，如果在同一个物理节点上运行着多个 Task，多个 Task 都需要该数据，有了 Broadcast 机制，只需要拉取一份存储在本地物理机磁盘即可，供多个 Task 计算共享。   另外，用户程序在进行调度过程中，会根据调度策略将 Task 计算逻辑数据（代码）移动到对应的 Worker 节点上，最优情况是对本地数据进行处理，那么代码（序列化格式）也需要在网络上传输，也是通过 Broadcast 机制进行传输，不过这种方式是首先将代码序列化到 Driver 所在 Worker 节点，后续如果 Task 在其他 Worker 中执行，需要读取对应代码的 Broadcast 变量，首先就是从 Driver 上拉取代码数据，接着其他晚一些被调度的 Task 可能直接从其他 Worker 上的 Executor 中拉取代码数据。   我们通过以 Broadcast 变量 taskBinary 为例，说明 Block 是如何管理的，如下图所示：   上图中，Driver 负责管理所有的 Broadcast 变量对应的数据所在的 Executor，即一个 Executor 维护一个 Block 列表。在 Executor 中运行一个 Task 时，执行到对应的 Broadcast 变量 taskBinary，如果本地没有对应的数据，则会向 Driver 请求获取 Broadcast 变量对应的数据，包括一个或多个 Block 所在的 Executor 列表，然后该 Executor 根据 Driver 返回的 Executor 列表，直接通过底层的 BlockTransferService 组件向对应 Executor 请求拉取 Block。Executor 拉取到的 Block 会缓存到本地，同时向 Driver 报告该 Executor 上存在的 Block 信息，以供其他 Executor 执行 Task 时获取 Broadcast 变量对应的数据。 &nbsp; 1.10整体应用   用户通过 spark-submit 提交或者运行 spark-shell REPL，集群创建 Driver，Driver 加载 Application，最后 Application 根据用户代码转化为 RDD，RDD 分解为 Tasks，Executor 执行 Task 等系列知识，整体交互蓝图如下： 回到顶部 第2章 Spark 通信架构   Spark作为分布式计算框架，多个节点的设计与相互通信模式是其重要的组成部分。Spark 一开始使用 Akka 作为内部通信部件。在 Spark 1.3 年代，为了解决大块数据（如 Shuffle）的传输问题，Spark 引入了 Netty 通信框架。到了 Spark 1.6，Spark 可以配置使用 Akka 或者 Netty 了，这意味着 Netty 可以完全替代 Akka了。再到 Spark 2，Spark 已经完全抛弃 Akka了，全部使用 Netty 了。   为什么呢？官方的解释是：   •1）很多 Spark 用户也使用 Akka，但是由于 Akka 不同版本之间无法互相通信，这就要求用户必须使用跟 Spark 完全一样的 Akka 版本，导致用户无法升级 Akka。   •2）Spark 的 Akka 配置是针对 Spark 自身来调优的，可能跟用户自己代码中的 Akka 配置冲突。   •3）Spark 用的 Akka 特性很少，这部分特性很容易自己实现。同时，这部分代码量相比 Akka 来说少很多，debug 比较容易。如果遇到什么 bug，也可以自己马上 fix，不需要等 Akka 上游发布新版本。而且，Spark 升级 Akka 本身又因为第一点会强制要求用户升级他们使用的 Akka，对于某些用户来说是不现实的。 SPARK 的通信架构 - Actor 比较，如下图所示： 2.1 通信组件概览 对源码分析，对于设计思路理解如下：   •1）RpcEndpoint：RPC 端点，Spark 针对于每个节点（Client/Master/Worker）都称之一个 Rpc 端点且都实现 RpcEndpoint 接口，内部根据不同端点的需求，设计不同的消息和不同的业务处理，如果需要发送（询问）则调用 Dispatcher。   •2）RpcEnv：RPC 上下文环境，每个 Rpc 端点运行时依赖的上下文环境称之为 RpcEnv。   •3）Dispatcher：消息分发器，针对于 RPC 端点需要发送消息或者从远程 RPC 接收到的消息，分发至对应的指令收件箱/发件箱。如果指令接收方是自己存入收件箱，如果指令接收方为非自身端点，则放入发件箱。   •4）Inbox：指令消息收件箱，一个本地端点对应一个收件箱，Dispatcher 在每次向 Inbox 存入消息时，都将对应 EndpointData 加入内部待 Receiver Queue中，另外 Dispatcher 创建时会启动一个单独线程进行轮询 Receiver Queue，进行收件箱消息消费。   •5）OutBox：指令消息发件箱，一个远程端点对应一个发件箱，当消息放入 Outbox 后，紧接着将消息通过 TransportClient 发送出去。消息放入发件箱以及发送过程是在同一个线程中进行，这样做的主要原因是远程消息分为 RpcOutboxMessage，OneWayOutboxMessage 两种消息，而针对于需要应答的消息直接发送且需要得到结果进行处理   •6）TransportClient：Netty 通信客户端，根据 OutBox 消息的 receiver 信息，请求对应远程 TransportServer。   •7）TransportServer：Netty 通信服务端，一个 RPC 端点一个 TransportServer，接受远程消息后调用 Dispatcher 分发消息至对应收发件箱。注意：   TransportClient 与 TransportServer 通信虚线表示两个 RpcEnv 之间的通信，图示没有单独表达式。   一个 Outbox 一个 TransportClient，图示没有单独表达式。   一个 RpcEnv 中存在两个 RpcEndpoint，一个代表本身启动的 RPC 端点，另外一个为 RpcEndpointVerifier。 Spark的通信架构 – 高层视图 Spark 的通信架构 – 类图 2.2 Endpoint 启动过程 启动的流程如下： Endpoint 启动后，默认会向 Inbox 中添加 OnStart 消息，不同的端点（Master/Worker/Client）消费 OnStart 指令时，进行相关端点的启动额外处理。 Endpoint 启动时，会默认启动 TransportServer，且启动结束后会进行一次同步测试 rpc 可用性（askSync-BoundPortsRequest）。 Dispatcher 作为一个分发器，内部存放了 Inbox，Outbox 的等相关句柄和存放了相关处理状态数据，结构大致如下： 2.3 Endpoint Send&amp;Ask 流程 Endpoint 的消息发送与请求流程，如下： Endpoint 根据业务需要存入两个维度的消息组合：send/ask 某个消息，receiver 是自身与非自身   •1）OneWayMessage：send + 自身，直接存入收件箱   •2）OneWayOutboxMessage：send + 非自身，存入发件箱并直接发送   •3）RpcMessage：ask + 自身，直接存入收件箱，另外还需要存入 LocalNettyRpcCallContext，需要回调后再返回   •4）RpcOutboxMessage：ask + 非自身，存入发件箱并直接发送，需要回调后再返回 &nbsp; 2.4 Endpoint Receive 流程 Endpoint 的消息的接收，流程如下： 上图 ServerBootstrap 为 Netty 启动服务，SocketChanel为Netty 数据通道。 上述包含 TransportSever 启动与消息接收两个流程。 &nbsp; 2.5 Endpoint Inbox 处理流程 Spark 在 Endpoint 的设计上核心设计即为 Inbox 与 Outbox，其中 Inbox 核心要点为：   •1）内部的处理流程拆分为多个消息指令（InboxMessage）存放入 Inbox。   •2）当 Dispatcher 启动最后，会启动一个名为【dispatcher-event-loop】的线程扫描 Inbox 待处理 InboxMessage，并调用 Endpoint 根据 InboxMessage 类型做相应处理   •3）当 Dispatcher 启动最后，默认会向 Inbox 存入 OnStart 类型的 InboxMessage，Endpoint 在根据 OnStart 指令做相关的额外启动工作，三端启动后所有的工作都是对 OnStart 指令处理衍生出来的，因此可以说 OnStart 指令是相互通信的源头。 消息指令类型大致如下三类：   •1）OnStart/OnStop   •2）RpcMessage/OneWayMessage   •3）RemoteProcessDisconnected/RemoteProcessConnected/RemoteProcessConnectionError 2.6 Endpoint 画像 回到顶部 第3章 脚本解析 在看源码之前，我们一般会看相关脚本了解其初始化信息以及 Bootstrap 类，Spark 也不例外，而 Spark 中相关的脚本如下： %SPARK_HOME%/sbin/start-master.sh %SPARK_HOME%/sbin/start-slaves.sh %SPARK_HOME%/sbin/start-all.sh %SPARK_HOME%/bin/spark-submit 启动脚本中对于公共处理部分进行抽取为独立的脚本，如下： 脚本 说明 sbin/spark-config.sh 初始化环境变量 SPARK_CONF_DIR, PYTHONPATH bin/load-spark-env.sh 初始化环境变量 SPARK_SCALA_VERSION，调用 %SPARK_HOME% conf/spark-env.sh 加载用户自定义环境变量 3.1 start-daemon.sh 主要完成进程相关基本信息初始化，然后调用 bin/spark-class 进行守护进程启动，该脚本是创建端点的通用脚本，三端各自脚本都会调用 spark-daemon.sh 脚本启动各自进程 详解如下： 1）初始化&nbsp;SPRK_HOME、SPARK_CONF_DIR、SPARK_IDENT_STRING、SPARK_LOG_DIR&nbsp;环境变量&nbsp;(如果不存在) 2）初始化日志并测试日志文件夹读写权限，初始化&nbsp;PID&nbsp;目录并校验&nbsp;PID&nbsp;信息 3）调用&nbsp;/bin/spark-class&nbsp;脚本，/bin/spark-class&nbsp;见下面 3.2 spark-class Master 调用举例： bin/spark-class&nbsp;\ --class&nbsp;org.apache.spark.deploy.master.Master&nbsp;\ --host&nbsp;$SPARK_MASTER_HOST&nbsp;\ --port&nbsp;$SPARK_MASTER_PORT&nbsp;\ --webui-port&nbsp;$SPARK_MASTER_WEBUI_PORT&nbsp;$ORIGINAL_ARGS 1）初始化&nbsp;RUNNER(java)、SPARK_JARS_DIR&nbsp;(%SPARK_HOME%/jars)、LAUNCH_CLASSPATH&nbsp;信息 2）调用&nbsp;(&quot;$RUNNER&quot;&nbsp;-Xmx128m&nbsp;-cp&nbsp;&quot;$LAUNCH_CLASSPATH&quot;&nbsp;org.apache.spark.launcher.Main&nbsp;&quot;$@&quot;)&nbsp;获取最终执行的&nbsp;shell&nbsp;语句 3）执行最终的&nbsp;shell&nbsp;语句，示例如下： /opt/module/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g&nbsp;\ -XX:MaxPermSize=256m&nbsp;\ org.apache.spark.deploy.master.Master&nbsp;\ --host&nbsp;hadoop102&nbsp;\ --port&nbsp;7077&nbsp;\ --webui-port&nbsp;8080 如果是&nbsp;Client，那么可能为&nbsp;r，或者&nbsp;python&nbsp;脚本。 3.3 start-master.sh 启动 Master 的脚本，流程如下： 详解如下： 1）用户执行&nbsp;start-master.sh&nbsp;脚本，初始化环境变量&nbsp;SPARK_HOME&nbsp;(如果&nbsp;PATH&nbsp;不存在&nbsp;SPARK_HOME，初始化脚本的上级目录为&nbsp;SPARK_HOME)，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh 2）如果环境变量&nbsp;SPARK_MASTER_HOST、SPARK_MASTER_PORT、SPARK_MASTER_WEBUI_PORT&nbsp;不存在，进行初始化&nbsp;7077，hostname&nbsp;-f，8080 3）调用&nbsp;spark-daemon.sh&nbsp;脚本启动&nbsp;master&nbsp;进程，如下： spark-daemon.sh&nbsp;start&nbsp;org.apache.spark.deploy.master.Master&nbsp;1&nbsp;\ --host&nbsp;$SPARK_MASTER_HOST&nbsp;\ --port&nbsp;$SPARK_MASTER_PORT&nbsp;\ --webui-port&nbsp;$SPARK_MASTER_WEBUI_PORT&nbsp;$ORIGINAL_ARGS） 3.4 start-slaves.sh 启动 Worker 的脚本，流程如下： 详解如下： 1）用户执行&nbsp;start-slaves.sh&nbsp;脚本，初始化环境变量&nbsp;SPARK_HOME，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh，初始化&nbsp;Master&nbsp;host/port&nbsp;信息 2）调用&nbsp;slaves.sh&nbsp;脚本，读取&nbsp;conf/slaves&nbsp;文件并遍历，通过&nbsp;ssh&nbsp;连接到对应&nbsp;slave&nbsp;节点，启动&nbsp;${SPARK_HOME}/sbin/start-slave.sh&nbsp;spark://$SPARK_MASTER_HOST:$SPARK_MASTER_PORT 3）start-slave.sh&nbsp;在各个节点中，初始化环境变量&nbsp;SPARK_HOME，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh，根据&nbsp;$SPARK_WORKER_INSTANCES&nbsp;计算&nbsp;WEBUI_PORT&nbsp;端口&nbsp;(worker&nbsp;端口号依次递增)&nbsp;并启动&nbsp;Worker&nbsp;进程，如下： ${SPARK_HOME}/sbin/spark-daemon.sh&nbsp;\ start&nbsp;org.apache.spark.deploy.worker.Worker&nbsp;$WORKER_NUM&nbsp;\ --webui-port&nbsp;&quot;$WEBUI_PORT&quot;&nbsp;$PORT_FLAG&nbsp;$PORT_NUM&nbsp;$MASTER&nbsp;&quot;$@&quot; 3.5 start-all.sh 属于快捷脚本，内部调用 start-master.sh 与 start-slaves.sh 脚本，并无额外工作。 3.6 spark-submit 任务提交的基本脚本，流程如下： 详解如下： 1）直接调用&nbsp;spark-class&nbsp;脚本进行进程创建，示例如下： ./spark-submit&nbsp;\ --class&nbsp;org.apache.spark.examples.SparkPi&nbsp;\ --master&nbsp;spark://hadoop102:7077&nbsp;\ ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 2）如果是&nbsp;java/scala&nbsp;任务，那么最终调用&nbsp;SparkSubmit.scala&nbsp;进行任务处理，示例如下： /opt/module/jdk1.8.0_144&nbsp;-cp&nbsp;\ /opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g&nbsp;-XX:MaxPermSize=256m&nbsp;\ org.apache.spark.deploy.SparkSubmit&nbsp;\ --master&nbsp;spark://hadoop102:7077&nbsp;\ --class&nbsp;org.apache.spark.examples.SparkPi&nbsp;\ ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 回到顶部 第4章 Master 节点启动 Master 作为 Endpoint 的具体实例，下面我们介绍一下 Master 启动以及 OnStart 指令后的相关工作。 4.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g&nbsp;\ -XX:MaxPermSize=256m&nbsp;\ org.apache.spark.deploy.master.Master&nbsp;\ --host&nbsp;hadoop102&nbsp;\ --port&nbsp;7077&nbsp;\ 4.2 启动流程 Master 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）MasterArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Master&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--ip&nbsp;-i&nbsp;--host&nbsp;-h&nbsp;--port&nbsp;-p&nbsp;--webui-port&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;b)将&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 3）NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 4）BoundPortsResponse&nbsp;返回&nbsp;rpcEndpointPort、webUIPort、restPort&nbsp;真实端口。 5）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 4.3 OnStart 监听事件 Master 的启动完成后异步执行工作如下： 详解如下： 1）【dispatcher-event-loop】线程扫描到&nbsp;OnStart&nbsp;指令后会启动相关&nbsp;MasterWebUI&nbsp;(默认端口&nbsp;8080），根据配置选择安装&nbsp;ResetServer&nbsp;(默认端口&nbsp;6066)。 2）另外新起【master-forward-message-thread】线程定期检查&nbsp;Worker&nbsp;心跳是否超时。 3）如果&nbsp;Worker&nbsp;心跳检测超时，那么对&nbsp;Worker&nbsp;下的发布的所有任务所属&nbsp;Driver&nbsp;进行&nbsp;ExecutorUpdated&nbsp;发送，同时自己再重新&nbsp;LaunchDriver。 4.4 RpcMessage 处理 (receiveAndReply) 4.5 OneWayMessage 处理 (receive) 4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑 这部分对整体 Master 理解作用不是很大且理解比较抽象，可以先读后续内容，回头再考虑看这部分内容，或者不读。 回到顶部 第5章 Worker 节点启动 Worker 作为 Endpoint 的具体实例，下面我们介绍一下 Worker 启动以及 OnStart 指令后的额外工作。 5.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g&nbsp;\ -XX:MaxPermSize=256m&nbsp;\ org.apache.spark.deploy.worker.Worker&nbsp;\ --webui-port&nbsp;8081 spark://hadoop102:7077 5.2 启动流程 Worker 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）WorkerArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Master&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--ip&nbsp;-i&nbsp;--host&nbsp;-h&nbsp;--port&nbsp;-p&nbsp;--cores&nbsp;-c&nbsp;--memory&nbsp;-m&nbsp;--work-dir&nbsp;--webui-port&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;--properties-file&nbsp;(没有配置默认为conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;在没有配置情况下，cores&nbsp;默认为服务器&nbsp;CPU&nbsp;核数。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;在没有配置情况下，memory&nbsp;默认为服务器内存减&nbsp;1G，如果低于&nbsp;1G&nbsp;取&nbsp;1G。 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;webUiPort&nbsp;默认为&nbsp;8081。 3）NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 4）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 5.3 OnStart 监听事件 Worker 的启动完成后异步执行工作如下： 详解如下： 1）【dispatcher-event-loop】线程扫描到&nbsp;OnStart&nbsp;指令后会启动相关&nbsp;WorkerWebUI&nbsp;(默认端口&nbsp;8081)。 2）Worker&nbsp;向&nbsp;Master&nbsp;发起一次&nbsp;RegisterWorker&nbsp;指令。 3）另起【master-forward-message-thread】线程定期执行&nbsp;ReregisterWithMaster&nbsp;任务，如果注册成功&nbsp;(RegisteredWorker)&nbsp;则跳过，否则再次向&nbsp;Master&nbsp;发起&nbsp;RegisterWorker&nbsp;指令，直到超过最大次数报错&nbsp;(默认16次)。 4）Master&nbsp;如果可以注册，则维护对应的&nbsp;WorkerInfo&nbsp;对象并持久化，完成后向&nbsp;Worker&nbsp;发起一条&nbsp;RegisteredWorker&nbsp;指令，如果&nbsp;Master&nbsp;为&nbsp;standby&nbsp;状态，则向&nbsp;Worker&nbsp;发起一条&nbsp;MasterInStandby&nbsp;指令。 5）Worker&nbsp;接受&nbsp;RegisteredWorker&nbsp;后，提交【master-forward-message-thread】线程定期执行&nbsp;SendHeartbeat&nbsp;任务，完成后向&nbsp;Worker&nbsp;发起一条&nbsp;WorkerLatestState&nbsp;指令。 6）Worker&nbsp;发心跳检测，会触发更新&nbsp;Master&nbsp;对应&nbsp;WorkerInfo&nbsp;对象，如果&nbsp;Master&nbsp;检测到异常，则发起&nbsp;ReconnectWorker&nbsp;指令至&nbsp;Worker，Worker&nbsp;则再次执行&nbsp;ReregisterWithMaster&nbsp;工作。 5.4 RpcMessage 处理 (receiveAndReply) 5.5 OneWayMessage 处理 (receive) 回到顶部 第6章 Client 启动流程 Client 作为 Endpoint 的具体实例，下面我们介绍一下 Client 启动以及 OnStart 指令后的额外工作。 6.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g -XX:MaxPermSize=256m org.apache.spark.deploy.SparkSubmit --master&nbsp;spark://hadoop102:7077 --class&nbsp;org.apache.spark.examples.SparkPi ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 6.2 SparkSubmit 启动流程 SparkSubmit 的启动流程如下： 详解如下： 1）SparkSubmitArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Client&nbsp;启动的参数 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--name&nbsp;--master&nbsp;--class&nbsp;--deploy-mode &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--num-executors&nbsp;--executor-cores&nbsp;--total-executor-cores&nbsp;--executor-memory &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--driver-memory&nbsp;--driver-cores&nbsp;--driver-class-path&nbsp;--driver-java-options&nbsp;--driver-library-path &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--kill&nbsp;--status&nbsp;--supervise&nbsp;--queue &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--files&nbsp;--py-files &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--archives&nbsp;--jars&nbsp;--packages&nbsp;--exclude-packages&nbsp;--repositories &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--conf&nbsp;(解析存入&nbsp;Map：sparkProperties&nbsp;中) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--proxy-user&nbsp;--principal&nbsp;--keytab&nbsp;--help&nbsp;--verbose&nbsp;--version&nbsp;--usage-error &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;合并&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;文件配置项&nbsp;(不在&nbsp;--conf&nbsp;中的配置&nbsp;)&nbsp;至&nbsp;sparkProperties &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;删除&nbsp;sparkProperties&nbsp;中不以&nbsp;spark.&nbsp;开头的配置项目 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;启动参数为空的配置项从&nbsp;sparkProperties&nbsp;中合并 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;根据&nbsp;action&nbsp;(SUBMIT、KILL、REQUEST_STATUS)&nbsp;校验各自必需参数是否有值 2）Case&nbsp;Submit： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;获取childMainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;clent(默认)：用户任务启动类&nbsp;mainClass&nbsp;(--class) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;useRest&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.rest.RestSubmissionClient &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;!useRest&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.Client &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;yarn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.yarn.Client &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;mesos:*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.rest.RestSubmissionClient &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;获取&nbsp;childArgs&nbsp;(子运行时对应命令行组装参数) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;useRest&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;包含&nbsp;primaryResource&nbsp;与&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;!useRest&nbsp;&nbsp;&nbsp;&nbsp;包含&nbsp;--supervise&nbsp;--memory&nbsp;--cores&nbsp;&nbsp;launch&nbsp;childArg,&nbsp;primaryResource,&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;yarn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--class&nbsp;--arg&nbsp;--jar/--primary-py-file/--primary-r-file &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;mesos:*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;primaryResource &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;获取&nbsp;childClasspath &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;clent&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;读取&nbsp;--jars&nbsp;配置，与&nbsp;primaryResource&nbsp;信息&nbsp;(../examples/jars/spark-examples_2.11-2.1.0.jar) &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;获取&nbsp;sysProps &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将&nbsp;sparkPropertie&nbsp;中的所有配置封装成新的&nbsp;sysProps&nbsp;对象，另外还增加了一下额外的配置项目 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;将&nbsp;childClasspath&nbsp;通过当前的类加载器加载中 &nbsp;&nbsp;&nbsp;&nbsp;f)&nbsp;将&nbsp;sysProps&nbsp;设置到当前&nbsp;jvm&nbsp;环境中 &nbsp;&nbsp;&nbsp;&nbsp;g)&nbsp;最终反射执行&nbsp;childMainClass，传参为&nbsp;childArgs 6.3 Client 启动流程 Client 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）ClientArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Client&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--cores&nbsp;-c&nbsp;--memory&nbsp;-m&nbsp;--supervise&nbsp;-s&nbsp;--verbose&nbsp;-v &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;launch&nbsp;jarUrl&nbsp;master&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kill&nbsp;master&nbsp;driverId &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;在没有配置情况下，cores&nbsp;默认为&nbsp;1&nbsp;核。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;在没有配置情况下，memory&nbsp;默认为&nbsp;1G。 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 3）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 6.4 Client 的 OnStart 监听事件 Client 的启动完成后异步执行工作如下：　 详解如下： 1）如果是发布任务(case&nbsp;launch)，Client&nbsp;创建一个&nbsp;DriverDescription，并向&nbsp;Master&nbsp;发起&nbsp;RequestSubmitDriver&nbsp;请求。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;Command&nbsp;中的&nbsp;mainClass&nbsp;为：&nbsp;org.apache.spark.deploy.worker.DriverWrapper &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;Command&nbsp;中的&nbsp;arguments&nbsp;为：&nbsp;Seq(&quot;{{WORKER_URL}}&quot;,&nbsp;&quot;{{USER_JAR}}&quot;,&nbsp;driverArgs.mainClass) 2）Master&nbsp;接受&nbsp;RequestSubmitDriver&nbsp;请求后，将&nbsp;DriverDescription&nbsp;封装为&nbsp;一个DriverInfo。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;startTime&nbsp;与&nbsp;submitDate&nbsp;都为当前时间 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;driverId&nbsp;格式为：driver-yyyyMMddHHmmss-nextId，nextId&nbsp;是全局唯一的 3）Master&nbsp;持久化&nbsp;DriverInfo，并加入待调度列表中&nbsp;(waitingDrivers)，触发公共资源调度逻辑。 4）Master&nbsp;公共资源调度结束后，返回&nbsp;SubmitDriverResponse给Client。 6.5 RpcMessage 处理 (receiveAndReply) 无。 6.6 OneWayMessage 处理(receive) 回到顶部 第7章 Driver 和 DriverRunner Client 向 Master 发起 RequestSubmitDriver 请求，Master 将 DriverInfo 添加待调度列表中 (waitingDrivers)，下面针对于 Driver 进一步梳理。 7.1 Master 对 Driver 资源分配 大致流程如下： 详解如下： waitingDrivers&nbsp;与&nbsp;aliveWorkers&nbsp;进行资源匹配： 1）在&nbsp;waitingDrivers&nbsp;循环内，轮询所有&nbsp;aliveWorker。 2）如果&nbsp;aliveWorker&nbsp;满足当前&nbsp;waitingDriver&nbsp;资源要求，给&nbsp;Worker&nbsp;发送&nbsp;LaunchDriver&nbsp;指令并将&nbsp;waitingDriver&nbsp;移除&nbsp;waitingDrivers，则进行下一次&nbsp;waitingDriver&nbsp;的轮询工作。 3）如果轮询完所有&nbsp;aliveWorker&nbsp;都不满足&nbsp;waitingDriver&nbsp;资源要求，则进行下一次&nbsp;waitingDriver&nbsp;的轮询工作。 4）所有发起的轮询开始点都上次轮询结束点的下一个点位开始。 7.2 Worker 运行 DriverRunner Driver 的启动，流程如下： 详解如下： 1）当&nbsp;Worker&nbsp;遇到&nbsp;LaunchDriver&nbsp;指令时，创建并启动一个&nbsp;DriverRunner。 2）DriverRunner&nbsp;启动一个线程&nbsp;DriverRunner&nbsp;for&nbsp;[driverId]&nbsp;处理&nbsp;Driver&nbsp;启动工作。 3）DriverRunner&nbsp;for&nbsp;[driverId]： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;添加&nbsp;JVM&nbsp;钩子，针对于每个&nbsp;diriverId&nbsp;创建一个临时目录。 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;DriverDesc.jarUrl&nbsp;通过&nbsp;Netty&nbsp;从&nbsp;Driver&nbsp;机器远程拷贝过来。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;根据&nbsp;DriverDesc.command&nbsp;模板构建本地执行的&nbsp;command&nbsp;命令，并启动该&nbsp;command&nbsp;对应的&nbsp;Process&nbsp;进程。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;将&nbsp;Process&nbsp;的输出流输出到文件&nbsp;stdout/stderror，如果&nbsp;Process&nbsp;启动失败，进行&nbsp;1-5&nbsp;的秒的反复启动工作，直到启动成功，在释放&nbsp;Worker&nbsp;节点的&nbsp;DriverRunner&nbsp;的资源。 7.3 DriverRunner 创建并运行 DriverWrapper DriverWrapper 的运行，流程如下： 详解如下： 1）DriverWapper&nbsp;创建了一个&nbsp;RpcEndpoint&nbsp;与&nbsp;RpcEnv。 2）RpcEndpoint&nbsp;为&nbsp;WorkerWatcher，主要目的为监控&nbsp;Worker&nbsp;节点是否正常，如果出现异常就直接退出。 3）然后当前的&nbsp;ClassLoader&nbsp;加载&nbsp;userJar，同时执行&nbsp;userMainClass。 4）执行用户的&nbsp;main&nbsp;方法后关闭&nbsp;workerWatcher。 回到顶部 第8章 SparkContext 解析 8.1 SparkContext 解析 SparkContext 是用户通往 Spark 集群的唯一入口，任何需要使用 Spark 的地方都需要先创建 SparkContext，那么 SparkContext 做了什么？ 首先 SparkContext 是在 Driver 程序里面启动的，可以看做 Driver 程序和 Spark 集群的一个连接，SparkContext 在初始化的时候，创建了很多对象，如下图所示： 上图列出了 SparkContext 在初始化创建的时候的一些主要组件的构建。 8.2 SparkContext 创建过程 详解如下： SparkContext&nbsp;在新建时： 1）内部创建一个&nbsp;SparkEnv，SparkEnv&nbsp;内部创建一个&nbsp;RpcEnv。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;RpcEnv&nbsp;内部创建并注册一个&nbsp;MapOutputTrackerMasterEndpoint(该&nbsp;Endpoint&nbsp;暂不介绍) 2）接着创建&nbsp;DAGScheduler、TaskSchedulerImpl、SchedulerBackend。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;TaskSchedulerImpl&nbsp;创建时创建&nbsp;SchedulableBuilder，SchedulableBuilder&nbsp;根据类型分为&nbsp;FIFOSchedulableBuilder、FairSchedulableBuilder&nbsp;两类 3）最后启动&nbsp;TaskSchedulerImpl，TaskSchedulerImpl&nbsp;启动&nbsp;SchedulerBackend。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;SchedulerBackend&nbsp;启动时创建&nbsp;ApplicationDescription、DriverEndpoint、StandloneAppClient &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;StandloneAppClient&nbsp;内部包括一个&nbsp;ClientEndpoint 8.3 SparkContext 简易结构与交互关系 详解如下： 1）SparkContext：是用户&nbsp;Spark&nbsp;执行任务的上下文，用户程序内部使用&nbsp;Spark&nbsp;提供的&nbsp;Api&nbsp;直接或间接创建一个&nbsp;SparkContext。 2）SparkEnv：用户执行的环境信息，包括通信相关的端点。 3）RpcEnv：SparkContext&nbsp;中远程通信环境。 4）ApplicationDescription：应用程序描述信息，主要包含&nbsp;appName、maxCores、memoryPerExecutorMB、coresPerExecutor、Command&nbsp;(CoarseGrainedExecutorBackend)、appUiUrl&nbsp;等。 5）ClientEndpoint：客户端端点，启动后向&nbsp;Master&nbsp;发起注册&nbsp;RegisterApplication&nbsp;请求。 6）Master：接受&nbsp;RegisterApplication&nbsp;请求后，进行&nbsp;Worker&nbsp;资源分配，并向分配的资源发起&nbsp;LaunchExecutor&nbsp;指令。 7）Worker：接受&nbsp;LaunchExecutor&nbsp;指令后，运行&nbsp;ExecutorRunner。 8）ExecutorRunner：运行&nbsp;applicationDescription&nbsp;的&nbsp;Command&nbsp;命令，最终&nbsp;Executor，同时向&nbsp;DriverEndpoint&nbsp;注册&nbsp;Executor&nbsp;信息。 8.4 Master 对 Application 资源分配 当 Master 接受 Driver 的 RegisterApplication 请求后，放入 waitingDrivers 队列中，在同一调度中进行资源分配，分配过程如下： 详解如下： waitingApps&nbsp;与&nbsp;aliveWorkers&nbsp;进行资源匹配： 1）如果&nbsp;waitingApp&nbsp;配置了&nbsp;app.desc.coresPerExecutor： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;轮询所有有效可分配的&nbsp;worker，每次分配一个&nbsp;executor，executor&nbsp;的核数为&nbsp;minCoresPerExecutor(app.desc.coresPerExecutor)，直到不存在有效可分配资源或者&nbsp;app&nbsp;依赖的资源已全部被分配。 2）如果&nbsp;waitingApp&nbsp;没有配置&nbsp;app.desc.coresPerExecutor： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;轮询所有有效可分配的&nbsp;worker，每个&nbsp;worker&nbsp;分配一个&nbsp;executor，executor&nbsp;的核数为从&nbsp;minCoresPerExecutor(为固定值1)&nbsp;开始递增，直到不存在有效可分配资源或者&nbsp;app&nbsp;依赖的资源已全部被分配。 3）其中有效可分配&nbsp;worker&nbsp;定义为满足一次资源分配的&nbsp;worker： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;cores&nbsp;满足：usableWorkers(pos).coresFree&nbsp;-&nbsp;assignedCores(pos)&nbsp;&gt;=&nbsp;minCoresPerExecutor &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;memory&nbsp;满足(如果是新的&nbsp;Executor)：usableWorkers(pos).memoryFree&nbsp;-&nbsp;assignedExecutors(pos)&nbsp;*&nbsp;memoryPerExecutor&nbsp;&gt;=&nbsp;memoryPerExecutor 注意：Master&nbsp;针对于&nbsp;applicationInfo&nbsp;进行资源分配时，只有存在有效可用的资源就直接分配，而分配剩余的&nbsp;app.coresLeft&nbsp;则等下一次再进行分配。 8.5 Worker 创建 Executor （图解：橙色组件是 Endpoint 组件） 详解如下： Worker&nbsp;启动&nbsp;Executor 1）在&nbsp;Worker&nbsp;的&nbsp;tempDir&nbsp;下面创建&nbsp;application&nbsp;以及&nbsp;executor&nbsp;的目录，并&nbsp;chmod&nbsp;700&nbsp;操作权限。 2）创建并启动&nbsp;ExecutorRunner&nbsp;进行&nbsp;Executor&nbsp;的创建。 3）向&nbsp;Master&nbsp;发送&nbsp;Executor&nbsp;的状态情况。 ExecutorRnner 1）新线程【ExecutorRunner&nbsp;for&nbsp;[executorId]】读取&nbsp;ApplicationDescription&nbsp;将其中&nbsp;Command&nbsp;转化为本地的&nbsp;Command&nbsp;命令。 2）调用&nbsp;Command&nbsp;并将日志输出至&nbsp;executor&nbsp;目录下的&nbsp;stdout&nbsp;和&nbsp;stderr&nbsp;日志文件中，Command&nbsp;对应的&nbsp;java&nbsp;类为&nbsp;CoarseGrainedExecutorBackend。 CoarseGrainedExecutorBackend 1）创建一个&nbsp;SparkEnv，创建&nbsp;ExecutorEndpoint(CoarseGrainedExecutorBackend)以及&nbsp;WorkerWatcher。 2）ExecutorEndpoint&nbsp;创建并启动后，向&nbsp;DriverEndpoint&nbsp;发送&nbsp;RegisterExecutor&nbsp;请求并等待返回。 3）DriverEndpoint&nbsp;处理&nbsp;RegisterExecutor&nbsp;请求，返回&nbsp;ExecutorEndpointRegister&nbsp;的结果。 4）如果注册成功，ExecutorEndpoint&nbsp;内部再创建&nbsp;Executor&nbsp;的处理对象。 至此，Spark&nbsp;运行任务的容器框架就搭建完成。 回到顶部 第9章 Job 提交和 Task 的拆分 在前面的章节 Client 的加载中，Spark 的 DriverRunner 已开始执行用户任务类（比如：org.apache.spark.examples.SparkPi），下面我们开始针对于用户任务类（或者任务代码）进行分析： 9.1 整体预览 详解如下： 1）Code：指的用户编写的代码 2）RDD：弹性分布式数据集，用户编码根据&nbsp;SparkContext&nbsp;与&nbsp;RDD&nbsp;的&nbsp;api&nbsp;能够很好的将&nbsp;Code&nbsp;转化为&nbsp;RDD&nbsp;数据结构(下文将做转化细节介绍)。 3）DAGScheduler：有向无环图调度器，将&nbsp;RDD&nbsp;封装为&nbsp;JobSubmitted&nbsp;对象存入&nbsp;EventLoop&nbsp;(实现类DAGSchedulerEventProcessLoop)&nbsp;队列中。 4）EventLoop：&nbsp;定时扫描未处理&nbsp;JobSubmitted&nbsp;对象，将&nbsp;JobSubmitted&nbsp;对象提交给&nbsp;DAGScheduler。 5）DAGScheduler：针对于&nbsp;JobSubmitted&nbsp;进行处理，最终将&nbsp;RDD&nbsp;转化为执行&nbsp;TaskSet，并将&nbsp;TaskSet&nbsp;提交至&nbsp;TaskScheduler。 6）TaskScheduler：&nbsp;根据&nbsp;TaskSet&nbsp;创建&nbsp;TaskSetManager&nbsp;对象存入&nbsp;SchedulableBuilder&nbsp;的数据池(Pool)中，并调用&nbsp;DriverEndpoint&nbsp;唤起消费(ReviveOffers)操作。 7）DriverEndpoint：接受&nbsp;ReviveOffers&nbsp;指令后将&nbsp;TaskSet&nbsp;中的&nbsp;Tasks&nbsp;根据相关规则均匀分配给Executor。 8）Executor：启动一个&nbsp;TaskRunner&nbsp;执行一个&nbsp;Task。 9.2 Code 转化为初始 RDDs 我们的用户代码通过调用 Spark 的 Api（比如：SparkSession.builder.appName(&quot;Spark Pi&quot;).getOrCreate()），该 Api 会创建 Spark 的上下文（SparkContext），当我们调用 transform 类方法（如：parallelize(),map()）都会创建（或者装饰已有的）Spark 数据结构（RDD），如果是 action 类操作（如：reduce()），那么将最后封装的 RDD 作为一次 Job 提交，存入待调度队列中（DAGSchedulerEventProcessLoop ）待后续异步处理。 如果多次调用 action 类操作，那么封装的多个 RDD 作为多个 Job 提交。 流程如下： 详解如下： ExecuteEnv（执行环境） 1）这里可以是通过&nbsp;spark-submit&nbsp;提交的&nbsp;MainClass，也可以是&nbsp;spark-shell&nbsp;脚本。 2）MainClass：代码中必定会创建或者获取一个&nbsp;SparkContext。 3）spark-shell：默认会创建一个&nbsp;SparkContext。 RDD（弹性分布式数据集） 1）create：可以直接创建（如：sc.parallelize(1&nbsp;until&nbsp;n,&nbsp;slices)&nbsp;），也可以在其他地方读取（如：sc.textFile(&quot;README.md&quot;)）等。 2）transformation：rdd&nbsp;提供了一组&nbsp;api&nbsp;可以进行对已有&nbsp;RDD&nbsp;进行反复封装成为新的&nbsp;RDD，这里采用的是`装饰者设计模式`，下面为部分装饰器类图。 3）action：当调用&nbsp;RDD&nbsp;的&nbsp;action&nbsp;类操作方法时（collect、reduce、lookup、save&nbsp;），这触发&nbsp;DAGScheduler&nbsp;的&nbsp;Job&nbsp;提交。 4）DAGScheduler：创建一个名为&nbsp;JobSubmitted&nbsp;的消息至&nbsp;DAGSchedulerEventProcessLoop&nbsp;阻塞消息队列（LinkedBlockingDeque）中。 5）DAGSchedulerEventProcessLoop：启动名为【dag-scheduler-event-loop】的线程实时消费消息队列。 6）【dag-scheduler-event-loop】处理完成后回调&nbsp;JobWaiter。 7）DAGScheduler：打印&nbsp;Job&nbsp;执行结果。 8）JobSubmitted：相关代码如下（其中&nbsp;jobId&nbsp;为&nbsp;DAGScheduler&nbsp;全局递增&nbsp;Id）。 &nbsp;&nbsp;&nbsp;&nbsp;eventProcessLoop.post(JobSubmitted( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobId,&nbsp;rdd,&nbsp;func2,&nbsp;partitions.toArray,&nbsp;callSite,&nbsp;waiter, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SerializationUtils.clone(properties))) 部分装饰器类图 最终示例： 最终转化的 RDD 分为四层，每层都依赖于上层 RDD，将 ShffleRDD 封装为一个 Job 存入 DAGSchedulerEventProcessLoop 待处理，如果我们的代码中存在几段上面示例代码，那么就会创建对应对的几个 ShffleRDD 分别存入 DAGSchedulerEventProcessLoop 中。 9.3 RDD 分解为待执行任务集合（TaskSet） Job 提交后，DAGScheduler 根据 RDD 层次关系解析为对应的 Stages，同时维护 Job 与 Stage 的关系。 将最上层的 Stage 根据并发关系（findMissingPartitions）分解为多个 Task，将这个多个 Task 封装为 TaskSet 提交给 TaskScheduler。非最上层的 Stage 的存入处理的列表中（waitingStages += stage） 流程如下： 详解如下： 1）DAGSchedulerEventProcessLoop中，线程【dag-scheduler-event-loop】处理到&nbsp;JobSubmitted 2）调用&nbsp;DAGScheduler&nbsp;进行&nbsp;handleJobSubmitted &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;首先根据&nbsp;RDD&nbsp;依赖关系依次创建&nbsp;Stage&nbsp;族，Stage&nbsp;分为&nbsp;ShuffleMapStage、ResultStage&nbsp;两类，如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;更新&nbsp;jobId&nbsp;与&nbsp;StageId&nbsp;关系&nbsp;Map &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;创建&nbsp;ActiveJob，调用&nbsp;LiveListenerBug，发送&nbsp;SparkListenerJobStart&nbsp;指令 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;找到最上层&nbsp;Stage&nbsp;进行提交，下层&nbsp;Stage&nbsp;存入&nbsp;waitingStage&nbsp;中待后续处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1)&nbsp;调用&nbsp;OutputCommitCoordinator&nbsp;进行&nbsp;stageStart()&nbsp;处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2)&nbsp;调用&nbsp;LiveListenerBug，发送&nbsp;SparkListenerStageSubmitted&nbsp;指令 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3)&nbsp;调用&nbsp;SparkContext的broadcast&nbsp;方法获取&nbsp;Broadcast&nbsp;对象，根据&nbsp;Stage&nbsp;类型创建对应多个&nbsp;Task，一个&nbsp;Stage&nbsp;根据&nbsp;findMissingPartitions&nbsp;分为多个对应的&nbsp;Task，Task&nbsp;分为&nbsp;ShuffleMapTask、ResultTask &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4)&nbsp;将&nbsp;Task&nbsp;封装为&nbsp;TaskSet，调用&nbsp;TaskScheduler.submitTasks(taskSet)&nbsp;进行&nbsp;Task&nbsp;调度，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskScheduler.submitTasks(new&nbsp;TaskSet( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tasks.toArray,&nbsp;stage.id,&nbsp;stage.latestInfo.attemptId,&nbsp;jobId,&nbsp;properties)) ShuffleMapStage、ResultStage 两类 9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver TaskScheduler 将 TaskSet 封装为 TaskSetManager(new TaskSetManager(this, taskSet, maxTaskFailures, blacklistTrackerOpt))，存入待处理任务池（Pool）中，发送 DriverEndpoint 唤起消费（ReviveOffers）指令。 详解如下： 1）DAGSheduler&nbsp;将&nbsp;TaskSet&nbsp;提交给&nbsp;TaskScheduler&nbsp;的实现类，这里是&nbsp;TaskChedulerImpl。 2）TaskSchedulerImpl&nbsp;创建一个&nbsp;TaskSetManager&nbsp;管理&nbsp;TaskSet，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;TaskSetManager(this,&nbsp;taskSet,&nbsp;maxTaskFailures,&nbsp;blacklistTrackerOpt) 3）同时将&nbsp;TaskSetManager&nbsp;添加&nbsp;SchedduableBuilder&nbsp;的任务池&nbsp;Poll&nbsp;中。 4）调用&nbsp;SchedulerBackend&nbsp;的实现类进行&nbsp;reviveOffers，这里是&nbsp;standlone&nbsp;模式的实现类&nbsp;StandaloneSchedulerBackend。 5）SchedulerBackend&nbsp;发送&nbsp;ReviveOffers&nbsp;指令至&nbsp;DriverEndpoint。 9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor Driver 接受唤起消费指令后，将所有待处理的 TaskSetManager 与 Driver 中注册的 Executor 资源进行匹配，最终一个 TaskSetManager 得到多个 TaskDescription 对象，按照 TaskDescription 相对应的 Executor 发送 LaunchTask 指令。 详解如下： 当&nbsp;Driver&nbsp;获取到&nbsp;ReviveOffers（请求消费）指令时 1）首先根据&nbsp;executorDataMap&nbsp;缓存信息得到可用的&nbsp;Executor&nbsp;资源信息（WorkerOffer），关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;activeExecutors&nbsp;=&nbsp;executorDataMap.filterKeys(executorIsAlive) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;workOffers&nbsp;=&nbsp;activeExecutors.map&nbsp;{&nbsp;case&nbsp;(id,&nbsp;executorData)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;WorkerOffer(id,&nbsp;executorData.executorHost,&nbsp;executorData.freeCores) &nbsp;&nbsp;&nbsp;&nbsp;}.toIndexedSeq 2）接着调用&nbsp;TaskScheduler&nbsp;进行资源匹配，方法定义如下： &nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;resourceOffers(offers:&nbsp;IndexedSeq[WorkerOffer]):&nbsp;Seq[Seq[TaskDescription]]&nbsp;=&nbsp;synchronized&nbsp;{..} &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;将&nbsp;WorkerOffer&nbsp;资源打乱，如：val&nbsp;shuffledOffers&nbsp;=&nbsp;Random.shuffle(offers) &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;Pool&nbsp;中待处理的&nbsp;TaskSetManager&nbsp;取出，如：val&nbsp;sortedTaskSets&nbsp;=&nbsp;rootPool.getSortedTaskSetQueue &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;并循环处理&nbsp;sortedTaskSets&nbsp;并与&nbsp;shuffledOffers&nbsp;循环匹配，如果&nbsp;shuffledOffers(i)&nbsp;有足够的&nbsp;CPU&nbsp;资源（&nbsp;if&nbsp;(availableCpus(i)&nbsp;&gt;=&nbsp;CPUS_PER_TASK)），调用&nbsp;TaskSetManager&nbsp;创建&nbsp;TaskDescription&nbsp;对象（taskSet.resourceOffer(execId,&nbsp;host,&nbsp;maxLocality)），最终创建了多个&nbsp;TaskDescription，TaskDescription&nbsp;定义如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;TaskDescription( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attemptNum, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;execId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskName, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;index, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sched.sc.addedFiles, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sched.sc.addedJars, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;task.localProperties, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serializedTask) 3）如果&nbsp;TaskDescriptions&nbsp;不为空，循环&nbsp;TaskDescriptions，序列化&nbsp;TaskDescription&nbsp;对象，并向&nbsp;ExecutorEndpoint&nbsp;发送&nbsp;LaunchTask&nbsp;指令，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(task&nbsp;&lt;-&nbsp;taskDescriptions.flatten)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;serializedTask&nbsp;=&nbsp;TaskDescription.encode(task) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;executorData&nbsp;=&nbsp;executorDataMap(task.executorId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorData.freeCores&nbsp;-=&nbsp;scheduler.CPUS_PER_TASK &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorData.executorEndpoint.send(LaunchTask(new&nbsp;SerializableBuffer(serializedTask))) &nbsp;&nbsp;&nbsp;&nbsp;} 回到顶部 第10章 Task 执行和回馈 DriverEndpoint 最终生成多个可执行的 TaskDescription 对象，并向各个 ExecutorEndpoint 发送 LaunchTask 指令，本节内容将关注 ExecutorEndpoint 如何处理 LaunchTask 指令，处理完成后如何回馈给 DriverEndpoint，以及整个 job 最终如何多次调度直至结束。 10.1 Task 的执行流程 Executor 接受 LaunchTask 指令后，开启一个新线程 TaskRunner 解析 RDD，并调用 RDD 的 compute 方法，归并函数得到最终任务执行结果。 详解如下： 1）ExecutorEndpoint&nbsp;接受到&nbsp;LaunchTask&nbsp;指令后，解码出&nbsp;TaskDescription，调用&nbsp;Executor&nbsp;的&nbsp;launchTask&nbsp;方法。 2）Executor&nbsp;创建一个&nbsp;TaskRunner&nbsp;线程，并启动线程，同时将改线程添加到&nbsp;Executor&nbsp;的成员对象中，代码如下： &nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;val&nbsp;runningTasks&nbsp;=&nbsp;new&nbsp;ConcurrentHashMap[Long,&nbsp;TaskRunner] &nbsp;&nbsp;&nbsp;&nbsp;runningTasks.put(taskDescription.taskId,&nbsp;taskRunner) TaskRunner 1）首先向&nbsp;DriverEndpoint&nbsp;发送任务最新状态为&nbsp;RUNNING。 2）从&nbsp;TaskDescription&nbsp;解析出&nbsp;Task，并调用&nbsp;Task&nbsp;的&nbsp;run&nbsp;方法。 Task 1）创建&nbsp;TaskContext&nbsp;以及&nbsp;CallerContext&nbsp;(与&nbsp;HDFS&nbsp;交互的上下文对象)。 2）执行&nbsp;Task&nbsp;的&nbsp;runTask&nbsp;方法： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;如果&nbsp;Task&nbsp;实例为&nbsp;ShuffleMapTask：解析出&nbsp;RDD&nbsp;以及&nbsp;ShuffleDependency&nbsp;信息，调用&nbsp;RDD&nbsp;的&nbsp;compute()&nbsp;方法将结果写&nbsp;Writer&nbsp;中（Writer&nbsp;这里不介绍，可以作为黑盒理解，比如写入一个文件中），返回&nbsp;MapStatus&nbsp;对象。 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;如果&nbsp;Task&nbsp;实例为&nbsp;ResultTask：解析出&nbsp;RDD&nbsp;以及合并函数信息，调用函数将调用后的结果返回。 TaskRunner&nbsp;将&nbsp;Task&nbsp;执行的结果序列化，再次向&nbsp;DriverEndpoint&nbsp;发送任务最新状态为&nbsp;FINISHED。 10.2 Task 的回馈流程 TaskRunner 执行结束后，都将执行状态发送至 DriverEndpoint，DriverEndpoint 最终反馈指令 CompletionEvent 发送至 DAGSchedulerEventProcessLoop 中。 详解如下： 1）DriverEndpoint&nbsp;接收到&nbsp;StatusUpdate&nbsp;消息后，调用&nbsp;TaskScheduler&nbsp;的&nbsp;statusUpdate(taskId,&nbsp;state,&nbsp;result)&nbsp;方法 2）TaskScheduler&nbsp;如果任务结果是完成，那么清除该任务处理中的状态，并调动&nbsp;TaskResultGetter&nbsp;相关方法，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;taskSet&nbsp;=&nbsp;taskIdToTaskSetManager.get(tid) &nbsp;&nbsp;&nbsp;&nbsp;taskIdToTaskSetManager.remove(tid) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskIdToExecutorId.remove(tid).foreach&nbsp;{&nbsp;executorId&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorIdToRunningTaskIds.get(executorId).foreach&nbsp;{&nbsp;_.remove(tid)&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;taskSet.removeRunningTask(tid) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(state&nbsp;==&nbsp;TaskState.FINISHED)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskResultGetter.enqueueSuccessfulTask(taskSet,&nbsp;tid,&nbsp;serializedData) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(Set(TaskState.FAILED,&nbsp;TaskState.KILLED,&nbsp;TaskState.LOST).contains(state))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskResultGetter.enqueueFailedTask(taskSet,&nbsp;tid,&nbsp;state,&nbsp;serializedData) &nbsp;&nbsp;&nbsp;&nbsp;} TaskResultGetter&nbsp;启动线程启动线程【task-result-getter】进行相关处理： 1）通过解析或者远程获取得到&nbsp;Task&nbsp;的&nbsp;TaskResult&nbsp;对象。 2）调用&nbsp;TaskSet&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法，TaskSet&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法直接调用&nbsp;TaskSetManager&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法。 TaskSetManager 1）更新内部&nbsp;TaskInfo&nbsp;对象状态，并将该&nbsp;Task&nbsp;从运行中&nbsp;Task&nbsp;的集合删除，代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;info&nbsp;=&nbsp;taskInfos(tid) &nbsp;&nbsp;&nbsp;&nbsp;info.markFinished(TaskState.FINISHED,&nbsp;clock.getTimeMillis()) &nbsp;&nbsp;&nbsp;&nbsp;removeRunningTask(tid) 2）调用&nbsp;DAGScheduler&nbsp;的&nbsp;taskEnded&nbsp;方法，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;sched.dagScheduler.taskEnded(tasks(index),&nbsp;Success,&nbsp;result.value(),&nbsp;result.accumUpdates,&nbsp;info) DAGScheduler&nbsp;向&nbsp;DAGSchedulerEventProcessLoop&nbsp;存入&nbsp;CompletionEvent&nbsp;指令，CompletionEvent&nbsp;对象定义如下： &nbsp;&nbsp;&nbsp;&nbsp;private[scheduler]&nbsp;case&nbsp;class&nbsp;CompletionEvent( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;task:&nbsp;Task[_], &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reason:&nbsp;TaskEndReason, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result:&nbsp;Any, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accumUpdates:&nbsp;Seq[AccumulatorV2[_,&nbsp;_]], &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskInfo:&nbsp;TaskInfo)&nbsp;extends&nbsp;DAGSchedulerEvent 10.3 Task 的迭代流程 DAGSchedulerEventProcessLoop 中针对于 CompletionEvent 指令，调用 DAGScheduler 进行处理，DAGScheduler 更新 Stage 与该 Task 的关系状态，如果 Stage 下 Task 都返回，则做下一层 Stage 的任务拆解与运算工作，直至 Job 被执行完毕： 详解如下： 1）DAGSchedulerEventProcessLoop&nbsp;接收到&nbsp;CompletionEvent&nbsp;指令后，调用&nbsp;DAGScheduler&nbsp;的&nbsp;handleTaskCompletion&nbsp;方法。 2）DAGScheduler&nbsp;根据&nbsp;Task&nbsp;的类型分别处理。 3）如果&nbsp;Task&nbsp;为&nbsp;ShuffleMapTask &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;等待回馈的&nbsp;Partitions&nbsp;减去当前&nbsp;partitionId &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;如果所有&nbsp;task&nbsp;都返回，则&nbsp;markStageAsFinished(shuffleStage)，同时向&nbsp;MapOutputTrackerMaster&nbsp;注册&nbsp;MapOutputs&nbsp;信息，且&nbsp;markMapStageJobAsFinished &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;调用&nbsp;submitWaitingChildStages(shuffleStage)&nbsp;进行下层&nbsp;Stages&nbsp;的处理，从而迭代处理，最终处理到&nbsp;ResultTask，job&nbsp;结束，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;def&nbsp;submitWaitingChildStages(parent:&nbsp;Stage)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;childStages&nbsp;=&nbsp;waitingStages.filter(_.parents.contains(parent)).toArray &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingStages&nbsp;--=&nbsp;childStages &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(stage&nbsp;&lt;-&nbsp;childStages.sortBy(_.firstJobId))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;submitStage(stage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} 4）如果&nbsp;Task&nbsp;为&nbsp;ResultTask &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;该&nbsp;job&nbsp;的&nbsp;partitions&nbsp;都已返回，则&nbsp;markStageAsFinished(resultStage)，并&nbsp;cleanupStateForJobAndIndependentStages(job)，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(stage&nbsp;&lt;-&nbsp;stageIdToStage.get(stageId))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(runningStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;running&nbsp;stage&nbsp;%d&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;((k,&nbsp;v)&nbsp;&lt;-&nbsp;shuffleIdToMapStage.find(_._2&nbsp;==&nbsp;stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shuffleIdToMapStage.remove(k) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(waitingStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;stage&nbsp;%d&nbsp;from&nbsp;waiting&nbsp;set.&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(failedStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;stage&nbsp;%d&nbsp;from&nbsp;failed&nbsp;set.&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;failedStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;data&nbsp;structures&nbsp;based&nbsp;on&nbsp;StageId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stageIdToStage&nbsp;-=&nbsp;stageId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobIdToStageIds&nbsp;-=&nbsp;job.jobId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobIdToActiveJob&nbsp;-=&nbsp;job.jobId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeJobs&nbsp;-=&nbsp;job 至此，用户编写的代码最终调用&nbsp;Spark&nbsp;分布式计算完毕。 10.4 精彩图解 Spark的交互流程 – 节点启动 Spark的交互流程 – 应用提交 Spark的交互流程 – 任务运行 Spark的交互流程 – 任务运行 回到顶部 第11章 Spark 的数据存储 Spark 计算速度远胜于 Hadoop 的原因之一就在于中间结果是缓存在内存而不是直接写入到 disk，本文尝试分析 Spark 中存储子系统的构成，并以数据写入和数据读取为例，讲述清楚存储子系统中各部件的交互关系。 11.1 存储子系统概览 Storage 模块主要分为两层：   1) 通信层：storage 模块采用的是 master-slave 结构来实现通信层，master 和 slave 之间传输控制信息、状态信息，这些都是通过通信层来实现的。   2) 存储层：storage 模块需要把数据存储到 disk 或是 memory 上面，有可能还需 replicate(复制) 到远端，这都是由存储层来实现和提供相应接口。 而其他模块若要和 storage 模块进行交互，storage 模块提供了统一的操作类 BlockManager，外部类与 storage 模块打交道都需要通过调用 BlockManager 相应接口来实现。 上图是Spark存储子系统中几个主要模块的关系示意图，现简要说明如下： 1）CacheManager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RDD&nbsp;在进行计算的时候，通过&nbsp;CacheManager&nbsp;来获取数据，并通过&nbsp;CacheManager&nbsp;来存储计算结果。 2）BlockManager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CacheManager&nbsp;在进行数据读取和存取的时候主要是依赖&nbsp;BlockManager&nbsp;接口来操作，BlockManager&nbsp;决定数据是从内存(MemoryStore)&nbsp;还是从磁盘(DiskStore)&nbsp;中获取。 3）MemoryStore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;负责将数据保存在内存或从内存读取。 4）DiskStore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;负责将数据写入磁盘或从磁盘读入。 5）BlockManagerWorker&nbsp;&nbsp;&nbsp;数据写入本地的&nbsp;MemoryStore&nbsp;或&nbsp;DiskStore&nbsp;是一个同步操作，为了容错还需要将数据复制到别的计算结点，以防止数据丢失的时候还能够恢复，数据复制的操作是异步完成，由&nbsp;BlockManagerWorker&nbsp;来处理这一部分事情。 6）ConnectionManager&nbsp;&nbsp;&nbsp;&nbsp;负责与其它计算结点建立连接，并负责数据的发送和接收。 7）BlockManagerMaster&nbsp;&nbsp;&nbsp;注意该模块只运行在&nbsp;Driver&nbsp;Application&nbsp;所在的&nbsp;Executor，功能是负责记录下所有&nbsp;BlockIds&nbsp;存储在哪个&nbsp;SlaveWorker&nbsp;上，比如&nbsp;RDD&nbsp;Task&nbsp;运行在机器&nbsp;A，所需要的&nbsp;BlockId&nbsp;为&nbsp;3，但在机器&nbsp;A&nbsp;上没有&nbsp;BlockId&nbsp;为&nbsp;3&nbsp;的数值，这个时候&nbsp;Slave&nbsp;worker&nbsp;需要通过&nbsp;BlockManager&nbsp;向&nbsp;BlockManagerMaster&nbsp;询问数据存储的位置，然后再通过&nbsp;ConnectionManager&nbsp;去获取。 11.2 启动过程分析 上述的各个模块由 SparkEnv 来创建，创建过程在 SparkEnv.create 中完成，代码如下： val&nbsp;blockManagerMaster&nbsp;=&nbsp;new&nbsp;BlockManagerMaster(registerOrLookup( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;BlockManagerMaster&quot;, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;BlockManagerMasterActor(isLocal,&nbsp;conf)),&nbsp;conf) val&nbsp;blockManager&nbsp;=&nbsp;new&nbsp;BlockManager(executorId,&nbsp;actorSystem,&nbsp;blockManagerMaster,&nbsp;serializer,&nbsp;conf) val&nbsp;connectionManager&nbsp;=&nbsp;blockManager.connectionManager val&nbsp;broadcastManager&nbsp;=&nbsp;new&nbsp;BroadcastManager(isDriver,&nbsp;conf) val&nbsp;cacheManager&nbsp;=&nbsp;new&nbsp;CacheManager(blockManager) 下面这段代码容易让人疑惑，看起来像是在所有的 cluster node 上都创建了 BlockManagerMasterActor，其实不然，仔细看 registerOrLookup 函数的实现。如果当前节点是 driver 则创建这个 actor，否则建立到 driver 的连接。代码如下： def&nbsp;registerOrLookup(name:&nbsp;String,&nbsp;newActor:&nbsp;=&gt;&nbsp;Actor):&nbsp;ActorRef&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;&quot;&nbsp;+&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;actorSystem.actorOf(Props(newActor),&nbsp;name&nbsp;=&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;driverHost:&nbsp;String&nbsp;=&nbsp;conf.get(&quot;spark.driver.host&quot;,&nbsp;&quot;localhost&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;driverPort:&nbsp;Int&nbsp;=&nbsp;conf.getInt(&quot;spark.driver.port&quot;,&nbsp;7077) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Utils.checkHost(driverHost,&nbsp;&quot;Expected&nbsp;hostname&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;url&nbsp;=&nbsp;s&quot;akka.tcp://spark@$driverHost:$driverPort/user/$name&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;timeout&nbsp;=&nbsp;AkkaUtils.lookupTimeout(conf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(s&quot;Connecting&nbsp;to&nbsp;$name:&nbsp;$url&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Await.result(actorSystem.actorSelection(url).resolveOne(timeout),&nbsp;timeout) &nbsp;&nbsp;&nbsp;&nbsp;} } 初始化过程中一个主要的动作就是 BlockManager 需要向 BlockManagerMaster 发起注册。 11.3 通信层 BlockManager 包装了 BlockManagerMaster，发送信息包装成 BlockManagerInfo。Spark 在 Driver 和 Worker 端都创建各自的 BlockManager，并通过 BlockManagerMaster 进行通信，通过 BlockManager 对 Storage 模块进行操作。 BlockManager 对象在 SparkEnv.create 函数中进行创建，代码如下： def&nbsp;registerOrLookupEndpoint( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;String,&nbsp;endpointCreator:&nbsp;=&gt;&nbsp;RpcEndpoint): RpcEndpointRef&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;&quot;&nbsp;+&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rpcEnv.setupEndpoint(name,&nbsp;endpointCreator) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RpcUtils.makeDriverRef(name,&nbsp;conf,&nbsp;rpcEnv) &nbsp;&nbsp;&nbsp;&nbsp;} } ...... val&nbsp;blockManagerMaster&nbsp;=&nbsp;new&nbsp;BlockManagerMaster(registerOrLookupEndpoint( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockManagerMaster.DRIVER_ENDPOINT_NAME, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;BlockManagerMasterEndpoint(rpcEnv,&nbsp;isLocal,&nbsp;conf,&nbsp;listenerBus)), &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;conf,&nbsp;isDriver) //&nbsp;NB:&nbsp;blockManager&nbsp;is&nbsp;not&nbsp;valid&nbsp;until&nbsp;initialize()&nbsp;is&nbsp;called&nbsp;later. val&nbsp;blockManager&nbsp;=&nbsp;new&nbsp;BlockManager(executorId,&nbsp;rpcEnv,&nbsp;blockManagerMaster, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serializer,&nbsp;conf,&nbsp;mapOutputTracker,&nbsp;shuffleManager,&nbsp;blockTransferService,&nbsp;securityManager,numUsableCores) 并且在创建之前对当前节点是否是 Driver 进行了判断。如果是，则创建这个 Endpoint；否则，创建 Driver 的连接。 在创建 BlockManager 之后，BlockManager 会调用 initialize 方法初始化自己。并且初始化的时候，会调用 BlockManagerMaster 向 Driver 注册自己，同时，在注册时也启动了Slave Endpoint。另外，向本地 shuffle 服务器注册 Executor 配置，如果存在的话。代码如下： def&nbsp;initialize(appId:&nbsp;String):&nbsp;Unit&nbsp;=&nbsp;{ ...... &nbsp;&nbsp;&nbsp;&nbsp;master.registerBlockManager(blockManagerId,&nbsp;maxMemory,&nbsp;slaveEndpoint) &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Register&nbsp;Executors&#39;&nbsp;configuration&nbsp;with&nbsp;the&nbsp;local&nbsp;shuffle&nbsp;service,&nbsp;if&nbsp;one&nbsp;should&nbsp;exist. &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(externalShuffleServiceEnabled&nbsp;&amp;&amp;&nbsp;!blockManagerId.isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;registerWithExternalShuffleServer() &nbsp;&nbsp;&nbsp;&nbsp;} } 而 BlockManagerMaster 将注册请求包装成 RegisterBlockManager 注册到 Driver。Driver 的 BlockManagerMasterEndpoint 会调用 register 方法，通过对消息 BlockManagerInfo 检查，向 Driver 注册，代码如下： private&nbsp;def&nbsp;register(id:&nbsp;BlockManagerId,&nbsp;maxMemSize:&nbsp;Long,&nbsp;slaveEndpoint:&nbsp;RpcEndpointRef)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;time&nbsp;=&nbsp;System.currentTimeMillis() &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!blockManagerInfo.contains(id))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerIdByExecutor.get(id.executorId)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(oldId)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;A&nbsp;block&nbsp;manager&nbsp;of&nbsp;the&nbsp;same&nbsp;executor&nbsp;already&nbsp;exists,&nbsp;so&nbsp;remove&nbsp;it&nbsp;(assumed&nbsp;dead) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logError(&quot;Got&nbsp;two&nbsp;different&nbsp;block&nbsp;manager&nbsp;registrations&nbsp;on&nbsp;same&nbsp;executor&nbsp;-&nbsp;&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;s&quot;&nbsp;will&nbsp;replace&nbsp;old&nbsp;one&nbsp;$oldId&nbsp;with&nbsp;new&nbsp;one&nbsp;$id&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;removeExecutor(id.executorId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;block&nbsp;manager&nbsp;%s&nbsp;with&nbsp;%s&nbsp;RAM,&nbsp;%s&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id.hostPort,&nbsp;Utils.bytesToString(maxMemSize),&nbsp;id)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerIdByExecutor(id.executorId)&nbsp;=&nbsp;id &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerInfo(id)&nbsp;=&nbsp;new&nbsp;BlockManagerInfo( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id,&nbsp;System.currentTimeMillis(),&nbsp;maxMemSize,&nbsp;slaveEndpoint) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;listenerBus.post(SparkListenerBlockManagerAdded(time,&nbsp;id,&nbsp;maxMemSize)) } 不难发现 BlockManagerInfo 对象被保存到 Map 映射中。在通信层中 BlockManagerMaster 控制着消息的流向，这里采用了模式匹配，所有的消息模式都在 BlockManagerMessage 中。 11.4 存储层 Spark Storage 的最小存储单位是 block，所有的操作都是以 block 为单位进行的。 在 BlockManager 被创建的时候 MemoryStore 和 DiskStore 对象就被创建出来了。代码如下： val&nbsp;diskBlockManager&nbsp;=&nbsp;new&nbsp;DiskBlockManager(this,&nbsp;conf) private[spark]&nbsp;val&nbsp;memoryStore&nbsp;=&nbsp;new&nbsp;MemoryStore(this,&nbsp;maxMemory) private[spark]&nbsp;val&nbsp;diskStore&nbsp;=&nbsp;new&nbsp;DiskStore(this,&nbsp;diskBlockManager) 11.4.1 Disk Store 由于当前的 Spark 版本对 Disk Store 进行了更细粒度的分工，把对文件的操作提取出来放到了 DiskBlockManager 中，DiskStore 仅仅负责数据的存储和读取。 Disk Store 会配置多个文件目录，Spark 会在不同的文件目录下创建文件夹，其中文件夹的命名方式是：spark-UUID（随机UUID码）。Disk Store 在存储的时候创建文件夹。并且根据【高内聚，低耦合】原则，这种服务型的工具代码就放到了 Utils 中（调用路径：DiskStore.putBytes —&gt; DiskBlockManager.createLocalDirs —&gt; Utils.createDirectory），代码如下： def&nbsp;createDirectory(root:&nbsp;String,&nbsp;namePrefix:&nbsp;String&nbsp;=&nbsp;&quot;spark&quot;):&nbsp;File&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;attempts&nbsp;=&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;maxAttempts&nbsp;=&nbsp;MAX_DIR_CREATION_ATTEMPTS &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;dir:&nbsp;File&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(dir&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attempts&nbsp;+=&nbsp;1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(attempts&nbsp;&gt;&nbsp;maxAttempts)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Failed&nbsp;to&nbsp;create&nbsp;a&nbsp;temp&nbsp;directory&nbsp;(under&nbsp;&quot;&nbsp;+&nbsp;root&nbsp;+&nbsp;&quot;)&nbsp;after&nbsp;&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;maxAttempts&nbsp;+&nbsp;&quot;&nbsp;attempts!&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dir&nbsp;=&nbsp;new&nbsp;File(root,&nbsp;namePrefix&nbsp;+&nbsp;&quot;-&quot;&nbsp;+&nbsp;UUID.randomUUID.toString) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(dir.exists()&nbsp;||&nbsp;!dir.mkdirs())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dir&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;catch&nbsp;{&nbsp;case&nbsp;e:&nbsp;SecurityException&nbsp;=&gt;&nbsp;dir&nbsp;=&nbsp;null;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;dir.getCanonicalFile } 在 DiskBlockManager 里，每个 block 都被存储为一个 file，通过计算 blockId 的 hash 值，将 block 映射到文件中。 def&nbsp;getFile(filename:&nbsp;String):&nbsp;File&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Figure&nbsp;out&nbsp;which&nbsp;local&nbsp;directory&nbsp;it&nbsp;hashes&nbsp;to,&nbsp;and&nbsp;which&nbsp;subdirectory&nbsp;in&nbsp;that &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;hash&nbsp;=&nbsp;Utils.nonNegativeHash(filename) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;dirId&nbsp;=&nbsp;hash&nbsp;%&nbsp;localDirs.length &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;subDirId&nbsp;=&nbsp;(hash&nbsp;/&nbsp;localDirs.length)&nbsp;%&nbsp;subDirsPerLocalDir &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;the&nbsp;subdirectory&nbsp;if&nbsp;it&nbsp;doesn&#39;t&nbsp;already&nbsp;exist &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;subDir&nbsp;=&nbsp;subDirs(dirId).synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;old&nbsp;=&nbsp;subDirs(dirId)(subDirId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(old&nbsp;!=&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;old &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;newDir&nbsp;=&nbsp;new&nbsp;File(localDirs(dirId),&nbsp;&quot;%02x&quot;.format(subDirId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!newDir.exists()&nbsp;&amp;&amp;&nbsp;!newDir.mkdir())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(s&quot;Failed&nbsp;to&nbsp;create&nbsp;local&nbsp;dir&nbsp;in&nbsp;$newDir.&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;subDirs(dirId)(subDirId)&nbsp;=&nbsp;newDir &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;newDir &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;File(subDir,&nbsp;filename) } def&nbsp;getFile(blockId:&nbsp;BlockId):&nbsp;File&nbsp;=&nbsp;getFile(blockId.name) 通过 hash 值的取模运算，求出 dirId 和 subDirId。然后，在从 subDirs 中找到 subDir，如果 subDir 不存在，则创建一个新 subDir。最后，以 subDir 为路径，blockId 的 name 属性为文件名，新建该文件。 文件创建完之后，那么 Spark 就会在 DiskStore 中向文件写与之映射的 block，代码如下： override&nbsp;def&nbsp;putBytes(blockId:&nbsp;BlockId,&nbsp;_bytes:&nbsp;ByteBuffer,&nbsp;level:&nbsp;StorageLevel):&nbsp;PutResult&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bytes&nbsp;=&nbsp;_bytes.duplicate() &nbsp;&nbsp;&nbsp;&nbsp;logDebug(s&quot;Attempting&nbsp;to&nbsp;put&nbsp;block&nbsp;$blockId&quot;) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;startTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;file&nbsp;=&nbsp;diskManager.getFile(blockId) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;channel&nbsp;=&nbsp;new&nbsp;FileOutputStream(file).getChannel &nbsp;&nbsp;&nbsp;&nbsp;Utils.tryWithSafeFinally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(bytes.remaining&nbsp;&gt;&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.write(bytes) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.close() &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;finishTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Block&nbsp;%s&nbsp;stored&nbsp;as&nbsp;%s&nbsp;file&nbsp;on&nbsp;disk&nbsp;in&nbsp;%d&nbsp;ms&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file.getName,&nbsp;Utils.bytesToString(bytes.limit),&nbsp;finishTime&nbsp;-&nbsp;startTime)) &nbsp;&nbsp;&nbsp;&nbsp;PutResult(bytes.limit(),&nbsp;Right(bytes.duplicate())) } 读取过程就简单了，DiskStore 根据 blockId 读取与之映射的 file 内容，当然，这中间需要从 DiskBlockManager 中得到文件信息。代码如下： private&nbsp;def&nbsp;getBytes(file:&nbsp;File,&nbsp;offset:&nbsp;Long,&nbsp;length:&nbsp;Long):&nbsp;Option[ByteBuffer]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;channel&nbsp;=&nbsp;new&nbsp;RandomAccessFile(file,&nbsp;&quot;r&quot;).getChannel &nbsp;&nbsp;&nbsp;&nbsp;Utils.tryWithSafeFinally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;For&nbsp;small&nbsp;files,&nbsp;directly&nbsp;read&nbsp;rather&nbsp;than&nbsp;memory&nbsp;map &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(length&nbsp;&lt;&nbsp;minMemoryMapBytes)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;buf&nbsp;=&nbsp;ByteBuffer.allocate(length.toInt) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.position(offset) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(buf.remaining()&nbsp;!=&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(channel.read(buf)&nbsp;==&nbsp;-1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Reached&nbsp;EOF&nbsp;before&nbsp;filling&nbsp;buffer\n&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s&quot;offset=$offset\nfile=${file.getAbsolutePath}\nbuf.remaining=${buf.remaining}&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buf.flip() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(buf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(channel.map(MapMode.READ_ONLY,&nbsp;offset,&nbsp;length)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.close() &nbsp;&nbsp;&nbsp;&nbsp;} } override&nbsp;def&nbsp;getBytes(blockId:&nbsp;BlockId):&nbsp;Option[ByteBuffer]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;file&nbsp;=&nbsp;diskManager.getFile(blockId.name) &nbsp;&nbsp;&nbsp;&nbsp;getBytes(file,&nbsp;0,&nbsp;file.length) } 11.4.2 Memory Store 相对 Disk Store，Memory Store 就显得容易很多。Memory Store 用一个 LinkedHashMap 来管理，其中 Key 是 blockId，Value 是 MemoryEntry 样例类，MemoryEntry 存储着数据信息。代码如下： private&nbsp;case&nbsp;class&nbsp;MemoryEntry(value:&nbsp;Any,&nbsp;size:&nbsp;Long,&nbsp;deserialized:&nbsp;Boolean) private&nbsp;val&nbsp;entries&nbsp;=&nbsp;new&nbsp;LinkedHashMap[BlockId,&nbsp;MemoryEntry](32,&nbsp;0.75f,&nbsp;true) 在 MemoryStore 中存储 block 的前提是当前内存有足够的空间存放。通过对 tryToPut 函数的调用对内存空间进行判断。代码如下： def&nbsp;putBytes(blockId:&nbsp;BlockId,&nbsp;size:&nbsp;Long,&nbsp;_bytes:&nbsp;()&nbsp;=&gt;&nbsp;ByteBuffer):&nbsp;PutResult&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Work&nbsp;on&nbsp;a&nbsp;duplicate&nbsp;-&nbsp;since&nbsp;the&nbsp;original&nbsp;input&nbsp;might&nbsp;be&nbsp;used&nbsp;elsewhere. &nbsp;&nbsp;&nbsp;&nbsp;lazy&nbsp;val&nbsp;bytes&nbsp;=&nbsp;_bytes().duplicate().rewind().asInstanceOf[ByteBuffer] &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putAttempt&nbsp;=&nbsp;tryToPut(blockId,&nbsp;()&nbsp;=&gt;&nbsp;bytes,&nbsp;size,&nbsp;deserialized&nbsp;=&nbsp;false) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;data&nbsp;= &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putAttempt.success)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(bytes.limit&nbsp;==&nbsp;size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right(bytes.duplicate()) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;PutResult(size,&nbsp;data,&nbsp;putAttempt.droppedBlocks) } 在 tryToPut 函数中，通过调用 enoughFreeSpace 函数判断内存空间。如果内存空间足够，那么就把 block 放到 LinkedHashMap 中；如果内存不足，那么就告诉 BlockManager 内存不足，如果允许 Disk Store，那么就把该 block 放到 disk 上。代码如下： private&nbsp;def&nbsp;tryToPut(blockId:&nbsp;BlockId,&nbsp;value:&nbsp;()&nbsp;=&gt;&nbsp;Any,&nbsp;size:&nbsp;Long,&nbsp;deserialized:&nbsp;Boolean):&nbsp;ResultWithDroppedBlocks&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;putSuccess&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;droppedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;accountingLock.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;freeSpaceResult&nbsp;=&nbsp;ensureFreeSpace(blockId,&nbsp;size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;enoughFreeSpace&nbsp;=&nbsp;freeSpaceResult.success &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;droppedBlocks&nbsp;++=&nbsp;freeSpaceResult.droppedBlocks &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(enoughFreeSpace)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;entry&nbsp;=&nbsp;new&nbsp;MemoryEntry(value(),&nbsp;size,&nbsp;deserialized) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.put(blockId,&nbsp;entry) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;currentMemory&nbsp;+=&nbsp;size &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;valuesOrBytes&nbsp;=&nbsp;if&nbsp;(deserialized)&nbsp;&quot;values&quot;&nbsp;else&nbsp;&quot;bytes&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Block&nbsp;%s&nbsp;stored&nbsp;as&nbsp;%s&nbsp;in&nbsp;memory&nbsp;(estimated&nbsp;size&nbsp;%s,&nbsp;free&nbsp;%s)&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId,&nbsp;valuesOrBytes,&nbsp;Utils.bytesToString(size),&nbsp;Utils.bytesToString(freeMemory))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putSuccess&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lazy&nbsp;val&nbsp;data&nbsp;=&nbsp;if&nbsp;(deserialized)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Left(value().asInstanceOf[Array[Any]]) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right(value().asInstanceOf[ByteBuffer].duplicate()) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;droppedBlockStatus&nbsp;=&nbsp;blockManager.dropFromMemory(blockId,&nbsp;()&nbsp;=&gt;&nbsp;data) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;droppedBlockStatus.foreach&nbsp;{&nbsp;status&nbsp;=&gt;&nbsp;droppedBlocks&nbsp;+=&nbsp;((blockId,&nbsp;status))&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;releasePendingUnrollMemoryForThisTask() &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;ResultWithDroppedBlocks(putSuccess,&nbsp;droppedBlocks) } Memory Store 读取 block 也很简单，只需要从 LinkedHashMap 中取出 blockId 的 Value 即可。代码如下： override&nbsp;def&nbsp;getValues(blockId:&nbsp;BlockId):&nbsp;Option[Iterator[Any]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;entry&nbsp;=&nbsp;entries.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.get(blockId) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(entry&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;None &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(entry.deserialized)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(entry.value.asInstanceOf[Array[Any]].iterator) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;buffer&nbsp;=&nbsp;entry.value.asInstanceOf[ByteBuffer].duplicate()&nbsp;//&nbsp;Doesn&#39;t&nbsp;actually&nbsp;copy&nbsp;data &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(blockManager.dataDeserialize(blockId,&nbsp;buffer)) &nbsp;&nbsp;&nbsp;&nbsp;} } 11.5 数据写入过程分析 数据写入的简要流程： 1）RDD.iterator&nbsp;是与&nbsp;storage&nbsp;子系统交互的入口。 2）CacheManager.getOrCompute&nbsp;调用&nbsp;BlockManager&nbsp;的&nbsp;put&nbsp;接口来写入数据。 3）数据优先写入到&nbsp;MemoryStore&nbsp;即内存，如果&nbsp;MemoryStore&nbsp;中的数据已满则将最近使用次数不频繁的数据写入到磁盘。 4）通知&nbsp;BlockManagerMaster&nbsp;有新的数据写入，在&nbsp;BlockManagerMaster&nbsp;中保存元数据。 5）将写入的数据与其它&nbsp;slave&nbsp;worker&nbsp;进行同步，一般来说在本机写入的数据，都会另先一台机器来进行数据的备份，即&nbsp;replicanumber=1。 其实，我们在&nbsp;put&nbsp;和&nbsp;get&nbsp;block&nbsp;的时候并没有那么复杂，前面的细节&nbsp;BlockManager&nbsp;都包装好了，我们只需要调用&nbsp;BlockManager&nbsp;中的&nbsp;put&nbsp;和&nbsp;get&nbsp;函数即可。 代码如下： def&nbsp;putBytes( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId:&nbsp;BlockId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes:&nbsp;ByteBuffer, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level:&nbsp;StorageLevel, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tellMaster:&nbsp;Boolean&nbsp;=&nbsp;true, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel:&nbsp;Option[StorageLevel]&nbsp;=&nbsp;None):&nbsp;Seq[(BlockId,&nbsp;BlockStatus)]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(bytes&nbsp;!=&nbsp;null,&nbsp;&quot;Bytes&nbsp;is&nbsp;null&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;doPut(blockId,&nbsp;ByteBufferValues(bytes),&nbsp;level,&nbsp;tellMaster,&nbsp;effectiveStorageLevel) &nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;private&nbsp;def&nbsp;doPut( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId:&nbsp;BlockId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data:&nbsp;BlockValues, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level:&nbsp;StorageLevel, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tellMaster:&nbsp;Boolean&nbsp;=&nbsp;true, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel:&nbsp;Option[StorageLevel]&nbsp;=&nbsp;None) :&nbsp;Seq[(BlockId,&nbsp;BlockStatus)]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(blockId&nbsp;!=&nbsp;null,&nbsp;&quot;BlockId&nbsp;is&nbsp;null&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(level&nbsp;!=&nbsp;null&nbsp;&amp;&amp;&nbsp;level.isValid,&nbsp;&quot;StorageLevel&nbsp;is&nbsp;null&nbsp;or&nbsp;invalid&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel.foreach&nbsp;{&nbsp;level&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(level&nbsp;!=&nbsp;null&nbsp;&amp;&amp;&nbsp;level.isValid,&nbsp;&quot;Effective&nbsp;StorageLevel&nbsp;is&nbsp;null&nbsp;or&nbsp;invalid&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;updatedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putBlockInfo&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;tinfo&nbsp;=&nbsp;new&nbsp;BlockInfo(level,&nbsp;tellMaster) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;oldBlockOpt&nbsp;=&nbsp;blockInfo.putIfAbsent(blockId,&nbsp;tinfo) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(oldBlockOpt.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(oldBlockOpt.get.waitForReady())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logWarning(s&quot;Block&nbsp;$blockId&nbsp;already&nbsp;exists&nbsp;on&nbsp;this&nbsp;machine;&nbsp;not&nbsp;re-adding&nbsp;it&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;updatedBlocks &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;oldBlockOpt.get &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tinfo &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} } &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;startTimeMs&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;valuesAfterPut:&nbsp;Iterator[Any]&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;bytesAfterPut:&nbsp;ByteBuffer&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;size&nbsp;=&nbsp;0L &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putLevel&nbsp;=&nbsp;effectiveStorageLevel.getOrElse(level) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;replicationFuture&nbsp;=&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;b:&nbsp;ByteBufferValues&nbsp;if&nbsp;putLevel.replication&nbsp;&gt;&nbsp;1&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Duplicate&nbsp;doesn&#39;t&nbsp;copy&nbsp;the&nbsp;bytes,&nbsp;but&nbsp;just&nbsp;creates&nbsp;a&nbsp;wrapper &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bufferView&nbsp;=&nbsp;b.buffer.duplicate() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Future&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replicate(blockId,&nbsp;bufferView,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}(futureExecutionContext) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logTrace(&quot;Put&nbsp;for&nbsp;block&nbsp;%s&nbsp;took&nbsp;%s&nbsp;to&nbsp;get&nbsp;into&nbsp;synchronized&nbsp;block&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;marked&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;(returnValues,&nbsp;blockStore:&nbsp;BlockStore)&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.useMemory)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(true,&nbsp;memoryStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(putLevel.useOffHeap)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(false,&nbsp;externalBlockStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(putLevel.useDisk)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1,&nbsp;diskStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(putLevel&nbsp;==&nbsp;StorageLevel.NONE) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;BlockException( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId,&nbsp;s&quot;Attempted&nbsp;to&nbsp;put&nbsp;block&nbsp;$blockId&nbsp;without&nbsp;specifying&nbsp;storage&nbsp;level!&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;result&nbsp;=&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;IteratorValues(iterator)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putIterator(blockId,&nbsp;iterator,&nbsp;putLevel,&nbsp;returnValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ArrayValues(array)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putArray(blockId,&nbsp;array,&nbsp;putLevel,&nbsp;returnValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ByteBufferValues(bytes)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes.rewind() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putBytes(blockId,&nbsp;bytes,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size&nbsp;=&nbsp;result.size &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result.data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Left&nbsp;(newIterator)&nbsp;if&nbsp;putLevel.useMemory&nbsp;=&gt;&nbsp;valuesAfterPut&nbsp;=&nbsp;newIterator &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Right&nbsp;(newBytes)&nbsp;=&gt;&nbsp;bytesAfterPut&nbsp;=&nbsp;newBytes &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.useMemory)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result.droppedBlocks.foreach&nbsp;{&nbsp;updatedBlocks&nbsp;+=&nbsp;_&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putBlockStatus&nbsp;=&nbsp;getCurrentBlockStatus(blockId,&nbsp;putBlockInfo) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putBlockStatus.storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;marked&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.markReady(size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(tellMaster)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reportBlockStatus(blockId,&nbsp;putBlockInfo,&nbsp;putBlockStatus) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updatedBlocks&nbsp;+=&nbsp;((blockId,&nbsp;putBlockStatus)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!marked)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockInfo.remove(blockId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.markFailure() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logWarning(s&quot;Putting&nbsp;block&nbsp;$blockId&nbsp;failed&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Put&nbsp;block&nbsp;%s&nbsp;locally&nbsp;took&nbsp;%s&quot;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ByteBufferValues(bytes)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(replicationFuture&nbsp;!=&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Await.ready(replicationFuture,&nbsp;Duration.Inf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;remoteStartTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(bytesAfterPut&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(valuesAfterPut&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;SparkException( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Underlying&nbsp;put&nbsp;returned&nbsp;neither&nbsp;an&nbsp;Iterator&nbsp;nor&nbsp;bytes!&nbsp;This&nbsp;shouldn&#39;t&nbsp;happen.&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytesAfterPut&nbsp;=&nbsp;dataSerialize(blockId,&nbsp;valuesAfterPut) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replicate(blockId,&nbsp;bytesAfterPut,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Put&nbsp;block&nbsp;%s&nbsp;remotely&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(remoteStartTime))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockManager.dispose(bytesAfterPut) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Putting&nbsp;block&nbsp;%s&nbsp;with&nbsp;replication&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Putting&nbsp;block&nbsp;%s&nbsp;without&nbsp;replication&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updatedBlocks &nbsp;&nbsp;&nbsp;} 对于 doPut 函数，主要做了以下几个操作：   1）创建 BlockInfo 对象存储 block 信息。   2）将 BlockInfo 加锁，然后根据 Storage Level 判断存储到 Memory 还是 Disk。同时，对于已经准备好读的 BlockInfo 要进行解锁。   3）根据 block 的副本数量决定是否向远程发送副本。 11.5.1 序列化与否 写入的具体内容可以是序列化之后的 bytes 也可以是没有序列化的 value. 此处有一个对 scala 的语法中 Either, Left, Right 关键字的理解。 11.6 数据读取过程分析 def&nbsp;get(blockId:&nbsp;BlockId):&nbsp;Option[Iterator[Any]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;local&nbsp;=&nbsp;getLocal(blockId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(local.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Found&nbsp;block&nbsp;%s&nbsp;locally&quot;.format(blockId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;local &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;remote&nbsp;=&nbsp;getRemote(blockId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(remote.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Found&nbsp;block&nbsp;%s&nbsp;remotely&quot;.format(blockId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;remote &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;None } 11.6.1 本地读取 首先在查询本机的 MemoryStore 和 DiskStore 中是否有所需要的 block 数据存在，如果没有则发起远程数据获取。 11.6.2 远程读取 远程获取调用路径， getRemote --&gt; doGetRemote, 在 doGetRemote 中最主要的就是调用 BlockManagerWorker.syncGetBlock 来从远程获得数据。 def&nbsp;syncGetBlock(msg:&nbsp;GetBlock,&nbsp;toConnManagerId:&nbsp;ConnectionManagerId):&nbsp;ByteBuffer&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockManager&nbsp;=&nbsp;blockManagerWorker.blockManager &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;connectionManager&nbsp;=&nbsp;blockManager.connectionManager &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockMessage&nbsp;=&nbsp;BlockMessage.fromGetBlock(msg) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockMessageArray&nbsp;=&nbsp;new&nbsp;BlockMessageArray(blockMessage) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;responseMessage&nbsp;=&nbsp;connectionManager.sendMessageReliablySync( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;toConnManagerId,&nbsp;blockMessageArray.toBufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;responseMessage&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(message)&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bufferMessage&nbsp;=&nbsp;message.asInstanceOf[BufferMessage] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Response&nbsp;message&nbsp;received&nbsp;&quot;&nbsp;+&nbsp;bufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockMessageArray.fromBufferMessage(bufferMessage).foreach(blockMessage&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Found&nbsp;&quot;&nbsp;+&nbsp;blockMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;blockMessage.getData &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt;&nbsp;logDebug(&quot;No&nbsp;response&nbsp;message&nbsp;received&quot;) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;null } 上述这段代码中最有意思的莫过于 sendMessageReliablySync，远程数据读取毫无疑问是一个异步 i/o 操作，这里的代码怎么写起来就像是在进行同步的操作一样呢。也就是说如何知道对方发送回来响应的呢？ 别急，继续去看看 sendMessageReliablySync 的定义： def&nbsp;sendMessageReliably(connectionManagerId:&nbsp;ConnectionManagerId,&nbsp;message:&nbsp;Message) &nbsp;&nbsp;:&nbsp;Future[Option[Message]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;promise&nbsp;=&nbsp;Promise[Option[Message]] &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;status&nbsp;=&nbsp;new&nbsp;MessageStatus( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message,&nbsp;connectionManagerId,&nbsp;s&nbsp;=&gt;&nbsp;promise.success(s.ackMessage)) &nbsp;&nbsp;&nbsp;&nbsp;messageStatuses.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses&nbsp;+=&nbsp;((message.id,&nbsp;status)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;sendMessage(connectionManagerId,&nbsp;message) &nbsp;&nbsp;&nbsp;&nbsp;promise.future } 要是我说秘密在这里，你肯定会说我在扯淡，但确实在此处。注意到关键字 Promise 和 Future 没？ 如果这个 future 执行完毕，返回 s.ackMessage。我们再看看这个 ackMessage 是在什么地方被写入的呢。看一看 ConnectionManager.handleMessage 中的代码片段： case&nbsp;bufferMessage:&nbsp;BufferMessage&nbsp;=&gt; { &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(authEnabled)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;res&nbsp;=&nbsp;handleAuthentication(connection,&nbsp;bufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(res&nbsp;==&nbsp;true)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;message&nbsp;was&nbsp;security&nbsp;negotiation&nbsp;so&nbsp;skip&nbsp;the&nbsp;rest &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;After&nbsp;handleAuth&nbsp;result&nbsp;was&nbsp;true,&nbsp;returning&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(bufferMessage.hasAckId)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sentMessageStatus&nbsp;=&nbsp;messageStatuses.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses.get(bufferMessage.ackId)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(status)&nbsp;=&gt;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses&nbsp;-=&nbsp;bufferMessage.ackId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;status &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;Exception(&quot;Could&nbsp;not&nbsp;find&nbsp;reference&nbsp;for&nbsp;received&nbsp;ack&nbsp;message&nbsp;&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message.id) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.ackMessage&nbsp;=&nbsp;Some(message) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.attempted&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.acked&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStaus.markDone() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 注意：此处的所调用的 sentMessageStatus.markDone 就会调用在 sendMessageReliablySync 中定义的 promise.Success，不妨看看 MessageStatus 的定义。 class&nbsp;MessageStatus( val&nbsp;message:&nbsp;Message, val&nbsp;connectionManagerId:&nbsp;ConnectionManagerId, completionHandler:&nbsp;MessageStatus&nbsp;=&gt;&nbsp;Unit)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;ackMessage:&nbsp;Option[Message]&nbsp;=&nbsp;None &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;attempted&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;acked&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;markDone()&nbsp;{&nbsp;completionHandler(this)&nbsp;} } 11.7 Partition 如何转化为 Block 在 storage 模块里面所有的操作都是和 block 相关的，但是在 RDD 里面所有的运算都是基于 partition 的，那么 partition 是如何与 block 对应上的呢？ RDD 计算的核心函数是 iterator() 函数： final&nbsp;def&nbsp;iterator(split:&nbsp;Partition,&nbsp;context:&nbsp;TaskContext):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparkEnv.get.cacheManager.getOrCompute(this,&nbsp;split,&nbsp;context,&nbsp;storageLevel) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;} } 如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute() 函数计算 RDD，在这个函数中 partition 和 block 发生了关系： 首先根据 RDD id 和 partition index 构造出 block id (rdd_xx_xx)，接着从 BlockManager 中取出相应的 block。   如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。   如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的 block，并将其存储到 BlockManager 中。 需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。 def&nbsp;getOrCompute[T](rdd:RDD[T],split:Partition,context:TaskContext,storageLevel:StorageLevel):Iterator[T]= { &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;key&nbsp;=&nbsp;&quot;rdd_%d_%d&quot;.format(rdd.id,&nbsp;split.index) &nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Looking&nbsp;for&nbsp;partition&nbsp;&quot;&nbsp;+&nbsp;key) &nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(values)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Partition&nbsp;is&nbsp;already&nbsp;materialized,&nbsp;so&nbsp;just&nbsp;return&nbsp;its&nbsp;values &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;values.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Mark&nbsp;the&nbsp;split&nbsp;as&nbsp;loading&nbsp;(unless&nbsp;someone&nbsp;else&nbsp;marks&nbsp;it&nbsp;first) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(loading.contains(key))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Another&nbsp;thread&nbsp;is&nbsp;loading&nbsp;%s,&nbsp;waiting&nbsp;for&nbsp;it&nbsp;to&nbsp;finish...&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(loading.contains(key))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.wait() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;catch&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Throwable&nbsp;=&gt;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Finished&nbsp;waiting&nbsp;for&nbsp;%s&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;See&nbsp;whether&nbsp;someone&nbsp;else&nbsp;has&nbsp;successfully&nbsp;loaded&nbsp;it.&nbsp;The&nbsp;main&nbsp;way&nbsp;this&nbsp;would&nbsp;fail &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;is&nbsp;for&nbsp;the&nbsp;RDD-level&nbsp;cache&nbsp;eviction&nbsp;policy&nbsp;if&nbsp;someone&nbsp;else&nbsp;has&nbsp;loaded&nbsp;the&nbsp;same&nbsp;RDD &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;partition&nbsp;but&nbsp;we&nbsp;didn&#39;t&nbsp;want&nbsp;to&nbsp;make&nbsp;space&nbsp;for&nbsp;it.&nbsp;However,&nbsp;that&nbsp;case&nbsp;is&nbsp;unlikely &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;because&nbsp;it&#39;s&nbsp;unlikely&nbsp;that&nbsp;two&nbsp;threads&nbsp;would&nbsp;work&nbsp;on&nbsp;the&nbsp;same&nbsp;RDD&nbsp;partition.&nbsp;One &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;downside&nbsp;of&nbsp;the&nbsp;current&nbsp;code&nbsp;is&nbsp;that&nbsp;threads&nbsp;wait&nbsp;serially&nbsp;if&nbsp;this&nbsp;does&nbsp;happen. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(values)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;values.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Whoever&nbsp;was&nbsp;loading&nbsp;%s&nbsp;failed;&nbsp;we&#39;ll&nbsp;try&nbsp;it&nbsp;ourselves&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.add(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.add(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;If&nbsp;we&nbsp;got&nbsp;here,&nbsp;we&nbsp;have&nbsp;to&nbsp;load&nbsp;the&nbsp;split &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Partition&nbsp;%s&nbsp;not&nbsp;found,&nbsp;computing&nbsp;it&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;computedValues&nbsp;=&nbsp;rdd.computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Persist&nbsp;the&nbsp;result,&nbsp;so&nbsp;long&nbsp;as&nbsp;the&nbsp;task&nbsp;is&nbsp;not&nbsp;running&nbsp;locally &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(context.runningLocally)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;elements&nbsp;=&nbsp;new&nbsp;ArrayBuffer[Any] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elements++&nbsp;=&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManager.put(key,&nbsp;elements,&nbsp;storageLevel,&nbsp;true) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;elements.iterator.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.remove(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.notifyAll() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 这样 RDD 的 transformation、action 就和 block 数据建立了联系，虽然抽象上我们的操作是在 partition 层面上进行的，但是 partitio n最终还是被映射成为 block，因此实际上我们的所有操作都是对 block 的处理和存取。 11.8 partition 和 block 的对应关系 在 RDD 中，核心的函数是 iterator： final&nbsp;def&nbsp;iterator(split:&nbsp;Partition,&nbsp;context:&nbsp;TaskContext):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparkEnv.get.cacheManager.getOrCompute(this,&nbsp;split,&nbsp;context,&nbsp;storageLevel) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;} } 如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute 函数计算 RDD，在这个函数中 partition 和 block 就对应起来了：   getOrCompute 函数会先构造 RDDBlockId，其中 RDDBlockId 就把 block 和 partition 联系起来了，RDDBlockId 产生的 name 就是 BlockId 的 name 属性，形式是：rdd_rdd.id_partition.index。 def&nbsp;getOrCompute[T]( rdd:&nbsp;RDD[T], partition:&nbsp;Partition, context:&nbsp;TaskContext, storageLevel:&nbsp;StorageLevel):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;key&nbsp;=&nbsp;RDDBlockId(rdd.id,&nbsp;partition.index) &nbsp;&nbsp;&nbsp;&nbsp;logDebug(s&quot;Looking&nbsp;for&nbsp;partition&nbsp;$key&quot;) &nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(blockResult)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;existingMetrics&nbsp;=&nbsp;context.taskMetrics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.getInputMetricsForReadMethod(blockResult.readMethod) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;existingMetrics.incBytesRead(blockResult.bytes) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;iter&nbsp;=&nbsp;blockResult.data.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;InterruptibleIterator[T](context,&nbsp;iter)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;next():&nbsp;T&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;existingMetrics.incRecordsRead(1) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delegate.next() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;storedValues&nbsp;=&nbsp;acquireLockForPartition[T](key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storedValues.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;new&nbsp;InterruptibleIterator[T](context,&nbsp;storedValues.get) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(s&quot;Partition&nbsp;$key&nbsp;not&nbsp;found,&nbsp;computing&nbsp;it&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;computedValues&nbsp;=&nbsp;rdd.computeOrReadCheckpoint(partition,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(context.isRunningLocally)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;updatedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;cachedValues&nbsp;=&nbsp;putInBlockManager(key,&nbsp;computedValues,&nbsp;storageLevel,&nbsp;updatedBlocks) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;metrics&nbsp;=&nbsp;context.taskMetrics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;lastUpdatedBlocks&nbsp;=&nbsp;metrics.updatedBlocks.getOrElse(Seq[(BlockId,&nbsp;BlockStatus)]()) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metrics.updatedBlocks&nbsp;=&nbsp;Some(lastUpdatedBlocks&nbsp;++&nbsp;updatedBlocks.toSeq) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;InterruptibleIterator(context,&nbsp;cachedValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.remove(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.notifyAll() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 同时 getOrCompute 函数会对 block 进行判断：   如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。   如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的block，并将其存储到 BlockManager 中。   需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。 回到顶部 第12章 Spark Shuffle 过程 12.1 MapReduce 的 Shuffle 过程介绍   Shuffle 的本义是洗牌、混洗，把一组有一定规则的数据尽量转换成一组无规则的数据，越随机越好。MapReduce 中的 Shuffle 更像是洗牌的逆过程，把一组无规则的数据尽量转换成一组具有一定规则的数据。   为什么 MapReduce 计算模型需要 Shuffle 过程？我们都知道 MapReduce 计算模型一般包括两个重要的阶段：Map 是映射，负责数据的过滤分发；Reduce 是规约，负责数据的计算归并。Reduce 的数据来源于 Map，Map 的输出即是 Reduce 的输入，Reduce 需要通过 Shuffle来 获取数据。   从 Map 输出到 Reduce 输入的整个过程可以广义地称为 Shuffle。Shuffle 横跨 Map 端和 Reduce 端，在 Map 端包括 Spill 过程，在 Reduce 端包括 copy 和 sort 过程，如图所示：    12.1.1 Spill 过程(刷写过程)   Spill 过程包括输出、排序、溢写、合并等步骤，如图所示：    Collect   每个 Map 任务不断地以&nbsp;&lt;key, value&gt;&nbsp;对的形式把数据输出到内存中构造的一个环形数据结构中。使用环形数据结构是为了更有效地使用内存空间，在内存中放置尽可能多的数据。   这个数据结构其实就是个字节数组，叫 kvbuffer，名如其义，但是这里面不光放置了&nbsp;&lt;key, value&gt;数据，还放置了一些索引数据，给放置索引数据的区域起了一个 kvmeta 的别名，在 kvbuffer 的一块区域上穿了一个 IntBuffer（字节序采用的是平台自身的字节序）的马甲。&lt;key, value&gt;&nbsp;数据区域和索引数据区域在 kvbuffer 中是相邻不重叠的两个区域，用一个分界点来划分两者，分界点不是亘古不变的，而是每次 Spill 之后都会更新一次。初始的分界点是 0，&lt;key, value&gt;&nbsp;数据的存储方向是向上增长，索引数据的存储方向是向下增长，如图所示：      kvbuffer 的存放指针 bufindex 是一直闷着头地向上增长，比如 bufindex 初始值为 0，一个 Int 型的 key 写完之后，bufindex 增长为 4，一个 Int 型的 value 写完之后，bufindex 增长为 8。   索引是对&nbsp;&lt;key, value&gt;&nbsp;在 kvbuffer 中的索引，是个四元组，包括：value 的起始位置、key 的起始位置、partition 值、value 的长度，占用四个 Int 长度，kvmeta 的存放指针 kvindex 每次都是向下跳四个“格子”，然后再向上一个格子一个格子地填充四元组的数据。比如 Kvindex 初始位置是 -4，当第一个&nbsp;&lt;key, value&gt;&nbsp;写完之后，(kvindex+0) 的位置存放 value 的起始位置、(kvindex+1) 的位置存放 key 的起始位置、(kvindex+2) 的位置存放 partition 的值、(kvindex+3) 的位置存放 value 的长度，然后 kvindex 跳到 -8 位置，等第二个&nbsp;&lt;key, value&gt;&nbsp;和索引写完之后，kvindex 跳到-32 位置。   kvbuffer 的大小虽然可以通过参数设置，但是总共就那么大，&lt;key, value&gt;&nbsp;和索引不断地增加，加着加着，kvbuffer 总有不够用的那天，那怎么办？把数据从内存刷到磁盘上再接着往内存写数据，把 kvbuffer 中的数据刷到磁盘上的过程就叫 Spill，多么明了的叫法，内存中的数据满了就自动地 spill 到具有更大空间的磁盘。   关于 Spill 触发的条件，也就是 kvbuffer 用到什么程度开始 Spill，还是要讲究一下的。如果把 kvbuffer 用得死死得，一点缝都不剩的时候再开始 Spill，那 Map 任务就需要等 Spill 完成腾出空间之后才能继续写数据；如果 kvbuffer 只是满到一定程度，比如 80% 的时候就开始 Spill，那在 Spill 的同时，Map 任务还能继续写数据，如果 Spill 够快，Map 可能都不需要为空闲空间而发愁。两利相衡取其大，一般选择后者。   Spill 这个重要的过程是由 Spill 线程承担，Spill 线程从 Map 任务接到“命令”之后就开始正式干活，干的活叫 SortAndSpill，原来不仅仅是 Spill，在 Spill 之前还有个颇具争议性的 Sort。 Sort   先把 kvbuffer 中的数据按照 partition 值和 key 两个关键字升序排序，移动的只是索引数据，排序结果是 kvmeta 中数据按照 partition 为单位聚集在一起，同一 partition 内的按照 key 有序。 Spill   Spill 线程为这次 Spill 过程创建一个磁盘文件：从所有的本地目录中轮询查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out” 的文件。Spill 线程根据排过序的 kvmeta 挨个 partition 的把&nbsp;&lt;key, value&gt;&nbsp;数据吐到这个文件中，一个 partition 对应的数据吐完之后顺序地吐下个 partition，直到把所有的 partition 遍历完。一个 partition 在文件中对应的数据也叫段 (segment)。   所有的 partition 对应的数据都放在这个文件里，虽然是顺序存放的，但是怎么直接知道某个 partition 在这个文件中存放的起始位置呢？强大的索引又出场了。有一个三元组记录某个 partition 对应的数据在这个文件中的索引：起始位置、原始数据长度、压缩之后的数据长度，一个 partition 对应一个三元组。然后把这些索引信息存放在内存中，如果内存中放不下了，后续的索引信息就需要写到磁盘文件中了：从所有的本地目录中轮训查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out.index” 的文件，文件中不光存储了索引数据，还存储了 crc32 的校验数据。(spill12.out.index 不一定在磁盘上创建，如果内存（默认 1M 空间）中能放得下就放在内存中，即使在磁盘上创建了，和 spill12.out 文件也不一定在同一个目录下。)   每一次 Spill 过程就会最少生成一个 out 文件，有时还会生成 index 文件，Spill 的次数也烙印在文件名中。索引文件和数据文件的对应关系如下图所示：      在 Spill 线程如火如荼的进行 SortAndSpill 工作的同时，Map 任务不会因此而停歇，而是一无既往地进行着数据输出。Map 还是把数据写到 kvbuffer 中，那问题就来了：&lt;key, value&gt;&nbsp;只顾着闷头按照 bufindex 指针向上增长，kvmeta 只顾着按照 kvindex 向下增长，是保持指针起始位置不变继续跑呢，还是另谋它路？如果保持指针起始位置不变，很快 bufindex 和 kvindex 就碰头了，碰头之后再重新开始或者移动内存都比较麻烦，不可取。Map 取 kvbuffer 中剩余空间的中间位置，用这个位置设置为新的分界点，bufindex 指针移动到这个分界点，kvindex 移动到这个分界点的 -16 位置，然后两者就可以和谐地按照自己既定的轨迹放置数据了，当 Spill 完成，空间腾出之后，不需要做任何改动继续前进。分界点的转换如下图所示：      Map 任务总要把输出的数据写到磁盘上，即使输出数据量很小在内存中全部能装得下，在最后也会把数据刷到磁盘上。 &nbsp; 12.1.2 Merge      Map 任务如果输出数据量很大，可能会进行好几次 Spill，out 文件和 Index 文件会产生很多，分布在不同的磁盘上。最后把这些文件进行合并的 merge 过程闪亮登场。   Merge 过程怎么知道产生的 Spill 文件都在哪了呢？从所有的本地目录上扫描得到产生的 Spill 文件，然后把路径存储在一个数组里。Merge 过程又怎么知道 Spill 的索引信息呢？没错，也是从所有的本地目录上扫描得到 Index 文件，然后把索引信息存储在一个列表里。到这里，又遇到了一个值得纳闷的地方。在之前 Spill 过程中的时候为什么不直接把这些信息存储在内存中呢，何必又多了这步扫描的操作？特别是 Spill 的索引数据，之前当内存超限之后就把数据写到磁盘，现在又要从磁盘把这些数据读出来，还是需要装到更多的内存中。之所以多此一举，是因为这时 kvbuffer 这个内存大户已经不再使用可以回收，有内存空间来装这些数据了。（对于内存空间较大的土豪来说，用内存来省却这两个 io 步骤还是值得考虑的。） &nbsp;   然后为 merge 过程创建一个叫 file.out 的文件和一个叫 file.out.Index 的文件用来存储最终的输出和索引。   一个 partition 一个 partition 的进行合并输出。对于某个 partition 来说，从索引列表中查询这个 partition 对应的所有索引信息，每个对应一个段插入到段列表中。也就是这个 partition 对应一个段列表，记录所有的 Spill 文件中对应的这个 partition 那段数据的文件名、起始位置、长度等等。   然后对这个 partition 对应的所有的 segment 进行合并，目标是合并成一个 segment。当这个 partition 对应很多个 segment 时，会分批地进行合并：先从 segment 列表中把第一批取出来，以 key 为关键字放置成最小堆，然后从最小堆中每次取出最小的&nbsp;&lt;key, value&gt;&nbsp;输出到一个临时文件中，这样就把这一批段合并成一个临时的段，把它加回到 segment 列表中；再从 segment 列表中把第二批取出来合并输出到一个临时 segment，把其加入到列表中；这样往复执行，直到剩下的段是一批，输出到最终的文件中。   最终的索引数据仍然输出到 Index 文件中。   Map 端的 Shuffle 过程到此结束。 12.1.3 Copy   Reduce 任务通过 HTTP 向各个 Map 任务拖取它所需要的数据。每个节点都会启动一个常驻的 HTTP server，其中一项服务就是响应 Reduce 拖取 Map 数据。当有 MapOutput 的 HTTP 请求过来的时候，HTTP server 就读取相应的 Map 输出文件中对应这个 Reduce 部分的数据通过网络流输出给 Reduce。   Reduce 任务拖取某个 Map 对应的数据，如果在内存中能放得下这次数据的话就直接把数据写到内存中。Reduce 要向每个 Map 去拖取数据，在内存中每个 Map 对应一块数据，当内存中存储的 Map 数据占用空间达到一定程度的时候，开始启动内存中 merge，把内存中的数据 merge 输出到磁盘上一个文件中。   如果在内存中不能放得下这个 Map 的数据的话，直接把 Map 数据写到磁盘上，在本地目录创建一个文件，从 HTTP 流中读取数据然后写到磁盘，使用的缓存区大小是 64K。拖一个 Map 数据过来就会创建一个文件，当文件数量达到一定阈值时，开始启动磁盘文件 merge，把这些文件合并输出到一个文件。   有些 Map 的数据较小是可以放在内存中的，有些 Map 的数据较大需要放在磁盘上，这样最后 Reduce 任务拖过来的数据有些放在内存中了有些放在磁盘上，最后会对这些来一个全局合并。 12.1.4 Merge Sort   这里使用的 Merge 和 Map 端使用的 Merge 过程一样。Map 的输出数据已经是有序的，Merge 进行一次合并排序，所谓 Reduce 端的 sort 过程就是这个合并的过程。一般 Reduce 是一边 copy 一边 sort，即 copy 和 sort 两个阶段是重叠而不是完全分开的。   Reduce 端的 Shuffle 过程至此结束。 12.2 HashShuffle 过程介绍   Spark 丰富了任务类型，有些任务之间数据流转不需要通过 Shuffle，但是有些任务之间还是需要通过 Shuffle 来传递数据，比如 wide dependency 的 group by key。   Spark 中需要 Shuffle 输出的 Map 任务会为每个 Reduce 创建对应的 bucket，Map 产生的结果会根据设置的 partitioner 得到对应的 bucketId，然后填充到相应的 bucket 中去。每个 Map 的输出结果可能包含所有的 Reduce 所需要的数据，所以每个 Map 会创建 R 个 bucket（R 是 reduce 的个数），M 个 Map 总共会创建 M*R 个 bucket。   Map 创建的 bucket 其实对应磁盘上的一个文件，Map 的结果写到每个 bucket 中其实就是写到那个磁盘文件中，这个文件也被称为 blockFile，是 Disk Block Manager 管理器通过文件名的 Hash 值对应到本地目录的子目录中创建的。每个 Map 要在节点上创建 R 个磁盘文件用于结果输出，Map 的结果是直接输出到磁盘文件上的，100KB 的内存缓冲是用来创建 Fast Buffered OutputStream 输出流。这种方式一个问题就是 Shuffle 文件过多。      1）每一个 Mapper 创建出和 Reducer 数目相同的 bucket，bucket 实际上是一个 buffer，其大小为 spark.shuffle.file.buffer.kb（默认 32KB）。   2）Mapper 产生的结果会根据设置的 partition 算法填充到每个 bucket 中去，然后再写入到磁盘文件。   3）Reducer 从远端或是本地的 block manager 中找到相应的文件读取数据。 &nbsp;   针对上述 Shuffle 过程产生的文件过多问题，Spark 有另外一种改进的 Shuffle 过程：consolidation Shuffle，以期显著减少 Shuffle 文件的数量。在 consolidation Shuffle 中每个 bucket 并非对应一个文件，而是对应文件中的一个 segment 部分。Job 的 map 在某个节点上第一次执行，为每个 reduce 创建 bucke 对应的输出文件，把这些文件组织成&nbsp;ShuffleFileGroup，当这次 map 执行完之后，这个 ShuffleFileGroup 可以释放为下次循环利用；当又有 map 在这个节点上执行时，不需要创建新的 bucket 文件，而是在上次的 ShuffleFileGroup 中取得已经创建的文件继续追加写一个 segment；当前次 map 还没执行完，ShuffleFileGroup 还没有释放，这时如果有新的 map 在这个节点上执行，无法循环利用这个 ShuffleFileGroup，而是只能创建新的 bucket 文件组成新的 ShuffleFileGroup 来写输出。      比如一个 Job 有 3 个 Map 和 2 个 reduce：   (1) 如果此时集群有 3 个节点有空槽，每个节点空闲了一个 core，则 3 个 Map 会调度到这 3 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，总共创建 6 个 Shuffle 文件；   (2) 如果此时集群有 2 个节点有空槽，每个节点空闲了一个 core，则 2 个 Map 先调度到这 2 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，然后其中一个节点执行完 Map 之后又调度执行另一个 Map，则这个 Map 不会创建新的 Shuffle 文件，而是把结果输出追加到之前 Map 创建的 Shuffle 文件中；总共创建 4 个 Shuffle 文件；   (3) 如果此时集群有 2 个节点有空槽，一个节点有 2 个空 core 一个节点有 1 个空 core，则一个节点调度 2 个 Map 一个节点调度 1 个 Map，调度 2 个 Map 的节点上，一个 Map 创建了 Shuffle 文件，后面的 Map 还是会创建新的 Shuffle 文件，因为上一个 Map 还正在写，它创建的 ShuffleFileGroup 还没有释放；总共创建 6 个 Shuffle 文件。优点：   1）快-不需要排序，也不需要维持 hash 表   2）不需要额外空间用作排序   3）不需要额外IO-数据写入磁盘只需一次，读取也只需一次缺点：   1）当 partitions 大时，输出大量的文件（cores * R），性能开始降低   2）大量的文件写入，使文件系统开始变为随机写，性能比顺序写要降低 100 倍   3）缓存空间占用比较大   Reduce 去拖 Map 的输出数据，Spark 提供了两套不同的拉取数据框架：通过 socket 连接去取数据；使用n etty 框架去取数据。   每个节点的 Executor 会创建一个 BlockManager，其中会创建一个 BlockManagerWorker 用于响应请求。当 Reduce 的 GET_BLOCK 的请求过来时，读取本地文件将这个 blockId 的数据返回给 Reduce。如果使用的是 Netty 框架，BlockManager 会创建 ShuffleSender 用于发送 Shuffle 数据。   并不是所有的数据都是通过网络读取，对于在本节点的 Map 数据，Reduce 直接去磁盘上读取而不再通过网络框架。   Reduce 拖过来数据之后以什么方式存储呢？Spark Map 输出的数据没有经过排序，Spark Shuffle 过来的数据也不会进行排序，Spark 认为 Shuffle 过程中的排序不是必须的，并不是所有类型的 Reduce 需要的数据都需要排序，强制地进行排序只会增加 Shuffle 的负担。Reduce 拖过来的数据会放在一个 HashMap 中，HashMap 中存储的也是&nbsp;&lt;key, value&gt;&nbsp;对，key 是 Map 输出的 key，Map 输出对应这个 key 的所有 value 组成 HashMap 的 value。Spark 将 Shuffle 取过来的每一个&nbsp;&lt;key, value&gt;对插入或者更新到 HashMap 中，来一个处理一个。HashMap 全部放在内存中。   Shuffle 取过来的数据全部存放在内存中，对于数据量比较小或者已经在 Map 端做过合并处理的 Shuffle 数据，占用内存空间不会太大，但是对于比如 group by key 这样的操作，Reduce 需要得到 key 对应的所有 value，并将这些 value 组一个数组放在内存中，这样当数据量较大时，就需要较多内存。   当内存不够时，要不就失败，要不就用老办法把内存中的数据移到磁盘上放着。Spark 意识到在处理数据规模远远大于内存空间时所带来的不足，引入了一个具有外部排序的方案。Shuffle 过来的数据先放在内存中，当内存中存储的&nbsp;&lt;key, value&gt;&nbsp;对超过 1000 并且内存使用超过 70% 时，判断节点上可用内存如果还足够，则把内存缓冲区大小翻倍，如果可用内存不再够了，则把内存中的&nbsp;&lt;key, value&gt;&nbsp;对排序然后写到磁盘文件中。最后把内存缓冲区中的数据排序之后和那些磁盘文件组成一个最小堆，每次从最小堆中读取最小的数据，这个和 MapReduce 中的 merge 过程类似。 12.3 SortShuffle 过程介绍   从 1.2.0 开始默认为 sort shuffle(spark.shuffle.manager = sort)，实现逻辑类似于 Hadoop MapReduce，Hash Shuffle 每一个 reducers 产生一个文件，但是 Sort Shuffle 只是产生一个按照 reducer id 排序可索引的文件，这样，只需获取有关文件中的相关数据块的位置信息，并 fseek 就可以读取指定 reducer 的数据。但对于 rueducer 数比较少的情况，Hash Shuffle 明显要比 Sort Shuffle 快，因此 Sort Shuffle 有个 “fallback” 计划，对于 reducers 数少于 “spark.shuffle.sort.bypassMergeThreshold” (200 by default)，我们使用 fallback 计划，hashing 相关数据到分开的文件，然后合并这些文件为一个，具体实现为 BypassMergeSortShuffleWriter。      在 map 进行排序，在 reduce 端应用 Timsort[1] 进行合并。map 端是否容许 spill，通过 spark.shuffle.spill 来设置，默认是 true。设置为 false，如果没有足够的内存来存储 map 的输出，那么就会导致 OOM 错误，因此要慎用。   用于存储 map 输出的内存为：“JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction，默认为： “JVM Heap Size” * 0.2 * 0.8 = “JVM Heap Size” * 0.16。如果你在同一个执行程序中运行多个线程（设定 spark.executor.cores/ spark.task.cpus 超过 1），每个 map 任务存储的空间为 “JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction / spark.executor.cores * spark.task.cpus，默认 2 个 cores，那么为 0.08 * “JVM Heap Size”。      spark 使用 AppendOnlyMap 存储 map 输出的数据，利用开源 hash 函数 MurmurHash3 和平方探测法把 key 和 value 保存在相同的 array 中。这种保存方法可以是 spark 进行 combine。如果 spill 为 true，会在 spill 前 sort。   与 hash shuffle 相比，sort shuffle 中每个 Mapper 只产生一个数据文件和一个索引文件，数据文件中的数据按照 Reducer 排序，但属于同一个 Reducer 的数据不排序。Mapper 产生的数据先放到 AppendOnlyMap 这个数据结构中，如果内存不够，数据则会 spill 到磁盘，最后合并成一个文件。   与 Hash shuffle 相比，shuffle 文件数量减少，内存使用更加可控。但排序会影响速度。优点：   1）map 创建文件量较少。   2）少量的 IO 随机操作，大部分是顺序读写。缺点：   1）要比 Hash Shuffle 要慢，需要自己通过 spark.shuffle.sort.bypassMergeThreshold 来设置合适的值。   2）如果使用 SSD 盘存储 shuffle 数据，那么 Hash Shuffle 可能更合适。 12.4 TungstenShuffle 过程介绍   Tungsten-sort 算不得一个全新的 shuffle 方案，它在特定场景下基于类似现有的 Sort Based Shuffle 处理流程，对内存 /CPU/Cache 使用做了非常大的优化。带来高效的同时，也就限定了自己的使用场景。如果 Tungsten-sort 发现自己无法处理，则会自动使用 Sort Based Shuffle 进行处理。Tungsten 中文是钨丝的意思。 Tungsten Project 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，该计划初期似乎对 Spark SQL 优化的最多。不过部分 RDD API 还有 Shuffle 也因此受益。Tungsten-sort 优化点主要在三个方面:   1）直接在 serialized binary data 上 sort 而不是 java objects，减少了 memory 的开销和 GC 的 overhead。   2）提供 cache-efficient sorter，使用一个 8bytes 的指针，把排序转化成了一个指针数组的排序。   3）spill 的 merge 过程也无需反序列化即可完成。   这些优化的实现导致引入了一个新的内存管理模型，类似 OS 的 Page，对应的实际数据结构为 MemoryBlock，支持 off-heap 以及 in-heap 两种模式。为了能够对 Record 在这些 MemoryBlock 进行定位，引入了 Pointer（指针）的概念。 如果你还记得 Sort Based Shuffle 里存储数据的对象 PartitionedAppendOnlyMap，这是一个放在 JVM heap 里普通对象，在 Tungsten-sort 中，他被替换成了类似操作系统内存页的对象。如果你无法申请到新的 Page，这个时候就要执行 spill 操作，也就是写入到磁盘的操作。具体触发条件，和 Sort Based Shuffle 也是类似的。   Spark 默认开启的是 Sort Based Shuffle，想要打开 Tungsten-sort，请设置   spark.shuffle.manager=tungsten-sort   对应的实现类是：org.apache.spark.shuffle.unsafe.UnsafeShuffleManager   名字的来源是因为使用了大量 JDK Sun Unsafe API。 当且仅当下面条件都满足时，才会使用新的 Shuffle 方式：   1）Shuffle dependency 不能带有 aggregation 或者输出需要排序   2）Shuffle 的序列化器需要是 KryoSerializer 或者 Spark SQL&#39;s 自定义的一些序列化方式.   3）Shuffle 文件的数量不能大于 16777216。   4）序列化时，单条记录不能大于 128 MB。 可以看到，能使用的条件还是挺苛刻的。 这些限制来源于哪里 参看如下代码，page 的大小：   this.pageSizeBytes = (int) Math.min(PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES,shuffleMemoryManager.pageSizeBytes()); 这就保证了页大小不超过 PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES 的值，该值就被定义成了 128M。 而产生这个限制的具体设计原因，我们还要仔细分析下 Tungsten 的内存模型，如下图所示：    这张图其实画的是 on-heap 的内存逻辑图，其中 #Page 部分为 13bit，Offset 为 51bit，你会发现 2^51 &gt;&gt; 128M 的。但是在 Shuffle 的过程中，对 51bit 做了压缩，使用了 27bit，具体如下：   [24 bit partition number][13 bit memory page number][27 bit offset in page] 这里预留出的 24bi t给了 partition number，为了后面的排序用。上面的好几个限制其实都是因为这个指针引起的：   第一个是 partition 的限制，前面的数字 16777216 就是来源于 partition number 使用 24bit 表示的。   第二个是 page number。   第三个是偏移量，最大能表示到 2^27=128M。那一个 Task 能管理到的内存是受限于这个指针的，最多是 2^13 * 128M 也就是 1TB 左右。 有了这个指针，我们就可以定位和管理到 off-heap 或者 on-heap 里的内存了。这个模型还是很漂亮的，内存管理也非常高效，记得之前的预估 PartitionedAppendOnlyMap 的内存是非常困难的，但是通过现在的内存管理机制，是非常快速并且精确的。 对于第一个限制，那是因为后续 Shuffle Write 的 sort 部分，只对前面 24bit 的 partiton number 进行排序，key 的值没有被编码到这个指针，所以没办法进行 ordering。 同时，因为整个过程是追求不反序列化的，所以不能做 aggregation。 Shuffle Write 核心类：&nbsp;   org.apache.spark.shuffle.unsafe.UnsafeShuffleWriter 数据会通过 UnsafeShuffleExternalSorter.insertRecordIntoSorter 一条一条写入到 serOutputStream 序列化输出流。 这里消耗内存的地方是   serBuffer = new MyByteArrayOutputStream(1024 * 1024) 默认是 1M，类似于 Sort Based Shuffle 中的 ExternalSorter，在 Tungsten Sort 对应的为 UnsafeShuffleExternalSorter，记录序列化后就通过 sorter.insertRecord 方法放到 sorter 里去了。 这里 sorter 负责申请 Page，释放 Page，判断是否要进行 spill 都这个类里完成。代码的架子其实和 Sort Based 是一样的。    (另外，值得注意的是，这张图里进行 spill 操作的同时检查内存可用而导致的 Exeception 的 bug 已经在 1.5.1 版本被修复了，忽略那条路径) 内存是否充足的条件依然 shuffleMemoryManager 来决定，也就是所有 Task Shuffle 申请的 Page 内存总和不能大于下面的值：   ExecutorHeapMemeory * 0.2 * 0.8 上面的数字可通过下面两个配置来更改：   spark.shuffle.memoryFraction=0.2   spark.shuffle.safetyFraction=0.8 UnsafeShuffleExternalSorter 负责申请内存，并且会生成该条记录最后的逻辑地址，也就前面提到的 Pointer。 接着 Record 会继续流转到 UnsafeShuffleInMemorySorter 中，这个对象维护了一个指针数组：   private long[] pointerArray; 数组的初始大小为 4096，后续如果不够了，则按每次两倍大小进行扩充。 假设 100 万条记录，那么该数组大约是 8M 左右，所以其实还是很小的。一旦 spill 后该 UnsafeShuffleInMemorySorter 就会被赋为 null，被回收掉。 我们回过头来看 spill，其实逻辑上也异常简单了，UnsafeShuffleInMemorySorter 会返回一个迭代器，该迭代器粒度每个元素就是一个指针，然后到根据该指针可以拿到真实的 record，然后写入到磁盘，因为这些 record 在一开始进入 UnsafeShuffleExternalSorter 就已经被序列化了，所以在这里就纯粹变成写字节数组了。形成的结构依然和 Sort Based Shuffle 一致，一个文件里不同的 partiton 的数据用 fileSegment 来表示，对应的信息存在一个 index 文件里。 另外写文件的时候也需要一个 buffer：   spark.shuffle.file.buffer=32k 另外从内存里拿到数据放到 DiskWriter，这中间还要有个中转，是通过：   final byte[] writeBuffer = new byte[DISK_WRITE_BUFFER_SIZE=1024 * 1024]; 来完成的，都是内存，所以很快。 Task 结束前，我们要做一次 mergeSpills 操作，然后形成一个 shuffle 文件。这里面其实也挺复杂的， 如果开启了   spark.shuffle.unsafe.fastMergeEnabled=true 并且没有开启&nbsp;   spark.shuffle.compress=true 或者压缩方式为：   LZFCompressionCodec 则可以非常高效的进行合并，叫做 transferTo。不过无论是什么合并，都不需要进行反序列化。 Shuffle Read Shuffle Read 完全复用 HashShuffleReader，具体参看 Sort-Based Shuffle。 12.5 MapReduce 与 Spark 过程对比 MapReduce 和 Spark 的 Shuffle 过程对比如下： 回到顶部 第13章 Spark 内存管理   Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文中阐述的原理基于 Spark 2.1 版本。&nbsp;   在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业（Job），并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。 13.1 堆内和堆外内存规划   作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。堆内和堆外内存示意图如下： 13.1.1 堆内内存   堆内内存的大小，由 Spark 应用程序启动时的&nbsp;-executor-memory&nbsp;或&nbsp;spark.executor.memory参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同（下面第 2 小节会进行介绍）。   Spark 对堆内内存的管理是一种逻辑上的规划式的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存，我们来看其具体流程：申请内存：   1）Spark 在代码中 new 一个对象实例   2）JVM 从堆内内存分配空间，创建对象并返回对象引用   3）Spark 保存该对象的引用，记录该对象占用的内存释放内存：   1）Spark 记录该对象释放的内存，删除该对象的引用   2）等待 JVM 的垃圾回收机制释放该对象占用的堆内内存   我们知道，JVM 的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转化为连续空间或块存储，在访问时则需要进行序列化的逆过程--反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。   对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。   虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。 13.1.2 堆外内存   为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。   在默认情况下堆外内存并不启用，可通过配置&nbsp;spark.memory.offHeap.enabled&nbsp;参数启用，并由&nbsp;spark.memory.offHeap.size&nbsp;参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。 13.1.3 内存管理接口   Spark 为存储内存和执行内存的管理提供了统一的接口--MemoryManager，同一个 Executor 内的任务都调用这个接口的方法来申请或释放内存: 内存管理接口的主要方法： //&nbsp;申请存储内存 def&nbsp;acquireStorageMemory(blockId:&nbsp;BlockId,&nbsp;numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Boolean //&nbsp;申请展开内存 def&nbsp;acquireUnrollMemory(blockId:&nbsp;BlockId,&nbsp;numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Boolean //&nbsp;申请执行内存 def&nbsp;acquireExecutionMemory(numBytes:&nbsp;Long,&nbsp;taskAttemptId:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Long //&nbsp;释放存储内存 def&nbsp;releaseStorageMemory(numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit //&nbsp;释放执行内存 def&nbsp;releaseExecutionMemory(numBytes:&nbsp;Long,&nbsp;taskAttemptId:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit //&nbsp;释放展开内存 def&nbsp;releaseUnrollMemory(numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit Spark的内存管理 – 内存管理接口   我们看到，在调用这些方法时都需要指定其内存模式（MemoryMode），这个参数决定了是在堆内还是堆外完成这次操作。MemoryManager 的具体实现上，Spark 1.6 之后默认为统一管理（Unified Memory Manager）方式，1.6 之前采用的静态管理（Static Memory Manager）方式仍被保留，可通过配置&nbsp;spark.memory.useLegacyMode&nbsp;参数启用。两种方式的区别在于对空间分配的方式，下面的第 2 小节会分别对这两种方式进行介绍。 13.2 内存空间分配 13.2.1 静态内存管理   在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。 静态内存管理图示--堆内 可以看到，可用的堆内内存的大小需要按照下面的方式计算： 可用堆内内存空间： 可用的存储内存&nbsp;=&nbsp;systemMaxMemory&nbsp;*&nbsp;spark.storage.memoryFraction&nbsp;*&nbsp;spark.storage.safetyFraction 可用的执行内存&nbsp;=&nbsp;systemMaxMemory&nbsp;*&nbsp;spark.shuffle.memoryFraction&nbsp;*&nbsp;spark.shuffle.safetyFraction   其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和 “其它内存” 一样交给了 JVM 去管理。   堆外的空间分配较为简单，只有存储内存和执行内存，如下图所示。可用的执行内存和存储内存占用的空间大小直接由参数&nbsp;spark.memory.storageFraction&nbsp;决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。 静态内存管理图示--堆外   静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成 “一半海水，一半火焰” 的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。 13.2.2 统一内存管理   Spark 1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域。 统一内存管理图示--堆内 统一内存管理图示--堆外 其中最重要的优化在于动态占用机制，其规则如下：   1）设定基本的存储内存和执行内存区域（spark.storage.storageFraction&nbsp;参数），该设定确定了双方各自拥有的空间的范围。   2）双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block）。   3）执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后 “归还” 借用的空间。   4）存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。 动态占用机制图示   凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护 Spark 内存的难度，但并不意味着开发者可以高枕无忧。譬如，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的 RDD 数据通常都是长期驻留内存的。所以要想充分发挥 Spark 的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。 13.3 存储内存管理 13.3.1 RDD 的持久化机制   弹性分布式数据集（RDD）作为 Spark 最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换（Transformation）操作产生一个新的 RDD。转换后的 RDD 与原始的 RDD 之间产生的依赖关系，构成了血统（Lineage）。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。但 RDD 的所有转换都是惰性的，即只有当一个返回结果给 Driver 的行动（Action）发生时，Spark 才会创建任务读取 RDD，然后真正触发转换的执行。   Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 上要执行多次行动，可以在第一次行动中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。事实上，cache 方法是使用默认的 MEMORY_ONLY 的存储级别将 RDD 持久化到内存，故缓存是一种特殊的持久化。堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理（存储内存的其他应用场景，如缓存 broadcast 数据，暂时不在本文的讨论范围之内）。   RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来。在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD。 Storage 模块示意图 在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY、MEMORY_AND_DISK 等 7 种不同的 存储级别，而存储级别是以下 5 个变量的组合： 存储级别 class&nbsp;StorageLevel&nbsp;private( &nbsp;&nbsp;private&nbsp;var&nbsp;_useDisk:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;磁盘 &nbsp;&nbsp;private&nbsp;var&nbsp;_useMemory:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;这里其实是指堆内内存 &nbsp;&nbsp;private&nbsp;var&nbsp;_useOffHeap:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;堆外内存 &nbsp;&nbsp;private&nbsp;var&nbsp;_deserialized:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;//&nbsp;是否为非序列化 &nbsp;&nbsp;private&nbsp;var&nbsp;_replication:&nbsp;Int&nbsp;=&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;副本个数 ) 通过对数据结构的分析，可以看出存储级别从三个维度定义了 RDD 的 Partition（同时也就是 Block）的存储方式： &nbsp;&nbsp;&nbsp;&nbsp;1）存储位置：磁盘／堆内内存／堆外内存。如&nbsp;MEMORY_AND_DISK&nbsp;是同时在磁盘和堆内内存上存储，实现了冗余备份。OFF_HEAP&nbsp;则是只在堆外内存存储，目前选择堆外内存时不能同时存储到其他位置。 &nbsp;&nbsp;&nbsp;&nbsp;2）存储形式：Block&nbsp;缓存到存储内存后，是否为非序列化的形式。如&nbsp;MEMORY_ONLY&nbsp;是非序列化方式存储，OFF_HEAP&nbsp;是序列化方式存储。 &nbsp;&nbsp;&nbsp;&nbsp;3）副本数量：大于&nbsp;1&nbsp;时需要远程冗余备份到其他节点。如&nbsp;DISK_ONLY_2&nbsp;需要远程备份&nbsp;1&nbsp;个副本。 13.3.2 RDD 缓存的过程   RDD 在缓存到存储内存之前，Partition 中的数据一般以迭代器（Iterator）的数据结构来访问，这是 Scala 语言中一种遍历数据集合的方法。通过 Iterator 可以获取分区中每一条序列化或者非序列化的数据项 (Record)，这些 Record 的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同 Record 的空间并不连续。   RDD 在缓存到存储内存之后，Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为 “展开”（Unroll）。Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 以一种 DeserializedMemoryEntry 的数据结构定义，用一个数组存储所有的对象实例，序列化的 Block 则以 SerializedMemoryEntry 的数据结构定义，用字节缓冲区（ByteBuffer）来存储二进制数据。每个 Executor 的 Storage 模块用一个链式 Map 结构（LinkedHashMap）来管理堆内和堆外存储内存中所有的 Block 对象的实例，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。   因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。而非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。如果最终 Unroll 成功，当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间，如下图所示。 Spark Unroll 示意图   在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，当存储空间不足时会根据动态占用机制进行处理。 13.3.3 淘汰和落盘   由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中的旧 Block 进行淘汰（Eviction），而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘（Drop），否则直接删除该 Block。   存储内存的淘汰规则为：   1）被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存。   2）新旧 Block 不能属于同一个 RDD，避免循环淘汰。   3）旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题。   4）遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性。   落盘的流程则比较简单，如果其存储级别符合_useDisk 为 true&nbsp;的条件，再根据其&nbsp;_deserialized&nbsp;判断是否是非序列化的形式，若是则对其进行序列化，最后将数据存储到磁盘，在 Storage 模块中更新其信息。 13.4 执行内存管理 13.4.1 多任务间内存分配   Executor 内运行的任务同样共享执行内存，Spark 用一个 HashMap 结构保存了任务到内存耗费的映射。每个任务可占用的执行内存大小的范围为 1/2N ~ 1/N，其中 N 为当前 Executor 内正在运行的任务的个数。每个任务在启动之时，要向 MemoryManager 请求申请最少为 1/2N 的执行内存，如果不能被满足要求则该任务被阻塞，直到有其他任务释放了足够的执行内存，该任务才可以被唤醒。 13.4.2 Shuffle 的内存占用   执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程，我们来看 Shuffle 的 Write 和 Read 两阶段对执行内存的使用：Shuffle Write   1）若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。   2）若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够。Shuffle Read   1）在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间。   2）如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter 处理，占用堆内执行空间。   在 ExternalSorter 和 Aggregator 中，Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据，但在 Shuffle 过程中所有数据并不能都保存到该哈希表中，当这个哈希表占用的内存会进行周期性地采样估算，当其大到一定程度，无法再从 MemoryManager 申请到新的执行内存时，Spark 就会将其全部内容存储到磁盘文件中，这个过程被称为溢存(Spill)，溢存到磁盘的文件最后会被归并(Merge)。   Shuffle Write 阶段中用到的 Tungsten 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，解决了一些 JVM 在性能上的限制和弊端。Spark 会根据 Shuffle 的情况来自动选择是否采用 Tungsten 排序。Tungsten 采用的页式内存管理机制建立在 MemoryManager 之上，即 Tungsten 对执行内存的使用进行了一步的抽象，这样在 Shuffle 过程中无需关心数据具体存储在堆内还是堆外。每个内存页用一个 MemoryBlock 来定义，并用 Object obj 和 long offset 这两个变量统一标识一个内存页在系统内存中的地址。堆内的 MemoryBlock 是以 long 型数组的形式分配的内存，其 obj 的值为是这个数组的对象引用，offset 是 long 型数组的在 JVM 中的初始偏移地址，两者配合使用可以定位这个数组在堆内的绝对地址；堆外的 MemoryBlock 是直接申请到的内存块，其 obj 为 null，offset 是这个内存块在系统内存中的 64 位绝对地址。Spark 用 MemoryBlock 巧妙地将堆内和堆外内存页统一抽象封装，并用页表(pageTable)管理每个 Task 申请到的内存页。   Tungsten 页式管理下的所有内存用 64 位的逻辑地址表示，由页号和页内偏移量组成：   页号：占 13 位，唯一标识一个内存页，Spark 在申请内存页之前要先申请空闲页号。   页内偏移量：占 51 位，是在使用内存页存储数据时，数据在页内的偏移地址。   有了统一的寻址方式，Spark 可以用 64 位逻辑地址的指针定位到堆内或堆外的内存，整个 Shuffle Write 排序的过程只需要对指针进行排序，并且无需反序列化，整个过程非常高效，对于内存访问效率和 CPU 使用效率带来了明显的提升。   Spark 的存储内存和执行内存有着截然不同的管理方式：对于存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；而对于执行内存，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。 回到顶部 第14章 部署模式解析 14.1 部署模式概述   Spark 支持的主要的三种分布式部署方式分别是 standalone、spark on mesos 和 spark on YARN。standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。它是 Spark 实现的资源调度框架，其主要的节点有 Client 节点、Master 节点和 Worker 节点。而 yarn 是统一的资源管理机制，在上面可以运行多套计算框架，如 map reduce、storm 等根据 driver 在集群中的位置不同，分为 yarn client 和 yarn cluster。而 mesos 是一个更强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括 yarn。基本上，Spark 的运行模式取决于传递给 SparkContext 的 MASTER 环境变量的值，个别模式还需要辅助的程序接口来配合使用，目前支持的 Master 字符串及 URL 包括：      用户在提交任务给 Spark 处理时，以下两个参数共同决定了 Spark 的运行方式：   • --master MASTER_URL ：决定了 Spark 任务提交给哪种集群处理。   • --deploy-mode DEPLOY_MODE ：决定了 Driver 的运行方式，可选值为 Client 或者 Cluster。 &nbsp; 14.2 standalone 框架   standalone 集群由三个不同级别的节点组成，分别是：   1）Master 主控节点，可以类比为董事长或总舵主，在整个集群之中，最多只有一个 Master 处在 Active 状态。   2）Worker 工作节点，这个是 manager，是分舵主， 在整个集群中，可以有多个 Worker，如果 Worker 为零，什么事也做不了。   3）Executor 干苦力活的，直接受 Worker 掌控，一个 Worker 可以启动多个 executor，启动的个数受限于机器中的 cpu 核数。   这三种不同类型的节点各自运行于自己的JVM进程之中。   Standalone 模式下，集群启动时包括 Master 与 Worker，其中 Master 负责接收客户端提交的作业，管理 Worker。根据作业提交的方式不同，分为 driver on client 和 drvier on worker。如下图所示，上图为 driver on client 模式，下图为 driver on work 模式。两种模式的主要不同点在于 driver 所在的位置。   在 standalone 部署模式下又分为 client 模式和 cluster 模式。   在client 模式下，driver 和 client 运行于同一 JVM 中，不由 worker 启动，该 JVM 进程直到 spark application 计算完成返回结果后才退出。如下图所示：      而在 cluster 模式下，driver 由 worker 启动，client 在确认 spark application 成功提交给 cluster 后直接退出，并不等待 spark application 运行结果返回。如下图所示：    从部署图来进行分析，每个 JVM 进程在启动时的文件依赖如何得到满足。   1）Master 进程最为简单，除了 spark jar 包之外，不存在第三方库依赖。   2）Driver 和 Executor 在运行的时候都有可能存在第三方包依赖，分开来讲。   3）Driver 比较简单，spark-submit 在提交的时候会指定所要依赖的 jar 文件从哪里读取。   4）Executor 由 Worker 来启动，Worker 需要下载 Executor 启动时所需要的 jar 文件，那么从哪里下载呢？   Spark Standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖其他资源管理系统。在该模式下，用户可以通过手动启动 Master 和 Worker 来启动一个独立的集群。其中，Master 充当了资源管理的角色，Workder 充当了计算节点的角色。在该模式下，Spark Driver 程序在客户端(Client)运行，而 Executor 则在 Worker 节点上运行。以下是一个运行在 Standalone 模式下，包含一个 Master 节点，两个 Worker 节点的 Spark 任务调度交互部署架构图。 从上面的 Spark 任务调度过程可以看到：   1）整个集群分为 Master 节点和 Worker 节点，其 Driver 程序运行在客户端。Master 节点负责为任务分配 Worker 节点上的计算资源，两者会通过相互通信来同步资源状态，见途中红色双向箭头。   2）客户端启动任务后会运行 Driver 程序，Driver 程序中会完成 SparkContext 对象的初始化，并向 Master 进行注册。   3）每个 Workder 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟客户端节点上的 Driver 程序进行通信，上报任务状态。 &nbsp; 14.2.1 Standalone 模式下任务运行过程   上面的过程反映了 Spark 在 standalone 模式下，整体上客户端、Master 和 Workder 节点之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。1）&nbsp;用户通过 bin/spark-submit 部署工具或者 bin/spark-class 启动应用程序的 Driver 进程，Driver 进程会初始化 SparkContext 对象，并向 Master 节点进行注册。   • 1、Master 节点接受 Driver 程序的注册，检查它所管理的 Worker 节点，为该 Driver 程序分配需要的计算资源 Executor。Worker 节点完成 Executor 的分配后，向 Master 报告 Executor 的状态。   • 2、Worker 节点上的 ExecutorBackend 进程启动后，向 Driver 进程注册。2）&nbsp;Driver 进程内部通过 DAG Schaduler、Stage Schaduler、Task Schaduler 等过程完成任务的划分后，向 Worker 节点上的 ExecutorBackend 分配 TASK。   • 1、ExecutorBackend 进行 TASK 计算，并向 Driver 报告 TASK 状态，直至结束。   • 2、Driver 进程在所有 TASK 都处理完成后，向 Master 注销。 14.2.2 总结   Spark 能够以 standalone 模式运行，这是 Spark 自身提供的运行模式，用户可以通过手动启动 master 和 worker 进程来启动一个独立的集群，也可以在一台机器上运行这些守护进程进行测试。standalone 模式可以用在生产环境，它有效的降低了用户学习、测试 Spark 框架的成本。   standalone 模式目前只支持跨应用程序的简单 FIFO 调度。然而，为了允许多个并发用户，你可以控制每个应用使用的资源的最大数。默认情况下，它会请求使用集群的全部 CUP 内核。   缺省情况下，standalone 任务调度允许 worker 的失败（在这种情况下它可以将失败的任务转移给其他的 worker）。但是，调度器使用 master 来做调度，这会产生一个单点问题：如果 master 崩溃，新的应用不会被创建。为了解决这个问题，可以通过 zookeeper 的选举机制在集群中启动多个 master，也可以使用本地文件实现单节点恢复。 14.3 yarn 集群模式   Apache yarn 是 apache Hadoop 开源项目的一部分。设计之初是为了解决 mapreduce 计算框架资源管理的问题。到 haodoop 2.0 使用 yarn 将 mapreduce 的分布式计算和资源管理区分开来。它的引入使得 Hadoop 分布式计算系统进入了平台化时代，即各种计算框架可以运行在一个集群中，由资源管理系统 YRAN 进行统一的管理和调度，从而共享整个集群资源、提高资源利用率。   YARN 总体上也 Master/Slave 架构--ResourceManager/NodeManager。前者(RM)负责对各个 NodeManager(NM) 上的资源进行统一管理和调度。而 Container 是资源分配和调度的基本单位，其中封装了机器资源，如内存、CPU、磁盘和网络等，每个任务会被分配一个 Container，该任务只能在该 Container 中执行，并使用该 Container 封装的资源。NodeManager 的作用则是负责接收并启动应用的 Container、而向 RM 回报本节点上的应用 Container 运行状态和资源使用情况。ApplicationMaster 与具体的 Application 相关，主要负责同 ResourceManager 协商以获取合适的 Container，并跟踪这些 Container 的状态和监控其进度。如下图所示为 yarn 集群的一般模型。 简单架构图如下：    详细架构图如下：      Spark 在 yarn 集群上的部署方式分为两种，yarn cluster（driver 运行在 master 上）和 yarn client（driver 运行在 client 上）。   driver on master&nbsp;如下图所示：      • (1) Spark Yarn Client 向 YARN 中提交应用程序，包括 Application Master 程序、启动 Application Master 的命令、需要在 Executor 中运行的程序等。   • (2) Resource manager 收到请求后，在其中一个 Node Manager 中为应用程序分配一个 Container，要求它在 Container 中启动应用程序的 Application Master，Application Master 初始化 sparkContext 以及创建 DAG Scheduler 和 Task Scheduler。   • (3) Application Master 根据 SparkContext 中的配置，向 Resource Manager 申请 Container，同时，Application Master 向 Resource Manager 注册，这样用户可通过 Resource Manager 查看应用程序的运行状态。   • (4) Resource Manager 在集群中寻找符合条件的 Node Manager，在 Node Manager 启动 Container，要求 Container 启动 Executor。   • (5) Executor 启动后向 Application Master 注册，并接收 Application Master 分配的 Task。   • (6) 应用程序运行完成后，Application Master 向 Resource Manager 申请注销并关闭自己。   driver on client&nbsp;如下图所示：      • (1) Spark Yarn Client 向 YARN 的 Resource Manager 申请启动 Application Master。同时在 SparkContent 初始化中将创建 DAG Scheduler 和 Task Scheduler 等。   • (2) ResourceManager 收到请求后，在集群中选择一个 NodeManager，为该应用程序分配第一个 Container，要求它在这个 Container 中启动应用程序的 ApplicationMaster，与 YARN-Cluster 区别的是在该 ApplicationMaster 不运行 SparkContext，只与 SparkContext 进行联系进行资源的分派。   • (3) Client 中的 SparkContext 初始化完毕后，与 Application Master 建立通讯，向 Resource Manager 注册，根据任务信息向 Resource Manager 申请资源 (Container)。   • (4) 当 Application Master 申请到资源后，便与 Node Manager 通信，要求它启动 Container。   • (5) Container 启动后向 Driver 中的 SparkContext 注册，并申请 Task。   • (6) 应用程序运行完成后，Client 的 SparkContext 向 ResourceManage r申请注销并关闭自己。 &nbsp;   Yarn-client 和Yarn cluster 模式对比可以看出，在 Yarn-client（Driver on client）中，Application Master 仅仅从 Yarn 中申请资源给 Executor，之后 client 会跟 container 通信进行作业的调度。如果 client 离集群距离较远，建议不要采用此方式，不过此方式有利于交互式的作业。　　      Spark 能够以集群的形式运行，可用的集群管理系统有 Yarn、Mesos 等。集群管理器的核心功能是资源管理和任务调度。以 Yarn 为例，Yarn 以 Master/Slave 模式工作，在 Master 节点运行的是 Resource Manager(RM)，负责管理整个集群的资源和资源分配。在 Slave 节点运行的 Node Manager(NM)，是集群中实际拥有资源的工作节点。我们提交 Job 以后，会将组成 Job 的多个 Task 调度到对应的 Node Manager 上进行执行。另外，在 Node Manager 上将资源以 Container 的形式进行抽象，Container 包括两种资源 内存 和 CPU。   以下是一个运行在 Yarn 集群上，包含一个 Resource Manager 节点，三个 Node Manager 节点(其中，两个是 Worker 节点，一个 Master 节点)的 Spark 任务调度交换部署架构图。　 从上面的Spark任务调度过程图可以看到:   1）整个集群分为 Master 节点和 Worker 节点，它们都存在于 Node Manager 节点上，在客户端提交任务时由 Resource Manager 统一分配，运行 Driver 程序的节点被称为 Master 节点，执行具体任务的节点被称为 Worder 节点。Node Manager 节点上资源的变化都需要及时更新给 Resource Manager，见图中红色双向箭头。   2）Master 节点上常驻 Master 守护进程 -- Driver 程序，Driver 程序中会创建 SparkContext对 象，并负责跟各个 Worker 节点上的 ExecutorBackend 进程进行通信，管理 Worker 节点上的任务，同步任务进度。实际上，在 Yarn 中 Node Manager 之间的关系是平等的，因此 Driver 程序会被调度到任何一个 Node Manager 节点。   3）每个 Worker 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟 Master 节点上的 Driver 程序进行通信，上报任务状态。　　 &nbsp; 集群下任务运行过程   上面的过程反映出了 Spark 在集群模式下，整体上 Resource Manager 和 Node Manager 节点间的交互，Master 和 Worker 之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。   • 1) 用户通过 bin/spark-submit 部署工具或者 bin/spark-class 向 Yarn 集群提交应用程序。   • 2) Yarn 集群的 Resource Manager 为提交的应用程序选择一个 Node Manager 节点并分配第一个 Container，并在该节点的 Container 上启动 SparkContext 对象。   • 3) SparkContext 对象向 Yarn 集群的 Resource Manager 申请资源以运行 Executor。   • 4) Yarn 集群的 Resource Manager 分配 Container 给 SparkContext 对象，SparkContext 和相关的 Node Manager 通讯，在获得的 Container 上启动 ExecutorBackend 守护进程，ExecutorBackend 启动后开始向 SparkContext 注册并申请 Task。   • 5) SparkContext 分配 Task 给 ExecutorBackend 执行。   • 6) ExecutorBackend 开始执行 Task，并及时向 SparkContext 汇报运行状况。Task 运行完毕，SparkContext 归还资源给 Node Manager，并注销退。 14.4 mesos 集群模式   Mesos 是 apache 下的开源分布式资源管理框架。起源于加州大学伯克利分校，后被 Twitter 推广使用。Mesos 上可以部署多种分布式框架，Mesos 的架构图如下图所示，其中 Framework 是指外部的计算框架，如 Hadoop、Mesos 等，这些计算框架可通过注册的方式接入 Mesos，以便 Mesos 进行统一管理和资源分配。      在 Mesos 上运行的 Framework 由两部分组成：一个是 scheduler ，通过注册到 Master 来获取集群资源。另一个是在 Slave 节点上运行的 executor 进程，它可以执行 Framework 的 task 。 Master 决定为每个 Framework 提供多少资源，Framework 的 scheduler 来选择其中提供的资源。当 Framework 同意了提供的资源，它通过 Master 将 task 发送到提供资源的 Slaves 上运行。Mesos c的资源分配图如下图所示：      (1) Slave1 向 Master 报告，有 4 个 CPU 和 4 GB 内存可用。   (2) Master 发送一个 Resource Offer 给 Framework1 来描述 Slave1 有多少可用资源。   (3) FrameWork1 中的 FW Scheduler 会答复 Master，我有两个 Task 需要运行在 Slave1，一个 Task 需要&nbsp;&lt;2个CPU，1 GB内存=&quot;&quot;&gt;，另外一个 Task 需要&nbsp;&lt;1个CPU，2 GB内存=&quot;&quot;&gt;。   (4) 最后，Master 发送这些 Tasks 给 Slave1。然后，Slave1 还有 1 个 CPU 和 1GB 内存没有使用，所以分配模块可以把这些资源提供给 Framework2。 &nbsp;   Spark 可作为其中一个分布式框架部署在 mesos 上，部署图与 mesos 的一般框架部署图类似，如下图所示，这里不再重述。 14.5 spark 三种部署模式的区别   在这三种部署模式中，standalone 作为 spark 自带的分布式部署模式，是最简单也是最基本的 spark 应用程序部署模式，这里就不再赘述。这里就讲一下 yarn 和 mesos 的区别：   (1) 就两种框架本身而言，mesos上可部署 yarn 框架。而 yarn 是更通用的一种部署框架，而且技术较成熟。   (2) mesos 双层调度机制，能支持多种调度模式，而 yarn 通过 Resource　Mananger 管理集群资源，只能使用一种调度模式。Mesos 的双层调度机制为：mesos 可接入如 yarn 一般的分布式部署框架，但 Mesos 要求可接入的框架必须有一个调度器模块，该调度器负责框架内部的任务调度。当一个 Framework 想要接入 mesos 时，需要修改自己的调度器，以便向 mesos 注册，并获取 mesos 分配给自己的资源，这样再由自己的调度器将这些资源分配给框架中的任务，也就是说，整个 mesos 系统采用了双层调度框架：第一层，由 mesos 将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。   (3) mesos 可实现粗、细粒度资源调度，可动态分配资源，而 yarn 只能实现静态资源分配。其中粗粒度和细粒度调度定义如下：   粗粒度模式（Coarse-grained Mode）：程序运行之前就要把所需要的各种资源（每个 executor 占用多少资源，内部可运行多少个 executor）申请好，运行过程中不能改变。   细粒度模式（Fine-grained Mode）：为了防止资源浪费，对资源进行按需分配。与粗粒度模式一样，应用程序启动时，先会启动 executor，但每个 executor 占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos 会为每个 executor 动态分配资源，每分配一些，便可以运行一个新任务，单个 Task 运行完之后可以马上释放对应的资源。每个 Task 会汇报状态给 Mesos Slave 和 Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于 MapReduce 调度模式，每个 Task 完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。   从 yarn 和 mesos 的区别可看出，它们各自有优缺点。因此实际使用中，选择哪种框架，要根据本公司的实际需要而定，可考虑现有的大数据生态环境。如我司采用 yarn 部署 spark，原因是，我司早已有较成熟的 hadoop 的框架，考虑到使用的方便性，采用了 yarn 模式的部署。 14.6 异常场景分析 上面说明的是正常情况下，各节点的消息分发细节。那么如果在运行中，集群中的某些节点出现了问题，整个集群是否还能够正常处理 Application 中的任务呢？ 14.6.1 异常分析1：Worker 异常退出 在 Spark 运行过程中，经常碰到的问题就是 Worker 异常退出，当 Worker 退出时，整个集群会有哪些故事发生呢？请看下面的具体描述：   1）Worker 异常退出，比如说有意识的通过 kill 指令将 Worker 杀死。   2）Worker 在退出之前，会将自己所管控的所有小弟 Executor 全干掉。   3）Worker 需要定期向 Master 改善心跳消息的，现在 Worker 进程都已经玩完了，哪有心跳消息，所以 Master 会在超时处理中意识到有一个 “分舵” 离开了。   4）Master 非常伤心，伤心的 Master 将情况汇报给了相应的 Driver。 Driver 通过两方面确认分配给自己的 Executor 不幸离开了，一是 Master 发送过来的通知，二是 Driver 没有在规定时间内收到 Executor 的 StatusUpdate，于是 Driver 会将注册的 Executor 移除。 后果分析 Worker 异常退出会带来哪些影响：   1）Executor 退出导致提交的 Task 无法正常结束，会被再一次提交运行。   2）如果所有的 Worker 都异常退出，则整个集群不可用。   3）需要有相应的程序来重启 Worker 进程，比如使用 supervisord 或 runit。 测试步骤   1）启动 Master。   2）启动 Worker。   3）启动 spark-shell。   4）手工 kill 掉 Worker 进程。   5）用 jps 或 ps -ef | grep -i java 来查看启动着的 java 进程。 异常退出的代码处理 定义 ExecutorRunner.scala 的 start 函数 def&nbsp;start()&nbsp;{ &nbsp;&nbsp;workerThread&nbsp;=&nbsp;new&nbsp;Thread(&quot;ExecutorRunner&nbsp;for&nbsp;&quot;&nbsp;+&nbsp;fullId)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;run()&nbsp;{&nbsp;fetchAndRunExecutor()&nbsp;} &nbsp;&nbsp;} &nbsp;&nbsp;workerThread.start() &nbsp;&nbsp;//&nbsp;Shutdown&nbsp;hook&nbsp;that&nbsp;kills&nbsp;actors&nbsp;on&nbsp;shutdown. &nbsp;&nbsp;shutdownHook&nbsp;=&nbsp;new&nbsp;Thread()&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;run()&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(Some(&quot;Worker&nbsp;shutting&nbsp;down&quot;)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;} &nbsp;&nbsp;Runtime.getRuntime.addShutdownHook(shutdownHook) } killProcess 的过程就是停止相应 CoarseGrainedExecutorBackend 的过程。 Worker 停止的时候，一定要先将自己启动的 Executor 停止掉。这是不是很像水浒中宋江的手段，李逵就是这样不明不白的把命给丢了。 小结   需要特别指出的是，当 Worker 在启动 Executor 的时候，是通过 ExecutorRunner 来完成的，ExecutorRunner 是一个独立的线程，和 Executor 是一对一的关系，这很重要。Executor 作为一个独立的进程在运行，但会受到 ExecutorRunner 的严密监控。 14.6.2 异常分析2：Executor 异常退出 后果分析 Executor 作为 Standalone 集群部署方式下的最底层员工，一旦异常退出，其后果会是什么呢？   1）Executor 异常退出，ExecutorRunner 注意到异常，将情况通过 ExecutorStateChanged 汇报给 Master。   2）Master 收到通知之后，非常不高兴，尽然有小弟要跑路，那还了得，要求 Executor 所属的 Worker 再次启动。   3）Worker 收到 LaunchExecutor 指令，再次启动 Executor。 测试步骤   1）启动 Master   2）启动 Worker   3）启动 spark-shell   4）手工 kill 掉 CoarseGrainedExecutorBackend fetchAndRunExecutor fetchAndRunExecutor 负责启动具体的 Executor，并监控其运行状态，具体代码逻辑如下所示 def&nbsp;fetchAndRunExecutor()&nbsp;{ &nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;the&nbsp;executor&#39;s&nbsp;working&nbsp;directory &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;executorDir&nbsp;=&nbsp;new&nbsp;File(workDir,&nbsp;appId&nbsp;+&nbsp;&quot;/&quot;&nbsp;+&nbsp;execId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!executorDir.mkdirs())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Failed&nbsp;to&nbsp;create&nbsp;directory&nbsp;&quot;&nbsp;+&nbsp;executorDir) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Launch&nbsp;the&nbsp;process &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;command&nbsp;=&nbsp;getCommandSeq &nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Launch&nbsp;command:&nbsp;&quot;&nbsp;+&nbsp;command.mkString(&quot;\&quot;&quot;,&nbsp;&quot;\&quot;&nbsp;\&quot;&quot;,&nbsp;&quot;\&quot;&quot;)) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;builder&nbsp;=&nbsp;new&nbsp;ProcessBuilder(command:&nbsp;_*).directory(executorDir) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;env&nbsp;=&nbsp;builder.environment() &nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;((key,&nbsp;value)&nbsp;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Runner&nbsp;thread&nbsp;for&nbsp;executor&nbsp;&quot;&nbsp;+&nbsp;fullId&nbsp;+&nbsp;&quot;&nbsp;interrupted&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state&nbsp;=&nbsp;ExecutorState.KILLED &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(None) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;e:&nbsp;Exception&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logError(&quot;Error&nbsp;running&nbsp;executor&quot;,&nbsp;e) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state&nbsp;=&nbsp;ExecutorState.FAILED &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(Some(e.toString)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;} } 14.6.3 异常分析3：Master 异常退出 Worker 和 Executor 异常退出的场景都讲到了，我们剩下最后一种情况了，Master 挂掉了怎么办？ 后果分析 带头大哥如果不在了，会是什么后果呢？   1）Worker 没有汇报的对象了，也就是如果 Executor 再次跑飞，Worker 是不会将 Executor 启动起来的，大哥没给指令。   2）无法向集群提交新的任务。   3）老的任务即便结束了，占用的资源也无法清除，因为资源清除的指令是 Master 发出的。 回到顶部 第15章 wordcount 程序运行原理窥探 15.1 spark 之 scala 实现 wordcount 在 spark 中使用 scala 来实现 wordcount（统计单词出现次数模型）更加简单，相对 java 代码上更加简洁，其函数式编程的思维逻辑也更加直观。 package&nbsp;com.spark.firstApp import&nbsp;org.apache.spark.{SparkContext,&nbsp;SparkConf} /** &nbsp;&nbsp;*&nbsp;scala&nbsp;实现&nbsp;wordcount &nbsp;&nbsp;*/ object&nbsp;WordCount1&nbsp;{ &nbsp;&nbsp;def&nbsp;main(args:&nbsp;Array[String])&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(args.length&nbsp;==&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;System.err.println(&quot;Usage:&nbsp;WordCount1&nbsp;&lt;file1&gt;&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;System.exit(1) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;/** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;1、实例化&nbsp;SparkConf &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;2、构建&nbsp;SparkContext，SparkContext&nbsp;是&nbsp;spark&nbsp;应用程序的唯一入口 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;3.&nbsp;通过&nbsp;SparkContext&nbsp;的&nbsp;textFile&nbsp;方法读取文本文件 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;conf&nbsp;=&nbsp;new&nbsp;SparkConf().setAppName(&quot;WordCount1&quot;).setMaster(&quot;local&quot;) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sc&nbsp;=&nbsp;new&nbsp;SparkContext(conf) &nbsp;&nbsp;&nbsp;&nbsp;/** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;4、通过&nbsp;flatMap&nbsp;对文本中每一行的单词进行拆分（分割符号为空格），并利用&nbsp;map&nbsp;进行函数转换形成&nbsp;(K,V)&nbsp;对形式，再进行&nbsp;reduceByKey，打印输出&nbsp;10&nbsp;个结果 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;&nbsp;&nbsp;&nbsp;函数式编程更加直观的反映思维逻辑 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/ &nbsp;&nbsp;&nbsp;&nbsp;sc.textFile(args(0)).flatMap(_.split(&quot;&nbsp;&quot;)).map(x&nbsp;=&gt;&nbsp;(x,&nbsp;1)).reduceByKey(_&nbsp;+&nbsp;_).take(10).foreach(println) &nbsp;&nbsp;&nbsp;&nbsp;sc.stop() &nbsp;&nbsp;} } 15.2 原理窥探 在 spark 集群中运行 wordcount 程序其主要业务逻辑比较简单，涵盖一下 3 个过程：   1）读取存储介质上的文本文件（一般存储在 hdfs 上）；   2）对文本文件内容进行解析，按照单词进行分组统计汇总；   3）将过程 2 的分组结果保存到存储介质上。（一般存储在 hdfs 或者 RMDB 上） 虽然 wordcount 的业务逻辑非常简单，但其应用程序在 spark 中的运行过程却巧妙得体现了 spark 的核心精髓--分布式弹性数据集、内存迭代以及函数式编程等特点。下图对 spark 集群中 wordcount 的运行过程进行剖析，加深对 spark 技术原理窥探。   该图横向分割下面给出了 wordcount 的 scala 核心程序实现，该程序在 spark 集群的运行过程涉及几个核心的 RDD，主要有 textFileRDD、flatMapRDD、mapToPairRDD、shuffleRDD（reduceByKey）等。   应用程序通过 textFile 方法读取 hdfs 上的文本文件，数据分片的形式以 RDD 为统一模式将数据加载到不同的物理节点上，如上图所示的节点 1、节点 2 到节点 n；并通过一系列的数据转换，如利用 flatMap 将文本文件中对应每行数据进行拆分（文本文件中单词以空格为分割符号），形成一个以每个单词为核心新的数据集合 RDD；之后通过 MapRDD 继续转换形成形成 (K,V) 对 数据形式，以便进一步使用 reduceByKey 方法，该方法会触发 shuffle 行为，促使不同的单词到对应的节点上进行汇聚统计（实际上在夸节点进行数据 shuffle 之前会在本地先对相同单词进行合并累加），形成 wordcount 的统计结果；最终通过 saveAsTextFile 方法将数据保存到 hdfs 上。具体的运行逻辑原理以及过程上图给出了详细的示意说明。 我的GitHub地址：https://github.com/heizemingjun 我的博客园地址：https://www.cnblogs.com/chenmingjun 我的CSDN地址：https://blog.csdn.net/u012990179&nbsp; 我的蚂蚁笔记博客地址：https://blog.leanote.com/chenmingjun Copyright ©2018-2019 黑泽明军【转载文章务必保留出处和署名，谢谢！】" />
<meta property="og:description" content="https://www.cnblogs.com/chenmingjun/p/10803261.html 文章目录 第1章 Spark 整体概述 1.1 整体概念 1.2 RDD 抽象 1.3 计算抽象 1.4 集群模式 1.5 RPC 网络通信抽象 1.6 启动 Standalone 集群 1.7 核心组件 1.8 核心组件交互流程 1.9 Block 管理 1.10整体应用 第2章 Spark 通信架构 2.1 通信组件概览 2.2 Endpoint 启动过程 2.3 Endpoint Send&amp;Ask 流程 2.4 Endpoint Receive 流程 2.5 Endpoint Inbox 处理流程 2.6 Endpoint 画像 第3章 脚本解析 3.1 start-daemon.sh 3.2 spark-class 3.3 start-master.sh 3.4 start-slaves.sh 3.5 start-all.sh 3.6 spark-submit 第4章 Master 节点启动 4.1 脚本概览 4.2 启动流程 4.3 OnStart 监听事件 4.4 RpcMessage 处理 (receiveAndReply) 4.5 OneWayMessage 处理 (receive) 4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑 第5章 Worker 节点启动 5.1 脚本概览 5.2 启动流程 5.3 OnStart 监听事件 5.4 RpcMessage 处理 (receiveAndReply) 5.5 OneWayMessage 处理 (receive) 第6章 Client 启动流程 6.1 脚本概览 6.2 SparkSubmit 启动流程 6.3 Client 启动流程 6.4 Client 的 OnStart 监听事件 6.5 RpcMessage 处理 (receiveAndReply) 6.6 OneWayMessage 处理(receive) 第7章 Driver 和 DriverRunner 7.1 Master 对 Driver 资源分配 7.2 Worker 运行 DriverRunner 7.3 DriverRunner 创建并运行 DriverWrapper 第8章 SparkContext 解析 8.1 SparkContext 解析 8.2 SparkContext 创建过程 8.3 SparkContext 简易结构与交互关系 8.4 Master 对 Application 资源分配 8.5 Worker 创建 Executor 第9章 Job 提交和 Task 的拆分 9.1 整体预览 9.2 Code 转化为初始 RDDs 9.3 RDD 分解为待执行任务集合（TaskSet） 9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver 9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor 第10章 Task 执行和回馈 10.1 Task 的执行流程 10.2 Task 的回馈流程 10.3 Task 的迭代流程 10.4 精彩图解 第11章 Spark 的数据存储 11.1 存储子系统概览 11.2 启动过程分析 11.3 通信层 11.4 存储层 11.5 数据写入过程分析 11.6 数据读取过程分析 11.7 Partition 如何转化为 Block 11.8 partition 和 block 的对应关系 第12章 Spark Shuffle 过程 12.1 MapReduce 的 Shuffle 过程介绍 12.2 HashShuffle 过程介绍 12.3 SortShuffle 过程介绍 12.4 TungstenShuffle 过程介绍 12.5 MapReduce 与 Spark 过程对比 第13章 Spark 内存管理 13.1 堆内和堆外内存规划 13.2 内存空间分配 13.3 存储内存管理 13.4 执行内存管理 第14章 部署模式解析 14.1 部署模式概述 14.2 standalone 框架 14.3 yarn 集群模式 14.4 mesos 集群模式 14.5 spark 三种部署模式的区别 14.6 异常场景分析 第15章 wordcount 程序运行原理窥探 15.1 spark 之 scala 实现 wordcount 15.2 原理窥探 &nbsp; 第1章 Spark 整体概述1.1 整体概念1.2 RDD 抽象1.3 计算抽象1.4 集群模式1.5 RPC 网络通信抽象1.6 启动 Standalone 集群1.7 核心组件1.8 核心组件交互流程1.9 Block 管理1.10整体应用第2章 Spark 通信架构2.1 通信组件概览2.2 Endpoint 启动过程2.3 Endpoint Send&amp;Ask 流程2.4 Endpoint Receive 流程2.5 Endpoint Inbox 处理流程2.6 Endpoint 画像第3章 脚本解析3.1 start-daemon.sh3.2 spark-class3.3 start-master.sh3.4 start-slaves.sh3.5 start-all.sh3.6 spark-submit第4章 Master 节点启动4.1 脚本概览4.2 启动流程4.3 OnStart 监听事件4.4 RpcMessage 处理 (receiveAndReply)4.5 OneWayMessage 处理 (receive)4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑第5章 Worker 节点启动5.1 脚本概览5.2 启动流程5.3 OnStart 监听事件5.4 RpcMessage 处理 (receiveAndReply)5.5 OneWayMessage 处理 (receive)第6章 Client 启动流程6.1 脚本概览6.2 SparkSubmit 启动流程6.3 Client 启动流程6.4 Client 的 OnStart 监听事件6.5 RpcMessage 处理 (receiveAndReply)6.6 OneWayMessage 处理(receive)第7章 Driver 和 DriverRunner7.1 Master 对 Driver 资源分配7.2 Worker 运行 DriverRunner7.3 DriverRunner 创建并运行 DriverWrapper第8章 SparkContext 解析8.1 SparkContext 解析8.2 SparkContext 创建过程8.3 SparkContext 简易结构与交互关系8.4 Master 对 Application 资源分配8.5 Worker 创建 Executor第9章 Job 提交和 Task 的拆分9.1 整体预览9.2 Code 转化为初始 RDDs9.3 RDD 分解为待执行任务集合（TaskSet）9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor第10章 Task 执行和回馈10.1 Task 的执行流程10.2 Task 的回馈流程10.3 Task 的迭代流程10.4 精彩图解第11章 Spark 的数据存储11.1 存储子系统概览11.2 启动过程分析11.3 通信层11.4 存储层11.4.1 Disk Store11.4.2 Memory Store11.5 数据写入过程分析11.5.1 序列化与否11.6 数据读取过程分析11.6.1 本地读取11.6.2 远程读取11.7 Partition 如何转化为 Block11.8 partition 和 block 的对应关系第12章 Spark Shuffle 过程12.1 MapReduce 的 Shuffle 过程介绍12.1.1 Spill 过程(刷写过程)12.1.2 Merge12.1.3 Copy12.1.4 Merge Sort12.2 HashShuffle 过程介绍12.3 SortShuffle 过程介绍12.4 TungstenShuffle 过程介绍12.5 MapReduce 与 Spark 过程对比第13章 Spark 内存管理13.1 堆内和堆外内存规划13.1.1 堆内内存13.1.2 堆外内存13.1.3 内存管理接口13.2 内存空间分配13.2.1 静态内存管理13.2.2 统一内存管理13.3 存储内存管理13.3.1 RDD 的持久化机制13.3.2 RDD 缓存的过程13.3.3 淘汰和落盘13.4 执行内存管理13.4.1 多任务间内存分配13.4.2 Shuffle 的内存占用第14章 部署模式解析14.1 部署模式概述14.2 standalone 框架14.2.1 Standalone 模式下任务运行过程14.2.2 总结14.3 yarn 集群模式14.4 mesos 集群模式14.5 spark 三种部署模式的区别14.6 异常场景分析14.6.1 异常分析1：Worker 异常退出14.6.2 异常分析2：Executor 异常退出14.6.3 异常分析3：Master 异常退出第15章 wordcount 程序运行原理窥探15.1 spark 之 scala 实现 wordcount15.2 原理窥探 回到顶部 第1章 Spark 整体概述 1.1 整体概念   Apache Spark 是一个开源的通用集群计算系统，它提供了 High-level 编程 API，支持 Scala、Java 和 Python 三种编程语言。Spark 内核使用 Scala 语言编写，通过基于 Scala 的函数式编程特性，在不同的计算层面进行抽象，代码设计非常优秀。 1.2 RDD 抽象   RDD（Resilient Distributed Datasets），弹性分布式数据集，它是对分布式数据集的一种内存抽象，通过受限的共享内存方式来提供容错性，同时这种内存模型使得计算比传统的数据流模型要高效。RDD 具有 5 个重要的特性，如下图所示： 上图展示了 2 个 RDD 进行 JOIN 操作，体现了 RDD 所具备的 5 个主要特性，如下所示：   • 1）一组分区   • 2）计算每一个数据分片的函数   • 3）RDD 上的一组依赖   • 4）可选，对于键值对 RDD，有一个 Partitioner（通常是 HashPartitioner）   • 5）可选，一组 Preferred location 信息（例如，HDFS 文件的 Block 所在 location 信息） 有了上述特性，能够非常好地通过 RDD 来表达分布式数据集，并作为构建 DAG 图的基础：首先抽象一个分布式计算任务的逻辑表示，最终将任务在实际的物理计算环境中进行处理执行。 &nbsp; 1.3 计算抽象 在描述 Spark 中的计算抽象，我们首先需要了解如下几个概念： 1）Application   • 用户编写的 Spark 程序，完成一个计算任务的处理。它是由一个 Driver 程序和一组运行于 Spark 集群上的 Executor 组成。 2）Job   • 用户程序中，每次调用 Action 时，逻辑上会生成一个 Job，一个 Job 包含了多个 Stage 。 3）Stage   • Stage 包括两类：ShuffleMapStage 和 ResultStage，如果用户程序中调用了需要进行 Shuffle 计算的 Operator，如 groupByKey 等，就会以 Shuffle 为边界分成 ShuffleMapStage 和 ResultStage。 4）TaskSet   • 基于 Stage 可以直接映射为 TaskSet，一个 TaskSet 封装了一次需要运算的、具有相同处理逻辑的 Task，这些 Task 可以并行计算，粗粒度的调度是以 TaskSet 为单位的。 5）Task   • Task 是在物理节点上运行的基本单位，Task 包含两类：ShuffleMapTask 和 ResultTask，分别对应于 Stage 中 ShuffleMapStage 和 ResultStage 中的一个执行基本单元。 下面，我们看一下，上面这些基本概念之间的关系，如下图所示：   上图，为了简单，每个 Job 假设都很简单，并且只需要进行一次 Shuffle 处理，所以都对应 2 个 Stage。实际应用中，一个 Job 可能包含若干个 Stage，或者是一个相对复杂的 Stage DAG。 在 Standalone 模式下，默认使用的是 FIFO 这种简单的调度策略，在进行调度的过程中，大概流程如下图所示：   从用户提交 Spark 程序，最终生成 TaskSet，而在调度时，通过 TaskSetManager 来管理一个 TaskSet（包含一组可在物理节点上执行的 Task），这里面 TaskSet 必须要按照顺序执行才能保证计算结果的正确性，因为 TaskSet 之间是有序依赖的（上溯到 ShuffleMapStage 和 ResultStage），只有一个 TaskSet 中的所有 Task 都运行完成后，才能调度下一个 TaskSet 中的 Task 去执行。 &nbsp; 1.4 集群模式   Spark 集群在设计的时候，并没有在资源管理的设计上对外封闭，而是充分考虑了未来对接一些更强大的资源管理系统，如 YARN、Mesos 等，所以 Spark 架构设计将资源管理单独抽象出一层，通过这种抽象能够构建一种适合企业当前技术栈的插件式资源管理模块，从而为不同的计算场景提供不同的资源分配与调度策略。Spark 集群模式架构，如下图所示： 上图中，Spark集群Cluster Manager目前支持如下三种模式： 1）Standalone 模式   • Standalone 模式是 Spark 内部默认实现的一种集群管理模式，这种模式是通过集群中的 Master 来统一管理资源，而与 Master 进行资源请求协商的是 Driver 内部的 StandaloneSchedulerBackend（实际上是其内部的 StandaloneAppClient 真正与 Master 通信），后面会详细说明。 2）YARN 模式   • YARN 模式下，可以将资源的管理统一交给 YARN 集群的 ResourceManager 去管理，选择这种模式，可以更大限度的适应企业内部已有的技术栈，如果企业内部已经在使用 Hadoop 技术构建大数据处理平台。 3）Mesos 模式   • 随着 Apache Mesos 的不断成熟，一些企业已经在尝试使用 Mesos 构建数据中心的操作系统（DCOS），Spark 构建在 Mesos 之上，能够支持细粒度、粗粒度的资源调度策略（Mesos 的优势），也可以更好地适应企业内部已有技术栈。   • 那么，Spark 中是怎么考虑满足这一重要的设计决策的呢？也就是说，如何能够保证 Spark 非常容易的让第三方资源管理系统轻松地接入进来。我们深入到类设计的层面看一下，如下类图所示：   • 可以看出，Task 调度直接依赖 SchedulerBackend，SchedulerBackend 与实际资源管理模块交互实现资源请求。这里面，CoarseGrainedSchedulerBackend 是 Spark 中与资源调度相关的最重要的抽象，它需要抽象出与 TaskScheduler 通信的逻辑，同时还要能够与各种不同的第三方资源管理系统无缝地交互。实际上，CoarseGrainedSchedulerBackend 内部采用了一种 ResourceOffer 的方式来处理资源请求。 &nbsp; 1.5 RPC 网络通信抽象   Spark RPC 层是基于优秀的网络通信框架 Netty 设计开发的，但是 Spark 提供了一种很好地抽象方式，将底层的通信细节屏蔽起来，而且也能够基于此来设计满足扩展性，比如，如果有其他不基于 Netty 的网络通信框架的新的RPC接入需求，可以很好地扩展而不影响上层的设计。RPC 层设计，如下图类图所示：   任何两个 Endpoint 只能通过消息进行通信，可以实现一个 RpcEndpoint 和一个 RpcEndpointRef。想要与 RpcEndpoint 通信，需要获取到该 RpcEndpoint 对应的 RpcEndpointRef 即可，而且管理 RpcEndpoint 和 RpcEndpointRef 创建及其通信的逻辑，统一在 RpcEnv 对象中管理。 &nbsp; 1.6 启动 Standalone 集群   Standalone 模式下，Spark 集群采用了简单的 Master-Slave 架构模式，Master 统一管理所有的 Worker，这种模式很常见，我们简单地看下 Spark Standalone 集群启动的基本流程，如下图所示： 可以看到，Spark 集群采用的消息的模式进行通信，也就是 EDA 架构模式，借助于 RPC 层的优雅设计，任何两个 Endpoint 想要通信，发送消息并携带数据即可。上图的流程描述如下所示：   • 1）Master 启动时首先创一个 RpcEnv 对象，负责管理所有通信逻辑。   • 2）Master 通过 RpcEnv 对象创建一个 Endpoint，Master 就是一个 Endpoint，Worker 可以与其进行通信。   • 3）Worker 启动时也是创一个 RpcEnv 对象。   • 4）Worker 通过 RpcEnv 对象创建一个 Endpoint。   • 5）Worker 通过 RpcEnv 对，建立到 Master 的连接，获取到一个 RpcEndpointRef 对象，通过该对象可以与 Master 通信。   • 6）Worker 向 Master 注册，注册内容包括主机名、端口、CPU Core 数量、内存数量。   • 7）Master 接收到 Worker 的注册，将注册信息维护在内存中的 Table 中，其中还包含了一个到 Worker 的 RpcEndpointRef 对象引用。   • 8）Master 回复 Worker 已经接收到注册，告知 Worker 已经注册成功。   • 9）此时如果有用户提交 Spark 程序，Master 需要协调启动 Driver；而 Worker 端收到成功注册响应后，开始周期性向 Master 发送心跳。 &nbsp; 1.7 核心组件   集群处理计算任务的运行时（即用户提交了 Spark 程序），最核心的顶层组件就是 Driver 和 Executor，它们内部管理很多重要的组件来协同完成计算任务，核心组件栈如下图所示：   Driver 和 Executor 都是运行时创建的组件，一旦用户程序运行结束，他们都会释放资源，等待下一个用户程序提交到集群而进行后续调度。上图，我们列出了大多数组件，其中 SparkEnv 是一个重量级组件，他们内部包含计算过程中需要的主要组件，而且，Driver 和 Executor 共同需要的组件在 SparkEnv 中也包含了很多。这里，我们不做过多详述，后面交互流程等处会说明大部分组件负责的功能。 &nbsp; 1.8 核心组件交互流程   在 Standalone 模式下，Spark 中各个组件之间交互还是比较复杂的，但是对于一个通用的分布式计算系统来说，这些都是非常重要而且比较基础的交互。首先，为了理解组件之间的主要交互流程，我们给出一些基本要点：   • 一个 Application 会启动一个 Driver   • 一个 Driver 负责跟踪管理该 Application 运行过程中所有的资源状态和任务状态   • 一个 Driver 会管理一组 Executor   • 一个 Executor 只执行属于一个 Driver 的 Task 核心组件之间的主要交互流程，如下图所示： 上图中，通过不同颜色或类型的线条，给出了如下 6 个核心的交互流程，我们会详细说明：橙色：提交用户 Spark 程序 用户提交一个 Spark 程序，主要的流程如下所示：   •1）用户 spark-submit 脚本提交一个 Spark 程序，会创建一个 ClientEndpoint 对象，该对象负责与 Master 通信交互   •2）ClientEndpoint 向 Master 发送一个 RequestSubmitDriver 消息，表示提交用户程序   •3）Master 收到 RequestSubmitDriver 消息，向 ClientEndpoint 回复 SubmitDriverResponse，表示用户程序已经完成注册   •4）ClientEndpoint 向 Master 发送 RequestDriverStatus 消息，请求 Driver 状态   •5）如果当前用户程序对应的 Driver 已经启动，则 ClientEndpoint 直接退出，完成提交用户程序紫色：启动 Driver 进程 当用户提交用户 Spark 程序后，需要启动 Driver 来处理用户程序的计算逻辑，完成计算任务，这时 Master 协调需要启动一个 Driver，具体流程如下所示：   •1）Maser 内存中维护着用户提交计算的任务 Application，每次内存结构变更都会触发调度，向 Worker 发送 LaunchDriver 请求   •2）Worker 收到 LaunchDriver 消息，会启动一个 DriverRunner 线程去执行 LaunchDriver 的任务   •3）DriverRunner 线程在 Worker 上启动一个新的 JVM 实例，该 JVM 实例内运行一个 Driver 进程，该 Driver 会创建 SparkContext 对象红色：注册 Application Dirver 启动以后，它会创建 SparkContext 对象，初始化计算过程中必需的基本组件，并向 Master 注册 Application，流程描述如下：   •1）创建 SparkEnv 对象，创建并管理一些数基本组件   •2）创建 TaskScheduler，负责 Task 调度   •3）创建 StandaloneSchedulerBackend，负责与 ClusterManager 进行资源协商   •4）创建 DriverEndpoint，其它组件可以与 Driver 进行通信   •5）在 StandaloneSchedulerBackend 内部创建一个 StandaloneAppClient，负责处理与 Master 的通信交互   •6）StandaloneAppClient 创建一个 ClientEndpoint，实际负责与 Master 通信   •7）ClientEndpoint 向 Master 发送 RegisterApplication 消息，注册 Application   •8）Master 收到 RegisterApplication 请求后，回复 ClientEndpoint 一个 RegisteredApplication 消息，表示已经注册成功蓝色：启动 Executor 进程   •1）Master 向 Worker 发送 LaunchExecutor 消息，请求启动 Executor；同时 Master 会向 Driver 发送 ExecutorAdded 消息，表示 Master 已经新增了一个 Executor（此时还未启动）   •2）Worker 收到 LaunchExecutor 消息，会启动一个 ExecutorRunner 线程去执行 LaunchExecutor 的任务   •3）Worker 向 Master 发送 ExecutorStageChanged 消息，通知 Executor 状态已发生变化   •4）Master 向 Driver 发送 ExecutorUpdated 消息，此时 Executor 已经启动粉色：启动 Task 执行   •1）StandaloneSchedulerBackend 启动一个 DriverEndpoint   •2）DriverEndpoint 启动后，会周期性地检查 Driver 维护的 Executor 的状态，如果有空闲的 Executor 便会调度任务执行   •3）DriverEndpoint 向 TaskScheduler 发送 Resource Offer 请求   •4）如果有可用资源启动 Task，则 DriverEndpoint 向 Executor 发送 LaunchTask 请求   •5）Executor 进程内部的 CoarseGrainedExecutorBackend 调用内部的 Executor 线程的 launchTask 方法启动 Task   •6）Executor 线程内部维护一个线程池，创建一个 TaskRunner 线程并提交到线程池执行绿色：Task 运行完成   •1）Executor 进程内部的 Executor 线程通知 CoarseGrainedExecutorBackend，Task 运行完成   •2）CoarseGrainedExecutorBackend 向 DriverEndpoint 发送 StatusUpdated 消息，通知 Driver 运行的 Task 状态发生变更   •3）StandaloneSchedulerBackend 调用T askScheduler 的 updateStatus 方法更新 Task 状态   •4）StandaloneSchedulerBackend 继续调用 TaskScheduler 的 resourceOffers 方法，调度其他任务运行 &nbsp; 1.9 Block 管理   Block 管理，主要是为 Spark 提供的 Broadcast 机制提供服务支撑的。Spark 中内置采用 TorrentBroadcast 实现，该 Broadcast 变量对应的数据（Task 数据）或数据集（如 RDD），默认会被切分成若干 4M 大小的 Block，Task 运行过程中读取到该 Broadcast 变量，会以 4M 为单位的 Block 为拉取数据的最小单位，最后将所有的 Block 合并成 Broadcast 变量对应的完整数据或数据集。将数据切分成 4M 大小的 Block，Task 从多个 Executor 拉取 Block，可以非常好地均衡网络传输负载，提高整个计算集群的稳定性。   通常，用户程序在编写过程中，会对某个变量进行 Broadcast，该变量称为 Broadcast 变量。在实际物理节点的 Executor 上执行 Task 时，需要读取 Broadcast 变量对应的数据集，那么此时会根据需要拉取 DAG 执行流上游已经生成的数据集。采用 Broadcast 机制，可以有效地降低数据在计算集群环境中传输的开销。具体地，如果一个用户对应的程序中的 Broadcast 变量，对应着一个数据集，它在计算过程中需要拉取对应的数据，如果在同一个物理节点上运行着多个 Task，多个 Task 都需要该数据，有了 Broadcast 机制，只需要拉取一份存储在本地物理机磁盘即可，供多个 Task 计算共享。   另外，用户程序在进行调度过程中，会根据调度策略将 Task 计算逻辑数据（代码）移动到对应的 Worker 节点上，最优情况是对本地数据进行处理，那么代码（序列化格式）也需要在网络上传输，也是通过 Broadcast 机制进行传输，不过这种方式是首先将代码序列化到 Driver 所在 Worker 节点，后续如果 Task 在其他 Worker 中执行，需要读取对应代码的 Broadcast 变量，首先就是从 Driver 上拉取代码数据，接着其他晚一些被调度的 Task 可能直接从其他 Worker 上的 Executor 中拉取代码数据。   我们通过以 Broadcast 变量 taskBinary 为例，说明 Block 是如何管理的，如下图所示：   上图中，Driver 负责管理所有的 Broadcast 变量对应的数据所在的 Executor，即一个 Executor 维护一个 Block 列表。在 Executor 中运行一个 Task 时，执行到对应的 Broadcast 变量 taskBinary，如果本地没有对应的数据，则会向 Driver 请求获取 Broadcast 变量对应的数据，包括一个或多个 Block 所在的 Executor 列表，然后该 Executor 根据 Driver 返回的 Executor 列表，直接通过底层的 BlockTransferService 组件向对应 Executor 请求拉取 Block。Executor 拉取到的 Block 会缓存到本地，同时向 Driver 报告该 Executor 上存在的 Block 信息，以供其他 Executor 执行 Task 时获取 Broadcast 变量对应的数据。 &nbsp; 1.10整体应用   用户通过 spark-submit 提交或者运行 spark-shell REPL，集群创建 Driver，Driver 加载 Application，最后 Application 根据用户代码转化为 RDD，RDD 分解为 Tasks，Executor 执行 Task 等系列知识，整体交互蓝图如下： 回到顶部 第2章 Spark 通信架构   Spark作为分布式计算框架，多个节点的设计与相互通信模式是其重要的组成部分。Spark 一开始使用 Akka 作为内部通信部件。在 Spark 1.3 年代，为了解决大块数据（如 Shuffle）的传输问题，Spark 引入了 Netty 通信框架。到了 Spark 1.6，Spark 可以配置使用 Akka 或者 Netty 了，这意味着 Netty 可以完全替代 Akka了。再到 Spark 2，Spark 已经完全抛弃 Akka了，全部使用 Netty 了。   为什么呢？官方的解释是：   •1）很多 Spark 用户也使用 Akka，但是由于 Akka 不同版本之间无法互相通信，这就要求用户必须使用跟 Spark 完全一样的 Akka 版本，导致用户无法升级 Akka。   •2）Spark 的 Akka 配置是针对 Spark 自身来调优的，可能跟用户自己代码中的 Akka 配置冲突。   •3）Spark 用的 Akka 特性很少，这部分特性很容易自己实现。同时，这部分代码量相比 Akka 来说少很多，debug 比较容易。如果遇到什么 bug，也可以自己马上 fix，不需要等 Akka 上游发布新版本。而且，Spark 升级 Akka 本身又因为第一点会强制要求用户升级他们使用的 Akka，对于某些用户来说是不现实的。 SPARK 的通信架构 - Actor 比较，如下图所示： 2.1 通信组件概览 对源码分析，对于设计思路理解如下：   •1）RpcEndpoint：RPC 端点，Spark 针对于每个节点（Client/Master/Worker）都称之一个 Rpc 端点且都实现 RpcEndpoint 接口，内部根据不同端点的需求，设计不同的消息和不同的业务处理，如果需要发送（询问）则调用 Dispatcher。   •2）RpcEnv：RPC 上下文环境，每个 Rpc 端点运行时依赖的上下文环境称之为 RpcEnv。   •3）Dispatcher：消息分发器，针对于 RPC 端点需要发送消息或者从远程 RPC 接收到的消息，分发至对应的指令收件箱/发件箱。如果指令接收方是自己存入收件箱，如果指令接收方为非自身端点，则放入发件箱。   •4）Inbox：指令消息收件箱，一个本地端点对应一个收件箱，Dispatcher 在每次向 Inbox 存入消息时，都将对应 EndpointData 加入内部待 Receiver Queue中，另外 Dispatcher 创建时会启动一个单独线程进行轮询 Receiver Queue，进行收件箱消息消费。   •5）OutBox：指令消息发件箱，一个远程端点对应一个发件箱，当消息放入 Outbox 后，紧接着将消息通过 TransportClient 发送出去。消息放入发件箱以及发送过程是在同一个线程中进行，这样做的主要原因是远程消息分为 RpcOutboxMessage，OneWayOutboxMessage 两种消息，而针对于需要应答的消息直接发送且需要得到结果进行处理   •6）TransportClient：Netty 通信客户端，根据 OutBox 消息的 receiver 信息，请求对应远程 TransportServer。   •7）TransportServer：Netty 通信服务端，一个 RPC 端点一个 TransportServer，接受远程消息后调用 Dispatcher 分发消息至对应收发件箱。注意：   TransportClient 与 TransportServer 通信虚线表示两个 RpcEnv 之间的通信，图示没有单独表达式。   一个 Outbox 一个 TransportClient，图示没有单独表达式。   一个 RpcEnv 中存在两个 RpcEndpoint，一个代表本身启动的 RPC 端点，另外一个为 RpcEndpointVerifier。 Spark的通信架构 – 高层视图 Spark 的通信架构 – 类图 2.2 Endpoint 启动过程 启动的流程如下： Endpoint 启动后，默认会向 Inbox 中添加 OnStart 消息，不同的端点（Master/Worker/Client）消费 OnStart 指令时，进行相关端点的启动额外处理。 Endpoint 启动时，会默认启动 TransportServer，且启动结束后会进行一次同步测试 rpc 可用性（askSync-BoundPortsRequest）。 Dispatcher 作为一个分发器，内部存放了 Inbox，Outbox 的等相关句柄和存放了相关处理状态数据，结构大致如下： 2.3 Endpoint Send&amp;Ask 流程 Endpoint 的消息发送与请求流程，如下： Endpoint 根据业务需要存入两个维度的消息组合：send/ask 某个消息，receiver 是自身与非自身   •1）OneWayMessage：send + 自身，直接存入收件箱   •2）OneWayOutboxMessage：send + 非自身，存入发件箱并直接发送   •3）RpcMessage：ask + 自身，直接存入收件箱，另外还需要存入 LocalNettyRpcCallContext，需要回调后再返回   •4）RpcOutboxMessage：ask + 非自身，存入发件箱并直接发送，需要回调后再返回 &nbsp; 2.4 Endpoint Receive 流程 Endpoint 的消息的接收，流程如下： 上图 ServerBootstrap 为 Netty 启动服务，SocketChanel为Netty 数据通道。 上述包含 TransportSever 启动与消息接收两个流程。 &nbsp; 2.5 Endpoint Inbox 处理流程 Spark 在 Endpoint 的设计上核心设计即为 Inbox 与 Outbox，其中 Inbox 核心要点为：   •1）内部的处理流程拆分为多个消息指令（InboxMessage）存放入 Inbox。   •2）当 Dispatcher 启动最后，会启动一个名为【dispatcher-event-loop】的线程扫描 Inbox 待处理 InboxMessage，并调用 Endpoint 根据 InboxMessage 类型做相应处理   •3）当 Dispatcher 启动最后，默认会向 Inbox 存入 OnStart 类型的 InboxMessage，Endpoint 在根据 OnStart 指令做相关的额外启动工作，三端启动后所有的工作都是对 OnStart 指令处理衍生出来的，因此可以说 OnStart 指令是相互通信的源头。 消息指令类型大致如下三类：   •1）OnStart/OnStop   •2）RpcMessage/OneWayMessage   •3）RemoteProcessDisconnected/RemoteProcessConnected/RemoteProcessConnectionError 2.6 Endpoint 画像 回到顶部 第3章 脚本解析 在看源码之前，我们一般会看相关脚本了解其初始化信息以及 Bootstrap 类，Spark 也不例外，而 Spark 中相关的脚本如下： %SPARK_HOME%/sbin/start-master.sh %SPARK_HOME%/sbin/start-slaves.sh %SPARK_HOME%/sbin/start-all.sh %SPARK_HOME%/bin/spark-submit 启动脚本中对于公共处理部分进行抽取为独立的脚本，如下： 脚本 说明 sbin/spark-config.sh 初始化环境变量 SPARK_CONF_DIR, PYTHONPATH bin/load-spark-env.sh 初始化环境变量 SPARK_SCALA_VERSION，调用 %SPARK_HOME% conf/spark-env.sh 加载用户自定义环境变量 3.1 start-daemon.sh 主要完成进程相关基本信息初始化，然后调用 bin/spark-class 进行守护进程启动，该脚本是创建端点的通用脚本，三端各自脚本都会调用 spark-daemon.sh 脚本启动各自进程 详解如下： 1）初始化&nbsp;SPRK_HOME、SPARK_CONF_DIR、SPARK_IDENT_STRING、SPARK_LOG_DIR&nbsp;环境变量&nbsp;(如果不存在) 2）初始化日志并测试日志文件夹读写权限，初始化&nbsp;PID&nbsp;目录并校验&nbsp;PID&nbsp;信息 3）调用&nbsp;/bin/spark-class&nbsp;脚本，/bin/spark-class&nbsp;见下面 3.2 spark-class Master 调用举例： bin/spark-class&nbsp;\ --class&nbsp;org.apache.spark.deploy.master.Master&nbsp;\ --host&nbsp;$SPARK_MASTER_HOST&nbsp;\ --port&nbsp;$SPARK_MASTER_PORT&nbsp;\ --webui-port&nbsp;$SPARK_MASTER_WEBUI_PORT&nbsp;$ORIGINAL_ARGS 1）初始化&nbsp;RUNNER(java)、SPARK_JARS_DIR&nbsp;(%SPARK_HOME%/jars)、LAUNCH_CLASSPATH&nbsp;信息 2）调用&nbsp;(&quot;$RUNNER&quot;&nbsp;-Xmx128m&nbsp;-cp&nbsp;&quot;$LAUNCH_CLASSPATH&quot;&nbsp;org.apache.spark.launcher.Main&nbsp;&quot;$@&quot;)&nbsp;获取最终执行的&nbsp;shell&nbsp;语句 3）执行最终的&nbsp;shell&nbsp;语句，示例如下： /opt/module/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g&nbsp;\ -XX:MaxPermSize=256m&nbsp;\ org.apache.spark.deploy.master.Master&nbsp;\ --host&nbsp;hadoop102&nbsp;\ --port&nbsp;7077&nbsp;\ --webui-port&nbsp;8080 如果是&nbsp;Client，那么可能为&nbsp;r，或者&nbsp;python&nbsp;脚本。 3.3 start-master.sh 启动 Master 的脚本，流程如下： 详解如下： 1）用户执行&nbsp;start-master.sh&nbsp;脚本，初始化环境变量&nbsp;SPARK_HOME&nbsp;(如果&nbsp;PATH&nbsp;不存在&nbsp;SPARK_HOME，初始化脚本的上级目录为&nbsp;SPARK_HOME)，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh 2）如果环境变量&nbsp;SPARK_MASTER_HOST、SPARK_MASTER_PORT、SPARK_MASTER_WEBUI_PORT&nbsp;不存在，进行初始化&nbsp;7077，hostname&nbsp;-f，8080 3）调用&nbsp;spark-daemon.sh&nbsp;脚本启动&nbsp;master&nbsp;进程，如下： spark-daemon.sh&nbsp;start&nbsp;org.apache.spark.deploy.master.Master&nbsp;1&nbsp;\ --host&nbsp;$SPARK_MASTER_HOST&nbsp;\ --port&nbsp;$SPARK_MASTER_PORT&nbsp;\ --webui-port&nbsp;$SPARK_MASTER_WEBUI_PORT&nbsp;$ORIGINAL_ARGS） 3.4 start-slaves.sh 启动 Worker 的脚本，流程如下： 详解如下： 1）用户执行&nbsp;start-slaves.sh&nbsp;脚本，初始化环境变量&nbsp;SPARK_HOME，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh，初始化&nbsp;Master&nbsp;host/port&nbsp;信息 2）调用&nbsp;slaves.sh&nbsp;脚本，读取&nbsp;conf/slaves&nbsp;文件并遍历，通过&nbsp;ssh&nbsp;连接到对应&nbsp;slave&nbsp;节点，启动&nbsp;${SPARK_HOME}/sbin/start-slave.sh&nbsp;spark://$SPARK_MASTER_HOST:$SPARK_MASTER_PORT 3）start-slave.sh&nbsp;在各个节点中，初始化环境变量&nbsp;SPARK_HOME，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh，根据&nbsp;$SPARK_WORKER_INSTANCES&nbsp;计算&nbsp;WEBUI_PORT&nbsp;端口&nbsp;(worker&nbsp;端口号依次递增)&nbsp;并启动&nbsp;Worker&nbsp;进程，如下： ${SPARK_HOME}/sbin/spark-daemon.sh&nbsp;\ start&nbsp;org.apache.spark.deploy.worker.Worker&nbsp;$WORKER_NUM&nbsp;\ --webui-port&nbsp;&quot;$WEBUI_PORT&quot;&nbsp;$PORT_FLAG&nbsp;$PORT_NUM&nbsp;$MASTER&nbsp;&quot;$@&quot; 3.5 start-all.sh 属于快捷脚本，内部调用 start-master.sh 与 start-slaves.sh 脚本，并无额外工作。 3.6 spark-submit 任务提交的基本脚本，流程如下： 详解如下： 1）直接调用&nbsp;spark-class&nbsp;脚本进行进程创建，示例如下： ./spark-submit&nbsp;\ --class&nbsp;org.apache.spark.examples.SparkPi&nbsp;\ --master&nbsp;spark://hadoop102:7077&nbsp;\ ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 2）如果是&nbsp;java/scala&nbsp;任务，那么最终调用&nbsp;SparkSubmit.scala&nbsp;进行任务处理，示例如下： /opt/module/jdk1.8.0_144&nbsp;-cp&nbsp;\ /opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g&nbsp;-XX:MaxPermSize=256m&nbsp;\ org.apache.spark.deploy.SparkSubmit&nbsp;\ --master&nbsp;spark://hadoop102:7077&nbsp;\ --class&nbsp;org.apache.spark.examples.SparkPi&nbsp;\ ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 回到顶部 第4章 Master 节点启动 Master 作为 Endpoint 的具体实例，下面我们介绍一下 Master 启动以及 OnStart 指令后的相关工作。 4.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g&nbsp;\ -XX:MaxPermSize=256m&nbsp;\ org.apache.spark.deploy.master.Master&nbsp;\ --host&nbsp;hadoop102&nbsp;\ --port&nbsp;7077&nbsp;\ 4.2 启动流程 Master 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）MasterArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Master&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--ip&nbsp;-i&nbsp;--host&nbsp;-h&nbsp;--port&nbsp;-p&nbsp;--webui-port&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;b)将&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 3）NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 4）BoundPortsResponse&nbsp;返回&nbsp;rpcEndpointPort、webUIPort、restPort&nbsp;真实端口。 5）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 4.3 OnStart 监听事件 Master 的启动完成后异步执行工作如下： 详解如下： 1）【dispatcher-event-loop】线程扫描到&nbsp;OnStart&nbsp;指令后会启动相关&nbsp;MasterWebUI&nbsp;(默认端口&nbsp;8080），根据配置选择安装&nbsp;ResetServer&nbsp;(默认端口&nbsp;6066)。 2）另外新起【master-forward-message-thread】线程定期检查&nbsp;Worker&nbsp;心跳是否超时。 3）如果&nbsp;Worker&nbsp;心跳检测超时，那么对&nbsp;Worker&nbsp;下的发布的所有任务所属&nbsp;Driver&nbsp;进行&nbsp;ExecutorUpdated&nbsp;发送，同时自己再重新&nbsp;LaunchDriver。 4.4 RpcMessage 处理 (receiveAndReply) 4.5 OneWayMessage 处理 (receive) 4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑 这部分对整体 Master 理解作用不是很大且理解比较抽象，可以先读后续内容，回头再考虑看这部分内容，或者不读。 回到顶部 第5章 Worker 节点启动 Worker 作为 Endpoint 的具体实例，下面我们介绍一下 Worker 启动以及 OnStart 指令后的额外工作。 5.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g&nbsp;\ -XX:MaxPermSize=256m&nbsp;\ org.apache.spark.deploy.worker.Worker&nbsp;\ --webui-port&nbsp;8081 spark://hadoop102:7077 5.2 启动流程 Worker 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）WorkerArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Master&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--ip&nbsp;-i&nbsp;--host&nbsp;-h&nbsp;--port&nbsp;-p&nbsp;--cores&nbsp;-c&nbsp;--memory&nbsp;-m&nbsp;--work-dir&nbsp;--webui-port&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;--properties-file&nbsp;(没有配置默认为conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;在没有配置情况下，cores&nbsp;默认为服务器&nbsp;CPU&nbsp;核数。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;在没有配置情况下，memory&nbsp;默认为服务器内存减&nbsp;1G，如果低于&nbsp;1G&nbsp;取&nbsp;1G。 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;webUiPort&nbsp;默认为&nbsp;8081。 3）NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 4）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 5.3 OnStart 监听事件 Worker 的启动完成后异步执行工作如下： 详解如下： 1）【dispatcher-event-loop】线程扫描到&nbsp;OnStart&nbsp;指令后会启动相关&nbsp;WorkerWebUI&nbsp;(默认端口&nbsp;8081)。 2）Worker&nbsp;向&nbsp;Master&nbsp;发起一次&nbsp;RegisterWorker&nbsp;指令。 3）另起【master-forward-message-thread】线程定期执行&nbsp;ReregisterWithMaster&nbsp;任务，如果注册成功&nbsp;(RegisteredWorker)&nbsp;则跳过，否则再次向&nbsp;Master&nbsp;发起&nbsp;RegisterWorker&nbsp;指令，直到超过最大次数报错&nbsp;(默认16次)。 4）Master&nbsp;如果可以注册，则维护对应的&nbsp;WorkerInfo&nbsp;对象并持久化，完成后向&nbsp;Worker&nbsp;发起一条&nbsp;RegisteredWorker&nbsp;指令，如果&nbsp;Master&nbsp;为&nbsp;standby&nbsp;状态，则向&nbsp;Worker&nbsp;发起一条&nbsp;MasterInStandby&nbsp;指令。 5）Worker&nbsp;接受&nbsp;RegisteredWorker&nbsp;后，提交【master-forward-message-thread】线程定期执行&nbsp;SendHeartbeat&nbsp;任务，完成后向&nbsp;Worker&nbsp;发起一条&nbsp;WorkerLatestState&nbsp;指令。 6）Worker&nbsp;发心跳检测，会触发更新&nbsp;Master&nbsp;对应&nbsp;WorkerInfo&nbsp;对象，如果&nbsp;Master&nbsp;检测到异常，则发起&nbsp;ReconnectWorker&nbsp;指令至&nbsp;Worker，Worker&nbsp;则再次执行&nbsp;ReregisterWithMaster&nbsp;工作。 5.4 RpcMessage 处理 (receiveAndReply) 5.5 OneWayMessage 处理 (receive) 回到顶部 第6章 Client 启动流程 Client 作为 Endpoint 的具体实例，下面我们介绍一下 Client 启动以及 OnStart 指令后的额外工作。 6.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\ -Xmx1g -XX:MaxPermSize=256m org.apache.spark.deploy.SparkSubmit --master&nbsp;spark://hadoop102:7077 --class&nbsp;org.apache.spark.examples.SparkPi ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 6.2 SparkSubmit 启动流程 SparkSubmit 的启动流程如下： 详解如下： 1）SparkSubmitArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Client&nbsp;启动的参数 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--name&nbsp;--master&nbsp;--class&nbsp;--deploy-mode &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--num-executors&nbsp;--executor-cores&nbsp;--total-executor-cores&nbsp;--executor-memory &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--driver-memory&nbsp;--driver-cores&nbsp;--driver-class-path&nbsp;--driver-java-options&nbsp;--driver-library-path &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--kill&nbsp;--status&nbsp;--supervise&nbsp;--queue &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--files&nbsp;--py-files &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--archives&nbsp;--jars&nbsp;--packages&nbsp;--exclude-packages&nbsp;--repositories &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--conf&nbsp;(解析存入&nbsp;Map：sparkProperties&nbsp;中) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--proxy-user&nbsp;--principal&nbsp;--keytab&nbsp;--help&nbsp;--verbose&nbsp;--version&nbsp;--usage-error &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;合并&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;文件配置项&nbsp;(不在&nbsp;--conf&nbsp;中的配置&nbsp;)&nbsp;至&nbsp;sparkProperties &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;删除&nbsp;sparkProperties&nbsp;中不以&nbsp;spark.&nbsp;开头的配置项目 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;启动参数为空的配置项从&nbsp;sparkProperties&nbsp;中合并 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;根据&nbsp;action&nbsp;(SUBMIT、KILL、REQUEST_STATUS)&nbsp;校验各自必需参数是否有值 2）Case&nbsp;Submit： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;获取childMainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;clent(默认)：用户任务启动类&nbsp;mainClass&nbsp;(--class) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;useRest&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.rest.RestSubmissionClient &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;!useRest&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.Client &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;yarn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.yarn.Client &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;mesos:*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.rest.RestSubmissionClient &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;获取&nbsp;childArgs&nbsp;(子运行时对应命令行组装参数) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;useRest&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;包含&nbsp;primaryResource&nbsp;与&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;!useRest&nbsp;&nbsp;&nbsp;&nbsp;包含&nbsp;--supervise&nbsp;--memory&nbsp;--cores&nbsp;&nbsp;launch&nbsp;childArg,&nbsp;primaryResource,&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;yarn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--class&nbsp;--arg&nbsp;--jar/--primary-py-file/--primary-r-file &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;mesos:*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;primaryResource &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;获取&nbsp;childClasspath &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;clent&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;读取&nbsp;--jars&nbsp;配置，与&nbsp;primaryResource&nbsp;信息&nbsp;(../examples/jars/spark-examples_2.11-2.1.0.jar) &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;获取&nbsp;sysProps &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将&nbsp;sparkPropertie&nbsp;中的所有配置封装成新的&nbsp;sysProps&nbsp;对象，另外还增加了一下额外的配置项目 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;将&nbsp;childClasspath&nbsp;通过当前的类加载器加载中 &nbsp;&nbsp;&nbsp;&nbsp;f)&nbsp;将&nbsp;sysProps&nbsp;设置到当前&nbsp;jvm&nbsp;环境中 &nbsp;&nbsp;&nbsp;&nbsp;g)&nbsp;最终反射执行&nbsp;childMainClass，传参为&nbsp;childArgs 6.3 Client 启动流程 Client 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）ClientArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Client&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--cores&nbsp;-c&nbsp;--memory&nbsp;-m&nbsp;--supervise&nbsp;-s&nbsp;--verbose&nbsp;-v &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;launch&nbsp;jarUrl&nbsp;master&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kill&nbsp;master&nbsp;driverId &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;在没有配置情况下，cores&nbsp;默认为&nbsp;1&nbsp;核。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;在没有配置情况下，memory&nbsp;默认为&nbsp;1G。 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 3）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 6.4 Client 的 OnStart 监听事件 Client 的启动完成后异步执行工作如下：　 详解如下： 1）如果是发布任务(case&nbsp;launch)，Client&nbsp;创建一个&nbsp;DriverDescription，并向&nbsp;Master&nbsp;发起&nbsp;RequestSubmitDriver&nbsp;请求。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;Command&nbsp;中的&nbsp;mainClass&nbsp;为：&nbsp;org.apache.spark.deploy.worker.DriverWrapper &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;Command&nbsp;中的&nbsp;arguments&nbsp;为：&nbsp;Seq(&quot;{{WORKER_URL}}&quot;,&nbsp;&quot;{{USER_JAR}}&quot;,&nbsp;driverArgs.mainClass) 2）Master&nbsp;接受&nbsp;RequestSubmitDriver&nbsp;请求后，将&nbsp;DriverDescription&nbsp;封装为&nbsp;一个DriverInfo。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;startTime&nbsp;与&nbsp;submitDate&nbsp;都为当前时间 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;driverId&nbsp;格式为：driver-yyyyMMddHHmmss-nextId，nextId&nbsp;是全局唯一的 3）Master&nbsp;持久化&nbsp;DriverInfo，并加入待调度列表中&nbsp;(waitingDrivers)，触发公共资源调度逻辑。 4）Master&nbsp;公共资源调度结束后，返回&nbsp;SubmitDriverResponse给Client。 6.5 RpcMessage 处理 (receiveAndReply) 无。 6.6 OneWayMessage 处理(receive) 回到顶部 第7章 Driver 和 DriverRunner Client 向 Master 发起 RequestSubmitDriver 请求，Master 将 DriverInfo 添加待调度列表中 (waitingDrivers)，下面针对于 Driver 进一步梳理。 7.1 Master 对 Driver 资源分配 大致流程如下： 详解如下： waitingDrivers&nbsp;与&nbsp;aliveWorkers&nbsp;进行资源匹配： 1）在&nbsp;waitingDrivers&nbsp;循环内，轮询所有&nbsp;aliveWorker。 2）如果&nbsp;aliveWorker&nbsp;满足当前&nbsp;waitingDriver&nbsp;资源要求，给&nbsp;Worker&nbsp;发送&nbsp;LaunchDriver&nbsp;指令并将&nbsp;waitingDriver&nbsp;移除&nbsp;waitingDrivers，则进行下一次&nbsp;waitingDriver&nbsp;的轮询工作。 3）如果轮询完所有&nbsp;aliveWorker&nbsp;都不满足&nbsp;waitingDriver&nbsp;资源要求，则进行下一次&nbsp;waitingDriver&nbsp;的轮询工作。 4）所有发起的轮询开始点都上次轮询结束点的下一个点位开始。 7.2 Worker 运行 DriverRunner Driver 的启动，流程如下： 详解如下： 1）当&nbsp;Worker&nbsp;遇到&nbsp;LaunchDriver&nbsp;指令时，创建并启动一个&nbsp;DriverRunner。 2）DriverRunner&nbsp;启动一个线程&nbsp;DriverRunner&nbsp;for&nbsp;[driverId]&nbsp;处理&nbsp;Driver&nbsp;启动工作。 3）DriverRunner&nbsp;for&nbsp;[driverId]： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;添加&nbsp;JVM&nbsp;钩子，针对于每个&nbsp;diriverId&nbsp;创建一个临时目录。 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;DriverDesc.jarUrl&nbsp;通过&nbsp;Netty&nbsp;从&nbsp;Driver&nbsp;机器远程拷贝过来。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;根据&nbsp;DriverDesc.command&nbsp;模板构建本地执行的&nbsp;command&nbsp;命令，并启动该&nbsp;command&nbsp;对应的&nbsp;Process&nbsp;进程。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;将&nbsp;Process&nbsp;的输出流输出到文件&nbsp;stdout/stderror，如果&nbsp;Process&nbsp;启动失败，进行&nbsp;1-5&nbsp;的秒的反复启动工作，直到启动成功，在释放&nbsp;Worker&nbsp;节点的&nbsp;DriverRunner&nbsp;的资源。 7.3 DriverRunner 创建并运行 DriverWrapper DriverWrapper 的运行，流程如下： 详解如下： 1）DriverWapper&nbsp;创建了一个&nbsp;RpcEndpoint&nbsp;与&nbsp;RpcEnv。 2）RpcEndpoint&nbsp;为&nbsp;WorkerWatcher，主要目的为监控&nbsp;Worker&nbsp;节点是否正常，如果出现异常就直接退出。 3）然后当前的&nbsp;ClassLoader&nbsp;加载&nbsp;userJar，同时执行&nbsp;userMainClass。 4）执行用户的&nbsp;main&nbsp;方法后关闭&nbsp;workerWatcher。 回到顶部 第8章 SparkContext 解析 8.1 SparkContext 解析 SparkContext 是用户通往 Spark 集群的唯一入口，任何需要使用 Spark 的地方都需要先创建 SparkContext，那么 SparkContext 做了什么？ 首先 SparkContext 是在 Driver 程序里面启动的，可以看做 Driver 程序和 Spark 集群的一个连接，SparkContext 在初始化的时候，创建了很多对象，如下图所示： 上图列出了 SparkContext 在初始化创建的时候的一些主要组件的构建。 8.2 SparkContext 创建过程 详解如下： SparkContext&nbsp;在新建时： 1）内部创建一个&nbsp;SparkEnv，SparkEnv&nbsp;内部创建一个&nbsp;RpcEnv。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;RpcEnv&nbsp;内部创建并注册一个&nbsp;MapOutputTrackerMasterEndpoint(该&nbsp;Endpoint&nbsp;暂不介绍) 2）接着创建&nbsp;DAGScheduler、TaskSchedulerImpl、SchedulerBackend。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;TaskSchedulerImpl&nbsp;创建时创建&nbsp;SchedulableBuilder，SchedulableBuilder&nbsp;根据类型分为&nbsp;FIFOSchedulableBuilder、FairSchedulableBuilder&nbsp;两类 3）最后启动&nbsp;TaskSchedulerImpl，TaskSchedulerImpl&nbsp;启动&nbsp;SchedulerBackend。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;SchedulerBackend&nbsp;启动时创建&nbsp;ApplicationDescription、DriverEndpoint、StandloneAppClient &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;StandloneAppClient&nbsp;内部包括一个&nbsp;ClientEndpoint 8.3 SparkContext 简易结构与交互关系 详解如下： 1）SparkContext：是用户&nbsp;Spark&nbsp;执行任务的上下文，用户程序内部使用&nbsp;Spark&nbsp;提供的&nbsp;Api&nbsp;直接或间接创建一个&nbsp;SparkContext。 2）SparkEnv：用户执行的环境信息，包括通信相关的端点。 3）RpcEnv：SparkContext&nbsp;中远程通信环境。 4）ApplicationDescription：应用程序描述信息，主要包含&nbsp;appName、maxCores、memoryPerExecutorMB、coresPerExecutor、Command&nbsp;(CoarseGrainedExecutorBackend)、appUiUrl&nbsp;等。 5）ClientEndpoint：客户端端点，启动后向&nbsp;Master&nbsp;发起注册&nbsp;RegisterApplication&nbsp;请求。 6）Master：接受&nbsp;RegisterApplication&nbsp;请求后，进行&nbsp;Worker&nbsp;资源分配，并向分配的资源发起&nbsp;LaunchExecutor&nbsp;指令。 7）Worker：接受&nbsp;LaunchExecutor&nbsp;指令后，运行&nbsp;ExecutorRunner。 8）ExecutorRunner：运行&nbsp;applicationDescription&nbsp;的&nbsp;Command&nbsp;命令，最终&nbsp;Executor，同时向&nbsp;DriverEndpoint&nbsp;注册&nbsp;Executor&nbsp;信息。 8.4 Master 对 Application 资源分配 当 Master 接受 Driver 的 RegisterApplication 请求后，放入 waitingDrivers 队列中，在同一调度中进行资源分配，分配过程如下： 详解如下： waitingApps&nbsp;与&nbsp;aliveWorkers&nbsp;进行资源匹配： 1）如果&nbsp;waitingApp&nbsp;配置了&nbsp;app.desc.coresPerExecutor： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;轮询所有有效可分配的&nbsp;worker，每次分配一个&nbsp;executor，executor&nbsp;的核数为&nbsp;minCoresPerExecutor(app.desc.coresPerExecutor)，直到不存在有效可分配资源或者&nbsp;app&nbsp;依赖的资源已全部被分配。 2）如果&nbsp;waitingApp&nbsp;没有配置&nbsp;app.desc.coresPerExecutor： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;轮询所有有效可分配的&nbsp;worker，每个&nbsp;worker&nbsp;分配一个&nbsp;executor，executor&nbsp;的核数为从&nbsp;minCoresPerExecutor(为固定值1)&nbsp;开始递增，直到不存在有效可分配资源或者&nbsp;app&nbsp;依赖的资源已全部被分配。 3）其中有效可分配&nbsp;worker&nbsp;定义为满足一次资源分配的&nbsp;worker： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;cores&nbsp;满足：usableWorkers(pos).coresFree&nbsp;-&nbsp;assignedCores(pos)&nbsp;&gt;=&nbsp;minCoresPerExecutor &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;memory&nbsp;满足(如果是新的&nbsp;Executor)：usableWorkers(pos).memoryFree&nbsp;-&nbsp;assignedExecutors(pos)&nbsp;*&nbsp;memoryPerExecutor&nbsp;&gt;=&nbsp;memoryPerExecutor 注意：Master&nbsp;针对于&nbsp;applicationInfo&nbsp;进行资源分配时，只有存在有效可用的资源就直接分配，而分配剩余的&nbsp;app.coresLeft&nbsp;则等下一次再进行分配。 8.5 Worker 创建 Executor （图解：橙色组件是 Endpoint 组件） 详解如下： Worker&nbsp;启动&nbsp;Executor 1）在&nbsp;Worker&nbsp;的&nbsp;tempDir&nbsp;下面创建&nbsp;application&nbsp;以及&nbsp;executor&nbsp;的目录，并&nbsp;chmod&nbsp;700&nbsp;操作权限。 2）创建并启动&nbsp;ExecutorRunner&nbsp;进行&nbsp;Executor&nbsp;的创建。 3）向&nbsp;Master&nbsp;发送&nbsp;Executor&nbsp;的状态情况。 ExecutorRnner 1）新线程【ExecutorRunner&nbsp;for&nbsp;[executorId]】读取&nbsp;ApplicationDescription&nbsp;将其中&nbsp;Command&nbsp;转化为本地的&nbsp;Command&nbsp;命令。 2）调用&nbsp;Command&nbsp;并将日志输出至&nbsp;executor&nbsp;目录下的&nbsp;stdout&nbsp;和&nbsp;stderr&nbsp;日志文件中，Command&nbsp;对应的&nbsp;java&nbsp;类为&nbsp;CoarseGrainedExecutorBackend。 CoarseGrainedExecutorBackend 1）创建一个&nbsp;SparkEnv，创建&nbsp;ExecutorEndpoint(CoarseGrainedExecutorBackend)以及&nbsp;WorkerWatcher。 2）ExecutorEndpoint&nbsp;创建并启动后，向&nbsp;DriverEndpoint&nbsp;发送&nbsp;RegisterExecutor&nbsp;请求并等待返回。 3）DriverEndpoint&nbsp;处理&nbsp;RegisterExecutor&nbsp;请求，返回&nbsp;ExecutorEndpointRegister&nbsp;的结果。 4）如果注册成功，ExecutorEndpoint&nbsp;内部再创建&nbsp;Executor&nbsp;的处理对象。 至此，Spark&nbsp;运行任务的容器框架就搭建完成。 回到顶部 第9章 Job 提交和 Task 的拆分 在前面的章节 Client 的加载中，Spark 的 DriverRunner 已开始执行用户任务类（比如：org.apache.spark.examples.SparkPi），下面我们开始针对于用户任务类（或者任务代码）进行分析： 9.1 整体预览 详解如下： 1）Code：指的用户编写的代码 2）RDD：弹性分布式数据集，用户编码根据&nbsp;SparkContext&nbsp;与&nbsp;RDD&nbsp;的&nbsp;api&nbsp;能够很好的将&nbsp;Code&nbsp;转化为&nbsp;RDD&nbsp;数据结构(下文将做转化细节介绍)。 3）DAGScheduler：有向无环图调度器，将&nbsp;RDD&nbsp;封装为&nbsp;JobSubmitted&nbsp;对象存入&nbsp;EventLoop&nbsp;(实现类DAGSchedulerEventProcessLoop)&nbsp;队列中。 4）EventLoop：&nbsp;定时扫描未处理&nbsp;JobSubmitted&nbsp;对象，将&nbsp;JobSubmitted&nbsp;对象提交给&nbsp;DAGScheduler。 5）DAGScheduler：针对于&nbsp;JobSubmitted&nbsp;进行处理，最终将&nbsp;RDD&nbsp;转化为执行&nbsp;TaskSet，并将&nbsp;TaskSet&nbsp;提交至&nbsp;TaskScheduler。 6）TaskScheduler：&nbsp;根据&nbsp;TaskSet&nbsp;创建&nbsp;TaskSetManager&nbsp;对象存入&nbsp;SchedulableBuilder&nbsp;的数据池(Pool)中，并调用&nbsp;DriverEndpoint&nbsp;唤起消费(ReviveOffers)操作。 7）DriverEndpoint：接受&nbsp;ReviveOffers&nbsp;指令后将&nbsp;TaskSet&nbsp;中的&nbsp;Tasks&nbsp;根据相关规则均匀分配给Executor。 8）Executor：启动一个&nbsp;TaskRunner&nbsp;执行一个&nbsp;Task。 9.2 Code 转化为初始 RDDs 我们的用户代码通过调用 Spark 的 Api（比如：SparkSession.builder.appName(&quot;Spark Pi&quot;).getOrCreate()），该 Api 会创建 Spark 的上下文（SparkContext），当我们调用 transform 类方法（如：parallelize(),map()）都会创建（或者装饰已有的）Spark 数据结构（RDD），如果是 action 类操作（如：reduce()），那么将最后封装的 RDD 作为一次 Job 提交，存入待调度队列中（DAGSchedulerEventProcessLoop ）待后续异步处理。 如果多次调用 action 类操作，那么封装的多个 RDD 作为多个 Job 提交。 流程如下： 详解如下： ExecuteEnv（执行环境） 1）这里可以是通过&nbsp;spark-submit&nbsp;提交的&nbsp;MainClass，也可以是&nbsp;spark-shell&nbsp;脚本。 2）MainClass：代码中必定会创建或者获取一个&nbsp;SparkContext。 3）spark-shell：默认会创建一个&nbsp;SparkContext。 RDD（弹性分布式数据集） 1）create：可以直接创建（如：sc.parallelize(1&nbsp;until&nbsp;n,&nbsp;slices)&nbsp;），也可以在其他地方读取（如：sc.textFile(&quot;README.md&quot;)）等。 2）transformation：rdd&nbsp;提供了一组&nbsp;api&nbsp;可以进行对已有&nbsp;RDD&nbsp;进行反复封装成为新的&nbsp;RDD，这里采用的是`装饰者设计模式`，下面为部分装饰器类图。 3）action：当调用&nbsp;RDD&nbsp;的&nbsp;action&nbsp;类操作方法时（collect、reduce、lookup、save&nbsp;），这触发&nbsp;DAGScheduler&nbsp;的&nbsp;Job&nbsp;提交。 4）DAGScheduler：创建一个名为&nbsp;JobSubmitted&nbsp;的消息至&nbsp;DAGSchedulerEventProcessLoop&nbsp;阻塞消息队列（LinkedBlockingDeque）中。 5）DAGSchedulerEventProcessLoop：启动名为【dag-scheduler-event-loop】的线程实时消费消息队列。 6）【dag-scheduler-event-loop】处理完成后回调&nbsp;JobWaiter。 7）DAGScheduler：打印&nbsp;Job&nbsp;执行结果。 8）JobSubmitted：相关代码如下（其中&nbsp;jobId&nbsp;为&nbsp;DAGScheduler&nbsp;全局递增&nbsp;Id）。 &nbsp;&nbsp;&nbsp;&nbsp;eventProcessLoop.post(JobSubmitted( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobId,&nbsp;rdd,&nbsp;func2,&nbsp;partitions.toArray,&nbsp;callSite,&nbsp;waiter, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SerializationUtils.clone(properties))) 部分装饰器类图 最终示例： 最终转化的 RDD 分为四层，每层都依赖于上层 RDD，将 ShffleRDD 封装为一个 Job 存入 DAGSchedulerEventProcessLoop 待处理，如果我们的代码中存在几段上面示例代码，那么就会创建对应对的几个 ShffleRDD 分别存入 DAGSchedulerEventProcessLoop 中。 9.3 RDD 分解为待执行任务集合（TaskSet） Job 提交后，DAGScheduler 根据 RDD 层次关系解析为对应的 Stages，同时维护 Job 与 Stage 的关系。 将最上层的 Stage 根据并发关系（findMissingPartitions）分解为多个 Task，将这个多个 Task 封装为 TaskSet 提交给 TaskScheduler。非最上层的 Stage 的存入处理的列表中（waitingStages += stage） 流程如下： 详解如下： 1）DAGSchedulerEventProcessLoop中，线程【dag-scheduler-event-loop】处理到&nbsp;JobSubmitted 2）调用&nbsp;DAGScheduler&nbsp;进行&nbsp;handleJobSubmitted &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;首先根据&nbsp;RDD&nbsp;依赖关系依次创建&nbsp;Stage&nbsp;族，Stage&nbsp;分为&nbsp;ShuffleMapStage、ResultStage&nbsp;两类，如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;更新&nbsp;jobId&nbsp;与&nbsp;StageId&nbsp;关系&nbsp;Map &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;创建&nbsp;ActiveJob，调用&nbsp;LiveListenerBug，发送&nbsp;SparkListenerJobStart&nbsp;指令 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;找到最上层&nbsp;Stage&nbsp;进行提交，下层&nbsp;Stage&nbsp;存入&nbsp;waitingStage&nbsp;中待后续处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1)&nbsp;调用&nbsp;OutputCommitCoordinator&nbsp;进行&nbsp;stageStart()&nbsp;处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2)&nbsp;调用&nbsp;LiveListenerBug，发送&nbsp;SparkListenerStageSubmitted&nbsp;指令 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3)&nbsp;调用&nbsp;SparkContext的broadcast&nbsp;方法获取&nbsp;Broadcast&nbsp;对象，根据&nbsp;Stage&nbsp;类型创建对应多个&nbsp;Task，一个&nbsp;Stage&nbsp;根据&nbsp;findMissingPartitions&nbsp;分为多个对应的&nbsp;Task，Task&nbsp;分为&nbsp;ShuffleMapTask、ResultTask &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4)&nbsp;将&nbsp;Task&nbsp;封装为&nbsp;TaskSet，调用&nbsp;TaskScheduler.submitTasks(taskSet)&nbsp;进行&nbsp;Task&nbsp;调度，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskScheduler.submitTasks(new&nbsp;TaskSet( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tasks.toArray,&nbsp;stage.id,&nbsp;stage.latestInfo.attemptId,&nbsp;jobId,&nbsp;properties)) ShuffleMapStage、ResultStage 两类 9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver TaskScheduler 将 TaskSet 封装为 TaskSetManager(new TaskSetManager(this, taskSet, maxTaskFailures, blacklistTrackerOpt))，存入待处理任务池（Pool）中，发送 DriverEndpoint 唤起消费（ReviveOffers）指令。 详解如下： 1）DAGSheduler&nbsp;将&nbsp;TaskSet&nbsp;提交给&nbsp;TaskScheduler&nbsp;的实现类，这里是&nbsp;TaskChedulerImpl。 2）TaskSchedulerImpl&nbsp;创建一个&nbsp;TaskSetManager&nbsp;管理&nbsp;TaskSet，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;TaskSetManager(this,&nbsp;taskSet,&nbsp;maxTaskFailures,&nbsp;blacklistTrackerOpt) 3）同时将&nbsp;TaskSetManager&nbsp;添加&nbsp;SchedduableBuilder&nbsp;的任务池&nbsp;Poll&nbsp;中。 4）调用&nbsp;SchedulerBackend&nbsp;的实现类进行&nbsp;reviveOffers，这里是&nbsp;standlone&nbsp;模式的实现类&nbsp;StandaloneSchedulerBackend。 5）SchedulerBackend&nbsp;发送&nbsp;ReviveOffers&nbsp;指令至&nbsp;DriverEndpoint。 9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor Driver 接受唤起消费指令后，将所有待处理的 TaskSetManager 与 Driver 中注册的 Executor 资源进行匹配，最终一个 TaskSetManager 得到多个 TaskDescription 对象，按照 TaskDescription 相对应的 Executor 发送 LaunchTask 指令。 详解如下： 当&nbsp;Driver&nbsp;获取到&nbsp;ReviveOffers（请求消费）指令时 1）首先根据&nbsp;executorDataMap&nbsp;缓存信息得到可用的&nbsp;Executor&nbsp;资源信息（WorkerOffer），关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;activeExecutors&nbsp;=&nbsp;executorDataMap.filterKeys(executorIsAlive) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;workOffers&nbsp;=&nbsp;activeExecutors.map&nbsp;{&nbsp;case&nbsp;(id,&nbsp;executorData)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;WorkerOffer(id,&nbsp;executorData.executorHost,&nbsp;executorData.freeCores) &nbsp;&nbsp;&nbsp;&nbsp;}.toIndexedSeq 2）接着调用&nbsp;TaskScheduler&nbsp;进行资源匹配，方法定义如下： &nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;resourceOffers(offers:&nbsp;IndexedSeq[WorkerOffer]):&nbsp;Seq[Seq[TaskDescription]]&nbsp;=&nbsp;synchronized&nbsp;{..} &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;将&nbsp;WorkerOffer&nbsp;资源打乱，如：val&nbsp;shuffledOffers&nbsp;=&nbsp;Random.shuffle(offers) &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;Pool&nbsp;中待处理的&nbsp;TaskSetManager&nbsp;取出，如：val&nbsp;sortedTaskSets&nbsp;=&nbsp;rootPool.getSortedTaskSetQueue &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;并循环处理&nbsp;sortedTaskSets&nbsp;并与&nbsp;shuffledOffers&nbsp;循环匹配，如果&nbsp;shuffledOffers(i)&nbsp;有足够的&nbsp;CPU&nbsp;资源（&nbsp;if&nbsp;(availableCpus(i)&nbsp;&gt;=&nbsp;CPUS_PER_TASK)），调用&nbsp;TaskSetManager&nbsp;创建&nbsp;TaskDescription&nbsp;对象（taskSet.resourceOffer(execId,&nbsp;host,&nbsp;maxLocality)），最终创建了多个&nbsp;TaskDescription，TaskDescription&nbsp;定义如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;TaskDescription( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attemptNum, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;execId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskName, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;index, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sched.sc.addedFiles, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sched.sc.addedJars, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;task.localProperties, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serializedTask) 3）如果&nbsp;TaskDescriptions&nbsp;不为空，循环&nbsp;TaskDescriptions，序列化&nbsp;TaskDescription&nbsp;对象，并向&nbsp;ExecutorEndpoint&nbsp;发送&nbsp;LaunchTask&nbsp;指令，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(task&nbsp;&lt;-&nbsp;taskDescriptions.flatten)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;serializedTask&nbsp;=&nbsp;TaskDescription.encode(task) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;executorData&nbsp;=&nbsp;executorDataMap(task.executorId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorData.freeCores&nbsp;-=&nbsp;scheduler.CPUS_PER_TASK &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorData.executorEndpoint.send(LaunchTask(new&nbsp;SerializableBuffer(serializedTask))) &nbsp;&nbsp;&nbsp;&nbsp;} 回到顶部 第10章 Task 执行和回馈 DriverEndpoint 最终生成多个可执行的 TaskDescription 对象，并向各个 ExecutorEndpoint 发送 LaunchTask 指令，本节内容将关注 ExecutorEndpoint 如何处理 LaunchTask 指令，处理完成后如何回馈给 DriverEndpoint，以及整个 job 最终如何多次调度直至结束。 10.1 Task 的执行流程 Executor 接受 LaunchTask 指令后，开启一个新线程 TaskRunner 解析 RDD，并调用 RDD 的 compute 方法，归并函数得到最终任务执行结果。 详解如下： 1）ExecutorEndpoint&nbsp;接受到&nbsp;LaunchTask&nbsp;指令后，解码出&nbsp;TaskDescription，调用&nbsp;Executor&nbsp;的&nbsp;launchTask&nbsp;方法。 2）Executor&nbsp;创建一个&nbsp;TaskRunner&nbsp;线程，并启动线程，同时将改线程添加到&nbsp;Executor&nbsp;的成员对象中，代码如下： &nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;val&nbsp;runningTasks&nbsp;=&nbsp;new&nbsp;ConcurrentHashMap[Long,&nbsp;TaskRunner] &nbsp;&nbsp;&nbsp;&nbsp;runningTasks.put(taskDescription.taskId,&nbsp;taskRunner) TaskRunner 1）首先向&nbsp;DriverEndpoint&nbsp;发送任务最新状态为&nbsp;RUNNING。 2）从&nbsp;TaskDescription&nbsp;解析出&nbsp;Task，并调用&nbsp;Task&nbsp;的&nbsp;run&nbsp;方法。 Task 1）创建&nbsp;TaskContext&nbsp;以及&nbsp;CallerContext&nbsp;(与&nbsp;HDFS&nbsp;交互的上下文对象)。 2）执行&nbsp;Task&nbsp;的&nbsp;runTask&nbsp;方法： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;如果&nbsp;Task&nbsp;实例为&nbsp;ShuffleMapTask：解析出&nbsp;RDD&nbsp;以及&nbsp;ShuffleDependency&nbsp;信息，调用&nbsp;RDD&nbsp;的&nbsp;compute()&nbsp;方法将结果写&nbsp;Writer&nbsp;中（Writer&nbsp;这里不介绍，可以作为黑盒理解，比如写入一个文件中），返回&nbsp;MapStatus&nbsp;对象。 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;如果&nbsp;Task&nbsp;实例为&nbsp;ResultTask：解析出&nbsp;RDD&nbsp;以及合并函数信息，调用函数将调用后的结果返回。 TaskRunner&nbsp;将&nbsp;Task&nbsp;执行的结果序列化，再次向&nbsp;DriverEndpoint&nbsp;发送任务最新状态为&nbsp;FINISHED。 10.2 Task 的回馈流程 TaskRunner 执行结束后，都将执行状态发送至 DriverEndpoint，DriverEndpoint 最终反馈指令 CompletionEvent 发送至 DAGSchedulerEventProcessLoop 中。 详解如下： 1）DriverEndpoint&nbsp;接收到&nbsp;StatusUpdate&nbsp;消息后，调用&nbsp;TaskScheduler&nbsp;的&nbsp;statusUpdate(taskId,&nbsp;state,&nbsp;result)&nbsp;方法 2）TaskScheduler&nbsp;如果任务结果是完成，那么清除该任务处理中的状态，并调动&nbsp;TaskResultGetter&nbsp;相关方法，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;taskSet&nbsp;=&nbsp;taskIdToTaskSetManager.get(tid) &nbsp;&nbsp;&nbsp;&nbsp;taskIdToTaskSetManager.remove(tid) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskIdToExecutorId.remove(tid).foreach&nbsp;{&nbsp;executorId&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorIdToRunningTaskIds.get(executorId).foreach&nbsp;{&nbsp;_.remove(tid)&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;taskSet.removeRunningTask(tid) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(state&nbsp;==&nbsp;TaskState.FINISHED)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskResultGetter.enqueueSuccessfulTask(taskSet,&nbsp;tid,&nbsp;serializedData) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(Set(TaskState.FAILED,&nbsp;TaskState.KILLED,&nbsp;TaskState.LOST).contains(state))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskResultGetter.enqueueFailedTask(taskSet,&nbsp;tid,&nbsp;state,&nbsp;serializedData) &nbsp;&nbsp;&nbsp;&nbsp;} TaskResultGetter&nbsp;启动线程启动线程【task-result-getter】进行相关处理： 1）通过解析或者远程获取得到&nbsp;Task&nbsp;的&nbsp;TaskResult&nbsp;对象。 2）调用&nbsp;TaskSet&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法，TaskSet&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法直接调用&nbsp;TaskSetManager&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法。 TaskSetManager 1）更新内部&nbsp;TaskInfo&nbsp;对象状态，并将该&nbsp;Task&nbsp;从运行中&nbsp;Task&nbsp;的集合删除，代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;info&nbsp;=&nbsp;taskInfos(tid) &nbsp;&nbsp;&nbsp;&nbsp;info.markFinished(TaskState.FINISHED,&nbsp;clock.getTimeMillis()) &nbsp;&nbsp;&nbsp;&nbsp;removeRunningTask(tid) 2）调用&nbsp;DAGScheduler&nbsp;的&nbsp;taskEnded&nbsp;方法，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;sched.dagScheduler.taskEnded(tasks(index),&nbsp;Success,&nbsp;result.value(),&nbsp;result.accumUpdates,&nbsp;info) DAGScheduler&nbsp;向&nbsp;DAGSchedulerEventProcessLoop&nbsp;存入&nbsp;CompletionEvent&nbsp;指令，CompletionEvent&nbsp;对象定义如下： &nbsp;&nbsp;&nbsp;&nbsp;private[scheduler]&nbsp;case&nbsp;class&nbsp;CompletionEvent( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;task:&nbsp;Task[_], &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reason:&nbsp;TaskEndReason, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result:&nbsp;Any, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accumUpdates:&nbsp;Seq[AccumulatorV2[_,&nbsp;_]], &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskInfo:&nbsp;TaskInfo)&nbsp;extends&nbsp;DAGSchedulerEvent 10.3 Task 的迭代流程 DAGSchedulerEventProcessLoop 中针对于 CompletionEvent 指令，调用 DAGScheduler 进行处理，DAGScheduler 更新 Stage 与该 Task 的关系状态，如果 Stage 下 Task 都返回，则做下一层 Stage 的任务拆解与运算工作，直至 Job 被执行完毕： 详解如下： 1）DAGSchedulerEventProcessLoop&nbsp;接收到&nbsp;CompletionEvent&nbsp;指令后，调用&nbsp;DAGScheduler&nbsp;的&nbsp;handleTaskCompletion&nbsp;方法。 2）DAGScheduler&nbsp;根据&nbsp;Task&nbsp;的类型分别处理。 3）如果&nbsp;Task&nbsp;为&nbsp;ShuffleMapTask &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;等待回馈的&nbsp;Partitions&nbsp;减去当前&nbsp;partitionId &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;如果所有&nbsp;task&nbsp;都返回，则&nbsp;markStageAsFinished(shuffleStage)，同时向&nbsp;MapOutputTrackerMaster&nbsp;注册&nbsp;MapOutputs&nbsp;信息，且&nbsp;markMapStageJobAsFinished &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;调用&nbsp;submitWaitingChildStages(shuffleStage)&nbsp;进行下层&nbsp;Stages&nbsp;的处理，从而迭代处理，最终处理到&nbsp;ResultTask，job&nbsp;结束，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;def&nbsp;submitWaitingChildStages(parent:&nbsp;Stage)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;childStages&nbsp;=&nbsp;waitingStages.filter(_.parents.contains(parent)).toArray &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingStages&nbsp;--=&nbsp;childStages &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(stage&nbsp;&lt;-&nbsp;childStages.sortBy(_.firstJobId))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;submitStage(stage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} 4）如果&nbsp;Task&nbsp;为&nbsp;ResultTask &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;该&nbsp;job&nbsp;的&nbsp;partitions&nbsp;都已返回，则&nbsp;markStageAsFinished(resultStage)，并&nbsp;cleanupStateForJobAndIndependentStages(job)，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(stage&nbsp;&lt;-&nbsp;stageIdToStage.get(stageId))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(runningStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;running&nbsp;stage&nbsp;%d&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;((k,&nbsp;v)&nbsp;&lt;-&nbsp;shuffleIdToMapStage.find(_._2&nbsp;==&nbsp;stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shuffleIdToMapStage.remove(k) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(waitingStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;stage&nbsp;%d&nbsp;from&nbsp;waiting&nbsp;set.&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(failedStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;stage&nbsp;%d&nbsp;from&nbsp;failed&nbsp;set.&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;failedStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;data&nbsp;structures&nbsp;based&nbsp;on&nbsp;StageId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stageIdToStage&nbsp;-=&nbsp;stageId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobIdToStageIds&nbsp;-=&nbsp;job.jobId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobIdToActiveJob&nbsp;-=&nbsp;job.jobId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeJobs&nbsp;-=&nbsp;job 至此，用户编写的代码最终调用&nbsp;Spark&nbsp;分布式计算完毕。 10.4 精彩图解 Spark的交互流程 – 节点启动 Spark的交互流程 – 应用提交 Spark的交互流程 – 任务运行 Spark的交互流程 – 任务运行 回到顶部 第11章 Spark 的数据存储 Spark 计算速度远胜于 Hadoop 的原因之一就在于中间结果是缓存在内存而不是直接写入到 disk，本文尝试分析 Spark 中存储子系统的构成，并以数据写入和数据读取为例，讲述清楚存储子系统中各部件的交互关系。 11.1 存储子系统概览 Storage 模块主要分为两层：   1) 通信层：storage 模块采用的是 master-slave 结构来实现通信层，master 和 slave 之间传输控制信息、状态信息，这些都是通过通信层来实现的。   2) 存储层：storage 模块需要把数据存储到 disk 或是 memory 上面，有可能还需 replicate(复制) 到远端，这都是由存储层来实现和提供相应接口。 而其他模块若要和 storage 模块进行交互，storage 模块提供了统一的操作类 BlockManager，外部类与 storage 模块打交道都需要通过调用 BlockManager 相应接口来实现。 上图是Spark存储子系统中几个主要模块的关系示意图，现简要说明如下： 1）CacheManager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RDD&nbsp;在进行计算的时候，通过&nbsp;CacheManager&nbsp;来获取数据，并通过&nbsp;CacheManager&nbsp;来存储计算结果。 2）BlockManager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CacheManager&nbsp;在进行数据读取和存取的时候主要是依赖&nbsp;BlockManager&nbsp;接口来操作，BlockManager&nbsp;决定数据是从内存(MemoryStore)&nbsp;还是从磁盘(DiskStore)&nbsp;中获取。 3）MemoryStore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;负责将数据保存在内存或从内存读取。 4）DiskStore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;负责将数据写入磁盘或从磁盘读入。 5）BlockManagerWorker&nbsp;&nbsp;&nbsp;数据写入本地的&nbsp;MemoryStore&nbsp;或&nbsp;DiskStore&nbsp;是一个同步操作，为了容错还需要将数据复制到别的计算结点，以防止数据丢失的时候还能够恢复，数据复制的操作是异步完成，由&nbsp;BlockManagerWorker&nbsp;来处理这一部分事情。 6）ConnectionManager&nbsp;&nbsp;&nbsp;&nbsp;负责与其它计算结点建立连接，并负责数据的发送和接收。 7）BlockManagerMaster&nbsp;&nbsp;&nbsp;注意该模块只运行在&nbsp;Driver&nbsp;Application&nbsp;所在的&nbsp;Executor，功能是负责记录下所有&nbsp;BlockIds&nbsp;存储在哪个&nbsp;SlaveWorker&nbsp;上，比如&nbsp;RDD&nbsp;Task&nbsp;运行在机器&nbsp;A，所需要的&nbsp;BlockId&nbsp;为&nbsp;3，但在机器&nbsp;A&nbsp;上没有&nbsp;BlockId&nbsp;为&nbsp;3&nbsp;的数值，这个时候&nbsp;Slave&nbsp;worker&nbsp;需要通过&nbsp;BlockManager&nbsp;向&nbsp;BlockManagerMaster&nbsp;询问数据存储的位置，然后再通过&nbsp;ConnectionManager&nbsp;去获取。 11.2 启动过程分析 上述的各个模块由 SparkEnv 来创建，创建过程在 SparkEnv.create 中完成，代码如下： val&nbsp;blockManagerMaster&nbsp;=&nbsp;new&nbsp;BlockManagerMaster(registerOrLookup( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;BlockManagerMaster&quot;, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;BlockManagerMasterActor(isLocal,&nbsp;conf)),&nbsp;conf) val&nbsp;blockManager&nbsp;=&nbsp;new&nbsp;BlockManager(executorId,&nbsp;actorSystem,&nbsp;blockManagerMaster,&nbsp;serializer,&nbsp;conf) val&nbsp;connectionManager&nbsp;=&nbsp;blockManager.connectionManager val&nbsp;broadcastManager&nbsp;=&nbsp;new&nbsp;BroadcastManager(isDriver,&nbsp;conf) val&nbsp;cacheManager&nbsp;=&nbsp;new&nbsp;CacheManager(blockManager) 下面这段代码容易让人疑惑，看起来像是在所有的 cluster node 上都创建了 BlockManagerMasterActor，其实不然，仔细看 registerOrLookup 函数的实现。如果当前节点是 driver 则创建这个 actor，否则建立到 driver 的连接。代码如下： def&nbsp;registerOrLookup(name:&nbsp;String,&nbsp;newActor:&nbsp;=&gt;&nbsp;Actor):&nbsp;ActorRef&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;&quot;&nbsp;+&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;actorSystem.actorOf(Props(newActor),&nbsp;name&nbsp;=&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;driverHost:&nbsp;String&nbsp;=&nbsp;conf.get(&quot;spark.driver.host&quot;,&nbsp;&quot;localhost&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;driverPort:&nbsp;Int&nbsp;=&nbsp;conf.getInt(&quot;spark.driver.port&quot;,&nbsp;7077) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Utils.checkHost(driverHost,&nbsp;&quot;Expected&nbsp;hostname&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;url&nbsp;=&nbsp;s&quot;akka.tcp://spark@$driverHost:$driverPort/user/$name&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;timeout&nbsp;=&nbsp;AkkaUtils.lookupTimeout(conf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(s&quot;Connecting&nbsp;to&nbsp;$name:&nbsp;$url&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Await.result(actorSystem.actorSelection(url).resolveOne(timeout),&nbsp;timeout) &nbsp;&nbsp;&nbsp;&nbsp;} } 初始化过程中一个主要的动作就是 BlockManager 需要向 BlockManagerMaster 发起注册。 11.3 通信层 BlockManager 包装了 BlockManagerMaster，发送信息包装成 BlockManagerInfo。Spark 在 Driver 和 Worker 端都创建各自的 BlockManager，并通过 BlockManagerMaster 进行通信，通过 BlockManager 对 Storage 模块进行操作。 BlockManager 对象在 SparkEnv.create 函数中进行创建，代码如下： def&nbsp;registerOrLookupEndpoint( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;String,&nbsp;endpointCreator:&nbsp;=&gt;&nbsp;RpcEndpoint): RpcEndpointRef&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;&quot;&nbsp;+&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rpcEnv.setupEndpoint(name,&nbsp;endpointCreator) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RpcUtils.makeDriverRef(name,&nbsp;conf,&nbsp;rpcEnv) &nbsp;&nbsp;&nbsp;&nbsp;} } ...... val&nbsp;blockManagerMaster&nbsp;=&nbsp;new&nbsp;BlockManagerMaster(registerOrLookupEndpoint( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockManagerMaster.DRIVER_ENDPOINT_NAME, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;BlockManagerMasterEndpoint(rpcEnv,&nbsp;isLocal,&nbsp;conf,&nbsp;listenerBus)), &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;conf,&nbsp;isDriver) //&nbsp;NB:&nbsp;blockManager&nbsp;is&nbsp;not&nbsp;valid&nbsp;until&nbsp;initialize()&nbsp;is&nbsp;called&nbsp;later. val&nbsp;blockManager&nbsp;=&nbsp;new&nbsp;BlockManager(executorId,&nbsp;rpcEnv,&nbsp;blockManagerMaster, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serializer,&nbsp;conf,&nbsp;mapOutputTracker,&nbsp;shuffleManager,&nbsp;blockTransferService,&nbsp;securityManager,numUsableCores) 并且在创建之前对当前节点是否是 Driver 进行了判断。如果是，则创建这个 Endpoint；否则，创建 Driver 的连接。 在创建 BlockManager 之后，BlockManager 会调用 initialize 方法初始化自己。并且初始化的时候，会调用 BlockManagerMaster 向 Driver 注册自己，同时，在注册时也启动了Slave Endpoint。另外，向本地 shuffle 服务器注册 Executor 配置，如果存在的话。代码如下： def&nbsp;initialize(appId:&nbsp;String):&nbsp;Unit&nbsp;=&nbsp;{ ...... &nbsp;&nbsp;&nbsp;&nbsp;master.registerBlockManager(blockManagerId,&nbsp;maxMemory,&nbsp;slaveEndpoint) &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Register&nbsp;Executors&#39;&nbsp;configuration&nbsp;with&nbsp;the&nbsp;local&nbsp;shuffle&nbsp;service,&nbsp;if&nbsp;one&nbsp;should&nbsp;exist. &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(externalShuffleServiceEnabled&nbsp;&amp;&amp;&nbsp;!blockManagerId.isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;registerWithExternalShuffleServer() &nbsp;&nbsp;&nbsp;&nbsp;} } 而 BlockManagerMaster 将注册请求包装成 RegisterBlockManager 注册到 Driver。Driver 的 BlockManagerMasterEndpoint 会调用 register 方法，通过对消息 BlockManagerInfo 检查，向 Driver 注册，代码如下： private&nbsp;def&nbsp;register(id:&nbsp;BlockManagerId,&nbsp;maxMemSize:&nbsp;Long,&nbsp;slaveEndpoint:&nbsp;RpcEndpointRef)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;time&nbsp;=&nbsp;System.currentTimeMillis() &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!blockManagerInfo.contains(id))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerIdByExecutor.get(id.executorId)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(oldId)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;A&nbsp;block&nbsp;manager&nbsp;of&nbsp;the&nbsp;same&nbsp;executor&nbsp;already&nbsp;exists,&nbsp;so&nbsp;remove&nbsp;it&nbsp;(assumed&nbsp;dead) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logError(&quot;Got&nbsp;two&nbsp;different&nbsp;block&nbsp;manager&nbsp;registrations&nbsp;on&nbsp;same&nbsp;executor&nbsp;-&nbsp;&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;s&quot;&nbsp;will&nbsp;replace&nbsp;old&nbsp;one&nbsp;$oldId&nbsp;with&nbsp;new&nbsp;one&nbsp;$id&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;removeExecutor(id.executorId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;block&nbsp;manager&nbsp;%s&nbsp;with&nbsp;%s&nbsp;RAM,&nbsp;%s&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id.hostPort,&nbsp;Utils.bytesToString(maxMemSize),&nbsp;id)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerIdByExecutor(id.executorId)&nbsp;=&nbsp;id &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerInfo(id)&nbsp;=&nbsp;new&nbsp;BlockManagerInfo( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id,&nbsp;System.currentTimeMillis(),&nbsp;maxMemSize,&nbsp;slaveEndpoint) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;listenerBus.post(SparkListenerBlockManagerAdded(time,&nbsp;id,&nbsp;maxMemSize)) } 不难发现 BlockManagerInfo 对象被保存到 Map 映射中。在通信层中 BlockManagerMaster 控制着消息的流向，这里采用了模式匹配，所有的消息模式都在 BlockManagerMessage 中。 11.4 存储层 Spark Storage 的最小存储单位是 block，所有的操作都是以 block 为单位进行的。 在 BlockManager 被创建的时候 MemoryStore 和 DiskStore 对象就被创建出来了。代码如下： val&nbsp;diskBlockManager&nbsp;=&nbsp;new&nbsp;DiskBlockManager(this,&nbsp;conf) private[spark]&nbsp;val&nbsp;memoryStore&nbsp;=&nbsp;new&nbsp;MemoryStore(this,&nbsp;maxMemory) private[spark]&nbsp;val&nbsp;diskStore&nbsp;=&nbsp;new&nbsp;DiskStore(this,&nbsp;diskBlockManager) 11.4.1 Disk Store 由于当前的 Spark 版本对 Disk Store 进行了更细粒度的分工，把对文件的操作提取出来放到了 DiskBlockManager 中，DiskStore 仅仅负责数据的存储和读取。 Disk Store 会配置多个文件目录，Spark 会在不同的文件目录下创建文件夹，其中文件夹的命名方式是：spark-UUID（随机UUID码）。Disk Store 在存储的时候创建文件夹。并且根据【高内聚，低耦合】原则，这种服务型的工具代码就放到了 Utils 中（调用路径：DiskStore.putBytes —&gt; DiskBlockManager.createLocalDirs —&gt; Utils.createDirectory），代码如下： def&nbsp;createDirectory(root:&nbsp;String,&nbsp;namePrefix:&nbsp;String&nbsp;=&nbsp;&quot;spark&quot;):&nbsp;File&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;attempts&nbsp;=&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;maxAttempts&nbsp;=&nbsp;MAX_DIR_CREATION_ATTEMPTS &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;dir:&nbsp;File&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(dir&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attempts&nbsp;+=&nbsp;1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(attempts&nbsp;&gt;&nbsp;maxAttempts)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Failed&nbsp;to&nbsp;create&nbsp;a&nbsp;temp&nbsp;directory&nbsp;(under&nbsp;&quot;&nbsp;+&nbsp;root&nbsp;+&nbsp;&quot;)&nbsp;after&nbsp;&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;maxAttempts&nbsp;+&nbsp;&quot;&nbsp;attempts!&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dir&nbsp;=&nbsp;new&nbsp;File(root,&nbsp;namePrefix&nbsp;+&nbsp;&quot;-&quot;&nbsp;+&nbsp;UUID.randomUUID.toString) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(dir.exists()&nbsp;||&nbsp;!dir.mkdirs())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dir&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;catch&nbsp;{&nbsp;case&nbsp;e:&nbsp;SecurityException&nbsp;=&gt;&nbsp;dir&nbsp;=&nbsp;null;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;dir.getCanonicalFile } 在 DiskBlockManager 里，每个 block 都被存储为一个 file，通过计算 blockId 的 hash 值，将 block 映射到文件中。 def&nbsp;getFile(filename:&nbsp;String):&nbsp;File&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Figure&nbsp;out&nbsp;which&nbsp;local&nbsp;directory&nbsp;it&nbsp;hashes&nbsp;to,&nbsp;and&nbsp;which&nbsp;subdirectory&nbsp;in&nbsp;that &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;hash&nbsp;=&nbsp;Utils.nonNegativeHash(filename) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;dirId&nbsp;=&nbsp;hash&nbsp;%&nbsp;localDirs.length &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;subDirId&nbsp;=&nbsp;(hash&nbsp;/&nbsp;localDirs.length)&nbsp;%&nbsp;subDirsPerLocalDir &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;the&nbsp;subdirectory&nbsp;if&nbsp;it&nbsp;doesn&#39;t&nbsp;already&nbsp;exist &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;subDir&nbsp;=&nbsp;subDirs(dirId).synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;old&nbsp;=&nbsp;subDirs(dirId)(subDirId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(old&nbsp;!=&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;old &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;newDir&nbsp;=&nbsp;new&nbsp;File(localDirs(dirId),&nbsp;&quot;%02x&quot;.format(subDirId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!newDir.exists()&nbsp;&amp;&amp;&nbsp;!newDir.mkdir())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(s&quot;Failed&nbsp;to&nbsp;create&nbsp;local&nbsp;dir&nbsp;in&nbsp;$newDir.&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;subDirs(dirId)(subDirId)&nbsp;=&nbsp;newDir &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;newDir &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;File(subDir,&nbsp;filename) } def&nbsp;getFile(blockId:&nbsp;BlockId):&nbsp;File&nbsp;=&nbsp;getFile(blockId.name) 通过 hash 值的取模运算，求出 dirId 和 subDirId。然后，在从 subDirs 中找到 subDir，如果 subDir 不存在，则创建一个新 subDir。最后，以 subDir 为路径，blockId 的 name 属性为文件名，新建该文件。 文件创建完之后，那么 Spark 就会在 DiskStore 中向文件写与之映射的 block，代码如下： override&nbsp;def&nbsp;putBytes(blockId:&nbsp;BlockId,&nbsp;_bytes:&nbsp;ByteBuffer,&nbsp;level:&nbsp;StorageLevel):&nbsp;PutResult&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bytes&nbsp;=&nbsp;_bytes.duplicate() &nbsp;&nbsp;&nbsp;&nbsp;logDebug(s&quot;Attempting&nbsp;to&nbsp;put&nbsp;block&nbsp;$blockId&quot;) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;startTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;file&nbsp;=&nbsp;diskManager.getFile(blockId) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;channel&nbsp;=&nbsp;new&nbsp;FileOutputStream(file).getChannel &nbsp;&nbsp;&nbsp;&nbsp;Utils.tryWithSafeFinally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(bytes.remaining&nbsp;&gt;&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.write(bytes) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.close() &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;finishTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Block&nbsp;%s&nbsp;stored&nbsp;as&nbsp;%s&nbsp;file&nbsp;on&nbsp;disk&nbsp;in&nbsp;%d&nbsp;ms&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file.getName,&nbsp;Utils.bytesToString(bytes.limit),&nbsp;finishTime&nbsp;-&nbsp;startTime)) &nbsp;&nbsp;&nbsp;&nbsp;PutResult(bytes.limit(),&nbsp;Right(bytes.duplicate())) } 读取过程就简单了，DiskStore 根据 blockId 读取与之映射的 file 内容，当然，这中间需要从 DiskBlockManager 中得到文件信息。代码如下： private&nbsp;def&nbsp;getBytes(file:&nbsp;File,&nbsp;offset:&nbsp;Long,&nbsp;length:&nbsp;Long):&nbsp;Option[ByteBuffer]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;channel&nbsp;=&nbsp;new&nbsp;RandomAccessFile(file,&nbsp;&quot;r&quot;).getChannel &nbsp;&nbsp;&nbsp;&nbsp;Utils.tryWithSafeFinally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;For&nbsp;small&nbsp;files,&nbsp;directly&nbsp;read&nbsp;rather&nbsp;than&nbsp;memory&nbsp;map &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(length&nbsp;&lt;&nbsp;minMemoryMapBytes)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;buf&nbsp;=&nbsp;ByteBuffer.allocate(length.toInt) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.position(offset) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(buf.remaining()&nbsp;!=&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(channel.read(buf)&nbsp;==&nbsp;-1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Reached&nbsp;EOF&nbsp;before&nbsp;filling&nbsp;buffer\n&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s&quot;offset=$offset\nfile=${file.getAbsolutePath}\nbuf.remaining=${buf.remaining}&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buf.flip() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(buf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(channel.map(MapMode.READ_ONLY,&nbsp;offset,&nbsp;length)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.close() &nbsp;&nbsp;&nbsp;&nbsp;} } override&nbsp;def&nbsp;getBytes(blockId:&nbsp;BlockId):&nbsp;Option[ByteBuffer]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;file&nbsp;=&nbsp;diskManager.getFile(blockId.name) &nbsp;&nbsp;&nbsp;&nbsp;getBytes(file,&nbsp;0,&nbsp;file.length) } 11.4.2 Memory Store 相对 Disk Store，Memory Store 就显得容易很多。Memory Store 用一个 LinkedHashMap 来管理，其中 Key 是 blockId，Value 是 MemoryEntry 样例类，MemoryEntry 存储着数据信息。代码如下： private&nbsp;case&nbsp;class&nbsp;MemoryEntry(value:&nbsp;Any,&nbsp;size:&nbsp;Long,&nbsp;deserialized:&nbsp;Boolean) private&nbsp;val&nbsp;entries&nbsp;=&nbsp;new&nbsp;LinkedHashMap[BlockId,&nbsp;MemoryEntry](32,&nbsp;0.75f,&nbsp;true) 在 MemoryStore 中存储 block 的前提是当前内存有足够的空间存放。通过对 tryToPut 函数的调用对内存空间进行判断。代码如下： def&nbsp;putBytes(blockId:&nbsp;BlockId,&nbsp;size:&nbsp;Long,&nbsp;_bytes:&nbsp;()&nbsp;=&gt;&nbsp;ByteBuffer):&nbsp;PutResult&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Work&nbsp;on&nbsp;a&nbsp;duplicate&nbsp;-&nbsp;since&nbsp;the&nbsp;original&nbsp;input&nbsp;might&nbsp;be&nbsp;used&nbsp;elsewhere. &nbsp;&nbsp;&nbsp;&nbsp;lazy&nbsp;val&nbsp;bytes&nbsp;=&nbsp;_bytes().duplicate().rewind().asInstanceOf[ByteBuffer] &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putAttempt&nbsp;=&nbsp;tryToPut(blockId,&nbsp;()&nbsp;=&gt;&nbsp;bytes,&nbsp;size,&nbsp;deserialized&nbsp;=&nbsp;false) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;data&nbsp;= &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putAttempt.success)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(bytes.limit&nbsp;==&nbsp;size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right(bytes.duplicate()) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;PutResult(size,&nbsp;data,&nbsp;putAttempt.droppedBlocks) } 在 tryToPut 函数中，通过调用 enoughFreeSpace 函数判断内存空间。如果内存空间足够，那么就把 block 放到 LinkedHashMap 中；如果内存不足，那么就告诉 BlockManager 内存不足，如果允许 Disk Store，那么就把该 block 放到 disk 上。代码如下： private&nbsp;def&nbsp;tryToPut(blockId:&nbsp;BlockId,&nbsp;value:&nbsp;()&nbsp;=&gt;&nbsp;Any,&nbsp;size:&nbsp;Long,&nbsp;deserialized:&nbsp;Boolean):&nbsp;ResultWithDroppedBlocks&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;putSuccess&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;droppedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;accountingLock.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;freeSpaceResult&nbsp;=&nbsp;ensureFreeSpace(blockId,&nbsp;size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;enoughFreeSpace&nbsp;=&nbsp;freeSpaceResult.success &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;droppedBlocks&nbsp;++=&nbsp;freeSpaceResult.droppedBlocks &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(enoughFreeSpace)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;entry&nbsp;=&nbsp;new&nbsp;MemoryEntry(value(),&nbsp;size,&nbsp;deserialized) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.put(blockId,&nbsp;entry) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;currentMemory&nbsp;+=&nbsp;size &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;valuesOrBytes&nbsp;=&nbsp;if&nbsp;(deserialized)&nbsp;&quot;values&quot;&nbsp;else&nbsp;&quot;bytes&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Block&nbsp;%s&nbsp;stored&nbsp;as&nbsp;%s&nbsp;in&nbsp;memory&nbsp;(estimated&nbsp;size&nbsp;%s,&nbsp;free&nbsp;%s)&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId,&nbsp;valuesOrBytes,&nbsp;Utils.bytesToString(size),&nbsp;Utils.bytesToString(freeMemory))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putSuccess&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lazy&nbsp;val&nbsp;data&nbsp;=&nbsp;if&nbsp;(deserialized)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Left(value().asInstanceOf[Array[Any]]) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right(value().asInstanceOf[ByteBuffer].duplicate()) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;droppedBlockStatus&nbsp;=&nbsp;blockManager.dropFromMemory(blockId,&nbsp;()&nbsp;=&gt;&nbsp;data) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;droppedBlockStatus.foreach&nbsp;{&nbsp;status&nbsp;=&gt;&nbsp;droppedBlocks&nbsp;+=&nbsp;((blockId,&nbsp;status))&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;releasePendingUnrollMemoryForThisTask() &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;ResultWithDroppedBlocks(putSuccess,&nbsp;droppedBlocks) } Memory Store 读取 block 也很简单，只需要从 LinkedHashMap 中取出 blockId 的 Value 即可。代码如下： override&nbsp;def&nbsp;getValues(blockId:&nbsp;BlockId):&nbsp;Option[Iterator[Any]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;entry&nbsp;=&nbsp;entries.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.get(blockId) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(entry&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;None &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(entry.deserialized)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(entry.value.asInstanceOf[Array[Any]].iterator) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;buffer&nbsp;=&nbsp;entry.value.asInstanceOf[ByteBuffer].duplicate()&nbsp;//&nbsp;Doesn&#39;t&nbsp;actually&nbsp;copy&nbsp;data &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(blockManager.dataDeserialize(blockId,&nbsp;buffer)) &nbsp;&nbsp;&nbsp;&nbsp;} } 11.5 数据写入过程分析 数据写入的简要流程： 1）RDD.iterator&nbsp;是与&nbsp;storage&nbsp;子系统交互的入口。 2）CacheManager.getOrCompute&nbsp;调用&nbsp;BlockManager&nbsp;的&nbsp;put&nbsp;接口来写入数据。 3）数据优先写入到&nbsp;MemoryStore&nbsp;即内存，如果&nbsp;MemoryStore&nbsp;中的数据已满则将最近使用次数不频繁的数据写入到磁盘。 4）通知&nbsp;BlockManagerMaster&nbsp;有新的数据写入，在&nbsp;BlockManagerMaster&nbsp;中保存元数据。 5）将写入的数据与其它&nbsp;slave&nbsp;worker&nbsp;进行同步，一般来说在本机写入的数据，都会另先一台机器来进行数据的备份，即&nbsp;replicanumber=1。 其实，我们在&nbsp;put&nbsp;和&nbsp;get&nbsp;block&nbsp;的时候并没有那么复杂，前面的细节&nbsp;BlockManager&nbsp;都包装好了，我们只需要调用&nbsp;BlockManager&nbsp;中的&nbsp;put&nbsp;和&nbsp;get&nbsp;函数即可。 代码如下： def&nbsp;putBytes( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId:&nbsp;BlockId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes:&nbsp;ByteBuffer, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level:&nbsp;StorageLevel, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tellMaster:&nbsp;Boolean&nbsp;=&nbsp;true, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel:&nbsp;Option[StorageLevel]&nbsp;=&nbsp;None):&nbsp;Seq[(BlockId,&nbsp;BlockStatus)]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(bytes&nbsp;!=&nbsp;null,&nbsp;&quot;Bytes&nbsp;is&nbsp;null&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;doPut(blockId,&nbsp;ByteBufferValues(bytes),&nbsp;level,&nbsp;tellMaster,&nbsp;effectiveStorageLevel) &nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;private&nbsp;def&nbsp;doPut( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId:&nbsp;BlockId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data:&nbsp;BlockValues, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level:&nbsp;StorageLevel, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tellMaster:&nbsp;Boolean&nbsp;=&nbsp;true, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel:&nbsp;Option[StorageLevel]&nbsp;=&nbsp;None) :&nbsp;Seq[(BlockId,&nbsp;BlockStatus)]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(blockId&nbsp;!=&nbsp;null,&nbsp;&quot;BlockId&nbsp;is&nbsp;null&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(level&nbsp;!=&nbsp;null&nbsp;&amp;&amp;&nbsp;level.isValid,&nbsp;&quot;StorageLevel&nbsp;is&nbsp;null&nbsp;or&nbsp;invalid&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel.foreach&nbsp;{&nbsp;level&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(level&nbsp;!=&nbsp;null&nbsp;&amp;&amp;&nbsp;level.isValid,&nbsp;&quot;Effective&nbsp;StorageLevel&nbsp;is&nbsp;null&nbsp;or&nbsp;invalid&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;updatedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putBlockInfo&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;tinfo&nbsp;=&nbsp;new&nbsp;BlockInfo(level,&nbsp;tellMaster) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;oldBlockOpt&nbsp;=&nbsp;blockInfo.putIfAbsent(blockId,&nbsp;tinfo) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(oldBlockOpt.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(oldBlockOpt.get.waitForReady())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logWarning(s&quot;Block&nbsp;$blockId&nbsp;already&nbsp;exists&nbsp;on&nbsp;this&nbsp;machine;&nbsp;not&nbsp;re-adding&nbsp;it&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;updatedBlocks &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;oldBlockOpt.get &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tinfo &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} } &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;startTimeMs&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;valuesAfterPut:&nbsp;Iterator[Any]&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;bytesAfterPut:&nbsp;ByteBuffer&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;size&nbsp;=&nbsp;0L &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putLevel&nbsp;=&nbsp;effectiveStorageLevel.getOrElse(level) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;replicationFuture&nbsp;=&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;b:&nbsp;ByteBufferValues&nbsp;if&nbsp;putLevel.replication&nbsp;&gt;&nbsp;1&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Duplicate&nbsp;doesn&#39;t&nbsp;copy&nbsp;the&nbsp;bytes,&nbsp;but&nbsp;just&nbsp;creates&nbsp;a&nbsp;wrapper &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bufferView&nbsp;=&nbsp;b.buffer.duplicate() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Future&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replicate(blockId,&nbsp;bufferView,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}(futureExecutionContext) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logTrace(&quot;Put&nbsp;for&nbsp;block&nbsp;%s&nbsp;took&nbsp;%s&nbsp;to&nbsp;get&nbsp;into&nbsp;synchronized&nbsp;block&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;marked&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;(returnValues,&nbsp;blockStore:&nbsp;BlockStore)&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.useMemory)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(true,&nbsp;memoryStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(putLevel.useOffHeap)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(false,&nbsp;externalBlockStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(putLevel.useDisk)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1,&nbsp;diskStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(putLevel&nbsp;==&nbsp;StorageLevel.NONE) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;BlockException( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId,&nbsp;s&quot;Attempted&nbsp;to&nbsp;put&nbsp;block&nbsp;$blockId&nbsp;without&nbsp;specifying&nbsp;storage&nbsp;level!&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;result&nbsp;=&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;IteratorValues(iterator)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putIterator(blockId,&nbsp;iterator,&nbsp;putLevel,&nbsp;returnValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ArrayValues(array)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putArray(blockId,&nbsp;array,&nbsp;putLevel,&nbsp;returnValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ByteBufferValues(bytes)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes.rewind() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putBytes(blockId,&nbsp;bytes,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size&nbsp;=&nbsp;result.size &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result.data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Left&nbsp;(newIterator)&nbsp;if&nbsp;putLevel.useMemory&nbsp;=&gt;&nbsp;valuesAfterPut&nbsp;=&nbsp;newIterator &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Right&nbsp;(newBytes)&nbsp;=&gt;&nbsp;bytesAfterPut&nbsp;=&nbsp;newBytes &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.useMemory)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result.droppedBlocks.foreach&nbsp;{&nbsp;updatedBlocks&nbsp;+=&nbsp;_&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putBlockStatus&nbsp;=&nbsp;getCurrentBlockStatus(blockId,&nbsp;putBlockInfo) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putBlockStatus.storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;marked&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.markReady(size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(tellMaster)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reportBlockStatus(blockId,&nbsp;putBlockInfo,&nbsp;putBlockStatus) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updatedBlocks&nbsp;+=&nbsp;((blockId,&nbsp;putBlockStatus)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!marked)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockInfo.remove(blockId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.markFailure() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logWarning(s&quot;Putting&nbsp;block&nbsp;$blockId&nbsp;failed&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Put&nbsp;block&nbsp;%s&nbsp;locally&nbsp;took&nbsp;%s&quot;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ByteBufferValues(bytes)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(replicationFuture&nbsp;!=&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Await.ready(replicationFuture,&nbsp;Duration.Inf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;remoteStartTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(bytesAfterPut&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(valuesAfterPut&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;SparkException( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Underlying&nbsp;put&nbsp;returned&nbsp;neither&nbsp;an&nbsp;Iterator&nbsp;nor&nbsp;bytes!&nbsp;This&nbsp;shouldn&#39;t&nbsp;happen.&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytesAfterPut&nbsp;=&nbsp;dataSerialize(blockId,&nbsp;valuesAfterPut) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replicate(blockId,&nbsp;bytesAfterPut,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Put&nbsp;block&nbsp;%s&nbsp;remotely&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(remoteStartTime))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockManager.dispose(bytesAfterPut) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Putting&nbsp;block&nbsp;%s&nbsp;with&nbsp;replication&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Putting&nbsp;block&nbsp;%s&nbsp;without&nbsp;replication&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updatedBlocks &nbsp;&nbsp;&nbsp;} 对于 doPut 函数，主要做了以下几个操作：   1）创建 BlockInfo 对象存储 block 信息。   2）将 BlockInfo 加锁，然后根据 Storage Level 判断存储到 Memory 还是 Disk。同时，对于已经准备好读的 BlockInfo 要进行解锁。   3）根据 block 的副本数量决定是否向远程发送副本。 11.5.1 序列化与否 写入的具体内容可以是序列化之后的 bytes 也可以是没有序列化的 value. 此处有一个对 scala 的语法中 Either, Left, Right 关键字的理解。 11.6 数据读取过程分析 def&nbsp;get(blockId:&nbsp;BlockId):&nbsp;Option[Iterator[Any]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;local&nbsp;=&nbsp;getLocal(blockId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(local.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Found&nbsp;block&nbsp;%s&nbsp;locally&quot;.format(blockId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;local &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;remote&nbsp;=&nbsp;getRemote(blockId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(remote.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Found&nbsp;block&nbsp;%s&nbsp;remotely&quot;.format(blockId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;remote &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;None } 11.6.1 本地读取 首先在查询本机的 MemoryStore 和 DiskStore 中是否有所需要的 block 数据存在，如果没有则发起远程数据获取。 11.6.2 远程读取 远程获取调用路径， getRemote --&gt; doGetRemote, 在 doGetRemote 中最主要的就是调用 BlockManagerWorker.syncGetBlock 来从远程获得数据。 def&nbsp;syncGetBlock(msg:&nbsp;GetBlock,&nbsp;toConnManagerId:&nbsp;ConnectionManagerId):&nbsp;ByteBuffer&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockManager&nbsp;=&nbsp;blockManagerWorker.blockManager &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;connectionManager&nbsp;=&nbsp;blockManager.connectionManager &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockMessage&nbsp;=&nbsp;BlockMessage.fromGetBlock(msg) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockMessageArray&nbsp;=&nbsp;new&nbsp;BlockMessageArray(blockMessage) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;responseMessage&nbsp;=&nbsp;connectionManager.sendMessageReliablySync( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;toConnManagerId,&nbsp;blockMessageArray.toBufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;responseMessage&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(message)&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bufferMessage&nbsp;=&nbsp;message.asInstanceOf[BufferMessage] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Response&nbsp;message&nbsp;received&nbsp;&quot;&nbsp;+&nbsp;bufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockMessageArray.fromBufferMessage(bufferMessage).foreach(blockMessage&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Found&nbsp;&quot;&nbsp;+&nbsp;blockMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;blockMessage.getData &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt;&nbsp;logDebug(&quot;No&nbsp;response&nbsp;message&nbsp;received&quot;) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;null } 上述这段代码中最有意思的莫过于 sendMessageReliablySync，远程数据读取毫无疑问是一个异步 i/o 操作，这里的代码怎么写起来就像是在进行同步的操作一样呢。也就是说如何知道对方发送回来响应的呢？ 别急，继续去看看 sendMessageReliablySync 的定义： def&nbsp;sendMessageReliably(connectionManagerId:&nbsp;ConnectionManagerId,&nbsp;message:&nbsp;Message) &nbsp;&nbsp;:&nbsp;Future[Option[Message]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;promise&nbsp;=&nbsp;Promise[Option[Message]] &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;status&nbsp;=&nbsp;new&nbsp;MessageStatus( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message,&nbsp;connectionManagerId,&nbsp;s&nbsp;=&gt;&nbsp;promise.success(s.ackMessage)) &nbsp;&nbsp;&nbsp;&nbsp;messageStatuses.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses&nbsp;+=&nbsp;((message.id,&nbsp;status)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;sendMessage(connectionManagerId,&nbsp;message) &nbsp;&nbsp;&nbsp;&nbsp;promise.future } 要是我说秘密在这里，你肯定会说我在扯淡，但确实在此处。注意到关键字 Promise 和 Future 没？ 如果这个 future 执行完毕，返回 s.ackMessage。我们再看看这个 ackMessage 是在什么地方被写入的呢。看一看 ConnectionManager.handleMessage 中的代码片段： case&nbsp;bufferMessage:&nbsp;BufferMessage&nbsp;=&gt; { &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(authEnabled)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;res&nbsp;=&nbsp;handleAuthentication(connection,&nbsp;bufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(res&nbsp;==&nbsp;true)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;message&nbsp;was&nbsp;security&nbsp;negotiation&nbsp;so&nbsp;skip&nbsp;the&nbsp;rest &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;After&nbsp;handleAuth&nbsp;result&nbsp;was&nbsp;true,&nbsp;returning&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(bufferMessage.hasAckId)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sentMessageStatus&nbsp;=&nbsp;messageStatuses.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses.get(bufferMessage.ackId)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(status)&nbsp;=&gt;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses&nbsp;-=&nbsp;bufferMessage.ackId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;status &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;Exception(&quot;Could&nbsp;not&nbsp;find&nbsp;reference&nbsp;for&nbsp;received&nbsp;ack&nbsp;message&nbsp;&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message.id) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.ackMessage&nbsp;=&nbsp;Some(message) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.attempted&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.acked&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStaus.markDone() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 注意：此处的所调用的 sentMessageStatus.markDone 就会调用在 sendMessageReliablySync 中定义的 promise.Success，不妨看看 MessageStatus 的定义。 class&nbsp;MessageStatus( val&nbsp;message:&nbsp;Message, val&nbsp;connectionManagerId:&nbsp;ConnectionManagerId, completionHandler:&nbsp;MessageStatus&nbsp;=&gt;&nbsp;Unit)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;ackMessage:&nbsp;Option[Message]&nbsp;=&nbsp;None &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;attempted&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;acked&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;markDone()&nbsp;{&nbsp;completionHandler(this)&nbsp;} } 11.7 Partition 如何转化为 Block 在 storage 模块里面所有的操作都是和 block 相关的，但是在 RDD 里面所有的运算都是基于 partition 的，那么 partition 是如何与 block 对应上的呢？ RDD 计算的核心函数是 iterator() 函数： final&nbsp;def&nbsp;iterator(split:&nbsp;Partition,&nbsp;context:&nbsp;TaskContext):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparkEnv.get.cacheManager.getOrCompute(this,&nbsp;split,&nbsp;context,&nbsp;storageLevel) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;} } 如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute() 函数计算 RDD，在这个函数中 partition 和 block 发生了关系： 首先根据 RDD id 和 partition index 构造出 block id (rdd_xx_xx)，接着从 BlockManager 中取出相应的 block。   如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。   如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的 block，并将其存储到 BlockManager 中。 需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。 def&nbsp;getOrCompute[T](rdd:RDD[T],split:Partition,context:TaskContext,storageLevel:StorageLevel):Iterator[T]= { &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;key&nbsp;=&nbsp;&quot;rdd_%d_%d&quot;.format(rdd.id,&nbsp;split.index) &nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Looking&nbsp;for&nbsp;partition&nbsp;&quot;&nbsp;+&nbsp;key) &nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(values)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Partition&nbsp;is&nbsp;already&nbsp;materialized,&nbsp;so&nbsp;just&nbsp;return&nbsp;its&nbsp;values &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;values.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Mark&nbsp;the&nbsp;split&nbsp;as&nbsp;loading&nbsp;(unless&nbsp;someone&nbsp;else&nbsp;marks&nbsp;it&nbsp;first) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(loading.contains(key))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Another&nbsp;thread&nbsp;is&nbsp;loading&nbsp;%s,&nbsp;waiting&nbsp;for&nbsp;it&nbsp;to&nbsp;finish...&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(loading.contains(key))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.wait() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;catch&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Throwable&nbsp;=&gt;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Finished&nbsp;waiting&nbsp;for&nbsp;%s&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;See&nbsp;whether&nbsp;someone&nbsp;else&nbsp;has&nbsp;successfully&nbsp;loaded&nbsp;it.&nbsp;The&nbsp;main&nbsp;way&nbsp;this&nbsp;would&nbsp;fail &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;is&nbsp;for&nbsp;the&nbsp;RDD-level&nbsp;cache&nbsp;eviction&nbsp;policy&nbsp;if&nbsp;someone&nbsp;else&nbsp;has&nbsp;loaded&nbsp;the&nbsp;same&nbsp;RDD &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;partition&nbsp;but&nbsp;we&nbsp;didn&#39;t&nbsp;want&nbsp;to&nbsp;make&nbsp;space&nbsp;for&nbsp;it.&nbsp;However,&nbsp;that&nbsp;case&nbsp;is&nbsp;unlikely &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;because&nbsp;it&#39;s&nbsp;unlikely&nbsp;that&nbsp;two&nbsp;threads&nbsp;would&nbsp;work&nbsp;on&nbsp;the&nbsp;same&nbsp;RDD&nbsp;partition.&nbsp;One &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;downside&nbsp;of&nbsp;the&nbsp;current&nbsp;code&nbsp;is&nbsp;that&nbsp;threads&nbsp;wait&nbsp;serially&nbsp;if&nbsp;this&nbsp;does&nbsp;happen. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(values)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;values.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Whoever&nbsp;was&nbsp;loading&nbsp;%s&nbsp;failed;&nbsp;we&#39;ll&nbsp;try&nbsp;it&nbsp;ourselves&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.add(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.add(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;If&nbsp;we&nbsp;got&nbsp;here,&nbsp;we&nbsp;have&nbsp;to&nbsp;load&nbsp;the&nbsp;split &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Partition&nbsp;%s&nbsp;not&nbsp;found,&nbsp;computing&nbsp;it&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;computedValues&nbsp;=&nbsp;rdd.computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Persist&nbsp;the&nbsp;result,&nbsp;so&nbsp;long&nbsp;as&nbsp;the&nbsp;task&nbsp;is&nbsp;not&nbsp;running&nbsp;locally &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(context.runningLocally)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;elements&nbsp;=&nbsp;new&nbsp;ArrayBuffer[Any] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elements++&nbsp;=&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManager.put(key,&nbsp;elements,&nbsp;storageLevel,&nbsp;true) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;elements.iterator.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.remove(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.notifyAll() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 这样 RDD 的 transformation、action 就和 block 数据建立了联系，虽然抽象上我们的操作是在 partition 层面上进行的，但是 partitio n最终还是被映射成为 block，因此实际上我们的所有操作都是对 block 的处理和存取。 11.8 partition 和 block 的对应关系 在 RDD 中，核心的函数是 iterator： final&nbsp;def&nbsp;iterator(split:&nbsp;Partition,&nbsp;context:&nbsp;TaskContext):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparkEnv.get.cacheManager.getOrCompute(this,&nbsp;split,&nbsp;context,&nbsp;storageLevel) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;} } 如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute 函数计算 RDD，在这个函数中 partition 和 block 就对应起来了：   getOrCompute 函数会先构造 RDDBlockId，其中 RDDBlockId 就把 block 和 partition 联系起来了，RDDBlockId 产生的 name 就是 BlockId 的 name 属性，形式是：rdd_rdd.id_partition.index。 def&nbsp;getOrCompute[T]( rdd:&nbsp;RDD[T], partition:&nbsp;Partition, context:&nbsp;TaskContext, storageLevel:&nbsp;StorageLevel):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;key&nbsp;=&nbsp;RDDBlockId(rdd.id,&nbsp;partition.index) &nbsp;&nbsp;&nbsp;&nbsp;logDebug(s&quot;Looking&nbsp;for&nbsp;partition&nbsp;$key&quot;) &nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(blockResult)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;existingMetrics&nbsp;=&nbsp;context.taskMetrics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.getInputMetricsForReadMethod(blockResult.readMethod) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;existingMetrics.incBytesRead(blockResult.bytes) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;iter&nbsp;=&nbsp;blockResult.data.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;InterruptibleIterator[T](context,&nbsp;iter)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;next():&nbsp;T&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;existingMetrics.incRecordsRead(1) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delegate.next() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;storedValues&nbsp;=&nbsp;acquireLockForPartition[T](key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storedValues.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;new&nbsp;InterruptibleIterator[T](context,&nbsp;storedValues.get) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(s&quot;Partition&nbsp;$key&nbsp;not&nbsp;found,&nbsp;computing&nbsp;it&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;computedValues&nbsp;=&nbsp;rdd.computeOrReadCheckpoint(partition,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(context.isRunningLocally)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;updatedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;cachedValues&nbsp;=&nbsp;putInBlockManager(key,&nbsp;computedValues,&nbsp;storageLevel,&nbsp;updatedBlocks) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;metrics&nbsp;=&nbsp;context.taskMetrics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;lastUpdatedBlocks&nbsp;=&nbsp;metrics.updatedBlocks.getOrElse(Seq[(BlockId,&nbsp;BlockStatus)]()) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metrics.updatedBlocks&nbsp;=&nbsp;Some(lastUpdatedBlocks&nbsp;++&nbsp;updatedBlocks.toSeq) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;InterruptibleIterator(context,&nbsp;cachedValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.remove(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.notifyAll() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 同时 getOrCompute 函数会对 block 进行判断：   如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。   如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的block，并将其存储到 BlockManager 中。   需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。 回到顶部 第12章 Spark Shuffle 过程 12.1 MapReduce 的 Shuffle 过程介绍   Shuffle 的本义是洗牌、混洗，把一组有一定规则的数据尽量转换成一组无规则的数据，越随机越好。MapReduce 中的 Shuffle 更像是洗牌的逆过程，把一组无规则的数据尽量转换成一组具有一定规则的数据。   为什么 MapReduce 计算模型需要 Shuffle 过程？我们都知道 MapReduce 计算模型一般包括两个重要的阶段：Map 是映射，负责数据的过滤分发；Reduce 是规约，负责数据的计算归并。Reduce 的数据来源于 Map，Map 的输出即是 Reduce 的输入，Reduce 需要通过 Shuffle来 获取数据。   从 Map 输出到 Reduce 输入的整个过程可以广义地称为 Shuffle。Shuffle 横跨 Map 端和 Reduce 端，在 Map 端包括 Spill 过程，在 Reduce 端包括 copy 和 sort 过程，如图所示：    12.1.1 Spill 过程(刷写过程)   Spill 过程包括输出、排序、溢写、合并等步骤，如图所示：    Collect   每个 Map 任务不断地以&nbsp;&lt;key, value&gt;&nbsp;对的形式把数据输出到内存中构造的一个环形数据结构中。使用环形数据结构是为了更有效地使用内存空间，在内存中放置尽可能多的数据。   这个数据结构其实就是个字节数组，叫 kvbuffer，名如其义，但是这里面不光放置了&nbsp;&lt;key, value&gt;数据，还放置了一些索引数据，给放置索引数据的区域起了一个 kvmeta 的别名，在 kvbuffer 的一块区域上穿了一个 IntBuffer（字节序采用的是平台自身的字节序）的马甲。&lt;key, value&gt;&nbsp;数据区域和索引数据区域在 kvbuffer 中是相邻不重叠的两个区域，用一个分界点来划分两者，分界点不是亘古不变的，而是每次 Spill 之后都会更新一次。初始的分界点是 0，&lt;key, value&gt;&nbsp;数据的存储方向是向上增长，索引数据的存储方向是向下增长，如图所示：      kvbuffer 的存放指针 bufindex 是一直闷着头地向上增长，比如 bufindex 初始值为 0，一个 Int 型的 key 写完之后，bufindex 增长为 4，一个 Int 型的 value 写完之后，bufindex 增长为 8。   索引是对&nbsp;&lt;key, value&gt;&nbsp;在 kvbuffer 中的索引，是个四元组，包括：value 的起始位置、key 的起始位置、partition 值、value 的长度，占用四个 Int 长度，kvmeta 的存放指针 kvindex 每次都是向下跳四个“格子”，然后再向上一个格子一个格子地填充四元组的数据。比如 Kvindex 初始位置是 -4，当第一个&nbsp;&lt;key, value&gt;&nbsp;写完之后，(kvindex+0) 的位置存放 value 的起始位置、(kvindex+1) 的位置存放 key 的起始位置、(kvindex+2) 的位置存放 partition 的值、(kvindex+3) 的位置存放 value 的长度，然后 kvindex 跳到 -8 位置，等第二个&nbsp;&lt;key, value&gt;&nbsp;和索引写完之后，kvindex 跳到-32 位置。   kvbuffer 的大小虽然可以通过参数设置，但是总共就那么大，&lt;key, value&gt;&nbsp;和索引不断地增加，加着加着，kvbuffer 总有不够用的那天，那怎么办？把数据从内存刷到磁盘上再接着往内存写数据，把 kvbuffer 中的数据刷到磁盘上的过程就叫 Spill，多么明了的叫法，内存中的数据满了就自动地 spill 到具有更大空间的磁盘。   关于 Spill 触发的条件，也就是 kvbuffer 用到什么程度开始 Spill，还是要讲究一下的。如果把 kvbuffer 用得死死得，一点缝都不剩的时候再开始 Spill，那 Map 任务就需要等 Spill 完成腾出空间之后才能继续写数据；如果 kvbuffer 只是满到一定程度，比如 80% 的时候就开始 Spill，那在 Spill 的同时，Map 任务还能继续写数据，如果 Spill 够快，Map 可能都不需要为空闲空间而发愁。两利相衡取其大，一般选择后者。   Spill 这个重要的过程是由 Spill 线程承担，Spill 线程从 Map 任务接到“命令”之后就开始正式干活，干的活叫 SortAndSpill，原来不仅仅是 Spill，在 Spill 之前还有个颇具争议性的 Sort。 Sort   先把 kvbuffer 中的数据按照 partition 值和 key 两个关键字升序排序，移动的只是索引数据，排序结果是 kvmeta 中数据按照 partition 为单位聚集在一起，同一 partition 内的按照 key 有序。 Spill   Spill 线程为这次 Spill 过程创建一个磁盘文件：从所有的本地目录中轮询查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out” 的文件。Spill 线程根据排过序的 kvmeta 挨个 partition 的把&nbsp;&lt;key, value&gt;&nbsp;数据吐到这个文件中，一个 partition 对应的数据吐完之后顺序地吐下个 partition，直到把所有的 partition 遍历完。一个 partition 在文件中对应的数据也叫段 (segment)。   所有的 partition 对应的数据都放在这个文件里，虽然是顺序存放的，但是怎么直接知道某个 partition 在这个文件中存放的起始位置呢？强大的索引又出场了。有一个三元组记录某个 partition 对应的数据在这个文件中的索引：起始位置、原始数据长度、压缩之后的数据长度，一个 partition 对应一个三元组。然后把这些索引信息存放在内存中，如果内存中放不下了，后续的索引信息就需要写到磁盘文件中了：从所有的本地目录中轮训查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out.index” 的文件，文件中不光存储了索引数据，还存储了 crc32 的校验数据。(spill12.out.index 不一定在磁盘上创建，如果内存（默认 1M 空间）中能放得下就放在内存中，即使在磁盘上创建了，和 spill12.out 文件也不一定在同一个目录下。)   每一次 Spill 过程就会最少生成一个 out 文件，有时还会生成 index 文件，Spill 的次数也烙印在文件名中。索引文件和数据文件的对应关系如下图所示：      在 Spill 线程如火如荼的进行 SortAndSpill 工作的同时，Map 任务不会因此而停歇，而是一无既往地进行着数据输出。Map 还是把数据写到 kvbuffer 中，那问题就来了：&lt;key, value&gt;&nbsp;只顾着闷头按照 bufindex 指针向上增长，kvmeta 只顾着按照 kvindex 向下增长，是保持指针起始位置不变继续跑呢，还是另谋它路？如果保持指针起始位置不变，很快 bufindex 和 kvindex 就碰头了，碰头之后再重新开始或者移动内存都比较麻烦，不可取。Map 取 kvbuffer 中剩余空间的中间位置，用这个位置设置为新的分界点，bufindex 指针移动到这个分界点，kvindex 移动到这个分界点的 -16 位置，然后两者就可以和谐地按照自己既定的轨迹放置数据了，当 Spill 完成，空间腾出之后，不需要做任何改动继续前进。分界点的转换如下图所示：      Map 任务总要把输出的数据写到磁盘上，即使输出数据量很小在内存中全部能装得下，在最后也会把数据刷到磁盘上。 &nbsp; 12.1.2 Merge      Map 任务如果输出数据量很大，可能会进行好几次 Spill，out 文件和 Index 文件会产生很多，分布在不同的磁盘上。最后把这些文件进行合并的 merge 过程闪亮登场。   Merge 过程怎么知道产生的 Spill 文件都在哪了呢？从所有的本地目录上扫描得到产生的 Spill 文件，然后把路径存储在一个数组里。Merge 过程又怎么知道 Spill 的索引信息呢？没错，也是从所有的本地目录上扫描得到 Index 文件，然后把索引信息存储在一个列表里。到这里，又遇到了一个值得纳闷的地方。在之前 Spill 过程中的时候为什么不直接把这些信息存储在内存中呢，何必又多了这步扫描的操作？特别是 Spill 的索引数据，之前当内存超限之后就把数据写到磁盘，现在又要从磁盘把这些数据读出来，还是需要装到更多的内存中。之所以多此一举，是因为这时 kvbuffer 这个内存大户已经不再使用可以回收，有内存空间来装这些数据了。（对于内存空间较大的土豪来说，用内存来省却这两个 io 步骤还是值得考虑的。） &nbsp;   然后为 merge 过程创建一个叫 file.out 的文件和一个叫 file.out.Index 的文件用来存储最终的输出和索引。   一个 partition 一个 partition 的进行合并输出。对于某个 partition 来说，从索引列表中查询这个 partition 对应的所有索引信息，每个对应一个段插入到段列表中。也就是这个 partition 对应一个段列表，记录所有的 Spill 文件中对应的这个 partition 那段数据的文件名、起始位置、长度等等。   然后对这个 partition 对应的所有的 segment 进行合并，目标是合并成一个 segment。当这个 partition 对应很多个 segment 时，会分批地进行合并：先从 segment 列表中把第一批取出来，以 key 为关键字放置成最小堆，然后从最小堆中每次取出最小的&nbsp;&lt;key, value&gt;&nbsp;输出到一个临时文件中，这样就把这一批段合并成一个临时的段，把它加回到 segment 列表中；再从 segment 列表中把第二批取出来合并输出到一个临时 segment，把其加入到列表中；这样往复执行，直到剩下的段是一批，输出到最终的文件中。   最终的索引数据仍然输出到 Index 文件中。   Map 端的 Shuffle 过程到此结束。 12.1.3 Copy   Reduce 任务通过 HTTP 向各个 Map 任务拖取它所需要的数据。每个节点都会启动一个常驻的 HTTP server，其中一项服务就是响应 Reduce 拖取 Map 数据。当有 MapOutput 的 HTTP 请求过来的时候，HTTP server 就读取相应的 Map 输出文件中对应这个 Reduce 部分的数据通过网络流输出给 Reduce。   Reduce 任务拖取某个 Map 对应的数据，如果在内存中能放得下这次数据的话就直接把数据写到内存中。Reduce 要向每个 Map 去拖取数据，在内存中每个 Map 对应一块数据，当内存中存储的 Map 数据占用空间达到一定程度的时候，开始启动内存中 merge，把内存中的数据 merge 输出到磁盘上一个文件中。   如果在内存中不能放得下这个 Map 的数据的话，直接把 Map 数据写到磁盘上，在本地目录创建一个文件，从 HTTP 流中读取数据然后写到磁盘，使用的缓存区大小是 64K。拖一个 Map 数据过来就会创建一个文件，当文件数量达到一定阈值时，开始启动磁盘文件 merge，把这些文件合并输出到一个文件。   有些 Map 的数据较小是可以放在内存中的，有些 Map 的数据较大需要放在磁盘上，这样最后 Reduce 任务拖过来的数据有些放在内存中了有些放在磁盘上，最后会对这些来一个全局合并。 12.1.4 Merge Sort   这里使用的 Merge 和 Map 端使用的 Merge 过程一样。Map 的输出数据已经是有序的，Merge 进行一次合并排序，所谓 Reduce 端的 sort 过程就是这个合并的过程。一般 Reduce 是一边 copy 一边 sort，即 copy 和 sort 两个阶段是重叠而不是完全分开的。   Reduce 端的 Shuffle 过程至此结束。 12.2 HashShuffle 过程介绍   Spark 丰富了任务类型，有些任务之间数据流转不需要通过 Shuffle，但是有些任务之间还是需要通过 Shuffle 来传递数据，比如 wide dependency 的 group by key。   Spark 中需要 Shuffle 输出的 Map 任务会为每个 Reduce 创建对应的 bucket，Map 产生的结果会根据设置的 partitioner 得到对应的 bucketId，然后填充到相应的 bucket 中去。每个 Map 的输出结果可能包含所有的 Reduce 所需要的数据，所以每个 Map 会创建 R 个 bucket（R 是 reduce 的个数），M 个 Map 总共会创建 M*R 个 bucket。   Map 创建的 bucket 其实对应磁盘上的一个文件，Map 的结果写到每个 bucket 中其实就是写到那个磁盘文件中，这个文件也被称为 blockFile，是 Disk Block Manager 管理器通过文件名的 Hash 值对应到本地目录的子目录中创建的。每个 Map 要在节点上创建 R 个磁盘文件用于结果输出，Map 的结果是直接输出到磁盘文件上的，100KB 的内存缓冲是用来创建 Fast Buffered OutputStream 输出流。这种方式一个问题就是 Shuffle 文件过多。      1）每一个 Mapper 创建出和 Reducer 数目相同的 bucket，bucket 实际上是一个 buffer，其大小为 spark.shuffle.file.buffer.kb（默认 32KB）。   2）Mapper 产生的结果会根据设置的 partition 算法填充到每个 bucket 中去，然后再写入到磁盘文件。   3）Reducer 从远端或是本地的 block manager 中找到相应的文件读取数据。 &nbsp;   针对上述 Shuffle 过程产生的文件过多问题，Spark 有另外一种改进的 Shuffle 过程：consolidation Shuffle，以期显著减少 Shuffle 文件的数量。在 consolidation Shuffle 中每个 bucket 并非对应一个文件，而是对应文件中的一个 segment 部分。Job 的 map 在某个节点上第一次执行，为每个 reduce 创建 bucke 对应的输出文件，把这些文件组织成&nbsp;ShuffleFileGroup，当这次 map 执行完之后，这个 ShuffleFileGroup 可以释放为下次循环利用；当又有 map 在这个节点上执行时，不需要创建新的 bucket 文件，而是在上次的 ShuffleFileGroup 中取得已经创建的文件继续追加写一个 segment；当前次 map 还没执行完，ShuffleFileGroup 还没有释放，这时如果有新的 map 在这个节点上执行，无法循环利用这个 ShuffleFileGroup，而是只能创建新的 bucket 文件组成新的 ShuffleFileGroup 来写输出。      比如一个 Job 有 3 个 Map 和 2 个 reduce：   (1) 如果此时集群有 3 个节点有空槽，每个节点空闲了一个 core，则 3 个 Map 会调度到这 3 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，总共创建 6 个 Shuffle 文件；   (2) 如果此时集群有 2 个节点有空槽，每个节点空闲了一个 core，则 2 个 Map 先调度到这 2 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，然后其中一个节点执行完 Map 之后又调度执行另一个 Map，则这个 Map 不会创建新的 Shuffle 文件，而是把结果输出追加到之前 Map 创建的 Shuffle 文件中；总共创建 4 个 Shuffle 文件；   (3) 如果此时集群有 2 个节点有空槽，一个节点有 2 个空 core 一个节点有 1 个空 core，则一个节点调度 2 个 Map 一个节点调度 1 个 Map，调度 2 个 Map 的节点上，一个 Map 创建了 Shuffle 文件，后面的 Map 还是会创建新的 Shuffle 文件，因为上一个 Map 还正在写，它创建的 ShuffleFileGroup 还没有释放；总共创建 6 个 Shuffle 文件。优点：   1）快-不需要排序，也不需要维持 hash 表   2）不需要额外空间用作排序   3）不需要额外IO-数据写入磁盘只需一次，读取也只需一次缺点：   1）当 partitions 大时，输出大量的文件（cores * R），性能开始降低   2）大量的文件写入，使文件系统开始变为随机写，性能比顺序写要降低 100 倍   3）缓存空间占用比较大   Reduce 去拖 Map 的输出数据，Spark 提供了两套不同的拉取数据框架：通过 socket 连接去取数据；使用n etty 框架去取数据。   每个节点的 Executor 会创建一个 BlockManager，其中会创建一个 BlockManagerWorker 用于响应请求。当 Reduce 的 GET_BLOCK 的请求过来时，读取本地文件将这个 blockId 的数据返回给 Reduce。如果使用的是 Netty 框架，BlockManager 会创建 ShuffleSender 用于发送 Shuffle 数据。   并不是所有的数据都是通过网络读取，对于在本节点的 Map 数据，Reduce 直接去磁盘上读取而不再通过网络框架。   Reduce 拖过来数据之后以什么方式存储呢？Spark Map 输出的数据没有经过排序，Spark Shuffle 过来的数据也不会进行排序，Spark 认为 Shuffle 过程中的排序不是必须的，并不是所有类型的 Reduce 需要的数据都需要排序，强制地进行排序只会增加 Shuffle 的负担。Reduce 拖过来的数据会放在一个 HashMap 中，HashMap 中存储的也是&nbsp;&lt;key, value&gt;&nbsp;对，key 是 Map 输出的 key，Map 输出对应这个 key 的所有 value 组成 HashMap 的 value。Spark 将 Shuffle 取过来的每一个&nbsp;&lt;key, value&gt;对插入或者更新到 HashMap 中，来一个处理一个。HashMap 全部放在内存中。   Shuffle 取过来的数据全部存放在内存中，对于数据量比较小或者已经在 Map 端做过合并处理的 Shuffle 数据，占用内存空间不会太大，但是对于比如 group by key 这样的操作，Reduce 需要得到 key 对应的所有 value，并将这些 value 组一个数组放在内存中，这样当数据量较大时，就需要较多内存。   当内存不够时，要不就失败，要不就用老办法把内存中的数据移到磁盘上放着。Spark 意识到在处理数据规模远远大于内存空间时所带来的不足，引入了一个具有外部排序的方案。Shuffle 过来的数据先放在内存中，当内存中存储的&nbsp;&lt;key, value&gt;&nbsp;对超过 1000 并且内存使用超过 70% 时，判断节点上可用内存如果还足够，则把内存缓冲区大小翻倍，如果可用内存不再够了，则把内存中的&nbsp;&lt;key, value&gt;&nbsp;对排序然后写到磁盘文件中。最后把内存缓冲区中的数据排序之后和那些磁盘文件组成一个最小堆，每次从最小堆中读取最小的数据，这个和 MapReduce 中的 merge 过程类似。 12.3 SortShuffle 过程介绍   从 1.2.0 开始默认为 sort shuffle(spark.shuffle.manager = sort)，实现逻辑类似于 Hadoop MapReduce，Hash Shuffle 每一个 reducers 产生一个文件，但是 Sort Shuffle 只是产生一个按照 reducer id 排序可索引的文件，这样，只需获取有关文件中的相关数据块的位置信息，并 fseek 就可以读取指定 reducer 的数据。但对于 rueducer 数比较少的情况，Hash Shuffle 明显要比 Sort Shuffle 快，因此 Sort Shuffle 有个 “fallback” 计划，对于 reducers 数少于 “spark.shuffle.sort.bypassMergeThreshold” (200 by default)，我们使用 fallback 计划，hashing 相关数据到分开的文件，然后合并这些文件为一个，具体实现为 BypassMergeSortShuffleWriter。      在 map 进行排序，在 reduce 端应用 Timsort[1] 进行合并。map 端是否容许 spill，通过 spark.shuffle.spill 来设置，默认是 true。设置为 false，如果没有足够的内存来存储 map 的输出，那么就会导致 OOM 错误，因此要慎用。   用于存储 map 输出的内存为：“JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction，默认为： “JVM Heap Size” * 0.2 * 0.8 = “JVM Heap Size” * 0.16。如果你在同一个执行程序中运行多个线程（设定 spark.executor.cores/ spark.task.cpus 超过 1），每个 map 任务存储的空间为 “JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction / spark.executor.cores * spark.task.cpus，默认 2 个 cores，那么为 0.08 * “JVM Heap Size”。      spark 使用 AppendOnlyMap 存储 map 输出的数据，利用开源 hash 函数 MurmurHash3 和平方探测法把 key 和 value 保存在相同的 array 中。这种保存方法可以是 spark 进行 combine。如果 spill 为 true，会在 spill 前 sort。   与 hash shuffle 相比，sort shuffle 中每个 Mapper 只产生一个数据文件和一个索引文件，数据文件中的数据按照 Reducer 排序，但属于同一个 Reducer 的数据不排序。Mapper 产生的数据先放到 AppendOnlyMap 这个数据结构中，如果内存不够，数据则会 spill 到磁盘，最后合并成一个文件。   与 Hash shuffle 相比，shuffle 文件数量减少，内存使用更加可控。但排序会影响速度。优点：   1）map 创建文件量较少。   2）少量的 IO 随机操作，大部分是顺序读写。缺点：   1）要比 Hash Shuffle 要慢，需要自己通过 spark.shuffle.sort.bypassMergeThreshold 来设置合适的值。   2）如果使用 SSD 盘存储 shuffle 数据，那么 Hash Shuffle 可能更合适。 12.4 TungstenShuffle 过程介绍   Tungsten-sort 算不得一个全新的 shuffle 方案，它在特定场景下基于类似现有的 Sort Based Shuffle 处理流程，对内存 /CPU/Cache 使用做了非常大的优化。带来高效的同时，也就限定了自己的使用场景。如果 Tungsten-sort 发现自己无法处理，则会自动使用 Sort Based Shuffle 进行处理。Tungsten 中文是钨丝的意思。 Tungsten Project 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，该计划初期似乎对 Spark SQL 优化的最多。不过部分 RDD API 还有 Shuffle 也因此受益。Tungsten-sort 优化点主要在三个方面:   1）直接在 serialized binary data 上 sort 而不是 java objects，减少了 memory 的开销和 GC 的 overhead。   2）提供 cache-efficient sorter，使用一个 8bytes 的指针，把排序转化成了一个指针数组的排序。   3）spill 的 merge 过程也无需反序列化即可完成。   这些优化的实现导致引入了一个新的内存管理模型，类似 OS 的 Page，对应的实际数据结构为 MemoryBlock，支持 off-heap 以及 in-heap 两种模式。为了能够对 Record 在这些 MemoryBlock 进行定位，引入了 Pointer（指针）的概念。 如果你还记得 Sort Based Shuffle 里存储数据的对象 PartitionedAppendOnlyMap，这是一个放在 JVM heap 里普通对象，在 Tungsten-sort 中，他被替换成了类似操作系统内存页的对象。如果你无法申请到新的 Page，这个时候就要执行 spill 操作，也就是写入到磁盘的操作。具体触发条件，和 Sort Based Shuffle 也是类似的。   Spark 默认开启的是 Sort Based Shuffle，想要打开 Tungsten-sort，请设置   spark.shuffle.manager=tungsten-sort   对应的实现类是：org.apache.spark.shuffle.unsafe.UnsafeShuffleManager   名字的来源是因为使用了大量 JDK Sun Unsafe API。 当且仅当下面条件都满足时，才会使用新的 Shuffle 方式：   1）Shuffle dependency 不能带有 aggregation 或者输出需要排序   2）Shuffle 的序列化器需要是 KryoSerializer 或者 Spark SQL&#39;s 自定义的一些序列化方式.   3）Shuffle 文件的数量不能大于 16777216。   4）序列化时，单条记录不能大于 128 MB。 可以看到，能使用的条件还是挺苛刻的。 这些限制来源于哪里 参看如下代码，page 的大小：   this.pageSizeBytes = (int) Math.min(PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES,shuffleMemoryManager.pageSizeBytes()); 这就保证了页大小不超过 PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES 的值，该值就被定义成了 128M。 而产生这个限制的具体设计原因，我们还要仔细分析下 Tungsten 的内存模型，如下图所示：    这张图其实画的是 on-heap 的内存逻辑图，其中 #Page 部分为 13bit，Offset 为 51bit，你会发现 2^51 &gt;&gt; 128M 的。但是在 Shuffle 的过程中，对 51bit 做了压缩，使用了 27bit，具体如下：   [24 bit partition number][13 bit memory page number][27 bit offset in page] 这里预留出的 24bi t给了 partition number，为了后面的排序用。上面的好几个限制其实都是因为这个指针引起的：   第一个是 partition 的限制，前面的数字 16777216 就是来源于 partition number 使用 24bit 表示的。   第二个是 page number。   第三个是偏移量，最大能表示到 2^27=128M。那一个 Task 能管理到的内存是受限于这个指针的，最多是 2^13 * 128M 也就是 1TB 左右。 有了这个指针，我们就可以定位和管理到 off-heap 或者 on-heap 里的内存了。这个模型还是很漂亮的，内存管理也非常高效，记得之前的预估 PartitionedAppendOnlyMap 的内存是非常困难的，但是通过现在的内存管理机制，是非常快速并且精确的。 对于第一个限制，那是因为后续 Shuffle Write 的 sort 部分，只对前面 24bit 的 partiton number 进行排序，key 的值没有被编码到这个指针，所以没办法进行 ordering。 同时，因为整个过程是追求不反序列化的，所以不能做 aggregation。 Shuffle Write 核心类：&nbsp;   org.apache.spark.shuffle.unsafe.UnsafeShuffleWriter 数据会通过 UnsafeShuffleExternalSorter.insertRecordIntoSorter 一条一条写入到 serOutputStream 序列化输出流。 这里消耗内存的地方是   serBuffer = new MyByteArrayOutputStream(1024 * 1024) 默认是 1M，类似于 Sort Based Shuffle 中的 ExternalSorter，在 Tungsten Sort 对应的为 UnsafeShuffleExternalSorter，记录序列化后就通过 sorter.insertRecord 方法放到 sorter 里去了。 这里 sorter 负责申请 Page，释放 Page，判断是否要进行 spill 都这个类里完成。代码的架子其实和 Sort Based 是一样的。    (另外，值得注意的是，这张图里进行 spill 操作的同时检查内存可用而导致的 Exeception 的 bug 已经在 1.5.1 版本被修复了，忽略那条路径) 内存是否充足的条件依然 shuffleMemoryManager 来决定，也就是所有 Task Shuffle 申请的 Page 内存总和不能大于下面的值：   ExecutorHeapMemeory * 0.2 * 0.8 上面的数字可通过下面两个配置来更改：   spark.shuffle.memoryFraction=0.2   spark.shuffle.safetyFraction=0.8 UnsafeShuffleExternalSorter 负责申请内存，并且会生成该条记录最后的逻辑地址，也就前面提到的 Pointer。 接着 Record 会继续流转到 UnsafeShuffleInMemorySorter 中，这个对象维护了一个指针数组：   private long[] pointerArray; 数组的初始大小为 4096，后续如果不够了，则按每次两倍大小进行扩充。 假设 100 万条记录，那么该数组大约是 8M 左右，所以其实还是很小的。一旦 spill 后该 UnsafeShuffleInMemorySorter 就会被赋为 null，被回收掉。 我们回过头来看 spill，其实逻辑上也异常简单了，UnsafeShuffleInMemorySorter 会返回一个迭代器，该迭代器粒度每个元素就是一个指针，然后到根据该指针可以拿到真实的 record，然后写入到磁盘，因为这些 record 在一开始进入 UnsafeShuffleExternalSorter 就已经被序列化了，所以在这里就纯粹变成写字节数组了。形成的结构依然和 Sort Based Shuffle 一致，一个文件里不同的 partiton 的数据用 fileSegment 来表示，对应的信息存在一个 index 文件里。 另外写文件的时候也需要一个 buffer：   spark.shuffle.file.buffer=32k 另外从内存里拿到数据放到 DiskWriter，这中间还要有个中转，是通过：   final byte[] writeBuffer = new byte[DISK_WRITE_BUFFER_SIZE=1024 * 1024]; 来完成的，都是内存，所以很快。 Task 结束前，我们要做一次 mergeSpills 操作，然后形成一个 shuffle 文件。这里面其实也挺复杂的， 如果开启了   spark.shuffle.unsafe.fastMergeEnabled=true 并且没有开启&nbsp;   spark.shuffle.compress=true 或者压缩方式为：   LZFCompressionCodec 则可以非常高效的进行合并，叫做 transferTo。不过无论是什么合并，都不需要进行反序列化。 Shuffle Read Shuffle Read 完全复用 HashShuffleReader，具体参看 Sort-Based Shuffle。 12.5 MapReduce 与 Spark 过程对比 MapReduce 和 Spark 的 Shuffle 过程对比如下： 回到顶部 第13章 Spark 内存管理   Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文中阐述的原理基于 Spark 2.1 版本。&nbsp;   在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业（Job），并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。 13.1 堆内和堆外内存规划   作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。堆内和堆外内存示意图如下： 13.1.1 堆内内存   堆内内存的大小，由 Spark 应用程序启动时的&nbsp;-executor-memory&nbsp;或&nbsp;spark.executor.memory参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同（下面第 2 小节会进行介绍）。   Spark 对堆内内存的管理是一种逻辑上的规划式的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存，我们来看其具体流程：申请内存：   1）Spark 在代码中 new 一个对象实例   2）JVM 从堆内内存分配空间，创建对象并返回对象引用   3）Spark 保存该对象的引用，记录该对象占用的内存释放内存：   1）Spark 记录该对象释放的内存，删除该对象的引用   2）等待 JVM 的垃圾回收机制释放该对象占用的堆内内存   我们知道，JVM 的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转化为连续空间或块存储，在访问时则需要进行序列化的逆过程--反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。   对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。   虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。 13.1.2 堆外内存   为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。   在默认情况下堆外内存并不启用，可通过配置&nbsp;spark.memory.offHeap.enabled&nbsp;参数启用，并由&nbsp;spark.memory.offHeap.size&nbsp;参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。 13.1.3 内存管理接口   Spark 为存储内存和执行内存的管理提供了统一的接口--MemoryManager，同一个 Executor 内的任务都调用这个接口的方法来申请或释放内存: 内存管理接口的主要方法： //&nbsp;申请存储内存 def&nbsp;acquireStorageMemory(blockId:&nbsp;BlockId,&nbsp;numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Boolean //&nbsp;申请展开内存 def&nbsp;acquireUnrollMemory(blockId:&nbsp;BlockId,&nbsp;numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Boolean //&nbsp;申请执行内存 def&nbsp;acquireExecutionMemory(numBytes:&nbsp;Long,&nbsp;taskAttemptId:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Long //&nbsp;释放存储内存 def&nbsp;releaseStorageMemory(numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit //&nbsp;释放执行内存 def&nbsp;releaseExecutionMemory(numBytes:&nbsp;Long,&nbsp;taskAttemptId:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit //&nbsp;释放展开内存 def&nbsp;releaseUnrollMemory(numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit Spark的内存管理 – 内存管理接口   我们看到，在调用这些方法时都需要指定其内存模式（MemoryMode），这个参数决定了是在堆内还是堆外完成这次操作。MemoryManager 的具体实现上，Spark 1.6 之后默认为统一管理（Unified Memory Manager）方式，1.6 之前采用的静态管理（Static Memory Manager）方式仍被保留，可通过配置&nbsp;spark.memory.useLegacyMode&nbsp;参数启用。两种方式的区别在于对空间分配的方式，下面的第 2 小节会分别对这两种方式进行介绍。 13.2 内存空间分配 13.2.1 静态内存管理   在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。 静态内存管理图示--堆内 可以看到，可用的堆内内存的大小需要按照下面的方式计算： 可用堆内内存空间： 可用的存储内存&nbsp;=&nbsp;systemMaxMemory&nbsp;*&nbsp;spark.storage.memoryFraction&nbsp;*&nbsp;spark.storage.safetyFraction 可用的执行内存&nbsp;=&nbsp;systemMaxMemory&nbsp;*&nbsp;spark.shuffle.memoryFraction&nbsp;*&nbsp;spark.shuffle.safetyFraction   其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和 “其它内存” 一样交给了 JVM 去管理。   堆外的空间分配较为简单，只有存储内存和执行内存，如下图所示。可用的执行内存和存储内存占用的空间大小直接由参数&nbsp;spark.memory.storageFraction&nbsp;决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。 静态内存管理图示--堆外   静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成 “一半海水，一半火焰” 的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。 13.2.2 统一内存管理   Spark 1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域。 统一内存管理图示--堆内 统一内存管理图示--堆外 其中最重要的优化在于动态占用机制，其规则如下：   1）设定基本的存储内存和执行内存区域（spark.storage.storageFraction&nbsp;参数），该设定确定了双方各自拥有的空间的范围。   2）双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block）。   3）执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后 “归还” 借用的空间。   4）存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。 动态占用机制图示   凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护 Spark 内存的难度，但并不意味着开发者可以高枕无忧。譬如，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的 RDD 数据通常都是长期驻留内存的。所以要想充分发挥 Spark 的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。 13.3 存储内存管理 13.3.1 RDD 的持久化机制   弹性分布式数据集（RDD）作为 Spark 最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换（Transformation）操作产生一个新的 RDD。转换后的 RDD 与原始的 RDD 之间产生的依赖关系，构成了血统（Lineage）。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。但 RDD 的所有转换都是惰性的，即只有当一个返回结果给 Driver 的行动（Action）发生时，Spark 才会创建任务读取 RDD，然后真正触发转换的执行。   Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 上要执行多次行动，可以在第一次行动中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。事实上，cache 方法是使用默认的 MEMORY_ONLY 的存储级别将 RDD 持久化到内存，故缓存是一种特殊的持久化。堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理（存储内存的其他应用场景，如缓存 broadcast 数据，暂时不在本文的讨论范围之内）。   RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来。在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD。 Storage 模块示意图 在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY、MEMORY_AND_DISK 等 7 种不同的 存储级别，而存储级别是以下 5 个变量的组合： 存储级别 class&nbsp;StorageLevel&nbsp;private( &nbsp;&nbsp;private&nbsp;var&nbsp;_useDisk:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;磁盘 &nbsp;&nbsp;private&nbsp;var&nbsp;_useMemory:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;这里其实是指堆内内存 &nbsp;&nbsp;private&nbsp;var&nbsp;_useOffHeap:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;堆外内存 &nbsp;&nbsp;private&nbsp;var&nbsp;_deserialized:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;//&nbsp;是否为非序列化 &nbsp;&nbsp;private&nbsp;var&nbsp;_replication:&nbsp;Int&nbsp;=&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;副本个数 ) 通过对数据结构的分析，可以看出存储级别从三个维度定义了 RDD 的 Partition（同时也就是 Block）的存储方式： &nbsp;&nbsp;&nbsp;&nbsp;1）存储位置：磁盘／堆内内存／堆外内存。如&nbsp;MEMORY_AND_DISK&nbsp;是同时在磁盘和堆内内存上存储，实现了冗余备份。OFF_HEAP&nbsp;则是只在堆外内存存储，目前选择堆外内存时不能同时存储到其他位置。 &nbsp;&nbsp;&nbsp;&nbsp;2）存储形式：Block&nbsp;缓存到存储内存后，是否为非序列化的形式。如&nbsp;MEMORY_ONLY&nbsp;是非序列化方式存储，OFF_HEAP&nbsp;是序列化方式存储。 &nbsp;&nbsp;&nbsp;&nbsp;3）副本数量：大于&nbsp;1&nbsp;时需要远程冗余备份到其他节点。如&nbsp;DISK_ONLY_2&nbsp;需要远程备份&nbsp;1&nbsp;个副本。 13.3.2 RDD 缓存的过程   RDD 在缓存到存储内存之前，Partition 中的数据一般以迭代器（Iterator）的数据结构来访问，这是 Scala 语言中一种遍历数据集合的方法。通过 Iterator 可以获取分区中每一条序列化或者非序列化的数据项 (Record)，这些 Record 的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同 Record 的空间并不连续。   RDD 在缓存到存储内存之后，Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为 “展开”（Unroll）。Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 以一种 DeserializedMemoryEntry 的数据结构定义，用一个数组存储所有的对象实例，序列化的 Block 则以 SerializedMemoryEntry 的数据结构定义，用字节缓冲区（ByteBuffer）来存储二进制数据。每个 Executor 的 Storage 模块用一个链式 Map 结构（LinkedHashMap）来管理堆内和堆外存储内存中所有的 Block 对象的实例，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。   因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。而非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。如果最终 Unroll 成功，当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间，如下图所示。 Spark Unroll 示意图   在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，当存储空间不足时会根据动态占用机制进行处理。 13.3.3 淘汰和落盘   由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中的旧 Block 进行淘汰（Eviction），而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘（Drop），否则直接删除该 Block。   存储内存的淘汰规则为：   1）被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存。   2）新旧 Block 不能属于同一个 RDD，避免循环淘汰。   3）旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题。   4）遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性。   落盘的流程则比较简单，如果其存储级别符合_useDisk 为 true&nbsp;的条件，再根据其&nbsp;_deserialized&nbsp;判断是否是非序列化的形式，若是则对其进行序列化，最后将数据存储到磁盘，在 Storage 模块中更新其信息。 13.4 执行内存管理 13.4.1 多任务间内存分配   Executor 内运行的任务同样共享执行内存，Spark 用一个 HashMap 结构保存了任务到内存耗费的映射。每个任务可占用的执行内存大小的范围为 1/2N ~ 1/N，其中 N 为当前 Executor 内正在运行的任务的个数。每个任务在启动之时，要向 MemoryManager 请求申请最少为 1/2N 的执行内存，如果不能被满足要求则该任务被阻塞，直到有其他任务释放了足够的执行内存，该任务才可以被唤醒。 13.4.2 Shuffle 的内存占用   执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程，我们来看 Shuffle 的 Write 和 Read 两阶段对执行内存的使用：Shuffle Write   1）若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。   2）若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够。Shuffle Read   1）在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间。   2）如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter 处理，占用堆内执行空间。   在 ExternalSorter 和 Aggregator 中，Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据，但在 Shuffle 过程中所有数据并不能都保存到该哈希表中，当这个哈希表占用的内存会进行周期性地采样估算，当其大到一定程度，无法再从 MemoryManager 申请到新的执行内存时，Spark 就会将其全部内容存储到磁盘文件中，这个过程被称为溢存(Spill)，溢存到磁盘的文件最后会被归并(Merge)。   Shuffle Write 阶段中用到的 Tungsten 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，解决了一些 JVM 在性能上的限制和弊端。Spark 会根据 Shuffle 的情况来自动选择是否采用 Tungsten 排序。Tungsten 采用的页式内存管理机制建立在 MemoryManager 之上，即 Tungsten 对执行内存的使用进行了一步的抽象，这样在 Shuffle 过程中无需关心数据具体存储在堆内还是堆外。每个内存页用一个 MemoryBlock 来定义，并用 Object obj 和 long offset 这两个变量统一标识一个内存页在系统内存中的地址。堆内的 MemoryBlock 是以 long 型数组的形式分配的内存，其 obj 的值为是这个数组的对象引用，offset 是 long 型数组的在 JVM 中的初始偏移地址，两者配合使用可以定位这个数组在堆内的绝对地址；堆外的 MemoryBlock 是直接申请到的内存块，其 obj 为 null，offset 是这个内存块在系统内存中的 64 位绝对地址。Spark 用 MemoryBlock 巧妙地将堆内和堆外内存页统一抽象封装，并用页表(pageTable)管理每个 Task 申请到的内存页。   Tungsten 页式管理下的所有内存用 64 位的逻辑地址表示，由页号和页内偏移量组成：   页号：占 13 位，唯一标识一个内存页，Spark 在申请内存页之前要先申请空闲页号。   页内偏移量：占 51 位，是在使用内存页存储数据时，数据在页内的偏移地址。   有了统一的寻址方式，Spark 可以用 64 位逻辑地址的指针定位到堆内或堆外的内存，整个 Shuffle Write 排序的过程只需要对指针进行排序，并且无需反序列化，整个过程非常高效，对于内存访问效率和 CPU 使用效率带来了明显的提升。   Spark 的存储内存和执行内存有着截然不同的管理方式：对于存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；而对于执行内存，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。 回到顶部 第14章 部署模式解析 14.1 部署模式概述   Spark 支持的主要的三种分布式部署方式分别是 standalone、spark on mesos 和 spark on YARN。standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。它是 Spark 实现的资源调度框架，其主要的节点有 Client 节点、Master 节点和 Worker 节点。而 yarn 是统一的资源管理机制，在上面可以运行多套计算框架，如 map reduce、storm 等根据 driver 在集群中的位置不同，分为 yarn client 和 yarn cluster。而 mesos 是一个更强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括 yarn。基本上，Spark 的运行模式取决于传递给 SparkContext 的 MASTER 环境变量的值，个别模式还需要辅助的程序接口来配合使用，目前支持的 Master 字符串及 URL 包括：      用户在提交任务给 Spark 处理时，以下两个参数共同决定了 Spark 的运行方式：   • --master MASTER_URL ：决定了 Spark 任务提交给哪种集群处理。   • --deploy-mode DEPLOY_MODE ：决定了 Driver 的运行方式，可选值为 Client 或者 Cluster。 &nbsp; 14.2 standalone 框架   standalone 集群由三个不同级别的节点组成，分别是：   1）Master 主控节点，可以类比为董事长或总舵主，在整个集群之中，最多只有一个 Master 处在 Active 状态。   2）Worker 工作节点，这个是 manager，是分舵主， 在整个集群中，可以有多个 Worker，如果 Worker 为零，什么事也做不了。   3）Executor 干苦力活的，直接受 Worker 掌控，一个 Worker 可以启动多个 executor，启动的个数受限于机器中的 cpu 核数。   这三种不同类型的节点各自运行于自己的JVM进程之中。   Standalone 模式下，集群启动时包括 Master 与 Worker，其中 Master 负责接收客户端提交的作业，管理 Worker。根据作业提交的方式不同，分为 driver on client 和 drvier on worker。如下图所示，上图为 driver on client 模式，下图为 driver on work 模式。两种模式的主要不同点在于 driver 所在的位置。   在 standalone 部署模式下又分为 client 模式和 cluster 模式。   在client 模式下，driver 和 client 运行于同一 JVM 中，不由 worker 启动，该 JVM 进程直到 spark application 计算完成返回结果后才退出。如下图所示：      而在 cluster 模式下，driver 由 worker 启动，client 在确认 spark application 成功提交给 cluster 后直接退出，并不等待 spark application 运行结果返回。如下图所示：    从部署图来进行分析，每个 JVM 进程在启动时的文件依赖如何得到满足。   1）Master 进程最为简单，除了 spark jar 包之外，不存在第三方库依赖。   2）Driver 和 Executor 在运行的时候都有可能存在第三方包依赖，分开来讲。   3）Driver 比较简单，spark-submit 在提交的时候会指定所要依赖的 jar 文件从哪里读取。   4）Executor 由 Worker 来启动，Worker 需要下载 Executor 启动时所需要的 jar 文件，那么从哪里下载呢？   Spark Standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖其他资源管理系统。在该模式下，用户可以通过手动启动 Master 和 Worker 来启动一个独立的集群。其中，Master 充当了资源管理的角色，Workder 充当了计算节点的角色。在该模式下，Spark Driver 程序在客户端(Client)运行，而 Executor 则在 Worker 节点上运行。以下是一个运行在 Standalone 模式下，包含一个 Master 节点，两个 Worker 节点的 Spark 任务调度交互部署架构图。 从上面的 Spark 任务调度过程可以看到：   1）整个集群分为 Master 节点和 Worker 节点，其 Driver 程序运行在客户端。Master 节点负责为任务分配 Worker 节点上的计算资源，两者会通过相互通信来同步资源状态，见途中红色双向箭头。   2）客户端启动任务后会运行 Driver 程序，Driver 程序中会完成 SparkContext 对象的初始化，并向 Master 进行注册。   3）每个 Workder 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟客户端节点上的 Driver 程序进行通信，上报任务状态。 &nbsp; 14.2.1 Standalone 模式下任务运行过程   上面的过程反映了 Spark 在 standalone 模式下，整体上客户端、Master 和 Workder 节点之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。1）&nbsp;用户通过 bin/spark-submit 部署工具或者 bin/spark-class 启动应用程序的 Driver 进程，Driver 进程会初始化 SparkContext 对象，并向 Master 节点进行注册。   • 1、Master 节点接受 Driver 程序的注册，检查它所管理的 Worker 节点，为该 Driver 程序分配需要的计算资源 Executor。Worker 节点完成 Executor 的分配后，向 Master 报告 Executor 的状态。   • 2、Worker 节点上的 ExecutorBackend 进程启动后，向 Driver 进程注册。2）&nbsp;Driver 进程内部通过 DAG Schaduler、Stage Schaduler、Task Schaduler 等过程完成任务的划分后，向 Worker 节点上的 ExecutorBackend 分配 TASK。   • 1、ExecutorBackend 进行 TASK 计算，并向 Driver 报告 TASK 状态，直至结束。   • 2、Driver 进程在所有 TASK 都处理完成后，向 Master 注销。 14.2.2 总结   Spark 能够以 standalone 模式运行，这是 Spark 自身提供的运行模式，用户可以通过手动启动 master 和 worker 进程来启动一个独立的集群，也可以在一台机器上运行这些守护进程进行测试。standalone 模式可以用在生产环境，它有效的降低了用户学习、测试 Spark 框架的成本。   standalone 模式目前只支持跨应用程序的简单 FIFO 调度。然而，为了允许多个并发用户，你可以控制每个应用使用的资源的最大数。默认情况下，它会请求使用集群的全部 CUP 内核。   缺省情况下，standalone 任务调度允许 worker 的失败（在这种情况下它可以将失败的任务转移给其他的 worker）。但是，调度器使用 master 来做调度，这会产生一个单点问题：如果 master 崩溃，新的应用不会被创建。为了解决这个问题，可以通过 zookeeper 的选举机制在集群中启动多个 master，也可以使用本地文件实现单节点恢复。 14.3 yarn 集群模式   Apache yarn 是 apache Hadoop 开源项目的一部分。设计之初是为了解决 mapreduce 计算框架资源管理的问题。到 haodoop 2.0 使用 yarn 将 mapreduce 的分布式计算和资源管理区分开来。它的引入使得 Hadoop 分布式计算系统进入了平台化时代，即各种计算框架可以运行在一个集群中，由资源管理系统 YRAN 进行统一的管理和调度，从而共享整个集群资源、提高资源利用率。   YARN 总体上也 Master/Slave 架构--ResourceManager/NodeManager。前者(RM)负责对各个 NodeManager(NM) 上的资源进行统一管理和调度。而 Container 是资源分配和调度的基本单位，其中封装了机器资源，如内存、CPU、磁盘和网络等，每个任务会被分配一个 Container，该任务只能在该 Container 中执行，并使用该 Container 封装的资源。NodeManager 的作用则是负责接收并启动应用的 Container、而向 RM 回报本节点上的应用 Container 运行状态和资源使用情况。ApplicationMaster 与具体的 Application 相关，主要负责同 ResourceManager 协商以获取合适的 Container，并跟踪这些 Container 的状态和监控其进度。如下图所示为 yarn 集群的一般模型。 简单架构图如下：    详细架构图如下：      Spark 在 yarn 集群上的部署方式分为两种，yarn cluster（driver 运行在 master 上）和 yarn client（driver 运行在 client 上）。   driver on master&nbsp;如下图所示：      • (1) Spark Yarn Client 向 YARN 中提交应用程序，包括 Application Master 程序、启动 Application Master 的命令、需要在 Executor 中运行的程序等。   • (2) Resource manager 收到请求后，在其中一个 Node Manager 中为应用程序分配一个 Container，要求它在 Container 中启动应用程序的 Application Master，Application Master 初始化 sparkContext 以及创建 DAG Scheduler 和 Task Scheduler。   • (3) Application Master 根据 SparkContext 中的配置，向 Resource Manager 申请 Container，同时，Application Master 向 Resource Manager 注册，这样用户可通过 Resource Manager 查看应用程序的运行状态。   • (4) Resource Manager 在集群中寻找符合条件的 Node Manager，在 Node Manager 启动 Container，要求 Container 启动 Executor。   • (5) Executor 启动后向 Application Master 注册，并接收 Application Master 分配的 Task。   • (6) 应用程序运行完成后，Application Master 向 Resource Manager 申请注销并关闭自己。   driver on client&nbsp;如下图所示：      • (1) Spark Yarn Client 向 YARN 的 Resource Manager 申请启动 Application Master。同时在 SparkContent 初始化中将创建 DAG Scheduler 和 Task Scheduler 等。   • (2) ResourceManager 收到请求后，在集群中选择一个 NodeManager，为该应用程序分配第一个 Container，要求它在这个 Container 中启动应用程序的 ApplicationMaster，与 YARN-Cluster 区别的是在该 ApplicationMaster 不运行 SparkContext，只与 SparkContext 进行联系进行资源的分派。   • (3) Client 中的 SparkContext 初始化完毕后，与 Application Master 建立通讯，向 Resource Manager 注册，根据任务信息向 Resource Manager 申请资源 (Container)。   • (4) 当 Application Master 申请到资源后，便与 Node Manager 通信，要求它启动 Container。   • (5) Container 启动后向 Driver 中的 SparkContext 注册，并申请 Task。   • (6) 应用程序运行完成后，Client 的 SparkContext 向 ResourceManage r申请注销并关闭自己。 &nbsp;   Yarn-client 和Yarn cluster 模式对比可以看出，在 Yarn-client（Driver on client）中，Application Master 仅仅从 Yarn 中申请资源给 Executor，之后 client 会跟 container 通信进行作业的调度。如果 client 离集群距离较远，建议不要采用此方式，不过此方式有利于交互式的作业。　　      Spark 能够以集群的形式运行，可用的集群管理系统有 Yarn、Mesos 等。集群管理器的核心功能是资源管理和任务调度。以 Yarn 为例，Yarn 以 Master/Slave 模式工作，在 Master 节点运行的是 Resource Manager(RM)，负责管理整个集群的资源和资源分配。在 Slave 节点运行的 Node Manager(NM)，是集群中实际拥有资源的工作节点。我们提交 Job 以后，会将组成 Job 的多个 Task 调度到对应的 Node Manager 上进行执行。另外，在 Node Manager 上将资源以 Container 的形式进行抽象，Container 包括两种资源 内存 和 CPU。   以下是一个运行在 Yarn 集群上，包含一个 Resource Manager 节点，三个 Node Manager 节点(其中，两个是 Worker 节点，一个 Master 节点)的 Spark 任务调度交换部署架构图。　 从上面的Spark任务调度过程图可以看到:   1）整个集群分为 Master 节点和 Worker 节点，它们都存在于 Node Manager 节点上，在客户端提交任务时由 Resource Manager 统一分配，运行 Driver 程序的节点被称为 Master 节点，执行具体任务的节点被称为 Worder 节点。Node Manager 节点上资源的变化都需要及时更新给 Resource Manager，见图中红色双向箭头。   2）Master 节点上常驻 Master 守护进程 -- Driver 程序，Driver 程序中会创建 SparkContext对 象，并负责跟各个 Worker 节点上的 ExecutorBackend 进程进行通信，管理 Worker 节点上的任务，同步任务进度。实际上，在 Yarn 中 Node Manager 之间的关系是平等的，因此 Driver 程序会被调度到任何一个 Node Manager 节点。   3）每个 Worker 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟 Master 节点上的 Driver 程序进行通信，上报任务状态。　　 &nbsp; 集群下任务运行过程   上面的过程反映出了 Spark 在集群模式下，整体上 Resource Manager 和 Node Manager 节点间的交互，Master 和 Worker 之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。   • 1) 用户通过 bin/spark-submit 部署工具或者 bin/spark-class 向 Yarn 集群提交应用程序。   • 2) Yarn 集群的 Resource Manager 为提交的应用程序选择一个 Node Manager 节点并分配第一个 Container，并在该节点的 Container 上启动 SparkContext 对象。   • 3) SparkContext 对象向 Yarn 集群的 Resource Manager 申请资源以运行 Executor。   • 4) Yarn 集群的 Resource Manager 分配 Container 给 SparkContext 对象，SparkContext 和相关的 Node Manager 通讯，在获得的 Container 上启动 ExecutorBackend 守护进程，ExecutorBackend 启动后开始向 SparkContext 注册并申请 Task。   • 5) SparkContext 分配 Task 给 ExecutorBackend 执行。   • 6) ExecutorBackend 开始执行 Task，并及时向 SparkContext 汇报运行状况。Task 运行完毕，SparkContext 归还资源给 Node Manager，并注销退。 14.4 mesos 集群模式   Mesos 是 apache 下的开源分布式资源管理框架。起源于加州大学伯克利分校，后被 Twitter 推广使用。Mesos 上可以部署多种分布式框架，Mesos 的架构图如下图所示，其中 Framework 是指外部的计算框架，如 Hadoop、Mesos 等，这些计算框架可通过注册的方式接入 Mesos，以便 Mesos 进行统一管理和资源分配。      在 Mesos 上运行的 Framework 由两部分组成：一个是 scheduler ，通过注册到 Master 来获取集群资源。另一个是在 Slave 节点上运行的 executor 进程，它可以执行 Framework 的 task 。 Master 决定为每个 Framework 提供多少资源，Framework 的 scheduler 来选择其中提供的资源。当 Framework 同意了提供的资源，它通过 Master 将 task 发送到提供资源的 Slaves 上运行。Mesos c的资源分配图如下图所示：      (1) Slave1 向 Master 报告，有 4 个 CPU 和 4 GB 内存可用。   (2) Master 发送一个 Resource Offer 给 Framework1 来描述 Slave1 有多少可用资源。   (3) FrameWork1 中的 FW Scheduler 会答复 Master，我有两个 Task 需要运行在 Slave1，一个 Task 需要&nbsp;&lt;2个CPU，1 GB内存=&quot;&quot;&gt;，另外一个 Task 需要&nbsp;&lt;1个CPU，2 GB内存=&quot;&quot;&gt;。   (4) 最后，Master 发送这些 Tasks 给 Slave1。然后，Slave1 还有 1 个 CPU 和 1GB 内存没有使用，所以分配模块可以把这些资源提供给 Framework2。 &nbsp;   Spark 可作为其中一个分布式框架部署在 mesos 上，部署图与 mesos 的一般框架部署图类似，如下图所示，这里不再重述。 14.5 spark 三种部署模式的区别   在这三种部署模式中，standalone 作为 spark 自带的分布式部署模式，是最简单也是最基本的 spark 应用程序部署模式，这里就不再赘述。这里就讲一下 yarn 和 mesos 的区别：   (1) 就两种框架本身而言，mesos上可部署 yarn 框架。而 yarn 是更通用的一种部署框架，而且技术较成熟。   (2) mesos 双层调度机制，能支持多种调度模式，而 yarn 通过 Resource　Mananger 管理集群资源，只能使用一种调度模式。Mesos 的双层调度机制为：mesos 可接入如 yarn 一般的分布式部署框架，但 Mesos 要求可接入的框架必须有一个调度器模块，该调度器负责框架内部的任务调度。当一个 Framework 想要接入 mesos 时，需要修改自己的调度器，以便向 mesos 注册，并获取 mesos 分配给自己的资源，这样再由自己的调度器将这些资源分配给框架中的任务，也就是说，整个 mesos 系统采用了双层调度框架：第一层，由 mesos 将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。   (3) mesos 可实现粗、细粒度资源调度，可动态分配资源，而 yarn 只能实现静态资源分配。其中粗粒度和细粒度调度定义如下：   粗粒度模式（Coarse-grained Mode）：程序运行之前就要把所需要的各种资源（每个 executor 占用多少资源，内部可运行多少个 executor）申请好，运行过程中不能改变。   细粒度模式（Fine-grained Mode）：为了防止资源浪费，对资源进行按需分配。与粗粒度模式一样，应用程序启动时，先会启动 executor，但每个 executor 占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos 会为每个 executor 动态分配资源，每分配一些，便可以运行一个新任务，单个 Task 运行完之后可以马上释放对应的资源。每个 Task 会汇报状态给 Mesos Slave 和 Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于 MapReduce 调度模式，每个 Task 完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。   从 yarn 和 mesos 的区别可看出，它们各自有优缺点。因此实际使用中，选择哪种框架，要根据本公司的实际需要而定，可考虑现有的大数据生态环境。如我司采用 yarn 部署 spark，原因是，我司早已有较成熟的 hadoop 的框架，考虑到使用的方便性，采用了 yarn 模式的部署。 14.6 异常场景分析 上面说明的是正常情况下，各节点的消息分发细节。那么如果在运行中，集群中的某些节点出现了问题，整个集群是否还能够正常处理 Application 中的任务呢？ 14.6.1 异常分析1：Worker 异常退出 在 Spark 运行过程中，经常碰到的问题就是 Worker 异常退出，当 Worker 退出时，整个集群会有哪些故事发生呢？请看下面的具体描述：   1）Worker 异常退出，比如说有意识的通过 kill 指令将 Worker 杀死。   2）Worker 在退出之前，会将自己所管控的所有小弟 Executor 全干掉。   3）Worker 需要定期向 Master 改善心跳消息的，现在 Worker 进程都已经玩完了，哪有心跳消息，所以 Master 会在超时处理中意识到有一个 “分舵” 离开了。   4）Master 非常伤心，伤心的 Master 将情况汇报给了相应的 Driver。 Driver 通过两方面确认分配给自己的 Executor 不幸离开了，一是 Master 发送过来的通知，二是 Driver 没有在规定时间内收到 Executor 的 StatusUpdate，于是 Driver 会将注册的 Executor 移除。 后果分析 Worker 异常退出会带来哪些影响：   1）Executor 退出导致提交的 Task 无法正常结束，会被再一次提交运行。   2）如果所有的 Worker 都异常退出，则整个集群不可用。   3）需要有相应的程序来重启 Worker 进程，比如使用 supervisord 或 runit。 测试步骤   1）启动 Master。   2）启动 Worker。   3）启动 spark-shell。   4）手工 kill 掉 Worker 进程。   5）用 jps 或 ps -ef | grep -i java 来查看启动着的 java 进程。 异常退出的代码处理 定义 ExecutorRunner.scala 的 start 函数 def&nbsp;start()&nbsp;{ &nbsp;&nbsp;workerThread&nbsp;=&nbsp;new&nbsp;Thread(&quot;ExecutorRunner&nbsp;for&nbsp;&quot;&nbsp;+&nbsp;fullId)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;run()&nbsp;{&nbsp;fetchAndRunExecutor()&nbsp;} &nbsp;&nbsp;} &nbsp;&nbsp;workerThread.start() &nbsp;&nbsp;//&nbsp;Shutdown&nbsp;hook&nbsp;that&nbsp;kills&nbsp;actors&nbsp;on&nbsp;shutdown. &nbsp;&nbsp;shutdownHook&nbsp;=&nbsp;new&nbsp;Thread()&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;run()&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(Some(&quot;Worker&nbsp;shutting&nbsp;down&quot;)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;} &nbsp;&nbsp;Runtime.getRuntime.addShutdownHook(shutdownHook) } killProcess 的过程就是停止相应 CoarseGrainedExecutorBackend 的过程。 Worker 停止的时候，一定要先将自己启动的 Executor 停止掉。这是不是很像水浒中宋江的手段，李逵就是这样不明不白的把命给丢了。 小结   需要特别指出的是，当 Worker 在启动 Executor 的时候，是通过 ExecutorRunner 来完成的，ExecutorRunner 是一个独立的线程，和 Executor 是一对一的关系，这很重要。Executor 作为一个独立的进程在运行，但会受到 ExecutorRunner 的严密监控。 14.6.2 异常分析2：Executor 异常退出 后果分析 Executor 作为 Standalone 集群部署方式下的最底层员工，一旦异常退出，其后果会是什么呢？   1）Executor 异常退出，ExecutorRunner 注意到异常，将情况通过 ExecutorStateChanged 汇报给 Master。   2）Master 收到通知之后，非常不高兴，尽然有小弟要跑路，那还了得，要求 Executor 所属的 Worker 再次启动。   3）Worker 收到 LaunchExecutor 指令，再次启动 Executor。 测试步骤   1）启动 Master   2）启动 Worker   3）启动 spark-shell   4）手工 kill 掉 CoarseGrainedExecutorBackend fetchAndRunExecutor fetchAndRunExecutor 负责启动具体的 Executor，并监控其运行状态，具体代码逻辑如下所示 def&nbsp;fetchAndRunExecutor()&nbsp;{ &nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;the&nbsp;executor&#39;s&nbsp;working&nbsp;directory &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;executorDir&nbsp;=&nbsp;new&nbsp;File(workDir,&nbsp;appId&nbsp;+&nbsp;&quot;/&quot;&nbsp;+&nbsp;execId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!executorDir.mkdirs())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Failed&nbsp;to&nbsp;create&nbsp;directory&nbsp;&quot;&nbsp;+&nbsp;executorDir) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Launch&nbsp;the&nbsp;process &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;command&nbsp;=&nbsp;getCommandSeq &nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Launch&nbsp;command:&nbsp;&quot;&nbsp;+&nbsp;command.mkString(&quot;\&quot;&quot;,&nbsp;&quot;\&quot;&nbsp;\&quot;&quot;,&nbsp;&quot;\&quot;&quot;)) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;builder&nbsp;=&nbsp;new&nbsp;ProcessBuilder(command:&nbsp;_*).directory(executorDir) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;env&nbsp;=&nbsp;builder.environment() &nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;((key,&nbsp;value)&nbsp;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Runner&nbsp;thread&nbsp;for&nbsp;executor&nbsp;&quot;&nbsp;+&nbsp;fullId&nbsp;+&nbsp;&quot;&nbsp;interrupted&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state&nbsp;=&nbsp;ExecutorState.KILLED &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(None) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;e:&nbsp;Exception&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logError(&quot;Error&nbsp;running&nbsp;executor&quot;,&nbsp;e) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state&nbsp;=&nbsp;ExecutorState.FAILED &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(Some(e.toString)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;} } 14.6.3 异常分析3：Master 异常退出 Worker 和 Executor 异常退出的场景都讲到了，我们剩下最后一种情况了，Master 挂掉了怎么办？ 后果分析 带头大哥如果不在了，会是什么后果呢？   1）Worker 没有汇报的对象了，也就是如果 Executor 再次跑飞，Worker 是不会将 Executor 启动起来的，大哥没给指令。   2）无法向集群提交新的任务。   3）老的任务即便结束了，占用的资源也无法清除，因为资源清除的指令是 Master 发出的。 回到顶部 第15章 wordcount 程序运行原理窥探 15.1 spark 之 scala 实现 wordcount 在 spark 中使用 scala 来实现 wordcount（统计单词出现次数模型）更加简单，相对 java 代码上更加简洁，其函数式编程的思维逻辑也更加直观。 package&nbsp;com.spark.firstApp import&nbsp;org.apache.spark.{SparkContext,&nbsp;SparkConf} /** &nbsp;&nbsp;*&nbsp;scala&nbsp;实现&nbsp;wordcount &nbsp;&nbsp;*/ object&nbsp;WordCount1&nbsp;{ &nbsp;&nbsp;def&nbsp;main(args:&nbsp;Array[String])&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(args.length&nbsp;==&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;System.err.println(&quot;Usage:&nbsp;WordCount1&nbsp;&lt;file1&gt;&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;System.exit(1) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;/** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;1、实例化&nbsp;SparkConf &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;2、构建&nbsp;SparkContext，SparkContext&nbsp;是&nbsp;spark&nbsp;应用程序的唯一入口 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;3.&nbsp;通过&nbsp;SparkContext&nbsp;的&nbsp;textFile&nbsp;方法读取文本文件 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;conf&nbsp;=&nbsp;new&nbsp;SparkConf().setAppName(&quot;WordCount1&quot;).setMaster(&quot;local&quot;) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sc&nbsp;=&nbsp;new&nbsp;SparkContext(conf) &nbsp;&nbsp;&nbsp;&nbsp;/** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;4、通过&nbsp;flatMap&nbsp;对文本中每一行的单词进行拆分（分割符号为空格），并利用&nbsp;map&nbsp;进行函数转换形成&nbsp;(K,V)&nbsp;对形式，再进行&nbsp;reduceByKey，打印输出&nbsp;10&nbsp;个结果 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;&nbsp;&nbsp;&nbsp;函数式编程更加直观的反映思维逻辑 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/ &nbsp;&nbsp;&nbsp;&nbsp;sc.textFile(args(0)).flatMap(_.split(&quot;&nbsp;&quot;)).map(x&nbsp;=&gt;&nbsp;(x,&nbsp;1)).reduceByKey(_&nbsp;+&nbsp;_).take(10).foreach(println) &nbsp;&nbsp;&nbsp;&nbsp;sc.stop() &nbsp;&nbsp;} } 15.2 原理窥探 在 spark 集群中运行 wordcount 程序其主要业务逻辑比较简单，涵盖一下 3 个过程：   1）读取存储介质上的文本文件（一般存储在 hdfs 上）；   2）对文本文件内容进行解析，按照单词进行分组统计汇总；   3）将过程 2 的分组结果保存到存储介质上。（一般存储在 hdfs 或者 RMDB 上） 虽然 wordcount 的业务逻辑非常简单，但其应用程序在 spark 中的运行过程却巧妙得体现了 spark 的核心精髓--分布式弹性数据集、内存迭代以及函数式编程等特点。下图对 spark 集群中 wordcount 的运行过程进行剖析，加深对 spark 技术原理窥探。   该图横向分割下面给出了 wordcount 的 scala 核心程序实现，该程序在 spark 集群的运行过程涉及几个核心的 RDD，主要有 textFileRDD、flatMapRDD、mapToPairRDD、shuffleRDD（reduceByKey）等。   应用程序通过 textFile 方法读取 hdfs 上的文本文件，数据分片的形式以 RDD 为统一模式将数据加载到不同的物理节点上，如上图所示的节点 1、节点 2 到节点 n；并通过一系列的数据转换，如利用 flatMap 将文本文件中对应每行数据进行拆分（文本文件中单词以空格为分割符号），形成一个以每个单词为核心新的数据集合 RDD；之后通过 MapRDD 继续转换形成形成 (K,V) 对 数据形式，以便进一步使用 reduceByKey 方法，该方法会触发 shuffle 行为，促使不同的单词到对应的节点上进行汇聚统计（实际上在夸节点进行数据 shuffle 之前会在本地先对相同单词进行合并累加），形成 wordcount 的统计结果；最终通过 saveAsTextFile 方法将数据保存到 hdfs 上。具体的运行逻辑原理以及过程上图给出了详细的示意说明。 我的GitHub地址：https://github.com/heizemingjun 我的博客园地址：https://www.cnblogs.com/chenmingjun 我的CSDN地址：https://blog.csdn.net/u012990179&nbsp; 我的蚂蚁笔记博客地址：https://blog.leanote.com/chenmingjun Copyright ©2018-2019 黑泽明军【转载文章务必保留出处和署名，谢谢！】" />
<link rel="canonical" href="https://mlh.app/2019/05/04/729870.html" />
<meta property="og:url" content="https://mlh.app/2019/05/04/729870.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-04T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"https://www.cnblogs.com/chenmingjun/p/10803261.html 文章目录 第1章 Spark 整体概述 1.1 整体概念 1.2 RDD 抽象 1.3 计算抽象 1.4 集群模式 1.5 RPC 网络通信抽象 1.6 启动 Standalone 集群 1.7 核心组件 1.8 核心组件交互流程 1.9 Block 管理 1.10整体应用 第2章 Spark 通信架构 2.1 通信组件概览 2.2 Endpoint 启动过程 2.3 Endpoint Send&amp;Ask 流程 2.4 Endpoint Receive 流程 2.5 Endpoint Inbox 处理流程 2.6 Endpoint 画像 第3章 脚本解析 3.1 start-daemon.sh 3.2 spark-class 3.3 start-master.sh 3.4 start-slaves.sh 3.5 start-all.sh 3.6 spark-submit 第4章 Master 节点启动 4.1 脚本概览 4.2 启动流程 4.3 OnStart 监听事件 4.4 RpcMessage 处理 (receiveAndReply) 4.5 OneWayMessage 处理 (receive) 4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑 第5章 Worker 节点启动 5.1 脚本概览 5.2 启动流程 5.3 OnStart 监听事件 5.4 RpcMessage 处理 (receiveAndReply) 5.5 OneWayMessage 处理 (receive) 第6章 Client 启动流程 6.1 脚本概览 6.2 SparkSubmit 启动流程 6.3 Client 启动流程 6.4 Client 的 OnStart 监听事件 6.5 RpcMessage 处理 (receiveAndReply) 6.6 OneWayMessage 处理(receive) 第7章 Driver 和 DriverRunner 7.1 Master 对 Driver 资源分配 7.2 Worker 运行 DriverRunner 7.3 DriverRunner 创建并运行 DriverWrapper 第8章 SparkContext 解析 8.1 SparkContext 解析 8.2 SparkContext 创建过程 8.3 SparkContext 简易结构与交互关系 8.4 Master 对 Application 资源分配 8.5 Worker 创建 Executor 第9章 Job 提交和 Task 的拆分 9.1 整体预览 9.2 Code 转化为初始 RDDs 9.3 RDD 分解为待执行任务集合（TaskSet） 9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver 9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor 第10章 Task 执行和回馈 10.1 Task 的执行流程 10.2 Task 的回馈流程 10.3 Task 的迭代流程 10.4 精彩图解 第11章 Spark 的数据存储 11.1 存储子系统概览 11.2 启动过程分析 11.3 通信层 11.4 存储层 11.5 数据写入过程分析 11.6 数据读取过程分析 11.7 Partition 如何转化为 Block 11.8 partition 和 block 的对应关系 第12章 Spark Shuffle 过程 12.1 MapReduce 的 Shuffle 过程介绍 12.2 HashShuffle 过程介绍 12.3 SortShuffle 过程介绍 12.4 TungstenShuffle 过程介绍 12.5 MapReduce 与 Spark 过程对比 第13章 Spark 内存管理 13.1 堆内和堆外内存规划 13.2 内存空间分配 13.3 存储内存管理 13.4 执行内存管理 第14章 部署模式解析 14.1 部署模式概述 14.2 standalone 框架 14.3 yarn 集群模式 14.4 mesos 集群模式 14.5 spark 三种部署模式的区别 14.6 异常场景分析 第15章 wordcount 程序运行原理窥探 15.1 spark 之 scala 实现 wordcount 15.2 原理窥探 &nbsp; 第1章 Spark 整体概述1.1 整体概念1.2 RDD 抽象1.3 计算抽象1.4 集群模式1.5 RPC 网络通信抽象1.6 启动 Standalone 集群1.7 核心组件1.8 核心组件交互流程1.9 Block 管理1.10整体应用第2章 Spark 通信架构2.1 通信组件概览2.2 Endpoint 启动过程2.3 Endpoint Send&amp;Ask 流程2.4 Endpoint Receive 流程2.5 Endpoint Inbox 处理流程2.6 Endpoint 画像第3章 脚本解析3.1 start-daemon.sh3.2 spark-class3.3 start-master.sh3.4 start-slaves.sh3.5 start-all.sh3.6 spark-submit第4章 Master 节点启动4.1 脚本概览4.2 启动流程4.3 OnStart 监听事件4.4 RpcMessage 处理 (receiveAndReply)4.5 OneWayMessage 处理 (receive)4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑第5章 Worker 节点启动5.1 脚本概览5.2 启动流程5.3 OnStart 监听事件5.4 RpcMessage 处理 (receiveAndReply)5.5 OneWayMessage 处理 (receive)第6章 Client 启动流程6.1 脚本概览6.2 SparkSubmit 启动流程6.3 Client 启动流程6.4 Client 的 OnStart 监听事件6.5 RpcMessage 处理 (receiveAndReply)6.6 OneWayMessage 处理(receive)第7章 Driver 和 DriverRunner7.1 Master 对 Driver 资源分配7.2 Worker 运行 DriverRunner7.3 DriverRunner 创建并运行 DriverWrapper第8章 SparkContext 解析8.1 SparkContext 解析8.2 SparkContext 创建过程8.3 SparkContext 简易结构与交互关系8.4 Master 对 Application 资源分配8.5 Worker 创建 Executor第9章 Job 提交和 Task 的拆分9.1 整体预览9.2 Code 转化为初始 RDDs9.3 RDD 分解为待执行任务集合（TaskSet）9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor第10章 Task 执行和回馈10.1 Task 的执行流程10.2 Task 的回馈流程10.3 Task 的迭代流程10.4 精彩图解第11章 Spark 的数据存储11.1 存储子系统概览11.2 启动过程分析11.3 通信层11.4 存储层11.4.1 Disk Store11.4.2 Memory Store11.5 数据写入过程分析11.5.1 序列化与否11.6 数据读取过程分析11.6.1 本地读取11.6.2 远程读取11.7 Partition 如何转化为 Block11.8 partition 和 block 的对应关系第12章 Spark Shuffle 过程12.1 MapReduce 的 Shuffle 过程介绍12.1.1 Spill 过程(刷写过程)12.1.2 Merge12.1.3 Copy12.1.4 Merge Sort12.2 HashShuffle 过程介绍12.3 SortShuffle 过程介绍12.4 TungstenShuffle 过程介绍12.5 MapReduce 与 Spark 过程对比第13章 Spark 内存管理13.1 堆内和堆外内存规划13.1.1 堆内内存13.1.2 堆外内存13.1.3 内存管理接口13.2 内存空间分配13.2.1 静态内存管理13.2.2 统一内存管理13.3 存储内存管理13.3.1 RDD 的持久化机制13.3.2 RDD 缓存的过程13.3.3 淘汰和落盘13.4 执行内存管理13.4.1 多任务间内存分配13.4.2 Shuffle 的内存占用第14章 部署模式解析14.1 部署模式概述14.2 standalone 框架14.2.1 Standalone 模式下任务运行过程14.2.2 总结14.3 yarn 集群模式14.4 mesos 集群模式14.5 spark 三种部署模式的区别14.6 异常场景分析14.6.1 异常分析1：Worker 异常退出14.6.2 异常分析2：Executor 异常退出14.6.3 异常分析3：Master 异常退出第15章 wordcount 程序运行原理窥探15.1 spark 之 scala 实现 wordcount15.2 原理窥探 回到顶部 第1章 Spark 整体概述 1.1 整体概念   Apache Spark 是一个开源的通用集群计算系统，它提供了 High-level 编程 API，支持 Scala、Java 和 Python 三种编程语言。Spark 内核使用 Scala 语言编写，通过基于 Scala 的函数式编程特性，在不同的计算层面进行抽象，代码设计非常优秀。 1.2 RDD 抽象   RDD（Resilient Distributed Datasets），弹性分布式数据集，它是对分布式数据集的一种内存抽象，通过受限的共享内存方式来提供容错性，同时这种内存模型使得计算比传统的数据流模型要高效。RDD 具有 5 个重要的特性，如下图所示： 上图展示了 2 个 RDD 进行 JOIN 操作，体现了 RDD 所具备的 5 个主要特性，如下所示：   • 1）一组分区   • 2）计算每一个数据分片的函数   • 3）RDD 上的一组依赖   • 4）可选，对于键值对 RDD，有一个 Partitioner（通常是 HashPartitioner）   • 5）可选，一组 Preferred location 信息（例如，HDFS 文件的 Block 所在 location 信息） 有了上述特性，能够非常好地通过 RDD 来表达分布式数据集，并作为构建 DAG 图的基础：首先抽象一个分布式计算任务的逻辑表示，最终将任务在实际的物理计算环境中进行处理执行。 &nbsp; 1.3 计算抽象 在描述 Spark 中的计算抽象，我们首先需要了解如下几个概念： 1）Application   • 用户编写的 Spark 程序，完成一个计算任务的处理。它是由一个 Driver 程序和一组运行于 Spark 集群上的 Executor 组成。 2）Job   • 用户程序中，每次调用 Action 时，逻辑上会生成一个 Job，一个 Job 包含了多个 Stage 。 3）Stage   • Stage 包括两类：ShuffleMapStage 和 ResultStage，如果用户程序中调用了需要进行 Shuffle 计算的 Operator，如 groupByKey 等，就会以 Shuffle 为边界分成 ShuffleMapStage 和 ResultStage。 4）TaskSet   • 基于 Stage 可以直接映射为 TaskSet，一个 TaskSet 封装了一次需要运算的、具有相同处理逻辑的 Task，这些 Task 可以并行计算，粗粒度的调度是以 TaskSet 为单位的。 5）Task   • Task 是在物理节点上运行的基本单位，Task 包含两类：ShuffleMapTask 和 ResultTask，分别对应于 Stage 中 ShuffleMapStage 和 ResultStage 中的一个执行基本单元。 下面，我们看一下，上面这些基本概念之间的关系，如下图所示：   上图，为了简单，每个 Job 假设都很简单，并且只需要进行一次 Shuffle 处理，所以都对应 2 个 Stage。实际应用中，一个 Job 可能包含若干个 Stage，或者是一个相对复杂的 Stage DAG。 在 Standalone 模式下，默认使用的是 FIFO 这种简单的调度策略，在进行调度的过程中，大概流程如下图所示：   从用户提交 Spark 程序，最终生成 TaskSet，而在调度时，通过 TaskSetManager 来管理一个 TaskSet（包含一组可在物理节点上执行的 Task），这里面 TaskSet 必须要按照顺序执行才能保证计算结果的正确性，因为 TaskSet 之间是有序依赖的（上溯到 ShuffleMapStage 和 ResultStage），只有一个 TaskSet 中的所有 Task 都运行完成后，才能调度下一个 TaskSet 中的 Task 去执行。 &nbsp; 1.4 集群模式   Spark 集群在设计的时候，并没有在资源管理的设计上对外封闭，而是充分考虑了未来对接一些更强大的资源管理系统，如 YARN、Mesos 等，所以 Spark 架构设计将资源管理单独抽象出一层，通过这种抽象能够构建一种适合企业当前技术栈的插件式资源管理模块，从而为不同的计算场景提供不同的资源分配与调度策略。Spark 集群模式架构，如下图所示： 上图中，Spark集群Cluster Manager目前支持如下三种模式： 1）Standalone 模式   • Standalone 模式是 Spark 内部默认实现的一种集群管理模式，这种模式是通过集群中的 Master 来统一管理资源，而与 Master 进行资源请求协商的是 Driver 内部的 StandaloneSchedulerBackend（实际上是其内部的 StandaloneAppClient 真正与 Master 通信），后面会详细说明。 2）YARN 模式   • YARN 模式下，可以将资源的管理统一交给 YARN 集群的 ResourceManager 去管理，选择这种模式，可以更大限度的适应企业内部已有的技术栈，如果企业内部已经在使用 Hadoop 技术构建大数据处理平台。 3）Mesos 模式   • 随着 Apache Mesos 的不断成熟，一些企业已经在尝试使用 Mesos 构建数据中心的操作系统（DCOS），Spark 构建在 Mesos 之上，能够支持细粒度、粗粒度的资源调度策略（Mesos 的优势），也可以更好地适应企业内部已有技术栈。   • 那么，Spark 中是怎么考虑满足这一重要的设计决策的呢？也就是说，如何能够保证 Spark 非常容易的让第三方资源管理系统轻松地接入进来。我们深入到类设计的层面看一下，如下类图所示：   • 可以看出，Task 调度直接依赖 SchedulerBackend，SchedulerBackend 与实际资源管理模块交互实现资源请求。这里面，CoarseGrainedSchedulerBackend 是 Spark 中与资源调度相关的最重要的抽象，它需要抽象出与 TaskScheduler 通信的逻辑，同时还要能够与各种不同的第三方资源管理系统无缝地交互。实际上，CoarseGrainedSchedulerBackend 内部采用了一种 ResourceOffer 的方式来处理资源请求。 &nbsp; 1.5 RPC 网络通信抽象   Spark RPC 层是基于优秀的网络通信框架 Netty 设计开发的，但是 Spark 提供了一种很好地抽象方式，将底层的通信细节屏蔽起来，而且也能够基于此来设计满足扩展性，比如，如果有其他不基于 Netty 的网络通信框架的新的RPC接入需求，可以很好地扩展而不影响上层的设计。RPC 层设计，如下图类图所示：   任何两个 Endpoint 只能通过消息进行通信，可以实现一个 RpcEndpoint 和一个 RpcEndpointRef。想要与 RpcEndpoint 通信，需要获取到该 RpcEndpoint 对应的 RpcEndpointRef 即可，而且管理 RpcEndpoint 和 RpcEndpointRef 创建及其通信的逻辑，统一在 RpcEnv 对象中管理。 &nbsp; 1.6 启动 Standalone 集群   Standalone 模式下，Spark 集群采用了简单的 Master-Slave 架构模式，Master 统一管理所有的 Worker，这种模式很常见，我们简单地看下 Spark Standalone 集群启动的基本流程，如下图所示： 可以看到，Spark 集群采用的消息的模式进行通信，也就是 EDA 架构模式，借助于 RPC 层的优雅设计，任何两个 Endpoint 想要通信，发送消息并携带数据即可。上图的流程描述如下所示：   • 1）Master 启动时首先创一个 RpcEnv 对象，负责管理所有通信逻辑。   • 2）Master 通过 RpcEnv 对象创建一个 Endpoint，Master 就是一个 Endpoint，Worker 可以与其进行通信。   • 3）Worker 启动时也是创一个 RpcEnv 对象。   • 4）Worker 通过 RpcEnv 对象创建一个 Endpoint。   • 5）Worker 通过 RpcEnv 对，建立到 Master 的连接，获取到一个 RpcEndpointRef 对象，通过该对象可以与 Master 通信。   • 6）Worker 向 Master 注册，注册内容包括主机名、端口、CPU Core 数量、内存数量。   • 7）Master 接收到 Worker 的注册，将注册信息维护在内存中的 Table 中，其中还包含了一个到 Worker 的 RpcEndpointRef 对象引用。   • 8）Master 回复 Worker 已经接收到注册，告知 Worker 已经注册成功。   • 9）此时如果有用户提交 Spark 程序，Master 需要协调启动 Driver；而 Worker 端收到成功注册响应后，开始周期性向 Master 发送心跳。 &nbsp; 1.7 核心组件   集群处理计算任务的运行时（即用户提交了 Spark 程序），最核心的顶层组件就是 Driver 和 Executor，它们内部管理很多重要的组件来协同完成计算任务，核心组件栈如下图所示：   Driver 和 Executor 都是运行时创建的组件，一旦用户程序运行结束，他们都会释放资源，等待下一个用户程序提交到集群而进行后续调度。上图，我们列出了大多数组件，其中 SparkEnv 是一个重量级组件，他们内部包含计算过程中需要的主要组件，而且，Driver 和 Executor 共同需要的组件在 SparkEnv 中也包含了很多。这里，我们不做过多详述，后面交互流程等处会说明大部分组件负责的功能。 &nbsp; 1.8 核心组件交互流程   在 Standalone 模式下，Spark 中各个组件之间交互还是比较复杂的，但是对于一个通用的分布式计算系统来说，这些都是非常重要而且比较基础的交互。首先，为了理解组件之间的主要交互流程，我们给出一些基本要点：   • 一个 Application 会启动一个 Driver   • 一个 Driver 负责跟踪管理该 Application 运行过程中所有的资源状态和任务状态   • 一个 Driver 会管理一组 Executor   • 一个 Executor 只执行属于一个 Driver 的 Task 核心组件之间的主要交互流程，如下图所示： 上图中，通过不同颜色或类型的线条，给出了如下 6 个核心的交互流程，我们会详细说明：橙色：提交用户 Spark 程序 用户提交一个 Spark 程序，主要的流程如下所示：   •1）用户 spark-submit 脚本提交一个 Spark 程序，会创建一个 ClientEndpoint 对象，该对象负责与 Master 通信交互   •2）ClientEndpoint 向 Master 发送一个 RequestSubmitDriver 消息，表示提交用户程序   •3）Master 收到 RequestSubmitDriver 消息，向 ClientEndpoint 回复 SubmitDriverResponse，表示用户程序已经完成注册   •4）ClientEndpoint 向 Master 发送 RequestDriverStatus 消息，请求 Driver 状态   •5）如果当前用户程序对应的 Driver 已经启动，则 ClientEndpoint 直接退出，完成提交用户程序紫色：启动 Driver 进程 当用户提交用户 Spark 程序后，需要启动 Driver 来处理用户程序的计算逻辑，完成计算任务，这时 Master 协调需要启动一个 Driver，具体流程如下所示：   •1）Maser 内存中维护着用户提交计算的任务 Application，每次内存结构变更都会触发调度，向 Worker 发送 LaunchDriver 请求   •2）Worker 收到 LaunchDriver 消息，会启动一个 DriverRunner 线程去执行 LaunchDriver 的任务   •3）DriverRunner 线程在 Worker 上启动一个新的 JVM 实例，该 JVM 实例内运行一个 Driver 进程，该 Driver 会创建 SparkContext 对象红色：注册 Application Dirver 启动以后，它会创建 SparkContext 对象，初始化计算过程中必需的基本组件，并向 Master 注册 Application，流程描述如下：   •1）创建 SparkEnv 对象，创建并管理一些数基本组件   •2）创建 TaskScheduler，负责 Task 调度   •3）创建 StandaloneSchedulerBackend，负责与 ClusterManager 进行资源协商   •4）创建 DriverEndpoint，其它组件可以与 Driver 进行通信   •5）在 StandaloneSchedulerBackend 内部创建一个 StandaloneAppClient，负责处理与 Master 的通信交互   •6）StandaloneAppClient 创建一个 ClientEndpoint，实际负责与 Master 通信   •7）ClientEndpoint 向 Master 发送 RegisterApplication 消息，注册 Application   •8）Master 收到 RegisterApplication 请求后，回复 ClientEndpoint 一个 RegisteredApplication 消息，表示已经注册成功蓝色：启动 Executor 进程   •1）Master 向 Worker 发送 LaunchExecutor 消息，请求启动 Executor；同时 Master 会向 Driver 发送 ExecutorAdded 消息，表示 Master 已经新增了一个 Executor（此时还未启动）   •2）Worker 收到 LaunchExecutor 消息，会启动一个 ExecutorRunner 线程去执行 LaunchExecutor 的任务   •3）Worker 向 Master 发送 ExecutorStageChanged 消息，通知 Executor 状态已发生变化   •4）Master 向 Driver 发送 ExecutorUpdated 消息，此时 Executor 已经启动粉色：启动 Task 执行   •1）StandaloneSchedulerBackend 启动一个 DriverEndpoint   •2）DriverEndpoint 启动后，会周期性地检查 Driver 维护的 Executor 的状态，如果有空闲的 Executor 便会调度任务执行   •3）DriverEndpoint 向 TaskScheduler 发送 Resource Offer 请求   •4）如果有可用资源启动 Task，则 DriverEndpoint 向 Executor 发送 LaunchTask 请求   •5）Executor 进程内部的 CoarseGrainedExecutorBackend 调用内部的 Executor 线程的 launchTask 方法启动 Task   •6）Executor 线程内部维护一个线程池，创建一个 TaskRunner 线程并提交到线程池执行绿色：Task 运行完成   •1）Executor 进程内部的 Executor 线程通知 CoarseGrainedExecutorBackend，Task 运行完成   •2）CoarseGrainedExecutorBackend 向 DriverEndpoint 发送 StatusUpdated 消息，通知 Driver 运行的 Task 状态发生变更   •3）StandaloneSchedulerBackend 调用T askScheduler 的 updateStatus 方法更新 Task 状态   •4）StandaloneSchedulerBackend 继续调用 TaskScheduler 的 resourceOffers 方法，调度其他任务运行 &nbsp; 1.9 Block 管理   Block 管理，主要是为 Spark 提供的 Broadcast 机制提供服务支撑的。Spark 中内置采用 TorrentBroadcast 实现，该 Broadcast 变量对应的数据（Task 数据）或数据集（如 RDD），默认会被切分成若干 4M 大小的 Block，Task 运行过程中读取到该 Broadcast 变量，会以 4M 为单位的 Block 为拉取数据的最小单位，最后将所有的 Block 合并成 Broadcast 变量对应的完整数据或数据集。将数据切分成 4M 大小的 Block，Task 从多个 Executor 拉取 Block，可以非常好地均衡网络传输负载，提高整个计算集群的稳定性。   通常，用户程序在编写过程中，会对某个变量进行 Broadcast，该变量称为 Broadcast 变量。在实际物理节点的 Executor 上执行 Task 时，需要读取 Broadcast 变量对应的数据集，那么此时会根据需要拉取 DAG 执行流上游已经生成的数据集。采用 Broadcast 机制，可以有效地降低数据在计算集群环境中传输的开销。具体地，如果一个用户对应的程序中的 Broadcast 变量，对应着一个数据集，它在计算过程中需要拉取对应的数据，如果在同一个物理节点上运行着多个 Task，多个 Task 都需要该数据，有了 Broadcast 机制，只需要拉取一份存储在本地物理机磁盘即可，供多个 Task 计算共享。   另外，用户程序在进行调度过程中，会根据调度策略将 Task 计算逻辑数据（代码）移动到对应的 Worker 节点上，最优情况是对本地数据进行处理，那么代码（序列化格式）也需要在网络上传输，也是通过 Broadcast 机制进行传输，不过这种方式是首先将代码序列化到 Driver 所在 Worker 节点，后续如果 Task 在其他 Worker 中执行，需要读取对应代码的 Broadcast 变量，首先就是从 Driver 上拉取代码数据，接着其他晚一些被调度的 Task 可能直接从其他 Worker 上的 Executor 中拉取代码数据。   我们通过以 Broadcast 变量 taskBinary 为例，说明 Block 是如何管理的，如下图所示：   上图中，Driver 负责管理所有的 Broadcast 变量对应的数据所在的 Executor，即一个 Executor 维护一个 Block 列表。在 Executor 中运行一个 Task 时，执行到对应的 Broadcast 变量 taskBinary，如果本地没有对应的数据，则会向 Driver 请求获取 Broadcast 变量对应的数据，包括一个或多个 Block 所在的 Executor 列表，然后该 Executor 根据 Driver 返回的 Executor 列表，直接通过底层的 BlockTransferService 组件向对应 Executor 请求拉取 Block。Executor 拉取到的 Block 会缓存到本地，同时向 Driver 报告该 Executor 上存在的 Block 信息，以供其他 Executor 执行 Task 时获取 Broadcast 变量对应的数据。 &nbsp; 1.10整体应用   用户通过 spark-submit 提交或者运行 spark-shell REPL，集群创建 Driver，Driver 加载 Application，最后 Application 根据用户代码转化为 RDD，RDD 分解为 Tasks，Executor 执行 Task 等系列知识，整体交互蓝图如下： 回到顶部 第2章 Spark 通信架构   Spark作为分布式计算框架，多个节点的设计与相互通信模式是其重要的组成部分。Spark 一开始使用 Akka 作为内部通信部件。在 Spark 1.3 年代，为了解决大块数据（如 Shuffle）的传输问题，Spark 引入了 Netty 通信框架。到了 Spark 1.6，Spark 可以配置使用 Akka 或者 Netty 了，这意味着 Netty 可以完全替代 Akka了。再到 Spark 2，Spark 已经完全抛弃 Akka了，全部使用 Netty 了。   为什么呢？官方的解释是：   •1）很多 Spark 用户也使用 Akka，但是由于 Akka 不同版本之间无法互相通信，这就要求用户必须使用跟 Spark 完全一样的 Akka 版本，导致用户无法升级 Akka。   •2）Spark 的 Akka 配置是针对 Spark 自身来调优的，可能跟用户自己代码中的 Akka 配置冲突。   •3）Spark 用的 Akka 特性很少，这部分特性很容易自己实现。同时，这部分代码量相比 Akka 来说少很多，debug 比较容易。如果遇到什么 bug，也可以自己马上 fix，不需要等 Akka 上游发布新版本。而且，Spark 升级 Akka 本身又因为第一点会强制要求用户升级他们使用的 Akka，对于某些用户来说是不现实的。 SPARK 的通信架构 - Actor 比较，如下图所示： 2.1 通信组件概览 对源码分析，对于设计思路理解如下：   •1）RpcEndpoint：RPC 端点，Spark 针对于每个节点（Client/Master/Worker）都称之一个 Rpc 端点且都实现 RpcEndpoint 接口，内部根据不同端点的需求，设计不同的消息和不同的业务处理，如果需要发送（询问）则调用 Dispatcher。   •2）RpcEnv：RPC 上下文环境，每个 Rpc 端点运行时依赖的上下文环境称之为 RpcEnv。   •3）Dispatcher：消息分发器，针对于 RPC 端点需要发送消息或者从远程 RPC 接收到的消息，分发至对应的指令收件箱/发件箱。如果指令接收方是自己存入收件箱，如果指令接收方为非自身端点，则放入发件箱。   •4）Inbox：指令消息收件箱，一个本地端点对应一个收件箱，Dispatcher 在每次向 Inbox 存入消息时，都将对应 EndpointData 加入内部待 Receiver Queue中，另外 Dispatcher 创建时会启动一个单独线程进行轮询 Receiver Queue，进行收件箱消息消费。   •5）OutBox：指令消息发件箱，一个远程端点对应一个发件箱，当消息放入 Outbox 后，紧接着将消息通过 TransportClient 发送出去。消息放入发件箱以及发送过程是在同一个线程中进行，这样做的主要原因是远程消息分为 RpcOutboxMessage，OneWayOutboxMessage 两种消息，而针对于需要应答的消息直接发送且需要得到结果进行处理   •6）TransportClient：Netty 通信客户端，根据 OutBox 消息的 receiver 信息，请求对应远程 TransportServer。   •7）TransportServer：Netty 通信服务端，一个 RPC 端点一个 TransportServer，接受远程消息后调用 Dispatcher 分发消息至对应收发件箱。注意：   TransportClient 与 TransportServer 通信虚线表示两个 RpcEnv 之间的通信，图示没有单独表达式。   一个 Outbox 一个 TransportClient，图示没有单独表达式。   一个 RpcEnv 中存在两个 RpcEndpoint，一个代表本身启动的 RPC 端点，另外一个为 RpcEndpointVerifier。 Spark的通信架构 – 高层视图 Spark 的通信架构 – 类图 2.2 Endpoint 启动过程 启动的流程如下： Endpoint 启动后，默认会向 Inbox 中添加 OnStart 消息，不同的端点（Master/Worker/Client）消费 OnStart 指令时，进行相关端点的启动额外处理。 Endpoint 启动时，会默认启动 TransportServer，且启动结束后会进行一次同步测试 rpc 可用性（askSync-BoundPortsRequest）。 Dispatcher 作为一个分发器，内部存放了 Inbox，Outbox 的等相关句柄和存放了相关处理状态数据，结构大致如下： 2.3 Endpoint Send&amp;Ask 流程 Endpoint 的消息发送与请求流程，如下： Endpoint 根据业务需要存入两个维度的消息组合：send/ask 某个消息，receiver 是自身与非自身   •1）OneWayMessage：send + 自身，直接存入收件箱   •2）OneWayOutboxMessage：send + 非自身，存入发件箱并直接发送   •3）RpcMessage：ask + 自身，直接存入收件箱，另外还需要存入 LocalNettyRpcCallContext，需要回调后再返回   •4）RpcOutboxMessage：ask + 非自身，存入发件箱并直接发送，需要回调后再返回 &nbsp; 2.4 Endpoint Receive 流程 Endpoint 的消息的接收，流程如下： 上图 ServerBootstrap 为 Netty 启动服务，SocketChanel为Netty 数据通道。 上述包含 TransportSever 启动与消息接收两个流程。 &nbsp; 2.5 Endpoint Inbox 处理流程 Spark 在 Endpoint 的设计上核心设计即为 Inbox 与 Outbox，其中 Inbox 核心要点为：   •1）内部的处理流程拆分为多个消息指令（InboxMessage）存放入 Inbox。   •2）当 Dispatcher 启动最后，会启动一个名为【dispatcher-event-loop】的线程扫描 Inbox 待处理 InboxMessage，并调用 Endpoint 根据 InboxMessage 类型做相应处理   •3）当 Dispatcher 启动最后，默认会向 Inbox 存入 OnStart 类型的 InboxMessage，Endpoint 在根据 OnStart 指令做相关的额外启动工作，三端启动后所有的工作都是对 OnStart 指令处理衍生出来的，因此可以说 OnStart 指令是相互通信的源头。 消息指令类型大致如下三类：   •1）OnStart/OnStop   •2）RpcMessage/OneWayMessage   •3）RemoteProcessDisconnected/RemoteProcessConnected/RemoteProcessConnectionError 2.6 Endpoint 画像 回到顶部 第3章 脚本解析 在看源码之前，我们一般会看相关脚本了解其初始化信息以及 Bootstrap 类，Spark 也不例外，而 Spark 中相关的脚本如下： %SPARK_HOME%/sbin/start-master.sh %SPARK_HOME%/sbin/start-slaves.sh %SPARK_HOME%/sbin/start-all.sh %SPARK_HOME%/bin/spark-submit 启动脚本中对于公共处理部分进行抽取为独立的脚本，如下： 脚本 说明 sbin/spark-config.sh 初始化环境变量 SPARK_CONF_DIR, PYTHONPATH bin/load-spark-env.sh 初始化环境变量 SPARK_SCALA_VERSION，调用 %SPARK_HOME% conf/spark-env.sh 加载用户自定义环境变量 3.1 start-daemon.sh 主要完成进程相关基本信息初始化，然后调用 bin/spark-class 进行守护进程启动，该脚本是创建端点的通用脚本，三端各自脚本都会调用 spark-daemon.sh 脚本启动各自进程 详解如下： 1）初始化&nbsp;SPRK_HOME、SPARK_CONF_DIR、SPARK_IDENT_STRING、SPARK_LOG_DIR&nbsp;环境变量&nbsp;(如果不存在) 2）初始化日志并测试日志文件夹读写权限，初始化&nbsp;PID&nbsp;目录并校验&nbsp;PID&nbsp;信息 3）调用&nbsp;/bin/spark-class&nbsp;脚本，/bin/spark-class&nbsp;见下面 3.2 spark-class Master 调用举例： bin/spark-class&nbsp;\\ --class&nbsp;org.apache.spark.deploy.master.Master&nbsp;\\ --host&nbsp;$SPARK_MASTER_HOST&nbsp;\\ --port&nbsp;$SPARK_MASTER_PORT&nbsp;\\ --webui-port&nbsp;$SPARK_MASTER_WEBUI_PORT&nbsp;$ORIGINAL_ARGS 1）初始化&nbsp;RUNNER(java)、SPARK_JARS_DIR&nbsp;(%SPARK_HOME%/jars)、LAUNCH_CLASSPATH&nbsp;信息 2）调用&nbsp;(&quot;$RUNNER&quot;&nbsp;-Xmx128m&nbsp;-cp&nbsp;&quot;$LAUNCH_CLASSPATH&quot;&nbsp;org.apache.spark.launcher.Main&nbsp;&quot;$@&quot;)&nbsp;获取最终执行的&nbsp;shell&nbsp;语句 3）执行最终的&nbsp;shell&nbsp;语句，示例如下： /opt/module/jdk1.8.0_144&nbsp;\\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\\ -Xmx1g&nbsp;\\ -XX:MaxPermSize=256m&nbsp;\\ org.apache.spark.deploy.master.Master&nbsp;\\ --host&nbsp;hadoop102&nbsp;\\ --port&nbsp;7077&nbsp;\\ --webui-port&nbsp;8080 如果是&nbsp;Client，那么可能为&nbsp;r，或者&nbsp;python&nbsp;脚本。 3.3 start-master.sh 启动 Master 的脚本，流程如下： 详解如下： 1）用户执行&nbsp;start-master.sh&nbsp;脚本，初始化环境变量&nbsp;SPARK_HOME&nbsp;(如果&nbsp;PATH&nbsp;不存在&nbsp;SPARK_HOME，初始化脚本的上级目录为&nbsp;SPARK_HOME)，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh 2）如果环境变量&nbsp;SPARK_MASTER_HOST、SPARK_MASTER_PORT、SPARK_MASTER_WEBUI_PORT&nbsp;不存在，进行初始化&nbsp;7077，hostname&nbsp;-f，8080 3）调用&nbsp;spark-daemon.sh&nbsp;脚本启动&nbsp;master&nbsp;进程，如下： spark-daemon.sh&nbsp;start&nbsp;org.apache.spark.deploy.master.Master&nbsp;1&nbsp;\\ --host&nbsp;$SPARK_MASTER_HOST&nbsp;\\ --port&nbsp;$SPARK_MASTER_PORT&nbsp;\\ --webui-port&nbsp;$SPARK_MASTER_WEBUI_PORT&nbsp;$ORIGINAL_ARGS） 3.4 start-slaves.sh 启动 Worker 的脚本，流程如下： 详解如下： 1）用户执行&nbsp;start-slaves.sh&nbsp;脚本，初始化环境变量&nbsp;SPARK_HOME，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh，初始化&nbsp;Master&nbsp;host/port&nbsp;信息 2）调用&nbsp;slaves.sh&nbsp;脚本，读取&nbsp;conf/slaves&nbsp;文件并遍历，通过&nbsp;ssh&nbsp;连接到对应&nbsp;slave&nbsp;节点，启动&nbsp;${SPARK_HOME}/sbin/start-slave.sh&nbsp;spark://$SPARK_MASTER_HOST:$SPARK_MASTER_PORT 3）start-slave.sh&nbsp;在各个节点中，初始化环境变量&nbsp;SPARK_HOME，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh，根据&nbsp;$SPARK_WORKER_INSTANCES&nbsp;计算&nbsp;WEBUI_PORT&nbsp;端口&nbsp;(worker&nbsp;端口号依次递增)&nbsp;并启动&nbsp;Worker&nbsp;进程，如下： ${SPARK_HOME}/sbin/spark-daemon.sh&nbsp;\\ start&nbsp;org.apache.spark.deploy.worker.Worker&nbsp;$WORKER_NUM&nbsp;\\ --webui-port&nbsp;&quot;$WEBUI_PORT&quot;&nbsp;$PORT_FLAG&nbsp;$PORT_NUM&nbsp;$MASTER&nbsp;&quot;$@&quot; 3.5 start-all.sh 属于快捷脚本，内部调用 start-master.sh 与 start-slaves.sh 脚本，并无额外工作。 3.6 spark-submit 任务提交的基本脚本，流程如下： 详解如下： 1）直接调用&nbsp;spark-class&nbsp;脚本进行进程创建，示例如下： ./spark-submit&nbsp;\\ --class&nbsp;org.apache.spark.examples.SparkPi&nbsp;\\ --master&nbsp;spark://hadoop102:7077&nbsp;\\ ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 2）如果是&nbsp;java/scala&nbsp;任务，那么最终调用&nbsp;SparkSubmit.scala&nbsp;进行任务处理，示例如下： /opt/module/jdk1.8.0_144&nbsp;-cp&nbsp;\\ /opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\\ -Xmx1g&nbsp;-XX:MaxPermSize=256m&nbsp;\\ org.apache.spark.deploy.SparkSubmit&nbsp;\\ --master&nbsp;spark://hadoop102:7077&nbsp;\\ --class&nbsp;org.apache.spark.examples.SparkPi&nbsp;\\ ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 回到顶部 第4章 Master 节点启动 Master 作为 Endpoint 的具体实例，下面我们介绍一下 Master 启动以及 OnStart 指令后的相关工作。 4.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\\ -Xmx1g&nbsp;\\ -XX:MaxPermSize=256m&nbsp;\\ org.apache.spark.deploy.master.Master&nbsp;\\ --host&nbsp;hadoop102&nbsp;\\ --port&nbsp;7077&nbsp;\\ 4.2 启动流程 Master 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）MasterArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Master&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--ip&nbsp;-i&nbsp;--host&nbsp;-h&nbsp;--port&nbsp;-p&nbsp;--webui-port&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;b)将&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 3）NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 4）BoundPortsResponse&nbsp;返回&nbsp;rpcEndpointPort、webUIPort、restPort&nbsp;真实端口。 5）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 4.3 OnStart 监听事件 Master 的启动完成后异步执行工作如下： 详解如下： 1）【dispatcher-event-loop】线程扫描到&nbsp;OnStart&nbsp;指令后会启动相关&nbsp;MasterWebUI&nbsp;(默认端口&nbsp;8080），根据配置选择安装&nbsp;ResetServer&nbsp;(默认端口&nbsp;6066)。 2）另外新起【master-forward-message-thread】线程定期检查&nbsp;Worker&nbsp;心跳是否超时。 3）如果&nbsp;Worker&nbsp;心跳检测超时，那么对&nbsp;Worker&nbsp;下的发布的所有任务所属&nbsp;Driver&nbsp;进行&nbsp;ExecutorUpdated&nbsp;发送，同时自己再重新&nbsp;LaunchDriver。 4.4 RpcMessage 处理 (receiveAndReply) 4.5 OneWayMessage 处理 (receive) 4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑 这部分对整体 Master 理解作用不是很大且理解比较抽象，可以先读后续内容，回头再考虑看这部分内容，或者不读。 回到顶部 第5章 Worker 节点启动 Worker 作为 Endpoint 的具体实例，下面我们介绍一下 Worker 启动以及 OnStart 指令后的额外工作。 5.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\\ -Xmx1g&nbsp;\\ -XX:MaxPermSize=256m&nbsp;\\ org.apache.spark.deploy.worker.Worker&nbsp;\\ --webui-port&nbsp;8081 spark://hadoop102:7077 5.2 启动流程 Worker 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）WorkerArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Master&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--ip&nbsp;-i&nbsp;--host&nbsp;-h&nbsp;--port&nbsp;-p&nbsp;--cores&nbsp;-c&nbsp;--memory&nbsp;-m&nbsp;--work-dir&nbsp;--webui-port&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;--properties-file&nbsp;(没有配置默认为conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;在没有配置情况下，cores&nbsp;默认为服务器&nbsp;CPU&nbsp;核数。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;在没有配置情况下，memory&nbsp;默认为服务器内存减&nbsp;1G，如果低于&nbsp;1G&nbsp;取&nbsp;1G。 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;webUiPort&nbsp;默认为&nbsp;8081。 3）NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 4）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 5.3 OnStart 监听事件 Worker 的启动完成后异步执行工作如下： 详解如下： 1）【dispatcher-event-loop】线程扫描到&nbsp;OnStart&nbsp;指令后会启动相关&nbsp;WorkerWebUI&nbsp;(默认端口&nbsp;8081)。 2）Worker&nbsp;向&nbsp;Master&nbsp;发起一次&nbsp;RegisterWorker&nbsp;指令。 3）另起【master-forward-message-thread】线程定期执行&nbsp;ReregisterWithMaster&nbsp;任务，如果注册成功&nbsp;(RegisteredWorker)&nbsp;则跳过，否则再次向&nbsp;Master&nbsp;发起&nbsp;RegisterWorker&nbsp;指令，直到超过最大次数报错&nbsp;(默认16次)。 4）Master&nbsp;如果可以注册，则维护对应的&nbsp;WorkerInfo&nbsp;对象并持久化，完成后向&nbsp;Worker&nbsp;发起一条&nbsp;RegisteredWorker&nbsp;指令，如果&nbsp;Master&nbsp;为&nbsp;standby&nbsp;状态，则向&nbsp;Worker&nbsp;发起一条&nbsp;MasterInStandby&nbsp;指令。 5）Worker&nbsp;接受&nbsp;RegisteredWorker&nbsp;后，提交【master-forward-message-thread】线程定期执行&nbsp;SendHeartbeat&nbsp;任务，完成后向&nbsp;Worker&nbsp;发起一条&nbsp;WorkerLatestState&nbsp;指令。 6）Worker&nbsp;发心跳检测，会触发更新&nbsp;Master&nbsp;对应&nbsp;WorkerInfo&nbsp;对象，如果&nbsp;Master&nbsp;检测到异常，则发起&nbsp;ReconnectWorker&nbsp;指令至&nbsp;Worker，Worker&nbsp;则再次执行&nbsp;ReregisterWithMaster&nbsp;工作。 5.4 RpcMessage 处理 (receiveAndReply) 5.5 OneWayMessage 处理 (receive) 回到顶部 第6章 Client 启动流程 Client 作为 Endpoint 的具体实例，下面我们介绍一下 Client 启动以及 OnStart 指令后的额外工作。 6.1 脚本概览 下面是一个举例： /opt/module/jdk1.8.0_144&nbsp;\\ -cp&nbsp;/opt/module/spark-2.1.1-bin-hadoop2.7/conf/:/opt/module/spark-2.1.1-bin-hadoop2.7/jars/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\\ -Xmx1g -XX:MaxPermSize=256m org.apache.spark.deploy.SparkSubmit --master&nbsp;spark://hadoop102:7077 --class&nbsp;org.apache.spark.examples.SparkPi ../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10 6.2 SparkSubmit 启动流程 SparkSubmit 的启动流程如下： 详解如下： 1）SparkSubmitArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Client&nbsp;启动的参数 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--name&nbsp;--master&nbsp;--class&nbsp;--deploy-mode &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--num-executors&nbsp;--executor-cores&nbsp;--total-executor-cores&nbsp;--executor-memory &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--driver-memory&nbsp;--driver-cores&nbsp;--driver-class-path&nbsp;--driver-java-options&nbsp;--driver-library-path &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--kill&nbsp;--status&nbsp;--supervise&nbsp;--queue &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--files&nbsp;--py-files &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--archives&nbsp;--jars&nbsp;--packages&nbsp;--exclude-packages&nbsp;--repositories &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--conf&nbsp;(解析存入&nbsp;Map：sparkProperties&nbsp;中) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--proxy-user&nbsp;--principal&nbsp;--keytab&nbsp;--help&nbsp;--verbose&nbsp;--version&nbsp;--usage-error &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;合并&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;文件配置项&nbsp;(不在&nbsp;--conf&nbsp;中的配置&nbsp;)&nbsp;至&nbsp;sparkProperties &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;删除&nbsp;sparkProperties&nbsp;中不以&nbsp;spark.&nbsp;开头的配置项目 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;启动参数为空的配置项从&nbsp;sparkProperties&nbsp;中合并 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;根据&nbsp;action&nbsp;(SUBMIT、KILL、REQUEST_STATUS)&nbsp;校验各自必需参数是否有值 2）Case&nbsp;Submit： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;获取childMainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;clent(默认)：用户任务启动类&nbsp;mainClass&nbsp;(--class) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;useRest&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.rest.RestSubmissionClient &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;!useRest&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.Client &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;yarn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.yarn.Client &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;mesos:*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.rest.RestSubmissionClient &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;获取&nbsp;childArgs&nbsp;(子运行时对应命令行组装参数) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;useRest&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;包含&nbsp;primaryResource&nbsp;与&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;!useRest&nbsp;&nbsp;&nbsp;&nbsp;包含&nbsp;--supervise&nbsp;--memory&nbsp;--cores&nbsp;&nbsp;launch&nbsp;childArg,&nbsp;primaryResource,&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;yarn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--class&nbsp;--arg&nbsp;--jar/--primary-py-file/--primary-r-file &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;mesos:*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;primaryResource &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;获取&nbsp;childClasspath &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;clent&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;读取&nbsp;--jars&nbsp;配置，与&nbsp;primaryResource&nbsp;信息&nbsp;(../examples/jars/spark-examples_2.11-2.1.0.jar) &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;获取&nbsp;sysProps &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将&nbsp;sparkPropertie&nbsp;中的所有配置封装成新的&nbsp;sysProps&nbsp;对象，另外还增加了一下额外的配置项目 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;将&nbsp;childClasspath&nbsp;通过当前的类加载器加载中 &nbsp;&nbsp;&nbsp;&nbsp;f)&nbsp;将&nbsp;sysProps&nbsp;设置到当前&nbsp;jvm&nbsp;环境中 &nbsp;&nbsp;&nbsp;&nbsp;g)&nbsp;最终反射执行&nbsp;childMainClass，传参为&nbsp;childArgs 6.3 Client 启动流程 Client 的启动流程如下： 详解如下： 1）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 2）ClientArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Client&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--cores&nbsp;-c&nbsp;--memory&nbsp;-m&nbsp;--supervise&nbsp;-s&nbsp;--verbose&nbsp;-v &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;launch&nbsp;jarUrl&nbsp;master&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kill&nbsp;master&nbsp;driverId &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;在没有配置情况下，cores&nbsp;默认为&nbsp;1&nbsp;核。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;在没有配置情况下，memory&nbsp;默认为&nbsp;1G。 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 3）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 6.4 Client 的 OnStart 监听事件 Client 的启动完成后异步执行工作如下：　 详解如下： 1）如果是发布任务(case&nbsp;launch)，Client&nbsp;创建一个&nbsp;DriverDescription，并向&nbsp;Master&nbsp;发起&nbsp;RequestSubmitDriver&nbsp;请求。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;Command&nbsp;中的&nbsp;mainClass&nbsp;为：&nbsp;org.apache.spark.deploy.worker.DriverWrapper &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;Command&nbsp;中的&nbsp;arguments&nbsp;为：&nbsp;Seq(&quot;{{WORKER_URL}}&quot;,&nbsp;&quot;{{USER_JAR}}&quot;,&nbsp;driverArgs.mainClass) 2）Master&nbsp;接受&nbsp;RequestSubmitDriver&nbsp;请求后，将&nbsp;DriverDescription&nbsp;封装为&nbsp;一个DriverInfo。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;startTime&nbsp;与&nbsp;submitDate&nbsp;都为当前时间 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;driverId&nbsp;格式为：driver-yyyyMMddHHmmss-nextId，nextId&nbsp;是全局唯一的 3）Master&nbsp;持久化&nbsp;DriverInfo，并加入待调度列表中&nbsp;(waitingDrivers)，触发公共资源调度逻辑。 4）Master&nbsp;公共资源调度结束后，返回&nbsp;SubmitDriverResponse给Client。 6.5 RpcMessage 处理 (receiveAndReply) 无。 6.6 OneWayMessage 处理(receive) 回到顶部 第7章 Driver 和 DriverRunner Client 向 Master 发起 RequestSubmitDriver 请求，Master 将 DriverInfo 添加待调度列表中 (waitingDrivers)，下面针对于 Driver 进一步梳理。 7.1 Master 对 Driver 资源分配 大致流程如下： 详解如下： waitingDrivers&nbsp;与&nbsp;aliveWorkers&nbsp;进行资源匹配： 1）在&nbsp;waitingDrivers&nbsp;循环内，轮询所有&nbsp;aliveWorker。 2）如果&nbsp;aliveWorker&nbsp;满足当前&nbsp;waitingDriver&nbsp;资源要求，给&nbsp;Worker&nbsp;发送&nbsp;LaunchDriver&nbsp;指令并将&nbsp;waitingDriver&nbsp;移除&nbsp;waitingDrivers，则进行下一次&nbsp;waitingDriver&nbsp;的轮询工作。 3）如果轮询完所有&nbsp;aliveWorker&nbsp;都不满足&nbsp;waitingDriver&nbsp;资源要求，则进行下一次&nbsp;waitingDriver&nbsp;的轮询工作。 4）所有发起的轮询开始点都上次轮询结束点的下一个点位开始。 7.2 Worker 运行 DriverRunner Driver 的启动，流程如下： 详解如下： 1）当&nbsp;Worker&nbsp;遇到&nbsp;LaunchDriver&nbsp;指令时，创建并启动一个&nbsp;DriverRunner。 2）DriverRunner&nbsp;启动一个线程&nbsp;DriverRunner&nbsp;for&nbsp;[driverId]&nbsp;处理&nbsp;Driver&nbsp;启动工作。 3）DriverRunner&nbsp;for&nbsp;[driverId]： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;添加&nbsp;JVM&nbsp;钩子，针对于每个&nbsp;diriverId&nbsp;创建一个临时目录。 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;DriverDesc.jarUrl&nbsp;通过&nbsp;Netty&nbsp;从&nbsp;Driver&nbsp;机器远程拷贝过来。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;根据&nbsp;DriverDesc.command&nbsp;模板构建本地执行的&nbsp;command&nbsp;命令，并启动该&nbsp;command&nbsp;对应的&nbsp;Process&nbsp;进程。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;将&nbsp;Process&nbsp;的输出流输出到文件&nbsp;stdout/stderror，如果&nbsp;Process&nbsp;启动失败，进行&nbsp;1-5&nbsp;的秒的反复启动工作，直到启动成功，在释放&nbsp;Worker&nbsp;节点的&nbsp;DriverRunner&nbsp;的资源。 7.3 DriverRunner 创建并运行 DriverWrapper DriverWrapper 的运行，流程如下： 详解如下： 1）DriverWapper&nbsp;创建了一个&nbsp;RpcEndpoint&nbsp;与&nbsp;RpcEnv。 2）RpcEndpoint&nbsp;为&nbsp;WorkerWatcher，主要目的为监控&nbsp;Worker&nbsp;节点是否正常，如果出现异常就直接退出。 3）然后当前的&nbsp;ClassLoader&nbsp;加载&nbsp;userJar，同时执行&nbsp;userMainClass。 4）执行用户的&nbsp;main&nbsp;方法后关闭&nbsp;workerWatcher。 回到顶部 第8章 SparkContext 解析 8.1 SparkContext 解析 SparkContext 是用户通往 Spark 集群的唯一入口，任何需要使用 Spark 的地方都需要先创建 SparkContext，那么 SparkContext 做了什么？ 首先 SparkContext 是在 Driver 程序里面启动的，可以看做 Driver 程序和 Spark 集群的一个连接，SparkContext 在初始化的时候，创建了很多对象，如下图所示： 上图列出了 SparkContext 在初始化创建的时候的一些主要组件的构建。 8.2 SparkContext 创建过程 详解如下： SparkContext&nbsp;在新建时： 1）内部创建一个&nbsp;SparkEnv，SparkEnv&nbsp;内部创建一个&nbsp;RpcEnv。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;RpcEnv&nbsp;内部创建并注册一个&nbsp;MapOutputTrackerMasterEndpoint(该&nbsp;Endpoint&nbsp;暂不介绍) 2）接着创建&nbsp;DAGScheduler、TaskSchedulerImpl、SchedulerBackend。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;TaskSchedulerImpl&nbsp;创建时创建&nbsp;SchedulableBuilder，SchedulableBuilder&nbsp;根据类型分为&nbsp;FIFOSchedulableBuilder、FairSchedulableBuilder&nbsp;两类 3）最后启动&nbsp;TaskSchedulerImpl，TaskSchedulerImpl&nbsp;启动&nbsp;SchedulerBackend。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;SchedulerBackend&nbsp;启动时创建&nbsp;ApplicationDescription、DriverEndpoint、StandloneAppClient &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;StandloneAppClient&nbsp;内部包括一个&nbsp;ClientEndpoint 8.3 SparkContext 简易结构与交互关系 详解如下： 1）SparkContext：是用户&nbsp;Spark&nbsp;执行任务的上下文，用户程序内部使用&nbsp;Spark&nbsp;提供的&nbsp;Api&nbsp;直接或间接创建一个&nbsp;SparkContext。 2）SparkEnv：用户执行的环境信息，包括通信相关的端点。 3）RpcEnv：SparkContext&nbsp;中远程通信环境。 4）ApplicationDescription：应用程序描述信息，主要包含&nbsp;appName、maxCores、memoryPerExecutorMB、coresPerExecutor、Command&nbsp;(CoarseGrainedExecutorBackend)、appUiUrl&nbsp;等。 5）ClientEndpoint：客户端端点，启动后向&nbsp;Master&nbsp;发起注册&nbsp;RegisterApplication&nbsp;请求。 6）Master：接受&nbsp;RegisterApplication&nbsp;请求后，进行&nbsp;Worker&nbsp;资源分配，并向分配的资源发起&nbsp;LaunchExecutor&nbsp;指令。 7）Worker：接受&nbsp;LaunchExecutor&nbsp;指令后，运行&nbsp;ExecutorRunner。 8）ExecutorRunner：运行&nbsp;applicationDescription&nbsp;的&nbsp;Command&nbsp;命令，最终&nbsp;Executor，同时向&nbsp;DriverEndpoint&nbsp;注册&nbsp;Executor&nbsp;信息。 8.4 Master 对 Application 资源分配 当 Master 接受 Driver 的 RegisterApplication 请求后，放入 waitingDrivers 队列中，在同一调度中进行资源分配，分配过程如下： 详解如下： waitingApps&nbsp;与&nbsp;aliveWorkers&nbsp;进行资源匹配： 1）如果&nbsp;waitingApp&nbsp;配置了&nbsp;app.desc.coresPerExecutor： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;轮询所有有效可分配的&nbsp;worker，每次分配一个&nbsp;executor，executor&nbsp;的核数为&nbsp;minCoresPerExecutor(app.desc.coresPerExecutor)，直到不存在有效可分配资源或者&nbsp;app&nbsp;依赖的资源已全部被分配。 2）如果&nbsp;waitingApp&nbsp;没有配置&nbsp;app.desc.coresPerExecutor： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;轮询所有有效可分配的&nbsp;worker，每个&nbsp;worker&nbsp;分配一个&nbsp;executor，executor&nbsp;的核数为从&nbsp;minCoresPerExecutor(为固定值1)&nbsp;开始递增，直到不存在有效可分配资源或者&nbsp;app&nbsp;依赖的资源已全部被分配。 3）其中有效可分配&nbsp;worker&nbsp;定义为满足一次资源分配的&nbsp;worker： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;cores&nbsp;满足：usableWorkers(pos).coresFree&nbsp;-&nbsp;assignedCores(pos)&nbsp;&gt;=&nbsp;minCoresPerExecutor &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;memory&nbsp;满足(如果是新的&nbsp;Executor)：usableWorkers(pos).memoryFree&nbsp;-&nbsp;assignedExecutors(pos)&nbsp;*&nbsp;memoryPerExecutor&nbsp;&gt;=&nbsp;memoryPerExecutor 注意：Master&nbsp;针对于&nbsp;applicationInfo&nbsp;进行资源分配时，只有存在有效可用的资源就直接分配，而分配剩余的&nbsp;app.coresLeft&nbsp;则等下一次再进行分配。 8.5 Worker 创建 Executor （图解：橙色组件是 Endpoint 组件） 详解如下： Worker&nbsp;启动&nbsp;Executor 1）在&nbsp;Worker&nbsp;的&nbsp;tempDir&nbsp;下面创建&nbsp;application&nbsp;以及&nbsp;executor&nbsp;的目录，并&nbsp;chmod&nbsp;700&nbsp;操作权限。 2）创建并启动&nbsp;ExecutorRunner&nbsp;进行&nbsp;Executor&nbsp;的创建。 3）向&nbsp;Master&nbsp;发送&nbsp;Executor&nbsp;的状态情况。 ExecutorRnner 1）新线程【ExecutorRunner&nbsp;for&nbsp;[executorId]】读取&nbsp;ApplicationDescription&nbsp;将其中&nbsp;Command&nbsp;转化为本地的&nbsp;Command&nbsp;命令。 2）调用&nbsp;Command&nbsp;并将日志输出至&nbsp;executor&nbsp;目录下的&nbsp;stdout&nbsp;和&nbsp;stderr&nbsp;日志文件中，Command&nbsp;对应的&nbsp;java&nbsp;类为&nbsp;CoarseGrainedExecutorBackend。 CoarseGrainedExecutorBackend 1）创建一个&nbsp;SparkEnv，创建&nbsp;ExecutorEndpoint(CoarseGrainedExecutorBackend)以及&nbsp;WorkerWatcher。 2）ExecutorEndpoint&nbsp;创建并启动后，向&nbsp;DriverEndpoint&nbsp;发送&nbsp;RegisterExecutor&nbsp;请求并等待返回。 3）DriverEndpoint&nbsp;处理&nbsp;RegisterExecutor&nbsp;请求，返回&nbsp;ExecutorEndpointRegister&nbsp;的结果。 4）如果注册成功，ExecutorEndpoint&nbsp;内部再创建&nbsp;Executor&nbsp;的处理对象。 至此，Spark&nbsp;运行任务的容器框架就搭建完成。 回到顶部 第9章 Job 提交和 Task 的拆分 在前面的章节 Client 的加载中，Spark 的 DriverRunner 已开始执行用户任务类（比如：org.apache.spark.examples.SparkPi），下面我们开始针对于用户任务类（或者任务代码）进行分析： 9.1 整体预览 详解如下： 1）Code：指的用户编写的代码 2）RDD：弹性分布式数据集，用户编码根据&nbsp;SparkContext&nbsp;与&nbsp;RDD&nbsp;的&nbsp;api&nbsp;能够很好的将&nbsp;Code&nbsp;转化为&nbsp;RDD&nbsp;数据结构(下文将做转化细节介绍)。 3）DAGScheduler：有向无环图调度器，将&nbsp;RDD&nbsp;封装为&nbsp;JobSubmitted&nbsp;对象存入&nbsp;EventLoop&nbsp;(实现类DAGSchedulerEventProcessLoop)&nbsp;队列中。 4）EventLoop：&nbsp;定时扫描未处理&nbsp;JobSubmitted&nbsp;对象，将&nbsp;JobSubmitted&nbsp;对象提交给&nbsp;DAGScheduler。 5）DAGScheduler：针对于&nbsp;JobSubmitted&nbsp;进行处理，最终将&nbsp;RDD&nbsp;转化为执行&nbsp;TaskSet，并将&nbsp;TaskSet&nbsp;提交至&nbsp;TaskScheduler。 6）TaskScheduler：&nbsp;根据&nbsp;TaskSet&nbsp;创建&nbsp;TaskSetManager&nbsp;对象存入&nbsp;SchedulableBuilder&nbsp;的数据池(Pool)中，并调用&nbsp;DriverEndpoint&nbsp;唤起消费(ReviveOffers)操作。 7）DriverEndpoint：接受&nbsp;ReviveOffers&nbsp;指令后将&nbsp;TaskSet&nbsp;中的&nbsp;Tasks&nbsp;根据相关规则均匀分配给Executor。 8）Executor：启动一个&nbsp;TaskRunner&nbsp;执行一个&nbsp;Task。 9.2 Code 转化为初始 RDDs 我们的用户代码通过调用 Spark 的 Api（比如：SparkSession.builder.appName(&quot;Spark Pi&quot;).getOrCreate()），该 Api 会创建 Spark 的上下文（SparkContext），当我们调用 transform 类方法（如：parallelize(),map()）都会创建（或者装饰已有的）Spark 数据结构（RDD），如果是 action 类操作（如：reduce()），那么将最后封装的 RDD 作为一次 Job 提交，存入待调度队列中（DAGSchedulerEventProcessLoop ）待后续异步处理。 如果多次调用 action 类操作，那么封装的多个 RDD 作为多个 Job 提交。 流程如下： 详解如下： ExecuteEnv（执行环境） 1）这里可以是通过&nbsp;spark-submit&nbsp;提交的&nbsp;MainClass，也可以是&nbsp;spark-shell&nbsp;脚本。 2）MainClass：代码中必定会创建或者获取一个&nbsp;SparkContext。 3）spark-shell：默认会创建一个&nbsp;SparkContext。 RDD（弹性分布式数据集） 1）create：可以直接创建（如：sc.parallelize(1&nbsp;until&nbsp;n,&nbsp;slices)&nbsp;），也可以在其他地方读取（如：sc.textFile(&quot;README.md&quot;)）等。 2）transformation：rdd&nbsp;提供了一组&nbsp;api&nbsp;可以进行对已有&nbsp;RDD&nbsp;进行反复封装成为新的&nbsp;RDD，这里采用的是`装饰者设计模式`，下面为部分装饰器类图。 3）action：当调用&nbsp;RDD&nbsp;的&nbsp;action&nbsp;类操作方法时（collect、reduce、lookup、save&nbsp;），这触发&nbsp;DAGScheduler&nbsp;的&nbsp;Job&nbsp;提交。 4）DAGScheduler：创建一个名为&nbsp;JobSubmitted&nbsp;的消息至&nbsp;DAGSchedulerEventProcessLoop&nbsp;阻塞消息队列（LinkedBlockingDeque）中。 5）DAGSchedulerEventProcessLoop：启动名为【dag-scheduler-event-loop】的线程实时消费消息队列。 6）【dag-scheduler-event-loop】处理完成后回调&nbsp;JobWaiter。 7）DAGScheduler：打印&nbsp;Job&nbsp;执行结果。 8）JobSubmitted：相关代码如下（其中&nbsp;jobId&nbsp;为&nbsp;DAGScheduler&nbsp;全局递增&nbsp;Id）。 &nbsp;&nbsp;&nbsp;&nbsp;eventProcessLoop.post(JobSubmitted( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobId,&nbsp;rdd,&nbsp;func2,&nbsp;partitions.toArray,&nbsp;callSite,&nbsp;waiter, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SerializationUtils.clone(properties))) 部分装饰器类图 最终示例： 最终转化的 RDD 分为四层，每层都依赖于上层 RDD，将 ShffleRDD 封装为一个 Job 存入 DAGSchedulerEventProcessLoop 待处理，如果我们的代码中存在几段上面示例代码，那么就会创建对应对的几个 ShffleRDD 分别存入 DAGSchedulerEventProcessLoop 中。 9.3 RDD 分解为待执行任务集合（TaskSet） Job 提交后，DAGScheduler 根据 RDD 层次关系解析为对应的 Stages，同时维护 Job 与 Stage 的关系。 将最上层的 Stage 根据并发关系（findMissingPartitions）分解为多个 Task，将这个多个 Task 封装为 TaskSet 提交给 TaskScheduler。非最上层的 Stage 的存入处理的列表中（waitingStages += stage） 流程如下： 详解如下： 1）DAGSchedulerEventProcessLoop中，线程【dag-scheduler-event-loop】处理到&nbsp;JobSubmitted 2）调用&nbsp;DAGScheduler&nbsp;进行&nbsp;handleJobSubmitted &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;首先根据&nbsp;RDD&nbsp;依赖关系依次创建&nbsp;Stage&nbsp;族，Stage&nbsp;分为&nbsp;ShuffleMapStage、ResultStage&nbsp;两类，如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;更新&nbsp;jobId&nbsp;与&nbsp;StageId&nbsp;关系&nbsp;Map &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;创建&nbsp;ActiveJob，调用&nbsp;LiveListenerBug，发送&nbsp;SparkListenerJobStart&nbsp;指令 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;找到最上层&nbsp;Stage&nbsp;进行提交，下层&nbsp;Stage&nbsp;存入&nbsp;waitingStage&nbsp;中待后续处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1)&nbsp;调用&nbsp;OutputCommitCoordinator&nbsp;进行&nbsp;stageStart()&nbsp;处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2)&nbsp;调用&nbsp;LiveListenerBug，发送&nbsp;SparkListenerStageSubmitted&nbsp;指令 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3)&nbsp;调用&nbsp;SparkContext的broadcast&nbsp;方法获取&nbsp;Broadcast&nbsp;对象，根据&nbsp;Stage&nbsp;类型创建对应多个&nbsp;Task，一个&nbsp;Stage&nbsp;根据&nbsp;findMissingPartitions&nbsp;分为多个对应的&nbsp;Task，Task&nbsp;分为&nbsp;ShuffleMapTask、ResultTask &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4)&nbsp;将&nbsp;Task&nbsp;封装为&nbsp;TaskSet，调用&nbsp;TaskScheduler.submitTasks(taskSet)&nbsp;进行&nbsp;Task&nbsp;调度，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskScheduler.submitTasks(new&nbsp;TaskSet( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tasks.toArray,&nbsp;stage.id,&nbsp;stage.latestInfo.attemptId,&nbsp;jobId,&nbsp;properties)) ShuffleMapStage、ResultStage 两类 9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver TaskScheduler 将 TaskSet 封装为 TaskSetManager(new TaskSetManager(this, taskSet, maxTaskFailures, blacklistTrackerOpt))，存入待处理任务池（Pool）中，发送 DriverEndpoint 唤起消费（ReviveOffers）指令。 详解如下： 1）DAGSheduler&nbsp;将&nbsp;TaskSet&nbsp;提交给&nbsp;TaskScheduler&nbsp;的实现类，这里是&nbsp;TaskChedulerImpl。 2）TaskSchedulerImpl&nbsp;创建一个&nbsp;TaskSetManager&nbsp;管理&nbsp;TaskSet，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;TaskSetManager(this,&nbsp;taskSet,&nbsp;maxTaskFailures,&nbsp;blacklistTrackerOpt) 3）同时将&nbsp;TaskSetManager&nbsp;添加&nbsp;SchedduableBuilder&nbsp;的任务池&nbsp;Poll&nbsp;中。 4）调用&nbsp;SchedulerBackend&nbsp;的实现类进行&nbsp;reviveOffers，这里是&nbsp;standlone&nbsp;模式的实现类&nbsp;StandaloneSchedulerBackend。 5）SchedulerBackend&nbsp;发送&nbsp;ReviveOffers&nbsp;指令至&nbsp;DriverEndpoint。 9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor Driver 接受唤起消费指令后，将所有待处理的 TaskSetManager 与 Driver 中注册的 Executor 资源进行匹配，最终一个 TaskSetManager 得到多个 TaskDescription 对象，按照 TaskDescription 相对应的 Executor 发送 LaunchTask 指令。 详解如下： 当&nbsp;Driver&nbsp;获取到&nbsp;ReviveOffers（请求消费）指令时 1）首先根据&nbsp;executorDataMap&nbsp;缓存信息得到可用的&nbsp;Executor&nbsp;资源信息（WorkerOffer），关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;activeExecutors&nbsp;=&nbsp;executorDataMap.filterKeys(executorIsAlive) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;workOffers&nbsp;=&nbsp;activeExecutors.map&nbsp;{&nbsp;case&nbsp;(id,&nbsp;executorData)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;WorkerOffer(id,&nbsp;executorData.executorHost,&nbsp;executorData.freeCores) &nbsp;&nbsp;&nbsp;&nbsp;}.toIndexedSeq 2）接着调用&nbsp;TaskScheduler&nbsp;进行资源匹配，方法定义如下： &nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;resourceOffers(offers:&nbsp;IndexedSeq[WorkerOffer]):&nbsp;Seq[Seq[TaskDescription]]&nbsp;=&nbsp;synchronized&nbsp;{..} &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;将&nbsp;WorkerOffer&nbsp;资源打乱，如：val&nbsp;shuffledOffers&nbsp;=&nbsp;Random.shuffle(offers) &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;Pool&nbsp;中待处理的&nbsp;TaskSetManager&nbsp;取出，如：val&nbsp;sortedTaskSets&nbsp;=&nbsp;rootPool.getSortedTaskSetQueue &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;并循环处理&nbsp;sortedTaskSets&nbsp;并与&nbsp;shuffledOffers&nbsp;循环匹配，如果&nbsp;shuffledOffers(i)&nbsp;有足够的&nbsp;CPU&nbsp;资源（&nbsp;if&nbsp;(availableCpus(i)&nbsp;&gt;=&nbsp;CPUS_PER_TASK)），调用&nbsp;TaskSetManager&nbsp;创建&nbsp;TaskDescription&nbsp;对象（taskSet.resourceOffer(execId,&nbsp;host,&nbsp;maxLocality)），最终创建了多个&nbsp;TaskDescription，TaskDescription&nbsp;定义如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;TaskDescription( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attemptNum, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;execId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskName, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;index, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sched.sc.addedFiles, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sched.sc.addedJars, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;task.localProperties, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serializedTask) 3）如果&nbsp;TaskDescriptions&nbsp;不为空，循环&nbsp;TaskDescriptions，序列化&nbsp;TaskDescription&nbsp;对象，并向&nbsp;ExecutorEndpoint&nbsp;发送&nbsp;LaunchTask&nbsp;指令，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(task&nbsp;&lt;-&nbsp;taskDescriptions.flatten)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;serializedTask&nbsp;=&nbsp;TaskDescription.encode(task) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;executorData&nbsp;=&nbsp;executorDataMap(task.executorId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorData.freeCores&nbsp;-=&nbsp;scheduler.CPUS_PER_TASK &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorData.executorEndpoint.send(LaunchTask(new&nbsp;SerializableBuffer(serializedTask))) &nbsp;&nbsp;&nbsp;&nbsp;} 回到顶部 第10章 Task 执行和回馈 DriverEndpoint 最终生成多个可执行的 TaskDescription 对象，并向各个 ExecutorEndpoint 发送 LaunchTask 指令，本节内容将关注 ExecutorEndpoint 如何处理 LaunchTask 指令，处理完成后如何回馈给 DriverEndpoint，以及整个 job 最终如何多次调度直至结束。 10.1 Task 的执行流程 Executor 接受 LaunchTask 指令后，开启一个新线程 TaskRunner 解析 RDD，并调用 RDD 的 compute 方法，归并函数得到最终任务执行结果。 详解如下： 1）ExecutorEndpoint&nbsp;接受到&nbsp;LaunchTask&nbsp;指令后，解码出&nbsp;TaskDescription，调用&nbsp;Executor&nbsp;的&nbsp;launchTask&nbsp;方法。 2）Executor&nbsp;创建一个&nbsp;TaskRunner&nbsp;线程，并启动线程，同时将改线程添加到&nbsp;Executor&nbsp;的成员对象中，代码如下： &nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;val&nbsp;runningTasks&nbsp;=&nbsp;new&nbsp;ConcurrentHashMap[Long,&nbsp;TaskRunner] &nbsp;&nbsp;&nbsp;&nbsp;runningTasks.put(taskDescription.taskId,&nbsp;taskRunner) TaskRunner 1）首先向&nbsp;DriverEndpoint&nbsp;发送任务最新状态为&nbsp;RUNNING。 2）从&nbsp;TaskDescription&nbsp;解析出&nbsp;Task，并调用&nbsp;Task&nbsp;的&nbsp;run&nbsp;方法。 Task 1）创建&nbsp;TaskContext&nbsp;以及&nbsp;CallerContext&nbsp;(与&nbsp;HDFS&nbsp;交互的上下文对象)。 2）执行&nbsp;Task&nbsp;的&nbsp;runTask&nbsp;方法： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;如果&nbsp;Task&nbsp;实例为&nbsp;ShuffleMapTask：解析出&nbsp;RDD&nbsp;以及&nbsp;ShuffleDependency&nbsp;信息，调用&nbsp;RDD&nbsp;的&nbsp;compute()&nbsp;方法将结果写&nbsp;Writer&nbsp;中（Writer&nbsp;这里不介绍，可以作为黑盒理解，比如写入一个文件中），返回&nbsp;MapStatus&nbsp;对象。 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;如果&nbsp;Task&nbsp;实例为&nbsp;ResultTask：解析出&nbsp;RDD&nbsp;以及合并函数信息，调用函数将调用后的结果返回。 TaskRunner&nbsp;将&nbsp;Task&nbsp;执行的结果序列化，再次向&nbsp;DriverEndpoint&nbsp;发送任务最新状态为&nbsp;FINISHED。 10.2 Task 的回馈流程 TaskRunner 执行结束后，都将执行状态发送至 DriverEndpoint，DriverEndpoint 最终反馈指令 CompletionEvent 发送至 DAGSchedulerEventProcessLoop 中。 详解如下： 1）DriverEndpoint&nbsp;接收到&nbsp;StatusUpdate&nbsp;消息后，调用&nbsp;TaskScheduler&nbsp;的&nbsp;statusUpdate(taskId,&nbsp;state,&nbsp;result)&nbsp;方法 2）TaskScheduler&nbsp;如果任务结果是完成，那么清除该任务处理中的状态，并调动&nbsp;TaskResultGetter&nbsp;相关方法，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;taskSet&nbsp;=&nbsp;taskIdToTaskSetManager.get(tid) &nbsp;&nbsp;&nbsp;&nbsp;taskIdToTaskSetManager.remove(tid) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskIdToExecutorId.remove(tid).foreach&nbsp;{&nbsp;executorId&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorIdToRunningTaskIds.get(executorId).foreach&nbsp;{&nbsp;_.remove(tid)&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;taskSet.removeRunningTask(tid) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(state&nbsp;==&nbsp;TaskState.FINISHED)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskResultGetter.enqueueSuccessfulTask(taskSet,&nbsp;tid,&nbsp;serializedData) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(Set(TaskState.FAILED,&nbsp;TaskState.KILLED,&nbsp;TaskState.LOST).contains(state))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskResultGetter.enqueueFailedTask(taskSet,&nbsp;tid,&nbsp;state,&nbsp;serializedData) &nbsp;&nbsp;&nbsp;&nbsp;} TaskResultGetter&nbsp;启动线程启动线程【task-result-getter】进行相关处理： 1）通过解析或者远程获取得到&nbsp;Task&nbsp;的&nbsp;TaskResult&nbsp;对象。 2）调用&nbsp;TaskSet&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法，TaskSet&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法直接调用&nbsp;TaskSetManager&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法。 TaskSetManager 1）更新内部&nbsp;TaskInfo&nbsp;对象状态，并将该&nbsp;Task&nbsp;从运行中&nbsp;Task&nbsp;的集合删除，代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;info&nbsp;=&nbsp;taskInfos(tid) &nbsp;&nbsp;&nbsp;&nbsp;info.markFinished(TaskState.FINISHED,&nbsp;clock.getTimeMillis()) &nbsp;&nbsp;&nbsp;&nbsp;removeRunningTask(tid) 2）调用&nbsp;DAGScheduler&nbsp;的&nbsp;taskEnded&nbsp;方法，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;sched.dagScheduler.taskEnded(tasks(index),&nbsp;Success,&nbsp;result.value(),&nbsp;result.accumUpdates,&nbsp;info) DAGScheduler&nbsp;向&nbsp;DAGSchedulerEventProcessLoop&nbsp;存入&nbsp;CompletionEvent&nbsp;指令，CompletionEvent&nbsp;对象定义如下： &nbsp;&nbsp;&nbsp;&nbsp;private[scheduler]&nbsp;case&nbsp;class&nbsp;CompletionEvent( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;task:&nbsp;Task[_], &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reason:&nbsp;TaskEndReason, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result:&nbsp;Any, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accumUpdates:&nbsp;Seq[AccumulatorV2[_,&nbsp;_]], &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskInfo:&nbsp;TaskInfo)&nbsp;extends&nbsp;DAGSchedulerEvent 10.3 Task 的迭代流程 DAGSchedulerEventProcessLoop 中针对于 CompletionEvent 指令，调用 DAGScheduler 进行处理，DAGScheduler 更新 Stage 与该 Task 的关系状态，如果 Stage 下 Task 都返回，则做下一层 Stage 的任务拆解与运算工作，直至 Job 被执行完毕： 详解如下： 1）DAGSchedulerEventProcessLoop&nbsp;接收到&nbsp;CompletionEvent&nbsp;指令后，调用&nbsp;DAGScheduler&nbsp;的&nbsp;handleTaskCompletion&nbsp;方法。 2）DAGScheduler&nbsp;根据&nbsp;Task&nbsp;的类型分别处理。 3）如果&nbsp;Task&nbsp;为&nbsp;ShuffleMapTask &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;等待回馈的&nbsp;Partitions&nbsp;减去当前&nbsp;partitionId &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;如果所有&nbsp;task&nbsp;都返回，则&nbsp;markStageAsFinished(shuffleStage)，同时向&nbsp;MapOutputTrackerMaster&nbsp;注册&nbsp;MapOutputs&nbsp;信息，且&nbsp;markMapStageJobAsFinished &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;调用&nbsp;submitWaitingChildStages(shuffleStage)&nbsp;进行下层&nbsp;Stages&nbsp;的处理，从而迭代处理，最终处理到&nbsp;ResultTask，job&nbsp;结束，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;private&nbsp;def&nbsp;submitWaitingChildStages(parent:&nbsp;Stage)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;childStages&nbsp;=&nbsp;waitingStages.filter(_.parents.contains(parent)).toArray &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingStages&nbsp;--=&nbsp;childStages &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(stage&nbsp;&lt;-&nbsp;childStages.sortBy(_.firstJobId))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;submitStage(stage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} 4）如果&nbsp;Task&nbsp;为&nbsp;ResultTask &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;该&nbsp;job&nbsp;的&nbsp;partitions&nbsp;都已返回，则&nbsp;markStageAsFinished(resultStage)，并&nbsp;cleanupStateForJobAndIndependentStages(job)，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;(stage&nbsp;&lt;-&nbsp;stageIdToStage.get(stageId))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(runningStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;running&nbsp;stage&nbsp;%d&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;((k,&nbsp;v)&nbsp;&lt;-&nbsp;shuffleIdToMapStage.find(_._2&nbsp;==&nbsp;stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shuffleIdToMapStage.remove(k) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(waitingStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;stage&nbsp;%d&nbsp;from&nbsp;waiting&nbsp;set.&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(failedStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Removing&nbsp;stage&nbsp;%d&nbsp;from&nbsp;failed&nbsp;set.&quot;.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;failedStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;data&nbsp;structures&nbsp;based&nbsp;on&nbsp;StageId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stageIdToStage&nbsp;-=&nbsp;stageId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobIdToStageIds&nbsp;-=&nbsp;job.jobId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobIdToActiveJob&nbsp;-=&nbsp;job.jobId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeJobs&nbsp;-=&nbsp;job 至此，用户编写的代码最终调用&nbsp;Spark&nbsp;分布式计算完毕。 10.4 精彩图解 Spark的交互流程 – 节点启动 Spark的交互流程 – 应用提交 Spark的交互流程 – 任务运行 Spark的交互流程 – 任务运行 回到顶部 第11章 Spark 的数据存储 Spark 计算速度远胜于 Hadoop 的原因之一就在于中间结果是缓存在内存而不是直接写入到 disk，本文尝试分析 Spark 中存储子系统的构成，并以数据写入和数据读取为例，讲述清楚存储子系统中各部件的交互关系。 11.1 存储子系统概览 Storage 模块主要分为两层：   1) 通信层：storage 模块采用的是 master-slave 结构来实现通信层，master 和 slave 之间传输控制信息、状态信息，这些都是通过通信层来实现的。   2) 存储层：storage 模块需要把数据存储到 disk 或是 memory 上面，有可能还需 replicate(复制) 到远端，这都是由存储层来实现和提供相应接口。 而其他模块若要和 storage 模块进行交互，storage 模块提供了统一的操作类 BlockManager，外部类与 storage 模块打交道都需要通过调用 BlockManager 相应接口来实现。 上图是Spark存储子系统中几个主要模块的关系示意图，现简要说明如下： 1）CacheManager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RDD&nbsp;在进行计算的时候，通过&nbsp;CacheManager&nbsp;来获取数据，并通过&nbsp;CacheManager&nbsp;来存储计算结果。 2）BlockManager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CacheManager&nbsp;在进行数据读取和存取的时候主要是依赖&nbsp;BlockManager&nbsp;接口来操作，BlockManager&nbsp;决定数据是从内存(MemoryStore)&nbsp;还是从磁盘(DiskStore)&nbsp;中获取。 3）MemoryStore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;负责将数据保存在内存或从内存读取。 4）DiskStore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;负责将数据写入磁盘或从磁盘读入。 5）BlockManagerWorker&nbsp;&nbsp;&nbsp;数据写入本地的&nbsp;MemoryStore&nbsp;或&nbsp;DiskStore&nbsp;是一个同步操作，为了容错还需要将数据复制到别的计算结点，以防止数据丢失的时候还能够恢复，数据复制的操作是异步完成，由&nbsp;BlockManagerWorker&nbsp;来处理这一部分事情。 6）ConnectionManager&nbsp;&nbsp;&nbsp;&nbsp;负责与其它计算结点建立连接，并负责数据的发送和接收。 7）BlockManagerMaster&nbsp;&nbsp;&nbsp;注意该模块只运行在&nbsp;Driver&nbsp;Application&nbsp;所在的&nbsp;Executor，功能是负责记录下所有&nbsp;BlockIds&nbsp;存储在哪个&nbsp;SlaveWorker&nbsp;上，比如&nbsp;RDD&nbsp;Task&nbsp;运行在机器&nbsp;A，所需要的&nbsp;BlockId&nbsp;为&nbsp;3，但在机器&nbsp;A&nbsp;上没有&nbsp;BlockId&nbsp;为&nbsp;3&nbsp;的数值，这个时候&nbsp;Slave&nbsp;worker&nbsp;需要通过&nbsp;BlockManager&nbsp;向&nbsp;BlockManagerMaster&nbsp;询问数据存储的位置，然后再通过&nbsp;ConnectionManager&nbsp;去获取。 11.2 启动过程分析 上述的各个模块由 SparkEnv 来创建，创建过程在 SparkEnv.create 中完成，代码如下： val&nbsp;blockManagerMaster&nbsp;=&nbsp;new&nbsp;BlockManagerMaster(registerOrLookup( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;BlockManagerMaster&quot;, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;BlockManagerMasterActor(isLocal,&nbsp;conf)),&nbsp;conf) val&nbsp;blockManager&nbsp;=&nbsp;new&nbsp;BlockManager(executorId,&nbsp;actorSystem,&nbsp;blockManagerMaster,&nbsp;serializer,&nbsp;conf) val&nbsp;connectionManager&nbsp;=&nbsp;blockManager.connectionManager val&nbsp;broadcastManager&nbsp;=&nbsp;new&nbsp;BroadcastManager(isDriver,&nbsp;conf) val&nbsp;cacheManager&nbsp;=&nbsp;new&nbsp;CacheManager(blockManager) 下面这段代码容易让人疑惑，看起来像是在所有的 cluster node 上都创建了 BlockManagerMasterActor，其实不然，仔细看 registerOrLookup 函数的实现。如果当前节点是 driver 则创建这个 actor，否则建立到 driver 的连接。代码如下： def&nbsp;registerOrLookup(name:&nbsp;String,&nbsp;newActor:&nbsp;=&gt;&nbsp;Actor):&nbsp;ActorRef&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;&quot;&nbsp;+&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;actorSystem.actorOf(Props(newActor),&nbsp;name&nbsp;=&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;driverHost:&nbsp;String&nbsp;=&nbsp;conf.get(&quot;spark.driver.host&quot;,&nbsp;&quot;localhost&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;driverPort:&nbsp;Int&nbsp;=&nbsp;conf.getInt(&quot;spark.driver.port&quot;,&nbsp;7077) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Utils.checkHost(driverHost,&nbsp;&quot;Expected&nbsp;hostname&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;url&nbsp;=&nbsp;s&quot;akka.tcp://spark@$driverHost:$driverPort/user/$name&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;timeout&nbsp;=&nbsp;AkkaUtils.lookupTimeout(conf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(s&quot;Connecting&nbsp;to&nbsp;$name:&nbsp;$url&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Await.result(actorSystem.actorSelection(url).resolveOne(timeout),&nbsp;timeout) &nbsp;&nbsp;&nbsp;&nbsp;} } 初始化过程中一个主要的动作就是 BlockManager 需要向 BlockManagerMaster 发起注册。 11.3 通信层 BlockManager 包装了 BlockManagerMaster，发送信息包装成 BlockManagerInfo。Spark 在 Driver 和 Worker 端都创建各自的 BlockManager，并通过 BlockManagerMaster 进行通信，通过 BlockManager 对 Storage 模块进行操作。 BlockManager 对象在 SparkEnv.create 函数中进行创建，代码如下： def&nbsp;registerOrLookupEndpoint( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;String,&nbsp;endpointCreator:&nbsp;=&gt;&nbsp;RpcEndpoint): RpcEndpointRef&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;&quot;&nbsp;+&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rpcEnv.setupEndpoint(name,&nbsp;endpointCreator) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RpcUtils.makeDriverRef(name,&nbsp;conf,&nbsp;rpcEnv) &nbsp;&nbsp;&nbsp;&nbsp;} } ...... val&nbsp;blockManagerMaster&nbsp;=&nbsp;new&nbsp;BlockManagerMaster(registerOrLookupEndpoint( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockManagerMaster.DRIVER_ENDPOINT_NAME, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;BlockManagerMasterEndpoint(rpcEnv,&nbsp;isLocal,&nbsp;conf,&nbsp;listenerBus)), &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;conf,&nbsp;isDriver) //&nbsp;NB:&nbsp;blockManager&nbsp;is&nbsp;not&nbsp;valid&nbsp;until&nbsp;initialize()&nbsp;is&nbsp;called&nbsp;later. val&nbsp;blockManager&nbsp;=&nbsp;new&nbsp;BlockManager(executorId,&nbsp;rpcEnv,&nbsp;blockManagerMaster, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serializer,&nbsp;conf,&nbsp;mapOutputTracker,&nbsp;shuffleManager,&nbsp;blockTransferService,&nbsp;securityManager,numUsableCores) 并且在创建之前对当前节点是否是 Driver 进行了判断。如果是，则创建这个 Endpoint；否则，创建 Driver 的连接。 在创建 BlockManager 之后，BlockManager 会调用 initialize 方法初始化自己。并且初始化的时候，会调用 BlockManagerMaster 向 Driver 注册自己，同时，在注册时也启动了Slave Endpoint。另外，向本地 shuffle 服务器注册 Executor 配置，如果存在的话。代码如下： def&nbsp;initialize(appId:&nbsp;String):&nbsp;Unit&nbsp;=&nbsp;{ ...... &nbsp;&nbsp;&nbsp;&nbsp;master.registerBlockManager(blockManagerId,&nbsp;maxMemory,&nbsp;slaveEndpoint) &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Register&nbsp;Executors&#39;&nbsp;configuration&nbsp;with&nbsp;the&nbsp;local&nbsp;shuffle&nbsp;service,&nbsp;if&nbsp;one&nbsp;should&nbsp;exist. &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(externalShuffleServiceEnabled&nbsp;&amp;&amp;&nbsp;!blockManagerId.isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;registerWithExternalShuffleServer() &nbsp;&nbsp;&nbsp;&nbsp;} } 而 BlockManagerMaster 将注册请求包装成 RegisterBlockManager 注册到 Driver。Driver 的 BlockManagerMasterEndpoint 会调用 register 方法，通过对消息 BlockManagerInfo 检查，向 Driver 注册，代码如下： private&nbsp;def&nbsp;register(id:&nbsp;BlockManagerId,&nbsp;maxMemSize:&nbsp;Long,&nbsp;slaveEndpoint:&nbsp;RpcEndpointRef)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;time&nbsp;=&nbsp;System.currentTimeMillis() &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!blockManagerInfo.contains(id))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerIdByExecutor.get(id.executorId)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(oldId)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;A&nbsp;block&nbsp;manager&nbsp;of&nbsp;the&nbsp;same&nbsp;executor&nbsp;already&nbsp;exists,&nbsp;so&nbsp;remove&nbsp;it&nbsp;(assumed&nbsp;dead) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logError(&quot;Got&nbsp;two&nbsp;different&nbsp;block&nbsp;manager&nbsp;registrations&nbsp;on&nbsp;same&nbsp;executor&nbsp;-&nbsp;&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;s&quot;&nbsp;will&nbsp;replace&nbsp;old&nbsp;one&nbsp;$oldId&nbsp;with&nbsp;new&nbsp;one&nbsp;$id&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;removeExecutor(id.executorId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Registering&nbsp;block&nbsp;manager&nbsp;%s&nbsp;with&nbsp;%s&nbsp;RAM,&nbsp;%s&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id.hostPort,&nbsp;Utils.bytesToString(maxMemSize),&nbsp;id)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerIdByExecutor(id.executorId)&nbsp;=&nbsp;id &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerInfo(id)&nbsp;=&nbsp;new&nbsp;BlockManagerInfo( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id,&nbsp;System.currentTimeMillis(),&nbsp;maxMemSize,&nbsp;slaveEndpoint) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;listenerBus.post(SparkListenerBlockManagerAdded(time,&nbsp;id,&nbsp;maxMemSize)) } 不难发现 BlockManagerInfo 对象被保存到 Map 映射中。在通信层中 BlockManagerMaster 控制着消息的流向，这里采用了模式匹配，所有的消息模式都在 BlockManagerMessage 中。 11.4 存储层 Spark Storage 的最小存储单位是 block，所有的操作都是以 block 为单位进行的。 在 BlockManager 被创建的时候 MemoryStore 和 DiskStore 对象就被创建出来了。代码如下： val&nbsp;diskBlockManager&nbsp;=&nbsp;new&nbsp;DiskBlockManager(this,&nbsp;conf) private[spark]&nbsp;val&nbsp;memoryStore&nbsp;=&nbsp;new&nbsp;MemoryStore(this,&nbsp;maxMemory) private[spark]&nbsp;val&nbsp;diskStore&nbsp;=&nbsp;new&nbsp;DiskStore(this,&nbsp;diskBlockManager) 11.4.1 Disk Store 由于当前的 Spark 版本对 Disk Store 进行了更细粒度的分工，把对文件的操作提取出来放到了 DiskBlockManager 中，DiskStore 仅仅负责数据的存储和读取。 Disk Store 会配置多个文件目录，Spark 会在不同的文件目录下创建文件夹，其中文件夹的命名方式是：spark-UUID（随机UUID码）。Disk Store 在存储的时候创建文件夹。并且根据【高内聚，低耦合】原则，这种服务型的工具代码就放到了 Utils 中（调用路径：DiskStore.putBytes —&gt; DiskBlockManager.createLocalDirs —&gt; Utils.createDirectory），代码如下： def&nbsp;createDirectory(root:&nbsp;String,&nbsp;namePrefix:&nbsp;String&nbsp;=&nbsp;&quot;spark&quot;):&nbsp;File&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;attempts&nbsp;=&nbsp;0 &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;maxAttempts&nbsp;=&nbsp;MAX_DIR_CREATION_ATTEMPTS &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;dir:&nbsp;File&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(dir&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attempts&nbsp;+=&nbsp;1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(attempts&nbsp;&gt;&nbsp;maxAttempts)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Failed&nbsp;to&nbsp;create&nbsp;a&nbsp;temp&nbsp;directory&nbsp;(under&nbsp;&quot;&nbsp;+&nbsp;root&nbsp;+&nbsp;&quot;)&nbsp;after&nbsp;&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;maxAttempts&nbsp;+&nbsp;&quot;&nbsp;attempts!&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dir&nbsp;=&nbsp;new&nbsp;File(root,&nbsp;namePrefix&nbsp;+&nbsp;&quot;-&quot;&nbsp;+&nbsp;UUID.randomUUID.toString) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(dir.exists()&nbsp;||&nbsp;!dir.mkdirs())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dir&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;catch&nbsp;{&nbsp;case&nbsp;e:&nbsp;SecurityException&nbsp;=&gt;&nbsp;dir&nbsp;=&nbsp;null;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;dir.getCanonicalFile } 在 DiskBlockManager 里，每个 block 都被存储为一个 file，通过计算 blockId 的 hash 值，将 block 映射到文件中。 def&nbsp;getFile(filename:&nbsp;String):&nbsp;File&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Figure&nbsp;out&nbsp;which&nbsp;local&nbsp;directory&nbsp;it&nbsp;hashes&nbsp;to,&nbsp;and&nbsp;which&nbsp;subdirectory&nbsp;in&nbsp;that &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;hash&nbsp;=&nbsp;Utils.nonNegativeHash(filename) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;dirId&nbsp;=&nbsp;hash&nbsp;%&nbsp;localDirs.length &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;subDirId&nbsp;=&nbsp;(hash&nbsp;/&nbsp;localDirs.length)&nbsp;%&nbsp;subDirsPerLocalDir &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;the&nbsp;subdirectory&nbsp;if&nbsp;it&nbsp;doesn&#39;t&nbsp;already&nbsp;exist &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;subDir&nbsp;=&nbsp;subDirs(dirId).synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;old&nbsp;=&nbsp;subDirs(dirId)(subDirId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(old&nbsp;!=&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;old &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;newDir&nbsp;=&nbsp;new&nbsp;File(localDirs(dirId),&nbsp;&quot;%02x&quot;.format(subDirId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!newDir.exists()&nbsp;&amp;&amp;&nbsp;!newDir.mkdir())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(s&quot;Failed&nbsp;to&nbsp;create&nbsp;local&nbsp;dir&nbsp;in&nbsp;$newDir.&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;subDirs(dirId)(subDirId)&nbsp;=&nbsp;newDir &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;newDir &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;File(subDir,&nbsp;filename) } def&nbsp;getFile(blockId:&nbsp;BlockId):&nbsp;File&nbsp;=&nbsp;getFile(blockId.name) 通过 hash 值的取模运算，求出 dirId 和 subDirId。然后，在从 subDirs 中找到 subDir，如果 subDir 不存在，则创建一个新 subDir。最后，以 subDir 为路径，blockId 的 name 属性为文件名，新建该文件。 文件创建完之后，那么 Spark 就会在 DiskStore 中向文件写与之映射的 block，代码如下： override&nbsp;def&nbsp;putBytes(blockId:&nbsp;BlockId,&nbsp;_bytes:&nbsp;ByteBuffer,&nbsp;level:&nbsp;StorageLevel):&nbsp;PutResult&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bytes&nbsp;=&nbsp;_bytes.duplicate() &nbsp;&nbsp;&nbsp;&nbsp;logDebug(s&quot;Attempting&nbsp;to&nbsp;put&nbsp;block&nbsp;$blockId&quot;) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;startTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;file&nbsp;=&nbsp;diskManager.getFile(blockId) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;channel&nbsp;=&nbsp;new&nbsp;FileOutputStream(file).getChannel &nbsp;&nbsp;&nbsp;&nbsp;Utils.tryWithSafeFinally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(bytes.remaining&nbsp;&gt;&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.write(bytes) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.close() &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;finishTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Block&nbsp;%s&nbsp;stored&nbsp;as&nbsp;%s&nbsp;file&nbsp;on&nbsp;disk&nbsp;in&nbsp;%d&nbsp;ms&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file.getName,&nbsp;Utils.bytesToString(bytes.limit),&nbsp;finishTime&nbsp;-&nbsp;startTime)) &nbsp;&nbsp;&nbsp;&nbsp;PutResult(bytes.limit(),&nbsp;Right(bytes.duplicate())) } 读取过程就简单了，DiskStore 根据 blockId 读取与之映射的 file 内容，当然，这中间需要从 DiskBlockManager 中得到文件信息。代码如下： private&nbsp;def&nbsp;getBytes(file:&nbsp;File,&nbsp;offset:&nbsp;Long,&nbsp;length:&nbsp;Long):&nbsp;Option[ByteBuffer]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;channel&nbsp;=&nbsp;new&nbsp;RandomAccessFile(file,&nbsp;&quot;r&quot;).getChannel &nbsp;&nbsp;&nbsp;&nbsp;Utils.tryWithSafeFinally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;For&nbsp;small&nbsp;files,&nbsp;directly&nbsp;read&nbsp;rather&nbsp;than&nbsp;memory&nbsp;map &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(length&nbsp;&lt;&nbsp;minMemoryMapBytes)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;buf&nbsp;=&nbsp;ByteBuffer.allocate(length.toInt) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.position(offset) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(buf.remaining()&nbsp;!=&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(channel.read(buf)&nbsp;==&nbsp;-1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Reached&nbsp;EOF&nbsp;before&nbsp;filling&nbsp;buffer\\n&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s&quot;offset=$offset\\nfile=${file.getAbsolutePath}\\nbuf.remaining=${buf.remaining}&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buf.flip() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(buf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(channel.map(MapMode.READ_ONLY,&nbsp;offset,&nbsp;length)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.close() &nbsp;&nbsp;&nbsp;&nbsp;} } override&nbsp;def&nbsp;getBytes(blockId:&nbsp;BlockId):&nbsp;Option[ByteBuffer]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;file&nbsp;=&nbsp;diskManager.getFile(blockId.name) &nbsp;&nbsp;&nbsp;&nbsp;getBytes(file,&nbsp;0,&nbsp;file.length) } 11.4.2 Memory Store 相对 Disk Store，Memory Store 就显得容易很多。Memory Store 用一个 LinkedHashMap 来管理，其中 Key 是 blockId，Value 是 MemoryEntry 样例类，MemoryEntry 存储着数据信息。代码如下： private&nbsp;case&nbsp;class&nbsp;MemoryEntry(value:&nbsp;Any,&nbsp;size:&nbsp;Long,&nbsp;deserialized:&nbsp;Boolean) private&nbsp;val&nbsp;entries&nbsp;=&nbsp;new&nbsp;LinkedHashMap[BlockId,&nbsp;MemoryEntry](32,&nbsp;0.75f,&nbsp;true) 在 MemoryStore 中存储 block 的前提是当前内存有足够的空间存放。通过对 tryToPut 函数的调用对内存空间进行判断。代码如下： def&nbsp;putBytes(blockId:&nbsp;BlockId,&nbsp;size:&nbsp;Long,&nbsp;_bytes:&nbsp;()&nbsp;=&gt;&nbsp;ByteBuffer):&nbsp;PutResult&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Work&nbsp;on&nbsp;a&nbsp;duplicate&nbsp;-&nbsp;since&nbsp;the&nbsp;original&nbsp;input&nbsp;might&nbsp;be&nbsp;used&nbsp;elsewhere. &nbsp;&nbsp;&nbsp;&nbsp;lazy&nbsp;val&nbsp;bytes&nbsp;=&nbsp;_bytes().duplicate().rewind().asInstanceOf[ByteBuffer] &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putAttempt&nbsp;=&nbsp;tryToPut(blockId,&nbsp;()&nbsp;=&gt;&nbsp;bytes,&nbsp;size,&nbsp;deserialized&nbsp;=&nbsp;false) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;data&nbsp;= &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putAttempt.success)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(bytes.limit&nbsp;==&nbsp;size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right(bytes.duplicate()) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;PutResult(size,&nbsp;data,&nbsp;putAttempt.droppedBlocks) } 在 tryToPut 函数中，通过调用 enoughFreeSpace 函数判断内存空间。如果内存空间足够，那么就把 block 放到 LinkedHashMap 中；如果内存不足，那么就告诉 BlockManager 内存不足，如果允许 Disk Store，那么就把该 block 放到 disk 上。代码如下： private&nbsp;def&nbsp;tryToPut(blockId:&nbsp;BlockId,&nbsp;value:&nbsp;()&nbsp;=&gt;&nbsp;Any,&nbsp;size:&nbsp;Long,&nbsp;deserialized:&nbsp;Boolean):&nbsp;ResultWithDroppedBlocks&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;putSuccess&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;droppedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;accountingLock.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;freeSpaceResult&nbsp;=&nbsp;ensureFreeSpace(blockId,&nbsp;size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;enoughFreeSpace&nbsp;=&nbsp;freeSpaceResult.success &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;droppedBlocks&nbsp;++=&nbsp;freeSpaceResult.droppedBlocks &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(enoughFreeSpace)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;entry&nbsp;=&nbsp;new&nbsp;MemoryEntry(value(),&nbsp;size,&nbsp;deserialized) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.put(blockId,&nbsp;entry) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;currentMemory&nbsp;+=&nbsp;size &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;valuesOrBytes&nbsp;=&nbsp;if&nbsp;(deserialized)&nbsp;&quot;values&quot;&nbsp;else&nbsp;&quot;bytes&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Block&nbsp;%s&nbsp;stored&nbsp;as&nbsp;%s&nbsp;in&nbsp;memory&nbsp;(estimated&nbsp;size&nbsp;%s,&nbsp;free&nbsp;%s)&quot;.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId,&nbsp;valuesOrBytes,&nbsp;Utils.bytesToString(size),&nbsp;Utils.bytesToString(freeMemory))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putSuccess&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lazy&nbsp;val&nbsp;data&nbsp;=&nbsp;if&nbsp;(deserialized)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Left(value().asInstanceOf[Array[Any]]) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right(value().asInstanceOf[ByteBuffer].duplicate()) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;droppedBlockStatus&nbsp;=&nbsp;blockManager.dropFromMemory(blockId,&nbsp;()&nbsp;=&gt;&nbsp;data) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;droppedBlockStatus.foreach&nbsp;{&nbsp;status&nbsp;=&gt;&nbsp;droppedBlocks&nbsp;+=&nbsp;((blockId,&nbsp;status))&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;releasePendingUnrollMemoryForThisTask() &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;ResultWithDroppedBlocks(putSuccess,&nbsp;droppedBlocks) } Memory Store 读取 block 也很简单，只需要从 LinkedHashMap 中取出 blockId 的 Value 即可。代码如下： override&nbsp;def&nbsp;getValues(blockId:&nbsp;BlockId):&nbsp;Option[Iterator[Any]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;entry&nbsp;=&nbsp;entries.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.get(blockId) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(entry&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;None &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(entry.deserialized)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(entry.value.asInstanceOf[Array[Any]].iterator) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;buffer&nbsp;=&nbsp;entry.value.asInstanceOf[ByteBuffer].duplicate()&nbsp;//&nbsp;Doesn&#39;t&nbsp;actually&nbsp;copy&nbsp;data &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(blockManager.dataDeserialize(blockId,&nbsp;buffer)) &nbsp;&nbsp;&nbsp;&nbsp;} } 11.5 数据写入过程分析 数据写入的简要流程： 1）RDD.iterator&nbsp;是与&nbsp;storage&nbsp;子系统交互的入口。 2）CacheManager.getOrCompute&nbsp;调用&nbsp;BlockManager&nbsp;的&nbsp;put&nbsp;接口来写入数据。 3）数据优先写入到&nbsp;MemoryStore&nbsp;即内存，如果&nbsp;MemoryStore&nbsp;中的数据已满则将最近使用次数不频繁的数据写入到磁盘。 4）通知&nbsp;BlockManagerMaster&nbsp;有新的数据写入，在&nbsp;BlockManagerMaster&nbsp;中保存元数据。 5）将写入的数据与其它&nbsp;slave&nbsp;worker&nbsp;进行同步，一般来说在本机写入的数据，都会另先一台机器来进行数据的备份，即&nbsp;replicanumber=1。 其实，我们在&nbsp;put&nbsp;和&nbsp;get&nbsp;block&nbsp;的时候并没有那么复杂，前面的细节&nbsp;BlockManager&nbsp;都包装好了，我们只需要调用&nbsp;BlockManager&nbsp;中的&nbsp;put&nbsp;和&nbsp;get&nbsp;函数即可。 代码如下： def&nbsp;putBytes( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId:&nbsp;BlockId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes:&nbsp;ByteBuffer, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level:&nbsp;StorageLevel, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tellMaster:&nbsp;Boolean&nbsp;=&nbsp;true, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel:&nbsp;Option[StorageLevel]&nbsp;=&nbsp;None):&nbsp;Seq[(BlockId,&nbsp;BlockStatus)]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(bytes&nbsp;!=&nbsp;null,&nbsp;&quot;Bytes&nbsp;is&nbsp;null&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;doPut(blockId,&nbsp;ByteBufferValues(bytes),&nbsp;level,&nbsp;tellMaster,&nbsp;effectiveStorageLevel) &nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;private&nbsp;def&nbsp;doPut( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId:&nbsp;BlockId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data:&nbsp;BlockValues, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level:&nbsp;StorageLevel, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tellMaster:&nbsp;Boolean&nbsp;=&nbsp;true, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel:&nbsp;Option[StorageLevel]&nbsp;=&nbsp;None) :&nbsp;Seq[(BlockId,&nbsp;BlockStatus)]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(blockId&nbsp;!=&nbsp;null,&nbsp;&quot;BlockId&nbsp;is&nbsp;null&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(level&nbsp;!=&nbsp;null&nbsp;&amp;&amp;&nbsp;level.isValid,&nbsp;&quot;StorageLevel&nbsp;is&nbsp;null&nbsp;or&nbsp;invalid&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel.foreach&nbsp;{&nbsp;level&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(level&nbsp;!=&nbsp;null&nbsp;&amp;&amp;&nbsp;level.isValid,&nbsp;&quot;Effective&nbsp;StorageLevel&nbsp;is&nbsp;null&nbsp;or&nbsp;invalid&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;updatedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putBlockInfo&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;tinfo&nbsp;=&nbsp;new&nbsp;BlockInfo(level,&nbsp;tellMaster) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;oldBlockOpt&nbsp;=&nbsp;blockInfo.putIfAbsent(blockId,&nbsp;tinfo) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(oldBlockOpt.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(oldBlockOpt.get.waitForReady())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logWarning(s&quot;Block&nbsp;$blockId&nbsp;already&nbsp;exists&nbsp;on&nbsp;this&nbsp;machine;&nbsp;not&nbsp;re-adding&nbsp;it&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;updatedBlocks &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;oldBlockOpt.get &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tinfo &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} } &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;startTimeMs&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;valuesAfterPut:&nbsp;Iterator[Any]&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;bytesAfterPut:&nbsp;ByteBuffer&nbsp;=&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;size&nbsp;=&nbsp;0L &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putLevel&nbsp;=&nbsp;effectiveStorageLevel.getOrElse(level) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;replicationFuture&nbsp;=&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;b:&nbsp;ByteBufferValues&nbsp;if&nbsp;putLevel.replication&nbsp;&gt;&nbsp;1&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Duplicate&nbsp;doesn&#39;t&nbsp;copy&nbsp;the&nbsp;bytes,&nbsp;but&nbsp;just&nbsp;creates&nbsp;a&nbsp;wrapper &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bufferView&nbsp;=&nbsp;b.buffer.duplicate() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Future&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replicate(blockId,&nbsp;bufferView,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}(futureExecutionContext) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logTrace(&quot;Put&nbsp;for&nbsp;block&nbsp;%s&nbsp;took&nbsp;%s&nbsp;to&nbsp;get&nbsp;into&nbsp;synchronized&nbsp;block&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;marked&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;(returnValues,&nbsp;blockStore:&nbsp;BlockStore)&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.useMemory)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(true,&nbsp;memoryStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(putLevel.useOffHeap)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(false,&nbsp;externalBlockStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;if&nbsp;(putLevel.useDisk)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1,&nbsp;diskStore) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;assert(putLevel&nbsp;==&nbsp;StorageLevel.NONE) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;BlockException( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId,&nbsp;s&quot;Attempted&nbsp;to&nbsp;put&nbsp;block&nbsp;$blockId&nbsp;without&nbsp;specifying&nbsp;storage&nbsp;level!&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;result&nbsp;=&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;IteratorValues(iterator)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putIterator(blockId,&nbsp;iterator,&nbsp;putLevel,&nbsp;returnValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ArrayValues(array)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putArray(blockId,&nbsp;array,&nbsp;putLevel,&nbsp;returnValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ByteBufferValues(bytes)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes.rewind() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putBytes(blockId,&nbsp;bytes,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size&nbsp;=&nbsp;result.size &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result.data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Left&nbsp;(newIterator)&nbsp;if&nbsp;putLevel.useMemory&nbsp;=&gt;&nbsp;valuesAfterPut&nbsp;=&nbsp;newIterator &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Right&nbsp;(newBytes)&nbsp;=&gt;&nbsp;bytesAfterPut&nbsp;=&nbsp;newBytes &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.useMemory)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result.droppedBlocks.foreach&nbsp;{&nbsp;updatedBlocks&nbsp;+=&nbsp;_&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putBlockStatus&nbsp;=&nbsp;getCurrentBlockStatus(blockId,&nbsp;putBlockInfo) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putBlockStatus.storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;marked&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.markReady(size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(tellMaster)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reportBlockStatus(blockId,&nbsp;putBlockInfo,&nbsp;putBlockStatus) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updatedBlocks&nbsp;+=&nbsp;((blockId,&nbsp;putBlockStatus)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!marked)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockInfo.remove(blockId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.markFailure() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logWarning(s&quot;Putting&nbsp;block&nbsp;$blockId&nbsp;failed&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Put&nbsp;block&nbsp;%s&nbsp;locally&nbsp;took&nbsp;%s&quot;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;ByteBufferValues(bytes)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(replicationFuture&nbsp;!=&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Await.ready(replicationFuture,&nbsp;Duration.Inf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;remoteStartTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(bytesAfterPut&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(valuesAfterPut&nbsp;==&nbsp;null)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;SparkException( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&quot;Underlying&nbsp;put&nbsp;returned&nbsp;neither&nbsp;an&nbsp;Iterator&nbsp;nor&nbsp;bytes!&nbsp;This&nbsp;shouldn&#39;t&nbsp;happen.&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytesAfterPut&nbsp;=&nbsp;dataSerialize(blockId,&nbsp;valuesAfterPut) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replicate(blockId,&nbsp;bytesAfterPut,&nbsp;putLevel) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Put&nbsp;block&nbsp;%s&nbsp;remotely&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(remoteStartTime))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockManager.dispose(bytesAfterPut) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;1)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Putting&nbsp;block&nbsp;%s&nbsp;with&nbsp;replication&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Putting&nbsp;block&nbsp;%s&nbsp;without&nbsp;replication&nbsp;took&nbsp;%s&quot; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updatedBlocks &nbsp;&nbsp;&nbsp;} 对于 doPut 函数，主要做了以下几个操作：   1）创建 BlockInfo 对象存储 block 信息。   2）将 BlockInfo 加锁，然后根据 Storage Level 判断存储到 Memory 还是 Disk。同时，对于已经准备好读的 BlockInfo 要进行解锁。   3）根据 block 的副本数量决定是否向远程发送副本。 11.5.1 序列化与否 写入的具体内容可以是序列化之后的 bytes 也可以是没有序列化的 value. 此处有一个对 scala 的语法中 Either, Left, Right 关键字的理解。 11.6 数据读取过程分析 def&nbsp;get(blockId:&nbsp;BlockId):&nbsp;Option[Iterator[Any]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;local&nbsp;=&nbsp;getLocal(blockId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(local.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Found&nbsp;block&nbsp;%s&nbsp;locally&quot;.format(blockId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;local &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;remote&nbsp;=&nbsp;getRemote(blockId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(remote.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Found&nbsp;block&nbsp;%s&nbsp;remotely&quot;.format(blockId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;remote &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;None } 11.6.1 本地读取 首先在查询本机的 MemoryStore 和 DiskStore 中是否有所需要的 block 数据存在，如果没有则发起远程数据获取。 11.6.2 远程读取 远程获取调用路径， getRemote --&gt; doGetRemote, 在 doGetRemote 中最主要的就是调用 BlockManagerWorker.syncGetBlock 来从远程获得数据。 def&nbsp;syncGetBlock(msg:&nbsp;GetBlock,&nbsp;toConnManagerId:&nbsp;ConnectionManagerId):&nbsp;ByteBuffer&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockManager&nbsp;=&nbsp;blockManagerWorker.blockManager &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;connectionManager&nbsp;=&nbsp;blockManager.connectionManager &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockMessage&nbsp;=&nbsp;BlockMessage.fromGetBlock(msg) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockMessageArray&nbsp;=&nbsp;new&nbsp;BlockMessageArray(blockMessage) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;responseMessage&nbsp;=&nbsp;connectionManager.sendMessageReliablySync( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;toConnManagerId,&nbsp;blockMessageArray.toBufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;responseMessage&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(message)&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bufferMessage&nbsp;=&nbsp;message.asInstanceOf[BufferMessage] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Response&nbsp;message&nbsp;received&nbsp;&quot;&nbsp;+&nbsp;bufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockMessageArray.fromBufferMessage(bufferMessage).foreach(blockMessage&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Found&nbsp;&quot;&nbsp;+&nbsp;blockMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;blockMessage.getData &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt;&nbsp;logDebug(&quot;No&nbsp;response&nbsp;message&nbsp;received&quot;) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;null } 上述这段代码中最有意思的莫过于 sendMessageReliablySync，远程数据读取毫无疑问是一个异步 i/o 操作，这里的代码怎么写起来就像是在进行同步的操作一样呢。也就是说如何知道对方发送回来响应的呢？ 别急，继续去看看 sendMessageReliablySync 的定义： def&nbsp;sendMessageReliably(connectionManagerId:&nbsp;ConnectionManagerId,&nbsp;message:&nbsp;Message) &nbsp;&nbsp;:&nbsp;Future[Option[Message]]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;promise&nbsp;=&nbsp;Promise[Option[Message]] &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;status&nbsp;=&nbsp;new&nbsp;MessageStatus( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message,&nbsp;connectionManagerId,&nbsp;s&nbsp;=&gt;&nbsp;promise.success(s.ackMessage)) &nbsp;&nbsp;&nbsp;&nbsp;messageStatuses.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses&nbsp;+=&nbsp;((message.id,&nbsp;status)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;sendMessage(connectionManagerId,&nbsp;message) &nbsp;&nbsp;&nbsp;&nbsp;promise.future } 要是我说秘密在这里，你肯定会说我在扯淡，但确实在此处。注意到关键字 Promise 和 Future 没？ 如果这个 future 执行完毕，返回 s.ackMessage。我们再看看这个 ackMessage 是在什么地方被写入的呢。看一看 ConnectionManager.handleMessage 中的代码片段： case&nbsp;bufferMessage:&nbsp;BufferMessage&nbsp;=&gt; { &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(authEnabled)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;res&nbsp;=&nbsp;handleAuthentication(connection,&nbsp;bufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(res&nbsp;==&nbsp;true)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;message&nbsp;was&nbsp;security&nbsp;negotiation&nbsp;so&nbsp;skip&nbsp;the&nbsp;rest &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;After&nbsp;handleAuth&nbsp;result&nbsp;was&nbsp;true,&nbsp;returning&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(bufferMessage.hasAckId)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sentMessageStatus&nbsp;=&nbsp;messageStatuses.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses.get(bufferMessage.ackId)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(status)&nbsp;=&gt;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses&nbsp;-=&nbsp;bufferMessage.ackId &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;status &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;Exception(&quot;Could&nbsp;not&nbsp;find&nbsp;reference&nbsp;for&nbsp;received&nbsp;ack&nbsp;message&nbsp;&quot;&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message.id) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;null &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.ackMessage&nbsp;=&nbsp;Some(message) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.attempted&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.acked&nbsp;=&nbsp;true &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStaus.markDone() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 注意：此处的所调用的 sentMessageStatus.markDone 就会调用在 sendMessageReliablySync 中定义的 promise.Success，不妨看看 MessageStatus 的定义。 class&nbsp;MessageStatus( val&nbsp;message:&nbsp;Message, val&nbsp;connectionManagerId:&nbsp;ConnectionManagerId, completionHandler:&nbsp;MessageStatus&nbsp;=&gt;&nbsp;Unit)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;ackMessage:&nbsp;Option[Message]&nbsp;=&nbsp;None &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;attempted&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;acked&nbsp;=&nbsp;false &nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;markDone()&nbsp;{&nbsp;completionHandler(this)&nbsp;} } 11.7 Partition 如何转化为 Block 在 storage 模块里面所有的操作都是和 block 相关的，但是在 RDD 里面所有的运算都是基于 partition 的，那么 partition 是如何与 block 对应上的呢？ RDD 计算的核心函数是 iterator() 函数： final&nbsp;def&nbsp;iterator(split:&nbsp;Partition,&nbsp;context:&nbsp;TaskContext):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparkEnv.get.cacheManager.getOrCompute(this,&nbsp;split,&nbsp;context,&nbsp;storageLevel) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;} } 如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute() 函数计算 RDD，在这个函数中 partition 和 block 发生了关系： 首先根据 RDD id 和 partition index 构造出 block id (rdd_xx_xx)，接着从 BlockManager 中取出相应的 block。   如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。   如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的 block，并将其存储到 BlockManager 中。 需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。 def&nbsp;getOrCompute[T](rdd:RDD[T],split:Partition,context:TaskContext,storageLevel:StorageLevel):Iterator[T]= { &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;key&nbsp;=&nbsp;&quot;rdd_%d_%d&quot;.format(rdd.id,&nbsp;split.index) &nbsp;&nbsp;&nbsp;&nbsp;logDebug(&quot;Looking&nbsp;for&nbsp;partition&nbsp;&quot;&nbsp;+&nbsp;key) &nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(values)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Partition&nbsp;is&nbsp;already&nbsp;materialized,&nbsp;so&nbsp;just&nbsp;return&nbsp;its&nbsp;values &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;values.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Mark&nbsp;the&nbsp;split&nbsp;as&nbsp;loading&nbsp;(unless&nbsp;someone&nbsp;else&nbsp;marks&nbsp;it&nbsp;first) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(loading.contains(key))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Another&nbsp;thread&nbsp;is&nbsp;loading&nbsp;%s,&nbsp;waiting&nbsp;for&nbsp;it&nbsp;to&nbsp;finish...&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;while&nbsp;(loading.contains(key))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.wait() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;catch&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;_: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Throwable&nbsp;=&gt;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Finished&nbsp;waiting&nbsp;for&nbsp;%s&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;See&nbsp;whether&nbsp;someone&nbsp;else&nbsp;has&nbsp;successfully&nbsp;loaded&nbsp;it.&nbsp;The&nbsp;main&nbsp;way&nbsp;this&nbsp;would&nbsp;fail &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;is&nbsp;for&nbsp;the&nbsp;RDD-level&nbsp;cache&nbsp;eviction&nbsp;policy&nbsp;if&nbsp;someone&nbsp;else&nbsp;has&nbsp;loaded&nbsp;the&nbsp;same&nbsp;RDD &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;partition&nbsp;but&nbsp;we&nbsp;didn&#39;t&nbsp;want&nbsp;to&nbsp;make&nbsp;space&nbsp;for&nbsp;it.&nbsp;However,&nbsp;that&nbsp;case&nbsp;is&nbsp;unlikely &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;because&nbsp;it&#39;s&nbsp;unlikely&nbsp;that&nbsp;two&nbsp;threads&nbsp;would&nbsp;work&nbsp;on&nbsp;the&nbsp;same&nbsp;RDD&nbsp;partition.&nbsp;One &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;downside&nbsp;of&nbsp;the&nbsp;current&nbsp;code&nbsp;is&nbsp;that&nbsp;threads&nbsp;wait&nbsp;serially&nbsp;if&nbsp;this&nbsp;does&nbsp;happen. &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(values)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;values.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Whoever&nbsp;was&nbsp;loading&nbsp;%s&nbsp;failed;&nbsp;we&#39;ll&nbsp;try&nbsp;it&nbsp;ourselves&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.add(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.add(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;If&nbsp;we&nbsp;got&nbsp;here,&nbsp;we&nbsp;have&nbsp;to&nbsp;load&nbsp;the&nbsp;split &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Partition&nbsp;%s&nbsp;not&nbsp;found,&nbsp;computing&nbsp;it&quot;.format(key)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;computedValues&nbsp;=&nbsp;rdd.computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Persist&nbsp;the&nbsp;result,&nbsp;so&nbsp;long&nbsp;as&nbsp;the&nbsp;task&nbsp;is&nbsp;not&nbsp;running&nbsp;locally &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(context.runningLocally)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;elements&nbsp;=&nbsp;new&nbsp;ArrayBuffer[Any] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elements++&nbsp;=&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManager.put(key,&nbsp;elements,&nbsp;storageLevel,&nbsp;true) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;elements.iterator.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.&nbsp;synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.remove(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.notifyAll() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 这样 RDD 的 transformation、action 就和 block 数据建立了联系，虽然抽象上我们的操作是在 partition 层面上进行的，但是 partitio n最终还是被映射成为 block，因此实际上我们的所有操作都是对 block 的处理和存取。 11.8 partition 和 block 的对应关系 在 RDD 中，核心的函数是 iterator： final&nbsp;def&nbsp;iterator(split:&nbsp;Partition,&nbsp;context:&nbsp;TaskContext):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparkEnv.get.cacheManager.getOrCompute(this,&nbsp;split,&nbsp;context,&nbsp;storageLevel) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;else&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;} } 如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute 函数计算 RDD，在这个函数中 partition 和 block 就对应起来了：   getOrCompute 函数会先构造 RDDBlockId，其中 RDDBlockId 就把 block 和 partition 联系起来了，RDDBlockId 产生的 name 就是 BlockId 的 name 属性，形式是：rdd_rdd.id_partition.index。 def&nbsp;getOrCompute[T]( rdd:&nbsp;RDD[T], partition:&nbsp;Partition, context:&nbsp;TaskContext, storageLevel:&nbsp;StorageLevel):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;key&nbsp;=&nbsp;RDDBlockId(rdd.id,&nbsp;partition.index) &nbsp;&nbsp;&nbsp;&nbsp;logDebug(s&quot;Looking&nbsp;for&nbsp;partition&nbsp;$key&quot;) &nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;Some(blockResult)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;existingMetrics&nbsp;=&nbsp;context.taskMetrics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.getInputMetricsForReadMethod(blockResult.readMethod) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;existingMetrics.incBytesRead(blockResult.bytes) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;iter&nbsp;=&nbsp;blockResult.data.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;InterruptibleIterator[T](context,&nbsp;iter)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;next():&nbsp;T&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;existingMetrics.incRecordsRead(1) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delegate.next() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;storedValues&nbsp;=&nbsp;acquireLockForPartition[T](key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(storedValues.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;new&nbsp;InterruptibleIterator[T](context,&nbsp;storedValues.get) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(s&quot;Partition&nbsp;$key&nbsp;not&nbsp;found,&nbsp;computing&nbsp;it&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;computedValues&nbsp;=&nbsp;rdd.computeOrReadCheckpoint(partition,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(context.isRunningLocally)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;return&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;updatedBlocks&nbsp;=&nbsp;new&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;cachedValues&nbsp;=&nbsp;putInBlockManager(key,&nbsp;computedValues,&nbsp;storageLevel,&nbsp;updatedBlocks) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;metrics&nbsp;=&nbsp;context.taskMetrics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;lastUpdatedBlocks&nbsp;=&nbsp;metrics.updatedBlocks.getOrElse(Seq[(BlockId,&nbsp;BlockStatus)]()) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metrics.updatedBlocks&nbsp;=&nbsp;Some(lastUpdatedBlocks&nbsp;++&nbsp;updatedBlocks.toSeq) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;new&nbsp;InterruptibleIterator(context,&nbsp;cachedValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;finally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.synchronized&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.remove(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.notifyAll() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } 同时 getOrCompute 函数会对 block 进行判断：   如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。   如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的block，并将其存储到 BlockManager 中。   需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。 回到顶部 第12章 Spark Shuffle 过程 12.1 MapReduce 的 Shuffle 过程介绍   Shuffle 的本义是洗牌、混洗，把一组有一定规则的数据尽量转换成一组无规则的数据，越随机越好。MapReduce 中的 Shuffle 更像是洗牌的逆过程，把一组无规则的数据尽量转换成一组具有一定规则的数据。   为什么 MapReduce 计算模型需要 Shuffle 过程？我们都知道 MapReduce 计算模型一般包括两个重要的阶段：Map 是映射，负责数据的过滤分发；Reduce 是规约，负责数据的计算归并。Reduce 的数据来源于 Map，Map 的输出即是 Reduce 的输入，Reduce 需要通过 Shuffle来 获取数据。   从 Map 输出到 Reduce 输入的整个过程可以广义地称为 Shuffle。Shuffle 横跨 Map 端和 Reduce 端，在 Map 端包括 Spill 过程，在 Reduce 端包括 copy 和 sort 过程，如图所示：    12.1.1 Spill 过程(刷写过程)   Spill 过程包括输出、排序、溢写、合并等步骤，如图所示：    Collect   每个 Map 任务不断地以&nbsp;&lt;key, value&gt;&nbsp;对的形式把数据输出到内存中构造的一个环形数据结构中。使用环形数据结构是为了更有效地使用内存空间，在内存中放置尽可能多的数据。   这个数据结构其实就是个字节数组，叫 kvbuffer，名如其义，但是这里面不光放置了&nbsp;&lt;key, value&gt;数据，还放置了一些索引数据，给放置索引数据的区域起了一个 kvmeta 的别名，在 kvbuffer 的一块区域上穿了一个 IntBuffer（字节序采用的是平台自身的字节序）的马甲。&lt;key, value&gt;&nbsp;数据区域和索引数据区域在 kvbuffer 中是相邻不重叠的两个区域，用一个分界点来划分两者，分界点不是亘古不变的，而是每次 Spill 之后都会更新一次。初始的分界点是 0，&lt;key, value&gt;&nbsp;数据的存储方向是向上增长，索引数据的存储方向是向下增长，如图所示：      kvbuffer 的存放指针 bufindex 是一直闷着头地向上增长，比如 bufindex 初始值为 0，一个 Int 型的 key 写完之后，bufindex 增长为 4，一个 Int 型的 value 写完之后，bufindex 增长为 8。   索引是对&nbsp;&lt;key, value&gt;&nbsp;在 kvbuffer 中的索引，是个四元组，包括：value 的起始位置、key 的起始位置、partition 值、value 的长度，占用四个 Int 长度，kvmeta 的存放指针 kvindex 每次都是向下跳四个“格子”，然后再向上一个格子一个格子地填充四元组的数据。比如 Kvindex 初始位置是 -4，当第一个&nbsp;&lt;key, value&gt;&nbsp;写完之后，(kvindex+0) 的位置存放 value 的起始位置、(kvindex+1) 的位置存放 key 的起始位置、(kvindex+2) 的位置存放 partition 的值、(kvindex+3) 的位置存放 value 的长度，然后 kvindex 跳到 -8 位置，等第二个&nbsp;&lt;key, value&gt;&nbsp;和索引写完之后，kvindex 跳到-32 位置。   kvbuffer 的大小虽然可以通过参数设置，但是总共就那么大，&lt;key, value&gt;&nbsp;和索引不断地增加，加着加着，kvbuffer 总有不够用的那天，那怎么办？把数据从内存刷到磁盘上再接着往内存写数据，把 kvbuffer 中的数据刷到磁盘上的过程就叫 Spill，多么明了的叫法，内存中的数据满了就自动地 spill 到具有更大空间的磁盘。   关于 Spill 触发的条件，也就是 kvbuffer 用到什么程度开始 Spill，还是要讲究一下的。如果把 kvbuffer 用得死死得，一点缝都不剩的时候再开始 Spill，那 Map 任务就需要等 Spill 完成腾出空间之后才能继续写数据；如果 kvbuffer 只是满到一定程度，比如 80% 的时候就开始 Spill，那在 Spill 的同时，Map 任务还能继续写数据，如果 Spill 够快，Map 可能都不需要为空闲空间而发愁。两利相衡取其大，一般选择后者。   Spill 这个重要的过程是由 Spill 线程承担，Spill 线程从 Map 任务接到“命令”之后就开始正式干活，干的活叫 SortAndSpill，原来不仅仅是 Spill，在 Spill 之前还有个颇具争议性的 Sort。 Sort   先把 kvbuffer 中的数据按照 partition 值和 key 两个关键字升序排序，移动的只是索引数据，排序结果是 kvmeta 中数据按照 partition 为单位聚集在一起，同一 partition 内的按照 key 有序。 Spill   Spill 线程为这次 Spill 过程创建一个磁盘文件：从所有的本地目录中轮询查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out” 的文件。Spill 线程根据排过序的 kvmeta 挨个 partition 的把&nbsp;&lt;key, value&gt;&nbsp;数据吐到这个文件中，一个 partition 对应的数据吐完之后顺序地吐下个 partition，直到把所有的 partition 遍历完。一个 partition 在文件中对应的数据也叫段 (segment)。   所有的 partition 对应的数据都放在这个文件里，虽然是顺序存放的，但是怎么直接知道某个 partition 在这个文件中存放的起始位置呢？强大的索引又出场了。有一个三元组记录某个 partition 对应的数据在这个文件中的索引：起始位置、原始数据长度、压缩之后的数据长度，一个 partition 对应一个三元组。然后把这些索引信息存放在内存中，如果内存中放不下了，后续的索引信息就需要写到磁盘文件中了：从所有的本地目录中轮训查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out.index” 的文件，文件中不光存储了索引数据，还存储了 crc32 的校验数据。(spill12.out.index 不一定在磁盘上创建，如果内存（默认 1M 空间）中能放得下就放在内存中，即使在磁盘上创建了，和 spill12.out 文件也不一定在同一个目录下。)   每一次 Spill 过程就会最少生成一个 out 文件，有时还会生成 index 文件，Spill 的次数也烙印在文件名中。索引文件和数据文件的对应关系如下图所示：      在 Spill 线程如火如荼的进行 SortAndSpill 工作的同时，Map 任务不会因此而停歇，而是一无既往地进行着数据输出。Map 还是把数据写到 kvbuffer 中，那问题就来了：&lt;key, value&gt;&nbsp;只顾着闷头按照 bufindex 指针向上增长，kvmeta 只顾着按照 kvindex 向下增长，是保持指针起始位置不变继续跑呢，还是另谋它路？如果保持指针起始位置不变，很快 bufindex 和 kvindex 就碰头了，碰头之后再重新开始或者移动内存都比较麻烦，不可取。Map 取 kvbuffer 中剩余空间的中间位置，用这个位置设置为新的分界点，bufindex 指针移动到这个分界点，kvindex 移动到这个分界点的 -16 位置，然后两者就可以和谐地按照自己既定的轨迹放置数据了，当 Spill 完成，空间腾出之后，不需要做任何改动继续前进。分界点的转换如下图所示：      Map 任务总要把输出的数据写到磁盘上，即使输出数据量很小在内存中全部能装得下，在最后也会把数据刷到磁盘上。 &nbsp; 12.1.2 Merge      Map 任务如果输出数据量很大，可能会进行好几次 Spill，out 文件和 Index 文件会产生很多，分布在不同的磁盘上。最后把这些文件进行合并的 merge 过程闪亮登场。   Merge 过程怎么知道产生的 Spill 文件都在哪了呢？从所有的本地目录上扫描得到产生的 Spill 文件，然后把路径存储在一个数组里。Merge 过程又怎么知道 Spill 的索引信息呢？没错，也是从所有的本地目录上扫描得到 Index 文件，然后把索引信息存储在一个列表里。到这里，又遇到了一个值得纳闷的地方。在之前 Spill 过程中的时候为什么不直接把这些信息存储在内存中呢，何必又多了这步扫描的操作？特别是 Spill 的索引数据，之前当内存超限之后就把数据写到磁盘，现在又要从磁盘把这些数据读出来，还是需要装到更多的内存中。之所以多此一举，是因为这时 kvbuffer 这个内存大户已经不再使用可以回收，有内存空间来装这些数据了。（对于内存空间较大的土豪来说，用内存来省却这两个 io 步骤还是值得考虑的。） &nbsp;   然后为 merge 过程创建一个叫 file.out 的文件和一个叫 file.out.Index 的文件用来存储最终的输出和索引。   一个 partition 一个 partition 的进行合并输出。对于某个 partition 来说，从索引列表中查询这个 partition 对应的所有索引信息，每个对应一个段插入到段列表中。也就是这个 partition 对应一个段列表，记录所有的 Spill 文件中对应的这个 partition 那段数据的文件名、起始位置、长度等等。   然后对这个 partition 对应的所有的 segment 进行合并，目标是合并成一个 segment。当这个 partition 对应很多个 segment 时，会分批地进行合并：先从 segment 列表中把第一批取出来，以 key 为关键字放置成最小堆，然后从最小堆中每次取出最小的&nbsp;&lt;key, value&gt;&nbsp;输出到一个临时文件中，这样就把这一批段合并成一个临时的段，把它加回到 segment 列表中；再从 segment 列表中把第二批取出来合并输出到一个临时 segment，把其加入到列表中；这样往复执行，直到剩下的段是一批，输出到最终的文件中。   最终的索引数据仍然输出到 Index 文件中。   Map 端的 Shuffle 过程到此结束。 12.1.3 Copy   Reduce 任务通过 HTTP 向各个 Map 任务拖取它所需要的数据。每个节点都会启动一个常驻的 HTTP server，其中一项服务就是响应 Reduce 拖取 Map 数据。当有 MapOutput 的 HTTP 请求过来的时候，HTTP server 就读取相应的 Map 输出文件中对应这个 Reduce 部分的数据通过网络流输出给 Reduce。   Reduce 任务拖取某个 Map 对应的数据，如果在内存中能放得下这次数据的话就直接把数据写到内存中。Reduce 要向每个 Map 去拖取数据，在内存中每个 Map 对应一块数据，当内存中存储的 Map 数据占用空间达到一定程度的时候，开始启动内存中 merge，把内存中的数据 merge 输出到磁盘上一个文件中。   如果在内存中不能放得下这个 Map 的数据的话，直接把 Map 数据写到磁盘上，在本地目录创建一个文件，从 HTTP 流中读取数据然后写到磁盘，使用的缓存区大小是 64K。拖一个 Map 数据过来就会创建一个文件，当文件数量达到一定阈值时，开始启动磁盘文件 merge，把这些文件合并输出到一个文件。   有些 Map 的数据较小是可以放在内存中的，有些 Map 的数据较大需要放在磁盘上，这样最后 Reduce 任务拖过来的数据有些放在内存中了有些放在磁盘上，最后会对这些来一个全局合并。 12.1.4 Merge Sort   这里使用的 Merge 和 Map 端使用的 Merge 过程一样。Map 的输出数据已经是有序的，Merge 进行一次合并排序，所谓 Reduce 端的 sort 过程就是这个合并的过程。一般 Reduce 是一边 copy 一边 sort，即 copy 和 sort 两个阶段是重叠而不是完全分开的。   Reduce 端的 Shuffle 过程至此结束。 12.2 HashShuffle 过程介绍   Spark 丰富了任务类型，有些任务之间数据流转不需要通过 Shuffle，但是有些任务之间还是需要通过 Shuffle 来传递数据，比如 wide dependency 的 group by key。   Spark 中需要 Shuffle 输出的 Map 任务会为每个 Reduce 创建对应的 bucket，Map 产生的结果会根据设置的 partitioner 得到对应的 bucketId，然后填充到相应的 bucket 中去。每个 Map 的输出结果可能包含所有的 Reduce 所需要的数据，所以每个 Map 会创建 R 个 bucket（R 是 reduce 的个数），M 个 Map 总共会创建 M*R 个 bucket。   Map 创建的 bucket 其实对应磁盘上的一个文件，Map 的结果写到每个 bucket 中其实就是写到那个磁盘文件中，这个文件也被称为 blockFile，是 Disk Block Manager 管理器通过文件名的 Hash 值对应到本地目录的子目录中创建的。每个 Map 要在节点上创建 R 个磁盘文件用于结果输出，Map 的结果是直接输出到磁盘文件上的，100KB 的内存缓冲是用来创建 Fast Buffered OutputStream 输出流。这种方式一个问题就是 Shuffle 文件过多。      1）每一个 Mapper 创建出和 Reducer 数目相同的 bucket，bucket 实际上是一个 buffer，其大小为 spark.shuffle.file.buffer.kb（默认 32KB）。   2）Mapper 产生的结果会根据设置的 partition 算法填充到每个 bucket 中去，然后再写入到磁盘文件。   3）Reducer 从远端或是本地的 block manager 中找到相应的文件读取数据。 &nbsp;   针对上述 Shuffle 过程产生的文件过多问题，Spark 有另外一种改进的 Shuffle 过程：consolidation Shuffle，以期显著减少 Shuffle 文件的数量。在 consolidation Shuffle 中每个 bucket 并非对应一个文件，而是对应文件中的一个 segment 部分。Job 的 map 在某个节点上第一次执行，为每个 reduce 创建 bucke 对应的输出文件，把这些文件组织成&nbsp;ShuffleFileGroup，当这次 map 执行完之后，这个 ShuffleFileGroup 可以释放为下次循环利用；当又有 map 在这个节点上执行时，不需要创建新的 bucket 文件，而是在上次的 ShuffleFileGroup 中取得已经创建的文件继续追加写一个 segment；当前次 map 还没执行完，ShuffleFileGroup 还没有释放，这时如果有新的 map 在这个节点上执行，无法循环利用这个 ShuffleFileGroup，而是只能创建新的 bucket 文件组成新的 ShuffleFileGroup 来写输出。      比如一个 Job 有 3 个 Map 和 2 个 reduce：   (1) 如果此时集群有 3 个节点有空槽，每个节点空闲了一个 core，则 3 个 Map 会调度到这 3 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，总共创建 6 个 Shuffle 文件；   (2) 如果此时集群有 2 个节点有空槽，每个节点空闲了一个 core，则 2 个 Map 先调度到这 2 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，然后其中一个节点执行完 Map 之后又调度执行另一个 Map，则这个 Map 不会创建新的 Shuffle 文件，而是把结果输出追加到之前 Map 创建的 Shuffle 文件中；总共创建 4 个 Shuffle 文件；   (3) 如果此时集群有 2 个节点有空槽，一个节点有 2 个空 core 一个节点有 1 个空 core，则一个节点调度 2 个 Map 一个节点调度 1 个 Map，调度 2 个 Map 的节点上，一个 Map 创建了 Shuffle 文件，后面的 Map 还是会创建新的 Shuffle 文件，因为上一个 Map 还正在写，它创建的 ShuffleFileGroup 还没有释放；总共创建 6 个 Shuffle 文件。优点：   1）快-不需要排序，也不需要维持 hash 表   2）不需要额外空间用作排序   3）不需要额外IO-数据写入磁盘只需一次，读取也只需一次缺点：   1）当 partitions 大时，输出大量的文件（cores * R），性能开始降低   2）大量的文件写入，使文件系统开始变为随机写，性能比顺序写要降低 100 倍   3）缓存空间占用比较大   Reduce 去拖 Map 的输出数据，Spark 提供了两套不同的拉取数据框架：通过 socket 连接去取数据；使用n etty 框架去取数据。   每个节点的 Executor 会创建一个 BlockManager，其中会创建一个 BlockManagerWorker 用于响应请求。当 Reduce 的 GET_BLOCK 的请求过来时，读取本地文件将这个 blockId 的数据返回给 Reduce。如果使用的是 Netty 框架，BlockManager 会创建 ShuffleSender 用于发送 Shuffle 数据。   并不是所有的数据都是通过网络读取，对于在本节点的 Map 数据，Reduce 直接去磁盘上读取而不再通过网络框架。   Reduce 拖过来数据之后以什么方式存储呢？Spark Map 输出的数据没有经过排序，Spark Shuffle 过来的数据也不会进行排序，Spark 认为 Shuffle 过程中的排序不是必须的，并不是所有类型的 Reduce 需要的数据都需要排序，强制地进行排序只会增加 Shuffle 的负担。Reduce 拖过来的数据会放在一个 HashMap 中，HashMap 中存储的也是&nbsp;&lt;key, value&gt;&nbsp;对，key 是 Map 输出的 key，Map 输出对应这个 key 的所有 value 组成 HashMap 的 value。Spark 将 Shuffle 取过来的每一个&nbsp;&lt;key, value&gt;对插入或者更新到 HashMap 中，来一个处理一个。HashMap 全部放在内存中。   Shuffle 取过来的数据全部存放在内存中，对于数据量比较小或者已经在 Map 端做过合并处理的 Shuffle 数据，占用内存空间不会太大，但是对于比如 group by key 这样的操作，Reduce 需要得到 key 对应的所有 value，并将这些 value 组一个数组放在内存中，这样当数据量较大时，就需要较多内存。   当内存不够时，要不就失败，要不就用老办法把内存中的数据移到磁盘上放着。Spark 意识到在处理数据规模远远大于内存空间时所带来的不足，引入了一个具有外部排序的方案。Shuffle 过来的数据先放在内存中，当内存中存储的&nbsp;&lt;key, value&gt;&nbsp;对超过 1000 并且内存使用超过 70% 时，判断节点上可用内存如果还足够，则把内存缓冲区大小翻倍，如果可用内存不再够了，则把内存中的&nbsp;&lt;key, value&gt;&nbsp;对排序然后写到磁盘文件中。最后把内存缓冲区中的数据排序之后和那些磁盘文件组成一个最小堆，每次从最小堆中读取最小的数据，这个和 MapReduce 中的 merge 过程类似。 12.3 SortShuffle 过程介绍   从 1.2.0 开始默认为 sort shuffle(spark.shuffle.manager = sort)，实现逻辑类似于 Hadoop MapReduce，Hash Shuffle 每一个 reducers 产生一个文件，但是 Sort Shuffle 只是产生一个按照 reducer id 排序可索引的文件，这样，只需获取有关文件中的相关数据块的位置信息，并 fseek 就可以读取指定 reducer 的数据。但对于 rueducer 数比较少的情况，Hash Shuffle 明显要比 Sort Shuffle 快，因此 Sort Shuffle 有个 “fallback” 计划，对于 reducers 数少于 “spark.shuffle.sort.bypassMergeThreshold” (200 by default)，我们使用 fallback 计划，hashing 相关数据到分开的文件，然后合并这些文件为一个，具体实现为 BypassMergeSortShuffleWriter。      在 map 进行排序，在 reduce 端应用 Timsort[1] 进行合并。map 端是否容许 spill，通过 spark.shuffle.spill 来设置，默认是 true。设置为 false，如果没有足够的内存来存储 map 的输出，那么就会导致 OOM 错误，因此要慎用。   用于存储 map 输出的内存为：“JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction，默认为： “JVM Heap Size” * 0.2 * 0.8 = “JVM Heap Size” * 0.16。如果你在同一个执行程序中运行多个线程（设定 spark.executor.cores/ spark.task.cpus 超过 1），每个 map 任务存储的空间为 “JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction / spark.executor.cores * spark.task.cpus，默认 2 个 cores，那么为 0.08 * “JVM Heap Size”。      spark 使用 AppendOnlyMap 存储 map 输出的数据，利用开源 hash 函数 MurmurHash3 和平方探测法把 key 和 value 保存在相同的 array 中。这种保存方法可以是 spark 进行 combine。如果 spill 为 true，会在 spill 前 sort。   与 hash shuffle 相比，sort shuffle 中每个 Mapper 只产生一个数据文件和一个索引文件，数据文件中的数据按照 Reducer 排序，但属于同一个 Reducer 的数据不排序。Mapper 产生的数据先放到 AppendOnlyMap 这个数据结构中，如果内存不够，数据则会 spill 到磁盘，最后合并成一个文件。   与 Hash shuffle 相比，shuffle 文件数量减少，内存使用更加可控。但排序会影响速度。优点：   1）map 创建文件量较少。   2）少量的 IO 随机操作，大部分是顺序读写。缺点：   1）要比 Hash Shuffle 要慢，需要自己通过 spark.shuffle.sort.bypassMergeThreshold 来设置合适的值。   2）如果使用 SSD 盘存储 shuffle 数据，那么 Hash Shuffle 可能更合适。 12.4 TungstenShuffle 过程介绍   Tungsten-sort 算不得一个全新的 shuffle 方案，它在特定场景下基于类似现有的 Sort Based Shuffle 处理流程，对内存 /CPU/Cache 使用做了非常大的优化。带来高效的同时，也就限定了自己的使用场景。如果 Tungsten-sort 发现自己无法处理，则会自动使用 Sort Based Shuffle 进行处理。Tungsten 中文是钨丝的意思。 Tungsten Project 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，该计划初期似乎对 Spark SQL 优化的最多。不过部分 RDD API 还有 Shuffle 也因此受益。Tungsten-sort 优化点主要在三个方面:   1）直接在 serialized binary data 上 sort 而不是 java objects，减少了 memory 的开销和 GC 的 overhead。   2）提供 cache-efficient sorter，使用一个 8bytes 的指针，把排序转化成了一个指针数组的排序。   3）spill 的 merge 过程也无需反序列化即可完成。   这些优化的实现导致引入了一个新的内存管理模型，类似 OS 的 Page，对应的实际数据结构为 MemoryBlock，支持 off-heap 以及 in-heap 两种模式。为了能够对 Record 在这些 MemoryBlock 进行定位，引入了 Pointer（指针）的概念。 如果你还记得 Sort Based Shuffle 里存储数据的对象 PartitionedAppendOnlyMap，这是一个放在 JVM heap 里普通对象，在 Tungsten-sort 中，他被替换成了类似操作系统内存页的对象。如果你无法申请到新的 Page，这个时候就要执行 spill 操作，也就是写入到磁盘的操作。具体触发条件，和 Sort Based Shuffle 也是类似的。   Spark 默认开启的是 Sort Based Shuffle，想要打开 Tungsten-sort，请设置   spark.shuffle.manager=tungsten-sort   对应的实现类是：org.apache.spark.shuffle.unsafe.UnsafeShuffleManager   名字的来源是因为使用了大量 JDK Sun Unsafe API。 当且仅当下面条件都满足时，才会使用新的 Shuffle 方式：   1）Shuffle dependency 不能带有 aggregation 或者输出需要排序   2）Shuffle 的序列化器需要是 KryoSerializer 或者 Spark SQL&#39;s 自定义的一些序列化方式.   3）Shuffle 文件的数量不能大于 16777216。   4）序列化时，单条记录不能大于 128 MB。 可以看到，能使用的条件还是挺苛刻的。 这些限制来源于哪里 参看如下代码，page 的大小：   this.pageSizeBytes = (int) Math.min(PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES,shuffleMemoryManager.pageSizeBytes()); 这就保证了页大小不超过 PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES 的值，该值就被定义成了 128M。 而产生这个限制的具体设计原因，我们还要仔细分析下 Tungsten 的内存模型，如下图所示：    这张图其实画的是 on-heap 的内存逻辑图，其中 #Page 部分为 13bit，Offset 为 51bit，你会发现 2^51 &gt;&gt; 128M 的。但是在 Shuffle 的过程中，对 51bit 做了压缩，使用了 27bit，具体如下：   [24 bit partition number][13 bit memory page number][27 bit offset in page] 这里预留出的 24bi t给了 partition number，为了后面的排序用。上面的好几个限制其实都是因为这个指针引起的：   第一个是 partition 的限制，前面的数字 16777216 就是来源于 partition number 使用 24bit 表示的。   第二个是 page number。   第三个是偏移量，最大能表示到 2^27=128M。那一个 Task 能管理到的内存是受限于这个指针的，最多是 2^13 * 128M 也就是 1TB 左右。 有了这个指针，我们就可以定位和管理到 off-heap 或者 on-heap 里的内存了。这个模型还是很漂亮的，内存管理也非常高效，记得之前的预估 PartitionedAppendOnlyMap 的内存是非常困难的，但是通过现在的内存管理机制，是非常快速并且精确的。 对于第一个限制，那是因为后续 Shuffle Write 的 sort 部分，只对前面 24bit 的 partiton number 进行排序，key 的值没有被编码到这个指针，所以没办法进行 ordering。 同时，因为整个过程是追求不反序列化的，所以不能做 aggregation。 Shuffle Write 核心类：&nbsp;   org.apache.spark.shuffle.unsafe.UnsafeShuffleWriter 数据会通过 UnsafeShuffleExternalSorter.insertRecordIntoSorter 一条一条写入到 serOutputStream 序列化输出流。 这里消耗内存的地方是   serBuffer = new MyByteArrayOutputStream(1024 * 1024) 默认是 1M，类似于 Sort Based Shuffle 中的 ExternalSorter，在 Tungsten Sort 对应的为 UnsafeShuffleExternalSorter，记录序列化后就通过 sorter.insertRecord 方法放到 sorter 里去了。 这里 sorter 负责申请 Page，释放 Page，判断是否要进行 spill 都这个类里完成。代码的架子其实和 Sort Based 是一样的。    (另外，值得注意的是，这张图里进行 spill 操作的同时检查内存可用而导致的 Exeception 的 bug 已经在 1.5.1 版本被修复了，忽略那条路径) 内存是否充足的条件依然 shuffleMemoryManager 来决定，也就是所有 Task Shuffle 申请的 Page 内存总和不能大于下面的值：   ExecutorHeapMemeory * 0.2 * 0.8 上面的数字可通过下面两个配置来更改：   spark.shuffle.memoryFraction=0.2   spark.shuffle.safetyFraction=0.8 UnsafeShuffleExternalSorter 负责申请内存，并且会生成该条记录最后的逻辑地址，也就前面提到的 Pointer。 接着 Record 会继续流转到 UnsafeShuffleInMemorySorter 中，这个对象维护了一个指针数组：   private long[] pointerArray; 数组的初始大小为 4096，后续如果不够了，则按每次两倍大小进行扩充。 假设 100 万条记录，那么该数组大约是 8M 左右，所以其实还是很小的。一旦 spill 后该 UnsafeShuffleInMemorySorter 就会被赋为 null，被回收掉。 我们回过头来看 spill，其实逻辑上也异常简单了，UnsafeShuffleInMemorySorter 会返回一个迭代器，该迭代器粒度每个元素就是一个指针，然后到根据该指针可以拿到真实的 record，然后写入到磁盘，因为这些 record 在一开始进入 UnsafeShuffleExternalSorter 就已经被序列化了，所以在这里就纯粹变成写字节数组了。形成的结构依然和 Sort Based Shuffle 一致，一个文件里不同的 partiton 的数据用 fileSegment 来表示，对应的信息存在一个 index 文件里。 另外写文件的时候也需要一个 buffer：   spark.shuffle.file.buffer=32k 另外从内存里拿到数据放到 DiskWriter，这中间还要有个中转，是通过：   final byte[] writeBuffer = new byte[DISK_WRITE_BUFFER_SIZE=1024 * 1024]; 来完成的，都是内存，所以很快。 Task 结束前，我们要做一次 mergeSpills 操作，然后形成一个 shuffle 文件。这里面其实也挺复杂的， 如果开启了   spark.shuffle.unsafe.fastMergeEnabled=true 并且没有开启&nbsp;   spark.shuffle.compress=true 或者压缩方式为：   LZFCompressionCodec 则可以非常高效的进行合并，叫做 transferTo。不过无论是什么合并，都不需要进行反序列化。 Shuffle Read Shuffle Read 完全复用 HashShuffleReader，具体参看 Sort-Based Shuffle。 12.5 MapReduce 与 Spark 过程对比 MapReduce 和 Spark 的 Shuffle 过程对比如下： 回到顶部 第13章 Spark 内存管理   Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文中阐述的原理基于 Spark 2.1 版本。&nbsp;   在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业（Job），并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，下文中的 Spark 内存均特指 Executor 的内存。 13.1 堆内和堆外内存规划   作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。堆内和堆外内存示意图如下： 13.1.1 堆内内存   堆内内存的大小，由 Spark 应用程序启动时的&nbsp;-executor-memory&nbsp;或&nbsp;spark.executor.memory参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为存储（Storage）内存，而这些任务在执行 Shuffle 时占用的内存被规划为执行（Execution）内存，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同（下面第 2 小节会进行介绍）。   Spark 对堆内内存的管理是一种逻辑上的规划式的管理，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存，我们来看其具体流程：申请内存：   1）Spark 在代码中 new 一个对象实例   2）JVM 从堆内内存分配空间，创建对象并返回对象引用   3）Spark 保存该对象的引用，记录该对象占用的内存释放内存：   1）Spark 记录该对象释放的内存，删除该对象的引用   2）等待 JVM 的垃圾回收机制释放该对象占用的堆内内存   我们知道，JVM 的对象可以以序列化的方式存储，序列化的过程是将对象转换为二进制字节流，本质上可以理解为将非连续空间的链式存储转化为连续空间或块存储，在访问时则需要进行序列化的逆过程--反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。   对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。   虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。 13.1.2 堆外内存   为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。堆外内存可以被精确地申请和释放，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。   在默认情况下堆外内存并不启用，可通过配置&nbsp;spark.memory.offHeap.enabled&nbsp;参数启用，并由&nbsp;spark.memory.offHeap.size&nbsp;参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。 13.1.3 内存管理接口   Spark 为存储内存和执行内存的管理提供了统一的接口--MemoryManager，同一个 Executor 内的任务都调用这个接口的方法来申请或释放内存: 内存管理接口的主要方法： //&nbsp;申请存储内存 def&nbsp;acquireStorageMemory(blockId:&nbsp;BlockId,&nbsp;numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Boolean //&nbsp;申请展开内存 def&nbsp;acquireUnrollMemory(blockId:&nbsp;BlockId,&nbsp;numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Boolean //&nbsp;申请执行内存 def&nbsp;acquireExecutionMemory(numBytes:&nbsp;Long,&nbsp;taskAttemptId:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Long //&nbsp;释放存储内存 def&nbsp;releaseStorageMemory(numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit //&nbsp;释放执行内存 def&nbsp;releaseExecutionMemory(numBytes:&nbsp;Long,&nbsp;taskAttemptId:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit //&nbsp;释放展开内存 def&nbsp;releaseUnrollMemory(numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode):&nbsp;Unit Spark的内存管理 – 内存管理接口   我们看到，在调用这些方法时都需要指定其内存模式（MemoryMode），这个参数决定了是在堆内还是堆外完成这次操作。MemoryManager 的具体实现上，Spark 1.6 之后默认为统一管理（Unified Memory Manager）方式，1.6 之前采用的静态管理（Static Memory Manager）方式仍被保留，可通过配置&nbsp;spark.memory.useLegacyMode&nbsp;参数启用。两种方式的区别在于对空间分配的方式，下面的第 2 小节会分别对这两种方式进行介绍。 13.2 内存空间分配 13.2.1 静态内存管理   在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。 静态内存管理图示--堆内 可以看到，可用的堆内内存的大小需要按照下面的方式计算： 可用堆内内存空间： 可用的存储内存&nbsp;=&nbsp;systemMaxMemory&nbsp;*&nbsp;spark.storage.memoryFraction&nbsp;*&nbsp;spark.storage.safetyFraction 可用的执行内存&nbsp;=&nbsp;systemMaxMemory&nbsp;*&nbsp;spark.shuffle.memoryFraction&nbsp;*&nbsp;spark.shuffle.safetyFraction   其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和 “其它内存” 一样交给了 JVM 去管理。   堆外的空间分配较为简单，只有存储内存和执行内存，如下图所示。可用的执行内存和存储内存占用的空间大小直接由参数&nbsp;spark.memory.storageFraction&nbsp;决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。 静态内存管理图示--堆外   静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成 “一半海水，一半火焰” 的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。 13.2.2 统一内存管理   Spark 1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域。 统一内存管理图示--堆内 统一内存管理图示--堆外 其中最重要的优化在于动态占用机制，其规则如下：   1）设定基本的存储内存和执行内存区域（spark.storage.storageFraction&nbsp;参数），该设定确定了双方各自拥有的空间的范围。   2）双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block）。   3）执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后 “归还” 借用的空间。   4）存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。 动态占用机制图示   凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护 Spark 内存的难度，但并不意味着开发者可以高枕无忧。譬如，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的 RDD 数据通常都是长期驻留内存的。所以要想充分发挥 Spark 的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。 13.3 存储内存管理 13.3.1 RDD 的持久化机制   弹性分布式数据集（RDD）作为 Spark 最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换（Transformation）操作产生一个新的 RDD。转换后的 RDD 与原始的 RDD 之间产生的依赖关系，构成了血统（Lineage）。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。但 RDD 的所有转换都是惰性的，即只有当一个返回结果给 Driver 的行动（Action）发生时，Spark 才会创建任务读取 RDD，然后真正触发转换的执行。   Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 上要执行多次行动，可以在第一次行动中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。事实上，cache 方法是使用默认的 MEMORY_ONLY 的存储级别将 RDD 持久化到内存，故缓存是一种特殊的持久化。堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理（存储内存的其他应用场景，如缓存 broadcast 数据，暂时不在本文的讨论范围之内）。   RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来。在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD。 Storage 模块示意图 在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY、MEMORY_AND_DISK 等 7 种不同的 存储级别，而存储级别是以下 5 个变量的组合： 存储级别 class&nbsp;StorageLevel&nbsp;private( &nbsp;&nbsp;private&nbsp;var&nbsp;_useDisk:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;磁盘 &nbsp;&nbsp;private&nbsp;var&nbsp;_useMemory:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;这里其实是指堆内内存 &nbsp;&nbsp;private&nbsp;var&nbsp;_useOffHeap:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;堆外内存 &nbsp;&nbsp;private&nbsp;var&nbsp;_deserialized:&nbsp;Boolean,&nbsp;&nbsp;&nbsp;//&nbsp;是否为非序列化 &nbsp;&nbsp;private&nbsp;var&nbsp;_replication:&nbsp;Int&nbsp;=&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;副本个数 ) 通过对数据结构的分析，可以看出存储级别从三个维度定义了 RDD 的 Partition（同时也就是 Block）的存储方式： &nbsp;&nbsp;&nbsp;&nbsp;1）存储位置：磁盘／堆内内存／堆外内存。如&nbsp;MEMORY_AND_DISK&nbsp;是同时在磁盘和堆内内存上存储，实现了冗余备份。OFF_HEAP&nbsp;则是只在堆外内存存储，目前选择堆外内存时不能同时存储到其他位置。 &nbsp;&nbsp;&nbsp;&nbsp;2）存储形式：Block&nbsp;缓存到存储内存后，是否为非序列化的形式。如&nbsp;MEMORY_ONLY&nbsp;是非序列化方式存储，OFF_HEAP&nbsp;是序列化方式存储。 &nbsp;&nbsp;&nbsp;&nbsp;3）副本数量：大于&nbsp;1&nbsp;时需要远程冗余备份到其他节点。如&nbsp;DISK_ONLY_2&nbsp;需要远程备份&nbsp;1&nbsp;个副本。 13.3.2 RDD 缓存的过程   RDD 在缓存到存储内存之前，Partition 中的数据一般以迭代器（Iterator）的数据结构来访问，这是 Scala 语言中一种遍历数据集合的方法。通过 Iterator 可以获取分区中每一条序列化或者非序列化的数据项 (Record)，这些 Record 的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同 Record 的空间并不连续。   RDD 在缓存到存储内存之后，Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为 “展开”（Unroll）。Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 以一种 DeserializedMemoryEntry 的数据结构定义，用一个数组存储所有的对象实例，序列化的 Block 则以 SerializedMemoryEntry 的数据结构定义，用字节缓冲区（ByteBuffer）来存储二进制数据。每个 Executor 的 Storage 模块用一个链式 Map 结构（LinkedHashMap）来管理堆内和堆外存储内存中所有的 Block 对象的实例，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。   因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。而非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。如果最终 Unroll 成功，当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间，如下图所示。 Spark Unroll 示意图   在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，当存储空间不足时会根据动态占用机制进行处理。 13.3.3 淘汰和落盘   由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中的旧 Block 进行淘汰（Eviction），而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘（Drop），否则直接删除该 Block。   存储内存的淘汰规则为：   1）被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存。   2）新旧 Block 不能属于同一个 RDD，避免循环淘汰。   3）旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题。   4）遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性。   落盘的流程则比较简单，如果其存储级别符合_useDisk 为 true&nbsp;的条件，再根据其&nbsp;_deserialized&nbsp;判断是否是非序列化的形式，若是则对其进行序列化，最后将数据存储到磁盘，在 Storage 模块中更新其信息。 13.4 执行内存管理 13.4.1 多任务间内存分配   Executor 内运行的任务同样共享执行内存，Spark 用一个 HashMap 结构保存了任务到内存耗费的映射。每个任务可占用的执行内存大小的范围为 1/2N ~ 1/N，其中 N 为当前 Executor 内正在运行的任务的个数。每个任务在启动之时，要向 MemoryManager 请求申请最少为 1/2N 的执行内存，如果不能被满足要求则该任务被阻塞，直到有其他任务释放了足够的执行内存，该任务才可以被唤醒。 13.4.2 Shuffle 的内存占用   执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程，我们来看 Shuffle 的 Write 和 Read 两阶段对执行内存的使用：Shuffle Write   1）若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。   2）若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够。Shuffle Read   1）在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间。   2）如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter 处理，占用堆内执行空间。   在 ExternalSorter 和 Aggregator 中，Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据，但在 Shuffle 过程中所有数据并不能都保存到该哈希表中，当这个哈希表占用的内存会进行周期性地采样估算，当其大到一定程度，无法再从 MemoryManager 申请到新的执行内存时，Spark 就会将其全部内容存储到磁盘文件中，这个过程被称为溢存(Spill)，溢存到磁盘的文件最后会被归并(Merge)。   Shuffle Write 阶段中用到的 Tungsten 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，解决了一些 JVM 在性能上的限制和弊端。Spark 会根据 Shuffle 的情况来自动选择是否采用 Tungsten 排序。Tungsten 采用的页式内存管理机制建立在 MemoryManager 之上，即 Tungsten 对执行内存的使用进行了一步的抽象，这样在 Shuffle 过程中无需关心数据具体存储在堆内还是堆外。每个内存页用一个 MemoryBlock 来定义，并用 Object obj 和 long offset 这两个变量统一标识一个内存页在系统内存中的地址。堆内的 MemoryBlock 是以 long 型数组的形式分配的内存，其 obj 的值为是这个数组的对象引用，offset 是 long 型数组的在 JVM 中的初始偏移地址，两者配合使用可以定位这个数组在堆内的绝对地址；堆外的 MemoryBlock 是直接申请到的内存块，其 obj 为 null，offset 是这个内存块在系统内存中的 64 位绝对地址。Spark 用 MemoryBlock 巧妙地将堆内和堆外内存页统一抽象封装，并用页表(pageTable)管理每个 Task 申请到的内存页。   Tungsten 页式管理下的所有内存用 64 位的逻辑地址表示，由页号和页内偏移量组成：   页号：占 13 位，唯一标识一个内存页，Spark 在申请内存页之前要先申请空闲页号。   页内偏移量：占 51 位，是在使用内存页存储数据时，数据在页内的偏移地址。   有了统一的寻址方式，Spark 可以用 64 位逻辑地址的指针定位到堆内或堆外的内存，整个 Shuffle Write 排序的过程只需要对指针进行排序，并且无需反序列化，整个过程非常高效，对于内存访问效率和 CPU 使用效率带来了明显的提升。   Spark 的存储内存和执行内存有着截然不同的管理方式：对于存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；而对于执行内存，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。 回到顶部 第14章 部署模式解析 14.1 部署模式概述   Spark 支持的主要的三种分布式部署方式分别是 standalone、spark on mesos 和 spark on YARN。standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。它是 Spark 实现的资源调度框架，其主要的节点有 Client 节点、Master 节点和 Worker 节点。而 yarn 是统一的资源管理机制，在上面可以运行多套计算框架，如 map reduce、storm 等根据 driver 在集群中的位置不同，分为 yarn client 和 yarn cluster。而 mesos 是一个更强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括 yarn。基本上，Spark 的运行模式取决于传递给 SparkContext 的 MASTER 环境变量的值，个别模式还需要辅助的程序接口来配合使用，目前支持的 Master 字符串及 URL 包括：      用户在提交任务给 Spark 处理时，以下两个参数共同决定了 Spark 的运行方式：   • --master MASTER_URL ：决定了 Spark 任务提交给哪种集群处理。   • --deploy-mode DEPLOY_MODE ：决定了 Driver 的运行方式，可选值为 Client 或者 Cluster。 &nbsp; 14.2 standalone 框架   standalone 集群由三个不同级别的节点组成，分别是：   1）Master 主控节点，可以类比为董事长或总舵主，在整个集群之中，最多只有一个 Master 处在 Active 状态。   2）Worker 工作节点，这个是 manager，是分舵主， 在整个集群中，可以有多个 Worker，如果 Worker 为零，什么事也做不了。   3）Executor 干苦力活的，直接受 Worker 掌控，一个 Worker 可以启动多个 executor，启动的个数受限于机器中的 cpu 核数。   这三种不同类型的节点各自运行于自己的JVM进程之中。   Standalone 模式下，集群启动时包括 Master 与 Worker，其中 Master 负责接收客户端提交的作业，管理 Worker。根据作业提交的方式不同，分为 driver on client 和 drvier on worker。如下图所示，上图为 driver on client 模式，下图为 driver on work 模式。两种模式的主要不同点在于 driver 所在的位置。   在 standalone 部署模式下又分为 client 模式和 cluster 模式。   在client 模式下，driver 和 client 运行于同一 JVM 中，不由 worker 启动，该 JVM 进程直到 spark application 计算完成返回结果后才退出。如下图所示：      而在 cluster 模式下，driver 由 worker 启动，client 在确认 spark application 成功提交给 cluster 后直接退出，并不等待 spark application 运行结果返回。如下图所示：    从部署图来进行分析，每个 JVM 进程在启动时的文件依赖如何得到满足。   1）Master 进程最为简单，除了 spark jar 包之外，不存在第三方库依赖。   2）Driver 和 Executor 在运行的时候都有可能存在第三方包依赖，分开来讲。   3）Driver 比较简单，spark-submit 在提交的时候会指定所要依赖的 jar 文件从哪里读取。   4）Executor 由 Worker 来启动，Worker 需要下载 Executor 启动时所需要的 jar 文件，那么从哪里下载呢？   Spark Standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖其他资源管理系统。在该模式下，用户可以通过手动启动 Master 和 Worker 来启动一个独立的集群。其中，Master 充当了资源管理的角色，Workder 充当了计算节点的角色。在该模式下，Spark Driver 程序在客户端(Client)运行，而 Executor 则在 Worker 节点上运行。以下是一个运行在 Standalone 模式下，包含一个 Master 节点，两个 Worker 节点的 Spark 任务调度交互部署架构图。 从上面的 Spark 任务调度过程可以看到：   1）整个集群分为 Master 节点和 Worker 节点，其 Driver 程序运行在客户端。Master 节点负责为任务分配 Worker 节点上的计算资源，两者会通过相互通信来同步资源状态，见途中红色双向箭头。   2）客户端启动任务后会运行 Driver 程序，Driver 程序中会完成 SparkContext 对象的初始化，并向 Master 进行注册。   3）每个 Workder 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟客户端节点上的 Driver 程序进行通信，上报任务状态。 &nbsp; 14.2.1 Standalone 模式下任务运行过程   上面的过程反映了 Spark 在 standalone 模式下，整体上客户端、Master 和 Workder 节点之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。1）&nbsp;用户通过 bin/spark-submit 部署工具或者 bin/spark-class 启动应用程序的 Driver 进程，Driver 进程会初始化 SparkContext 对象，并向 Master 节点进行注册。   • 1、Master 节点接受 Driver 程序的注册，检查它所管理的 Worker 节点，为该 Driver 程序分配需要的计算资源 Executor。Worker 节点完成 Executor 的分配后，向 Master 报告 Executor 的状态。   • 2、Worker 节点上的 ExecutorBackend 进程启动后，向 Driver 进程注册。2）&nbsp;Driver 进程内部通过 DAG Schaduler、Stage Schaduler、Task Schaduler 等过程完成任务的划分后，向 Worker 节点上的 ExecutorBackend 分配 TASK。   • 1、ExecutorBackend 进行 TASK 计算，并向 Driver 报告 TASK 状态，直至结束。   • 2、Driver 进程在所有 TASK 都处理完成后，向 Master 注销。 14.2.2 总结   Spark 能够以 standalone 模式运行，这是 Spark 自身提供的运行模式，用户可以通过手动启动 master 和 worker 进程来启动一个独立的集群，也可以在一台机器上运行这些守护进程进行测试。standalone 模式可以用在生产环境，它有效的降低了用户学习、测试 Spark 框架的成本。   standalone 模式目前只支持跨应用程序的简单 FIFO 调度。然而，为了允许多个并发用户，你可以控制每个应用使用的资源的最大数。默认情况下，它会请求使用集群的全部 CUP 内核。   缺省情况下，standalone 任务调度允许 worker 的失败（在这种情况下它可以将失败的任务转移给其他的 worker）。但是，调度器使用 master 来做调度，这会产生一个单点问题：如果 master 崩溃，新的应用不会被创建。为了解决这个问题，可以通过 zookeeper 的选举机制在集群中启动多个 master，也可以使用本地文件实现单节点恢复。 14.3 yarn 集群模式   Apache yarn 是 apache Hadoop 开源项目的一部分。设计之初是为了解决 mapreduce 计算框架资源管理的问题。到 haodoop 2.0 使用 yarn 将 mapreduce 的分布式计算和资源管理区分开来。它的引入使得 Hadoop 分布式计算系统进入了平台化时代，即各种计算框架可以运行在一个集群中，由资源管理系统 YRAN 进行统一的管理和调度，从而共享整个集群资源、提高资源利用率。   YARN 总体上也 Master/Slave 架构--ResourceManager/NodeManager。前者(RM)负责对各个 NodeManager(NM) 上的资源进行统一管理和调度。而 Container 是资源分配和调度的基本单位，其中封装了机器资源，如内存、CPU、磁盘和网络等，每个任务会被分配一个 Container，该任务只能在该 Container 中执行，并使用该 Container 封装的资源。NodeManager 的作用则是负责接收并启动应用的 Container、而向 RM 回报本节点上的应用 Container 运行状态和资源使用情况。ApplicationMaster 与具体的 Application 相关，主要负责同 ResourceManager 协商以获取合适的 Container，并跟踪这些 Container 的状态和监控其进度。如下图所示为 yarn 集群的一般模型。 简单架构图如下：    详细架构图如下：      Spark 在 yarn 集群上的部署方式分为两种，yarn cluster（driver 运行在 master 上）和 yarn client（driver 运行在 client 上）。   driver on master&nbsp;如下图所示：      • (1) Spark Yarn Client 向 YARN 中提交应用程序，包括 Application Master 程序、启动 Application Master 的命令、需要在 Executor 中运行的程序等。   • (2) Resource manager 收到请求后，在其中一个 Node Manager 中为应用程序分配一个 Container，要求它在 Container 中启动应用程序的 Application Master，Application Master 初始化 sparkContext 以及创建 DAG Scheduler 和 Task Scheduler。   • (3) Application Master 根据 SparkContext 中的配置，向 Resource Manager 申请 Container，同时，Application Master 向 Resource Manager 注册，这样用户可通过 Resource Manager 查看应用程序的运行状态。   • (4) Resource Manager 在集群中寻找符合条件的 Node Manager，在 Node Manager 启动 Container，要求 Container 启动 Executor。   • (5) Executor 启动后向 Application Master 注册，并接收 Application Master 分配的 Task。   • (6) 应用程序运行完成后，Application Master 向 Resource Manager 申请注销并关闭自己。   driver on client&nbsp;如下图所示：      • (1) Spark Yarn Client 向 YARN 的 Resource Manager 申请启动 Application Master。同时在 SparkContent 初始化中将创建 DAG Scheduler 和 Task Scheduler 等。   • (2) ResourceManager 收到请求后，在集群中选择一个 NodeManager，为该应用程序分配第一个 Container，要求它在这个 Container 中启动应用程序的 ApplicationMaster，与 YARN-Cluster 区别的是在该 ApplicationMaster 不运行 SparkContext，只与 SparkContext 进行联系进行资源的分派。   • (3) Client 中的 SparkContext 初始化完毕后，与 Application Master 建立通讯，向 Resource Manager 注册，根据任务信息向 Resource Manager 申请资源 (Container)。   • (4) 当 Application Master 申请到资源后，便与 Node Manager 通信，要求它启动 Container。   • (5) Container 启动后向 Driver 中的 SparkContext 注册，并申请 Task。   • (6) 应用程序运行完成后，Client 的 SparkContext 向 ResourceManage r申请注销并关闭自己。 &nbsp;   Yarn-client 和Yarn cluster 模式对比可以看出，在 Yarn-client（Driver on client）中，Application Master 仅仅从 Yarn 中申请资源给 Executor，之后 client 会跟 container 通信进行作业的调度。如果 client 离集群距离较远，建议不要采用此方式，不过此方式有利于交互式的作业。　　      Spark 能够以集群的形式运行，可用的集群管理系统有 Yarn、Mesos 等。集群管理器的核心功能是资源管理和任务调度。以 Yarn 为例，Yarn 以 Master/Slave 模式工作，在 Master 节点运行的是 Resource Manager(RM)，负责管理整个集群的资源和资源分配。在 Slave 节点运行的 Node Manager(NM)，是集群中实际拥有资源的工作节点。我们提交 Job 以后，会将组成 Job 的多个 Task 调度到对应的 Node Manager 上进行执行。另外，在 Node Manager 上将资源以 Container 的形式进行抽象，Container 包括两种资源 内存 和 CPU。   以下是一个运行在 Yarn 集群上，包含一个 Resource Manager 节点，三个 Node Manager 节点(其中，两个是 Worker 节点，一个 Master 节点)的 Spark 任务调度交换部署架构图。　 从上面的Spark任务调度过程图可以看到:   1）整个集群分为 Master 节点和 Worker 节点，它们都存在于 Node Manager 节点上，在客户端提交任务时由 Resource Manager 统一分配，运行 Driver 程序的节点被称为 Master 节点，执行具体任务的节点被称为 Worder 节点。Node Manager 节点上资源的变化都需要及时更新给 Resource Manager，见图中红色双向箭头。   2）Master 节点上常驻 Master 守护进程 -- Driver 程序，Driver 程序中会创建 SparkContext对 象，并负责跟各个 Worker 节点上的 ExecutorBackend 进程进行通信，管理 Worker 节点上的任务，同步任务进度。实际上，在 Yarn 中 Node Manager 之间的关系是平等的，因此 Driver 程序会被调度到任何一个 Node Manager 节点。   3）每个 Worker 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟 Master 节点上的 Driver 程序进行通信，上报任务状态。　　 &nbsp; 集群下任务运行过程   上面的过程反映出了 Spark 在集群模式下，整体上 Resource Manager 和 Node Manager 节点间的交互，Master 和 Worker 之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。   • 1) 用户通过 bin/spark-submit 部署工具或者 bin/spark-class 向 Yarn 集群提交应用程序。   • 2) Yarn 集群的 Resource Manager 为提交的应用程序选择一个 Node Manager 节点并分配第一个 Container，并在该节点的 Container 上启动 SparkContext 对象。   • 3) SparkContext 对象向 Yarn 集群的 Resource Manager 申请资源以运行 Executor。   • 4) Yarn 集群的 Resource Manager 分配 Container 给 SparkContext 对象，SparkContext 和相关的 Node Manager 通讯，在获得的 Container 上启动 ExecutorBackend 守护进程，ExecutorBackend 启动后开始向 SparkContext 注册并申请 Task。   • 5) SparkContext 分配 Task 给 ExecutorBackend 执行。   • 6) ExecutorBackend 开始执行 Task，并及时向 SparkContext 汇报运行状况。Task 运行完毕，SparkContext 归还资源给 Node Manager，并注销退。 14.4 mesos 集群模式   Mesos 是 apache 下的开源分布式资源管理框架。起源于加州大学伯克利分校，后被 Twitter 推广使用。Mesos 上可以部署多种分布式框架，Mesos 的架构图如下图所示，其中 Framework 是指外部的计算框架，如 Hadoop、Mesos 等，这些计算框架可通过注册的方式接入 Mesos，以便 Mesos 进行统一管理和资源分配。      在 Mesos 上运行的 Framework 由两部分组成：一个是 scheduler ，通过注册到 Master 来获取集群资源。另一个是在 Slave 节点上运行的 executor 进程，它可以执行 Framework 的 task 。 Master 决定为每个 Framework 提供多少资源，Framework 的 scheduler 来选择其中提供的资源。当 Framework 同意了提供的资源，它通过 Master 将 task 发送到提供资源的 Slaves 上运行。Mesos c的资源分配图如下图所示：      (1) Slave1 向 Master 报告，有 4 个 CPU 和 4 GB 内存可用。   (2) Master 发送一个 Resource Offer 给 Framework1 来描述 Slave1 有多少可用资源。   (3) FrameWork1 中的 FW Scheduler 会答复 Master，我有两个 Task 需要运行在 Slave1，一个 Task 需要&nbsp;&lt;2个CPU，1 GB内存=&quot;&quot;&gt;，另外一个 Task 需要&nbsp;&lt;1个CPU，2 GB内存=&quot;&quot;&gt;。   (4) 最后，Master 发送这些 Tasks 给 Slave1。然后，Slave1 还有 1 个 CPU 和 1GB 内存没有使用，所以分配模块可以把这些资源提供给 Framework2。 &nbsp;   Spark 可作为其中一个分布式框架部署在 mesos 上，部署图与 mesos 的一般框架部署图类似，如下图所示，这里不再重述。 14.5 spark 三种部署模式的区别   在这三种部署模式中，standalone 作为 spark 自带的分布式部署模式，是最简单也是最基本的 spark 应用程序部署模式，这里就不再赘述。这里就讲一下 yarn 和 mesos 的区别：   (1) 就两种框架本身而言，mesos上可部署 yarn 框架。而 yarn 是更通用的一种部署框架，而且技术较成熟。   (2) mesos 双层调度机制，能支持多种调度模式，而 yarn 通过 Resource　Mananger 管理集群资源，只能使用一种调度模式。Mesos 的双层调度机制为：mesos 可接入如 yarn 一般的分布式部署框架，但 Mesos 要求可接入的框架必须有一个调度器模块，该调度器负责框架内部的任务调度。当一个 Framework 想要接入 mesos 时，需要修改自己的调度器，以便向 mesos 注册，并获取 mesos 分配给自己的资源，这样再由自己的调度器将这些资源分配给框架中的任务，也就是说，整个 mesos 系统采用了双层调度框架：第一层，由 mesos 将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。   (3) mesos 可实现粗、细粒度资源调度，可动态分配资源，而 yarn 只能实现静态资源分配。其中粗粒度和细粒度调度定义如下：   粗粒度模式（Coarse-grained Mode）：程序运行之前就要把所需要的各种资源（每个 executor 占用多少资源，内部可运行多少个 executor）申请好，运行过程中不能改变。   细粒度模式（Fine-grained Mode）：为了防止资源浪费，对资源进行按需分配。与粗粒度模式一样，应用程序启动时，先会启动 executor，但每个 executor 占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos 会为每个 executor 动态分配资源，每分配一些，便可以运行一个新任务，单个 Task 运行完之后可以马上释放对应的资源。每个 Task 会汇报状态给 Mesos Slave 和 Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于 MapReduce 调度模式，每个 Task 完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。   从 yarn 和 mesos 的区别可看出，它们各自有优缺点。因此实际使用中，选择哪种框架，要根据本公司的实际需要而定，可考虑现有的大数据生态环境。如我司采用 yarn 部署 spark，原因是，我司早已有较成熟的 hadoop 的框架，考虑到使用的方便性，采用了 yarn 模式的部署。 14.6 异常场景分析 上面说明的是正常情况下，各节点的消息分发细节。那么如果在运行中，集群中的某些节点出现了问题，整个集群是否还能够正常处理 Application 中的任务呢？ 14.6.1 异常分析1：Worker 异常退出 在 Spark 运行过程中，经常碰到的问题就是 Worker 异常退出，当 Worker 退出时，整个集群会有哪些故事发生呢？请看下面的具体描述：   1）Worker 异常退出，比如说有意识的通过 kill 指令将 Worker 杀死。   2）Worker 在退出之前，会将自己所管控的所有小弟 Executor 全干掉。   3）Worker 需要定期向 Master 改善心跳消息的，现在 Worker 进程都已经玩完了，哪有心跳消息，所以 Master 会在超时处理中意识到有一个 “分舵” 离开了。   4）Master 非常伤心，伤心的 Master 将情况汇报给了相应的 Driver。 Driver 通过两方面确认分配给自己的 Executor 不幸离开了，一是 Master 发送过来的通知，二是 Driver 没有在规定时间内收到 Executor 的 StatusUpdate，于是 Driver 会将注册的 Executor 移除。 后果分析 Worker 异常退出会带来哪些影响：   1）Executor 退出导致提交的 Task 无法正常结束，会被再一次提交运行。   2）如果所有的 Worker 都异常退出，则整个集群不可用。   3）需要有相应的程序来重启 Worker 进程，比如使用 supervisord 或 runit。 测试步骤   1）启动 Master。   2）启动 Worker。   3）启动 spark-shell。   4）手工 kill 掉 Worker 进程。   5）用 jps 或 ps -ef | grep -i java 来查看启动着的 java 进程。 异常退出的代码处理 定义 ExecutorRunner.scala 的 start 函数 def&nbsp;start()&nbsp;{ &nbsp;&nbsp;workerThread&nbsp;=&nbsp;new&nbsp;Thread(&quot;ExecutorRunner&nbsp;for&nbsp;&quot;&nbsp;+&nbsp;fullId)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;run()&nbsp;{&nbsp;fetchAndRunExecutor()&nbsp;} &nbsp;&nbsp;} &nbsp;&nbsp;workerThread.start() &nbsp;&nbsp;//&nbsp;Shutdown&nbsp;hook&nbsp;that&nbsp;kills&nbsp;actors&nbsp;on&nbsp;shutdown. &nbsp;&nbsp;shutdownHook&nbsp;=&nbsp;new&nbsp;Thread()&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;override&nbsp;def&nbsp;run()&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(Some(&quot;Worker&nbsp;shutting&nbsp;down&quot;)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;} &nbsp;&nbsp;Runtime.getRuntime.addShutdownHook(shutdownHook) } killProcess 的过程就是停止相应 CoarseGrainedExecutorBackend 的过程。 Worker 停止的时候，一定要先将自己启动的 Executor 停止掉。这是不是很像水浒中宋江的手段，李逵就是这样不明不白的把命给丢了。 小结   需要特别指出的是，当 Worker 在启动 Executor 的时候，是通过 ExecutorRunner 来完成的，ExecutorRunner 是一个独立的线程，和 Executor 是一对一的关系，这很重要。Executor 作为一个独立的进程在运行，但会受到 ExecutorRunner 的严密监控。 14.6.2 异常分析2：Executor 异常退出 后果分析 Executor 作为 Standalone 集群部署方式下的最底层员工，一旦异常退出，其后果会是什么呢？   1）Executor 异常退出，ExecutorRunner 注意到异常，将情况通过 ExecutorStateChanged 汇报给 Master。   2）Master 收到通知之后，非常不高兴，尽然有小弟要跑路，那还了得，要求 Executor 所属的 Worker 再次启动。   3）Worker 收到 LaunchExecutor 指令，再次启动 Executor。 测试步骤   1）启动 Master   2）启动 Worker   3）启动 spark-shell   4）手工 kill 掉 CoarseGrainedExecutorBackend fetchAndRunExecutor fetchAndRunExecutor 负责启动具体的 Executor，并监控其运行状态，具体代码逻辑如下所示 def&nbsp;fetchAndRunExecutor()&nbsp;{ &nbsp;&nbsp;try&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Create&nbsp;the&nbsp;executor&#39;s&nbsp;working&nbsp;directory &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;executorDir&nbsp;=&nbsp;new&nbsp;File(workDir,&nbsp;appId&nbsp;+&nbsp;&quot;/&quot;&nbsp;+&nbsp;execId) &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(!executorDir.mkdirs())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;throw&nbsp;new&nbsp;IOException(&quot;Failed&nbsp;to&nbsp;create&nbsp;directory&nbsp;&quot;&nbsp;+&nbsp;executorDir) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;Launch&nbsp;the&nbsp;process &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;command&nbsp;=&nbsp;getCommandSeq &nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Launch&nbsp;command:&nbsp;&quot;&nbsp;+&nbsp;command.mkString(&quot;\\&quot;&quot;,&nbsp;&quot;\\&quot;&nbsp;\\&quot;&quot;,&nbsp;&quot;\\&quot;&quot;)) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;builder&nbsp;=&nbsp;new&nbsp;ProcessBuilder(command:&nbsp;_*).directory(executorDir) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;env&nbsp;=&nbsp;builder.environment() &nbsp;&nbsp;&nbsp;&nbsp;for&nbsp;((key,&nbsp;value)&nbsp;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(&quot;Runner&nbsp;thread&nbsp;for&nbsp;executor&nbsp;&quot;&nbsp;+&nbsp;fullId&nbsp;+&nbsp;&quot;&nbsp;interrupted&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state&nbsp;=&nbsp;ExecutorState.KILLED &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(None) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;case&nbsp;e:&nbsp;Exception&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logError(&quot;Error&nbsp;running&nbsp;executor&quot;,&nbsp;e) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state&nbsp;=&nbsp;ExecutorState.FAILED &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(Some(e.toString)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;} } 14.6.3 异常分析3：Master 异常退出 Worker 和 Executor 异常退出的场景都讲到了，我们剩下最后一种情况了，Master 挂掉了怎么办？ 后果分析 带头大哥如果不在了，会是什么后果呢？   1）Worker 没有汇报的对象了，也就是如果 Executor 再次跑飞，Worker 是不会将 Executor 启动起来的，大哥没给指令。   2）无法向集群提交新的任务。   3）老的任务即便结束了，占用的资源也无法清除，因为资源清除的指令是 Master 发出的。 回到顶部 第15章 wordcount 程序运行原理窥探 15.1 spark 之 scala 实现 wordcount 在 spark 中使用 scala 来实现 wordcount（统计单词出现次数模型）更加简单，相对 java 代码上更加简洁，其函数式编程的思维逻辑也更加直观。 package&nbsp;com.spark.firstApp import&nbsp;org.apache.spark.{SparkContext,&nbsp;SparkConf} /** &nbsp;&nbsp;*&nbsp;scala&nbsp;实现&nbsp;wordcount &nbsp;&nbsp;*/ object&nbsp;WordCount1&nbsp;{ &nbsp;&nbsp;def&nbsp;main(args:&nbsp;Array[String])&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;if&nbsp;(args.length&nbsp;==&nbsp;0)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;System.err.println(&quot;Usage:&nbsp;WordCount1&nbsp;&lt;file1&gt;&quot;) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;System.exit(1) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;/** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;1、实例化&nbsp;SparkConf &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;2、构建&nbsp;SparkContext，SparkContext&nbsp;是&nbsp;spark&nbsp;应用程序的唯一入口 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;3.&nbsp;通过&nbsp;SparkContext&nbsp;的&nbsp;textFile&nbsp;方法读取文本文件 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;conf&nbsp;=&nbsp;new&nbsp;SparkConf().setAppName(&quot;WordCount1&quot;).setMaster(&quot;local&quot;) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sc&nbsp;=&nbsp;new&nbsp;SparkContext(conf) &nbsp;&nbsp;&nbsp;&nbsp;/** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;4、通过&nbsp;flatMap&nbsp;对文本中每一行的单词进行拆分（分割符号为空格），并利用&nbsp;map&nbsp;进行函数转换形成&nbsp;(K,V)&nbsp;对形式，再进行&nbsp;reduceByKey，打印输出&nbsp;10&nbsp;个结果 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;&nbsp;&nbsp;&nbsp;函数式编程更加直观的反映思维逻辑 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/ &nbsp;&nbsp;&nbsp;&nbsp;sc.textFile(args(0)).flatMap(_.split(&quot;&nbsp;&quot;)).map(x&nbsp;=&gt;&nbsp;(x,&nbsp;1)).reduceByKey(_&nbsp;+&nbsp;_).take(10).foreach(println) &nbsp;&nbsp;&nbsp;&nbsp;sc.stop() &nbsp;&nbsp;} } 15.2 原理窥探 在 spark 集群中运行 wordcount 程序其主要业务逻辑比较简单，涵盖一下 3 个过程：   1）读取存储介质上的文本文件（一般存储在 hdfs 上）；   2）对文本文件内容进行解析，按照单词进行分组统计汇总；   3）将过程 2 的分组结果保存到存储介质上。（一般存储在 hdfs 或者 RMDB 上） 虽然 wordcount 的业务逻辑非常简单，但其应用程序在 spark 中的运行过程却巧妙得体现了 spark 的核心精髓--分布式弹性数据集、内存迭代以及函数式编程等特点。下图对 spark 集群中 wordcount 的运行过程进行剖析，加深对 spark 技术原理窥探。   该图横向分割下面给出了 wordcount 的 scala 核心程序实现，该程序在 spark 集群的运行过程涉及几个核心的 RDD，主要有 textFileRDD、flatMapRDD、mapToPairRDD、shuffleRDD（reduceByKey）等。   应用程序通过 textFile 方法读取 hdfs 上的文本文件，数据分片的形式以 RDD 为统一模式将数据加载到不同的物理节点上，如上图所示的节点 1、节点 2 到节点 n；并通过一系列的数据转换，如利用 flatMap 将文本文件中对应每行数据进行拆分（文本文件中单词以空格为分割符号），形成一个以每个单词为核心新的数据集合 RDD；之后通过 MapRDD 继续转换形成形成 (K,V) 对 数据形式，以便进一步使用 reduceByKey 方法，该方法会触发 shuffle 行为，促使不同的单词到对应的节点上进行汇聚统计（实际上在夸节点进行数据 shuffle 之前会在本地先对相同单词进行合并累加），形成 wordcount 的统计结果；最终通过 saveAsTextFile 方法将数据保存到 hdfs 上。具体的运行逻辑原理以及过程上图给出了详细的示意说明。 我的GitHub地址：https://github.com/heizemingjun 我的博客园地址：https://www.cnblogs.com/chenmingjun 我的CSDN地址：https://blog.csdn.net/u012990179&nbsp; 我的蚂蚁笔记博客地址：https://blog.leanote.com/chenmingjun Copyright ©2018-2019 黑泽明军【转载文章务必保留出处和署名，谢谢！】","@type":"BlogPosting","url":"https://mlh.app/2019/05/04/729870.html","headline":"大数据技术之_19_Spark学习_06_Spark 源码解析 + Spark 通信架构、脚本解析、standalone 模式启动、提交流程 + Spark Shuffle 过程 + Spark 内存","dateModified":"2019-05-04T00:00:00+08:00","datePublished":"2019-05-04T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/04/729870.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>大数据技术之_19_Spark学习_06_Spark 源码解析 + Spark 通信架构、脚本解析、standalone 模式启动、提交流程 + Spark Shuffle 过程 + Spark 内存</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p style="margin-left:10px;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html" rel="nofollow">https://www.cnblogs.com/chenmingjun/p/10803261.html</a></p> 
  <p style="margin-left:10px;"><span style="color:#393939;"><span style="color:#152e97;"><strong>文章目录</strong></span></span></p> 
  <ul style="margin-left:30px;">
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0" rel="nofollow">第1章 Spark 整体概述</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_0" rel="nofollow">1.1 整体概念</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_1" rel="nofollow">1.2 RDD 抽象</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_2" rel="nofollow">1.3 计算抽象</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_3" rel="nofollow">1.4 集群模式</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_4" rel="nofollow">1.5 RPC 网络通信抽象</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_5" rel="nofollow">1.6 启动 Standalone 集群</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_6" rel="nofollow">1.7 核心组件</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_7" rel="nofollow">1.8 核心组件交互流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_8" rel="nofollow">1.9 Block 管理</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label0_9" rel="nofollow">1.10整体应用</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label1" rel="nofollow">第2章 Spark 通信架构</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label1_0" rel="nofollow">2.1 通信组件概览</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label1_1" rel="nofollow">2.2 Endpoint 启动过程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label1_2" rel="nofollow">2.3 Endpoint Send&amp;Ask 流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label1_3" rel="nofollow">2.4 Endpoint Receive 流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label1_4" rel="nofollow">2.5 Endpoint Inbox 处理流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label1_5" rel="nofollow">2.6 Endpoint 画像</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label2" rel="nofollow">第3章 脚本解析</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label2_0" rel="nofollow">3.1 start-daemon.sh</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label2_1" rel="nofollow">3.2 spark-class</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label2_2" rel="nofollow">3.3 start-master.sh</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label2_3" rel="nofollow">3.4 start-slaves.sh</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label2_4" rel="nofollow">3.5 start-all.sh</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label2_5" rel="nofollow">3.6 spark-submit</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label3" rel="nofollow">第4章 Master 节点启动</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label3_0" rel="nofollow">4.1 脚本概览</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label3_1" rel="nofollow">4.2 启动流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label3_2" rel="nofollow">4.3 OnStart 监听事件</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label3_3" rel="nofollow">4.4 RpcMessage 处理 (receiveAndReply)</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label3_4" rel="nofollow">4.5 OneWayMessage 处理 (receive)</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label3_5" rel="nofollow">4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label4" rel="nofollow">第5章 Worker 节点启动</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label4_0" rel="nofollow">5.1 脚本概览</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label4_1" rel="nofollow">5.2 启动流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label4_2" rel="nofollow">5.3 OnStart 监听事件</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label4_3" rel="nofollow">5.4 RpcMessage 处理 (receiveAndReply)</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label4_4" rel="nofollow">5.5 OneWayMessage 处理 (receive)</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label5" rel="nofollow">第6章 Client 启动流程</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label5_0" rel="nofollow">6.1 脚本概览</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label5_1" rel="nofollow">6.2 SparkSubmit 启动流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label5_2" rel="nofollow">6.3 Client 启动流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label5_3" rel="nofollow">6.4 Client 的 OnStart 监听事件</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label5_4" rel="nofollow">6.5 RpcMessage 处理 (receiveAndReply)</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label5_5" rel="nofollow">6.6 OneWayMessage 处理(receive)</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label6" rel="nofollow">第7章 Driver 和 DriverRunner</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label6_0" rel="nofollow">7.1 Master 对 Driver 资源分配</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label6_1" rel="nofollow">7.2 Worker 运行 DriverRunner</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label6_2" rel="nofollow">7.3 DriverRunner 创建并运行 DriverWrapper</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label7" rel="nofollow">第8章 SparkContext 解析</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label7_0" rel="nofollow">8.1 SparkContext 解析</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label7_1" rel="nofollow">8.2 SparkContext 创建过程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label7_2" rel="nofollow">8.3 SparkContext 简易结构与交互关系</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label7_3" rel="nofollow">8.4 Master 对 Application 资源分配</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label7_4" rel="nofollow">8.5 Worker 创建 Executor</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label8" rel="nofollow">第9章 Job 提交和 Task 的拆分</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label8_0" rel="nofollow">9.1 整体预览</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label8_1" rel="nofollow">9.2 Code 转化为初始 RDDs</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label8_2" rel="nofollow">9.3 RDD 分解为待执行任务集合（TaskSet）</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label8_3" rel="nofollow">9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label8_4" rel="nofollow">9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label9" rel="nofollow">第10章 Task 执行和回馈</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label9_0" rel="nofollow">10.1 Task 的执行流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label9_1" rel="nofollow">10.2 Task 的回馈流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label9_2" rel="nofollow">10.3 Task 的迭代流程</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label9_3" rel="nofollow">10.4 精彩图解</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10" rel="nofollow">第11章 Spark 的数据存储</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10_0" rel="nofollow">11.1 存储子系统概览</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10_1" rel="nofollow">11.2 启动过程分析</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10_2" rel="nofollow">11.3 通信层</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10_3" rel="nofollow">11.4 存储层</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10_4" rel="nofollow">11.5 数据写入过程分析</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10_5" rel="nofollow">11.6 数据读取过程分析</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10_6" rel="nofollow">11.7 Partition 如何转化为 Block</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label10_7" rel="nofollow">11.8 partition 和 block 的对应关系</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label11" rel="nofollow">第12章 Spark Shuffle 过程</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label11_0" rel="nofollow">12.1 MapReduce 的 Shuffle 过程介绍</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label11_1" rel="nofollow">12.2 HashShuffle 过程介绍</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label11_2" rel="nofollow">12.3 SortShuffle 过程介绍</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label11_3" rel="nofollow">12.4 TungstenShuffle 过程介绍</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label11_4" rel="nofollow">12.5 MapReduce 与 Spark 过程对比</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label12" rel="nofollow">第13章 Spark 内存管理</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label12_0" rel="nofollow">13.1 堆内和堆外内存规划</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label12_1" rel="nofollow">13.2 内存空间分配</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label12_2" rel="nofollow">13.3 存储内存管理</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label12_3" rel="nofollow">13.4 执行内存管理</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label13" rel="nofollow">第14章 部署模式解析</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label13_0" rel="nofollow">14.1 部署模式概述</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label13_1" rel="nofollow">14.2 standalone 框架</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label13_2" rel="nofollow">14.3 yarn 集群模式</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label13_3" rel="nofollow">14.4 mesos 集群模式</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label13_4" rel="nofollow">14.5 spark 三种部署模式的区别</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label13_5" rel="nofollow">14.6 异常场景分析</a></span></span></li> 
    </ul></li> 
   <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label14" rel="nofollow">第15章 wordcount 程序运行原理窥探</a></span></span> 
    <ul style="margin-left:30px;">
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label14_0" rel="nofollow">15.1 spark 之 scala 实现 wordcount</a></span></span></li> 
     <li><span style="color:#393939;"><span style="color:#152e97;"><a href="#_label14_1" rel="nofollow">15.2 原理窥探</a></span></span></li> 
    </ul></li> 
  </ul>
  <p style="margin-left:10px;"><span style="color:#393939;">&nbsp;</span></p> 
  <hr>
  <p id="tocid_0" style="margin-left:25px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1spark" rel="nofollow">第1章 Spark 整体概述</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h11" rel="nofollow">1.1 整体概念</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h12rdd" rel="nofollow">1.2 RDD 抽象</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h13" rel="nofollow">1.3 计算抽象</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h14" rel="nofollow">1.4 集群模式</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h15rpc" rel="nofollow">1.5 RPC 网络通信抽象</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h16standalone" rel="nofollow">1.6 启动 Standalone 集群</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h17" rel="nofollow">1.7 核心组件</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h18" rel="nofollow">1.8 核心组件交互流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h19block" rel="nofollow">1.9 Block 管理</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h110" rel="nofollow">1.10整体应用</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h2spark" rel="nofollow">第2章 Spark 通信架构</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h21" rel="nofollow">2.1 通信组件概览</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h22endpoint" rel="nofollow">2.2 Endpoint 启动过程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h23endpointsendask" rel="nofollow">2.3 Endpoint Send&amp;Ask 流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h24endpointreceive" rel="nofollow">2.4 Endpoint Receive 流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h25endpointinbox" rel="nofollow">2.5 Endpoint Inbox 处理流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h26endpoint" rel="nofollow">2.6 Endpoint 画像</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h3" rel="nofollow">第3章 脚本解析</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h31startdaemonsh" rel="nofollow">3.1 start-daemon.sh</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h32sparkclass" rel="nofollow">3.2 spark-class</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h33startmastersh" rel="nofollow">3.3 start-master.sh</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h34startslavessh" rel="nofollow">3.4 start-slaves.sh</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h35startallsh" rel="nofollow">3.5 start-all.sh</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h36sparksubmit" rel="nofollow">3.6 spark-submit</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h4master" rel="nofollow">第4章 Master 节点启动</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h41" rel="nofollow">4.1 脚本概览</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h42" rel="nofollow">4.2 启动流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h43onstart" rel="nofollow">4.3 OnStart 监听事件</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h44rpcmessagereceiveandreply" rel="nofollow">4.4 RpcMessage 处理 (receiveAndReply)</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h45onewaymessagereceive" rel="nofollow">4.5 OneWayMessage 处理 (receive)</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h46masterrpcmessageonewaymessage" rel="nofollow">4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h5worker" rel="nofollow">第5章 Worker 节点启动</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h51" rel="nofollow">5.1 脚本概览</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h52" rel="nofollow">5.2 启动流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h53onstart" rel="nofollow">5.3 OnStart 监听事件</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h54rpcmessagereceiveandreply" rel="nofollow">5.4 RpcMessage 处理 (receiveAndReply)</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h55onewaymessagereceive" rel="nofollow">5.5 OneWayMessage 处理 (receive)</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h6client" rel="nofollow">第6章 Client 启动流程</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h61" rel="nofollow">6.1 脚本概览</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h62sparksubmit" rel="nofollow">6.2 SparkSubmit 启动流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h63client" rel="nofollow">6.3 Client 启动流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h64clientonstart" rel="nofollow">6.4 Client 的 OnStart 监听事件</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h65rpcmessagereceiveandreply" rel="nofollow">6.5 RpcMessage 处理 (receiveAndReply)</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h66onewaymessagereceive" rel="nofollow">6.6 OneWayMessage 处理(receive)</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h7driverdriverrunner" rel="nofollow">第7章 Driver 和 DriverRunner</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h71masterdriver" rel="nofollow">7.1 Master 对 Driver 资源分配</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h72workerdriverrunner" rel="nofollow">7.2 Worker 运行 DriverRunner</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h73driverrunnerdriverwrapper" rel="nofollow">7.3 DriverRunner 创建并运行 DriverWrapper</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h8sparkcontext" rel="nofollow">第8章 SparkContext 解析</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h81sparkcontext" rel="nofollow">8.1 SparkContext 解析</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h82sparkcontext" rel="nofollow">8.2 SparkContext 创建过程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h83sparkcontext" rel="nofollow">8.3 SparkContext 简易结构与交互关系</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h84masterapplication" rel="nofollow">8.4 Master 对 Application 资源分配</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h85workerexecutor" rel="nofollow">8.5 Worker 创建 Executor</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h9jobtask" rel="nofollow">第9章 Job 提交和 Task 的拆分</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h91" rel="nofollow">9.1 整体预览</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h92coderdds" rel="nofollow">9.2 Code 转化为初始 RDDs</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h93rddtaskset" rel="nofollow">9.3 RDD 分解为待执行任务集合（TaskSet）</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h94tasksettasksetmanagerdriver" rel="nofollow">9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h95drivertasksetmanagertaskdescriptionsexecutor" rel="nofollow">9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h10task" rel="nofollow">第10章 Task 执行和回馈</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h101task" rel="nofollow">10.1 Task 的执行流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h102task" rel="nofollow">10.2 Task 的回馈流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h103task" rel="nofollow">10.3 Task 的迭代流程</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h104" rel="nofollow">10.4 精彩图解</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h11spark" rel="nofollow">第11章 Spark 的数据存储</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h111" rel="nofollow">11.1 存储子系统概览</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h112" rel="nofollow">11.2 启动过程分析</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h113" rel="nofollow">11.3 通信层</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h114" rel="nofollow">11.4 存储层</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1141diskstore" rel="nofollow">11.4.1 Disk Store</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1142memorystore" rel="nofollow">11.4.2 Memory Store</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h115" rel="nofollow">11.5 数据写入过程分析</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1151" rel="nofollow">11.5.1 序列化与否</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h116" rel="nofollow">11.6 数据读取过程分析</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1161" rel="nofollow">11.6.1 本地读取</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1162" rel="nofollow">11.6.2 远程读取</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h117partitionblock" rel="nofollow">11.7 Partition 如何转化为 Block</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h118partitionblock" rel="nofollow">11.8 partition 和 block 的对应关系</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h12sparkshuffle" rel="nofollow">第12章 Spark Shuffle 过程</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h121mapreduceshuffle" rel="nofollow">12.1 MapReduce 的 Shuffle 过程介绍</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1211spill" rel="nofollow">12.1.1 Spill 过程(刷写过程)</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1212merge" rel="nofollow">12.1.2 Merge</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1213copy" rel="nofollow">12.1.3 Copy</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1214mergesort" rel="nofollow">12.1.4 Merge Sort</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h122hashshuffle" rel="nofollow">12.2 HashShuffle 过程介绍</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h123sortshuffle" rel="nofollow">12.3 SortShuffle 过程介绍</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h124tungstenshuffle" rel="nofollow">12.4 TungstenShuffle 过程介绍</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h125mapreducespark" rel="nofollow">12.5 MapReduce 与 Spark 过程对比</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h13spark" rel="nofollow">第13章 Spark 内存管理</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h131" rel="nofollow">13.1 堆内和堆外内存规划</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1311" rel="nofollow">13.1.1 堆内内存</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1312" rel="nofollow">13.1.2 堆外内存</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1313" rel="nofollow">13.1.3 内存管理接口</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h132" rel="nofollow">13.2 内存空间分配</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1321" rel="nofollow">13.2.1 静态内存管理</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1322" rel="nofollow">13.2.2 统一内存管理</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h133" rel="nofollow">13.3 存储内存管理</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1331rdd" rel="nofollow">13.3.1 RDD 的持久化机制</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1332rdd" rel="nofollow">13.3.2 RDD 缓存的过程</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1333" rel="nofollow">13.3.3 淘汰和落盘</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h134" rel="nofollow">13.4 执行内存管理</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1341" rel="nofollow">13.4.1 多任务间内存分配</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1342shuffle" rel="nofollow">13.4.2 Shuffle 的内存占用</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h14-1" rel="nofollow">第14章 部署模式解析</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h141" rel="nofollow">14.1 部署模式概述</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h142standalone" rel="nofollow">14.2 standalone 框架</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1421standalone" rel="nofollow">14.2.1 Standalone 模式下任务运行过程</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h1422" rel="nofollow">14.2.2 总结</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h143yarn" rel="nofollow">14.3 yarn 集群模式</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h144mesos" rel="nofollow">14.4 mesos 集群模式</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h145spark" rel="nofollow">14.5 spark 三种部署模式的区别</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h146" rel="nofollow">14.6 异常场景分析</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h14611worker" rel="nofollow">14.6.1 异常分析1：Worker 异常退出</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h14622executor" rel="nofollow">14.6.2 异常分析2：Executor 异常退出</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h14633master" rel="nofollow">14.6.3 异常分析3：Master 异常退出</a></span></span></span></span><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h15wordcount" rel="nofollow">第15章 wordcount 程序运行原理窥探</a></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h151sparkscalawordcount" rel="nofollow">15.1 spark 之 scala 实现 wordcount</a></span></span></span><span style="color:inherit;"><span style="color:inherit;"><span style="color:inherit;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#h152" rel="nofollow">15.2 原理窥探</a></span></span></span></span></span></span></p> 
  <hr>
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label0"></a></span></span></p> 
  <h2 id="h1spark" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第1章 Spark 整体概述</strong></span></span></strong></span></span></h2> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCqr4.png"><a name="_label0_0"></a></span></span></p> 
  <h3 id="h11" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.1 整体概念</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Apache Spark 是一个开源的通用集群计算系统，它提供了 High-level 编程 API，支持 Scala、Java 和 Python 三种编程语言。Spark 内核使用 Scala 语言编写，通过基于 Scala 的函数式编程特性，在不同的计算层面进行抽象，<code>代码设计非常优秀</code>。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_1"></a></span></span></p> 
  <h3 id="h12rdd" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.2 RDD 抽象</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  RDD（Resilient Distributed Datasets），弹性分布式数据集，它是对分布式数据集的一种内存抽象，通过受限的共享内存方式来提供容错性，同时这种内存模型使得计算比传统的数据流模型要高效。RDD 具有 5 个重要的特性，如下图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCoGV.png"><br> 上图展示了 2 个 RDD 进行 JOIN 操作，体现了 RDD 所具备的 5 个主要特性，如下所示：<br>   • 1）一组分区<br>   • 2）计算每一个数据分片的函数<br>   • 3）RDD 上的一组依赖<br>   • 4）可选，对于键值对 RDD，有一个 Partitioner（通常是 HashPartitioner）<br>   • 5）可选，一组 Preferred location 信息（例如，HDFS 文件的 Block 所在 location 信息）<br> 有了上述特性，能够非常好地通过 RDD 来表达分布式数据集，并作为构建 DAG 图的基础：首先抽象一个分布式计算任务的逻辑表示，最终将任务在实际的物理计算环境中进行处理执行。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_2"></a></span></span></p> 
  <h3 id="h13" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.3 计算抽象</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在描述 Spark 中的计算抽象，我们首先需要了解如下几个概念：<br> 1）Application<br>   • 用户编写的 Spark 程序，完成一个计算任务的处理。它是由一个 Driver 程序和一组运行于 Spark 集群上的 Executor 组成。<br> 2）Job<br>   • 用户程序中，每次调用 Action 时，逻辑上会生成一个 Job，一个 Job 包含了多个 Stage 。<br> 3）Stage<br>   • Stage 包括两类：ShuffleMapStage 和 ResultStage，如果用户程序中调用了需要进行 Shuffle 计算的 Operator，如 groupByKey 等，就会以 Shuffle 为边界分成 ShuffleMapStage 和 ResultStage。<br> 4）TaskSet<br>   • 基于 Stage 可以直接映射为 TaskSet，一个 TaskSet 封装了一次需要运算的、具有相同处理逻辑的 Task，这些 Task 可以并行计算，粗粒度的调度是以 TaskSet 为单位的。<br> 5）Task<br>   • Task 是在物理节点上运行的基本单位，Task 包含两类：ShuffleMapTask 和 ResultTask，分别对应于 Stage 中 ShuffleMapStage 和 ResultStage 中的一个执行基本单元。<br> 下面，我们看一下，上面这些基本概念之间的关系，如下图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtC45q.png"><br>   上图，为了简单，每个 Job 假设都很简单，并且只需要进行一次 Shuffle 处理，所以都对应 2 个 Stage。实际应用中，一个 Job 可能包含若干个 Stage，或者是一个相对复杂的 Stage DAG。<br> 在 Standalone 模式下，默认使用的是 FIFO 这种简单的调度策略，在进行调度的过程中，大概流程如下图所示：<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCfVs.png"><br>   从用户提交 Spark 程序，最终生成 TaskSet，而在调度时，通过 TaskSetManager 来管理一个 TaskSet（包含一组可在物理节点上执行的 Task），这里面 TaskSet 必须要按照顺序执行才能保证计算结果的正确性，因为 TaskSet 之间是有序依赖的（上溯到 ShuffleMapStage 和 ResultStage），只有一个 TaskSet 中的所有 Task 都运行完成后，才能调度下一个 TaskSet 中的 Task 去执行。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_3"></a></span></span></p> 
  <h3 id="h14" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.4 集群模式</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 集群在设计的时候，并没有在资源管理的设计上对外封闭，而是充分考虑了未来对接一些更强大的资源管理系统，如 YARN、Mesos 等，所以 Spark 架构设计将资源管理单独抽象出一层，通过这种抽象能够构建一种适合企业当前技术栈的插件式资源管理模块，从而为不同的计算场景提供不同的资源分配与调度策略。Spark 集群模式架构，如下图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtChan.png"><br> 上图中，Spark集群Cluster Manager目前支持如下三种模式：<br> 1）Standalone 模式<br>   • Standalone 模式是 Spark 内部默认实现的一种集群管理模式，这种模式是通过集群中的 Master 来统一管理资源，而与 Master 进行资源请求协商的是 Driver 内部的 StandaloneSchedulerBackend（实际上是其内部的 StandaloneAppClient 真正与 Master 通信），后面会详细说明。<br> 2）YARN 模式<br>   • YARN 模式下，可以将资源的管理统一交给 YARN 集群的 ResourceManager 去管理，选择这种模式，可以更大限度的适应企业内部已有的技术栈，如果企业内部已经在使用 Hadoop 技术构建大数据处理平台。<br> 3）Mesos 模式<br>   • 随着 Apache Mesos 的不断成熟，一些企业已经在尝试使用 Mesos 构建数据中心的操作系统（DCOS），Spark 构建在 Mesos 之上，能够支持细粒度、粗粒度的资源调度策略（Mesos 的优势），也可以更好地适应企业内部已有技术栈。<br>   • 那么，Spark 中是怎么考虑满足这一重要的设计决策的呢？也就是说，如何能够保证 Spark 非常容易的让第三方资源管理系统轻松地接入进来。我们深入到类设计的层面看一下，如下类图所示：<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCvI1.png"><br>   • 可以看出，Task 调度直接依赖 SchedulerBackend，SchedulerBackend 与实际资源管理模块交互实现资源请求。这里面，CoarseGrainedSchedulerBackend 是 Spark 中与资源调度相关的最重要的抽象，它需要抽象出与 TaskScheduler 通信的逻辑，同时还要能够与各种不同的第三方资源管理系统无缝地交互。实际上，CoarseGrainedSchedulerBackend 内部采用了一种 ResourceOffer 的方式来处理资源请求。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_4"></a></span></span></p> 
  <h3 id="h15rpc" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.5 RPC 网络通信抽象</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark RPC 层是基于优秀的网络通信框架 Netty 设计开发的，但是 Spark 提供了一种很好地抽象方式，将底层的通信细节屏蔽起来，而且也能够基于此来设计满足扩展性，比如，如果有其他不基于 Netty 的网络通信框架的新的RPC接入需求，可以很好地扩展而不影响上层的设计。RPC 层设计，如下图类图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCIP0.png"><br>   任何两个 Endpoint 只能通过消息进行通信，可以实现一个 RpcEndpoint 和一个 RpcEndpointRef。想要与 RpcEndpoint 通信，需要获取到该 RpcEndpoint 对应的 RpcEndpointRef 即可，而且管理 RpcEndpoint 和 RpcEndpointRef 创建及其通信的逻辑，统一在 RpcEnv 对象中管理。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_5"></a></span></span></p> 
  <h3 id="h16standalone" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.6 启动 Standalone 集群</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Standalone 模式下，Spark 集群采用了简单的 Master-Slave 架构模式，Master 统一管理所有的 Worker，这种模式很常见，我们简单地看下 Spark Standalone 集群启动的基本流程，如下图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCT2T.png"><br> 可以看到，Spark 集群采用的消息的模式进行通信，也就是 EDA 架构模式，借助于 RPC 层的优雅设计，任何两个 Endpoint 想要通信，发送消息并携带数据即可。上图的流程描述如下所示：<br>   • 1）Master 启动时首先创一个 RpcEnv 对象，负责管理所有通信逻辑。<br>   • 2）Master 通过 RpcEnv 对象创建一个 Endpoint，Master 就是一个 Endpoint，Worker 可以与其进行通信。<br>   • 3）Worker 启动时也是创一个 RpcEnv 对象。<br>   • 4）Worker 通过 RpcEnv 对象创建一个 Endpoint。<br>   • 5）Worker 通过 RpcEnv 对，建立到 Master 的连接，获取到一个 RpcEndpointRef 对象，通过该对象可以与 Master 通信。<br>   • 6）Worker 向 Master 注册，注册内容包括主机名、端口、CPU Core 数量、内存数量。<br>   • 7）Master 接收到 Worker 的注册，将注册信息维护在内存中的 Table 中，其中还包含了一个到 Worker 的 RpcEndpointRef 对象引用。<br>   • 8）Master 回复 Worker 已经接收到注册，告知 Worker 已经注册成功。<br>   • 9）此时如果有用户提交 Spark 程序，Master 需要协调启动 Driver；而 Worker 端收到成功注册响应后，开始周期性向 Master 发送心跳。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_6"></a></span></span></p> 
  <h3 id="h17" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.7 核心组件</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  集群处理计算任务的运行时（即用户提交了 Spark 程序），最核心的顶层组件就是 Driver 和 Executor，它们内部管理很多重要的组件来协同完成计算任务，核心组件栈如下图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtC7xU.png"><br>   Driver 和 Executor 都是运行时创建的组件，一旦用户程序运行结束，他们都会释放资源，等待下一个用户程序提交到集群而进行后续调度。上图，我们列出了大多数组件，其中 SparkEnv 是一个重量级组件，他们内部包含计算过程中需要的主要组件，而且，Driver 和 Executor 共同需要的组件在 SparkEnv 中也包含了很多。这里，我们不做过多详述，后面交互流程等处会说明大部分组件负责的功能。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_7"></a></span></span></p> 
  <h3 id="h18" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.8 核心组件交互流程</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  在 Standalone 模式下，Spark 中各个组件之间交互还是比较复杂的，但是对于一个通用的分布式计算系统来说，这些都是非常重要而且比较基础的交互。首先，为了理解组件之间的主要交互流程，我们给出一些基本要点：<br>   • 一个 Application 会启动一个 Driver<br>   • 一个 Driver 负责跟踪管理该 Application 运行过程中所有的资源状态和任务状态<br>   • 一个 Driver 会管理一组 Executor<br>   • 一个 Executor 只执行属于一个 Driver 的 Task<br> 核心组件之间的主要交互流程，如下图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCbMF.png"><br> 上图中，通过不同颜色或类型的线条，给出了如下 6 个核心的交互流程，我们会详细说明：<br><strong>橙色：提交用户 Spark 程序</strong><br> 用户提交一个 Spark 程序，主要的流程如下所示：<br>   •1）用户 spark-submit 脚本提交一个 Spark 程序，会创建一个 ClientEndpoint 对象，该对象负责与 Master 通信交互<br>   •2）ClientEndpoint 向 Master 发送一个 RequestSubmitDriver 消息，表示提交用户程序<br>   •3）Master 收到 RequestSubmitDriver 消息，向 ClientEndpoint 回复 SubmitDriverResponse，表示用户程序已经完成注册<br>   •4）ClientEndpoint 向 Master 发送 RequestDriverStatus 消息，请求 Driver 状态<br>   •5）如果当前用户程序对应的 Driver 已经启动，则 ClientEndpoint 直接退出，完成提交用户程序<br><strong>紫色：启动 Driver 进程</strong><br> 当用户提交用户 Spark 程序后，需要启动 Driver 来处理用户程序的计算逻辑，完成计算任务，这时 Master 协调需要启动一个 Driver，具体流程如下所示：<br>   •1）Maser 内存中维护着用户提交计算的任务 Application，每次内存结构变更都会触发调度，向 Worker 发送 LaunchDriver 请求<br>   •2）Worker 收到 LaunchDriver 消息，会启动一个 DriverRunner 线程去执行 LaunchDriver 的任务<br>   •3）DriverRunner 线程在 Worker 上启动一个新的 JVM 实例，该 JVM 实例内运行一个 Driver 进程，该 Driver 会创建 SparkContext 对象<br><strong>红色：注册 Application</strong><br> Dirver 启动以后，它会创建 SparkContext 对象，初始化计算过程中必需的基本组件，并向 Master 注册 Application，流程描述如下：<br>   •1）创建 SparkEnv 对象，创建并管理一些数基本组件<br>   •2）创建 TaskScheduler，负责 Task 调度<br>   •3）创建 StandaloneSchedulerBackend，负责与 ClusterManager 进行资源协商<br>   •4）创建 DriverEndpoint，其它组件可以与 Driver 进行通信<br>   •5）在 StandaloneSchedulerBackend 内部创建一个 StandaloneAppClient，负责处理与 Master 的通信交互<br>   •6）StandaloneAppClient 创建一个 ClientEndpoint，实际负责与 Master 通信<br>   •7）ClientEndpoint 向 Master 发送 RegisterApplication 消息，注册 Application<br>   •8）Master 收到 RegisterApplication 请求后，回复 ClientEndpoint 一个 RegisteredApplication 消息，表示已经注册成功<br><strong>蓝色：启动 Executor 进程</strong><br>   •1）Master 向 Worker 发送 LaunchExecutor 消息，请求启动 Executor；同时 Master 会向 Driver 发送 ExecutorAdded 消息，表示 Master 已经新增了一个 Executor（此时还未启动）<br>   •2）Worker 收到 LaunchExecutor 消息，会启动一个 ExecutorRunner 线程去执行 LaunchExecutor 的任务<br>   •3）Worker 向 Master 发送 ExecutorStageChanged 消息，通知 Executor 状态已发生变化<br>   •4）Master 向 Driver 发送 ExecutorUpdated 消息，此时 Executor 已经启动<br><strong>粉色：启动 Task 执行</strong><br>   •1）StandaloneSchedulerBackend 启动一个 DriverEndpoint<br>   •2）DriverEndpoint 启动后，会周期性地检查 Driver 维护的 Executor 的状态，如果有空闲的 Executor 便会调度任务执行<br>   •3）DriverEndpoint 向 TaskScheduler 发送 Resource Offer 请求<br>   •4）如果有可用资源启动 Task，则 DriverEndpoint 向 Executor 发送 LaunchTask 请求<br>   •5）Executor 进程内部的 CoarseGrainedExecutorBackend 调用内部的 Executor 线程的 launchTask 方法启动 Task<br>   •6）Executor 线程内部维护一个线程池，创建一个 TaskRunner 线程并提交到线程池执行<br><strong>绿色：Task 运行完成</strong><br>   •1）Executor 进程内部的 Executor 线程通知 CoarseGrainedExecutorBackend，Task 运行完成<br>   •2）CoarseGrainedExecutorBackend 向 DriverEndpoint 发送 StatusUpdated 消息，通知 Driver 运行的 Task 状态发生变更<br>   •3）StandaloneSchedulerBackend 调用T askScheduler 的 updateStatus 方法更新 Task 状态<br>   •4）StandaloneSchedulerBackend 继续调用 TaskScheduler 的 resourceOffers 方法，调度其他任务运行</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_8"></a></span></span></p> 
  <h3 id="h19block" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.9 Block 管理</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Block 管理，主要是为 Spark 提供的 Broadcast 机制提供服务支撑的。Spark 中内置采用 TorrentBroadcast 实现，该 Broadcast 变量对应的数据（Task 数据）或数据集（如 RDD），默认会被切分成若干 4M 大小的 Block，Task 运行过程中读取到该 Broadcast 变量，会以 4M 为单位的 Block 为拉取数据的最小单位，最后将所有的 Block 合并成 Broadcast 变量对应的完整数据或数据集。将数据切分成 4M 大小的 Block，Task 从多个 Executor 拉取 Block，可以非常好地均衡网络传输负载，提高整个计算集群的稳定性。<br>   通常，用户程序在编写过程中，会对某个变量进行 Broadcast，该变量称为 Broadcast 变量。在实际物理节点的 Executor 上执行 Task 时，需要读取 Broadcast 变量对应的数据集，那么此时会根据需要拉取 DAG 执行流上游已经生成的数据集。采用 Broadcast 机制，可以有效地降低数据在计算集群环境中传输的开销。具体地，如果一个用户对应的程序中的 Broadcast 变量，对应着一个数据集，它在计算过程中需要拉取对应的数据，如果在同一个物理节点上运行着多个 Task，多个 Task 都需要该数据，有了 Broadcast 机制，只需要拉取一份存储在本地物理机磁盘即可，供多个 Task 计算共享。<br>   另外，用户程序在进行调度过程中，会根据调度策略将 Task 计算逻辑数据（代码）移动到对应的 Worker 节点上，最优情况是对本地数据进行处理，那么代码（序列化格式）也需要在网络上传输，也是通过 Broadcast 机制进行传输，不过这种方式是首先将代码序列化到 Driver 所在 Worker 节点，后续如果 Task 在其他 Worker 中执行，需要读取对应代码的 Broadcast 变量，首先就是从 Driver 上拉取代码数据，接着其他晚一些被调度的 Task 可能直接从其他 Worker 上的 Executor 中拉取代码数据。<br>   我们通过以 Broadcast 变量 taskBinary 为例，说明 Block 是如何管理的，如下图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCjaR.png"><br>   上图中，Driver 负责管理所有的 Broadcast 变量对应的数据所在的 Executor，即一个 Executor 维护一个 Block 列表。在 Executor 中运行一个 Task 时，执行到对应的 Broadcast 变量 taskBinary，如果本地没有对应的数据，则会向 Driver 请求获取 Broadcast 变量对应的数据，包括一个或多个 Block 所在的 Executor 列表，然后该 Executor 根据 Driver 返回的 Executor 列表，直接通过底层的 BlockTransferService 组件向对应 Executor 请求拉取 Block。Executor 拉取到的 Block 会缓存到本地，同时向 Driver 报告该 Executor 上存在的 Block 信息，以供其他 Executor 执行 Task 时获取 Broadcast 变量对应的数据。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label0_9"></a></span></span></p> 
  <h3 id="h110" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>1.10整体应用</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  用户通过 spark-submit 提交或者运行 spark-shell REPL，集群创建 Driver，Driver 加载 Application，最后 Application 根据用户代码转化为 RDD，RDD 分解为 Tasks，Executor 执行 Task 等系列知识，整体交互蓝图如下：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCXZ9.png"></span></span>
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label1"></a></span></span></p> 
  <h2 id="h2spark" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第2章 Spark 通信架构</strong></span></span></strong></span></span></h2> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark作为分布式计算框架，多个节点的设计与相互通信模式是其重要的组成部分。Spark 一开始使用 Akka 作为内部通信部件。在 Spark 1.3 年代，为了解决大块数据（如 Shuffle）的传输问题，Spark 引入了 Netty 通信框架。到了 Spark 1.6，Spark 可以配置使用 Akka 或者 Netty 了，这意味着 Netty 可以完全替代 Akka了。再到 Spark 2，Spark 已经完全抛弃 Akka了，全部使用 Netty 了。<br>   为什么呢？官方的解释是：<br>   •1）很多 Spark 用户也使用 Akka，但是由于 Akka 不同版本之间无法互相通信，这就要求用户必须使用跟 Spark 完全一样的 Akka 版本，导致用户无法升级 Akka。<br>   •2）Spark 的 Akka 配置是针对 Spark 自身来调优的，可能跟用户自己代码中的 Akka 配置冲突。<br>   •3）Spark 用的 Akka 特性很少，这部分特性很容易自己实现。同时，这部分代码量相比 Akka 来说少很多，debug 比较容易。如果遇到什么 bug，也可以自己马上 fix，不需要等 Akka 上游发布新版本。而且，Spark 升级 Akka 本身又因为第一点会强制要求用户升级他们使用的 Akka，对于某些用户来说是不现实的。<br> SPARK 的通信架构 - Actor 比较，如下图所示：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPSG6.png"></span></span>
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label1_0"></a></span></span></p> 
  <h3 id="h21" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>2.1 通信组件概览</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">对源码分析，对于设计思路理解如下：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtCzPx.png"><br>   •1）RpcEndpoint：RPC 端点，Spark 针对于每个节点（Client/Master/Worker）都称之一个 Rpc 端点且都实现 RpcEndpoint 接口，内部根据不同端点的需求，设计不同的消息和不同的业务处理，如果需要发送（询问）则调用 Dispatcher。<br>   •2）RpcEnv：RPC 上下文环境，每个 Rpc 端点运行时依赖的上下文环境称之为 RpcEnv。<br>   •3）Dispatcher：消息分发器，针对于 RPC 端点需要发送消息或者从远程 RPC 接收到的消息，分发至对应的指令收件箱/发件箱。如果指令接收方是自己存入收件箱，如果指令接收方为非自身端点，则放入发件箱。<br>   •4）Inbox：指令消息收件箱，一个本地端点对应一个收件箱，Dispatcher 在每次向 Inbox 存入消息时，都将对应 EndpointData 加入内部待 Receiver Queue中，另外 Dispatcher 创建时会启动一个单独线程进行轮询 Receiver Queue，进行收件箱消息消费。<br>   •5）OutBox：指令消息发件箱，一个远程端点对应一个发件箱，当消息放入 Outbox 后，紧接着将消息通过 TransportClient 发送出去。消息放入发件箱以及发送过程是在同一个线程中进行，这样做的主要原因是远程消息分为 RpcOutboxMessage，OneWayOutboxMessage 两种消息，而针对于需要应答的消息直接发送且需要得到结果进行处理<br>   •6）TransportClient：Netty 通信客户端，根据 OutBox 消息的 receiver 信息，请求对应远程 TransportServer。<br>   •7）TransportServer：Netty 通信服务端，一个 RPC 端点一个 TransportServer，接受远程消息后调用 Dispatcher 分发消息至对应收发件箱。<br><code>注意</code>：<br>   TransportClient 与 TransportServer 通信虚线表示两个 RpcEnv 之间的通信，图示没有单独表达式。<br>   一个 Outbox 一个 TransportClient，图示没有单独表达式。<br>   一个 RpcEnv 中存在两个 RpcEndpoint，一个代表本身启动的 RPC 端点，另外一个为 RpcEndpointVerifier。<br> Spark的通信架构 – 高层视图<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtP9xO.png"><br> Spark 的通信架构 – 类图<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPise.png"></span></span>
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label1_1"></a></span></span></p> 
  <h3 id="h22endpoint" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>2.2 Endpoint 启动过程</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">启动的流程如下：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPVII.png"><br> Endpoint 启动后，默认会向 Inbox 中添加 OnStart 消息，不同的端点（Master/Worker/Client）消费 OnStart 指令时，进行相关端点的启动额外处理。<br> Endpoint 启动时，会默认启动 TransportServer，且启动结束后会进行一次同步测试 rpc 可用性（askSync-BoundPortsRequest）。<br> Dispatcher 作为一个分发器，内部存放了 Inbox，Outbox 的等相关句柄和存放了相关处理状态数据，结构大致如下：<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPpRK.png"></span></span>
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label1_2"></a></span></span></p> 
  <h3 id="h23endpointsendask" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>2.3 Endpoint Send&amp;Ask 流程</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Endpoint 的消息发送与请求流程，如下：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPPMD.png"><br> Endpoint 根据业务需要存入两个维度的消息组合：send/ask 某个消息，receiver 是自身与非自身<br>   •1）OneWayMessage：send + 自身，直接存入收件箱<br>   •2）OneWayOutboxMessage：send + 非自身，存入发件箱并直接发送<br>   •3）RpcMessage：ask + 自身，直接存入收件箱，另外还需要存入 LocalNettyRpcCallContext，需要回调后再返回<br>   •4）RpcOutboxMessage：ask + 非自身，存入发件箱并直接发送，需要回调后再返回</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label1_3"></a></span></span></p> 
  <h3 id="h24endpointreceive" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>2.4 Endpoint Receive 流程</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Endpoint 的消息的接收，流程如下：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPAZd.png"><br> 上图 ServerBootstrap 为 Netty 启动服务，SocketChanel为Netty 数据通道。<br> 上述包含 TransportSever 启动与消息接收两个流程。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label1_4"></a></span></span></p> 
  <h3 id="h25endpointinbox" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>2.5 Endpoint Inbox 处理流程</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Spark 在 Endpoint 的设计上核心设计即为 Inbox 与 Outbox，其中 Inbox 核心要点为：<br>   •1）内部的处理流程拆分为多个消息指令（InboxMessage）存放入 Inbox。<br>   •2）当 Dispatcher 启动最后，会启动一个名为【dispatcher-event-loop】的线程扫描 Inbox 待处理 InboxMessage，并调用 Endpoint 根据 InboxMessage 类型做相应处理<br>   •3）当 Dispatcher 启动最后，默认会向 Inbox 存入 OnStart 类型的 InboxMessage，Endpoint 在根据 OnStart 指令做相关的额外启动工作，三端启动后所有的工作都是对 OnStart 指令处理衍生出来的，因此可以说 OnStart 指令是相互通信的源头。</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPFqH.png"><br> 消息指令类型大致如下三类：<br>   •1）OnStart/OnStop<br>   •2）RpcMessage/OneWayMessage<br>   •3）RemoteProcessDisconnected/RemoteProcessConnected/RemoteProcessConnectionError</span></span>
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label1_5"></a></span></span></p> 
  <h3 id="h26endpoint" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>2.6 Endpoint 画像</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPEdA.png"></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label2"></a></span></span></p> 
  <h2 id="h3" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第3章 脚本解析</strong></span></span></strong></span></span></h2> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在看源码之前，我们一般会看相关脚本了解其初始化信息以及 Bootstrap 类，Spark 也不例外，而 Spark 中相关的脚本如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-shell"><span style="color:#df5320;"><span style="color:#2b91af;">%</span></span><span style="color:inherit;">SPARK_HOME%/sbin/start-master.sh</span> <span style="color:#df5320;">%</span><span style="color:inherit;">SPARK_HOME%/sbin/start-slaves.sh</span> <span style="color:#df5320;">%</span><span style="color:inherit;">SPARK_HOME%/sbin/start-all.sh</span> <span style="color:#df5320;">%</span><span style="color:inherit;">SPARK_HOME%/bin/spark-submit</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">启动脚本中对于公共处理部分进行抽取为独立的脚本，如下：</span></span></span></p> 
  <table border="1" cellspacing="0">
   <thead>
    <tr>
     <th style="text-align:left;"><span style="color:#393939;"><span style="color:#3e3e3e;">脚本</span></span></th> 
     <th style="text-align:left;"><span style="color:#393939;"><span style="color:#3e3e3e;">说明</span></span></th> 
    </tr>
   </thead>
   <tbody>
    <tr>
     <td style="border-color:#cccccc;text-align:left;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">sbin/spark-config.sh</span></span></span></td> 
     <td style="border-color:#cccccc;text-align:left;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">初始化环境变量 SPARK_CONF_DIR, PYTHONPATH</span></span></span></td> 
    </tr>
    <tr>
     <td style="border-color:#cccccc;text-align:left;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">bin/load-spark-env.sh</span></span></span></td> 
     <td style="border-color:#cccccc;text-align:left;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">初始化环境变量 SPARK_SCALA_VERSION，调用 %SPARK_HOME%</span></span></span></td> 
    </tr>
    <tr>
     <td style="border-color:#cccccc;text-align:left;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">conf/spark-env.sh</span></span></span></td> 
     <td style="border-color:#cccccc;text-align:left;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">加载用户自定义环境变量</span></span></span></td> 
    </tr>
   </tbody>
  </table>
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label2_0"></a></span></span></p> 
  <h3 id="h31startdaemonsh" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>3.1 start-daemon.sh</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">主要完成进程相关基本信息初始化，然后调用 bin/spark-class 进行守护进程启动，该脚本是创建端点的通用脚本，三端各自脚本都会调用 spark-daemon.sh 脚本启动各自进程</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPuz8.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）初始化&nbsp;SPRK_HOME、SPARK_CONF_DIR、SPARK_IDENT_STRING、SPARK_LOG_DIR&nbsp;环境变量&nbsp;(如果不存在) <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）初始化日志并测试日志文件夹读写权限，初始化&nbsp;PID&nbsp;目录并校验&nbsp;PID&nbsp;信息 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）调用&nbsp;/bin/spark-<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">class</span></span>&nbsp;脚本，/<span style="color:#407ee7;"><span style="color:#880000;">bin</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">class</span></span>&nbsp;见下面 </span></code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label2_1"></a></span></span></p> 
  <h3 id="h32sparkclass" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>3.2 spark-class</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Master 调用举例：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">bin/spark-<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">class</span></span>&nbsp;\ --<span style="color:#407ee7;"><span style="color:#880000;">class</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">org</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">apache</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">deploy</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">master</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">Master</span></span>&nbsp;\ --<span style="color:#407ee7;"><span style="color:#880000;">host</span></span>&nbsp;$<span style="color:#407ee7;"><span style="color:#880000;">SPARK_MASTER_HOST</span></span>&nbsp;\ --<span style="color:#407ee7;"><span style="color:#880000;">port</span></span>&nbsp;$<span style="color:#407ee7;"><span style="color:#880000;">SPARK_MASTER_PORT</span></span>&nbsp;\ --<span style="color:#407ee7;"><span style="color:#880000;">webui</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">port</span></span>&nbsp;$<span style="color:#407ee7;"><span style="color:#880000;">SPARK_MASTER_WEBUI_PORT</span></span>&nbsp;$<span style="color:#407ee7;"><span style="color:#880000;">ORIGINAL_ARGS</span></span> <span style="color:#880000;">1</span>）初始化&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">RUNNER</span></span>(<span style="color:#407ee7;"><span style="color:#880000;">java</span></span>)、<span style="color:#407ee7;"><span style="color:#880000;">SPARK_JARS_DIR</span></span>&nbsp;(%<span style="color:#407ee7;"><span style="color:#880000;">SPARK_HOME</span></span>%/<span style="color:#407ee7;"><span style="color:#880000;">jars</span></span>)、<span style="color:#407ee7;"><span style="color:#880000;">LAUNCH_CLASSPATH</span></span>&nbsp;信息 2）调用&nbsp;("$<span style="color:#407ee7;"><span style="color:#880000;">RUNNER</span></span>"&nbsp;-<span style="color:#407ee7;"><span style="color:#880000;">Xmx128m</span></span>&nbsp;-<span style="color:#407ee7;"><span style="color:#880000;">cp</span></span>&nbsp;"$<span style="color:#407ee7;"><span style="color:#880000;">LAUNCH_CLASSPATH</span></span>"&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">org</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">apache</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">launcher</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">Main</span></span>&nbsp;"$@")&nbsp;获取最终执行的&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">shell</span></span>&nbsp;语句 3）执行最终的&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">shell</span></span>&nbsp;语句，示例如下： /<span style="color:#407ee7;"><span style="color:#880000;">opt</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">module</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">jdk1</span></span>.8.0<span style="color:#407ee7;"><span style="color:#880000;">_144</span></span>&nbsp;\ -<span style="color:#407ee7;"><span style="color:#880000;">cp</span></span>&nbsp;/<span style="color:#407ee7;"><span style="color:#880000;">opt</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">module</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>-2.1.1-<span style="color:#407ee7;"><span style="color:#880000;">bin</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">hadoop2</span></span>.7/<span style="color:#407ee7;"><span style="color:#880000;">conf</span></span>/:/<span style="color:#407ee7;"><span style="color:#880000;">opt</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">module</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>-2.1.1-<span style="color:#407ee7;"><span style="color:#880000;">bin</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">hadoop2</span></span>.7/<span style="color:#407ee7;"><span style="color:#880000;">jars</span></span>/*:/<span style="color:#407ee7;"><span style="color:#880000;">opt</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">module</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">hadoop</span></span>-2.7.2/<span style="color:#407ee7;"><span style="color:#880000;">etc</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">hadoop</span></span>/&nbsp;\ -<span style="color:#407ee7;"><span style="color:#880000;">Xmx1g</span></span>&nbsp;\ -<span style="color:#407ee7;"><span style="color:#880000;">XX</span></span>:<span style="color:#407ee7;"><span style="color:#880000;">MaxPermSize</span></span></span>=<span style="color:#df5320;"><span style="color:#008800;">256</span></span>m&nbsp;\ org.apache.spark.deploy.master.Master&nbsp;\ --host&nbsp;hadoop102&nbsp;\ --port&nbsp;<span style="color:#df5320;"><span style="color:#008800;">7077</span></span>&nbsp;\ --webui-port&nbsp;<span style="color:#df5320;"><span style="color:#008800;">8080</span></span> 如果是&nbsp;Client，那么可能为&nbsp;r，或者&nbsp;python&nbsp;脚本。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label2_2"></a></span></span></p> 
  <h3 id="h33startmastersh" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>3.3 start-master.sh</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">启动 Master 的脚本，流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtP3Zj.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）用户执行&nbsp;start-master.sh&nbsp;脚本，初始化环境变量&nbsp;SPARK_HOME&nbsp;(如果&nbsp;PATH&nbsp;不存在&nbsp;SPARK_HOME，初始化脚本的上级目录为&nbsp;SPARK_HOME)，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh <span style="color:#df5320;">2</span>）如果环境变量&nbsp;SPARK_MASTER_HOST、SPARK_MASTER_PORT、SPARK_MASTER_WEBUI_PORT&nbsp;不存在，进行初始化&nbsp;<span style="color:#df5320;"><span style="color:#008800;">7077</span></span>，hostname&nbsp;-f，<span style="color:#df5320;"><span style="color:#008800;">8080</span></span> <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）调用&nbsp;spark-daemon.sh&nbsp;脚本启动&nbsp;master&nbsp;进程，如下： spark-daemon.sh&nbsp;start&nbsp;org.apache.spark.deploy.master.Master&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>&nbsp;\ --host&nbsp;$SPARK_MASTER_HOST&nbsp;\ --port&nbsp;$SPARK_MASTER_PORT&nbsp;\ --webui-port&nbsp;$SPARK_MASTER_WEBUI_PORT&nbsp;$ORIGINAL_ARGS） </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label2_3"></a></span></span></p> 
  <h3 id="h34startslavessh" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>3.4 start-slaves.sh</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">启动 Worker 的脚本，流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPmJP.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）用户执行&nbsp;start-slaves.sh&nbsp;脚本，初始化环境变量&nbsp;SPARK_HOME，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh，初始化&nbsp;Master&nbsp;host/port&nbsp;信息 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）调用&nbsp;slaves.sh&nbsp;脚本，读取&nbsp;conf/slaves&nbsp;文件并遍历，通过&nbsp;ssh&nbsp;连接到对应&nbsp;slave&nbsp;节点，启动&nbsp;${SPARK_HOME}/sbin/start-slave.sh&nbsp;spark:<span style="color:#766e6b;"><span style="color:#888888;">//$SPARK_MASTER_HOST:$SPARK_MASTER_PORT</span></span> <span style="color:#df5320;"><span style="color:#888888;">3</span></span><span style="color:#888888;">）start-slave.sh&nbsp;在各个节点中，初始化环境变量&nbsp;SPARK_HOME，调用&nbsp;spark-config.sh，调用&nbsp;load-spark-env.sh，根据&nbsp;$SPARK_WORKER_INSTANCES&nbsp;计算&nbsp;WEBUI_PORT&nbsp;端口&nbsp;(worker&nbsp;端口号依次递增)&nbsp;并启动&nbsp;Worker&nbsp;进程，如下：</span> <span style="color:#888888;">${SPARK_HOME}/sbin/spark-daemon.sh&nbsp;\</span> <span style="color:#888888;">start&nbsp;org.apache.spark.deploy.worker.Worker&nbsp;$WORKER_NUM&nbsp;\</span> <span style="color:#888888;">--webui-port&nbsp;</span><span style="color:#7b9726;"><span style="color:#888888;">"$WEBUI_PORT"</span></span><span style="color:#888888;">&nbsp;$PORT_FLAG&nbsp;$PORT_NUM&nbsp;$MASTER&nbsp;</span><span style="color:#7b9726;"><span style="color:#888888;">"$@"</span></span> </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label2_4"></a></span></span></p> 
  <h3 id="h35startallsh" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>3.5 start-all.sh</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">属于快捷脚本，内部调用 start-master.sh 与 start-slaves.sh 脚本，并无额外工作。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label2_5"></a></span></span></p> 
  <h3 id="h36sparksubmit" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>3.6 spark-submit</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">任务提交的基本脚本，流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPeit.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）直接调用&nbsp;spark-<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">class</span></span>&nbsp;脚本进行进程创建，示例如下： ./<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">submit</span></span>&nbsp;\ --<span style="color:#407ee7;"><span style="color:#880000;">class</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">org</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">apache</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">examples</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">SparkPi</span></span>&nbsp;\ --<span style="color:#407ee7;"><span style="color:#880000;">master</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>://<span style="color:#407ee7;"><span style="color:#880000;">hadoop102</span></span>:7077&nbsp;\ ../<span style="color:#407ee7;"><span style="color:#880000;">examples</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">jars</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">examples_2</span></span>.11-2.1.0.<span style="color:#407ee7;"><span style="color:#880000;">jar</span></span>&nbsp;10 2）如果是&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">java</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">scala</span></span>&nbsp;任务，那么最终调用&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">SparkSubmit</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">scala</span></span>&nbsp;进行任务处理，示例如下： /<span style="color:#407ee7;"><span style="color:#880000;">opt</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">module</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">jdk1</span></span>.8.0<span style="color:#407ee7;"><span style="color:#880000;">_144</span></span>&nbsp;-<span style="color:#407ee7;"><span style="color:#880000;">cp</span></span>&nbsp;\ /<span style="color:#407ee7;"><span style="color:#880000;">opt</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">module</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>-2.1.1-<span style="color:#407ee7;"><span style="color:#880000;">bin</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">hadoop2</span></span>.7/<span style="color:#407ee7;"><span style="color:#880000;">conf</span></span>/:/<span style="color:#407ee7;"><span style="color:#880000;">opt</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">module</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>-2.1.1-<span style="color:#407ee7;"><span style="color:#880000;">bin</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">hadoop2</span></span>.7/<span style="color:#407ee7;"><span style="color:#880000;">jars</span></span>/*:/<span style="color:#407ee7;"><span style="color:#880000;">opt</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">module</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">hadoop</span></span>-2.7.2/<span style="color:#407ee7;"><span style="color:#880000;">etc</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">hadoop</span></span>/&nbsp;\ -<span style="color:#407ee7;"><span style="color:#880000;">Xmx1g</span></span>&nbsp;-<span style="color:#407ee7;"><span style="color:#880000;">XX</span></span>:<span style="color:#407ee7;"><span style="color:#880000;">MaxPermSize</span></span></span>=<span style="color:#df5320;"><span style="color:#008800;">256</span></span>m&nbsp;\ org.apache.spark.deploy.SparkSubmit&nbsp;\ --master&nbsp;spark:<span style="color:#766e6b;"><span style="color:#888888;">//hadoop102:7077&nbsp;\</span></span> <span style="color:#888888;">--</span><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#888888;">class</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">org</span></span><span style="color:#888888;">.</span><span style="color:#407ee7;"><span style="color:#888888;">apache</span></span><span style="color:#888888;">.</span><span style="color:#407ee7;"><span style="color:#888888;">spark</span></span><span style="color:#888888;">.</span><span style="color:#407ee7;"><span style="color:#888888;">examples</span></span><span style="color:#888888;">.</span><span style="color:#407ee7;"><span style="color:#888888;">SparkPi</span></span><span style="color:#888888;">&nbsp;\</span> <span style="color:#888888;">../</span><span style="color:#407ee7;"><span style="color:#888888;">examples</span></span><span style="color:#888888;">/</span><span style="color:#407ee7;"><span style="color:#888888;">jars</span></span><span style="color:#888888;">/</span><span style="color:#407ee7;"><span style="color:#888888;">spark</span></span><span style="color:#888888;">-</span><span style="color:#407ee7;"><span style="color:#888888;">examples_2</span></span><span style="color:#888888;">.11-2.1.0.</span><span style="color:#407ee7;"><span style="color:#888888;">jar</span></span><span style="color:#888888;">&nbsp;10</span> </span></code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label3"></a></span></span></p> 
  <h2 id="h4master" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第4章 Master 节点启动</strong></span></span></strong></span></span></h2> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Master 作为 Endpoint 的具体实例，下面我们介绍一下 Master 启动以及 OnStart 指令后的相关工作。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label3_0"></a></span></span></p> 
  <h3 id="h41" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>4.1 脚本概览</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">下面是一个举例：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/spark-<span style="color:#df5320;"><span style="color:#008800;">2.1</span></span>.1-bin-hadoop2.7/conf/:/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/spark-<span style="color:#df5320;"><span style="color:#008800;">2.1</span></span>.1-bin-hadoop2.7/jars<span style="color:#766e6b;"><span style="color:#888888;">/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\</span> <span style="color:#888888;">-Xmx1g&nbsp;\</span> <span style="color:#888888;">-XX:MaxPermSize=256m&nbsp;\</span> <span style="color:#888888;">org.apache.spark.deploy.master.Master&nbsp;\</span> <span style="color:#888888;">--host&nbsp;hadoop102&nbsp;\</span> <span style="color:#888888;">--port&nbsp;7077&nbsp;\</span> </span></code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label3_1"></a></span></span></p> 
  <h3 id="h42" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>4.2 启动流程</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Master 的启动流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPQsg.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）MasterArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Master&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--ip&nbsp;-i&nbsp;--host&nbsp;-h&nbsp;--port&nbsp;-p&nbsp;--webui-port&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;b)将&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）BoundPortsResponse&nbsp;返回&nbsp;rpcEndpointPort、webUIPort、restPort&nbsp;真实端口。 <span style="color:#df5320;"><span style="color:#008800;">5</span></span>）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label3_2"></a></span></span></p> 
  <h3 id="h43onstart" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>4.3 OnStart 监听事件</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Master 的启动完成后异步执行工作如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPnRf.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）【dispatcher-event-loop】线程扫描到&nbsp;OnStart&nbsp;指令后会启动相关&nbsp;MasterWebUI&nbsp;(默认端口&nbsp;<span style="color:#df5320;"><span style="color:#008800;">8080</span></span>），根据配置选择安装&nbsp;ResetServer&nbsp;(默认端口&nbsp;<span style="color:#df5320;"><span style="color:#008800;">6066</span></span>)。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）另外新起【master-forward-message-thread】线程定期检查&nbsp;Worker&nbsp;心跳是否超时。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）如果&nbsp;Worker&nbsp;心跳检测超时，那么对&nbsp;Worker&nbsp;下的发布的所有任务所属&nbsp;Driver&nbsp;进行&nbsp;ExecutorUpdated&nbsp;发送，同时自己再重新&nbsp;LaunchDriver。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label3_3"></a></span></span></p> 
  <h3 id="h44rpcmessagereceiveandreply" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>4.4 RpcMessage 处理 (receiveAndReply)</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPMQS.png"><a name="_label3_4"></a></span></span></p> 
  <h3 id="h45onewaymessagereceive" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>4.5 OneWayMessage 处理 (receive)</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPlLQ.png"><a name="_label3_5"></a></span></span></p> 
  <h3 id="h46masterrpcmessageonewaymessage" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>4.6 Master 对 RpcMessage/OneWayMessage 处理逻辑</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">这部分对整体 Master 理解作用不是很大且理解比较抽象，可以先读后续内容，回头再考虑看这部分内容，或者不读。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPGon.png"></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label4"></a></span></span></p> 
  <h2 id="h5worker" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第5章 Worker 节点启动</strong></span></span></strong></span></span></h2> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Worker 作为 Endpoint 的具体实例，下面我们介绍一下 Worker 启动以及 OnStart 指令后的额外工作。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label4_0"></a></span></span></p> 
  <h3 id="h51" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>5.1 脚本概览</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">下面是一个举例：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/spark-<span style="color:#df5320;"><span style="color:#008800;">2.1</span></span>.1-bin-hadoop2.7/conf/:/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/spark-<span style="color:#df5320;"><span style="color:#008800;">2.1</span></span>.1-bin-hadoop2.7/jars<span style="color:#766e6b;"><span style="color:#888888;">/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\</span> <span style="color:#888888;">-Xmx1g&nbsp;\</span> <span style="color:#888888;">-XX:MaxPermSize=256m&nbsp;\</span> <span style="color:#888888;">org.apache.spark.deploy.worker.Worker&nbsp;\</span> <span style="color:#888888;">--webui-port&nbsp;8081</span> <span style="color:#888888;">spark://hadoop102:7077</span> </span></code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label4_1"></a></span></span></p> 
  <h3 id="h52" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>5.2 启动流程</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Worker 的启动流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPYiq.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）WorkerArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Master&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--ip&nbsp;-i&nbsp;--host&nbsp;-h&nbsp;--port&nbsp;-p&nbsp;--cores&nbsp;-c&nbsp;--memory&nbsp;-m&nbsp;--work-dir&nbsp;--webui-port&nbsp;--properties-file &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;--properties-file&nbsp;(没有配置默认为conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;在没有配置情况下，cores&nbsp;默认为服务器&nbsp;CPU&nbsp;核数。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;在没有配置情况下，memory&nbsp;默认为服务器内存减&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>G，如果低于&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>G&nbsp;取&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>G。 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;webUiPort&nbsp;默认为&nbsp;<span style="color:#df5320;"><span style="color:#008800;">8081</span></span>。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label4_2"></a></span></span></p> 
  <h3 id="h53onstart" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>5.3 OnStart 监听事件</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Worker 的启动完成后异步执行工作如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtP8ds.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）【dispatcher-event-loop】线程扫描到&nbsp;OnStart&nbsp;指令后会启动相关&nbsp;WorkerWebUI&nbsp;(默认端口&nbsp;<span style="color:#df5320;"><span style="color:#008800;">8081</span></span>)。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）Worker&nbsp;向&nbsp;Master&nbsp;发起一次&nbsp;RegisterWorker&nbsp;指令。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）另起【master-forward-message-thread】线程定期执行&nbsp;ReregisterWithMaster&nbsp;任务，如果注册成功&nbsp;(RegisteredWorker)&nbsp;则跳过，否则再次向&nbsp;Master&nbsp;发起&nbsp;RegisterWorker&nbsp;指令，直到超过最大次数报错&nbsp;(默认<span style="color:#df5320;"><span style="color:#008800;">16</span></span>次)。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）Master&nbsp;如果可以注册，则维护对应的&nbsp;WorkerInfo&nbsp;对象并持久化，完成后向&nbsp;Worker&nbsp;发起一条&nbsp;RegisteredWorker&nbsp;指令，如果&nbsp;Master&nbsp;为&nbsp;standby&nbsp;状态，则向&nbsp;Worker&nbsp;发起一条&nbsp;MasterInStandby&nbsp;指令。 <span style="color:#df5320;"><span style="color:#008800;">5</span></span>）Worker&nbsp;接受&nbsp;RegisteredWorker&nbsp;后，提交【master-forward-message-thread】线程定期执行&nbsp;SendHeartbeat&nbsp;任务，完成后向&nbsp;Worker&nbsp;发起一条&nbsp;WorkerLatestState&nbsp;指令。 <span style="color:#df5320;"><span style="color:#008800;">6</span></span>）Worker&nbsp;发心跳检测，会触发更新&nbsp;Master&nbsp;对应&nbsp;WorkerInfo&nbsp;对象，如果&nbsp;Master&nbsp;检测到异常，则发起&nbsp;ReconnectWorker&nbsp;指令至&nbsp;Worker，Worker&nbsp;则再次执行&nbsp;ReregisterWithMaster&nbsp;工作。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label4_3"></a></span></span></p> 
  <h3 id="h54rpcmessagereceiveandreply" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>5.4 RpcMessage 处理 (receiveAndReply)</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPtJ0.png"><a name="_label4_4"></a></span></span></p> 
  <h3 id="h55onewaymessagereceive" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>5.5 OneWayMessage 处理 (receive)</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPdQU.png"></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label5"></a></span></span></p> 
  <h2 id="h6client" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第6章 Client 启动流程</strong></span></span></strong></span></span></h2> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Client 作为 Endpoint 的具体实例，下面我们介绍一下 Client 启动以及 OnStart 指令后的额外工作。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label5_0"></a></span></span></p> 
  <h3 id="h61" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>6.1 脚本概览</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">下面是一个举例：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/jdk1.8.0_144&nbsp;\ -cp&nbsp;/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/spark-<span style="color:#df5320;"><span style="color:#008800;">2.1</span></span>.1-bin-hadoop2.7/conf/:/opt/<span style="color:#6666ea;"><span style="color:#0000ff;">module</span></span>/spark-<span style="color:#df5320;"><span style="color:#008800;">2.1</span></span>.1-bin-hadoop2.7/jars<span style="color:#766e6b;"><span style="color:#888888;">/*:/opt/module/hadoop-2.7.2/etc/hadoop/&nbsp;\</span> <span style="color:#888888;">-Xmx1g</span> <span style="color:#888888;">-XX:MaxPermSize=256m</span> <span style="color:#888888;">org.apache.spark.deploy.SparkSubmit</span> <span style="color:#888888;">--master&nbsp;spark://hadoop102:7077</span> <span style="color:#888888;">--class&nbsp;org.apache.spark.examples.SparkPi</span> <span style="color:#888888;">../examples/jars/spark-examples_2.11-2.1.0.jar&nbsp;10</span> </span></code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label5_1"></a></span></span></p> 
  <h3 id="h62sparksubmit" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>6.2 SparkSubmit 启动流程</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">SparkSubmit 的启动流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPNWV.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）SparkSubmitArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Client&nbsp;启动的参数 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--name&nbsp;--master&nbsp;--<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">class</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">deploy</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">mode</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">num</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">executors</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">executor</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">cores</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">total</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">executor</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">cores</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">executor</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">memory</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">driver</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">memory</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">driver</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">cores</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">driver</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">class</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">path</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">driver</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">java</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">options</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">driver</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">library</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">path</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">properties</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">file</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">kill</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">status</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">supervise</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">queue</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">files</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">py</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">files</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">archives</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">jars</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">packages</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">exclude</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">packages</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">repositories</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">conf</span></span>&nbsp;(解析存入&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Map</span></span>：<span style="color:#407ee7;"><span style="color:#880000;">sparkProperties</span></span>&nbsp;中) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">proxy</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">user</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">principal</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">keytab</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">help</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">verbose</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">version</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">usage</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">error</span></span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">b</span></span>)&nbsp;合并&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">properties</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">file</span></span>&nbsp;(没有配置默认为&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">conf</span></span>/<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">defaults</span></span>.<span style="color:#407ee7;"><span style="color:#880000;">conf</span></span>)&nbsp;文件配置项&nbsp;(不在&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">conf</span></span>&nbsp;中的配置&nbsp;)&nbsp;至&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">sparkProperties</span></span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">c</span></span>)&nbsp;删除&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">sparkProperties</span></span>&nbsp;中不以&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">spark</span></span>.&nbsp;开头的配置项目 &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">d</span></span>)&nbsp;启动参数为空的配置项从&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">sparkProperties</span></span>&nbsp;中合并 &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">e</span></span>)&nbsp;根据&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">action</span></span>&nbsp;(<span style="color:#407ee7;"><span style="color:#880000;">SUBMIT</span></span>、<span style="color:#407ee7;"><span style="color:#880000;">KILL</span></span>、<span style="color:#407ee7;"><span style="color:#880000;">REQUEST_STATUS</span></span>)&nbsp;校验各自必需参数是否有值 2）<span style="color:#407ee7;"><span style="color:#880000;">Case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Submit</span></span>： &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">a</span></span>)&nbsp;获取<span style="color:#407ee7;"><span style="color:#880000;">childMainClass</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--<span style="color:#407ee7;"><span style="color:#880000;">deploy</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">mode</span></span>]&nbsp;</span>=&nbsp;clent(默认)：用户任务启动类&nbsp;mainClass&nbsp;(--<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">class</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--<span style="color:#407ee7;"><span style="color:#880000;">deploy</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">mode</span></span>]&nbsp;</span>=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;useRest&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.rest.RestSubmissionClient &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;!useRest&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.Client &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;yarn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.yarn.Client &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;mesos:*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;org.apache.spark.deploy.rest.RestSubmissionClient &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;获取&nbsp;childArgs&nbsp;(子运行时对应命令行组装参数) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;useRest&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;包含&nbsp;primaryResource&nbsp;与&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;spark:*&nbsp;&amp;&nbsp;!useRest&nbsp;&nbsp;&nbsp;&nbsp;包含&nbsp;--supervise&nbsp;--memory&nbsp;--cores&nbsp;&nbsp;launch&nbsp;childArg,&nbsp;primaryResource,&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;yarn&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">class</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">arg</span></span>&nbsp;--<span style="color:#407ee7;"><span style="color:#880000;">jar</span></span>/--<span style="color:#407ee7;"><span style="color:#880000;">primary</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">py</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">file</span></span>/--<span style="color:#407ee7;"><span style="color:#880000;">primary</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">r</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">file</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--<span style="color:#407ee7;"><span style="color:#880000;">deploy</span></span>-<span style="color:#407ee7;"><span style="color:#880000;">mode</span></span>]&nbsp;</span>=&nbsp;cluster&nbsp;&amp;&nbsp;&nbsp;[--master]&nbsp;=&nbsp;mesos:*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;primaryResource &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;获取&nbsp;childClasspath &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[--deploy-mode]&nbsp;=&nbsp;clent&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;读取&nbsp;--jars&nbsp;配置，与&nbsp;primaryResource&nbsp;信息&nbsp;(../examples/jars/spark-examples_2.11-<span style="color:#df5320;"><span style="color:#008800;">2.1</span></span>.0.jar) &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;获取&nbsp;sysProps &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;将&nbsp;sparkPropertie&nbsp;中的所有配置封装成新的&nbsp;sysProps&nbsp;对象，另外还增加了一下额外的配置项目 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;将&nbsp;childClasspath&nbsp;通过当前的类加载器加载中 &nbsp;&nbsp;&nbsp;&nbsp;f)&nbsp;将&nbsp;sysProps&nbsp;设置到当前&nbsp;jvm&nbsp;环境中 &nbsp;&nbsp;&nbsp;&nbsp;g)&nbsp;最终反射执行&nbsp;childMainClass，传参为&nbsp;childArgs </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label5_2"></a></span></span></p> 
  <h3 id="h63client" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>6.3 Client 启动流程</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Client 的启动流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPDeJ.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）SparkConf：加载&nbsp;key&nbsp;以&nbsp;spark.&nbsp;开头的系统属性&nbsp;(Utils.getSystemProperties)。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）ClientArguments： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;解析&nbsp;Client&nbsp;启动的参数： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;--cores&nbsp;-c&nbsp;--memory&nbsp;-m&nbsp;--supervise&nbsp;-s&nbsp;--verbose&nbsp;-v &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;launch&nbsp;jarUrl&nbsp;master&nbsp;mainClass &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kill&nbsp;master&nbsp;driverId &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;--properties-file&nbsp;(没有配置默认为&nbsp;conf/spark-defaults.conf)&nbsp;中以&nbsp;spark.&nbsp;开头的配置存入&nbsp;SparkConf。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;在没有配置情况下，cores&nbsp;默认为&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>&nbsp;核。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;在没有配置情况下，memory&nbsp;默认为&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>G。 &nbsp;&nbsp;&nbsp;&nbsp;e)&nbsp;NettyRpcEnv&nbsp;中的内部处理遵循&nbsp;RpcEndpoint&nbsp;统一处理，这里不再赘述。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）最终守护进程会一直存在等待结束信&nbsp;awaitTermination。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label5_3"></a></span></span></p> 
  <h3 id="h64clientonstart" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>6.4 Client 的 OnStart 监听事件</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Client 的启动完成后异步执行工作如下：　</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtP0L4.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）如果是发布任务(<span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;launch)，Client&nbsp;创建一个&nbsp;DriverDescription，并向&nbsp;Master&nbsp;发起&nbsp;RequestSubmitDriver&nbsp;请求。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;Command&nbsp;中的&nbsp;mainClass&nbsp;为：&nbsp;org.apache.spark.deploy.worker.DriverWrapper &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;Command&nbsp;中的&nbsp;arguments&nbsp;为：&nbsp;Seq(<span style="color:#7b9726;"><span style="color:#880000;">"{{WORKER_URL}}"</span></span>,&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"{{USER_JAR}}"</span></span>,&nbsp;driverArgs.mainClass) <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）Master&nbsp;接受&nbsp;RequestSubmitDriver&nbsp;请求后，将&nbsp;DriverDescription&nbsp;封装为&nbsp;一个DriverInfo。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;startTime&nbsp;与&nbsp;submitDate&nbsp;都为当前时间 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;driverId&nbsp;格式为：driver-yyyyMMddHHmmss-nextId，nextId&nbsp;是全局唯一的 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）Master&nbsp;持久化&nbsp;DriverInfo，并加入待调度列表中&nbsp;(waitingDrivers)，触发公共资源调度逻辑。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）Master&nbsp;公共资源调度结束后，返回&nbsp;SubmitDriverResponse给Client。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label5_4"></a></span></span></p> 
  <h3 id="h65rpcmessagereceiveandreply" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>6.5 RpcMessage 处理 (receiveAndReply)</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">无。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label5_5"></a></span></span></p> 
  <h3 id="h66onewaymessagereceive" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>6.6 OneWayMessage 处理(receive)</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPUzT.png"></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label6"></a></span></span></p> 
  <h2 id="h7driverdriverrunner" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第7章 Driver 和 DriverRunner</strong></span></span></strong></span></span></h2> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Client 向 Master 发起 RequestSubmitDriver 请求，Master 将 DriverInfo 添加待调度列表中 (waitingDrivers)，下面针对于 Driver 进一步梳理。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label6_0"></a></span></span></p> 
  <h3 id="h71masterdriver" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>7.1 Master 对 Driver 资源分配</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">大致流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPrw9.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">waitingDrivers&nbsp;与&nbsp;aliveWorkers&nbsp;进行资源匹配： <span style="color:#df5320;"><span style="color:#008800;">1</span></span>）在&nbsp;waitingDrivers&nbsp;循环内，轮询所有&nbsp;aliveWorker。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）如果&nbsp;aliveWorker&nbsp;满足当前&nbsp;waitingDriver&nbsp;资源要求，给&nbsp;Worker&nbsp;发送&nbsp;LaunchDriver&nbsp;指令并将&nbsp;waitingDriver&nbsp;移除&nbsp;waitingDrivers，则进行下一次&nbsp;waitingDriver&nbsp;的轮询工作。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）如果轮询完所有&nbsp;aliveWorker&nbsp;都不满足&nbsp;waitingDriver&nbsp;资源要求，则进行下一次&nbsp;waitingDriver&nbsp;的轮询工作。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）所有发起的轮询开始点都上次轮询结束点的下一个点位开始。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label6_1"></a></span></span></p> 
  <h3 id="h72workerdriverrunner" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>7.2 Worker 运行 DriverRunner</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Driver 的启动，流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtP6F1.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）当&nbsp;Worker&nbsp;遇到&nbsp;LaunchDriver&nbsp;指令时，创建并启动一个&nbsp;DriverRunner。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）DriverRunner&nbsp;启动一个线程&nbsp;DriverRunner&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">for</span></span>&nbsp;[driverId]&nbsp;处理&nbsp;Driver&nbsp;启动工作。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）DriverRunner&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">for</span></span>&nbsp;[driverId]： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;添加&nbsp;JVM&nbsp;钩子，针对于每个&nbsp;diriverId&nbsp;创建一个临时目录。 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;DriverDesc.jarUrl&nbsp;通过&nbsp;Netty&nbsp;从&nbsp;Driver&nbsp;机器远程拷贝过来。 &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;根据&nbsp;DriverDesc.command&nbsp;模板构建本地执行的&nbsp;command&nbsp;命令，并启动该&nbsp;command&nbsp;对应的&nbsp;Process&nbsp;进程。 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;将&nbsp;Process&nbsp;的输出流输出到文件&nbsp;stdout/stderror，如果&nbsp;Process&nbsp;启动失败，进行&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>-<span style="color:#df5320;"><span style="color:#008800;">5</span></span>&nbsp;的秒的反复启动工作，直到启动成功，在释放&nbsp;Worker&nbsp;节点的&nbsp;DriverRunner&nbsp;的资源。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label6_2"></a></span></span></p> 
  <h3 id="h73driverrunnerdriverwrapper" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>7.3 DriverRunner 创建并运行 DriverWrapper</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">DriverWrapper 的运行，流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPsoR.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）DriverWapper&nbsp;创建了一个&nbsp;RpcEndpoint&nbsp;与&nbsp;RpcEnv。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）RpcEndpoint&nbsp;为&nbsp;WorkerWatcher，主要目的为监控&nbsp;Worker&nbsp;节点是否正常，如果出现异常就直接退出。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）然后当前的&nbsp;ClassLoader&nbsp;加载&nbsp;userJar，同时执行&nbsp;userMainClass。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）执行用户的&nbsp;main&nbsp;方法后关闭&nbsp;workerWatcher。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label7"></a></span></span></p> 
  <h2 id="h8sparkcontext" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第8章 SparkContext 解析</strong></span></span></strong></span></span></h2> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label7_0"></a></span></span></p> 
  <h3 id="h81sparkcontext" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>8.1 SparkContext 解析</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">SparkContext 是用户通往 Spark 集群的唯一入口，任何需要使用 Spark 的地方都需要先创建 SparkContext，那么 SparkContext 做了什么？<br> 首先 SparkContext 是在 Driver 程序里面启动的，可以看做 Driver 程序和 Spark 集群的一个连接，SparkContext 在初始化的时候，创建了很多对象，如下图所示：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPcJx.png"><br> 上图列出了 SparkContext 在初始化创建的时候的一些主要组件的构建。<a name="_label7_1"></a></span></span></p> 
  <h3 id="h82sparkcontext" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>8.2 SparkContext 创建过程</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPhOe.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">SparkContext&nbsp;在新建时： <span style="color:#df5320;"><span style="color:#008800;">1</span></span>）内部创建一个&nbsp;SparkEnv，SparkEnv&nbsp;内部创建一个&nbsp;RpcEnv。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;RpcEnv&nbsp;内部创建并注册一个&nbsp;MapOutputTrackerMasterEndpoint(该&nbsp;Endpoint&nbsp;暂不介绍) <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）接着创建&nbsp;DAGScheduler、TaskSchedulerImpl、SchedulerBackend。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;TaskSchedulerImpl&nbsp;创建时创建&nbsp;SchedulableBuilder，SchedulableBuilder&nbsp;根据类型分为&nbsp;FIFOSchedulableBuilder、FairSchedulableBuilder&nbsp;两类 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）最后启动&nbsp;TaskSchedulerImpl，TaskSchedulerImpl&nbsp;启动&nbsp;SchedulerBackend。 &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;SchedulerBackend&nbsp;启动时创建&nbsp;ApplicationDescription、DriverEndpoint、StandloneAppClient &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;StandloneAppClient&nbsp;内部包括一个&nbsp;ClientEndpoint </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label7_2"></a></span></span></p> 
  <h3 id="h83sparkcontext" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>8.3 SparkContext 简易结构与交互关系</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPgW6.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）SparkContext：是用户&nbsp;Spark&nbsp;执行任务的上下文，用户程序内部使用&nbsp;Spark&nbsp;提供的&nbsp;Api&nbsp;直接或间接创建一个&nbsp;SparkContext。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）SparkEnv：用户执行的环境信息，包括通信相关的端点。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）RpcEnv：SparkContext&nbsp;中远程通信环境。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）ApplicationDescription：应用程序描述信息，主要包含&nbsp;appName、maxCores、memoryPerExecutorMB、coresPerExecutor、Command&nbsp;(CoarseGrainedExecutorBackend)、appUiUrl&nbsp;等。 <span style="color:#df5320;"><span style="color:#008800;">5</span></span>）ClientEndpoint：客户端端点，启动后向&nbsp;Master&nbsp;发起注册&nbsp;RegisterApplication&nbsp;请求。 <span style="color:#df5320;"><span style="color:#008800;">6</span></span>）Master：接受&nbsp;RegisterApplication&nbsp;请求后，进行&nbsp;Worker&nbsp;资源分配，并向分配的资源发起&nbsp;LaunchExecutor&nbsp;指令。 <span style="color:#df5320;"><span style="color:#008800;">7</span></span>）Worker：接受&nbsp;LaunchExecutor&nbsp;指令后，运行&nbsp;ExecutorRunner。 <span style="color:#df5320;"><span style="color:#008800;">8</span></span>）ExecutorRunner：运行&nbsp;applicationDescription&nbsp;的&nbsp;Command&nbsp;命令，最终&nbsp;Executor，同时向&nbsp;DriverEndpoint&nbsp;注册&nbsp;Executor&nbsp;信息。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label7_3"></a></span></span></p> 
  <h3 id="h84masterapplication" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>8.4 Master 对 Application 资源分配</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">当 Master 接受 Driver 的 RegisterApplication 请求后，放入 waitingDrivers 队列中，在同一调度中进行资源分配，分配过程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPRSK.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">waitingApps&nbsp;与&nbsp;aliveWorkers&nbsp;进行资源匹配： <span style="color:#df5320;"><span style="color:#008800;">1</span></span>）如果&nbsp;waitingApp&nbsp;配置了&nbsp;app.desc.coresPerExecutor： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;轮询所有有效可分配的&nbsp;worker，每次分配一个&nbsp;executor，executor&nbsp;的核数为&nbsp;minCoresPerExecutor(app.desc.coresPerExecutor)，直到不存在有效可分配资源或者&nbsp;app&nbsp;依赖的资源已全部被分配。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）如果&nbsp;waitingApp&nbsp;没有配置&nbsp;app.desc.coresPerExecutor： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;轮询所有有效可分配的&nbsp;worker，每个&nbsp;worker&nbsp;分配一个&nbsp;executor，executor&nbsp;的核数为从&nbsp;minCoresPerExecutor(为固定值<span style="color:#df5320;"><span style="color:#008800;">1</span></span>)&nbsp;开始递增，直到不存在有效可分配资源或者&nbsp;app&nbsp;依赖的资源已全部被分配。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）其中有效可分配&nbsp;worker&nbsp;定义为满足一次资源分配的&nbsp;worker： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;cores&nbsp;满足：usableWorkers(pos).coresFree&nbsp;-&nbsp;assignedCores(pos)&nbsp;&gt;=&nbsp;minCoresPerExecutor &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;memory&nbsp;满足(如果是新的&nbsp;Executor)：usableWorkers(pos).memoryFree&nbsp;-&nbsp;assignedExecutors(pos)&nbsp;*&nbsp;memoryPerExecutor&nbsp;&gt;=&nbsp;memoryPerExecutor 注意：Master&nbsp;针对于&nbsp;applicationInfo&nbsp;进行资源分配时，只有存在有效可用的资源就直接分配，而分配剩余的&nbsp;app.coresLeft&nbsp;则等下一次再进行分配。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label7_4"></a></span></span></p> 
  <h3 id="h85workerexecutor" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>8.5 Worker 创建 Executor</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtP7FI.png"><br> （图解：橙色组件是 Endpoint 组件）</span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">Worker&nbsp;启动&nbsp;Executor <span style="color:#df5320;">1</span>）在&nbsp;Worker&nbsp;的&nbsp;tempDir&nbsp;下面创建&nbsp;application&nbsp;以及&nbsp;executor&nbsp;的目录，并&nbsp;chmod&nbsp;<span style="color:#df5320;"><span style="color:#008800;">700</span></span>&nbsp;操作权限。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）创建并启动&nbsp;ExecutorRunner&nbsp;进行&nbsp;Executor&nbsp;的创建。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）向&nbsp;Master&nbsp;发送&nbsp;Executor&nbsp;的状态情况。 ExecutorRnner <span style="color:#df5320;">1</span>）新线程【ExecutorRunner&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">for</span></span>&nbsp;[executorId]】读取&nbsp;ApplicationDescription&nbsp;将其中&nbsp;Command&nbsp;转化为本地的&nbsp;Command&nbsp;命令。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）调用&nbsp;Command&nbsp;并将日志输出至&nbsp;executor&nbsp;目录下的&nbsp;stdout&nbsp;和&nbsp;stderr&nbsp;日志文件中，Command&nbsp;对应的&nbsp;java&nbsp;类为&nbsp;CoarseGrainedExecutorBackend。 CoarseGrainedExecutorBackend <span style="color:#df5320;">1</span>）创建一个&nbsp;SparkEnv，创建&nbsp;ExecutorEndpoint(CoarseGrainedExecutorBackend)以及&nbsp;WorkerWatcher。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）ExecutorEndpoint&nbsp;创建并启动后，向&nbsp;DriverEndpoint&nbsp;发送&nbsp;RegisterExecutor&nbsp;请求并等待返回。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）DriverEndpoint&nbsp;处理&nbsp;RegisterExecutor&nbsp;请求，返回&nbsp;ExecutorEndpointRegister&nbsp;的结果。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）如果注册成功，ExecutorEndpoint&nbsp;内部再创建&nbsp;Executor&nbsp;的处理对象。 至此，Spark&nbsp;运行任务的容器框架就搭建完成。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label8"></a></span></span></p> 
  <h2 id="h9jobtask" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第9章 Job 提交和 Task 的拆分</strong></span></span></strong></span></span></h2> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在前面的章节 Client 的加载中，Spark 的 DriverRunner 已开始执行用户任务类（比如：org.apache.spark.examples.SparkPi），下面我们开始针对于用户任务类（或者任务代码）进行分析：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label8_0"></a></span></span></p> 
  <h3 id="h91" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>9.1 整体预览</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPWQO.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）Code：指的用户编写的代码 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）RDD：弹性分布式数据集，用户编码根据&nbsp;SparkContext&nbsp;与&nbsp;RDD&nbsp;的&nbsp;api&nbsp;能够很好的将&nbsp;Code&nbsp;转化为&nbsp;RDD&nbsp;数据结构(下文将做转化细节介绍)。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）DAGScheduler：有向无环图调度器，将&nbsp;RDD&nbsp;封装为&nbsp;JobSubmitted&nbsp;对象存入&nbsp;EventLoop&nbsp;(实现类DAGSchedulerEventProcessLoop)&nbsp;队列中。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）EventLoop：&nbsp;定时扫描未处理&nbsp;JobSubmitted&nbsp;对象，将&nbsp;JobSubmitted&nbsp;对象提交给&nbsp;DAGScheduler。 <span style="color:#df5320;"><span style="color:#008800;">5</span></span>）DAGScheduler：针对于&nbsp;JobSubmitted&nbsp;进行处理，最终将&nbsp;RDD&nbsp;转化为执行&nbsp;TaskSet，并将&nbsp;TaskSet&nbsp;提交至&nbsp;TaskScheduler。 <span style="color:#df5320;"><span style="color:#008800;">6</span></span>）TaskScheduler：&nbsp;根据&nbsp;TaskSet&nbsp;创建&nbsp;TaskSetManager&nbsp;对象存入&nbsp;SchedulableBuilder&nbsp;的数据池(Pool)中，并调用&nbsp;DriverEndpoint&nbsp;唤起消费(ReviveOffers)操作。 <span style="color:#df5320;"><span style="color:#008800;">7</span></span>）DriverEndpoint：接受&nbsp;ReviveOffers&nbsp;指令后将&nbsp;TaskSet&nbsp;中的&nbsp;Tasks&nbsp;根据相关规则均匀分配给Executor。 <span style="color:#df5320;"><span style="color:#008800;">8</span></span>）Executor：启动一个&nbsp;TaskRunner&nbsp;执行一个&nbsp;Task。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label8_1"></a></span></span></p> 
  <h3 id="h92coderdds" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>9.2 Code 转化为初始 RDDs</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">我们的用户代码通过调用 Spark 的 Api（比如：SparkSession.builder.appName("Spark Pi").getOrCreate()），该 Api 会创建 Spark 的上下文（SparkContext），当我们调用 transform 类方法（如：parallelize(),map()）都会创建（或者装饰已有的）Spark 数据结构（RDD），如果是 action 类操作（如：reduce()），那么将最后封装的 RDD 作为一次 Job 提交，存入待调度队列中（DAGSchedulerEventProcessLoop ）待后续异步处理。<br> 如果多次调用 action 类操作，那么封装的多个 RDD 作为多个 Job 提交。<br> 流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPfyD.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">ExecuteEnv（执行环境） <span style="color:#df5320;"><span style="color:#008800;">1</span></span>）这里可以是通过&nbsp;spark-submit&nbsp;提交的&nbsp;MainClass，也可以是&nbsp;spark-shell&nbsp;脚本。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）MainClass：代码中必定会创建或者获取一个&nbsp;SparkContext。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）spark-shell：默认会创建一个&nbsp;SparkContext。 RDD（弹性分布式数据集） <span style="color:#df5320;"><span style="color:#008800;">1</span></span>）create：可以直接创建（如：sc.parallelize(<span style="color:#df5320;"><span style="color:#008800;">1</span></span>&nbsp;until&nbsp;n,&nbsp;slices)&nbsp;），也可以在其他地方读取（如：sc.textFile(<span style="color:#7b9726;"><span style="color:#880000;">"README.md"</span></span>)）等。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）transformation：rdd&nbsp;提供了一组&nbsp;api&nbsp;可以进行对已有&nbsp;RDD&nbsp;进行反复封装成为新的&nbsp;RDD，这里采用的是`装饰者设计模式`，下面为部分装饰器类图。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）action：当调用&nbsp;RDD&nbsp;的&nbsp;action&nbsp;类操作方法时（collect、reduce、lookup、save&nbsp;），这触发&nbsp;DAGScheduler&nbsp;的&nbsp;Job&nbsp;提交。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）DAGScheduler：创建一个名为&nbsp;JobSubmitted&nbsp;的消息至&nbsp;DAGSchedulerEventProcessLoop&nbsp;阻塞消息队列（LinkedBlockingDeque）中。 <span style="color:#df5320;"><span style="color:#008800;">5</span></span>）DAGSchedulerEventProcessLoop：启动名为【dag-scheduler-event-loop】的线程实时消费消息队列。 <span style="color:#df5320;"><span style="color:#008800;">6</span></span>）【dag-scheduler-event-loop】处理完成后回调&nbsp;JobWaiter。 <span style="color:#df5320;"><span style="color:#008800;">7</span></span>）DAGScheduler：打印&nbsp;Job&nbsp;执行结果。 <span style="color:#df5320;"><span style="color:#008800;">8</span></span>）JobSubmitted：相关代码如下（其中&nbsp;jobId&nbsp;为&nbsp;DAGScheduler&nbsp;全局递增&nbsp;Id）。 &nbsp;&nbsp;&nbsp;&nbsp;eventProcessLoop.post(JobSubmitted( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobId,&nbsp;rdd,&nbsp;func2,&nbsp;partitions.toArray,&nbsp;callSite,&nbsp;waiter, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SerializationUtils.clone(properties))) </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">部分装饰器类图</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtP5eH.png"><br> 最终示例：<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPoTA.png"><br> 最终转化的 RDD 分为四层，每层都依赖于上层 RDD，将 ShffleRDD 封装为一个 Job 存入 DAGSchedulerEventProcessLoop 待处理，如果我们的代码中存在几段上面示例代码，那么就会创建对应对的几个 ShffleRDD 分别存入 DAGSchedulerEventProcessLoop 中。<a name="_label8_2"></a></span></span></p> 
  <h3 id="h93rddtaskset" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>9.3 RDD 分解为待执行任务集合（TaskSet）</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Job 提交后，DAGScheduler 根据 RDD 层次关系解析为对应的 Stages，同时维护 Job 与 Stage 的关系。<br> 将最上层的 Stage 根据并发关系（findMissingPartitions）分解为多个 Task，将这个多个 Task 封装为 TaskSet 提交给 TaskScheduler。非最上层的 Stage 的存入处理的列表中（waitingStages += stage）<br> 流程如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPIwd.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）DAGSchedulerEventProcessLoop中，线程【dag-scheduler-event-loop】处理到&nbsp;JobSubmitted <span style="color:#df5320;">2</span>）调用&nbsp;DAGScheduler&nbsp;进行&nbsp;handleJobSubmitted &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;首先根据&nbsp;RDD&nbsp;依赖关系依次创建&nbsp;Stage&nbsp;族，Stage&nbsp;分为&nbsp;ShuffleMapStage、ResultStage&nbsp;两类，如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;更新&nbsp;jobId&nbsp;与&nbsp;StageId&nbsp;关系&nbsp;Map &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;创建&nbsp;ActiveJob，调用&nbsp;LiveListenerBug，发送&nbsp;SparkListenerJobStart&nbsp;指令 &nbsp;&nbsp;&nbsp;&nbsp;d)&nbsp;找到最上层&nbsp;Stage&nbsp;进行提交，下层&nbsp;Stage&nbsp;存入&nbsp;waitingStage&nbsp;中待后续处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>)&nbsp;调用&nbsp;OutputCommitCoordinator&nbsp;进行&nbsp;stageStart()&nbsp;处理 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">2</span></span>)&nbsp;调用&nbsp;LiveListenerBug，发送&nbsp;SparkListenerStageSubmitted&nbsp;指令 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">3</span></span>)&nbsp;调用&nbsp;SparkContext的broadcast&nbsp;方法获取&nbsp;Broadcast&nbsp;对象，根据&nbsp;Stage&nbsp;类型创建对应多个&nbsp;Task，一个&nbsp;Stage&nbsp;根据&nbsp;findMissingPartitions&nbsp;分为多个对应的&nbsp;Task，Task&nbsp;分为&nbsp;ShuffleMapTask、ResultTask &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">4</span></span>)&nbsp;将&nbsp;Task&nbsp;封装为&nbsp;TaskSet，调用&nbsp;TaskScheduler.submitTasks(taskSet)&nbsp;进行&nbsp;Task&nbsp;调度，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskScheduler.submitTasks(<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;TaskSet( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tasks.toArray,&nbsp;stage.id,&nbsp;stage.latestInfo.attemptId,&nbsp;jobId,&nbsp;properties)) </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">ShuffleMapStage、ResultStage 两类</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/ENpVtx.png"><a name="_label8_3"></a></span></span></p> 
  <h3 id="h94tasksettasksetmanagerdriver" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>9.4 TaskSet 封装为 TaskSetManager 并提交至 Driver</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">TaskScheduler 将 TaskSet 封装为 TaskSetManager(new TaskSetManager(this, taskSet, maxTaskFailures, blacklistTrackerOpt))，存入待处理任务池（Pool）中，发送 DriverEndpoint 唤起消费（ReviveOffers）指令。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPbfP.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）DAGSheduler&nbsp;将&nbsp;TaskSet&nbsp;提交给&nbsp;TaskScheduler&nbsp;的实现类，这里是&nbsp;TaskChedulerImpl。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）TaskSchedulerImpl&nbsp;创建一个&nbsp;TaskSetManager&nbsp;管理&nbsp;TaskSet，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;TaskSetManager(<span style="color:#6666ea;"><span style="color:#0000ff;">this</span></span>,&nbsp;taskSet,&nbsp;maxTaskFailures,&nbsp;blacklistTrackerOpt) <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）同时将&nbsp;TaskSetManager&nbsp;添加&nbsp;SchedduableBuilder&nbsp;的任务池&nbsp;Poll&nbsp;中。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）调用&nbsp;SchedulerBackend&nbsp;的实现类进行&nbsp;reviveOffers，这里是&nbsp;standlone&nbsp;模式的实现类&nbsp;StandaloneSchedulerBackend。 <span style="color:#df5320;"><span style="color:#008800;">5</span></span>）SchedulerBackend&nbsp;发送&nbsp;ReviveOffers&nbsp;指令至&nbsp;DriverEndpoint。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label8_4"></a></span></span></p> 
  <h3 id="h95drivertasksetmanagertaskdescriptionsexecutor" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>9.5 Driver 将 TaskSetManager 分解为 TaskDescriptions 并发布任务到 Executor</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Driver 接受唤起消费指令后，将所有待处理的 TaskSetManager 与 Driver 中注册的 Executor 资源进行匹配，最终一个 TaskSetManager 得到多个 TaskDescription 对象，按照 TaskDescription 相对应的 Executor 发送 LaunchTask 指令。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPxmQ.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">当&nbsp;Driver&nbsp;获取到&nbsp;ReviveOffers（请求消费）指令时 <span style="color:#df5320;"><span style="color:#008800;">1</span></span>）首先根据&nbsp;executorDataMap&nbsp;缓存信息得到可用的&nbsp;Executor&nbsp;资源信息（WorkerOffer），关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;activeExecutors&nbsp;=&nbsp;executorDataMap.filterKeys(executorIsAlive) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;workOffers&nbsp;=&nbsp;activeExecutors.map&nbsp;{&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;(id,&nbsp;executorData)&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;WorkerOffer(id,&nbsp;executorData.executorHost,&nbsp;executorData.freeCores) &nbsp;&nbsp;&nbsp;&nbsp;}.toIndexedSeq <span style="color:#df5320;">2</span>）接着调用&nbsp;TaskScheduler&nbsp;进行资源匹配，方法定义如下： &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">resourceOffers</span></span><span style="color:#df5320;">(offers:&nbsp;IndexedSeq[WorkerOffer])</span>:&nbsp;Seq[Seq[TaskDescription]]&nbsp;</span>=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">synchronized</span></span>&nbsp;{..} &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;将&nbsp;WorkerOffer&nbsp;资源打乱，如：val&nbsp;shuffledOffers&nbsp;=&nbsp;Random.shuffle(offers) &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;将&nbsp;Pool&nbsp;中待处理的&nbsp;TaskSetManager&nbsp;取出，如：val&nbsp;sortedTaskSets&nbsp;=&nbsp;rootPool.getSortedTaskSetQueue &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;并循环处理&nbsp;sortedTaskSets&nbsp;并与&nbsp;shuffledOffers&nbsp;循环匹配，如果&nbsp;shuffledOffers(i)&nbsp;有足够的&nbsp;CPU&nbsp;资源（&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(availableCpus(i)&nbsp;&gt;=&nbsp;CPUS_PER_TASK)），调用&nbsp;TaskSetManager&nbsp;创建&nbsp;TaskDescription&nbsp;对象（taskSet.resourceOffer(execId,&nbsp;host,&nbsp;maxLocality)），最终创建了多个&nbsp;TaskDescription，TaskDescription&nbsp;定义如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;TaskDescription( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attemptNum, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;execId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskName, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;index, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sched.sc.addedFiles, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sched.sc.addedJars, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;task.localProperties, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serializedTask) <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）如果&nbsp;TaskDescriptions&nbsp;不为空，循环&nbsp;TaskDescriptions，序列化&nbsp;TaskDescription&nbsp;对象，并向&nbsp;ExecutorEndpoint&nbsp;发送&nbsp;LaunchTask&nbsp;指令，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">for</span></span>&nbsp;(task&nbsp;&lt;-&nbsp;taskDescriptions.flatten)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;serializedTask&nbsp;=&nbsp;TaskDescription.encode(task) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;executorData&nbsp;=&nbsp;executorDataMap(task.executorId) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorData.freeCores&nbsp;-=&nbsp;scheduler.CPUS_PER_TASK &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorData.executorEndpoint.send(LaunchTask(<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;SerializableBuffer(serializedTask))) &nbsp;&nbsp;&nbsp;&nbsp;} </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label9"></a></span></span></p> 
  <h2 id="h10task" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第10章 Task 执行和回馈</strong></span></span></strong></span></span></h2> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">DriverEndpoint 最终生成多个可执行的 TaskDescription 对象，并向各个 ExecutorEndpoint 发送 LaunchTask 指令，本节内容将关注 ExecutorEndpoint 如何处理 LaunchTask 指令，处理完成后如何回馈给 DriverEndpoint，以及整个 job 最终如何多次调度直至结束。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label9_0"></a></span></span></p> 
  <h3 id="h101task" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>10.1 Task 的执行流程</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Executor 接受 LaunchTask 指令后，开启一个新线程 TaskRunner 解析 RDD，并调用 RDD 的 compute 方法，归并函数得到最终任务执行结果。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPX6S.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）ExecutorEndpoint&nbsp;接受到&nbsp;LaunchTask&nbsp;指令后，解码出&nbsp;TaskDescription，调用&nbsp;Executor&nbsp;的&nbsp;launchTask&nbsp;方法。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）Executor&nbsp;创建一个&nbsp;TaskRunner&nbsp;线程，并启动线程，同时将改线程添加到&nbsp;Executor&nbsp;的成员对象中，代码如下： &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>&nbsp;val&nbsp;runningTasks&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;ConcurrentHashMap[Long,&nbsp;TaskRunner] &nbsp;&nbsp;&nbsp;&nbsp;runningTasks.put(taskDescription.taskId,&nbsp;taskRunner) TaskRunner <span style="color:#df5320;">1</span>）首先向&nbsp;DriverEndpoint&nbsp;发送任务最新状态为&nbsp;RUNNING。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）从&nbsp;TaskDescription&nbsp;解析出&nbsp;Task，并调用&nbsp;Task&nbsp;的&nbsp;run&nbsp;方法。 Task <span style="color:#df5320;">1</span>）创建&nbsp;TaskContext&nbsp;以及&nbsp;CallerContext&nbsp;(与&nbsp;HDFS&nbsp;交互的上下文对象)。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）执行&nbsp;Task&nbsp;的&nbsp;runTask&nbsp;方法： &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;如果&nbsp;Task&nbsp;实例为&nbsp;ShuffleMapTask：解析出&nbsp;RDD&nbsp;以及&nbsp;ShuffleDependency&nbsp;信息，调用&nbsp;RDD&nbsp;的&nbsp;compute()&nbsp;方法将结果写&nbsp;Writer&nbsp;中（Writer&nbsp;这里不介绍，可以作为黑盒理解，比如写入一个文件中），返回&nbsp;MapStatus&nbsp;对象。 &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;如果&nbsp;Task&nbsp;实例为&nbsp;ResultTask：解析出&nbsp;RDD&nbsp;以及合并函数信息，调用函数将调用后的结果返回。 TaskRunner&nbsp;将&nbsp;Task&nbsp;执行的结果序列化，再次向&nbsp;DriverEndpoint&nbsp;发送任务最新状态为&nbsp;FINISHED。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label9_1"></a></span></span></p> 
  <h3 id="h102task" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>10.2 Task 的回馈流程</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">TaskRunner 执行结束后，都将执行状态发送至 DriverEndpoint，DriverEndpoint 最终反馈指令 CompletionEvent 发送至 DAGSchedulerEventProcessLoop 中。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPLSf.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）DriverEndpoint&nbsp;接收到&nbsp;StatusUpdate&nbsp;消息后，调用&nbsp;TaskScheduler&nbsp;的&nbsp;statusUpdate(taskId,&nbsp;state,&nbsp;result)&nbsp;方法 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）TaskScheduler&nbsp;如果任务结果是完成，那么清除该任务处理中的状态，并调动&nbsp;TaskResultGetter&nbsp;相关方法，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;taskSet&nbsp;=&nbsp;taskIdToTaskSetManager.get(tid) &nbsp;&nbsp;&nbsp;&nbsp;taskIdToTaskSetManager.remove(tid) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskIdToExecutorId.remove(tid).foreach&nbsp;{&nbsp;executorId&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;executorIdToRunningTaskIds.get(executorId).foreach&nbsp;{&nbsp;_.remove(tid)&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;taskSet.removeRunningTask(tid) &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(state&nbsp;==&nbsp;TaskState.FINISHED)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskResultGetter.enqueueSuccessfulTask(taskSet,&nbsp;tid,&nbsp;serializedData) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(Set(TaskState.FAILED,&nbsp;TaskState.KILLED,&nbsp;TaskState.LOST).contains(state))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskResultGetter.enqueueFailedTask(taskSet,&nbsp;tid,&nbsp;state,&nbsp;serializedData) &nbsp;&nbsp;&nbsp;&nbsp;} TaskResultGetter&nbsp;启动线程启动线程【task-result-getter】进行相关处理： <span style="color:#df5320;"><span style="color:#008800;">1</span></span>）通过解析或者远程获取得到&nbsp;Task&nbsp;的&nbsp;TaskResult&nbsp;对象。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）调用&nbsp;TaskSet&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法，TaskSet&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法直接调用&nbsp;TaskSetManager&nbsp;的&nbsp;handleSuccessfulTask&nbsp;方法。 TaskSetManager <span style="color:#df5320;">1</span>）更新内部&nbsp;TaskInfo&nbsp;对象状态，并将该&nbsp;Task&nbsp;从运行中&nbsp;Task&nbsp;的集合删除，代码如下： &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;info&nbsp;=&nbsp;taskInfos(tid) &nbsp;&nbsp;&nbsp;&nbsp;info.markFinished(TaskState.FINISHED,&nbsp;clock.getTimeMillis()) &nbsp;&nbsp;&nbsp;&nbsp;removeRunningTask(tid) <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）调用&nbsp;DAGScheduler&nbsp;的&nbsp;taskEnded&nbsp;方法，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;sched.dagScheduler.taskEnded(tasks(index),&nbsp;Success,&nbsp;result.value(),&nbsp;result.accumUpdates,&nbsp;info) DAGScheduler&nbsp;向&nbsp;DAGSchedulerEventProcessLoop&nbsp;存入&nbsp;CompletionEvent&nbsp;指令，CompletionEvent&nbsp;对象定义如下： &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>[scheduler]&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;class&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">CompletionEvent</span></span><span style="color:#df5320;">( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;task:&nbsp;Task[_], &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reason:&nbsp;TaskEndReason, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result:&nbsp;Any, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;accumUpdates:&nbsp;Seq[AccumulatorV2[_,&nbsp;_]], &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;taskInfo:&nbsp;TaskInfo)</span>&nbsp;extends&nbsp;DAGSchedulerEvent </span></code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label9_2"></a></span></span></p> 
  <h3 id="h103task" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>10.3 Task 的迭代流程</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">DAGSchedulerEventProcessLoop 中针对于 CompletionEvent 指令，调用 DAGScheduler 进行处理，DAGScheduler 更新 Stage 与该 Task 的关系状态，如果 Stage 下 Task 都返回，则做下一层 Stage 的任务拆解与运算工作，直至 Job 被执行完毕：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPzwj.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">详解如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）DAGSchedulerEventProcessLoop&nbsp;接收到&nbsp;CompletionEvent&nbsp;指令后，调用&nbsp;DAGScheduler&nbsp;的&nbsp;handleTaskCompletion&nbsp;方法。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）DAGScheduler&nbsp;根据&nbsp;Task&nbsp;的类型分别处理。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）如果&nbsp;Task&nbsp;为&nbsp;ShuffleMapTask &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;等待回馈的&nbsp;Partitions&nbsp;减去当前&nbsp;partitionId &nbsp;&nbsp;&nbsp;&nbsp;b)&nbsp;如果所有&nbsp;task&nbsp;都返回，则&nbsp;markStageAsFinished(shuffleStage)，同时向&nbsp;MapOutputTrackerMaster&nbsp;注册&nbsp;MapOutputs&nbsp;信息，且&nbsp;markMapStageJobAsFinished &nbsp;&nbsp;&nbsp;&nbsp;c)&nbsp;调用&nbsp;submitWaitingChildStages(shuffleStage)&nbsp;进行下层&nbsp;Stages&nbsp;的处理，从而迭代处理，最终处理到&nbsp;ResultTask，job&nbsp;结束，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">submitWaitingChildStages</span></span><span style="color:#df5320;">(parent:&nbsp;Stage)</span>&nbsp;</span>{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;childStages&nbsp;=&nbsp;waitingStages.filter(_.parents.contains(parent)).toArray &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingStages&nbsp;--=&nbsp;<span style="color:inherit;">childStages &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">for</span></span>&nbsp;<span style="color:#df5320;">(stage&nbsp;&lt;-&nbsp;childStages.sortBy(_.firstJobId)</span>)&nbsp;</span>{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;submitStage(stage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）如果&nbsp;Task&nbsp;为&nbsp;ResultTask &nbsp;&nbsp;&nbsp;&nbsp;a)&nbsp;该&nbsp;job&nbsp;的&nbsp;partitions&nbsp;都已返回，则&nbsp;markStageAsFinished(resultStage)，并&nbsp;cleanupStateForJobAndIndependentStages(job)，关键代码如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">for</span></span>&nbsp;(stage&nbsp;&lt;-&nbsp;stageIdToStage.get(stageId))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(runningStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(<span style="color:#7b9726;"><span style="color:#880000;">"Removing&nbsp;running&nbsp;stage&nbsp;%d"</span></span>.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;runningStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">for</span></span>&nbsp;((k,&nbsp;v)&nbsp;&lt;-&nbsp;shuffleIdToMapStage.find(_._2&nbsp;==&nbsp;stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;shuffleIdToMapStage.remove(k) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(waitingStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(<span style="color:#7b9726;"><span style="color:#880000;">"Removing&nbsp;stage&nbsp;%d&nbsp;from&nbsp;waiting&nbsp;set."</span></span>.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;waitingStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(failedStages.contains(stage))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(<span style="color:#7b9726;"><span style="color:#880000;">"Removing&nbsp;stage&nbsp;%d&nbsp;from&nbsp;failed&nbsp;set."</span></span>.format(stageId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;failedStages&nbsp;-=&nbsp;stage &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;data&nbsp;structures&nbsp;based&nbsp;on&nbsp;StageId</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;stageIdToStage&nbsp;-=&nbsp;stageId</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobIdToStageIds&nbsp;-=&nbsp;job.jobId</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;jobIdToActiveJob&nbsp;-=&nbsp;job.jobId</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;activeJobs&nbsp;-=&nbsp;job</span> <span style="color:#888888;">至此，用户编写的代码最终调用&nbsp;Spark&nbsp;分布式计算完毕。</span> </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label9_3"></a></span></span></p> 
  <h3 id="h104" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>10.4 精彩图解</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Spark的交互流程 – 节点启动</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPOl8.png"><br> Spark的交互流程 – 应用提交<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtPjOg.png"><br> Spark的交互流程 – 任务运行<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtjLi8.png"><br> Spark的交互流程 – 任务运行<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etj7Zt.png"></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label10"></a></span></span></p> 
  <h2 id="h11spark" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第11章 Spark 的数据存储</strong></span></span></strong></span></span></h2> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Spark 计算速度远胜于 Hadoop 的原因之一就在于中间结果是缓存在内存而不是直接写入到 disk，本文尝试分析 Spark 中存储子系统的构成，并以数据写入和数据读取为例，讲述清楚存储子系统中各部件的交互关系。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label10_0"></a></span></span></p> 
  <h3 id="h111" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.1 存储子系统概览</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Storage 模块主要分为两层：<br>   1) 通信层：storage 模块采用的是 master-slave 结构来实现通信层，master 和 slave 之间传输控制信息、状态信息，这些都是通过通信层来实现的。<br>   2) 存储层：storage 模块需要把数据存储到 disk 或是 memory 上面，有可能还需 replicate(复制) 到远端，这都是由存储层来实现和提供相应接口。<br> 而其他模块若要和 storage 模块进行交互，storage 模块提供了统一的操作类 BlockManager，外部类与 storage 模块打交道都需要通过调用 BlockManager 相应接口来实现。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtjbIf.png"><br> 上图是Spark存储子系统中几个主要模块的关系示意图，现简要说明如下：</span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）CacheManager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RDD&nbsp;在进行计算的时候，通过&nbsp;CacheManager&nbsp;来获取数据，并通过&nbsp;CacheManager&nbsp;来存储计算结果。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）BlockManager&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;CacheManager&nbsp;在进行数据读取和存取的时候主要是依赖&nbsp;BlockManager&nbsp;接口来操作，BlockManager&nbsp;决定数据是从内存(MemoryStore)&nbsp;还是从磁盘(DiskStore)&nbsp;中获取。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）MemoryStore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;负责将数据保存在内存或从内存读取。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）DiskStore&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;负责将数据写入磁盘或从磁盘读入。 <span style="color:#df5320;"><span style="color:#008800;">5</span></span>）BlockManagerWorker&nbsp;&nbsp;&nbsp;数据写入本地的&nbsp;MemoryStore&nbsp;或&nbsp;DiskStore&nbsp;是一个同步操作，为了容错还需要将数据复制到别的计算结点，以防止数据丢失的时候还能够恢复，数据复制的操作是异步完成，由&nbsp;BlockManagerWorker&nbsp;来处理这一部分事情。 <span style="color:#df5320;"><span style="color:#008800;">6</span></span>）ConnectionManager&nbsp;&nbsp;&nbsp;&nbsp;负责与其它计算结点建立连接，并负责数据的发送和接收。 <span style="color:#df5320;"><span style="color:#008800;">7</span></span>）BlockManagerMaster&nbsp;&nbsp;&nbsp;注意该模块只运行在&nbsp;Driver&nbsp;Application&nbsp;所在的&nbsp;Executor，功能是负责记录下所有&nbsp;BlockIds&nbsp;存储在哪个&nbsp;SlaveWorker&nbsp;上，比如&nbsp;RDD&nbsp;Task&nbsp;运行在机器&nbsp;A，所需要的&nbsp;BlockId&nbsp;为&nbsp;<span style="color:#df5320;"><span style="color:#008800;">3</span></span>，但在机器&nbsp;A&nbsp;上没有&nbsp;BlockId&nbsp;为&nbsp;<span style="color:#df5320;"><span style="color:#008800;">3</span></span>&nbsp;的数值，这个时候&nbsp;Slave&nbsp;worker&nbsp;需要通过&nbsp;BlockManager&nbsp;向&nbsp;BlockManagerMaster&nbsp;询问数据存储的位置，然后再通过&nbsp;ConnectionManager&nbsp;去获取。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label10_1"></a></span></span></p> 
  <h3 id="h112" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.2 启动过程分析</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">上述的各个模块由 SparkEnv 来创建，创建过程在 SparkEnv.create 中完成，代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">val&nbsp;blockManagerMaster&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;BlockManagerMaster(registerOrLookup( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"BlockManagerMaster"</span></span>, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;BlockManagerMasterActor(isLocal,&nbsp;conf)),&nbsp;conf) val&nbsp;blockManager&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;BlockManager(executorId,&nbsp;actorSystem,&nbsp;blockManagerMaster,&nbsp;serializer,&nbsp;conf) val&nbsp;connectionManager&nbsp;=&nbsp;blockManager.connectionManager val&nbsp;broadcastManager&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;BroadcastManager(isDriver,&nbsp;conf) val&nbsp;cacheManager&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;CacheManager(blockManager) </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">下面这段代码容易让人疑惑，看起来像是在所有的 cluster node 上都创建了 BlockManagerMasterActor，其实不然，仔细看 registerOrLookup 函数的实现。如果当前节点是 driver 则创建这个 actor，否则建立到 driver 的连接。代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">registerOrLookup</span></span><span style="color:#df5320;">(name:&nbsp;String,&nbsp;newActor:&nbsp;=&gt;&nbsp;Actor)</span>:&nbsp;ActorRef&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(<span style="color:#7b9726;"><span style="color:#880000;">"Registering&nbsp;"</span></span>&nbsp;+&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;actorSystem.actorOf(Props(newActor),&nbsp;name&nbsp;=&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;driverHost:&nbsp;String&nbsp;=&nbsp;conf.get(<span style="color:#7b9726;"><span style="color:#880000;">"spark.driver.host"</span></span>,&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"localhost"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;driverPort:&nbsp;Int&nbsp;=&nbsp;conf.getInt(<span style="color:#7b9726;"><span style="color:#880000;">"spark.driver.port"</span></span>,&nbsp;<span style="color:#df5320;"><span style="color:#008800;">7077</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Utils.checkHost(driverHost,&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"Expected&nbsp;hostname"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;url&nbsp;=&nbsp;s<span style="color:#7b9726;"><span style="color:#880000;">"akka.tcp://spark@$driverHost:$driverPort/user/$name"</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;timeout&nbsp;=&nbsp;AkkaUtils.lookupTimeout(conf) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(s<span style="color:#7b9726;"><span style="color:#880000;">"Connecting&nbsp;to&nbsp;$name:&nbsp;$url"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Await.result(actorSystem.actorSelection(url).resolveOne(timeout),&nbsp;timeout) &nbsp;&nbsp;&nbsp;&nbsp;} } </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">初始化过程中一个主要的动作就是 BlockManager 需要向 BlockManagerMaster 发起注册。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label10_2"></a></span></span></p> 
  <h3 id="h113" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.3 通信层</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtjXRg.png"><br> BlockManager 包装了 BlockManagerMaster，发送信息包装成 BlockManagerInfo。Spark 在 Driver 和 Worker 端都创建各自的 BlockManager，并通过 BlockManagerMaster 进行通信，通过 BlockManager 对 Storage 模块进行操作。<br> BlockManager 对象在 SparkEnv.create 函数中进行创建，代码如下：</span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">registerOrLookupEndpoint</span></span><span style="color:#df5320;">( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;name:&nbsp;String,&nbsp;endpointCreator:&nbsp;=&gt;&nbsp;RpcEndpoint)</span>: RpcEndpointRef&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(isDriver)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(<span style="color:#7b9726;"><span style="color:#880000;">"Registering&nbsp;"</span></span>&nbsp;+&nbsp;name) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rpcEnv.setupEndpoint(name,&nbsp;endpointCreator) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RpcUtils.makeDriverRef(name,&nbsp;conf,&nbsp;rpcEnv) &nbsp;&nbsp;&nbsp;&nbsp;} } ...... val&nbsp;blockManagerMaster&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;BlockManagerMaster(registerOrLookupEndpoint( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockManagerMaster.DRIVER_ENDPOINT_NAME, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;BlockManagerMasterEndpoint(rpcEnv,&nbsp;isLocal,&nbsp;conf,&nbsp;listenerBus)), &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;conf,&nbsp;isDriver) <span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;NB:&nbsp;blockManager&nbsp;is&nbsp;not&nbsp;valid&nbsp;until&nbsp;initialize()&nbsp;is&nbsp;called&nbsp;later.</span></span> <span style="color:#888888;">val&nbsp;blockManager&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;BlockManager(executorId,&nbsp;rpcEnv,&nbsp;blockManagerMaster,</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;serializer,&nbsp;conf,&nbsp;mapOutputTracker,&nbsp;shuffleManager,&nbsp;blockTransferService,&nbsp;securityManager,numUsableCores)</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">并且在创建之前对当前节点是否是 Driver 进行了判断。如果是，则创建这个 Endpoint；否则，创建 Driver 的连接。</span></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在创建 BlockManager 之后，BlockManager 会调用 initialize 方法初始化自己。并且初始化的时候，会调用 BlockManagerMaster 向 Driver 注册自己，同时，在注册时也启动了Slave Endpoint。另外，向本地 shuffle 服务器注册 Executor 配置，如果存在的话。代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">initialize</span></span><span style="color:#df5320;">(appId:&nbsp;String)</span>:&nbsp;Unit&nbsp;</span>=&nbsp;{ ...... &nbsp;&nbsp;&nbsp;&nbsp;master.registerBlockManager(blockManagerId,&nbsp;maxMemory,&nbsp;slaveEndpoint) &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Register&nbsp;Executors'&nbsp;configuration&nbsp;with&nbsp;the&nbsp;local&nbsp;shuffle&nbsp;service,&nbsp;if&nbsp;one&nbsp;should&nbsp;exist.</span></span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(externalShuffleServiceEnabled&nbsp;&amp;&amp;&nbsp;!blockManagerId.isDriver)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;registerWithExternalShuffleServer()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">}</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">而 BlockManagerMaster 将注册请求包装成 RegisterBlockManager 注册到 Driver。Driver 的 BlockManagerMasterEndpoint 会调用 register 方法，通过对消息 BlockManagerInfo 检查，向 Driver 注册，代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">register</span></span><span style="color:#df5320;">(id:&nbsp;BlockManagerId,&nbsp;maxMemSize:&nbsp;Long,&nbsp;slaveEndpoint:&nbsp;RpcEndpointRef)</span>&nbsp;</span>{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;time&nbsp;=&nbsp;System.currentTimeMillis() &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(!blockManagerInfo.contains(id))&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerIdByExecutor.get(id.executorId)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Some</span></span><span style="color:#df5320;">(oldId)</span>&nbsp;</span>=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;A&nbsp;block&nbsp;manager&nbsp;of&nbsp;the&nbsp;same&nbsp;executor&nbsp;already&nbsp;exists,&nbsp;so&nbsp;remove&nbsp;it&nbsp;(assumed&nbsp;dead)</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logError(</span><span style="color:#7b9726;"><span style="color:#888888;">"Got&nbsp;two&nbsp;different&nbsp;block&nbsp;manager&nbsp;registrations&nbsp;on&nbsp;same&nbsp;executor&nbsp;-&nbsp;"</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;+&nbsp;s</span><span style="color:#7b9726;"><span style="color:#888888;">"&nbsp;will&nbsp;replace&nbsp;old&nbsp;one&nbsp;$oldId&nbsp;with&nbsp;new&nbsp;one&nbsp;$id"</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;removeExecutor(id.executorId)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;None&nbsp;=&gt;</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(</span><span style="color:#7b9726;"><span style="color:#888888;">"Registering&nbsp;block&nbsp;manager&nbsp;%s&nbsp;with&nbsp;%s&nbsp;RAM,&nbsp;%s"</span></span><span style="color:#888888;">.format(</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id.hostPort,&nbsp;Utils.bytesToString(maxMemSize),&nbsp;id))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManagerIdByExecutor(id.executorId)&nbsp;=&nbsp;</span><span style="color:inherit;"><span style="color:#888888;">id</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">blockManagerInfo</span></span><span style="color:#df5320;"><span style="color:#888888;">(id)</span></span>&nbsp;</span><span style="color:#888888;">=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;BlockManagerInfo(</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;id,&nbsp;System.currentTimeMillis(),&nbsp;maxMemSize,&nbsp;slaveEndpoint)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;listenerBus.post(SparkListenerBlockManagerAdded(time,&nbsp;id,&nbsp;maxMemSize))</span> <span style="color:#888888;">}</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">不难发现 BlockManagerInfo 对象被保存到 Map 映射中。在通信层中 BlockManagerMaster 控制着消息的流向，这里采用了模式匹配，所有的消息模式都在 BlockManagerMessage 中。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label10_3"></a></span></span></p> 
  <h3 id="h114" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.4 存储层</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtjoqI.png"><br> Spark Storage 的最小存储单位是 block，所有的操作都是以 block 为单位进行的。<br> 在 BlockManager 被创建的时候 MemoryStore 和 DiskStore 对象就被创建出来了。代码如下：</span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">val&nbsp;diskBlockManager&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;DiskBlockManager(<span style="color:#6666ea;"><span style="color:#0000ff;">this</span></span>,&nbsp;conf) <span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>[spark]&nbsp;val&nbsp;memoryStore&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;MemoryStore(<span style="color:#6666ea;"><span style="color:#0000ff;">this</span></span>,&nbsp;maxMemory) <span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>[spark]&nbsp;val&nbsp;diskStore&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;DiskStore(<span style="color:#6666ea;"><span style="color:#0000ff;">this</span></span>,&nbsp;diskBlockManager) </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.4.1 Disk Store</strong></span></span></strong></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">由于当前的 Spark 版本对 Disk Store 进行了更细粒度的分工，把对文件的操作提取出来放到了 DiskBlockManager 中，DiskStore 仅仅负责数据的存储和读取。<br> Disk Store 会配置多个文件目录，Spark 会在不同的文件目录下创建文件夹，其中文件夹的命名方式是：spark-UUID（随机UUID码）。Disk Store 在存储的时候创建文件夹。并且根据【高内聚，低耦合】原则，这种服务型的工具代码就放到了 Utils 中（调用路径：DiskStore.putBytes —&gt; DiskBlockManager.createLocalDirs —&gt; Utils.createDirectory），代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">createDirectory</span></span><span style="color:#df5320;">(root:&nbsp;String,&nbsp;namePrefix:&nbsp;String&nbsp;=&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"spark"</span></span>)</span>:&nbsp;File&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;attempts&nbsp;=&nbsp;<span style="color:#df5320;"><span style="color:#008800;">0</span></span> &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;maxAttempts&nbsp;=&nbsp;MAX_DIR_CREATION_ATTEMPTS &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;dir:&nbsp;File&nbsp;=&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">while</span></span>&nbsp;<span style="color:#df5320;">(dir&nbsp;==&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span>)</span>&nbsp;</span>{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;attempts&nbsp;+=&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(attempts&nbsp;&gt;&nbsp;maxAttempts)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">throw</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;IOException(<span style="color:#7b9726;"><span style="color:#880000;">"Failed&nbsp;to&nbsp;create&nbsp;a&nbsp;temp&nbsp;directory&nbsp;(under&nbsp;"</span></span>&nbsp;+&nbsp;root&nbsp;+&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">")&nbsp;after&nbsp;"</span></span>&nbsp;+ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;maxAttempts&nbsp;+&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"&nbsp;attempts!"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">try</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dir&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;File(root,&nbsp;namePrefix&nbsp;+&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"-"</span></span>&nbsp;+&nbsp;UUID.randomUUID.toString) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(dir.exists()&nbsp;||&nbsp;!dir.mkdirs())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;dir&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">catch</span></span>&nbsp;{&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;e:&nbsp;SecurityException&nbsp;=&gt;&nbsp;dir&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span>;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;dir.getCanonicalFile } </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在 DiskBlockManager 里，每个 block 都被存储为一个 file，通过计算 blockId 的 hash 值，将 block 映射到文件中。</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">getFile</span></span><span style="color:#df5320;">(filename:&nbsp;String)</span>:&nbsp;File&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Figure&nbsp;out&nbsp;which&nbsp;local&nbsp;directory&nbsp;it&nbsp;hashes&nbsp;to,&nbsp;and&nbsp;which&nbsp;subdirectory&nbsp;in&nbsp;that</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;hash&nbsp;=&nbsp;Utils.nonNegativeHash(filename)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;dirId&nbsp;=&nbsp;hash&nbsp;%&nbsp;localDirs.length</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;subDirId&nbsp;=&nbsp;(hash&nbsp;/&nbsp;localDirs.length)&nbsp;%&nbsp;subDirsPerLocalDir</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Create&nbsp;the&nbsp;subdirectory&nbsp;if&nbsp;it&nbsp;doesn't&nbsp;already&nbsp;exist</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;subDir&nbsp;=&nbsp;subDirs(dirId).</span><span style="color:#6666ea;"><span style="color:#888888;">synchronized</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;old&nbsp;=&nbsp;subDirs(dirId)(subDirId)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(old&nbsp;!=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">null</span></span><span style="color:#888888;">)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;old</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">else</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;newDir&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;File(localDirs(dirId),&nbsp;</span><span style="color:#7b9726;"><span style="color:#888888;">"%02x"</span></span><span style="color:#888888;">.format(subDirId))</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(!newDir.exists()&nbsp;&amp;&amp;&nbsp;!newDir.mkdir())&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">throw</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;IOException(s</span><span style="color:#7b9726;"><span style="color:#888888;">"Failed&nbsp;to&nbsp;create&nbsp;local&nbsp;dir&nbsp;in&nbsp;$newDir."</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;subDirs(dirId)(subDirId)&nbsp;=&nbsp;newDir</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;newDir</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;File(subDir,&nbsp;filename)</span> <span style="color:#888888;">}</span> <span style="color:inherit;"><span style="color:#888888;">def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">getFile</span></span><span style="color:#df5320;"><span style="color:#888888;">(blockId:&nbsp;BlockId)</span></span><span style="color:#888888;">:&nbsp;File&nbsp;</span></span><span style="color:#888888;">=&nbsp;getFile(blockId.name)</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">通过 hash 值的取模运算，求出 dirId 和 subDirId。然后，在从 subDirs 中找到 subDir，如果 subDir 不存在，则创建一个新 subDir。最后，以 subDir 为路径，blockId 的 name 属性为文件名，新建该文件。<br> 文件创建完之后，那么 Spark 就会在 DiskStore 中向文件写与之映射的 block，代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">override&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">putBytes</span></span><span style="color:#df5320;">(blockId:&nbsp;BlockId,&nbsp;_bytes:&nbsp;ByteBuffer,&nbsp;level:&nbsp;StorageLevel)</span>:&nbsp;PutResult&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bytes&nbsp;=&nbsp;_bytes.duplicate() &nbsp;&nbsp;&nbsp;&nbsp;logDebug(s<span style="color:#7b9726;"><span style="color:#880000;">"Attempting&nbsp;to&nbsp;put&nbsp;block&nbsp;$blockId"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;startTime&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;file&nbsp;=&nbsp;diskManager.getFile(blockId) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;channel&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;FileOutputStream(file).getChannel &nbsp;&nbsp;&nbsp;&nbsp;Utils.tryWithSafeFinally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">while</span></span>&nbsp;(bytes.remaining&nbsp;&gt;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">0</span></span>)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.write(bytes) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.close() &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;finishTime&nbsp;=&nbsp;System.<span style="color:inherit;">currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">logDebug</span></span><span style="color:#df5320;">(<span style="color:#7b9726;"><span style="color:#880000;">"Block&nbsp;%s&nbsp;stored&nbsp;as&nbsp;%s&nbsp;file&nbsp;on&nbsp;disk&nbsp;in&nbsp;%d&nbsp;ms"</span></span>.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;file.getName,&nbsp;Utils.bytesToString(bytes.limit)</span>,&nbsp;finishTime&nbsp;-&nbsp;startTime)) &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">PutResult</span></span><span style="color:#df5320;">(bytes.limit()</span>,&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Right</span></span><span style="color:#df5320;">(bytes.duplicate()</span>)) } </span></code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">读取过程就简单了，DiskStore 根据 blockId 读取与之映射的 file 内容，当然，这中间需要从 DiskBlockManager 中得到文件信息。代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">getBytes</span></span><span style="color:#df5320;">(file:&nbsp;File,&nbsp;offset:&nbsp;Long,&nbsp;length:&nbsp;Long)</span>:&nbsp;Option[ByteBuffer]&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;channel&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;RandomAccessFile(file,&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"r"</span></span>).getChannel &nbsp;&nbsp;&nbsp;&nbsp;Utils.tryWithSafeFinally&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;For&nbsp;small&nbsp;files,&nbsp;directly&nbsp;read&nbsp;rather&nbsp;than&nbsp;memory&nbsp;map</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(length&nbsp;&lt;&nbsp;minMemoryMapBytes)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;buf&nbsp;=&nbsp;ByteBuffer.allocate(length.toInt)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.position(offset)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">while</span></span><span style="color:#888888;">&nbsp;(buf.remaining()&nbsp;!=&nbsp;</span><span style="color:#df5320;"><span style="color:#888888;">0</span></span><span style="color:#888888;">)&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(channel.read(buf)&nbsp;==&nbsp;-</span><span style="color:#df5320;"><span style="color:#888888;">1</span></span><span style="color:#888888;">)&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">throw</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;IOException(</span><span style="color:#7b9726;"><span style="color:#888888;">"Reached&nbsp;EOF&nbsp;before&nbsp;filling&nbsp;buffer\n"</span></span><span style="color:#888888;">&nbsp;+</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;s</span><span style="color:#7b9726;"><span style="color:#888888;">"offset=$offset\nfile=${file.getAbsolutePath}\nbuf.remaining=${buf.remaining}"</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;buf.flip()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(buf)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">else</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(channel.map(MapMode.READ_ONLY,&nbsp;offset,&nbsp;length))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;channel.close()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">}</span> <span style="color:inherit;"><span style="color:#888888;">override&nbsp;def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">getBytes</span></span><span style="color:#df5320;"><span style="color:#888888;">(blockId:&nbsp;BlockId)</span></span><span style="color:#888888;">:&nbsp;Option[ByteBuffer]&nbsp;</span></span><span style="color:#888888;">=&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;file&nbsp;=&nbsp;diskManager.getFile(blockId.name)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;getBytes(file,&nbsp;</span><span style="color:#df5320;"><span style="color:#888888;">0</span></span><span style="color:#888888;">,&nbsp;file.length)</span> <span style="color:#888888;">}</span> </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.4.2 Memory Store</strong></span></span></strong></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">相对 Disk Store，Memory Store 就显得容易很多。Memory Store 用一个 LinkedHashMap 来管理，其中 Key 是 blockId，Value 是 MemoryEntry 样例类，MemoryEntry 存储着数据信息。代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;class&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">MemoryEntry</span></span><span style="color:#df5320;">(value:&nbsp;Any,&nbsp;size:&nbsp;Long,&nbsp;deserialized:&nbsp;Boolean)</span> <span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>&nbsp;val&nbsp;entries&nbsp;</span>=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;LinkedHashMap[BlockId,&nbsp;MemoryEntry](<span style="color:#df5320;"><span style="color:#008800;">32</span></span>,&nbsp;<span style="color:#df5320;"><span style="color:#008800;">0.75f</span></span>,&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">true</span></span>) </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在 MemoryStore 中存储 block 的前提是当前内存有足够的空间存放。通过对 tryToPut 函数的调用对内存空间进行判断。代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">putBytes</span></span><span style="color:#df5320;">(blockId:&nbsp;BlockId,&nbsp;size:&nbsp;Long,&nbsp;_bytes:&nbsp;()</span>&nbsp;</span>=&gt;&nbsp;ByteBuffer):&nbsp;PutResult&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Work&nbsp;on&nbsp;a&nbsp;duplicate&nbsp;-&nbsp;since&nbsp;the&nbsp;original&nbsp;input&nbsp;might&nbsp;be&nbsp;used&nbsp;elsewhere.</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;lazy&nbsp;val&nbsp;bytes&nbsp;=&nbsp;_bytes().duplicate().rewind().asInstanceOf[ByteBuffer]</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putAttempt&nbsp;=&nbsp;tryToPut(blockId,&nbsp;()&nbsp;=&gt;&nbsp;bytes,&nbsp;size,&nbsp;deserialized&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">false</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;data&nbsp;=</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(putAttempt.success)&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">assert</span></span><span style="color:#888888;">(bytes.limit&nbsp;==&nbsp;size)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right(bytes.duplicate())</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">else</span></span><span style="color:#888888;">&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">null</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;PutResult(size,&nbsp;data,&nbsp;putAttempt.droppedBlocks)</span> <span style="color:#888888;">}</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在 tryToPut 函数中，通过调用 enoughFreeSpace 函数判断内存空间。如果内存空间足够，那么就把 block 放到 LinkedHashMap 中；如果内存不足，那么就告诉 BlockManager 内存不足，如果允许 Disk Store，那么就把该 block 放到 disk 上。代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">tryToPut</span></span><span style="color:#df5320;">(blockId:&nbsp;BlockId,&nbsp;value:&nbsp;()</span>&nbsp;</span>=&gt;&nbsp;Any,&nbsp;size:&nbsp;Long,&nbsp;deserialized:&nbsp;Boolean):&nbsp;ResultWithDroppedBlocks&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;putSuccess&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">false</span></span> &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;droppedBlocks&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;accountingLock.<span style="color:#6666ea;"><span style="color:#0000ff;">synchronized</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;freeSpaceResult&nbsp;=&nbsp;ensureFreeSpace(blockId,&nbsp;size) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;enoughFreeSpace&nbsp;=&nbsp;freeSpaceResult.success &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;droppedBlocks&nbsp;++=&nbsp;freeSpaceResult.<span style="color:inherit;">droppedBlocks &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">if</span></span>&nbsp;<span style="color:#df5320;">(enoughFreeSpace)</span>&nbsp;</span>{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;entry&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;MemoryEntry(value(),&nbsp;size,&nbsp;deserialized) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.<span style="color:#6666ea;"><span style="color:#0000ff;">synchronized</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.put(blockId,&nbsp;entry) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;currentMemory&nbsp;+=&nbsp;size &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;valuesOrBytes&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(deserialized)&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"values"</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"bytes"</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(<span style="color:#7b9726;"><span style="color:#880000;">"Block&nbsp;%s&nbsp;stored&nbsp;as&nbsp;%s&nbsp;in&nbsp;memory&nbsp;(estimated&nbsp;size&nbsp;%s,&nbsp;free&nbsp;%s)"</span></span>.format( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId,&nbsp;valuesOrBytes,&nbsp;Utils.bytesToString(size),&nbsp;Utils.bytesToString(freeMemory))) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putSuccess&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">true</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;lazy&nbsp;val&nbsp;data&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(deserialized)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Left(value().asInstanceOf[Array[Any]]) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Right(value().asInstanceOf[ByteBuffer].duplicate()) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;droppedBlockStatus&nbsp;=&nbsp;blockManager.dropFromMemory(blockId,&nbsp;()&nbsp;=&gt;&nbsp;data) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;droppedBlockStatus.foreach&nbsp;{&nbsp;status&nbsp;=&gt;&nbsp;droppedBlocks&nbsp;+=&nbsp;((blockId,&nbsp;status))&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;releasePendingUnrollMemoryForThisTask() &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;ResultWithDroppedBlocks(putSuccess,&nbsp;droppedBlocks) } </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Memory Store 读取 block 也很简单，只需要从 LinkedHashMap 中取出 blockId 的 Value 即可。代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">override&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">getValues</span></span><span style="color:#df5320;">(blockId:&nbsp;BlockId)</span>:&nbsp;Option[Iterator[Any]]&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;entry&nbsp;=&nbsp;entries.<span style="color:#6666ea;"><span style="color:#0000ff;">synchronized</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;entries.get(blockId) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(entry&nbsp;==&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span>)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;None &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(entry.deserialized)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(entry.value.asInstanceOf[Array[Any]].iterator) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;buffer&nbsp;=&nbsp;entry.value.asInstanceOf[ByteBuffer].duplicate()&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Doesn't&nbsp;actually&nbsp;copy&nbsp;data</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Some(blockManager.dataDeserialize(blockId,&nbsp;buffer))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">}</span> </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label10_4"></a></span></span></p> 
  <h3 id="h115" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.5 数据写入过程分析</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/ENp9cF.png"><br> 数据写入的简要流程：</span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#df5320;"><span style="color:#008800;">1</span></span>）RDD.iterator&nbsp;是与&nbsp;storage&nbsp;子系统交互的入口。 <span style="color:#df5320;"><span style="color:#008800;">2</span></span>）CacheManager.getOrCompute&nbsp;调用&nbsp;BlockManager&nbsp;的&nbsp;put&nbsp;接口来写入数据。 <span style="color:#df5320;"><span style="color:#008800;">3</span></span>）数据优先写入到&nbsp;MemoryStore&nbsp;即内存，如果&nbsp;MemoryStore&nbsp;中的数据已满则将最近使用次数不频繁的数据写入到磁盘。 <span style="color:#df5320;"><span style="color:#008800;">4</span></span>）通知&nbsp;BlockManagerMaster&nbsp;有新的数据写入，在&nbsp;BlockManagerMaster&nbsp;中保存元数据。 <span style="color:#df5320;"><span style="color:#008800;">5</span></span>）将写入的数据与其它&nbsp;slave&nbsp;worker&nbsp;进行同步，一般来说在本机写入的数据，都会另先一台机器来进行数据的备份，即&nbsp;replicanumber=<span style="color:#df5320;"><span style="color:#008800;">1</span></span>。 其实，我们在&nbsp;put&nbsp;和&nbsp;get&nbsp;block&nbsp;的时候并没有那么复杂，前面的细节&nbsp;BlockManager&nbsp;都包装好了，我们只需要调用&nbsp;BlockManager&nbsp;中的&nbsp;put&nbsp;和&nbsp;get&nbsp;函数即可。 </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">代码如下：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">putBytes</span></span><span style="color:#df5320;">( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId:&nbsp;BlockId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes:&nbsp;ByteBuffer, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level:&nbsp;StorageLevel, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tellMaster:&nbsp;Boolean&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">true</span></span>, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel:&nbsp;Option[StorageLevel]&nbsp;=&nbsp;None)</span>:&nbsp;Seq[<span style="color:#df5320;">(BlockId,&nbsp;BlockStatus)</span>]&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(bytes&nbsp;!=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span>,&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"Bytes&nbsp;is&nbsp;null"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;doPut(blockId,&nbsp;ByteBufferValues(bytes),&nbsp;level,&nbsp;tellMaster,&nbsp;effectiveStorageLevel) &nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">private</span></span>&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">doPut</span></span><span style="color:#df5320;">( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId:&nbsp;BlockId, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data:&nbsp;BlockValues, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;level:&nbsp;StorageLevel, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tellMaster:&nbsp;Boolean&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">true</span></span>, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel:&nbsp;Option[StorageLevel]&nbsp;=&nbsp;None)</span> :&nbsp;Seq[<span style="color:#df5320;">(BlockId,&nbsp;BlockStatus)</span>]&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(blockId&nbsp;!=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span>,&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"BlockId&nbsp;is&nbsp;null"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(level&nbsp;!=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span>&nbsp;&amp;&amp;&nbsp;level.isValid,&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"StorageLevel&nbsp;is&nbsp;null&nbsp;or&nbsp;invalid"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;effectiveStorageLevel.foreach&nbsp;{&nbsp;level&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;require(level&nbsp;!=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span>&nbsp;&amp;&amp;&nbsp;level.isValid,&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"Effective&nbsp;StorageLevel&nbsp;is&nbsp;null&nbsp;or&nbsp;invalid"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;updatedBlocks&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putBlockInfo&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;tinfo&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;BlockInfo(level,&nbsp;tellMaster) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;oldBlockOpt&nbsp;=&nbsp;blockInfo.putIfAbsent(blockId,&nbsp;tinfo) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(oldBlockOpt.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(oldBlockOpt.get.waitForReady())&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logWarning(s<span style="color:#7b9726;"><span style="color:#880000;">"Block&nbsp;$blockId&nbsp;already&nbsp;exists&nbsp;on&nbsp;this&nbsp;machine;&nbsp;not&nbsp;re-adding&nbsp;it"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">return</span></span>&nbsp;updatedBlocks &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;oldBlockOpt.get &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;tinfo &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} } &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;startTimeMs&nbsp;=&nbsp;System.currentTimeMillis &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;valuesAfterPut:&nbsp;Iterator[Any]&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;bytesAfterPut:&nbsp;ByteBuffer&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;size&nbsp;=&nbsp;<span style="color:#df5320;"><span style="color:#008800;">0L</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putLevel&nbsp;=&nbsp;effectiveStorageLevel.getOrElse(level) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;replicationFuture&nbsp;=&nbsp;data&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;b:&nbsp;ByteBufferValues&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;putLevel.replication&nbsp;&gt;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Duplicate&nbsp;doesn't&nbsp;copy&nbsp;the&nbsp;bytes,&nbsp;but&nbsp;just&nbsp;creates&nbsp;a&nbsp;wrapper</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bufferView&nbsp;=&nbsp;b.buffer.duplicate()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Future&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replicate(blockId,&nbsp;bufferView,&nbsp;putLevel)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}(futureExecutionContext)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;_&nbsp;=&gt;&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">null</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.</span><span style="color:#6666ea;"><span style="color:#888888;">synchronized</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logTrace(</span><span style="color:#7b9726;"><span style="color:#888888;">"Put&nbsp;for&nbsp;block&nbsp;%s&nbsp;took&nbsp;%s&nbsp;to&nbsp;get&nbsp;into&nbsp;synchronized&nbsp;block"</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs)))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;marked&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">false</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">try</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;(returnValues,&nbsp;blockStore:&nbsp;BlockStore)&nbsp;=&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(putLevel.useMemory)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(</span><span style="color:#6666ea;"><span style="color:#888888;">true</span></span><span style="color:#888888;">,&nbsp;memoryStore)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">else</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(putLevel.useOffHeap)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(</span><span style="color:#6666ea;"><span style="color:#888888;">false</span></span><span style="color:#888888;">,&nbsp;externalBlockStore)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">else</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(putLevel.useDisk)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;</span><span style="color:#df5320;"><span style="color:#888888;">1</span></span><span style="color:#888888;">,&nbsp;diskStore)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">else</span></span><span style="color:#888888;">&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">assert</span></span><span style="color:#888888;">(putLevel&nbsp;==&nbsp;StorageLevel.NONE)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">throw</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;BlockException(</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockId,&nbsp;s</span><span style="color:#7b9726;"><span style="color:#888888;">"Attempted&nbsp;to&nbsp;put&nbsp;block&nbsp;$blockId&nbsp;without&nbsp;specifying&nbsp;storage&nbsp;level!"</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;result&nbsp;=&nbsp;data&nbsp;match&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#888888;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">IteratorValues</span></span><span style="color:#df5320;"><span style="color:#888888;">(iterator)</span></span>&nbsp;</span><span style="color:#888888;">=&gt;</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putIterator(blockId,&nbsp;iterator,&nbsp;putLevel,&nbsp;returnValues)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#888888;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">ArrayValues</span></span><span style="color:#df5320;"><span style="color:#888888;">(array)</span></span>&nbsp;</span><span style="color:#888888;">=&gt;</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putArray(blockId,&nbsp;array,&nbsp;putLevel,&nbsp;returnValues)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#888888;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">ByteBufferValues</span></span><span style="color:#df5320;"><span style="color:#888888;">(bytes)</span></span>&nbsp;</span><span style="color:#888888;">=&gt;</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytes.rewind()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockStore.putBytes(blockId,&nbsp;bytes,&nbsp;putLevel)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;size&nbsp;=&nbsp;result.size</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result.data&nbsp;match&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#888888;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">Left</span></span>&nbsp;<span style="color:#df5320;"><span style="color:#888888;">(newIterator)</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;putLevel.useMemory&nbsp;</span></span><span style="color:#888888;">=&gt;&nbsp;valuesAfterPut&nbsp;=&nbsp;</span><span style="color:inherit;"><span style="color:#888888;">newIterator</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">Right</span></span>&nbsp;<span style="color:#df5320;"><span style="color:#888888;">(newBytes)</span></span>&nbsp;</span><span style="color:#888888;">=&gt;&nbsp;bytesAfterPut&nbsp;=&nbsp;newBytes</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;_&nbsp;=&gt;</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(putLevel.useMemory)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;result.droppedBlocks.foreach&nbsp;{&nbsp;updatedBlocks&nbsp;+=&nbsp;_&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;putBlockStatus&nbsp;=&nbsp;getCurrentBlockStatus(blockId,&nbsp;putBlockInfo)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(putBlockStatus.storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;marked&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">true</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.markReady(size)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(tellMaster)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;reportBlockStatus(blockId,&nbsp;putBlockInfo,&nbsp;putBlockStatus)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updatedBlocks&nbsp;+=&nbsp;((blockId,&nbsp;putBlockStatus))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">finally</span></span><span style="color:#888888;">&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(!marked)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockInfo.remove(blockId)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;putBlockInfo.markFailure()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logWarning(s</span><span style="color:#7b9726;"><span style="color:#888888;">"Putting&nbsp;block&nbsp;$blockId&nbsp;failed"</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(</span><span style="color:#7b9726;"><span style="color:#888888;">"Put&nbsp;block&nbsp;%s&nbsp;locally&nbsp;took&nbsp;%s"</span></span><span style="color:#888888;">.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs)))</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;</span><span style="color:#df5320;"><span style="color:#888888;">1</span></span><span style="color:#888888;">)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;data&nbsp;match&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#888888;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">ByteBufferValues</span></span><span style="color:#df5320;"><span style="color:#888888;">(bytes)</span></span>&nbsp;</span><span style="color:#888888;">=&gt;</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(replicationFuture&nbsp;!=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">null</span></span><span style="color:#888888;">)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Await.ready(replicationFuture,&nbsp;Duration.Inf)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;_&nbsp;=&gt;</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;remoteStartTime&nbsp;=&nbsp;System.</span><span style="color:inherit;"><span style="color:#888888;">currentTimeMillis</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">if</span></span>&nbsp;<span style="color:#df5320;"><span style="color:#888888;">(bytesAfterPut&nbsp;==&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">null</span></span><span style="color:#888888;">)</span></span>&nbsp;</span><span style="color:#888888;">{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(valuesAfterPut&nbsp;==&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">null</span></span><span style="color:#888888;">)&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">throw</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;SparkException(</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#7b9726;"><span style="color:#888888;">"Underlying&nbsp;put&nbsp;returned&nbsp;neither&nbsp;an&nbsp;Iterator&nbsp;nor&nbsp;bytes!&nbsp;This&nbsp;shouldn't&nbsp;happen."</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;bytesAfterPut&nbsp;=&nbsp;dataSerialize(blockId,&nbsp;valuesAfterPut)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;replicate(blockId,&nbsp;bytesAfterPut,&nbsp;putLevel)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(</span><span style="color:#7b9726;"><span style="color:#888888;">"Put&nbsp;block&nbsp;%s&nbsp;remotely&nbsp;took&nbsp;%s"</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(remoteStartTime)))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockManager.dispose(bytesAfterPut)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(putLevel.replication&nbsp;&gt;&nbsp;</span><span style="color:#df5320;"><span style="color:#888888;">1</span></span><span style="color:#888888;">)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(</span><span style="color:#7b9726;"><span style="color:#888888;">"Putting&nbsp;block&nbsp;%s&nbsp;with&nbsp;replication&nbsp;took&nbsp;%s"</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs)))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">else</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(</span><span style="color:#7b9726;"><span style="color:#888888;">"Putting&nbsp;block&nbsp;%s&nbsp;without&nbsp;replication&nbsp;took&nbsp;%s"</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.format(blockId,&nbsp;Utils.getUsedTimeMs(startTimeMs)))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;updatedBlocks</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;}</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">对于 doPut 函数，主要做了以下几个操作：<br>   1）创建 BlockInfo 对象存储 block 信息。<br>   2）将 BlockInfo 加锁，然后根据 Storage Level 判断存储到 Memory 还是 Disk。同时，对于已经准备好读的 BlockInfo 要进行解锁。<br>   3）根据 block 的副本数量决定是否向远程发送副本。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.5.1 序列化与否</strong></span></span></strong></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">写入的具体内容可以是序列化之后的 bytes 也可以是没有序列化的 value. 此处有一个对 scala 的语法中 Either, Left, Right 关键字的理解。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label10_5"></a></span></span></p> 
  <h3 id="h116" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.6 数据读取过程分析</strong></span></span></strong></span></span></h3> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">get</span></span><span style="color:#df5320;">(blockId:&nbsp;BlockId)</span>:&nbsp;Option[Iterator[Any]]&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;local&nbsp;=&nbsp;getLocal(blockId) &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(local.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(<span style="color:#7b9726;"><span style="color:#880000;">"Found&nbsp;block&nbsp;%s&nbsp;locally"</span></span>.format(blockId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">return</span></span>&nbsp;local &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;remote&nbsp;=&nbsp;getRemote(blockId) &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(remote.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(<span style="color:#7b9726;"><span style="color:#880000;">"Found&nbsp;block&nbsp;%s&nbsp;remotely"</span></span>.format(blockId)) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">return</span></span>&nbsp;remote &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;None } </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.6.1 本地读取</strong></span></span></strong></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">首先在查询本机的 MemoryStore 和 DiskStore 中是否有所需要的 block 数据存在，如果没有则发起远程数据获取。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.6.2 远程读取</strong></span></span></strong></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">远程获取调用路径， getRemote --&gt; doGetRemote, 在 doGetRemote 中最主要的就是调用 BlockManagerWorker.syncGetBlock 来从远程获得数据。</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">syncGetBlock</span></span><span style="color:#df5320;">(msg:&nbsp;GetBlock,&nbsp;toConnManagerId:&nbsp;ConnectionManagerId)</span>:&nbsp;ByteBuffer&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockManager&nbsp;=&nbsp;blockManagerWorker.blockManager &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;connectionManager&nbsp;=&nbsp;blockManager.connectionManager &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockMessage&nbsp;=&nbsp;BlockMessage.fromGetBlock(msg) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;blockMessageArray&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;BlockMessageArray(blockMessage) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;responseMessage&nbsp;=&nbsp;connectionManager.sendMessageReliablySync( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;toConnManagerId,&nbsp;blockMessageArray.toBufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;responseMessage&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Some</span></span><span style="color:#df5320;">(message)</span>&nbsp;</span>=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;bufferMessage&nbsp;=&nbsp;message.asInstanceOf[BufferMessage] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(<span style="color:#7b9726;"><span style="color:#880000;">"Response&nbsp;message&nbsp;received&nbsp;"</span></span>&nbsp;+&nbsp;bufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;BlockMessageArray.fromBufferMessage(bufferMessage).foreach(blockMessage&nbsp;=&gt;&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(<span style="color:#7b9726;"><span style="color:#880000;">"Found&nbsp;"</span></span>&nbsp;+&nbsp;blockMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">return</span></span>&nbsp;blockMessage.getData &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;None&nbsp;=&gt;&nbsp;logDebug(<span style="color:#7b9726;"><span style="color:#880000;">"No&nbsp;response&nbsp;message&nbsp;received"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">null</span></span> } </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">上述这段代码中最有意思的莫过于 sendMessageReliablySync，远程数据读取毫无疑问是一个异步 i/o 操作，这里的代码怎么写起来就像是在进行同步的操作一样呢。也就是说如何知道对方发送回来响应的呢？<br> 别急，继续去看看 sendMessageReliablySync 的定义：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">sendMessageReliably</span></span><span style="color:#df5320;">(connectionManagerId:&nbsp;ConnectionManagerId,&nbsp;message:&nbsp;Message)</span> &nbsp;&nbsp;:&nbsp;Future[Option[Message]]&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;promise&nbsp;=&nbsp;Promise[Option[Message]] &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;status&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;MessageStatus( &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message,&nbsp;connectionManagerId,&nbsp;s&nbsp;=&gt;&nbsp;promise.success(s.ackMessage)) &nbsp;&nbsp;&nbsp;&nbsp;messageStatuses.<span style="color:#6666ea;"><span style="color:#0000ff;">synchronized</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses&nbsp;+=&nbsp;((message.id,&nbsp;status)) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;sendMessage(connectionManagerId,&nbsp;message) &nbsp;&nbsp;&nbsp;&nbsp;promise.future } </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">要是我说秘密在这里，你肯定会说我在扯淡，但确实在此处。注意到关键字 Promise 和 Future 没？<br> 如果这个 future 执行完毕，返回 s.ackMessage。我们再看看这个 ackMessage 是在什么地方被写入的呢。看一看 ConnectionManager.handleMessage 中的代码片段：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;bufferMessage:&nbsp;BufferMessage&nbsp;=&gt; { &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(authEnabled)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;res&nbsp;=&nbsp;handleAuthentication(connection,&nbsp;bufferMessage) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(res&nbsp;==&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">true</span></span>)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;message&nbsp;was&nbsp;security&nbsp;negotiation&nbsp;so&nbsp;skip&nbsp;the&nbsp;rest</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logDebug(</span><span style="color:#7b9726;"><span style="color:#888888;">"After&nbsp;handleAuth&nbsp;result&nbsp;was&nbsp;true,&nbsp;returning"</span></span><span style="color:#888888;">)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">return</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(bufferMessage.hasAckId)&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sentMessageStatus&nbsp;=&nbsp;messageStatuses.&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">synchronized</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses.get(bufferMessage.ackId)&nbsp;match&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#888888;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">Some</span></span><span style="color:#df5320;"><span style="color:#888888;">(status)</span></span>&nbsp;</span><span style="color:#888888;">=&gt;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;messageStatuses&nbsp;-=&nbsp;bufferMessage.ackId</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;status</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;None&nbsp;=&gt;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">throw</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;Exception(</span><span style="color:#7b9726;"><span style="color:#888888;">"Could&nbsp;not&nbsp;find&nbsp;reference&nbsp;for&nbsp;received&nbsp;ack&nbsp;message&nbsp;"</span></span><span style="color:#888888;">&nbsp;+</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;message.id)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">null</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">synchronized</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.ackMessage&nbsp;=&nbsp;Some(message)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.attempted&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">true</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStatus.acked&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">true</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;sentMessageStaus.markDone()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">}</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><code>注意</code>：此处的所调用的 sentMessageStatus.markDone 就会调用在 sendMessageReliablySync 中定义的 promise.Success，不妨看看 MessageStatus 的定义。</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">class</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">MessageStatus</span></span>( <span style="color:#407ee7;"><span style="color:#880000;">val</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">message</span></span>:&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Message</span></span>, <span style="color:#407ee7;"><span style="color:#880000;">val</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">connectionManagerId</span></span>:&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">ConnectionManagerId</span></span>, <span style="color:#407ee7;"><span style="color:#880000;">completionHandler</span></span>:&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">MessageStatus</span></span>&nbsp;</span>=&gt;&nbsp;Unit)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;ackMessage:&nbsp;Option[Message]&nbsp;=&nbsp;None &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;attempted&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">false</span></span> &nbsp;&nbsp;&nbsp;&nbsp;var&nbsp;acked&nbsp;=&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">false</span></span> &nbsp;&nbsp;&nbsp;&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">markDone</span></span><span style="color:#df5320;">()</span>&nbsp;</span>{&nbsp;completionHandler(<span style="color:#6666ea;"><span style="color:#0000ff;">this</span></span>)&nbsp;} } </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label10_6"></a></span></span></p> 
  <h3 id="h117partitionblock" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.7 Partition 如何转化为 Block</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在 storage 模块里面所有的操作都是和 block 相关的，但是在 RDD 里面所有的运算都是基于 partition 的，那么 partition 是如何与 block 对应上的呢？<br> RDD 计算的核心函数是 iterator() 函数：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">final</span></span>&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">iterator</span></span><span style="color:#df5320;">(split:&nbsp;Partition,&nbsp;context:&nbsp;TaskContext)</span>:&nbsp;Iterator[T]&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparkEnv.get.cacheManager.getOrCompute(<span style="color:#6666ea;"><span style="color:#0000ff;">this</span></span>,&nbsp;split,&nbsp;context,&nbsp;storageLevel) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;} } </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute() 函数计算 RDD，在这个函数中 partition 和 block 发生了关系：<br> 首先根据 RDD id 和 partition index 构造出 block id (rdd_xx_xx)，接着从 BlockManager 中取出相应的 block。<br>   如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。<br>   如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的 block，并将其存储到 BlockManager 中。<br> 需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">def&nbsp;getOrCompute[T](rdd:RDD[T],split:Partition,context:TaskContext,storageLevel:StorageLevel):Iterator[T]= { &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;key&nbsp;=&nbsp;<span style="color:#7b9726;"><span style="color:#880000;">"rdd_%d_%d"</span></span>.format(rdd.id,&nbsp;split.index) &nbsp;&nbsp;&nbsp;&nbsp;logDebug(<span style="color:#7b9726;"><span style="color:#880000;">"Looking&nbsp;for&nbsp;partition&nbsp;"</span></span>&nbsp;+&nbsp;key) &nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Some</span></span><span style="color:#df5320;">(values)</span>&nbsp;</span>=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Partition&nbsp;is&nbsp;already&nbsp;materialized,&nbsp;so&nbsp;just&nbsp;return&nbsp;its&nbsp;values</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">return</span></span><span style="color:#888888;">&nbsp;values.asInstanceOf[Iterator[T]]</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;None&nbsp;=&gt;</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Mark&nbsp;the&nbsp;split&nbsp;as&nbsp;loading&nbsp;(unless&nbsp;someone&nbsp;else&nbsp;marks&nbsp;it&nbsp;first)</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">synchronized</span></span><span style="color:#888888;">&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(loading.contains(key))&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(</span><span style="color:#7b9726;"><span style="color:#888888;">"Another&nbsp;thread&nbsp;is&nbsp;loading&nbsp;%s,&nbsp;waiting&nbsp;for&nbsp;it&nbsp;to&nbsp;finish..."</span></span><span style="color:#888888;">.format(key))</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">while</span></span><span style="color:#888888;">&nbsp;(loading.contains(key))&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">try</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.wait()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">catch</span></span><span style="color:#888888;">&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;_:</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Throwable&nbsp;=&gt;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(</span><span style="color:#7b9726;"><span style="color:#888888;">"Finished&nbsp;waiting&nbsp;for&nbsp;%s"</span></span><span style="color:#888888;">.format(key))</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;See&nbsp;whether&nbsp;someone&nbsp;else&nbsp;has&nbsp;successfully&nbsp;loaded&nbsp;it.&nbsp;The&nbsp;main&nbsp;way&nbsp;this&nbsp;would&nbsp;fail</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;is&nbsp;for&nbsp;the&nbsp;RDD-level&nbsp;cache&nbsp;eviction&nbsp;policy&nbsp;if&nbsp;someone&nbsp;else&nbsp;has&nbsp;loaded&nbsp;the&nbsp;same&nbsp;RDD</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;partition&nbsp;but&nbsp;we&nbsp;didn't&nbsp;want&nbsp;to&nbsp;make&nbsp;space&nbsp;for&nbsp;it.&nbsp;However,&nbsp;that&nbsp;case&nbsp;is&nbsp;unlikely</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;because&nbsp;it's&nbsp;unlikely&nbsp;that&nbsp;two&nbsp;threads&nbsp;would&nbsp;work&nbsp;on&nbsp;the&nbsp;same&nbsp;RDD&nbsp;partition.&nbsp;One</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;downside&nbsp;of&nbsp;the&nbsp;current&nbsp;code&nbsp;is&nbsp;that&nbsp;threads&nbsp;wait&nbsp;serially&nbsp;if&nbsp;this&nbsp;does&nbsp;happen.</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#888888;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">Some</span></span><span style="color:#df5320;"><span style="color:#888888;">(values)</span></span>&nbsp;</span><span style="color:#888888;">=&gt;</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">return</span></span><span style="color:#888888;">&nbsp;values.asInstanceOf[Iterator[T]]</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;None&nbsp;=&gt;</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(</span><span style="color:#7b9726;"><span style="color:#888888;">"Whoever&nbsp;was&nbsp;loading&nbsp;%s&nbsp;failed;&nbsp;we'll&nbsp;try&nbsp;it&nbsp;ourselves"</span></span><span style="color:#888888;">.format(key))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.add(key)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">else</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.add(key)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">try</span></span><span style="color:#888888;">&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;If&nbsp;we&nbsp;got&nbsp;here,&nbsp;we&nbsp;have&nbsp;to&nbsp;load&nbsp;the&nbsp;split</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(</span><span style="color:#7b9726;"><span style="color:#888888;">"Partition&nbsp;%s&nbsp;not&nbsp;found,&nbsp;computing&nbsp;it"</span></span><span style="color:#888888;">.format(key))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;computedValues&nbsp;=&nbsp;rdd.computeOrReadCheckpoint(split,&nbsp;context)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Persist&nbsp;the&nbsp;result,&nbsp;so&nbsp;long&nbsp;as&nbsp;the&nbsp;task&nbsp;is&nbsp;not&nbsp;running&nbsp;locally</span></span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(context.runningLocally)&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">return</span></span><span style="color:#888888;">&nbsp;computedValues</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;elements&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;ArrayBuffer[Any]</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;elements++&nbsp;=&nbsp;computedValues</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;blockManager.put(key,&nbsp;elements,&nbsp;storageLevel,&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">true</span></span><span style="color:#888888;">)</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">return</span></span><span style="color:#888888;">&nbsp;elements.iterator.asInstanceOf[Iterator[T]]</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">finally</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">synchronized</span></span><span style="color:#888888;">&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.remove(key)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.notifyAll()</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">}</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">这样 RDD 的 transformation、action 就和 block 数据建立了联系，虽然抽象上我们的操作是在 partition 层面上进行的，但是 partitio n最终还是被映射成为 block，因此实际上我们的所有操作都是对 block 的处理和存取。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label10_7"></a></span></span></p> 
  <h3 id="h118partitionblock" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>11.8 partition 和 block 的对应关系</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在 RDD 中，核心的函数是 iterator：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">final</span></span>&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">iterator</span></span><span style="color:#df5320;">(split:&nbsp;Partition,&nbsp;context:&nbsp;TaskContext)</span>:&nbsp;Iterator[T]&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(storageLevel&nbsp;!=&nbsp;StorageLevel.NONE)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SparkEnv.get.cacheManager.getOrCompute(<span style="color:#6666ea;"><span style="color:#0000ff;">this</span></span>,&nbsp;split,&nbsp;context,&nbsp;storageLevel) &nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">else</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;computeOrReadCheckpoint(split,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;} } </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">如果当前 RDD 的 storage level 不是 NONE 的话，表示该 RDD 在 BlockManager 中有存储，那么调用 CacheManager 中的 getOrCompute 函数计算 RDD，在这个函数中 partition 和 block 就对应起来了：<br>   getOrCompute 函数会先构造 RDDBlockId，其中 RDDBlockId 就把 block 和 partition 联系起来了，RDDBlockId 产生的 name 就是 BlockId 的 name 属性，形式是：rdd_rdd.id_partition.index。</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">def&nbsp;getOrCompute[T]( rdd:&nbsp;RDD[T], partition:&nbsp;Partition, context:&nbsp;TaskContext, storageLevel:&nbsp;StorageLevel):&nbsp;Iterator[T]&nbsp;=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;key&nbsp;=&nbsp;RDDBlockId(rdd.id,&nbsp;partition.index) &nbsp;&nbsp;&nbsp;&nbsp;logDebug(s<span style="color:#7b9726;"><span style="color:#880000;">"Looking&nbsp;for&nbsp;partition&nbsp;$key"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;blockManager.get(key)&nbsp;match&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Some</span></span><span style="color:#df5320;">(blockResult)</span>&nbsp;</span>=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;existingMetrics&nbsp;=&nbsp;context.taskMetrics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;.getInputMetricsForReadMethod(blockResult.readMethod) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;existingMetrics.incBytesRead(blockResult.bytes) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;iter&nbsp;=&nbsp;blockResult.data.asInstanceOf[Iterator[T]] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;InterruptibleIterator[T](context,&nbsp;iter)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;">override&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">next</span></span><span style="color:#df5320;">()</span>:&nbsp;T&nbsp;</span>=&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;existingMetrics.incRecordsRead(<span style="color:#df5320;"><span style="color:#008800;">1</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;delegate.next() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">case</span></span>&nbsp;None&nbsp;=&gt; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;storedValues&nbsp;=&nbsp;acquireLockForPartition[T](key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(storedValues.isDefined)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">return</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;InterruptibleIterator[T](context,&nbsp;storedValues.get) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">try</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(s<span style="color:#7b9726;"><span style="color:#880000;">"Partition&nbsp;$key&nbsp;not&nbsp;found,&nbsp;computing&nbsp;it"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;computedValues&nbsp;=&nbsp;rdd.computeOrReadCheckpoint(partition,&nbsp;context) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(context.isRunningLocally)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">return</span></span>&nbsp;computedValues &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;updatedBlocks&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;ArrayBuffer[(BlockId,&nbsp;BlockStatus)] &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;cachedValues&nbsp;=&nbsp;putInBlockManager(key,&nbsp;computedValues,&nbsp;storageLevel,&nbsp;updatedBlocks) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;metrics&nbsp;=&nbsp;context.taskMetrics &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;lastUpdatedBlocks&nbsp;=&nbsp;metrics.updatedBlocks.getOrElse(Seq[(BlockId,&nbsp;BlockStatus)]()) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;metrics.updatedBlocks&nbsp;=&nbsp;Some(lastUpdatedBlocks&nbsp;++&nbsp;updatedBlocks.toSeq) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;InterruptibleIterator(context,&nbsp;cachedValues) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">finally</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.<span style="color:#6666ea;"><span style="color:#0000ff;">synchronized</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.remove(key) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;loading.notifyAll() &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;} } </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">同时 getOrCompute 函数会对 block 进行判断：<br>   如果该 block 存在，表示此 RDD 在之前已经被计算过和存储在 BlockManager 中，因此取出即可，无需再重新计算。<br>   如果该 block 不存在则需要调用 RDD 的 computeOrReadCheckpoint() 函数计算出新的block，并将其存储到 BlockManager 中。<br>   需要注意的是 block 的计算和存储是阻塞的，若另一线程也需要用到此 block 则需等到该线程 block 的 loading 结束。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label11"></a></span></span></p> 
  <h2 id="h12sparkshuffle" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第12章 Spark Shuffle 过程</strong></span></span></strong></span></span></h2> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label11_0"></a></span></span></p> 
  <h3 id="h121mapreduceshuffle" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.1 MapReduce 的 Shuffle 过程介绍</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Shuffle 的本义是洗牌、混洗，把一组有一定规则的数据尽量转换成一组无规则的数据，越随机越好。MapReduce 中的 Shuffle 更像是洗牌的逆过程，把一组无规则的数据尽量转换成一组具有一定规则的数据。<br>   为什么 MapReduce 计算模型需要 Shuffle 过程？我们都知道 MapReduce 计算模型一般包括两个重要的阶段：Map 是映射，负责数据的过滤分发；Reduce 是规约，负责数据的计算归并。Reduce 的数据来源于 Map，Map 的输出即是 Reduce 的输入，Reduce 需要通过 Shuffle来 获取数据。<br>   从 Map 输出到 Reduce 输入的整个过程可以广义地称为 Shuffle。Shuffle 横跨 Map 端和 Reduce 端，在 Map 端包括 Spill 过程，在 Reduce 端包括 copy 和 sort 过程，如图所示：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtjOJS.png"></span></span>
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.1.1 Spill 过程(刷写过程)</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spill 过程包括输出、排序、溢写、合并等步骤，如图所示：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtjxMj.png"></span></span>
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>Collect</strong></span></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  每个 Map 任务不断地以&nbsp;<code>&lt;key, value&gt;</code>&nbsp;对的形式把数据输出到内存中构造的一个环形数据结构中。使用环形数据结构是为了更有效地使用内存空间，在内存中放置尽可能多的数据。<br>   这个数据结构其实就是个字节数组，叫 kvbuffer，名如其义，但是这里面不光放置了&nbsp;<code>&lt;key, value&gt;</code>数据，还放置了一些索引数据，给放置索引数据的区域起了一个 kvmeta 的别名，在 kvbuffer 的一块区域上穿了一个 IntBuffer（字节序采用的是平台自身的字节序）的马甲。<code>&lt;key, value&gt;</code>&nbsp;数据区域和索引数据区域在 kvbuffer 中是相邻不重叠的两个区域，用一个分界点来划分两者，分界点不是亘古不变的，而是每次 Spill 之后都会更新一次。初始的分界点是 0，<code>&lt;key, value&gt;</code>&nbsp;数据的存储方向是向上增长，索引数据的存储方向是向下增长，如图所示：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvEz4.png"></span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  kvbuffer 的存放指针 bufindex 是一直闷着头地向上增长，比如 bufindex 初始值为 0，一个 Int 型的 key 写完之后，bufindex 增长为 4，一个 Int 型的 value 写完之后，bufindex 增长为 8。<br>   索引是对&nbsp;<code>&lt;key, value&gt;</code>&nbsp;在 kvbuffer 中的索引，是个四元组，包括：value 的起始位置、key 的起始位置、partition 值、value 的长度，占用四个 Int 长度，kvmeta 的存放指针 kvindex 每次都是向下跳四个“格子”，然后再向上一个格子一个格子地填充四元组的数据。比如 Kvindex 初始位置是 -4，当第一个&nbsp;<code>&lt;key, value&gt;</code>&nbsp;写完之后，(kvindex+0) 的位置存放 value 的起始位置、(kvindex+1) 的位置存放 key 的起始位置、(kvindex+2) 的位置存放 partition 的值、(kvindex+3) 的位置存放 value 的长度，然后 kvindex 跳到 -8 位置，等第二个&nbsp;<code>&lt;key, value&gt;</code>&nbsp;和索引写完之后，kvindex 跳到-32 位置。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  kvbuffer 的大小虽然可以通过参数设置，但是总共就那么大，<code>&lt;key, value&gt;</code>&nbsp;和索引不断地增加，加着加着，kvbuffer 总有不够用的那天，那怎么办？把数据从内存刷到磁盘上再接着往内存写数据，<code>把 kvbuffer 中的数据刷到磁盘上的过程就叫 Spill</code>，多么明了的叫法，内存中的数据满了就自动地 spill 到具有更大空间的磁盘。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  关于 Spill 触发的条件，也就是 kvbuffer 用到什么程度开始 Spill，还是要讲究一下的。如果把 kvbuffer 用得死死得，一点缝都不剩的时候再开始 Spill，那 Map 任务就需要等 Spill 完成腾出空间之后才能继续写数据；如果 kvbuffer 只是满到一定程度，比如 80% 的时候就开始 Spill，那在 Spill 的同时，Map 任务还能继续写数据，如果 Spill 够快，Map 可能都不需要为空闲空间而发愁。两利相衡取其大，一般选择后者。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spill 这个重要的过程是由 Spill 线程承担，Spill 线程从 Map 任务接到“命令”之后就开始正式干活，干的活叫 SortAndSpill，原来不仅仅是 Spill，在 Spill 之前还有个颇具争议性的 Sort。</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>Sort</strong></span></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  先把 kvbuffer 中的数据按照 partition 值和 key 两个关键字升序排序，移动的只是索引数据，排序结果是 kvmeta 中数据按照 partition 为单位聚集在一起，同一 partition 内的按照 key 有序。</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>Spill</strong></span></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spill 线程为这次 Spill 过程创建一个磁盘文件：从所有的本地目录中轮询查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out” 的文件。Spill 线程根据排过序的 kvmeta 挨个 partition 的把&nbsp;<code>&lt;key, value&gt;</code>&nbsp;数据吐到这个文件中，一个 partition 对应的数据吐完之后顺序地吐下个 partition，直到把所有的 partition 遍历完。一个 partition 在文件中对应的数据也叫段 (segment)。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  所有的 partition 对应的数据都放在这个文件里，虽然是顺序存放的，但是怎么直接知道某个 partition 在这个文件中存放的起始位置呢？强大的索引又出场了。有一个三元组记录某个 partition 对应的数据在这个文件中的索引：起始位置、原始数据长度、压缩之后的数据长度，一个 partition 对应一个三元组。然后把这些索引信息存放在内存中，如果内存中放不下了，后续的索引信息就需要写到磁盘文件中了：从所有的本地目录中轮训查找能存储这么大空间的目录，找到之后在其中创建一个类似于 “spill12.out.index” 的文件，文件中不光存储了索引数据，还存储了 crc32 的校验数据。(spill12.out.index 不一定在磁盘上创建，如果内存（默认 1M 空间）中能放得下就放在内存中，即使在磁盘上创建了，和 spill12.out 文件也不一定在同一个目录下。)</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  每一次 Spill 过程就会最少生成一个 out 文件，有时还会生成 index 文件，Spill 的次数也烙印在文件名中。索引文件和数据文件的对应关系如下图所示：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etjzss.png"></span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  在 Spill 线程如火如荼的进行 SortAndSpill 工作的同时，Map 任务不会因此而停歇，而是一无既往地进行着数据输出。Map 还是把数据写到 kvbuffer 中，那问题就来了：<code>&lt;key, value&gt;</code>&nbsp;只顾着闷头按照 bufindex 指针向上增长，kvmeta 只顾着按照 kvindex 向下增长，是保持指针起始位置不变继续跑呢，还是另谋它路？如果保持指针起始位置不变，很快 bufindex 和 kvindex 就碰头了，碰头之后再重新开始或者移动内存都比较麻烦，不可取。Map 取 kvbuffer 中剩余空间的中间位置，用这个位置设置为新的分界点，bufindex 指针移动到这个分界点，kvindex 移动到这个分界点的 -16 位置，然后两者就可以和谐地按照自己既定的轨迹放置数据了，当 Spill 完成，空间腾出之后，不需要做任何改动继续前进。分界点的转换如下图所示：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtjjzQ.png"><br>   Map 任务总要把输出的数据写到磁盘上，即使输出数据量很小在内存中全部能装得下，在最后也会把数据刷到磁盘上。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.1.2 Merge</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvSLn.png"><br>   Map 任务如果输出数据量很大，可能会进行好几次 Spill，out 文件和 Index 文件会产生很多，分布在不同的磁盘上。最后把这些文件进行合并的 merge 过程闪亮登场。<br>   Merge 过程怎么知道产生的 Spill 文件都在哪了呢？从所有的本地目录上扫描得到产生的 Spill 文件，然后把路径存储在一个数组里。Merge 过程又怎么知道 Spill 的索引信息呢？没错，也是从所有的本地目录上扫描得到 Index 文件，然后把索引信息存储在一个列表里。到这里，又遇到了一个值得纳闷的地方。在之前 Spill 过程中的时候为什么不直接把这些信息存储在内存中呢，何必又多了这步扫描的操作？特别是 Spill 的索引数据，之前当内存超限之后就把数据写到磁盘，现在又要从磁盘把这些数据读出来，还是需要装到更多的内存中。之所以多此一举，是因为这时 kvbuffer 这个内存大户已经不再使用可以回收，有内存空间来装这些数据了。（对于内存空间较大的土豪来说，用内存来省却这两个 io 步骤还是值得考虑的。）</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  然后为 merge 过程创建一个叫 file.out 的文件和一个叫 file.out.Index 的文件用来存储最终的输出和索引。<br>   一个 partition 一个 partition 的进行合并输出。对于某个 partition 来说，从索引列表中查询这个 partition 对应的所有索引信息，每个对应一个段插入到段列表中。也就是这个 partition 对应一个段列表，记录所有的 Spill 文件中对应的这个 partition 那段数据的文件名、起始位置、长度等等。<br>   然后对这个 partition 对应的所有的 segment 进行合并，目标是合并成一个 segment。当这个 partition 对应很多个 segment 时，会分批地进行合并：先从 segment 列表中把第一批取出来，以 key 为关键字放置成最小堆，然后从最小堆中每次取出最小的&nbsp;<code>&lt;key, value&gt;</code>&nbsp;输出到一个临时文件中，这样就把这一批段合并成一个临时的段，把它加回到 segment 列表中；再从 segment 列表中把第二批取出来合并输出到一个临时 segment，把其加入到列表中；这样往复执行，直到剩下的段是一批，输出到最终的文件中。<br>   最终的索引数据仍然输出到 Index 文件中。<br>   Map 端的 Shuffle 过程到此结束。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.1.3 Copy</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Reduce 任务通过 HTTP 向各个 Map 任务拖取它所需要的数据。每个节点都会启动一个常驻的 HTTP server，其中一项服务就是响应 Reduce 拖取 Map 数据。当有 MapOutput 的 HTTP 请求过来的时候，HTTP server 就读取相应的 Map 输出文件中对应这个 Reduce 部分的数据通过网络流输出给 Reduce。<br>   Reduce 任务拖取某个 Map 对应的数据，如果在内存中能放得下这次数据的话就直接把数据写到内存中。Reduce 要向每个 Map 去拖取数据，在内存中每个 Map 对应一块数据，当内存中存储的 Map 数据占用空间达到一定程度的时候，开始启动内存中 merge，把内存中的数据 merge 输出到磁盘上一个文件中。<br>   如果在内存中不能放得下这个 Map 的数据的话，直接把 Map 数据写到磁盘上，在本地目录创建一个文件，从 HTTP 流中读取数据然后写到磁盘，使用的缓存区大小是 64K。拖一个 Map 数据过来就会创建一个文件，当文件数量达到一定阈值时，开始启动磁盘文件 merge，把这些文件合并输出到一个文件。<br>   有些 Map 的数据较小是可以放在内存中的，有些 Map 的数据较大需要放在磁盘上，这样最后 Reduce 任务拖过来的数据有些放在内存中了有些放在磁盘上，最后会对这些来一个全局合并。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.1.4 Merge Sort</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  这里使用的 Merge 和 Map 端使用的 Merge 过程一样。Map 的输出数据已经是有序的，Merge 进行一次合并排序，所谓 Reduce 端的 sort 过程就是这个合并的过程。一般 Reduce 是一边 copy 一边 sort，即 copy 和 sort 两个阶段是重叠而不是完全分开的。<br>   Reduce 端的 Shuffle 过程至此结束。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label11_1"></a></span></span></p> 
  <h3 id="h122hashshuffle" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.2 HashShuffle 过程介绍</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 丰富了任务类型，有些任务之间数据流转不需要通过 Shuffle，但是有些任务之间还是需要通过 Shuffle 来传递数据，比如 wide dependency 的 group by key。<br>   Spark 中需要 Shuffle 输出的 Map 任务会为每个 Reduce 创建对应的 bucket，Map 产生的结果会根据设置的 partitioner 得到对应的 bucketId，然后填充到相应的 bucket 中去。每个 Map 的输出结果可能包含所有的 Reduce 所需要的数据，所以每个 Map 会创建 R 个 bucket（R 是 reduce 的个数），M 个 Map 总共会创建 M*R 个 bucket。<br>   Map 创建的 bucket 其实对应磁盘上的一个文件，Map 的结果写到每个 bucket 中其实就是写到那个磁盘文件中，这个文件也被称为 blockFile，是 Disk Block Manager 管理器通过文件名的 Hash 值对应到本地目录的子目录中创建的。每个 Map 要在节点上创建 R 个磁盘文件用于结果输出，Map 的结果是直接输出到磁盘文件上的，100KB 的内存缓冲是用来创建 Fast Buffered OutputStream 输出流。这种方式一个问题就是 Shuffle 文件过多。<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etv9Zq.png"><br>   1）每一个 Mapper 创建出和 Reducer 数目相同的 bucket，bucket 实际上是一个 buffer，其大小为 spark.shuffle.file.buffer.kb（默认 32KB）。<br>   2）Mapper 产生的结果会根据设置的 partition 算法填充到每个 bucket 中去，然后再写入到磁盘文件。<br>   3）Reducer 从远端或是本地的 block manager 中找到相应的文件读取数据。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  针对上述 Shuffle 过程产生的文件过多问题，Spark 有另外一种改进的 Shuffle 过程：<code>consolidation Shuffle</code>，以期显著减少 Shuffle 文件的数量。在 consolidation Shuffle 中每个 bucket 并非对应一个文件，而是对应文件中的一个 segment 部分。Job 的 map 在某个节点上第一次执行，为每个 reduce 创建 bucke 对应的输出文件，把这些文件组织成&nbsp;<code>ShuffleFileGroup</code>，当这次 map 执行完之后，这个 ShuffleFileGroup 可以释放为下次循环利用；当又有 map 在这个节点上执行时，不需要创建新的 bucket 文件，而是在上次的 ShuffleFileGroup 中取得已经创建的文件继续追加写一个 segment；当前次 map 还没执行完，ShuffleFileGroup 还没有释放，这时如果有新的 map 在这个节点上执行，无法循环利用这个 ShuffleFileGroup，而是只能创建新的 bucket 文件组成新的 ShuffleFileGroup 来写输出。<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvCd0.png"></span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  比如一个 Job 有 3 个 Map 和 2 个 reduce：<br>   (1) 如果此时集群有 3 个节点有空槽，每个节点空闲了一个 core，则 3 个 Map 会调度到这 3 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，总共创建 6 个 Shuffle 文件；<br>   (2) 如果此时集群有 2 个节点有空槽，每个节点空闲了一个 core，则 2 个 Map 先调度到这 2 个节点上执行，每个 Map 都会创建 2 个 Shuffle 文件，然后其中一个节点执行完 Map 之后又调度执行另一个 Map，则这个 Map 不会创建新的 Shuffle 文件，而是把结果输出追加到之前 Map 创建的 Shuffle 文件中；总共创建 4 个 Shuffle 文件；<br>   (3) 如果此时集群有 2 个节点有空槽，一个节点有 2 个空 core 一个节点有 1 个空 core，则一个节点调度 2 个 Map 一个节点调度 1 个 Map，调度 2 个 Map 的节点上，一个 Map 创建了 Shuffle 文件，后面的 Map 还是会创建新的 Shuffle 文件，因为上一个 Map 还正在写，它创建的 ShuffleFileGroup 还没有释放；总共创建 6 个 Shuffle 文件。<br><strong>优点</strong>：<br>   1）快-不需要排序，也不需要维持 hash 表<br>   2）不需要额外空间用作排序<br>   3）不需要额外IO-数据写入磁盘只需一次，读取也只需一次<br><strong>缺点</strong>：<br>   1）当 partitions 大时，输出大量的文件（cores * R），性能开始降低<br>   2）大量的文件写入，使文件系统开始变为随机写，性能比顺序写要降低 100 倍<br>   3）缓存空间占用比较大<br>   Reduce 去拖 Map 的输出数据，Spark 提供了两套不同的拉取数据框架：通过 socket 连接去取数据；使用n etty 框架去取数据。<br>   每个节点的 Executor 会创建一个 BlockManager，其中会创建一个 BlockManagerWorker 用于响应请求。当 Reduce 的 GET_BLOCK 的请求过来时，读取本地文件将这个 blockId 的数据返回给 Reduce。如果使用的是 Netty 框架，BlockManager 会创建 ShuffleSender 用于发送 Shuffle 数据。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  并不是所有的数据都是通过网络读取，对于在本节点的 Map 数据，Reduce 直接去磁盘上读取而不再通过网络框架。<br>   Reduce 拖过来数据之后以什么方式存储呢？Spark Map 输出的数据没有经过排序，Spark Shuffle 过来的数据也不会进行排序，<code>Spark 认为 Shuffle 过程中的排序不是必须的</code>，并不是所有类型的 Reduce 需要的数据都需要排序，强制地进行排序只会增加 Shuffle 的负担。Reduce 拖过来的数据会放在一个 HashMap 中，HashMap 中存储的也是&nbsp;<code>&lt;key, value&gt;</code>&nbsp;对，key 是 Map 输出的 key，Map 输出对应这个 key 的所有 value 组成 HashMap 的 value。Spark 将 Shuffle 取过来的每一个&nbsp;<code>&lt;key, value&gt;</code>对插入或者更新到 HashMap 中，来一个处理一个。HashMap 全部放在内存中。<br>   Shuffle 取过来的数据全部存放在内存中，对于数据量比较小或者已经在 Map 端做过合并处理的 Shuffle 数据，占用内存空间不会太大，但是对于比如 group by key 这样的操作，Reduce 需要得到 key 对应的所有 value，并将这些 value 组一个数组放在内存中，这样当数据量较大时，就需要较多内存。<br>   当内存不够时，要不就失败，要不就用老办法把内存中的数据移到磁盘上放着。Spark 意识到在处理数据规模远远大于内存空间时所带来的不足，引入了一个具有外部排序的方案。Shuffle 过来的数据先放在内存中，当内存中存储的&nbsp;<code>&lt;key, value&gt;</code>&nbsp;对超过 1000 并且内存使用超过 70% 时，判断节点上可用内存如果还足够，则把内存缓冲区大小翻倍，如果可用内存不再够了，则把内存中的&nbsp;<code>&lt;key, value&gt;</code>&nbsp;对排序然后写到磁盘文件中。最后把内存缓冲区中的数据排序之后和那些磁盘文件组成一个最小堆，每次从最小堆中读取最小的数据，这个和 MapReduce 中的 merge 过程类似。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label11_2"></a></span></span></p> 
  <h3 id="h123sortshuffle" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.3 SortShuffle 过程介绍</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  从 1.2.0 开始默认为 sort shuffle(spark.shuffle.manager = sort)，实现逻辑类似于 Hadoop MapReduce，Hash Shuffle 每一个 reducers 产生一个文件，但是 Sort Shuffle 只是产生一个按照 reducer id 排序可索引的文件，这样，只需获取有关文件中的相关数据块的位置信息，并 fseek 就可以读取指定 reducer 的数据。但对于 rueducer 数比较少的情况，Hash Shuffle 明显要比 Sort Shuffle 快，因此 Sort Shuffle 有个 “fallback” 计划，对于 reducers 数少于 “spark.shuffle.sort.bypassMergeThreshold” (200 by default)，我们使用 fallback 计划，hashing 相关数据到分开的文件，然后合并这些文件为一个，具体实现为 BypassMergeSortShuffleWriter。<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvFiT.png"></span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  在 map 进行排序，在 reduce 端应用 Timsort[1] 进行合并。map 端是否容许 spill，通过 spark.shuffle.spill 来设置，默认是 true。设置为 false，如果没有足够的内存来存储 map 的输出，那么就会导致 OOM 错误，因此要慎用。<br>   用于存储 map 输出的内存为：“JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction，默认为： “JVM Heap Size” * 0.2 * 0.8 = “JVM Heap Size” * 0.16。如果你在同一个执行程序中运行多个线程（设定 spark.executor.cores/ spark.task.cpus 超过 1），每个 map 任务存储的空间为 “JVM Heap Size” * spark.shuffle.memoryFraction * spark.shuffle.safetyFraction / spark.executor.cores * spark.task.cpus，默认 2 个 cores，那么为 0.08 * “JVM Heap Size”。<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvPoV.png"></span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  spark 使用 AppendOnlyMap 存储 map 输出的数据，利用开源 hash 函数 MurmurHash3 和平方探测法把 key 和 value 保存在相同的 array 中。这种保存方法可以是 spark 进行 combine。如果 spill 为 true，会在 spill 前 sort。<br>   与 hash shuffle 相比，sort shuffle 中每个 Mapper 只产生一个数据文件和一个索引文件，数据文件中的数据按照 Reducer 排序，但属于同一个 Reducer 的数据不排序。Mapper 产生的数据先放到 AppendOnlyMap 这个数据结构中，如果内存不够，数据则会 spill 到磁盘，最后合并成一个文件。<br>   与 Hash shuffle 相比，shuffle 文件数量减少，内存使用更加可控。但排序会影响速度。<br><strong>优点</strong>：<br>   1）map 创建文件量较少。<br>   2）少量的 IO 随机操作，大部分是顺序读写。<br><strong>缺点</strong>：<br>   1）要比 Hash Shuffle 要慢，需要自己通过 spark.shuffle.sort.bypassMergeThreshold 来设置合适的值。<br>   2）如果使用 SSD 盘存储 shuffle 数据，那么 Hash Shuffle 可能更合适。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label11_3"></a></span></span></p> 
  <h3 id="h124tungstenshuffle" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.4 TungstenShuffle 过程介绍</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Tungsten-sort 算不得一个全新的 shuffle 方案，它在<code>特定场景下</code>基于类似现有的 Sort Based Shuffle 处理流程，对内存 /CPU/Cache 使用做了非常大的优化。带来高效的同时，也就限定了自己的使用场景。如果 Tungsten-sort 发现自己无法处理，则会自动使用 Sort Based Shuffle 进行处理。Tungsten 中文是钨丝的意思。 Tungsten Project 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，该计划初期似乎对 Spark SQL 优化的最多。不过部分 RDD API 还有 Shuffle 也因此受益。<br><strong>Tungsten-sort 优化点主要在三个方面</strong>:<br>   1）直接在 serialized binary data 上 sort 而不是 java objects，减少了 memory 的开销和 GC 的 overhead。<br>   2）提供 cache-efficient sorter，使用一个 8bytes 的指针，把排序转化成了一个指针数组的排序。<br>   3）spill 的 merge 过程也无需反序列化即可完成。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  这些优化的实现导致引入了一个新的内存管理模型，类似 OS 的 Page，对应的实际数据结构为 MemoryBlock，支持 off-heap 以及 in-heap 两种模式。为了能够对 Record 在这些 MemoryBlock 进行定位，引入了 Pointer（指针）的概念。<br> 如果你还记得 Sort Based Shuffle 里存储数据的对象 PartitionedAppendOnlyMap，这是一个放在 JVM heap 里普通对象，在 Tungsten-sort 中，他被替换成了类似操作系统内存页的对象。如果你无法申请到新的 Page，这个时候就要执行 spill 操作，也就是写入到磁盘的操作。具体触发条件，和 Sort Based Shuffle 也是类似的。<br>   Spark 默认开启的是 Sort Based Shuffle，想要打开 Tungsten-sort，请设置<br>   spark.shuffle.manager=tungsten-sort<br>   对应的实现类是：org.apache.spark.shuffle.unsafe.UnsafeShuffleManager<br>   名字的来源是因为使用了大量 JDK Sun Unsafe API。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">当且仅当下面条件都满足时，才会使用新的 Shuffle 方式：<br>   1）Shuffle dependency 不能带有 aggregation 或者输出需要排序<br>   2）Shuffle 的序列化器需要是 KryoSerializer 或者 Spark SQL's 自定义的一些序列化方式.<br>   3）Shuffle 文件的数量不能大于 16777216。<br>   4）序列化时，单条记录不能大于 128 MB。<br> 可以看到，能使用的条件还是挺苛刻的。<br> 这些限制来源于哪里<br> 参看如下代码，page 的大小：<br>   this.pageSizeBytes = (int) Math.min(PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES,shuffleMemoryManager.pageSizeBytes());<br> 这就保证了页大小不超过 PackedRecordPointer.MAXIMUM_PAGE_SIZE_BYTES 的值，该值就被定义成了 128M。<br> 而产生这个限制的具体设计原因，我们还要仔细分析下 Tungsten 的内存模型，如下图所示：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvAWF.png"></span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">这张图其实画的是 on-heap 的内存逻辑图，其中 #Page 部分为 13bit，Offset 为 51bit，你会发现 2^51 &gt;&gt; 128M 的。但是在 Shuffle 的过程中，对 51bit 做了压缩，使用了 27bit，具体如下：<br>   [24 bit partition number][13 bit memory page number][27 bit offset in page]<br> 这里预留出的 24bi t给了 partition number，为了后面的排序用。上面的好几个限制其实都是因为这个指针引起的：<br>   第一个是 partition 的限制，前面的数字 16777216 就是来源于 partition number 使用 24bit 表示的。<br>   第二个是 page number。<br>   第三个是偏移量，最大能表示到 2^27=128M。那一个 Task 能管理到的内存是受限于这个指针的，最多是 2^13 * 128M 也就是 1TB 左右。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">有了这个指针，我们就可以定位和管理到 off-heap 或者 on-heap 里的内存了。这个模型还是很漂亮的，内存管理也非常高效，记得之前的预估 PartitionedAppendOnlyMap 的内存是非常困难的，但是通过现在的内存管理机制，是非常快速并且精确的。<br> 对于第一个限制，那是因为后续 Shuffle Write 的 sort 部分，只对前面 24bit 的 partiton number 进行排序，key 的值没有被编码到这个指针，所以没办法进行 ordering。<br> 同时，因为整个过程是追求不反序列化的，所以不能做 aggregation。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>Shuffle Write</strong><br> 核心类：&nbsp;<br>   org.apache.spark.shuffle.unsafe.UnsafeShuffleWriter<br> 数据会通过 UnsafeShuffleExternalSorter.insertRecordIntoSorter 一条一条写入到 serOutputStream 序列化输出流。<br> 这里消耗内存的地方是<br>   serBuffer = new MyByteArrayOutputStream(1024 * 1024)<br> 默认是 1M，类似于 Sort Based Shuffle 中的 ExternalSorter，在 Tungsten Sort 对应的为 UnsafeShuffleExternalSorter，记录序列化后就通过 sorter.insertRecord 方法放到 sorter 里去了。<br> 这里 sorter 负责申请 Page，释放 Page，判断是否要进行 spill 都这个类里完成。代码的架子其实和 Sort Based 是一样的。<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvkJU.png"></span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">(另外，值得注意的是，这张图里进行 spill 操作的同时检查内存可用而导致的 Exeception 的 bug 已经在 1.5.1 版本被修复了，忽略那条路径)<br> 内存是否充足的条件依然 shuffleMemoryManager 来决定，也就是所有 Task Shuffle 申请的 Page 内存总和不能大于下面的值：<br>   ExecutorHeapMemeory * 0.2 * 0.8<br> 上面的数字可通过下面两个配置来更改：<br>   spark.shuffle.memoryFraction=0.2<br>   spark.shuffle.safetyFraction=0.8<br> UnsafeShuffleExternalSorter 负责申请内存，并且会生成该条记录最后的逻辑地址，也就前面提到的 Pointer。<br> 接着 Record 会继续流转到 UnsafeShuffleInMemorySorter 中，这个对象维护了一个指针数组：<br>   private long[] pointerArray;<br> 数组的初始大小为 4096，后续如果不够了，则按每次两倍大小进行扩充。<br> 假设 100 万条记录，那么该数组大约是 8M 左右，所以其实还是很小的。一旦 spill 后该 UnsafeShuffleInMemorySorter 就会被赋为 null，被回收掉。<br> 我们回过头来看 spill，其实逻辑上也异常简单了，UnsafeShuffleInMemorySorter 会返回一个迭代器，该迭代器粒度每个元素就是一个指针，然后到根据该指针可以拿到真实的 record，然后写入到磁盘，因为这些 record 在一开始进入 UnsafeShuffleExternalSorter 就已经被序列化了，所以在这里就纯粹变成写字节数组了。形成的结构依然和 Sort Based Shuffle 一致，一个文件里不同的 partiton 的数据用 fileSegment 来表示，对应的信息存在一个 index 文件里。<br> 另外写文件的时候也需要一个 buffer：<br>   spark.shuffle.file.buffer=32k<br> 另外从内存里拿到数据放到 DiskWriter，这中间还要有个中转，是通过：<br>   final byte[] writeBuffer = new byte[DISK_WRITE_BUFFER_SIZE=1024 * 1024];<br> 来完成的，都是内存，所以很快。<br> Task 结束前，我们要做一次 mergeSpills 操作，然后形成一个 shuffle 文件。这里面其实也挺复杂的，<br> 如果开启了<br>   spark.shuffle.unsafe.fastMergeEnabled=true<br> 并且没有开启&nbsp;<br>   spark.shuffle.compress=true<br> 或者压缩方式为：<br>   LZFCompressionCodec<br> 则可以非常高效的进行合并，叫做 transferTo。不过无论是什么合并，都不需要进行反序列化。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>Shuffle Read</strong><br> Shuffle Read 完全复用 HashShuffleReader，具体参看 Sort-Based Shuffle。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label11_4"></a></span></span></p> 
  <h3 id="h125mapreducespark" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>12.5 MapReduce 与 Spark 过程对比</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">MapReduce 和 Spark 的 Shuffle 过程对比如下：</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvmLR.png"></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label12"></a></span></span></p> 
  <h2 id="h13spark" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第13章 Spark 内存管理</strong></span></span></strong></span></span></h2> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 作为一个基于内存的分布式计算引擎，其内存管理模块在整个系统中扮演着非常重要的角色。理解 Spark 内存管理的基本原理，有助于更好地开发 Spark 应用程序和进行性能调优。本文中阐述的原理基于 Spark 2.1 版本。&nbsp;<br>   在执行 Spark 的应用程序时，Spark 集群会启动 Driver 和 Executor 两种 JVM 进程，前者为主控进程，负责创建 Spark 上下文，提交 Spark 作业（Job），并将作业转化为计算任务（Task），在各个 Executor 进程间协调任务的调度，后者负责在工作节点上执行具体的计算任务，并将结果返回给 Driver，同时为需要持久化的 RDD 提供存储功能。由于 Driver 的内存管理相对来说较为简单，本文主要对 Executor 的内存管理进行分析，<code>下文中的 Spark 内存均特指 Executor 的内存</code>。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label12_0"></a></span></span></p> 
  <h3 id="h131" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.1 堆内和堆外内存规划</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  作为一个 JVM 进程，Executor 的内存管理建立在 JVM 的内存管理之上，Spark 对 JVM 的堆内（On-heap）空间进行了更为详细的分配，以充分利用内存。同时，Spark 引入了堆外（Off-heap）内存，使之可以直接在工作节点的系统内存中开辟空间，进一步优化了内存的使用。堆内和堆外内存示意图如下：</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvZQJ.png"></span></span>
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.1.1 堆内内存</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  堆内内存的大小，由 Spark 应用程序启动时的&nbsp;<code>-executor-memory</code>&nbsp;或&nbsp;<code>spark.executor.memory</code>参数配置。Executor 内运行的并发任务共享 JVM 堆内内存，这些任务在缓存 RDD 数据和广播（Broadcast）数据时占用的内存被规划为<code>存储（Storage）内存</code>，而这些任务在执行 Shuffle 时占用的内存被规划为<code>执行（Execution）内存</code>，剩余的部分不做特殊规划，那些 Spark 内部的对象实例，或者用户定义的 Spark 应用程序中的对象实例，均占用剩余的空间。不同的管理模式下，这三部分占用的空间大小各不相同（下面第 2 小节会进行介绍）。<br>   Spark 对堆内内存的管理是一种逻辑上的<code>规划式的管理</code>，因为对象实例占用内存的申请和释放都由 JVM 完成，Spark 只能在申请后和释放前记录这些内存，我们来看其具体流程：<br><strong>申请内存</strong>：<br>   1）Spark 在代码中 new 一个对象实例<br>   2）JVM 从堆内内存分配空间，创建对象并返回对象引用<br>   3）Spark 保存该对象的引用，记录该对象占用的内存<br><strong>释放内存</strong>：<br>   1）Spark 记录该对象释放的内存，删除该对象的引用<br>   2）等待 JVM 的垃圾回收机制释放该对象占用的堆内内存</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  我们知道，<code>JVM 的对象可以以序列化的方式存储</code>，序列化的过程是将对象转换为二进制字节流，本质上可以理解为<code>将非连续空间的链式存储转化为连续空间或块存储</code>，在访问时则需要进行序列化的逆过程--反序列化，将字节流转化为对象，序列化的方式可以节省存储空间，但增加了存储和读取时候的计算开销。<br>   对于 Spark 中序列化的对象，由于是字节流的形式，其占用的内存大小可直接计算，而对于非序列化的对象，其占用的内存是通过周期性地采样近似估算而得，即并不是每次新增的数据项都会计算一次占用的内存大小，这种方法降低了时间开销但是有可能误差较大，导致某一时刻的实际内存有可能远远超出预期。此外，在被 Spark 标记为释放的对象实例，很有可能在实际上并没有被 JVM 回收，导致实际可用的内存小于 Spark 记录的可用内存。所以 Spark 并不能准确记录实际可用的堆内内存，从而也就无法完全避免内存溢出（OOM, Out of Memory）的异常。<br>   虽然不能精准控制堆内内存的申请和释放，但 Spark 通过对存储内存和执行内存各自独立的规划管理，可以决定是否要在存储内存里缓存新的 RDD，以及是否为新的任务分配执行内存，在一定程度上可以提升内存的利用率，减少异常的出现。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.1.2 堆外内存</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  为了进一步优化内存的使用以及提高 Shuffle 时排序的效率，Spark 引入了<code>堆外（Off-heap）内存</code>，使之<code>可以直接在工作节点的系统内存中开辟空间</code>，存储经过序列化的二进制数据。利用 JDK Unsafe API（从 Spark 2.0 开始，在管理堆外的存储内存时不再基于 Tachyon，而是与堆外的执行内存一样，基于 JDK Unsafe API 实现），Spark 可以直接操作系统堆外内存，减少了不必要的内存开销，以及频繁的 GC 扫描和回收，提升了处理性能。<code>堆外内存可以被精确地申请和释放</code>，而且序列化的数据占用的空间可以被精确计算，所以相比堆内内存来说降低了管理的难度，也降低了误差。<br>   在默认情况下堆外内存并不启用，可通过配置&nbsp;<code>spark.memory.offHeap.enabled</code>&nbsp;参数启用，并由&nbsp;<code>spark.memory.offHeap.size</code>&nbsp;参数设定堆外空间的大小。除了没有 other 空间，堆外内存与堆内内存的划分方式相同，所有运行中的并发任务共享存储内存和执行内存。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.1.3 内存管理接口</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 为存储内存和执行内存的管理提供了统一的接口--MemoryManager，同一个 Executor 内的任务都调用这个接口的方法来申请或释放内存:</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">内存管理接口的主要方法：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;申请存储内存</span></span> <span style="color:inherit;"><span style="color:#888888;">def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">acquireStorageMemory</span></span><span style="color:#df5320;"><span style="color:#888888;">(blockId:&nbsp;BlockId,&nbsp;numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode)</span></span><span style="color:#888888;">:&nbsp;Boolean</span> <span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;申请展开内存</span></span> <span style="color:#888888;">def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">acquireUnrollMemory</span></span><span style="color:#df5320;"><span style="color:#888888;">(blockId:&nbsp;BlockId,&nbsp;numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode)</span></span><span style="color:#888888;">:&nbsp;Boolean</span> <span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;申请执行内存</span></span> <span style="color:#888888;">def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">acquireExecutionMemory</span></span><span style="color:#df5320;"><span style="color:#888888;">(numBytes:&nbsp;Long,&nbsp;taskAttemptId:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode)</span></span><span style="color:#888888;">:&nbsp;Long</span> <span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;释放存储内存</span></span> <span style="color:#888888;">def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">releaseStorageMemory</span></span><span style="color:#df5320;"><span style="color:#888888;">(numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode)</span></span><span style="color:#888888;">:&nbsp;Unit</span> <span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;释放执行内存</span></span> <span style="color:#888888;">def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">releaseExecutionMemory</span></span><span style="color:#df5320;"><span style="color:#888888;">(numBytes:&nbsp;Long,&nbsp;taskAttemptId:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode)</span></span><span style="color:#888888;">:&nbsp;Unit</span> <span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;释放展开内存</span></span> <span style="color:#888888;">def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">releaseUnrollMemory</span></span><span style="color:#df5320;"><span style="color:#888888;">(numBytes:&nbsp;Long,&nbsp;memoryMode:&nbsp;MemoryMode)</span></span><span style="color:#888888;">:&nbsp;Unit</span> </span></code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Spark的内存管理 – 内存管理接口</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etvey9.png"></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  我们看到，在调用这些方法时都需要指定其内存模式（MemoryMode），这个参数决定了是在堆内还是堆外完成这次操作。MemoryManager 的具体实现上，Spark 1.6 之后默认为统一管理（Unified Memory Manager）方式，1.6 之前采用的静态管理（Static Memory Manager）方式仍被保留，可通过配置&nbsp;<code>spark.memory.useLegacyMode</code>&nbsp;参数启用。两种方式的区别在于对空间分配的方式，下面的第 2 小节会分别对这两种方式进行介绍。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label12_1"></a></span></span></p> 
  <h3 id="h132" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.2 内存空间分配</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.2.1 静态内存管理</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  在 Spark 最初采用的静态内存管理机制下，存储内存、执行内存和其他内存的大小在 Spark 应用程序运行期间均为固定的，但用户可以应用程序启动前进行配置。</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">静态内存管理图示--堆内</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvKdx.png"><br> 可以看到，可用的堆内内存的大小需要按照下面的方式计算：</span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">可用堆内内存空间：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code>可用的存储内存&nbsp;=&nbsp;systemMaxMemory&nbsp;<span style="color:#7b9726;"><span style="color:#008800;">*&nbsp;spark.storage.memoryFraction&nbsp;*</span></span>&nbsp;spark.storage.safetyFraction 可用的执行内存&nbsp;=&nbsp;systemMaxMemory&nbsp;<span style="color:#7b9726;"><span style="color:#008800;">*&nbsp;spark.shuffle.memoryFraction&nbsp;*</span></span>&nbsp;spark.shuffle.safetyFraction </code></span></span></pre> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  其中 systemMaxMemory 取决于当前 JVM 堆内内存的大小，最后可用的执行内存或者存储内存要在此基础上与各自的 memoryFraction 参数和 safetyFraction 参数相乘得出。上述计算公式中的两个 safetyFraction 参数，其意义在于在逻辑上预留出 1-safetyFraction 这么一块保险区域，降低因实际内存超出当前预设范围而导致 OOM 的风险（上文提到，对于非序列化对象的内存采样估算会产生误差）。值得注意的是，这个预留的保险区域仅仅是一种逻辑上的规划，在具体使用时 Spark 并没有区别对待，和 “其它内存” 一样交给了 JVM 去管理。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  堆外的空间分配较为简单，只有存储内存和执行内存，如下图所示。可用的执行内存和存储内存占用的空间大小直接由参数&nbsp;<code>spark.memory.storageFraction</code>&nbsp;决定，由于堆外内存占用的空间可以被精确计算，所以无需再设定保险区域。</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">静态内存管理图示--堆外</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etvue1.png"></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  静态内存管理机制实现起来较为简单，但如果用户不熟悉 Spark 的存储机制，或没有根据具体的数据规模和计算任务或做相应的配置，很容易造成 “一半海水，一半火焰” 的局面，即存储内存和执行内存中的一方剩余大量的空间，而另一方却早早被占满，不得不淘汰或移出旧的内容以存储新的内容。由于新的内存管理机制的出现，这种方式目前已经很少有开发者使用，出于兼容旧版本的应用程序的目的，Spark 仍然保留了它的实现。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.2.2 统一内存管理</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 1.6 之后引入的统一内存管理机制，与静态内存管理的区别在于存储内存和执行内存共享同一块空间，可以动态占用对方的空闲区域。</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">统一内存管理图示--堆内</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvMo6.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">统一内存管理图示--堆外</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvJQH.png"></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">其中最重要的优化在于<code>动态占用机制</code>，其规则如下：<br>   1）设定基本的存储内存和执行内存区域（<code>spark.storage.storageFraction</code>&nbsp;参数），该设定确定了双方各自拥有的空间的范围。<br>   2）双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间;（存储空间不足是指不足以放下一个完整的 Block）。<br>   3）执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后 “归还” 借用的空间。<br>   4）存储内存的空间被对方占用后，无法让对方 “归还”，因为需要考虑 Shuffle 过程中的很多因素，实现起来较为复杂。</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">动态占用机制图示</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etv3WD.png"></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  凭借统一内存管理机制，Spark 在一定程度上提高了堆内和堆外内存资源的利用率，降低了开发者维护 Spark 内存的难度，但并不意味着开发者可以高枕无忧。譬如，所以如果存储内存的空间太大或者说缓存的数据过多，反而会导致频繁的全量垃圾回收，降低任务执行时的性能，因为缓存的 RDD 数据通常都是长期驻留内存的。所以要想充分发挥 Spark 的性能，需要开发者进一步了解存储内存和执行内存各自的管理方式和实现原理。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label12_2"></a></span></span></p> 
  <h3 id="h133" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.3 存储内存管理</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.3.1 RDD 的持久化机制</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  弹性分布式数据集（RDD）作为 Spark 最根本的数据抽象，是只读的分区记录（Partition）的集合，只能基于在稳定物理存储中的数据集上创建，或者在其他已有的 RDD 上执行转换（Transformation）操作产生一个新的 RDD。转换后的 RDD 与原始的 RDD 之间产生的依赖关系，构成了血统（Lineage）。凭借血统，Spark 保证了每一个 RDD 都可以被重新恢复。但 RDD 的所有转换都是惰性的，即只有当一个返回结果给 Driver 的行动（Action）发生时，Spark 才会创建任务读取 RDD，然后真正触发转换的执行。<br>   Task 在启动之初读取一个分区时，会先判断这个分区是否已经被持久化，如果没有则需要检查 Checkpoint 或按照血统重新计算。所以如果一个 RDD 上要执行多次行动，可以在第一次行动中使用 persist 或 cache 方法，在内存或磁盘中持久化或缓存这个 RDD，从而在后面的行动时提升计算速度。事实上，cache 方法是使用默认的 MEMORY_ONLY 的存储级别将 RDD 持久化到内存，故缓存是一种特殊的持久化。<code>堆内和堆外存储内存的设计，便可以对缓存 RDD 时使用的内存做统一的规划和管理</code>（存储内存的其他应用场景，如缓存 broadcast 数据，暂时不在本文的讨论范围之内）。<br>   RDD 的持久化由 Spark 的 Storage 模块负责，实现了 RDD 与物理存储的解耦合。Storage 模块负责管理 Spark 在计算过程中产生的数据，将那些在内存或磁盘、在本地或远程存取数据的功能封装了起来。在具体实现时 Driver 端和 Executor 端的 Storage 模块构成了主从式的架构，即 Driver 端的 BlockManager 为 Master，Executor 端的 BlockManager 为 Slave。Storage 模块在逻辑上以 Block 为基本存储单位，RDD 的每个 Partition 经过处理后唯一对应一个 Block（BlockId 的格式为 rdd_RDD-ID_PARTITION-ID ）。Master 负责整个 Spark 应用程序的 Block 的元数据信息的管理和维护，而 Slave 需要将 Block 的更新等状态上报到 Master，同时接收 Master 的命令，例如新增或删除一个 RDD。</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Storage 模块示意图</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etv1JO.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在对 RDD 持久化时，Spark 规定了 MEMORY_ONLY、MEMORY_AND_DISK 等 7 种不同的 存储级别，而存储级别是以下 5 个变量的组合：<br> 存储级别</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;"><span style="color:#6666ea;"><span style="color:#0000ff;">class</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">StorageLevel</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">private</span></span>( &nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">private</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">var</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">_useDisk</span></span>:&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Boolean</span></span>,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;磁盘 &nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">private</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">var</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">_useMemory</span></span>:&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Boolean</span></span>,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;这里其实是指堆内内存 &nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">private</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">var</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">_useOffHeap</span></span>:&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Boolean</span></span>,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;//&nbsp;堆外内存 &nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">private</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">var</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">_deserialized</span></span>:&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Boolean</span></span>,&nbsp;&nbsp;&nbsp;//&nbsp;是否为非序列化 &nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">private</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">var</span></span>&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">_replication</span></span>:&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">Int</span></span>&nbsp;</span>=&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;副本个数</span></span> <span style="color:#888888;">)</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">通过对数据结构的分析，可以看出存储级别从三个维度定义了 RDD 的 Partition（同时也就是 Block）的存储方式：</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java">&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>）存储位置：磁盘／堆内内存／堆外内存。如&nbsp;MEMORY_AND_DISK&nbsp;是同时在磁盘和堆内内存上存储，实现了冗余备份。OFF_HEAP&nbsp;则是只在堆外内存存储，目前选择堆外内存时不能同时存储到其他位置。 &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">2</span></span>）存储形式：Block&nbsp;缓存到存储内存后，是否为非序列化的形式。如&nbsp;MEMORY_ONLY&nbsp;是非序列化方式存储，OFF_HEAP&nbsp;是序列化方式存储。 &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#df5320;"><span style="color:#008800;">3</span></span>）副本数量：大于&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>&nbsp;时需要远程冗余备份到其他节点。如&nbsp;DISK_ONLY_2&nbsp;需要远程备份&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>&nbsp;个副本。 </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.3.2 RDD 缓存的过程</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  RDD 在缓存到存储内存之前，Partition 中的数据一般以迭代器（Iterator）的数据结构来访问，这是 Scala 语言中一种遍历数据集合的方法。通过 Iterator 可以获取分区中每一条序列化或者非序列化的数据项 (Record)，这些 Record 的对象实例在逻辑上占用了 JVM 堆内内存的 other 部分的空间，同一 Partition 的不同 Record 的空间并不连续。<br>   RDD 在缓存到存储内存之后，Partition 被转换成 Block，Record 在堆内或堆外存储内存中占用一块连续的空间。<code>将 Partition 由不连续的存储空间转换为连续存储空间的过程，Spark 称之为 “展开”（Unroll）</code>。Block 有序列化和非序列化两种存储格式，具体以哪种方式取决于该 RDD 的存储级别。非序列化的 Block 以一种 DeserializedMemoryEntry 的数据结构定义，用一个数组存储所有的对象实例，序列化的 Block 则以 SerializedMemoryEntry 的数据结构定义，用字节缓冲区（ByteBuffer）来存储二进制数据。每个 Executor 的 Storage 模块用一个链式 Map 结构（LinkedHashMap）来管理堆内和堆外存储内存中所有的 Block 对象的实例，对这个 LinkedHashMap 新增和删除间接记录了内存的申请和释放。<br>   因为不能保证存储空间可以一次容纳 Iterator 中的所有数据，当前的计算任务在 Unroll 时要向 MemoryManager 申请足够的 Unroll 空间来临时占位，空间不足则 Unroll 失败，空间足够时可以继续进行。对于序列化的 Partition，其所需的 Unroll 空间可以直接累加计算，一次申请。而非序列化的 Partition 则要在遍历 Record 的过程中依次申请，即每读取一条 Record，采样估算其所需的 Unroll 空间并进行申请，空间不足时可以中断，释放已占用的 Unroll 空间。如果最终 Unroll 成功，当前 Partition 所占用的 Unroll 空间被转换为正常的缓存 RDD 的存储空间，如下图所示。</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">Spark Unroll 示意图</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvlFK.png"></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  在静态内存管理时，Spark 在存储内存中专门划分了一块 Unroll 空间，其大小是固定的，统一内存管理时则没有对 Unroll 空间进行特别区分，当存储空间不足时会根据动态占用机制进行处理。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.3.3 淘汰和落盘</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  由于同一个 Executor 的所有的计算任务共享有限的存储内存空间，当有新的 Block 需要缓存但是剩余空间不足且无法动态占用时，就要对 LinkedHashMap 中的旧 Block 进行淘汰（Eviction），而被淘汰的 Block 如果其存储级别中同时包含存储到磁盘的要求，则要对其进行落盘（Drop），否则直接删除该 Block。<br>   存储内存的淘汰规则为：<br>   1）被淘汰的旧 Block 要与新 Block 的 MemoryMode 相同，即同属于堆外或堆内内存。<br>   2）新旧 Block 不能属于同一个 RDD，避免循环淘汰。<br>   3）旧 Block 所属 RDD 不能处于被读状态，避免引发一致性问题。<br>   4）遍历 LinkedHashMap 中 Block，按照最近最少使用（LRU）的顺序淘汰，直到满足新 Block 所需的空间。其中 LRU 是 LinkedHashMap 的特性。<br>   落盘的流程则比较简单，如果其存储级别符合<code>_useDisk 为 true</code>&nbsp;的条件，再根据其&nbsp;<code>_deserialized</code>&nbsp;判断是否是非序列化的形式，若是则对其进行序列化，最后将数据存储到磁盘，在 Storage 模块中更新其信息。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label12_3"></a></span></span></p> 
  <h3 id="h134" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.4 执行内存管理</strong></span></span></strong></span></span></h3> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.4.1 多任务间内存分配</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Executor 内运行的任务同样共享执行内存，Spark 用一个 HashMap 结构保存了任务到内存耗费的映射。每个任务可占用的执行内存大小的范围为 1/2N ~ 1/N，其中 N 为当前 Executor 内正在运行的任务的个数。每个任务在启动之时，要向 MemoryManager 请求申请最少为 1/2N 的执行内存，如果不能被满足要求则该任务被阻塞，直到有其他任务释放了足够的执行内存，该任务才可以被唤醒。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>13.4.2 Shuffle 的内存占用</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  执行内存主要用来存储任务在执行 Shuffle 时占用的内存，Shuffle 是按照一定规则对 RDD 数据重新分区的过程，我们来看 Shuffle 的 Write 和 Read 两阶段对执行内存的使用：<br><strong>Shuffle Write</strong><br>   1）若在 map 端选择普通的排序方式，会采用 ExternalSorter 进行外排，在内存中存储数据时主要占用堆内执行空间。<br>   2）若在 map 端选择 Tungsten 的排序方式，则采用 ShuffleExternalSorter 直接对以序列化形式存储的数据排序，在内存中存储数据时可以占用堆外或堆内执行空间，取决于用户是否开启了堆外内存以及堆外执行内存是否足够。<br><strong>Shuffle Read</strong><br>   1）在对 reduce 端的数据进行聚合时，要将数据交给 Aggregator 处理，在内存中存储数据时占用堆内执行空间。<br>   2）如果需要进行最终结果排序，则要将再次将数据交给 ExternalSorter 处理，占用堆内执行空间。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  在 ExternalSorter 和 Aggregator 中，Spark 会使用一种叫 AppendOnlyMap 的哈希表在堆内执行内存中存储数据，但在 Shuffle 过程中所有数据并不能都保存到该哈希表中，当这个哈希表占用的内存会进行周期性地采样估算，当其大到一定程度，无法再从 MemoryManager 申请到新的执行内存时，Spark 就会将其全部内容存储到磁盘文件中，这个过程被称为溢存(Spill)，溢存到磁盘的文件最后会被归并(Merge)。<br>   Shuffle Write 阶段中用到的 Tungsten 是 Databricks 公司提出的对 Spark 优化内存和 CPU 使用的计划，解决了一些 JVM 在性能上的限制和弊端。Spark 会根据 Shuffle 的情况来自动选择是否采用 Tungsten 排序。Tungsten 采用的页式内存管理机制建立在 MemoryManager 之上，即 Tungsten 对执行内存的使用进行了一步的抽象，这样在 Shuffle 过程中无需关心数据具体存储在堆内还是堆外。每个内存页用一个 MemoryBlock 来定义，并用 Object obj 和 long offset 这两个变量统一标识一个内存页在系统内存中的地址。堆内的 MemoryBlock 是以 long 型数组的形式分配的内存，其 obj 的值为是这个数组的对象引用，offset 是 long 型数组的在 JVM 中的初始偏移地址，两者配合使用可以定位这个数组在堆内的绝对地址；堆外的 MemoryBlock 是直接申请到的内存块，其 obj 为 null，offset 是这个内存块在系统内存中的 64 位绝对地址。Spark 用 MemoryBlock 巧妙地将堆内和堆外内存页统一抽象封装，并用页表(pageTable)管理每个 Task 申请到的内存页。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Tungsten 页式管理下的所有内存用 64 位的逻辑地址表示，由页号和页内偏移量组成：<br>   页号：占 13 位，唯一标识一个内存页，Spark 在申请内存页之前要先申请空闲页号。<br>   页内偏移量：占 51 位，是在使用内存页存储数据时，数据在页内的偏移地址。<br>   有了统一的寻址方式，Spark 可以用 64 位逻辑地址的指针定位到堆内或堆外的内存，整个 Shuffle Write 排序的过程只需要对指针进行排序，并且无需反序列化，整个过程非常高效，对于内存访问效率和 CPU 使用效率带来了明显的提升。</span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 的存储内存和执行内存有着截然不同的管理方式：对于存储内存来说，Spark 用一个 LinkedHashMap 来集中管理所有的 Block，Block 由需要缓存的 RDD 的 Partition 转化而成；而对于执行内存，Spark 用 AppendOnlyMap 来存储 Shuffle 过程中的数据，在 Tungsten 排序中甚至抽象成为页式内存管理，开辟了全新的 JVM 内存管理机制。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label13"></a></span></span></p> 
  <h2 id="h14-1" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第14章 部署模式解析</strong></span></span></strong></span></span></h2> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label13_0"></a></span></span></p> 
  <h3 id="h141" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.1 部署模式概述</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 支持的主要的三种分布式部署方式分别是 standalone、spark on mesos 和 spark on YARN。standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖任何其他资源管理系统。它是 Spark 实现的资源调度框架，其主要的节点有 Client 节点、Master 节点和 Worker 节点。而 yarn 是统一的资源管理机制，在上面可以运行多套计算框架，如 map reduce、storm 等根据 driver 在集群中的位置不同，分为 yarn client 和 yarn cluster。而 mesos 是一个更强大的分布式资源管理框架，它允许多种不同的框架部署在其上，包括 yarn。基本上，Spark 的运行模式取决于传递给 SparkContext 的 MASTER 环境变量的值，个别模式还需要辅助的程序接口来配合使用，目前支持的 Master 字符串及 URL 包括：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvYyd.png"><br>   用户在提交任务给 Spark 处理时，以下两个参数共同决定了 Spark 的运行方式：<br>   • --master MASTER_URL ：决定了 Spark 任务提交给哪种集群处理。<br>   • --deploy-mode DEPLOY_MODE ：决定了 Driver 的运行方式，可选值为 Client 或者 Cluster。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label13_1"></a></span></span></p> 
  <h3 id="h142standalone" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.2 standalone 框架</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  standalone 集群由三个不同级别的节点组成，分别是：<br>   1）Master 主控节点，可以类比为董事长或总舵主，在整个集群之中，最多只有一个 Master 处在 Active 状态。<br>   2）Worker 工作节点，这个是 manager，是分舵主， 在整个集群中，可以有多个 Worker，如果 Worker 为零，什么事也做不了。<br>   3）Executor 干苦力活的，直接受 Worker 掌控，一个 Worker 可以启动多个 executor，启动的个数受限于机器中的 cpu 核数。<br>   <strong>这三种不同类型的节点各自运行于自己的JVM进程之中。</strong></span></span></span></p> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Standalone 模式下，集群启动时包括 Master 与 Worker，其中 Master 负责接收客户端提交的作业，管理 Worker。根据作业提交的方式不同，分为 driver on client 和 drvier on worker。如下图所示，上图为 driver on client 模式，下图为 driver on work 模式。两种模式的主要不同点在于 driver 所在的位置。<br>   在 standalone 部署模式下又分为 client 模式和 cluster 模式。<br>   在client 模式下，driver 和 client 运行于同一 JVM 中，不由 worker 启动，该 JVM 进程直到 spark application 计算完成返回结果后才退出。如下图所示：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvGSe.png"><br>   而在 cluster 模式下，driver 由 worker 启动，client 在确认 spark application 成功提交给 cluster 后直接退出，并不等待 spark application 运行结果返回。如下图所示：<br>   <img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvtOA.png"></span></span>
  </blockquote> 
  <hr>
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">从部署图来进行分析，每个 JVM 进程在启动时的文件依赖如何得到满足。<br>   1）Master 进程最为简单，除了 spark jar 包之外，不存在第三方库依赖。<br>   2）Driver 和 Executor 在运行的时候都有可能存在第三方包依赖，分开来讲。<br>   3）Driver 比较简单，spark-submit 在提交的时候会指定所要依赖的 jar 文件从哪里读取。<br>   4）Executor 由 Worker 来启动，Worker 需要下载 Executor 启动时所需要的 jar 文件，那么从哪里下载呢？</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etv0Ff.png"><br>   Spark Standalone 模式，即独立模式，自带完整的服务，可单独部署到一个集群中，无需依赖其他资源管理系统。在该模式下，用户可以通过手动启动 Master 和 Worker 来启动一个独立的集群。其中，Master 充当了资源管理的角色，Workder 充当了计算节点的角色。在该模式下，Spark Driver 程序在客户端(Client)运行，而 Executor 则在 Worker 节点上运行。以下是一个运行在 Standalone 模式下，包含一个 Master 节点，两个 Worker 节点的 Spark 任务调度交互部署架构图。<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etvawt.png"><br> 从上面的 Spark 任务调度过程可以看到：<br>   1）整个集群分为 Master 节点和 Worker 节点，其 Driver 程序运行在客户端。Master 节点负责为任务分配 Worker 节点上的计算资源，两者会通过相互通信来同步资源状态，见途中红色双向箭头。<br>   2）客户端启动任务后会运行 Driver 程序，Driver 程序中会完成 SparkContext 对象的初始化，并向 Master 进行注册。<br>   3）每个 Workder 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟客户端节点上的 Driver 程序进行通信，上报任务状态。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.2.1 Standalone 模式下任务运行过程</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  上面的过程反映了 Spark 在 standalone 模式下，整体上客户端、Master 和 Workder 节点之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。<br><strong>1）</strong>&nbsp;用户通过 bin/spark-submit 部署工具或者 bin/spark-class 启动应用程序的 Driver 进程，Driver 进程会初始化 SparkContext 对象，并向 Master 节点进行注册。<br>   • 1、Master 节点接受 Driver 程序的注册，检查它所管理的 Worker 节点，为该 Driver 程序分配需要的计算资源 Executor。Worker 节点完成 Executor 的分配后，向 Master 报告 Executor 的状态。<br>   • 2、Worker 节点上的 ExecutorBackend 进程启动后，向 Driver 进程注册。<br><strong>2）</strong>&nbsp;Driver 进程内部通过 DAG Schaduler、Stage Schaduler、Task Schaduler 等过程完成任务的划分后，向 Worker 节点上的 ExecutorBackend 分配 TASK。<br>   • 1、ExecutorBackend 进行 TASK 计算，并向 Driver 报告 TASK 状态，直至结束。<br>   • 2、Driver 进程在所有 TASK 都处理完成后，向 Master 注销。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.2.2 总结</strong></span></span></strong></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 能够以 standalone 模式运行，这是 Spark 自身提供的运行模式，用户可以通过手动启动 master 和 worker 进程来启动一个独立的集群，也可以在一台机器上运行这些守护进程进行测试。standalone 模式可以用在生产环境，它有效的降低了用户学习、测试 Spark 框架的成本。<br>   standalone 模式目前只支持跨应用程序的简单 FIFO 调度。然而，为了允许多个并发用户，你可以控制每个应用使用的资源的最大数。默认情况下，它会请求使用集群的全部 CUP 内核。<br>   缺省情况下，standalone 任务调度允许 worker 的失败（在这种情况下它可以将失败的任务转移给其他的 worker）。但是，调度器使用 master 来做调度，这会产生一个<code>单点问题</code>：如果 master 崩溃，新的应用不会被创建。为了解决这个问题，可以通过 zookeeper 的选举机制在集群中启动多个 master，也可以使用本地文件实现单节点恢复。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label13_2"></a></span></span></p> 
  <h3 id="h143yarn" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.3 yarn 集群模式</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Apache yarn 是 apache Hadoop 开源项目的一部分。设计之初是为了解决 mapreduce 计算框架资源管理的问题。到 haodoop 2.0 使用 yarn 将 mapreduce 的分布式计算和资源管理区分开来。它的引入使得 Hadoop 分布式计算系统进入了平台化时代，即<code>各种计算框架可以运行在一个集群中</code>，由资源管理系统 YRAN 进行统一的管理和调度，从而共享整个集群资源、提高资源利用率。<br>   YARN 总体上也 Master/Slave 架构--ResourceManager/NodeManager。前者(RM)负责对各个 NodeManager(NM) 上的资源进行统一管理和调度。而 Container 是资源分配和调度的基本单位，其中封装了机器资源，如内存、CPU、磁盘和网络等，每个任务会被分配一个 Container，该任务只能在该 Container 中执行，并使用该 Container 封装的资源。NodeManager 的作用则是负责接收并启动应用的 Container、而向 RM 回报本节点上的应用 Container 运行状态和资源使用情况。ApplicationMaster 与具体的 Application 相关，主要负责同 ResourceManager 协商以获取合适的 Container，并跟踪这些 Container 的状态和监控其进度。如下图所示为 yarn 集群的一般模型。<br> 简单架构图如下：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/ENSR0A.png"><br> 详细架构图如下：<br>   <img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvBY8.png"></span></span>
  </blockquote> 
  <hr>
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 在 yarn 集群上的部署方式分为两种，yarn cluster（driver 运行在 master 上）和 yarn client（driver 运行在 client 上）。<br>   <strong>driver on master</strong>&nbsp;如下图所示：<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvcOs.png"><br>   • (1) Spark Yarn Client 向 YARN 中提交应用程序，包括 Application Master 程序、启动 Application Master 的命令、需要在 Executor 中运行的程序等。<br>   • (2) Resource manager 收到请求后，在其中一个 Node Manager 中为应用程序分配一个 Container，要求它在 Container 中启动应用程序的 Application Master，Application Master 初始化 sparkContext 以及创建 DAG Scheduler 和 Task Scheduler。<br>   • (3) Application Master 根据 SparkContext 中的配置，向 Resource Manager 申请 Container，同时，Application Master 向 Resource Manager 注册，这样用户可通过 Resource Manager 查看应用程序的运行状态。<br>   • (4) Resource Manager 在集群中寻找符合条件的 Node Manager，在 Node Manager 启动 Container，要求 Container 启动 Executor。<br>   • (5) Executor 启动后向 Application Master 注册，并接收 Application Master 分配的 Task。<br>   • (6) 应用程序运行完成后，Application Master 向 Resource Manager 申请注销并关闭自己。<br>   <strong>driver on client</strong>&nbsp;如下图所示：<br>   <img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvdTP.png"><br>   • (1) Spark Yarn Client 向 YARN 的 Resource Manager 申请启动 Application Master。同时在 SparkContent 初始化中将创建 DAG Scheduler 和 Task Scheduler 等。<br>   • (2) ResourceManager 收到请求后，在集群中选择一个 NodeManager，为该应用程序分配第一个 Container，要求它在这个 Container 中启动应用程序的 ApplicationMaster，与 YARN-Cluster 区别的是在该 ApplicationMaster 不运行 SparkContext，只与 SparkContext 进行联系进行资源的分派。<br>   • (3) Client 中的 SparkContext 初始化完毕后，与 Application Master 建立通讯，向 Resource Manager 注册，根据任务信息向 Resource Manager 申请资源 (Container)。<br>   • (4) 当 Application Master 申请到资源后，便与 Node Manager 通信，要求它启动 Container。<br>   • (5) Container 启动后向 Driver 中的 SparkContext 注册，并申请 Task。<br>   • (6) 应用程序运行完成后，Client 的 SparkContext 向 ResourceManage r申请注销并关闭自己。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <hr>
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Yarn-client 和Yarn cluster 模式对比可以看出，在 Yarn-client（Driver on client）中，Application Master 仅仅从 Yarn 中申请资源给 Executor，之后 client 会跟 container 通信进行作业的调度。如果 client 离集群距离较远，建议不要采用此方式，不过此方式有利于交互式的作业。　　<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvylQ.png"><br>   Spark 能够以集群的形式运行，可用的集群管理系统有 Yarn、Mesos 等。集群管理器的核心功能是资源管理和任务调度。以 Yarn 为例，Yarn 以 Master/Slave 模式工作，在 Master 节点运行的是 Resource Manager(RM)，负责管理整个集群的资源和资源分配。在 Slave 节点运行的 Node Manager(NM)，是集群中实际拥有资源的工作节点。我们提交 Job 以后，会将组成 Job 的多个 Task 调度到对应的 Node Manager 上进行执行。另外，在 Node Manager 上将资源以 Container 的形式进行抽象，Container 包括两种资源 内存 和 CPU。<br>   以下是一个运行在 Yarn 集群上，包含一个 Resource Manager 节点，三个 Node Manager 节点(其中，两个是 Worker 节点，一个 Master 节点)的 Spark 任务调度交换部署架构图。　<br><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvDfS.png"><br> 从上面的Spark任务调度过程图可以看到:<br>   1）整个集群分为 Master 节点和 Worker 节点，它们都存在于 Node Manager 节点上，在客户端提交任务时由 Resource Manager 统一分配，运行 Driver 程序的节点被称为 Master 节点，执行具体任务的节点被称为 Worder 节点。Node Manager 节点上资源的变化都需要及时更新给 Resource Manager，见图中红色双向箭头。<br>   2）Master 节点上常驻 Master 守护进程 -- Driver 程序，Driver 程序中会创建 SparkContext对 象，并负责跟各个 Worker 节点上的 ExecutorBackend 进程进行通信，管理 Worker 节点上的任务，同步任务进度。实际上，在 Yarn 中 Node Manager 之间的关系是平等的，因此 Driver 程序会被调度到任何一个 Node Manager 节点。<br>   3）每个 Worker 节点上会存在一个或者多个 ExecutorBackend 进程。每个进程包含一个 Executor 对象，该对象持有一个线程池，每个线程池可以执行一个任务(Task)。ExecutorBackend 进程还负责跟 Master 节点上的 Driver 程序进行通信，上报任务状态。　　</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>集群下任务运行过程</strong></span></span></span></p> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  上面的过程反映出了 Spark 在集群模式下，整体上 Resource Manager 和 Node Manager 节点间的交互，Master 和 Worker 之间的交互。对于一个任务的具体运行过程需要更细致的分解，分解运行过程见图中的小字。<br>   • 1) 用户通过 bin/spark-submit 部署工具或者 bin/spark-class 向 Yarn 集群提交应用程序。<br>   • 2) Yarn 集群的 Resource Manager 为提交的应用程序选择一个 Node Manager 节点并分配第一个 Container，并在该节点的 Container 上启动 SparkContext 对象。<br>   • 3) SparkContext 对象向 Yarn 集群的 Resource Manager 申请资源以运行 Executor。<br>   • 4) Yarn 集群的 Resource Manager 分配 Container 给 SparkContext 对象，SparkContext 和相关的 Node Manager 通讯，在获得的 Container 上启动 ExecutorBackend 守护进程，ExecutorBackend 启动后开始向 SparkContext 注册并申请 Task。<br>   • 5) SparkContext 分配 Task 给 ExecutorBackend 执行。<br>   • 6) ExecutorBackend 开始执行 Task，并及时向 SparkContext 汇报运行状况。Task 运行完毕，SparkContext 归还资源给 Node Manager，并注销退。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label13_3"></a></span></span></p> 
  <h3 id="h144mesos" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.4 mesos 集群模式</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Mesos 是 apache 下的开源分布式资源管理框架。起源于<code>加州大学伯克利分校</code>，后被 Twitter 推广使用。Mesos 上可以部署多种分布式框架，Mesos 的架构图如下图所示，其中 Framework 是指外部的计算框架，如 Hadoop、Mesos 等，这些计算框架可通过注册的方式接入 Mesos，以便 Mesos 进行统一管理和资源分配。<br>   </span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvWT0.png"><br>   在 Mesos 上运行的 Framework 由两部分组成：一个是 scheduler ，通过注册到 Master 来获取集群资源。另一个是在 Slave 节点上运行的 executor 进程，它可以执行 Framework 的 task 。 Master 决定为每个 Framework 提供多少资源，Framework 的 scheduler 来选择其中提供的资源。当 Framework 同意了提供的资源，它通过 Master 将 task 发送到提供资源的 Slaves 上运行。Mesos c的资源分配图如下图所示：<br>   <img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvsSg.png"><br>   (1) Slave1 向 Master 报告，有 4 个 CPU 和 4 GB 内存可用。<br>   (2) Master 发送一个 Resource Offer 给 Framework1 来描述 Slave1 有多少可用资源。<br>   (3) FrameWork1 中的 FW Scheduler 会答复 Master，我有两个 Task 需要运行在 Slave1，一个 Task 需要&nbsp;<code>&lt;2个CPU，1 GB内存=""&gt;</code>，另外一个 Task 需要&nbsp;<code>&lt;1个CPU，2 GB内存=""&gt;</code>。<br>   (4) 最后，Master 发送这些 Tasks 给 Slave1。然后，Slave1 还有 1 个 CPU 和 1GB 内存没有使用，所以分配模块可以把这些资源提供给 Framework2。</span></span> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">&nbsp;</span></span></span></p> 
  </blockquote> 
  <hr>
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  Spark 可作为其中一个分布式框架部署在 mesos 上，部署图与 mesos 的一般框架部署图类似，如下图所示，这里不再重述。</span></span></span></p> 
   <span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvhkV.png"></span></span>
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label13_4"></a></span></span></p> 
  <h3 id="h145spark" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.5 spark 三种部署模式的区别</strong></span></span></strong></span></span></h3> 
  <blockquote> 
   <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">  在这三种部署模式中，standalone 作为 spark 自带的分布式部署模式，是最简单也是最基本的 spark 应用程序部署模式，这里就不再赘述。这里就讲一下 yarn 和 mesos 的区别：<br>   (1) 就两种框架本身而言，mesos上可部署 yarn 框架。而 yarn 是更通用的一种部署框架，而且技术较成熟。<br>   (2) mesos 双层调度机制，能支持多种调度模式，而 yarn 通过 Resource　Mananger 管理集群资源，只能使用一种调度模式。Mesos 的双层调度机制为：mesos 可接入如 yarn 一般的分布式部署框架，但 Mesos 要求可接入的框架必须有一个调度器模块，该调度器负责框架内部的任务调度。当一个 Framework 想要接入 mesos 时，需要修改自己的调度器，以便向 mesos 注册，并获取 mesos 分配给自己的资源，这样再由自己的调度器将这些资源分配给框架中的任务，也就是说，整个 mesos 系统采用了双层调度框架：第一层，由 mesos 将资源分配给框架；第二层，框架自己的调度器将资源分配给自己内部的任务。<br>   (3) mesos 可实现粗、细粒度资源调度，可动态分配资源，而 yarn 只能实现静态资源分配。其中粗粒度和细粒度调度定义如下：<br>   粗粒度模式（Coarse-grained Mode）：程序运行之前就要把所需要的各种资源（每个 executor 占用多少资源，内部可运行多少个 executor）申请好，运行过程中不能改变。<br>   细粒度模式（Fine-grained Mode）：为了防止资源浪费，对资源进行按需分配。与粗粒度模式一样，应用程序启动时，先会启动 executor，但每个 executor 占用资源仅仅是自己运行所需的资源，不需要考虑将来要运行的任务，之后，mesos 会为每个 executor 动态分配资源，每分配一些，便可以运行一个新任务，单个 Task 运行完之后可以马上释放对应的资源。每个 Task 会汇报状态给 Mesos Slave 和 Mesos Master，便于更加细粒度管理和容错，这种调度模式类似于 MapReduce 调度模式，每个 Task 完全独立，优点是便于资源控制和隔离，但缺点也很明显，短作业运行延迟大。<br>   从 yarn 和 mesos 的区别可看出，它们各自有优缺点。因此实际使用中，选择哪种框架，要根据本公司的实际需要而定，可考虑现有的大数据生态环境。如我司采用 yarn 部署 spark，原因是，我司早已有较成熟的 hadoop 的框架，考虑到使用的方便性，采用了 yarn 模式的部署。</span></span></span></p> 
  </blockquote> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label13_5"></a></span></span></p> 
  <h3 id="h146" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.6 异常场景分析</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">上面说明的是正常情况下，各节点的消息分发细节。那么如果在运行中，集群中的某些节点出现了问题，整个集群是否还能够正常处理 Application 中的任务呢？</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.6.1 异常分析1：Worker 异常退出</strong></span></span></strong></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etv6yj.png"><br> 在 Spark 运行过程中，经常碰到的问题就是 Worker 异常退出，当 Worker 退出时，整个集群会有哪些故事发生呢？请看下面的具体描述：<br>   1）Worker 异常退出，比如说有意识的通过 kill 指令将 Worker 杀死。<br>   2）Worker 在退出之前，会将自己所管控的所有小弟 Executor 全干掉。<br>   3）Worker 需要定期向 Master 改善心跳消息的，现在 Worker 进程都已经玩完了，哪有心跳消息，所以 Master 会在超时处理中意识到有一个 “分舵” 离开了。<br>   4）Master 非常伤心，伤心的 Master 将情况汇报给了相应的 Driver。<br> Driver 通过两方面确认分配给自己的 Executor 不幸离开了，一是 Master 发送过来的通知，二是 Driver 没有在规定时间内收到 Executor 的 StatusUpdate，于是 Driver 会将注册的 Executor 移除。</span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>后果分析</strong><br> Worker 异常退出会带来哪些影响：<br>   1）Executor 退出导致提交的 Task 无法正常结束，会被再一次提交运行。<br>   2）如果所有的 Worker 都异常退出，则整个集群不可用。<br>   3）需要有相应的程序来重启 Worker 进程，比如使用 supervisord 或 runit。</span></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>测试步骤</strong><br>   1）启动 Master。<br>   2）启动 Worker。<br>   3）启动 spark-shell。<br>   4）手工 kill 掉 Worker 进程。<br>   5）用 jps 或 ps -ef | grep -i java 来查看启动着的 java 进程。</span></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>异常退出的代码处理</strong><br> 定义 ExecutorRunner.scala 的 start 函数</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">start</span></span><span style="color:#df5320;">()</span>&nbsp;</span>{ &nbsp;&nbsp;workerThread&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;Thread(<span style="color:#7b9726;"><span style="color:#880000;">"ExecutorRunner&nbsp;for&nbsp;"</span></span>&nbsp;+&nbsp;fullId)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;">override&nbsp;def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">run</span></span><span style="color:#df5320;">()</span>&nbsp;</span>{&nbsp;fetchAndRunExecutor()&nbsp;} &nbsp;&nbsp;} &nbsp;&nbsp;workerThread.start() &nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Shutdown&nbsp;hook&nbsp;that&nbsp;kills&nbsp;actors&nbsp;on&nbsp;shutdown.</span></span> <span style="color:#888888;">&nbsp;&nbsp;shutdownHook&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;Thread()&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:inherit;"><span style="color:#888888;">override&nbsp;def&nbsp;</span><span style="color:#407ee7;"><span style="color:#888888;">run</span></span><span style="color:#df5320;"><span style="color:#888888;">()</span></span>&nbsp;</span><span style="color:#888888;">{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;killProcess(Some(</span><span style="color:#7b9726;"><span style="color:#888888;">"Worker&nbsp;shutting&nbsp;down"</span></span><span style="color:#888888;">))</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;Runtime.getRuntime.addShutdownHook(shutdownHook)</span> <span style="color:#888888;">}</span> </code></span></span></pre> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">killProcess 的过程就是停止相应 CoarseGrainedExecutorBackend 的过程。<br> Worker 停止的时候，一定要先将自己启动的 Executor 停止掉。这是不是很像水浒中宋江的手段，李逵就是这样不明不白的把命给丢了。</span></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>小结</strong><br>   需要特别指出的是，当 Worker 在启动 Executor 的时候，是通过 ExecutorRunner 来完成的，ExecutorRunner 是一个独立的线程，和 Executor 是一对一的关系，这很重要。Executor 作为一个独立的进程在运行，但会受到 ExecutorRunner 的严密监控。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.6.2 异常分析2：Executor 异常退出</strong></span></span></strong></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/EtvRwq.png"></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>后果分析</strong><br> Executor 作为 Standalone 集群部署方式下的最底层员工，一旦异常退出，其后果会是什么呢？<br>   1）Executor 异常退出，ExecutorRunner 注意到异常，将情况通过 ExecutorStateChanged 汇报给 Master。<br>   2）Master 收到通知之后，非常不高兴，尽然有小弟要跑路，那还了得，要求 Executor 所属的 Worker 再次启动。<br>   3）Worker 收到 LaunchExecutor 指令，再次启动 Executor。</span></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>测试步骤</strong><br>   1）启动 Master<br>   2）启动 Worker<br>   3）启动 spark-shell<br>   4）手工 kill 掉 CoarseGrainedExecutorBackend</span></span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>fetchAndRunExecutor</strong><br> fetchAndRunExecutor 负责启动具体的 Executor，并监控其运行状态，具体代码逻辑如下所示</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">fetchAndRunExecutor</span></span><span style="color:#df5320;">()</span>&nbsp;</span>{ &nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">try</span></span>&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Create&nbsp;the&nbsp;executor's&nbsp;working&nbsp;directory</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;executorDir&nbsp;=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;File(workDir,&nbsp;appId&nbsp;+&nbsp;</span><span style="color:#7b9726;"><span style="color:#888888;">"/"</span></span><span style="color:#888888;">&nbsp;+&nbsp;execId)</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">if</span></span><span style="color:#888888;">&nbsp;(!executorDir.mkdirs())&nbsp;{</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">throw</span></span>&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;IOException(</span><span style="color:#7b9726;"><span style="color:#888888;">"Failed&nbsp;to&nbsp;create&nbsp;directory&nbsp;"</span></span><span style="color:#888888;">&nbsp;+&nbsp;executorDir)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">//&nbsp;Launch&nbsp;the&nbsp;process</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;command&nbsp;=&nbsp;</span><span style="color:inherit;"><span style="color:#888888;">getCommandSeq</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">logInfo</span></span><span style="color:#df5320;"><span style="color:#888888;">(</span><span style="color:#7b9726;"><span style="color:#888888;">"Launch&nbsp;command:&nbsp;"</span></span><span style="color:#888888;">&nbsp;+&nbsp;command.mkString(</span><span style="color:#7b9726;"><span style="color:#888888;">"\""</span></span><span style="color:#888888;">,&nbsp;</span><span style="color:#7b9726;"><span style="color:#888888;">"\"&nbsp;\""</span></span><span style="color:#888888;">,&nbsp;</span><span style="color:#7b9726;"><span style="color:#888888;">"\""</span></span><span style="color:#888888;">)</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;builder&nbsp;</span></span><span style="color:#888888;">=&nbsp;</span><span style="color:#6666ea;"><span style="color:#888888;">new</span></span><span style="color:#888888;">&nbsp;ProcessBuilder(command:&nbsp;_*).directory(executorDir)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;env&nbsp;=&nbsp;builder.environment()</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">for</span></span><span style="color:#888888;">&nbsp;((key,&nbsp;value)&nbsp;&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logInfo(</span><span style="color:#7b9726;"><span style="color:#888888;">"Runner&nbsp;thread&nbsp;for&nbsp;executor&nbsp;"</span></span><span style="color:#888888;">&nbsp;+&nbsp;fullId&nbsp;+&nbsp;</span><span style="color:#7b9726;"><span style="color:#888888;">"&nbsp;interrupted"</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state&nbsp;=&nbsp;ExecutorState.</span><span style="color:inherit;"><span style="color:#888888;">KILLED</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">killProcess</span></span><span style="color:#df5320;"><span style="color:#888888;">(None)</span></span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#888888;">case</span></span><span style="color:#888888;">&nbsp;e:&nbsp;Exception&nbsp;</span></span><span style="color:#888888;">=&gt;&nbsp;{</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;logError(</span><span style="color:#7b9726;"><span style="color:#888888;">"Error&nbsp;running&nbsp;executor"</span></span><span style="color:#888888;">,&nbsp;e)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;state&nbsp;=&nbsp;ExecutorState.</span><span style="color:inherit;"><span style="color:#888888;">FAILED</span> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#407ee7;"><span style="color:#888888;">killProcess</span></span><span style="color:#df5320;"><span style="color:#888888;">(Some(e.toString)</span></span><span style="color:#888888;">)</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;}</span> <span style="color:#888888;">&nbsp;&nbsp;}</span> <span style="color:#888888;">}</span> </span></code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>14.6.3 异常分析3：Master 异常退出</strong></span></span></strong></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etv2mn.png"><br> Worker 和 Executor 异常退出的场景都讲到了，我们剩下最后一种情况了，Master 挂掉了怎么办？</span></span></p> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;"><strong>后果分析</strong><br> 带头大哥如果不在了，会是什么后果呢？<br>   1）Worker 没有汇报的对象了，也就是如果 Executor 再次跑飞，Worker 是不会将 Executor 启动起来的，大哥没给指令。<br>   2）无法向集群提交新的任务。<br>   3）老的任务即便结束了，占用的资源也无法清除，因为资源清除的指令是 Master 发出的。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a href="https://www.cnblogs.com/chenmingjun/p/10803261.html#_labelTop" rel="nofollow">回到顶部</a><a name="_label14"></a></span></span></p> 
  <h2 id="h15wordcount" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:#ffffff;"><strong>第15章 wordcount 程序运行原理窥探</strong></span></span></strong></span></span></h2> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label14_0"></a></span></span></p> 
  <h3 id="h151sparkscalawordcount" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>15.1 spark 之 scala 实现 wordcount</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在 spark 中使用 scala 来实现 wordcount（统计单词出现次数模型）更加简单，相对 java 代码上更加简洁，其函数式编程的思维逻辑也更加直观。</span></span></span></p> 
  <pre style="margin-left:0px;">
<span style="color:#393939;"><span style="color:#3e3e3e;"><code class="language-java"><span style="color:#6666ea;"><span style="color:#0000ff;">package</span></span>&nbsp;com.spark.firstApp <span style="color:#6666ea;">import</span>&nbsp;org.apache.spark.{SparkContext,&nbsp;SparkConf} <span style="color:#766e6b;"><span style="color:#888888;">/**</span> <span style="color:#888888;">&nbsp;&nbsp;*&nbsp;scala&nbsp;实现&nbsp;wordcount</span> <span style="color:#888888;">&nbsp;&nbsp;*/</span></span> object&nbsp;WordCount1&nbsp;{ &nbsp;&nbsp;<span style="color:inherit;">def&nbsp;<span style="color:#407ee7;"><span style="color:#880000;">main</span></span><span style="color:#df5320;">(args:&nbsp;Array[String])</span>&nbsp;</span>{ &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">if</span></span>&nbsp;(args.length&nbsp;==&nbsp;<span style="color:#df5320;"><span style="color:#008800;">0</span></span>)&nbsp;{ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;System.err.println(<span style="color:#7b9726;"><span style="color:#880000;">"Usage:&nbsp;WordCount1&nbsp;&lt;file1&gt;"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;System.exit(<span style="color:#df5320;"><span style="color:#008800;">1</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;} &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">/**</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;1、实例化&nbsp;SparkConf</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;2、构建&nbsp;SparkContext，SparkContext&nbsp;是&nbsp;spark&nbsp;应用程序的唯一入口</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;3.&nbsp;通过&nbsp;SparkContext&nbsp;的&nbsp;textFile&nbsp;方法读取文本文件</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/</span></span> &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;conf&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;SparkConf().setAppName(<span style="color:#7b9726;"><span style="color:#880000;">"WordCount1"</span></span>).setMaster(<span style="color:#7b9726;"><span style="color:#880000;">"local"</span></span>) &nbsp;&nbsp;&nbsp;&nbsp;val&nbsp;sc&nbsp;=&nbsp;<span style="color:#6666ea;"><span style="color:#0000ff;">new</span></span>&nbsp;SparkContext(conf) &nbsp;&nbsp;&nbsp;&nbsp;<span style="color:#766e6b;"><span style="color:#888888;">/**</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;4、通过&nbsp;flatMap&nbsp;对文本中每一行的单词进行拆分（分割符号为空格），并利用&nbsp;map&nbsp;进行函数转换形成&nbsp;(K,V)&nbsp;对形式，再进行&nbsp;reduceByKey，打印输出&nbsp;10&nbsp;个结果</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*&nbsp;&nbsp;&nbsp;&nbsp;函数式编程更加直观的反映思维逻辑</span> <span style="color:#888888;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;*/</span></span> &nbsp;&nbsp;&nbsp;&nbsp;sc.textFile(args(<span style="color:#df5320;"><span style="color:#008800;">0</span></span>)).flatMap(_.split(<span style="color:#7b9726;"><span style="color:#880000;">"&nbsp;"</span></span>)).map(x&nbsp;=&gt;&nbsp;(x,&nbsp;<span style="color:#df5320;"><span style="color:#008800;">1</span></span>)).reduceByKey(_&nbsp;+&nbsp;_).take(<span style="color:#df5320;"><span style="color:#008800;">10</span></span>).foreach(println) &nbsp;&nbsp;&nbsp;&nbsp;sc.stop() &nbsp;&nbsp;} } </code></span></span></pre> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><a name="_label14_1"></a></span></span></p> 
  <h3 id="h152" style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><strong><span style="color:inherit;"><span style="color:inherit;"><strong>15.2 原理窥探</strong></span></span></strong></span></span></h3> 
  <p style="margin-left:0px;"><span style="color:#393939;"><span style="color:#3e3e3e;"><span style="color:inherit;">在 spark 集群中运行 wordcount 程序其主要业务逻辑比较简单，涵盖一下 3 个过程：<br>   1）读取存储介质上的文本文件（一般存储在 hdfs 上）；<br>   2）对文本文件内容进行解析，按照单词进行分组统计汇总；<br>   3）将过程 2 的分组结果保存到存储介质上。（一般存储在 hdfs 或者 RMDB 上）<br> 虽然 wordcount 的业务逻辑非常简单，但其应用程序在 spark 中的运行过程却巧妙得体现了 spark 的核心精髓--<code>分布式弹性数据集</code>、<code>内存迭代</code>以及<code>函数式编程</code>等特点。下图对 spark 集群中 wordcount 的运行过程进行剖析，加深对 spark 技术原理窥探。</span></span></span></p> 
  <p><span style="color:#393939;"><span style="color:#3e3e3e;"><img alt="" class="has" src="https://s2.ax1x.com/2019/05/02/Etv4YT.png"><br>   该图横向分割下面给出了 wordcount 的 scala 核心程序实现，该程序在 spark 集群的运行过程涉及几个核心的 RDD，主要有 textFileRDD、flatMapRDD、mapToPairRDD、shuffleRDD（reduceByKey）等。<br>   应用程序通过 textFile 方法读取 hdfs 上的文本文件，数据分片的形式以 RDD 为统一模式将数据加载到不同的物理节点上，如上图所示的节点 1、节点 2 到节点 n；并通过一系列的数据转换，如利用 flatMap 将文本文件中对应每行数据进行拆分（文本文件中单词以空格为分割符号），形成一个以每个单词为核心新的数据集合 RDD；之后通过 MapRDD 继续转换形成形成 (K,V) 对 数据形式，以便进一步使用 reduceByKey 方法，该方法会触发 shuffle 行为，促使不同的单词到对应的节点上进行汇聚统计（实际上在夸节点进行数据 shuffle 之前会在本地先对相同单词进行合并累加），形成 wordcount 的统计结果；最终通过 saveAsTextFile 方法将数据保存到 hdfs 上。具体的运行逻辑原理以及过程上图给出了详细的示意说明。</span></span></p> 
  <p><span style="color:#393939;">我的GitHub地址：<a href="https://github.com/heizemingjun" rel="nofollow">https://github.com/heizemingjun</a><br> 我的博客园地址：<a href="https://www.cnblogs.com/chenmingjun" rel="nofollow">https://www.cnblogs.com/chenmingjun</a><br> 我的CSDN地址：<a href="https://blog.csdn.net/u012990179" rel="nofollow">https://blog.csdn.net/u012990179</a>&nbsp;<br> 我的蚂蚁笔记博客地址：<a href="https://blog.leanote.com/chenmingjun" rel="nofollow">https://blog.leanote.com/chenmingjun</a><br> Copyright ©2018-2019 黑泽明军<br><span style="color:#FF0000;">【转载文章务必保留出处和署名，谢谢！】</span></span></p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
