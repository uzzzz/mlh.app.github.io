<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Kafka 安装、原理、使用 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Kafka 安装、原理、使用" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="大数据组件使用 总文章 &nbsp; 1.Apache Kafka&nbsp; &nbsp;&nbsp; &nbsp;1.Apache Kafka 是一个开源消息系统，由 Scala 写成。是由 Apache 软件基金会开发的一个开源消息系统项目。 &nbsp;&nbsp; &nbsp;2.Kafka 最初是由 LinkedIn 开发，并于 2011 年初开源。2012 年 10 月从 Apache Incubator 毕业。 &nbsp;&nbsp; &nbsp; &nbsp;该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。 &nbsp;&nbsp; &nbsp;3.Kafka 是一个分布式消息队列(Queue)：生产者、消费者的功能。它提供了类似于 JMS 的特性，但是在设计实现上完全不同，此外它并不是 JMS 规范的实现。 &nbsp;&nbsp; &nbsp;4.Kafka 对消息保存时根据 Topic(主题) 进行归类 &nbsp;&nbsp; &nbsp;5.发送消息者称为 Producer，消息接受者称为 Consumer &nbsp;&nbsp; &nbsp;6.此外 kafka 集群有多个 kafka 实例组成，每个实例(server)成为 broker。 &nbsp;&nbsp; &nbsp;7.无论是 kafka 集群， 还是 producer 和 consumer 都依赖于 zookeeper 集群保存一些 meta 信息，来保证系统可用性 2.JMS 是什么&nbsp; &nbsp;&nbsp; &nbsp;JMS（JAVAMessage Service,java 消息服务）API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。 &nbsp;&nbsp; &nbsp;它使分布式通信耦合度更低，消息服务更加可靠以及异步性。 &nbsp;&nbsp; &nbsp;1.JMS 的基础 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMS 是什么：JMS 是 Java 提供的一套技术规范 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMS 干什么用：用来异构系统 集成通信，缓解系统瓶颈，提高系统的伸缩性增强系统用户体验，使得系统模块化和组件化变得可行并更加灵活 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;通过什么方式：生产消费者模式（生产者、服务器、消费者） &nbsp; &nbsp;&nbsp; &nbsp;2.JMS 消息传输模型 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;点对点模型通常是一个基于拉取或者轮询的消息传送模型，这种模型从队列中请求信息，而不是将消息推送到客户端。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，即使有多个消息监听者也是如此。  &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.发布/订阅模式（一对多，数据生产后，推送给所有订阅者） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;发布订阅模型则是一个基于推送的消息传送模型。&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;即使当前订阅者不可用，处于离线状态。 &nbsp;&nbsp; &nbsp;3.JMS 核心组件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.Destination：消息发送的目的地，也就是前面说的 队列(Queue) 或 Topic(主题)。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.Message：从字面上就可以看出是被发送的消息。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.Producer：消息的生产者，要发送一个消息，必须通过这个生产者来发送。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.MessageConsumer：与生产者相对应，这是消息的消费者或接收者，通过它来接收一个消息。 &nbsp;&nbsp; &nbsp;4.常见的类 JMS 消息服务器 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.JMS 消息服务器 ActiveMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ActiveMQ 是 Apache 出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1 和 J2EE 1.4 规范的。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;主要特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.多种语言和协议编写客户端。语言: Java, C, C++, C#, Ruby, Perl, Python, PHP。应用协议:OpenWire,Stomp REST,WS Notification,XMPP,AMQP &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.完全支持 JMS1.1 和 J2EE 1.4 规范 (持久化,XA 消息,事务) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.对 Spring 的支持,ActiveMQ 可以很容易内嵌到使用 Spring 的系统里面去,而且也支持Spring2.0 的特性 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.通过 常见 J2EE 服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试，其中通过 JCA1.5 resource adaptors 的配置， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;可以让 ActiveMQ 可以自动的部署到任何兼容 J2EE 1.4 商业服务器上 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;6.支持通过 JDBC 和 journal 提供高速的消息持久化 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;7.从设计上保证了高性能的集群,客户端-服务器,点对点 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;8.支持 Ajax &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;9.支持与 Axis 的整合 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;10.可以很容易得调用内嵌 JMS provider,进行测试 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.分布式消息中间件 Metamorphosis &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Metamorphosis (MetaQ) 是一个高性能、高可用、可扩展的分布式消息中间件，类似于 LinkedIn的 Kafka， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;具有消息存储顺序写、吞吐量大和支持本地和 XA 事务等特性，适用于大吞吐量、顺序消息、广播和日志数据传输等场景， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;在淘宝和支付宝有着广泛的应用，现已开源。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;主要特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;生产者、服务器和消费者都可分布 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;消息存储顺序写 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;性能极高,吞吐量大 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息顺序 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持本地和 XA 事务 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;客户端 pull，随机读,利用 sendfile 系统调用，zero-copy ,批量拉数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消费端事务 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息广播模式 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持异步发送消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持 http 协议 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息重试和 recover &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;数据迁移、扩容对用户透明 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;消费状态保存在客户端 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持同步和异步复制两种 HA &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持 group commit &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.分布式消息中间件 RocketMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;能够保证严格的消息顺序 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;提供丰富的消息拉取模式 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;高效的订阅者水平扩展能力 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;实时的消息订阅机制 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;亿级消息堆积能力 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Metaq3.0 版本改名，产品名称改为 RocketMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.其他 MQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;.NET 消息中间件 DotNetMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;基于 HBase 的消息队列 HQueue &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Go 的 MQ 框架 KiteQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AMQP 消息服务器 RabbitMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;MemcacheQ 是一个基于 MemcacheDB 的消息队列服务器。 3.为什么需要消息队列&nbsp; &nbsp;&nbsp; &nbsp;消息系统的核心作用就是三点：解耦、异步、并行 &nbsp;&nbsp; &nbsp;以用户注册的案列来说明消息系统的作用 &nbsp;&nbsp; &nbsp;1.用户注册的一般流程 &nbsp;&nbsp; &nbsp;2.用户注册的并行执行 &nbsp;&nbsp; &nbsp;3.用户注册的最终一致 4.Kafka 核心组件&nbsp; &nbsp;&nbsp; &nbsp;Topic(主题)：消息根据 Topic 进行归类 &nbsp;&nbsp; &nbsp;Producer：发送消息者 &nbsp;&nbsp; &nbsp;Consumer：消息接受者 &nbsp;&nbsp; &nbsp;broker(中间人)：kafka cluster(kafka群)中的 每个 kafka 实例(server) &nbsp;&nbsp; &nbsp;Zookeeper：依赖集群保存 meta 信息。 5.Kafka 集群部署&nbsp; &nbsp;&nbsp; &nbsp;1.集群部署的基本流程 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;下载安装包、解压安装包、修改配置文件、分发安装包、启动集群 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;2.集群部署的基础环境准备 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.安装前的准备工作（zk 集群已经部署完毕） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.关闭防火墙：chkconfig iptables off &amp;&amp; setenforce 0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.创建用户： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;groupadd 组名 &amp;&amp; useradd 用户名 &amp;&amp; usermod -a -G 组名 用户名 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;groupadd realtime &amp;&amp; useradd realtime &amp;&amp; usermod -a -G realtime realtime &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.创建工作目录并赋权 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mkdir /export &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mkdir /export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;chmod 755 -R /export &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.切换到 realtime 用户下：su realtime &nbsp;&nbsp; &nbsp;3.Kafka 集群部署 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.下载安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;下载地址：http://kafka.apache.org/downloads.html &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;在 linux 中使用 wget 命令下载安装包：wget http://mirrors.shuosc.org/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.解压安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;tar -zxvf kafka_2.11-1.0.0.tgz -C /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mv kafka_2.11-1.0.0 kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.修改配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cp /export/servers/kafka/config/server.properties /export/servers/kafka/config/server.properties.bak &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;vi /export/servers/kafka/config/server.properties &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;输入以下内容： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#broker 的全局唯一编号，不能重复 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来监听链接的端口，producer 或 consumer 将在此端口建立连接 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;port=9092 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#处理网络请求的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.network.threads=3 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来处理磁盘 IO 的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.io.threads=8 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#发送套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.send.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#接收套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.receive.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#请求套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.request.max.bytes=104857600 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#kafka 运行日志存放的路径 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.dirs=/export/servers/logs/kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#topic(主题) 在当前 broker(中间人) 上的分片个数 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.partitions=2 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来恢复和清理 data 下数据的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.recovery.threads.per.data.dir=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#segment 文件保留的最长时间，超时将被删除 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#滚动生成新的 segment 文件的最大时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.roll.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#日志文件中每个 segment 的大小，默认为 1G &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.segment.bytes=1073741824 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#周期性检查文件大小的时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.check.interval.ms=300000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#日志清理是否打开 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.cleaner.enable=true &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#broker 需要使用 zookeeper 保存 meta 数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connect=192.168.52.106:2181,192.168.52.107:2181,192.168.52.108:2181 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#zookeeper 链接超时时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connection.timeout.ms=6000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#partion buffer 中，消息的条数达到阈值，将触发 flush 到磁盘 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.flush.interval.messages=10000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#消息 buffer 的时间，达到阈值，将触发 flush 到磁盘 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.flush.interval.ms=3000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#删除 topic，需要 server.properties 中设置 delete.topic.enable=true，否则只是标记删除 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;delete.topic.enable=true &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#此处的 host.name 为本机 IP(重要)，如果不改，则客户端会抛出:Producer connection to localhost:9092 unsuccessful 错误! &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;host.name=kafka01 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.分发安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.scp -r /export/servers/kafka kafka02:/export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;然后分别在各机器上创建软连 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.scp -r /export/servers/kafka kafka03:/export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;然后分别在各机器上创建软连 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.再次修改配置文件（重要） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;依次修改各服务器上配置文件的的 broker.id，分别是 0,1,2 不得重复。&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 6.启动集群 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.依次在各节点上启动 kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;nohup /export/servers/kafka/bin/kafka-server-start.sh /export/servers/kafka/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.输出错误日志到黑洞 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;command &gt;/dev/null 2&gt;&amp;1 &amp; 6.Kafka 常用操作命令 &nbsp;&nbsp; &nbsp;1.查看当前服务器中的所有 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --list --zookeeper zk01:2181 &nbsp;&nbsp; &nbsp;2.创建 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --create --zookeeper zk01:2181 --replication-factor 1 --partitions 1 --topic test &nbsp;&nbsp; &nbsp;3.删除 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --delete --zookeeper zk01:2181 --topic test &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除或者直接重启。 &nbsp;&nbsp; &nbsp;4.通过 shell 命令发送消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-console-producer.sh --broker-list kafka01:9092 --topic test &nbsp;&nbsp; &nbsp;5.通过 shell 消费消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-console-consumer.sh --zookeeper zk01:2181 --from-beginning --topic test &nbsp;&nbsp; &nbsp;6.查看消费位置 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper zk01:2181 --group testGroup &nbsp;&nbsp; &nbsp;7.查看某个 Topic 的详情 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --topic test --describe --zookeeper zk01:2181 &nbsp;&nbsp; &nbsp;8.对分区数进行修改 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --zookeeper zk01 --alter --partitions 2 --topic test 7.Kafka JavaAPI &nbsp;&nbsp; &nbsp;1.Kafka 生产者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;version&gt;0.11.0.1&lt;/version&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;/dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public static void main(String[] args)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//1、准备配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Properties props = new Properties(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;bootstrap.servers&quot;, &quot;node01:9092&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;acks&quot;, &quot;all&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;retries&quot;, 0); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;batch.size&quot;, 16384); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;linger.ms&quot;, 1); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;buffer.memory&quot;, 33554432); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//2、创建 Kafka Producer 生产者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;String,String&gt;(props); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;for (int i=0;i&lt;100;i++) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//3、发送数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafkaProducer.send(new ProducerRecord&lt;String, String&gt;(&quot;test&quot;,&quot;num&quot;+i,&quot;value&quot;+i)); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;2.Kafka 消费者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;version&gt;0.11.0.1&lt;/version&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;/dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public static void main(String[] args)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 1、准备配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Properties props = new Properties(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;bootstrap.servers&quot;, &quot;node01:9092&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;group.id&quot;, &quot;test&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 2、创建 Kafka Consumer 消费者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;String, String&gt;(props); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 3、订阅数据，这里的 topic(主题) 可以是多个，可用List封装 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafkaConsumer.subscribe(Arrays.asList(&quot;test&quot;)); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 4、获取数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;while (true)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;System.out.printf(&quot;topic = %s,offset = %d, key = %s, value = %s%n&quot;,&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; record.topic(), record.offset(), record.key(), record.value()); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} 8.Kafka 整体结构图 &nbsp;&nbsp; &nbsp;1.Producer：消息生产者，就是向 kafka broker(中间人) 发消息的客户端&nbsp; &nbsp;&nbsp; &nbsp;2.Consumer：消息消费者，向 kafka broker(中间人) 取消息的客户端 &nbsp;&nbsp; &nbsp;3.Topic：主题 &nbsp;&nbsp; &nbsp;4.Consumer Group（CG）消费者组： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;这是 kafka 用来实现一个 topic(主题) 消息的广播（发给所有的 consumer消费者）和 单播（发给任意一个 consumer消费者）的手段。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;一个 topic(主题) 可以有多个 CG消费者组。topic(主题) 的消息会复制（不是真的复制，是概念上的）到所有的 CG消费者组， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;但每个 partion(分区) 只会把消息发给该 CG 中的一个consumer消费者。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;如果需要实现广播，只要每个 consumer消费者 有一个独立的 CG 就可以了。要实现单播只要所有的 consumer 在同一个 CG。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;用 CG消费者组 还可以将 consumer消费者 进行自由的分组，而不需要多次发送消息到不同的 topic(主题)。 &nbsp;&nbsp; &nbsp;5.Broker：一台 kafka 服务器就是一个 broker(中间人)。一个kafka集群(cluster) 由多个 broker(中间人) 组成。一个 broker 可以容纳多个 topic(主题)。 &nbsp;&nbsp; &nbsp;6.Partition(分区)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;为了实现扩展性，一个非常大的 topic(主题) 可以分布到多个 broker（即服务器）上，一个topic(主题) 可以分为多个 partition(分区)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 partition(分区) 是一个有序的队列(Queue)。partition(分区) 中的每条消息都会被分配一个有序的 id（offset）。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafka 只保证按一个 partition(分区) 中的顺序 将消息发给 consumer消费者，不保证一个 topic 的整体（多个 partition分区 间）的顺序 &nbsp;&nbsp; &nbsp;7.Offset： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是00000000000.kafka &nbsp;&nbsp; &nbsp;8.Replication(复制)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Kafka 支持以 Partition(分区) 为单位对 Message 进行冗余备份，每个 Partition(分区) 都可以配置至少 1 个 Replication(复制)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当仅只有 1 个 Replication(复制) 时 即仅该 Partition(分区) 本身。 &nbsp;&nbsp; &nbsp;9.Leader： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 Replication(复制) 集合中的 Partition(分区) 都会选出一个唯一的 Leader，所有的 读写请求 都由 Leader 处理。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;其他 Replicas(复数的复制品) 从 Leader 处把数据更新同步到本地，过程类似大家熟悉的 MySQL中的 Binlog 同步。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 Cluster(集群) 当中会选举出一个 Broker(中间人) 来担任 Controller，负责处理 Partition(分区) 的 Leader 选举，协调 Partition(分区) 迁移等工作。  &nbsp;&nbsp; &nbsp;10.ISR(In-Sync Replica)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;是 Replicas(复制品) 的一个子集，表示目前 Alive 且与 Leader 能够“Catch-up(追赶)”的 Replicas(复制品) 集合。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;由于读写都是首先落到 Leader 上，所以一般来说通过同步机制从 Leader 上拉取数据的 Replica(复制品) 都会和 Leader 有一些延迟 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该 Replica(复制品) 踢出 ISR。每个 Partition(分区) 都有它自己独立的 ISR。 9.Kafka 配置文件详解 10.Consumer消费者 与 topic主题 关系 &nbsp;&nbsp; &nbsp;1.本质上 kafka 只支持 Topic主题&nbsp; &nbsp;&nbsp; &nbsp;2.每个 group 中可以有多个 consumer消费者，每个 consumer消费者 属于一个 consumer group； &nbsp;&nbsp; &nbsp; &nbsp;通常情况下，一个 group 中会包含多个 consumer，这样不仅可以提高 topic主题 中消息的并发消费能力，而且还能提高&quot;故障容错&quot;性， &nbsp;&nbsp; &nbsp; &nbsp;如果 group 中的某个 consumer消费者 失效，那么其消费的 partitions分区 将会有其他 consumer 自动接管。 &nbsp;&nbsp; &nbsp;3.对于 Topic主题 中的一条特定的消息，只会被订阅此 Topic主题 的每个 group 中的其中一个 consumer消费者，此消息不会发送给一个 group 的多个 consumer； &nbsp;&nbsp; &nbsp; &nbsp;那么一个 group 中所有的 consumer消费者 将会交错的消费整个 Topic主题，每个 group 中 consumer 消息消费 互相独立，我们可以认为一个 group 是一个&quot;订阅&quot;者。 &nbsp;&nbsp; &nbsp;4.在 kafka 中，一个 partition分区 中的消息只会被 group 中的一个 consumer 消费(同一时刻)； &nbsp;&nbsp; &nbsp; &nbsp;一个 Topic主题 中的每个 partions分区，只会被一个&quot;订阅者&quot;中的一个 consumer 消费，不过一个 consumer 可以同时消费多个 partitions分区 中的消息。 &nbsp;&nbsp; &nbsp;5.kafka 的设计原理决定，对于一个 topic主题， 同一个 group 中不能有多于 partitions分区 个数的 consumer 同时消费，否则将意味着某些 consumer 将无法得到消息。 &nbsp;&nbsp; &nbsp;6.kafka 只能保证一个 partition分区 中的消息被某个 consumer 消费时是顺序的；事实上，从 Topic主题 角度来说，当有多个 partitions分区 时，消息仍不是全局有序的。 11.Kafka 消息的分发 &nbsp;&nbsp; &nbsp;1.Producer 客户端负责消息的分发 &nbsp;&nbsp; &nbsp;2.kafka 集群中的任何一个 broker中间者 都可以向 producer 提供 metadata 信息，这些 metadata 中包含&quot;集群中存活的 servers 列表&quot; / &quot;partitions分区 leader 列表&quot;等信息； &nbsp;&nbsp; &nbsp;3.当 producer 获取到 metadata 信息之后, producer 将会和 Topic 下所有 partition分区 leader 保持socket 连接； &nbsp;&nbsp; &nbsp;4.消息由 producer 直接通过 socket 发送到 broker中间者，中间不会经过任何&quot;路由层&quot;，事实上，消息被路由到哪个 partition分区 上由 producer 客户端决定； &nbsp;&nbsp; &nbsp; &nbsp;比如可以采用&quot;random&quot;、&quot;key-hash&quot;、&quot;轮询&quot;等，如果一个 topic主题 中有多个 partitions分区，那么在 producer 端实现&quot;消息均衡分发&quot;是必要的。 &nbsp;&nbsp; &nbsp;5.在 producer 端的配置文件中，开发者可以指定 partition 路由的方式。 &nbsp;&nbsp; &nbsp;6.Producer 消息发送的应答机制 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;设置发送数据是否需要服务端的反馈，有三个值 0、1、-1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;0：producer 不会等待 broker中间者 发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1：当 leader 接收到消息之后发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;-1：当所有的 follower 都同步消息成功后发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;request.required.acks=0 12.Consumer消费者 的负载均衡 &nbsp;&nbsp; &nbsp;当一个 group 中,有 consumer消费者 加入或者离开时，会触发 partitions分区 均衡。均衡的最终目的，是提升 topic主题 的并发消费能力，步骤如下： &nbsp;&nbsp; &nbsp;1.假如 topic主题 具有如下 partitions分区：P0、P1、P2、P3 &nbsp;&nbsp; &nbsp;2.加入 group 中，有如下 consumer消费者：C1、C2 &nbsp;&nbsp; &nbsp;3.首先根据 partition分区 索引号对 partitions分区 排序：P0、P1、P2、P3 &nbsp;&nbsp; &nbsp;4.根据 consumer.id 排序：C0、C1 &nbsp;&nbsp; &nbsp;5.计算倍数：M = [P0,P1,P2,P3].size / [C0,C1].size，本例值 M=2(向上取整) &nbsp;&nbsp; &nbsp;6.然后依次分配 partitions分区：C0 = [P0,P1]，C1 = [P2,P3]，即 Ci = [P(i * M),P((i + 1) * M -1)] 13.Kafka 文件存储机制 &nbsp;&nbsp;&nbsp;&nbsp;1.Kafka 文件存储基本结构 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.在Kafka文件存储中，同一个 topic主题 下有多个不同 partition分区， 每个 partition分区 为一个目录， partiton分区 命名规则为 topic主题名称 + 有序序号， &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一个 partiton分区 序号从 0 开始，序号最大值为 partitions分区 数量减 1。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.每个 partion分区(目录) 相当于一个巨型文件被平均分配到多个 大小相等 segment(段)数据文件中。&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但每个段 segment file 消息数量不一定相等，这种特性方便 old segment file 快速被删除。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认保留 7 天的数据。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.每个 partiton分区 只需要支持顺序读写就行了，segment 文件生命周期由服务端配置参数决定。（什么时候创建，什么时候删除） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：数据有序的讨论？一个 partition分区 的数据是否是有序的？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：间隔性有序，不连续针对一个 topic主题 里面的数据，只能做到 partition分区 内部有序，不能做到全局有序。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：特别加入消费者的场景后，如何保证消费者 消费的数据 全局有序的？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：伪命题。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：只有一种情况下才能保证全局有序？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：就是只有一个 partition。 14.Kafka Partition Segment &nbsp;&nbsp;&nbsp;&nbsp;1.Segment file 组成： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由 2 大部分组成，分别为 index file 和 data file，此 2 个文件一一对应，成对出现，后缀&quot;.index&quot;和“.log”分别表示为 segment 索引文件、数据文件。 &nbsp;&nbsp;&nbsp;&nbsp;2.Segment 文件命名规则：&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partion分区 全局的第一个 segment 从 0 开始， 后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。 &nbsp;&nbsp;&nbsp;&nbsp;3.索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下述图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton 表示第 368772 个 message)、以及该消息的物理偏移地址为 497。 &nbsp;&nbsp;&nbsp;&nbsp;4.segment data file 由许多 message 组成，物理结构如下： 15.Kafka 查找 message &nbsp;&nbsp; &nbsp;1.读取 offset=368776 的 message，需要通过下面 2 个步骤查找。 &nbsp;&nbsp; &nbsp;2.查找 segment file &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000000000.index 表示最开始的文件，起始偏移量(offset)为 0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000368769.index 的消息量起始偏移量为 368770 = 368769 + 1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000737337.index 的起始偏移量为 737338 = 737337 + 1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;其他后续文件依次类推。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;以起始偏移量命名并排序这些文件，只要根据 offset **二分查找**文件列表，就可以快速定位到具体文件。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当 offset = 368776 时定位到 00000000000000368769.index 和对应 log 文件。 &nbsp;&nbsp; &nbsp;3.通过 segment file 查找 message &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当 offset=368776 时，依次定位到 00000000000000368769.index 的元数据物理位置 和 00000000000000368769.log 的物理偏移地址， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;然后再通过 00000000000000368769.log 顺序查找直到 offset=368776 为止。 16.Kafka 自定义 Partition &nbsp;&nbsp; &nbsp;如果指定 partition，就用 partition &nbsp;&nbsp; &nbsp;如果指定 key，使用 key 进行 hash 取模。 &nbsp;&nbsp; &nbsp;如果没有指定 key，使用轮询的方式。 &nbsp;&nbsp; &nbsp;public class DefaultPartitioner implements Partitioner&nbsp; &nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;private final ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = new ConcurrentHashMap&lt;&gt;(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public void configure(Map&lt;String, ?&gt; configs) {} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;/** &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* 计算给定记录的分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param topic 主题名称 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param key 分区上的键（或如果没有键，则为空） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param keyBytes 序列化的分区键（或如果没有键，则为空） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param value 分区或无效的值 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param valueBytes 分区 序列化值 或 无效&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param cluster 当前集群 元数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int numPartitions = partitions.size(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (keyBytes == null)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int nextValue = nextValue(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (availablePartitions.size() &gt; 0)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int part = Utils.toPositive(nextValue) % availablePartitions.size(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return availablePartitions.get(part).partition(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;else&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 没有分区可用，给出非可用分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return Utils.toPositive(nextValue) % numPartitions; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;else&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 散列键值以选择分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;private int nextValue(String topic)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AtomicInteger counter = topicCounterMap.get(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (null == counter)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;counter = new AtomicInteger(ThreadLocalRandom.current().nextInt()); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (currentCounter != null)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;counter = currentCounter; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return counter.getAndIncrement(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public void close() {} &nbsp;&nbsp; &nbsp;} 17.Kafka 为什么那么快 &nbsp;&nbsp; &nbsp;1.Broker中间者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.不同于 Redis 和 MemcacheQ 等内存消息队列，Kafka 的设计是把所有的 Message 都要写入速度低容量大的硬盘，以此来换取更强的存储能力。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.实际上，Kafka 使用硬盘并没有带来过多的性能损失，“规规矩矩”的抄了一条“近道”。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;首先，说“规规矩矩”是因为 Kafka 在磁盘上只做 Sequence顺序 I/O，由于消息系统读写的特殊性，这并不存在什么问题。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;关于磁盘 I/O 的性能，引用一组 Kafka 官方给出的测试数据(Raid-5，7200rpm)：Sequence I/O: 600MB/s、Random I/O: 100KB/s。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;所以通过只做 Sequence顺序 I/O 的限制，规避了磁盘访问速度低下对性能可能造成的影响。 &nbsp;&nbsp; &nbsp;2.接下来我们再聊一聊 Kafka 是如何“抄近道的”。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.首先，Kafka 重度依赖底层操作系统提供的 Page Cache页面缓存 功能。当上层有写操作时，操作系统只是将数据写入 Page Cache页面缓存， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同时标记 Page页面 属性为 Dirty脏的。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.当读操作发生时，先从 Page Cache页面缓存 中查找，如果发生 缺页才进行磁盘调度，最终返回需要的数据。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;实际上 Page Cache页面缓存 是把尽可能多的空闲内存 都当做了磁盘缓存来使用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同时如果有其他进程申请内存，回收 Page Cache页面缓存 的代价又很小，所以现代的 OS 都支持 Page Cache页面缓存。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.使用 Page Cache页面缓存 功能同时可以避免在 JVM 内部缓存数据，JVM 为我们提供了强大的 GC(垃圾回收机制) 能力，同时也引入了一些问题不适用与 Kafka 的设计。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;如果在 Heap堆 内管理缓存，JVM 的 GC(垃圾回收机制) 线程会频繁扫描 Heap堆 空间，带来不必要的开销。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;如果 Heap堆过大，执行一次 Full GC 对系统的可用性来说将是极大的挑战。所有在 JVM 内的对象都不免带有一个 Object Overhead(对象开销)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;内存的有效空间利用率会因此降低。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.所有的 In-Process Cache进程内缓存 在 OS 中都有一份同样的 Page Cache页面缓存。 所以通过将缓存只放在 Page Cache页面缓存， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;可以至少让可用缓存空间翻倍。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.如果 Kafka 重启，所有的 In-Process Cache进程内缓存 都会失效，而 OS 管理的 Page Cache页面缓存 依然可以继续使用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;Page Cache页面缓存 还只是第一步，Kafka 为了进一步的优化性能还采用了 Sendfile 技术。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;在解释 Sendfile 之前，首先介绍一下传统的网络 I/O 操作流程，大体上分为以下 4 步。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.OS 从硬盘 把数据读到 内核区的 Page Cache页面缓存。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.用户进程 把 数据 从 内核区 Copy 到 用户区。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.然后 用户进程 再把 数据 写入到 Socket，数据 流入 内核区的 Socket Buffer 上。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.OS 再把 数据从 Buffer 中 Copy 到 网卡的 Buffer 上，这样完成一次发送。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;整个过程共经历两次 Context Switch上下文切换，四次 System Call系统调用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同一份数据在内核 Buffer 与用户 Buffer 之间重复拷贝，效率低下。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;其中 2、3 两步没有必要，完全可以直接在内核区完成数据拷贝。这也正是 Sendfile 所解决的问题，经过 Sendfile 优化后，整个 I/O 过程就变成了下面这个样子。 &nbsp; 18.Kafka 最佳实践 19.Kafka 监控工具&nbsp; &nbsp;&nbsp; &nbsp;1.Kafka Web Console：监控功能较为全面，可以预览消息，监控 Offset、Lag 等信息，但存在 bug，不建议在生产环境中使用。 &nbsp;&nbsp; &nbsp;2.Kafka Manager：偏向 Kafka 集群管理，若操作不当，容易导致集群出现故障。对 Kafka 实时生产和消费消息是通过 JMX 实现的。没有记录 Offset、Lag 等信息。 &nbsp;&nbsp; &nbsp;3.KafkaOffsetMonitor：程序一个 jar 包的形式运行，部署较为方便。只有监控功能，使用起来也较为安全。 &nbsp;&nbsp; &nbsp;4.若只需要监控功能，推荐使用 KafkaOffsetMonito，若偏重 Kafka 集群管理，推荐使用 KafkaManager。 &nbsp;&nbsp; &nbsp; &nbsp;因为都是开源程序，稳定性欠缺。 20.配置一键启动脚本" />
<meta property="og:description" content="大数据组件使用 总文章 &nbsp; 1.Apache Kafka&nbsp; &nbsp;&nbsp; &nbsp;1.Apache Kafka 是一个开源消息系统，由 Scala 写成。是由 Apache 软件基金会开发的一个开源消息系统项目。 &nbsp;&nbsp; &nbsp;2.Kafka 最初是由 LinkedIn 开发，并于 2011 年初开源。2012 年 10 月从 Apache Incubator 毕业。 &nbsp;&nbsp; &nbsp; &nbsp;该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。 &nbsp;&nbsp; &nbsp;3.Kafka 是一个分布式消息队列(Queue)：生产者、消费者的功能。它提供了类似于 JMS 的特性，但是在设计实现上完全不同，此外它并不是 JMS 规范的实现。 &nbsp;&nbsp; &nbsp;4.Kafka 对消息保存时根据 Topic(主题) 进行归类 &nbsp;&nbsp; &nbsp;5.发送消息者称为 Producer，消息接受者称为 Consumer &nbsp;&nbsp; &nbsp;6.此外 kafka 集群有多个 kafka 实例组成，每个实例(server)成为 broker。 &nbsp;&nbsp; &nbsp;7.无论是 kafka 集群， 还是 producer 和 consumer 都依赖于 zookeeper 集群保存一些 meta 信息，来保证系统可用性 2.JMS 是什么&nbsp; &nbsp;&nbsp; &nbsp;JMS（JAVAMessage Service,java 消息服务）API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。 &nbsp;&nbsp; &nbsp;它使分布式通信耦合度更低，消息服务更加可靠以及异步性。 &nbsp;&nbsp; &nbsp;1.JMS 的基础 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMS 是什么：JMS 是 Java 提供的一套技术规范 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMS 干什么用：用来异构系统 集成通信，缓解系统瓶颈，提高系统的伸缩性增强系统用户体验，使得系统模块化和组件化变得可行并更加灵活 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;通过什么方式：生产消费者模式（生产者、服务器、消费者） &nbsp; &nbsp;&nbsp; &nbsp;2.JMS 消息传输模型 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;点对点模型通常是一个基于拉取或者轮询的消息传送模型，这种模型从队列中请求信息，而不是将消息推送到客户端。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，即使有多个消息监听者也是如此。  &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.发布/订阅模式（一对多，数据生产后，推送给所有订阅者） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;发布订阅模型则是一个基于推送的消息传送模型。&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;即使当前订阅者不可用，处于离线状态。 &nbsp;&nbsp; &nbsp;3.JMS 核心组件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.Destination：消息发送的目的地，也就是前面说的 队列(Queue) 或 Topic(主题)。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.Message：从字面上就可以看出是被发送的消息。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.Producer：消息的生产者，要发送一个消息，必须通过这个生产者来发送。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.MessageConsumer：与生产者相对应，这是消息的消费者或接收者，通过它来接收一个消息。 &nbsp;&nbsp; &nbsp;4.常见的类 JMS 消息服务器 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.JMS 消息服务器 ActiveMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ActiveMQ 是 Apache 出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1 和 J2EE 1.4 规范的。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;主要特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.多种语言和协议编写客户端。语言: Java, C, C++, C#, Ruby, Perl, Python, PHP。应用协议:OpenWire,Stomp REST,WS Notification,XMPP,AMQP &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.完全支持 JMS1.1 和 J2EE 1.4 规范 (持久化,XA 消息,事务) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.对 Spring 的支持,ActiveMQ 可以很容易内嵌到使用 Spring 的系统里面去,而且也支持Spring2.0 的特性 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.通过 常见 J2EE 服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试，其中通过 JCA1.5 resource adaptors 的配置， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;可以让 ActiveMQ 可以自动的部署到任何兼容 J2EE 1.4 商业服务器上 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;6.支持通过 JDBC 和 journal 提供高速的消息持久化 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;7.从设计上保证了高性能的集群,客户端-服务器,点对点 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;8.支持 Ajax &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;9.支持与 Axis 的整合 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;10.可以很容易得调用内嵌 JMS provider,进行测试 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.分布式消息中间件 Metamorphosis &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Metamorphosis (MetaQ) 是一个高性能、高可用、可扩展的分布式消息中间件，类似于 LinkedIn的 Kafka， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;具有消息存储顺序写、吞吐量大和支持本地和 XA 事务等特性，适用于大吞吐量、顺序消息、广播和日志数据传输等场景， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;在淘宝和支付宝有着广泛的应用，现已开源。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;主要特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;生产者、服务器和消费者都可分布 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;消息存储顺序写 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;性能极高,吞吐量大 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息顺序 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持本地和 XA 事务 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;客户端 pull，随机读,利用 sendfile 系统调用，zero-copy ,批量拉数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消费端事务 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息广播模式 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持异步发送消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持 http 协议 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息重试和 recover &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;数据迁移、扩容对用户透明 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;消费状态保存在客户端 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持同步和异步复制两种 HA &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持 group commit &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.分布式消息中间件 RocketMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;能够保证严格的消息顺序 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;提供丰富的消息拉取模式 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;高效的订阅者水平扩展能力 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;实时的消息订阅机制 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;亿级消息堆积能力 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Metaq3.0 版本改名，产品名称改为 RocketMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.其他 MQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;.NET 消息中间件 DotNetMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;基于 HBase 的消息队列 HQueue &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Go 的 MQ 框架 KiteQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AMQP 消息服务器 RabbitMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;MemcacheQ 是一个基于 MemcacheDB 的消息队列服务器。 3.为什么需要消息队列&nbsp; &nbsp;&nbsp; &nbsp;消息系统的核心作用就是三点：解耦、异步、并行 &nbsp;&nbsp; &nbsp;以用户注册的案列来说明消息系统的作用 &nbsp;&nbsp; &nbsp;1.用户注册的一般流程 &nbsp;&nbsp; &nbsp;2.用户注册的并行执行 &nbsp;&nbsp; &nbsp;3.用户注册的最终一致 4.Kafka 核心组件&nbsp; &nbsp;&nbsp; &nbsp;Topic(主题)：消息根据 Topic 进行归类 &nbsp;&nbsp; &nbsp;Producer：发送消息者 &nbsp;&nbsp; &nbsp;Consumer：消息接受者 &nbsp;&nbsp; &nbsp;broker(中间人)：kafka cluster(kafka群)中的 每个 kafka 实例(server) &nbsp;&nbsp; &nbsp;Zookeeper：依赖集群保存 meta 信息。 5.Kafka 集群部署&nbsp; &nbsp;&nbsp; &nbsp;1.集群部署的基本流程 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;下载安装包、解压安装包、修改配置文件、分发安装包、启动集群 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;2.集群部署的基础环境准备 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.安装前的准备工作（zk 集群已经部署完毕） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.关闭防火墙：chkconfig iptables off &amp;&amp; setenforce 0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.创建用户： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;groupadd 组名 &amp;&amp; useradd 用户名 &amp;&amp; usermod -a -G 组名 用户名 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;groupadd realtime &amp;&amp; useradd realtime &amp;&amp; usermod -a -G realtime realtime &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.创建工作目录并赋权 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mkdir /export &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mkdir /export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;chmod 755 -R /export &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.切换到 realtime 用户下：su realtime &nbsp;&nbsp; &nbsp;3.Kafka 集群部署 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.下载安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;下载地址：http://kafka.apache.org/downloads.html &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;在 linux 中使用 wget 命令下载安装包：wget http://mirrors.shuosc.org/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.解压安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;tar -zxvf kafka_2.11-1.0.0.tgz -C /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mv kafka_2.11-1.0.0 kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.修改配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cp /export/servers/kafka/config/server.properties /export/servers/kafka/config/server.properties.bak &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;vi /export/servers/kafka/config/server.properties &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;输入以下内容： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#broker 的全局唯一编号，不能重复 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来监听链接的端口，producer 或 consumer 将在此端口建立连接 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;port=9092 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#处理网络请求的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.network.threads=3 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来处理磁盘 IO 的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.io.threads=8 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#发送套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.send.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#接收套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.receive.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#请求套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.request.max.bytes=104857600 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#kafka 运行日志存放的路径 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.dirs=/export/servers/logs/kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#topic(主题) 在当前 broker(中间人) 上的分片个数 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.partitions=2 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来恢复和清理 data 下数据的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.recovery.threads.per.data.dir=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#segment 文件保留的最长时间，超时将被删除 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#滚动生成新的 segment 文件的最大时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.roll.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#日志文件中每个 segment 的大小，默认为 1G &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.segment.bytes=1073741824 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#周期性检查文件大小的时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.check.interval.ms=300000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#日志清理是否打开 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.cleaner.enable=true &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#broker 需要使用 zookeeper 保存 meta 数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connect=192.168.52.106:2181,192.168.52.107:2181,192.168.52.108:2181 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#zookeeper 链接超时时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connection.timeout.ms=6000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#partion buffer 中，消息的条数达到阈值，将触发 flush 到磁盘 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.flush.interval.messages=10000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#消息 buffer 的时间，达到阈值，将触发 flush 到磁盘 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.flush.interval.ms=3000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#删除 topic，需要 server.properties 中设置 delete.topic.enable=true，否则只是标记删除 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;delete.topic.enable=true &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#此处的 host.name 为本机 IP(重要)，如果不改，则客户端会抛出:Producer connection to localhost:9092 unsuccessful 错误! &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;host.name=kafka01 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.分发安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.scp -r /export/servers/kafka kafka02:/export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;然后分别在各机器上创建软连 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.scp -r /export/servers/kafka kafka03:/export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;然后分别在各机器上创建软连 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.再次修改配置文件（重要） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;依次修改各服务器上配置文件的的 broker.id，分别是 0,1,2 不得重复。&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 6.启动集群 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.依次在各节点上启动 kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;nohup /export/servers/kafka/bin/kafka-server-start.sh /export/servers/kafka/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.输出错误日志到黑洞 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;command &gt;/dev/null 2&gt;&amp;1 &amp; 6.Kafka 常用操作命令 &nbsp;&nbsp; &nbsp;1.查看当前服务器中的所有 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --list --zookeeper zk01:2181 &nbsp;&nbsp; &nbsp;2.创建 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --create --zookeeper zk01:2181 --replication-factor 1 --partitions 1 --topic test &nbsp;&nbsp; &nbsp;3.删除 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --delete --zookeeper zk01:2181 --topic test &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除或者直接重启。 &nbsp;&nbsp; &nbsp;4.通过 shell 命令发送消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-console-producer.sh --broker-list kafka01:9092 --topic test &nbsp;&nbsp; &nbsp;5.通过 shell 消费消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-console-consumer.sh --zookeeper zk01:2181 --from-beginning --topic test &nbsp;&nbsp; &nbsp;6.查看消费位置 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper zk01:2181 --group testGroup &nbsp;&nbsp; &nbsp;7.查看某个 Topic 的详情 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --topic test --describe --zookeeper zk01:2181 &nbsp;&nbsp; &nbsp;8.对分区数进行修改 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --zookeeper zk01 --alter --partitions 2 --topic test 7.Kafka JavaAPI &nbsp;&nbsp; &nbsp;1.Kafka 生产者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;version&gt;0.11.0.1&lt;/version&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;/dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public static void main(String[] args)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//1、准备配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Properties props = new Properties(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;bootstrap.servers&quot;, &quot;node01:9092&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;acks&quot;, &quot;all&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;retries&quot;, 0); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;batch.size&quot;, 16384); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;linger.ms&quot;, 1); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;buffer.memory&quot;, 33554432); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//2、创建 Kafka Producer 生产者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;String,String&gt;(props); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;for (int i=0;i&lt;100;i++) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//3、发送数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafkaProducer.send(new ProducerRecord&lt;String, String&gt;(&quot;test&quot;,&quot;num&quot;+i,&quot;value&quot;+i)); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;2.Kafka 消费者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;version&gt;0.11.0.1&lt;/version&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;/dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public static void main(String[] args)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 1、准备配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Properties props = new Properties(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;bootstrap.servers&quot;, &quot;node01:9092&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;group.id&quot;, &quot;test&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 2、创建 Kafka Consumer 消费者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;String, String&gt;(props); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 3、订阅数据，这里的 topic(主题) 可以是多个，可用List封装 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafkaConsumer.subscribe(Arrays.asList(&quot;test&quot;)); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 4、获取数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;while (true)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;System.out.printf(&quot;topic = %s,offset = %d, key = %s, value = %s%n&quot;,&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; record.topic(), record.offset(), record.key(), record.value()); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} 8.Kafka 整体结构图 &nbsp;&nbsp; &nbsp;1.Producer：消息生产者，就是向 kafka broker(中间人) 发消息的客户端&nbsp; &nbsp;&nbsp; &nbsp;2.Consumer：消息消费者，向 kafka broker(中间人) 取消息的客户端 &nbsp;&nbsp; &nbsp;3.Topic：主题 &nbsp;&nbsp; &nbsp;4.Consumer Group（CG）消费者组： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;这是 kafka 用来实现一个 topic(主题) 消息的广播（发给所有的 consumer消费者）和 单播（发给任意一个 consumer消费者）的手段。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;一个 topic(主题) 可以有多个 CG消费者组。topic(主题) 的消息会复制（不是真的复制，是概念上的）到所有的 CG消费者组， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;但每个 partion(分区) 只会把消息发给该 CG 中的一个consumer消费者。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;如果需要实现广播，只要每个 consumer消费者 有一个独立的 CG 就可以了。要实现单播只要所有的 consumer 在同一个 CG。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;用 CG消费者组 还可以将 consumer消费者 进行自由的分组，而不需要多次发送消息到不同的 topic(主题)。 &nbsp;&nbsp; &nbsp;5.Broker：一台 kafka 服务器就是一个 broker(中间人)。一个kafka集群(cluster) 由多个 broker(中间人) 组成。一个 broker 可以容纳多个 topic(主题)。 &nbsp;&nbsp; &nbsp;6.Partition(分区)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;为了实现扩展性，一个非常大的 topic(主题) 可以分布到多个 broker（即服务器）上，一个topic(主题) 可以分为多个 partition(分区)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 partition(分区) 是一个有序的队列(Queue)。partition(分区) 中的每条消息都会被分配一个有序的 id（offset）。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafka 只保证按一个 partition(分区) 中的顺序 将消息发给 consumer消费者，不保证一个 topic 的整体（多个 partition分区 间）的顺序 &nbsp;&nbsp; &nbsp;7.Offset： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是00000000000.kafka &nbsp;&nbsp; &nbsp;8.Replication(复制)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Kafka 支持以 Partition(分区) 为单位对 Message 进行冗余备份，每个 Partition(分区) 都可以配置至少 1 个 Replication(复制)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当仅只有 1 个 Replication(复制) 时 即仅该 Partition(分区) 本身。 &nbsp;&nbsp; &nbsp;9.Leader： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 Replication(复制) 集合中的 Partition(分区) 都会选出一个唯一的 Leader，所有的 读写请求 都由 Leader 处理。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;其他 Replicas(复数的复制品) 从 Leader 处把数据更新同步到本地，过程类似大家熟悉的 MySQL中的 Binlog 同步。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 Cluster(集群) 当中会选举出一个 Broker(中间人) 来担任 Controller，负责处理 Partition(分区) 的 Leader 选举，协调 Partition(分区) 迁移等工作。  &nbsp;&nbsp; &nbsp;10.ISR(In-Sync Replica)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;是 Replicas(复制品) 的一个子集，表示目前 Alive 且与 Leader 能够“Catch-up(追赶)”的 Replicas(复制品) 集合。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;由于读写都是首先落到 Leader 上，所以一般来说通过同步机制从 Leader 上拉取数据的 Replica(复制品) 都会和 Leader 有一些延迟 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该 Replica(复制品) 踢出 ISR。每个 Partition(分区) 都有它自己独立的 ISR。 9.Kafka 配置文件详解 10.Consumer消费者 与 topic主题 关系 &nbsp;&nbsp; &nbsp;1.本质上 kafka 只支持 Topic主题&nbsp; &nbsp;&nbsp; &nbsp;2.每个 group 中可以有多个 consumer消费者，每个 consumer消费者 属于一个 consumer group； &nbsp;&nbsp; &nbsp; &nbsp;通常情况下，一个 group 中会包含多个 consumer，这样不仅可以提高 topic主题 中消息的并发消费能力，而且还能提高&quot;故障容错&quot;性， &nbsp;&nbsp; &nbsp; &nbsp;如果 group 中的某个 consumer消费者 失效，那么其消费的 partitions分区 将会有其他 consumer 自动接管。 &nbsp;&nbsp; &nbsp;3.对于 Topic主题 中的一条特定的消息，只会被订阅此 Topic主题 的每个 group 中的其中一个 consumer消费者，此消息不会发送给一个 group 的多个 consumer； &nbsp;&nbsp; &nbsp; &nbsp;那么一个 group 中所有的 consumer消费者 将会交错的消费整个 Topic主题，每个 group 中 consumer 消息消费 互相独立，我们可以认为一个 group 是一个&quot;订阅&quot;者。 &nbsp;&nbsp; &nbsp;4.在 kafka 中，一个 partition分区 中的消息只会被 group 中的一个 consumer 消费(同一时刻)； &nbsp;&nbsp; &nbsp; &nbsp;一个 Topic主题 中的每个 partions分区，只会被一个&quot;订阅者&quot;中的一个 consumer 消费，不过一个 consumer 可以同时消费多个 partitions分区 中的消息。 &nbsp;&nbsp; &nbsp;5.kafka 的设计原理决定，对于一个 topic主题， 同一个 group 中不能有多于 partitions分区 个数的 consumer 同时消费，否则将意味着某些 consumer 将无法得到消息。 &nbsp;&nbsp; &nbsp;6.kafka 只能保证一个 partition分区 中的消息被某个 consumer 消费时是顺序的；事实上，从 Topic主题 角度来说，当有多个 partitions分区 时，消息仍不是全局有序的。 11.Kafka 消息的分发 &nbsp;&nbsp; &nbsp;1.Producer 客户端负责消息的分发 &nbsp;&nbsp; &nbsp;2.kafka 集群中的任何一个 broker中间者 都可以向 producer 提供 metadata 信息，这些 metadata 中包含&quot;集群中存活的 servers 列表&quot; / &quot;partitions分区 leader 列表&quot;等信息； &nbsp;&nbsp; &nbsp;3.当 producer 获取到 metadata 信息之后, producer 将会和 Topic 下所有 partition分区 leader 保持socket 连接； &nbsp;&nbsp; &nbsp;4.消息由 producer 直接通过 socket 发送到 broker中间者，中间不会经过任何&quot;路由层&quot;，事实上，消息被路由到哪个 partition分区 上由 producer 客户端决定； &nbsp;&nbsp; &nbsp; &nbsp;比如可以采用&quot;random&quot;、&quot;key-hash&quot;、&quot;轮询&quot;等，如果一个 topic主题 中有多个 partitions分区，那么在 producer 端实现&quot;消息均衡分发&quot;是必要的。 &nbsp;&nbsp; &nbsp;5.在 producer 端的配置文件中，开发者可以指定 partition 路由的方式。 &nbsp;&nbsp; &nbsp;6.Producer 消息发送的应答机制 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;设置发送数据是否需要服务端的反馈，有三个值 0、1、-1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;0：producer 不会等待 broker中间者 发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1：当 leader 接收到消息之后发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;-1：当所有的 follower 都同步消息成功后发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;request.required.acks=0 12.Consumer消费者 的负载均衡 &nbsp;&nbsp; &nbsp;当一个 group 中,有 consumer消费者 加入或者离开时，会触发 partitions分区 均衡。均衡的最终目的，是提升 topic主题 的并发消费能力，步骤如下： &nbsp;&nbsp; &nbsp;1.假如 topic主题 具有如下 partitions分区：P0、P1、P2、P3 &nbsp;&nbsp; &nbsp;2.加入 group 中，有如下 consumer消费者：C1、C2 &nbsp;&nbsp; &nbsp;3.首先根据 partition分区 索引号对 partitions分区 排序：P0、P1、P2、P3 &nbsp;&nbsp; &nbsp;4.根据 consumer.id 排序：C0、C1 &nbsp;&nbsp; &nbsp;5.计算倍数：M = [P0,P1,P2,P3].size / [C0,C1].size，本例值 M=2(向上取整) &nbsp;&nbsp; &nbsp;6.然后依次分配 partitions分区：C0 = [P0,P1]，C1 = [P2,P3]，即 Ci = [P(i * M),P((i + 1) * M -1)] 13.Kafka 文件存储机制 &nbsp;&nbsp;&nbsp;&nbsp;1.Kafka 文件存储基本结构 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.在Kafka文件存储中，同一个 topic主题 下有多个不同 partition分区， 每个 partition分区 为一个目录， partiton分区 命名规则为 topic主题名称 + 有序序号， &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一个 partiton分区 序号从 0 开始，序号最大值为 partitions分区 数量减 1。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.每个 partion分区(目录) 相当于一个巨型文件被平均分配到多个 大小相等 segment(段)数据文件中。&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但每个段 segment file 消息数量不一定相等，这种特性方便 old segment file 快速被删除。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认保留 7 天的数据。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.每个 partiton分区 只需要支持顺序读写就行了，segment 文件生命周期由服务端配置参数决定。（什么时候创建，什么时候删除） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：数据有序的讨论？一个 partition分区 的数据是否是有序的？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：间隔性有序，不连续针对一个 topic主题 里面的数据，只能做到 partition分区 内部有序，不能做到全局有序。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：特别加入消费者的场景后，如何保证消费者 消费的数据 全局有序的？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：伪命题。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：只有一种情况下才能保证全局有序？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：就是只有一个 partition。 14.Kafka Partition Segment &nbsp;&nbsp;&nbsp;&nbsp;1.Segment file 组成： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由 2 大部分组成，分别为 index file 和 data file，此 2 个文件一一对应，成对出现，后缀&quot;.index&quot;和“.log”分别表示为 segment 索引文件、数据文件。 &nbsp;&nbsp;&nbsp;&nbsp;2.Segment 文件命名规则：&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partion分区 全局的第一个 segment 从 0 开始， 后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。 &nbsp;&nbsp;&nbsp;&nbsp;3.索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下述图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton 表示第 368772 个 message)、以及该消息的物理偏移地址为 497。 &nbsp;&nbsp;&nbsp;&nbsp;4.segment data file 由许多 message 组成，物理结构如下： 15.Kafka 查找 message &nbsp;&nbsp; &nbsp;1.读取 offset=368776 的 message，需要通过下面 2 个步骤查找。 &nbsp;&nbsp; &nbsp;2.查找 segment file &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000000000.index 表示最开始的文件，起始偏移量(offset)为 0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000368769.index 的消息量起始偏移量为 368770 = 368769 + 1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000737337.index 的起始偏移量为 737338 = 737337 + 1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;其他后续文件依次类推。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;以起始偏移量命名并排序这些文件，只要根据 offset **二分查找**文件列表，就可以快速定位到具体文件。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当 offset = 368776 时定位到 00000000000000368769.index 和对应 log 文件。 &nbsp;&nbsp; &nbsp;3.通过 segment file 查找 message &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当 offset=368776 时，依次定位到 00000000000000368769.index 的元数据物理位置 和 00000000000000368769.log 的物理偏移地址， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;然后再通过 00000000000000368769.log 顺序查找直到 offset=368776 为止。 16.Kafka 自定义 Partition &nbsp;&nbsp; &nbsp;如果指定 partition，就用 partition &nbsp;&nbsp; &nbsp;如果指定 key，使用 key 进行 hash 取模。 &nbsp;&nbsp; &nbsp;如果没有指定 key，使用轮询的方式。 &nbsp;&nbsp; &nbsp;public class DefaultPartitioner implements Partitioner&nbsp; &nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;private final ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = new ConcurrentHashMap&lt;&gt;(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public void configure(Map&lt;String, ?&gt; configs) {} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;/** &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* 计算给定记录的分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param topic 主题名称 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param key 分区上的键（或如果没有键，则为空） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param keyBytes 序列化的分区键（或如果没有键，则为空） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param value 分区或无效的值 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param valueBytes 分区 序列化值 或 无效&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param cluster 当前集群 元数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int numPartitions = partitions.size(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (keyBytes == null)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int nextValue = nextValue(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (availablePartitions.size() &gt; 0)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int part = Utils.toPositive(nextValue) % availablePartitions.size(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return availablePartitions.get(part).partition(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;else&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 没有分区可用，给出非可用分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return Utils.toPositive(nextValue) % numPartitions; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;else&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 散列键值以选择分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;private int nextValue(String topic)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AtomicInteger counter = topicCounterMap.get(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (null == counter)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;counter = new AtomicInteger(ThreadLocalRandom.current().nextInt()); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (currentCounter != null)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;counter = currentCounter; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return counter.getAndIncrement(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public void close() {} &nbsp;&nbsp; &nbsp;} 17.Kafka 为什么那么快 &nbsp;&nbsp; &nbsp;1.Broker中间者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.不同于 Redis 和 MemcacheQ 等内存消息队列，Kafka 的设计是把所有的 Message 都要写入速度低容量大的硬盘，以此来换取更强的存储能力。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.实际上，Kafka 使用硬盘并没有带来过多的性能损失，“规规矩矩”的抄了一条“近道”。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;首先，说“规规矩矩”是因为 Kafka 在磁盘上只做 Sequence顺序 I/O，由于消息系统读写的特殊性，这并不存在什么问题。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;关于磁盘 I/O 的性能，引用一组 Kafka 官方给出的测试数据(Raid-5，7200rpm)：Sequence I/O: 600MB/s、Random I/O: 100KB/s。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;所以通过只做 Sequence顺序 I/O 的限制，规避了磁盘访问速度低下对性能可能造成的影响。 &nbsp;&nbsp; &nbsp;2.接下来我们再聊一聊 Kafka 是如何“抄近道的”。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.首先，Kafka 重度依赖底层操作系统提供的 Page Cache页面缓存 功能。当上层有写操作时，操作系统只是将数据写入 Page Cache页面缓存， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同时标记 Page页面 属性为 Dirty脏的。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.当读操作发生时，先从 Page Cache页面缓存 中查找，如果发生 缺页才进行磁盘调度，最终返回需要的数据。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;实际上 Page Cache页面缓存 是把尽可能多的空闲内存 都当做了磁盘缓存来使用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同时如果有其他进程申请内存，回收 Page Cache页面缓存 的代价又很小，所以现代的 OS 都支持 Page Cache页面缓存。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.使用 Page Cache页面缓存 功能同时可以避免在 JVM 内部缓存数据，JVM 为我们提供了强大的 GC(垃圾回收机制) 能力，同时也引入了一些问题不适用与 Kafka 的设计。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;如果在 Heap堆 内管理缓存，JVM 的 GC(垃圾回收机制) 线程会频繁扫描 Heap堆 空间，带来不必要的开销。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;如果 Heap堆过大，执行一次 Full GC 对系统的可用性来说将是极大的挑战。所有在 JVM 内的对象都不免带有一个 Object Overhead(对象开销)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;内存的有效空间利用率会因此降低。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.所有的 In-Process Cache进程内缓存 在 OS 中都有一份同样的 Page Cache页面缓存。 所以通过将缓存只放在 Page Cache页面缓存， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;可以至少让可用缓存空间翻倍。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.如果 Kafka 重启，所有的 In-Process Cache进程内缓存 都会失效，而 OS 管理的 Page Cache页面缓存 依然可以继续使用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;Page Cache页面缓存 还只是第一步，Kafka 为了进一步的优化性能还采用了 Sendfile 技术。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;在解释 Sendfile 之前，首先介绍一下传统的网络 I/O 操作流程，大体上分为以下 4 步。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.OS 从硬盘 把数据读到 内核区的 Page Cache页面缓存。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.用户进程 把 数据 从 内核区 Copy 到 用户区。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.然后 用户进程 再把 数据 写入到 Socket，数据 流入 内核区的 Socket Buffer 上。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.OS 再把 数据从 Buffer 中 Copy 到 网卡的 Buffer 上，这样完成一次发送。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;整个过程共经历两次 Context Switch上下文切换，四次 System Call系统调用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同一份数据在内核 Buffer 与用户 Buffer 之间重复拷贝，效率低下。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;其中 2、3 两步没有必要，完全可以直接在内核区完成数据拷贝。这也正是 Sendfile 所解决的问题，经过 Sendfile 优化后，整个 I/O 过程就变成了下面这个样子。 &nbsp; 18.Kafka 最佳实践 19.Kafka 监控工具&nbsp; &nbsp;&nbsp; &nbsp;1.Kafka Web Console：监控功能较为全面，可以预览消息，监控 Offset、Lag 等信息，但存在 bug，不建议在生产环境中使用。 &nbsp;&nbsp; &nbsp;2.Kafka Manager：偏向 Kafka 集群管理，若操作不当，容易导致集群出现故障。对 Kafka 实时生产和消费消息是通过 JMX 实现的。没有记录 Offset、Lag 等信息。 &nbsp;&nbsp; &nbsp;3.KafkaOffsetMonitor：程序一个 jar 包的形式运行，部署较为方便。只有监控功能，使用起来也较为安全。 &nbsp;&nbsp; &nbsp;4.若只需要监控功能，推荐使用 KafkaOffsetMonito，若偏重 Kafka 集群管理，推荐使用 KafkaManager。 &nbsp;&nbsp; &nbsp; &nbsp;因为都是开源程序，稳定性欠缺。 20.配置一键启动脚本" />
<link rel="canonical" href="https://mlh.app/2019/05/04/729861.html" />
<meta property="og:url" content="https://mlh.app/2019/05/04/729861.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-04T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"大数据组件使用 总文章 &nbsp; 1.Apache Kafka&nbsp; &nbsp;&nbsp; &nbsp;1.Apache Kafka 是一个开源消息系统，由 Scala 写成。是由 Apache 软件基金会开发的一个开源消息系统项目。 &nbsp;&nbsp; &nbsp;2.Kafka 最初是由 LinkedIn 开发，并于 2011 年初开源。2012 年 10 月从 Apache Incubator 毕业。 &nbsp;&nbsp; &nbsp; &nbsp;该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。 &nbsp;&nbsp; &nbsp;3.Kafka 是一个分布式消息队列(Queue)：生产者、消费者的功能。它提供了类似于 JMS 的特性，但是在设计实现上完全不同，此外它并不是 JMS 规范的实现。 &nbsp;&nbsp; &nbsp;4.Kafka 对消息保存时根据 Topic(主题) 进行归类 &nbsp;&nbsp; &nbsp;5.发送消息者称为 Producer，消息接受者称为 Consumer &nbsp;&nbsp; &nbsp;6.此外 kafka 集群有多个 kafka 实例组成，每个实例(server)成为 broker。 &nbsp;&nbsp; &nbsp;7.无论是 kafka 集群， 还是 producer 和 consumer 都依赖于 zookeeper 集群保存一些 meta 信息，来保证系统可用性 2.JMS 是什么&nbsp; &nbsp;&nbsp; &nbsp;JMS（JAVAMessage Service,java 消息服务）API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。 &nbsp;&nbsp; &nbsp;它使分布式通信耦合度更低，消息服务更加可靠以及异步性。 &nbsp;&nbsp; &nbsp;1.JMS 的基础 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMS 是什么：JMS 是 Java 提供的一套技术规范 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMS 干什么用：用来异构系统 集成通信，缓解系统瓶颈，提高系统的伸缩性增强系统用户体验，使得系统模块化和组件化变得可行并更加灵活 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;通过什么方式：生产消费者模式（生产者、服务器、消费者） &nbsp; &nbsp;&nbsp; &nbsp;2.JMS 消息传输模型 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;点对点模型通常是一个基于拉取或者轮询的消息传送模型，这种模型从队列中请求信息，而不是将消息推送到客户端。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，即使有多个消息监听者也是如此。  &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.发布/订阅模式（一对多，数据生产后，推送给所有订阅者） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;发布订阅模型则是一个基于推送的消息传送模型。&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;即使当前订阅者不可用，处于离线状态。 &nbsp;&nbsp; &nbsp;3.JMS 核心组件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.Destination：消息发送的目的地，也就是前面说的 队列(Queue) 或 Topic(主题)。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.Message：从字面上就可以看出是被发送的消息。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.Producer：消息的生产者，要发送一个消息，必须通过这个生产者来发送。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.MessageConsumer：与生产者相对应，这是消息的消费者或接收者，通过它来接收一个消息。 &nbsp;&nbsp; &nbsp;4.常见的类 JMS 消息服务器 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.JMS 消息服务器 ActiveMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ActiveMQ 是 Apache 出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1 和 J2EE 1.4 规范的。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;主要特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.多种语言和协议编写客户端。语言: Java, C, C++, C#, Ruby, Perl, Python, PHP。应用协议:OpenWire,Stomp REST,WS Notification,XMPP,AMQP &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.完全支持 JMS1.1 和 J2EE 1.4 规范 (持久化,XA 消息,事务) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.对 Spring 的支持,ActiveMQ 可以很容易内嵌到使用 Spring 的系统里面去,而且也支持Spring2.0 的特性 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.通过 常见 J2EE 服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试，其中通过 JCA1.5 resource adaptors 的配置， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;可以让 ActiveMQ 可以自动的部署到任何兼容 J2EE 1.4 商业服务器上 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;6.支持通过 JDBC 和 journal 提供高速的消息持久化 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;7.从设计上保证了高性能的集群,客户端-服务器,点对点 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;8.支持 Ajax &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;9.支持与 Axis 的整合 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;10.可以很容易得调用内嵌 JMS provider,进行测试 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.分布式消息中间件 Metamorphosis &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Metamorphosis (MetaQ) 是一个高性能、高可用、可扩展的分布式消息中间件，类似于 LinkedIn的 Kafka， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;具有消息存储顺序写、吞吐量大和支持本地和 XA 事务等特性，适用于大吞吐量、顺序消息、广播和日志数据传输等场景， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;在淘宝和支付宝有着广泛的应用，现已开源。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;主要特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;生产者、服务器和消费者都可分布 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;消息存储顺序写 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;性能极高,吞吐量大 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息顺序 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持本地和 XA 事务 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;客户端 pull，随机读,利用 sendfile 系统调用，zero-copy ,批量拉数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消费端事务 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息广播模式 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持异步发送消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持 http 协议 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息重试和 recover &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;数据迁移、扩容对用户透明 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;消费状态保存在客户端 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持同步和异步复制两种 HA &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持 group commit &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.分布式消息中间件 RocketMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;能够保证严格的消息顺序 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;提供丰富的消息拉取模式 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;高效的订阅者水平扩展能力 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;实时的消息订阅机制 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;亿级消息堆积能力 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Metaq3.0 版本改名，产品名称改为 RocketMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.其他 MQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;.NET 消息中间件 DotNetMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;基于 HBase 的消息队列 HQueue &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Go 的 MQ 框架 KiteQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AMQP 消息服务器 RabbitMQ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;MemcacheQ 是一个基于 MemcacheDB 的消息队列服务器。 3.为什么需要消息队列&nbsp; &nbsp;&nbsp; &nbsp;消息系统的核心作用就是三点：解耦、异步、并行 &nbsp;&nbsp; &nbsp;以用户注册的案列来说明消息系统的作用 &nbsp;&nbsp; &nbsp;1.用户注册的一般流程 &nbsp;&nbsp; &nbsp;2.用户注册的并行执行 &nbsp;&nbsp; &nbsp;3.用户注册的最终一致 4.Kafka 核心组件&nbsp; &nbsp;&nbsp; &nbsp;Topic(主题)：消息根据 Topic 进行归类 &nbsp;&nbsp; &nbsp;Producer：发送消息者 &nbsp;&nbsp; &nbsp;Consumer：消息接受者 &nbsp;&nbsp; &nbsp;broker(中间人)：kafka cluster(kafka群)中的 每个 kafka 实例(server) &nbsp;&nbsp; &nbsp;Zookeeper：依赖集群保存 meta 信息。 5.Kafka 集群部署&nbsp; &nbsp;&nbsp; &nbsp;1.集群部署的基本流程 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;下载安装包、解压安装包、修改配置文件、分发安装包、启动集群 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;2.集群部署的基础环境准备 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.安装前的准备工作（zk 集群已经部署完毕） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.关闭防火墙：chkconfig iptables off &amp;&amp; setenforce 0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.创建用户： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;groupadd 组名 &amp;&amp; useradd 用户名 &amp;&amp; usermod -a -G 组名 用户名 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;groupadd realtime &amp;&amp; useradd realtime &amp;&amp; usermod -a -G realtime realtime &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.创建工作目录并赋权 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mkdir /export &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mkdir /export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;chmod 755 -R /export &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.切换到 realtime 用户下：su realtime &nbsp;&nbsp; &nbsp;3.Kafka 集群部署 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.下载安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;下载地址：http://kafka.apache.org/downloads.html &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;在 linux 中使用 wget 命令下载安装包：wget http://mirrors.shuosc.org/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.解压安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;tar -zxvf kafka_2.11-1.0.0.tgz -C /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mv kafka_2.11-1.0.0 kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.修改配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cp /export/servers/kafka/config/server.properties /export/servers/kafka/config/server.properties.bak &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;vi /export/servers/kafka/config/server.properties &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;输入以下内容： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#broker 的全局唯一编号，不能重复 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来监听链接的端口，producer 或 consumer 将在此端口建立连接 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;port=9092 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#处理网络请求的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.network.threads=3 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来处理磁盘 IO 的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.io.threads=8 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#发送套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.send.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#接收套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.receive.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#请求套接字的缓冲区大小 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.request.max.bytes=104857600 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#kafka 运行日志存放的路径 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.dirs=/export/servers/logs/kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#topic(主题) 在当前 broker(中间人) 上的分片个数 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.partitions=2 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来恢复和清理 data 下数据的线程数量 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.recovery.threads.per.data.dir=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#segment 文件保留的最长时间，超时将被删除 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#滚动生成新的 segment 文件的最大时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.roll.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#日志文件中每个 segment 的大小，默认为 1G &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.segment.bytes=1073741824 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#周期性检查文件大小的时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.check.interval.ms=300000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#日志清理是否打开 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.cleaner.enable=true &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#broker 需要使用 zookeeper 保存 meta 数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connect=192.168.52.106:2181,192.168.52.107:2181,192.168.52.108:2181 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#zookeeper 链接超时时间 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connection.timeout.ms=6000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#partion buffer 中，消息的条数达到阈值，将触发 flush 到磁盘 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.flush.interval.messages=10000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#消息 buffer 的时间，达到阈值，将触发 flush 到磁盘 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.flush.interval.ms=3000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#删除 topic，需要 server.properties 中设置 delete.topic.enable=true，否则只是标记删除 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;delete.topic.enable=true &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#此处的 host.name 为本机 IP(重要)，如果不改，则客户端会抛出:Producer connection to localhost:9092 unsuccessful 错误! &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;host.name=kafka01 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.分发安装包 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.scp -r /export/servers/kafka kafka02:/export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;然后分别在各机器上创建软连 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.scp -r /export/servers/kafka kafka03:/export/servers &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;然后分别在各机器上创建软连 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;cd /export/servers/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.再次修改配置文件（重要） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;依次修改各服务器上配置文件的的 broker.id，分别是 0,1,2 不得重复。&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 6.启动集群 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.依次在各节点上启动 kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;nohup /export/servers/kafka/bin/kafka-server-start.sh /export/servers/kafka/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.输出错误日志到黑洞 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;command &gt;/dev/null 2&gt;&amp;1 &amp; 6.Kafka 常用操作命令 &nbsp;&nbsp; &nbsp;1.查看当前服务器中的所有 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --list --zookeeper zk01:2181 &nbsp;&nbsp; &nbsp;2.创建 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --create --zookeeper zk01:2181 --replication-factor 1 --partitions 1 --topic test &nbsp;&nbsp; &nbsp;3.删除 topic &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --delete --zookeeper zk01:2181 --topic test &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除或者直接重启。 &nbsp;&nbsp; &nbsp;4.通过 shell 命令发送消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-console-producer.sh --broker-list kafka01:9092 --topic test &nbsp;&nbsp; &nbsp;5.通过 shell 消费消息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-console-consumer.sh --zookeeper zk01:2181 --from-beginning --topic test &nbsp;&nbsp; &nbsp;6.查看消费位置 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper zk01:2181 --group testGroup &nbsp;&nbsp; &nbsp;7.查看某个 Topic 的详情 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --topic test --describe --zookeeper zk01:2181 &nbsp;&nbsp; &nbsp;8.对分区数进行修改 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --zookeeper zk01 --alter --partitions 2 --topic test 7.Kafka JavaAPI &nbsp;&nbsp; &nbsp;1.Kafka 生产者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;version&gt;0.11.0.1&lt;/version&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;/dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public static void main(String[] args)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//1、准备配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Properties props = new Properties(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;bootstrap.servers&quot;, &quot;node01:9092&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;acks&quot;, &quot;all&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;retries&quot;, 0); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;batch.size&quot;, 16384); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;linger.ms&quot;, 1); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;buffer.memory&quot;, 33554432); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//2、创建 Kafka Producer 生产者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;String,String&gt;(props); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;for (int i=0;i&lt;100;i++) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//3、发送数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafkaProducer.send(new ProducerRecord&lt;String, String&gt;(&quot;test&quot;,&quot;num&quot;+i,&quot;value&quot;+i)); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;2.Kafka 消费者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;version&gt;0.11.0.1&lt;/version&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;/dependency&gt; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public static void main(String[] args)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 1、准备配置文件 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Properties props = new Properties(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;bootstrap.servers&quot;, &quot;node01:9092&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;group.id&quot;, &quot;test&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 2、创建 Kafka Consumer 消费者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;String, String&gt;(props); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 3、订阅数据，这里的 topic(主题) 可以是多个，可用List封装 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafkaConsumer.subscribe(Arrays.asList(&quot;test&quot;)); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 4、获取数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;while (true)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;System.out.printf(&quot;topic = %s,offset = %d, key = %s, value = %s%n&quot;,&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; record.topic(), record.offset(), record.key(), record.value()); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} 8.Kafka 整体结构图 &nbsp;&nbsp; &nbsp;1.Producer：消息生产者，就是向 kafka broker(中间人) 发消息的客户端&nbsp; &nbsp;&nbsp; &nbsp;2.Consumer：消息消费者，向 kafka broker(中间人) 取消息的客户端 &nbsp;&nbsp; &nbsp;3.Topic：主题 &nbsp;&nbsp; &nbsp;4.Consumer Group（CG）消费者组： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;这是 kafka 用来实现一个 topic(主题) 消息的广播（发给所有的 consumer消费者）和 单播（发给任意一个 consumer消费者）的手段。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;一个 topic(主题) 可以有多个 CG消费者组。topic(主题) 的消息会复制（不是真的复制，是概念上的）到所有的 CG消费者组， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;但每个 partion(分区) 只会把消息发给该 CG 中的一个consumer消费者。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;如果需要实现广播，只要每个 consumer消费者 有一个独立的 CG 就可以了。要实现单播只要所有的 consumer 在同一个 CG。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;用 CG消费者组 还可以将 consumer消费者 进行自由的分组，而不需要多次发送消息到不同的 topic(主题)。 &nbsp;&nbsp; &nbsp;5.Broker：一台 kafka 服务器就是一个 broker(中间人)。一个kafka集群(cluster) 由多个 broker(中间人) 组成。一个 broker 可以容纳多个 topic(主题)。 &nbsp;&nbsp; &nbsp;6.Partition(分区)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;为了实现扩展性，一个非常大的 topic(主题) 可以分布到多个 broker（即服务器）上，一个topic(主题) 可以分为多个 partition(分区)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 partition(分区) 是一个有序的队列(Queue)。partition(分区) 中的每条消息都会被分配一个有序的 id（offset）。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafka 只保证按一个 partition(分区) 中的顺序 将消息发给 consumer消费者，不保证一个 topic 的整体（多个 partition分区 间）的顺序 &nbsp;&nbsp; &nbsp;7.Offset： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是00000000000.kafka &nbsp;&nbsp; &nbsp;8.Replication(复制)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Kafka 支持以 Partition(分区) 为单位对 Message 进行冗余备份，每个 Partition(分区) 都可以配置至少 1 个 Replication(复制)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当仅只有 1 个 Replication(复制) 时 即仅该 Partition(分区) 本身。 &nbsp;&nbsp; &nbsp;9.Leader： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 Replication(复制) 集合中的 Partition(分区) 都会选出一个唯一的 Leader，所有的 读写请求 都由 Leader 处理。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;其他 Replicas(复数的复制品) 从 Leader 处把数据更新同步到本地，过程类似大家熟悉的 MySQL中的 Binlog 同步。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 Cluster(集群) 当中会选举出一个 Broker(中间人) 来担任 Controller，负责处理 Partition(分区) 的 Leader 选举，协调 Partition(分区) 迁移等工作。  &nbsp;&nbsp; &nbsp;10.ISR(In-Sync Replica)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;是 Replicas(复制品) 的一个子集，表示目前 Alive 且与 Leader 能够“Catch-up(追赶)”的 Replicas(复制品) 集合。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;由于读写都是首先落到 Leader 上，所以一般来说通过同步机制从 Leader 上拉取数据的 Replica(复制品) 都会和 Leader 有一些延迟 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该 Replica(复制品) 踢出 ISR。每个 Partition(分区) 都有它自己独立的 ISR。 9.Kafka 配置文件详解 10.Consumer消费者 与 topic主题 关系 &nbsp;&nbsp; &nbsp;1.本质上 kafka 只支持 Topic主题&nbsp; &nbsp;&nbsp; &nbsp;2.每个 group 中可以有多个 consumer消费者，每个 consumer消费者 属于一个 consumer group； &nbsp;&nbsp; &nbsp; &nbsp;通常情况下，一个 group 中会包含多个 consumer，这样不仅可以提高 topic主题 中消息的并发消费能力，而且还能提高&quot;故障容错&quot;性， &nbsp;&nbsp; &nbsp; &nbsp;如果 group 中的某个 consumer消费者 失效，那么其消费的 partitions分区 将会有其他 consumer 自动接管。 &nbsp;&nbsp; &nbsp;3.对于 Topic主题 中的一条特定的消息，只会被订阅此 Topic主题 的每个 group 中的其中一个 consumer消费者，此消息不会发送给一个 group 的多个 consumer； &nbsp;&nbsp; &nbsp; &nbsp;那么一个 group 中所有的 consumer消费者 将会交错的消费整个 Topic主题，每个 group 中 consumer 消息消费 互相独立，我们可以认为一个 group 是一个&quot;订阅&quot;者。 &nbsp;&nbsp; &nbsp;4.在 kafka 中，一个 partition分区 中的消息只会被 group 中的一个 consumer 消费(同一时刻)； &nbsp;&nbsp; &nbsp; &nbsp;一个 Topic主题 中的每个 partions分区，只会被一个&quot;订阅者&quot;中的一个 consumer 消费，不过一个 consumer 可以同时消费多个 partitions分区 中的消息。 &nbsp;&nbsp; &nbsp;5.kafka 的设计原理决定，对于一个 topic主题， 同一个 group 中不能有多于 partitions分区 个数的 consumer 同时消费，否则将意味着某些 consumer 将无法得到消息。 &nbsp;&nbsp; &nbsp;6.kafka 只能保证一个 partition分区 中的消息被某个 consumer 消费时是顺序的；事实上，从 Topic主题 角度来说，当有多个 partitions分区 时，消息仍不是全局有序的。 11.Kafka 消息的分发 &nbsp;&nbsp; &nbsp;1.Producer 客户端负责消息的分发 &nbsp;&nbsp; &nbsp;2.kafka 集群中的任何一个 broker中间者 都可以向 producer 提供 metadata 信息，这些 metadata 中包含&quot;集群中存活的 servers 列表&quot; / &quot;partitions分区 leader 列表&quot;等信息； &nbsp;&nbsp; &nbsp;3.当 producer 获取到 metadata 信息之后, producer 将会和 Topic 下所有 partition分区 leader 保持socket 连接； &nbsp;&nbsp; &nbsp;4.消息由 producer 直接通过 socket 发送到 broker中间者，中间不会经过任何&quot;路由层&quot;，事实上，消息被路由到哪个 partition分区 上由 producer 客户端决定； &nbsp;&nbsp; &nbsp; &nbsp;比如可以采用&quot;random&quot;、&quot;key-hash&quot;、&quot;轮询&quot;等，如果一个 topic主题 中有多个 partitions分区，那么在 producer 端实现&quot;消息均衡分发&quot;是必要的。 &nbsp;&nbsp; &nbsp;5.在 producer 端的配置文件中，开发者可以指定 partition 路由的方式。 &nbsp;&nbsp; &nbsp;6.Producer 消息发送的应答机制 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;设置发送数据是否需要服务端的反馈，有三个值 0、1、-1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;0：producer 不会等待 broker中间者 发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1：当 leader 接收到消息之后发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;-1：当所有的 follower 都同步消息成功后发送 ack(命令正确应答) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;request.required.acks=0 12.Consumer消费者 的负载均衡 &nbsp;&nbsp; &nbsp;当一个 group 中,有 consumer消费者 加入或者离开时，会触发 partitions分区 均衡。均衡的最终目的，是提升 topic主题 的并发消费能力，步骤如下： &nbsp;&nbsp; &nbsp;1.假如 topic主题 具有如下 partitions分区：P0、P1、P2、P3 &nbsp;&nbsp; &nbsp;2.加入 group 中，有如下 consumer消费者：C1、C2 &nbsp;&nbsp; &nbsp;3.首先根据 partition分区 索引号对 partitions分区 排序：P0、P1、P2、P3 &nbsp;&nbsp; &nbsp;4.根据 consumer.id 排序：C0、C1 &nbsp;&nbsp; &nbsp;5.计算倍数：M = [P0,P1,P2,P3].size / [C0,C1].size，本例值 M=2(向上取整) &nbsp;&nbsp; &nbsp;6.然后依次分配 partitions分区：C0 = [P0,P1]，C1 = [P2,P3]，即 Ci = [P(i * M),P((i + 1) * M -1)] 13.Kafka 文件存储机制 &nbsp;&nbsp;&nbsp;&nbsp;1.Kafka 文件存储基本结构 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.在Kafka文件存储中，同一个 topic主题 下有多个不同 partition分区， 每个 partition分区 为一个目录， partiton分区 命名规则为 topic主题名称 + 有序序号， &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一个 partiton分区 序号从 0 开始，序号最大值为 partitions分区 数量减 1。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.每个 partion分区(目录) 相当于一个巨型文件被平均分配到多个 大小相等 segment(段)数据文件中。&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但每个段 segment file 消息数量不一定相等，这种特性方便 old segment file 快速被删除。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认保留 7 天的数据。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.每个 partiton分区 只需要支持顺序读写就行了，segment 文件生命周期由服务端配置参数决定。（什么时候创建，什么时候删除） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：数据有序的讨论？一个 partition分区 的数据是否是有序的？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：间隔性有序，不连续针对一个 topic主题 里面的数据，只能做到 partition分区 内部有序，不能做到全局有序。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：特别加入消费者的场景后，如何保证消费者 消费的数据 全局有序的？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：伪命题。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：只有一种情况下才能保证全局有序？ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：就是只有一个 partition。 14.Kafka Partition Segment &nbsp;&nbsp;&nbsp;&nbsp;1.Segment file 组成： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由 2 大部分组成，分别为 index file 和 data file，此 2 个文件一一对应，成对出现，后缀&quot;.index&quot;和“.log”分别表示为 segment 索引文件、数据文件。 &nbsp;&nbsp;&nbsp;&nbsp;2.Segment 文件命名规则：&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partion分区 全局的第一个 segment 从 0 开始， 后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。 &nbsp;&nbsp;&nbsp;&nbsp;3.索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下述图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton 表示第 368772 个 message)、以及该消息的物理偏移地址为 497。 &nbsp;&nbsp;&nbsp;&nbsp;4.segment data file 由许多 message 组成，物理结构如下： 15.Kafka 查找 message &nbsp;&nbsp; &nbsp;1.读取 offset=368776 的 message，需要通过下面 2 个步骤查找。 &nbsp;&nbsp; &nbsp;2.查找 segment file &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000000000.index 表示最开始的文件，起始偏移量(offset)为 0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000368769.index 的消息量起始偏移量为 368770 = 368769 + 1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000737337.index 的起始偏移量为 737338 = 737337 + 1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;其他后续文件依次类推。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;以起始偏移量命名并排序这些文件，只要根据 offset **二分查找**文件列表，就可以快速定位到具体文件。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当 offset = 368776 时定位到 00000000000000368769.index 和对应 log 文件。 &nbsp;&nbsp; &nbsp;3.通过 segment file 查找 message &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当 offset=368776 时，依次定位到 00000000000000368769.index 的元数据物理位置 和 00000000000000368769.log 的物理偏移地址， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;然后再通过 00000000000000368769.log 顺序查找直到 offset=368776 为止。 16.Kafka 自定义 Partition &nbsp;&nbsp; &nbsp;如果指定 partition，就用 partition &nbsp;&nbsp; &nbsp;如果指定 key，使用 key 进行 hash 取模。 &nbsp;&nbsp; &nbsp;如果没有指定 key，使用轮询的方式。 &nbsp;&nbsp; &nbsp;public class DefaultPartitioner implements Partitioner&nbsp; &nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;private final ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = new ConcurrentHashMap&lt;&gt;(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public void configure(Map&lt;String, ?&gt; configs) {} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;/** &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* 计算给定记录的分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param topic 主题名称 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param key 分区上的键（或如果没有键，则为空） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param keyBytes 序列化的分区键（或如果没有键，则为空） &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param value 分区或无效的值 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param valueBytes 分区 序列化值 或 无效&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param cluster 当前集群 元数据 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*/ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int numPartitions = partitions.size(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (keyBytes == null)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int nextValue = nextValue(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (availablePartitions.size() &gt; 0)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int part = Utils.toPositive(nextValue) % availablePartitions.size(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return availablePartitions.get(part).partition(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;else&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 没有分区可用，给出非可用分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return Utils.toPositive(nextValue) % numPartitions; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;else&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 散列键值以选择分区 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;private int nextValue(String topic)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AtomicInteger counter = topicCounterMap.get(topic); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (null == counter)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;counter = new AtomicInteger(ThreadLocalRandom.current().nextInt()); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (currentCounter != null)&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;counter = currentCounter; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return counter.getAndIncrement(); &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;} &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public void close() {} &nbsp;&nbsp; &nbsp;} 17.Kafka 为什么那么快 &nbsp;&nbsp; &nbsp;1.Broker中间者 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.不同于 Redis 和 MemcacheQ 等内存消息队列，Kafka 的设计是把所有的 Message 都要写入速度低容量大的硬盘，以此来换取更强的存储能力。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.实际上，Kafka 使用硬盘并没有带来过多的性能损失，“规规矩矩”的抄了一条“近道”。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;首先，说“规规矩矩”是因为 Kafka 在磁盘上只做 Sequence顺序 I/O，由于消息系统读写的特殊性，这并不存在什么问题。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;关于磁盘 I/O 的性能，引用一组 Kafka 官方给出的测试数据(Raid-5，7200rpm)：Sequence I/O: 600MB/s、Random I/O: 100KB/s。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;所以通过只做 Sequence顺序 I/O 的限制，规避了磁盘访问速度低下对性能可能造成的影响。 &nbsp;&nbsp; &nbsp;2.接下来我们再聊一聊 Kafka 是如何“抄近道的”。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.首先，Kafka 重度依赖底层操作系统提供的 Page Cache页面缓存 功能。当上层有写操作时，操作系统只是将数据写入 Page Cache页面缓存， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同时标记 Page页面 属性为 Dirty脏的。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.当读操作发生时，先从 Page Cache页面缓存 中查找，如果发生 缺页才进行磁盘调度，最终返回需要的数据。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;实际上 Page Cache页面缓存 是把尽可能多的空闲内存 都当做了磁盘缓存来使用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同时如果有其他进程申请内存，回收 Page Cache页面缓存 的代价又很小，所以现代的 OS 都支持 Page Cache页面缓存。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.使用 Page Cache页面缓存 功能同时可以避免在 JVM 内部缓存数据，JVM 为我们提供了强大的 GC(垃圾回收机制) 能力，同时也引入了一些问题不适用与 Kafka 的设计。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;如果在 Heap堆 内管理缓存，JVM 的 GC(垃圾回收机制) 线程会频繁扫描 Heap堆 空间，带来不必要的开销。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;如果 Heap堆过大，执行一次 Full GC 对系统的可用性来说将是极大的挑战。所有在 JVM 内的对象都不免带有一个 Object Overhead(对象开销)， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;内存的有效空间利用率会因此降低。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.所有的 In-Process Cache进程内缓存 在 OS 中都有一份同样的 Page Cache页面缓存。 所以通过将缓存只放在 Page Cache页面缓存， &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;可以至少让可用缓存空间翻倍。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.如果 Kafka 重启，所有的 In-Process Cache进程内缓存 都会失效，而 OS 管理的 Page Cache页面缓存 依然可以继续使用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;Page Cache页面缓存 还只是第一步，Kafka 为了进一步的优化性能还采用了 Sendfile 技术。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;在解释 Sendfile 之前，首先介绍一下传统的网络 I/O 操作流程，大体上分为以下 4 步。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.OS 从硬盘 把数据读到 内核区的 Page Cache页面缓存。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.用户进程 把 数据 从 内核区 Copy 到 用户区。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.然后 用户进程 再把 数据 写入到 Socket，数据 流入 内核区的 Socket Buffer 上。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.OS 再把 数据从 Buffer 中 Copy 到 网卡的 Buffer 上，这样完成一次发送。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;整个过程共经历两次 Context Switch上下文切换，四次 System Call系统调用。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同一份数据在内核 Buffer 与用户 Buffer 之间重复拷贝，效率低下。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;其中 2、3 两步没有必要，完全可以直接在内核区完成数据拷贝。这也正是 Sendfile 所解决的问题，经过 Sendfile 优化后，整个 I/O 过程就变成了下面这个样子。 &nbsp; 18.Kafka 最佳实践 19.Kafka 监控工具&nbsp; &nbsp;&nbsp; &nbsp;1.Kafka Web Console：监控功能较为全面，可以预览消息，监控 Offset、Lag 等信息，但存在 bug，不建议在生产环境中使用。 &nbsp;&nbsp; &nbsp;2.Kafka Manager：偏向 Kafka 集群管理，若操作不当，容易导致集群出现故障。对 Kafka 实时生产和消费消息是通过 JMX 实现的。没有记录 Offset、Lag 等信息。 &nbsp;&nbsp; &nbsp;3.KafkaOffsetMonitor：程序一个 jar 包的形式运行，部署较为方便。只有监控功能，使用起来也较为安全。 &nbsp;&nbsp; &nbsp;4.若只需要监控功能，推荐使用 KafkaOffsetMonito，若偏重 Kafka 集群管理，推荐使用 KafkaManager。 &nbsp;&nbsp; &nbsp; &nbsp;因为都是开源程序，稳定性欠缺。 20.配置一键启动脚本","@type":"BlogPosting","url":"https://mlh.app/2019/05/04/729861.html","headline":"Kafka 安装、原理、使用","dateModified":"2019-05-04T00:00:00+08:00","datePublished":"2019-05-04T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/04/729861.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>Kafka 安装、原理、使用</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h1><u><strong><a href="https://blog.csdn.net/zimiao552147572/article/details/88602959" rel="nofollow">大数据组件使用 总文章</a></strong></u></h1> 
  <p>&nbsp;</p> 
  <p>1.Apache Kafka&nbsp;</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.Apache Kafka 是一个开源消息系统，由 Scala 写成。是由 Apache 软件基金会开发的一个开源消息系统项目。
&nbsp;&nbsp; &nbsp;2.Kafka 最初是由 LinkedIn 开发，并于 2011 年初开源。2012 年 10 月从 Apache Incubator 毕业。
&nbsp;&nbsp; &nbsp; &nbsp;该项目的目标是为处理实时数据提供一个统一、高通量、低等待的平台。
&nbsp;&nbsp; &nbsp;3.Kafka 是一个分布式消息队列(Queue)：生产者、消费者的功能。它提供了类似于 JMS 的特性，但是在设计实现上完全不同，此外它并不是 JMS 规范的实现。
&nbsp;&nbsp; &nbsp;4.Kafka 对消息保存时根据 Topic(主题) 进行归类
&nbsp;&nbsp; &nbsp;5.发送消息者称为 Producer，消息接受者称为 Consumer
&nbsp;&nbsp; &nbsp;6.此外 kafka 集群有多个 kafka 实例组成，每个实例(server)成为 broker。
&nbsp;&nbsp; &nbsp;7.无论是 kafka 集群， 还是 producer 和 consumer 都依赖于 zookeeper 集群保存一些 meta 信息，来保证系统可用性</code></pre> 
  <p><img alt="" class="has" height="271" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215550480.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="940"><br> 2.JMS 是什么&nbsp;</p> 
  <p>&nbsp;&nbsp; &nbsp;JMS（JAVAMessage Service,java 消息服务）API 是一个消息服务的标准或者说是规范，允许应用程序组件基于 JavaEE 平台创建、发送、接收和读取消息。<br> &nbsp;&nbsp; &nbsp;它使分布式通信耦合度更低，消息服务更加可靠以及异步性。</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.JMS 的基础
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMS 是什么：JMS 是 Java 提供的一套技术规范
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMS 干什么用：用来异构系统 集成通信，缓解系统瓶颈，提高系统的伸缩性增强系统用户体验，使得系统模块化和组件化变得可行并更加灵活
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;通过什么方式：生产消费者模式（生产者、服务器、消费者）</code></pre> 
  <p>&nbsp;</p> 
  <p><img alt="" class="has" height="250" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215550481.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="637"></p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;2.JMS 消息传输模型
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;点对点模型通常是一个基于拉取或者轮询的消息传送模型，这种模型从队列中请求信息，而不是将消息推送到客户端。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;这个模型的特点是发送到队列的消息被一个且只有一个接收者接收处理，即使有多个消息监听者也是如此。

&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.发布/订阅模式（一对多，数据生产后，推送给所有订阅者）
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;发布订阅模型则是一个基于推送的消息传送模型。&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;发布订阅模型可以有多种不同的订阅者，临时订阅者只在主动监听主题时才接收消息，而持久订阅者则监听主题的所有消息，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;即使当前订阅者不可用，处于离线状态。</code></pre> 
  <p><img alt="" class="has" height="476" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215727258.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="915"></p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;3.JMS 核心组件
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.Destination：消息发送的目的地，也就是前面说的 队列(Queue) 或 Topic(主题)。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.Message：从字面上就可以看出是被发送的消息。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.Producer：消息的生产者，要发送一个消息，必须通过这个生产者来发送。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.MessageConsumer：与生产者相对应，这是消息的消费者或接收者，通过它来接收一个消息。</code></pre> 
  <p><img alt="" class="has" height="541" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215737952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="851"></p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;4.常见的类 JMS 消息服务器
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.JMS 消息服务器 ActiveMQ
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ActiveMQ 是 Apache 出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1 和 J2EE 1.4 规范的。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;主要特点：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.多种语言和协议编写客户端。语言: Java, C, C++, C#, Ruby, Perl, Python, PHP。应用协议:OpenWire,Stomp REST,WS Notification,XMPP,AMQP
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.完全支持 JMS1.1 和 J2EE 1.4 规范 (持久化,XA 消息,事务)
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.对 Spring 的支持,ActiveMQ 可以很容易内嵌到使用 Spring 的系统里面去,而且也支持Spring2.0 的特性
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.通过 常见 J2EE 服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试，其中通过 JCA1.5 resource adaptors 的配置，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;可以让 ActiveMQ 可以自动的部署到任何兼容 J2EE 1.4 商业服务器上
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;6.支持通过 JDBC 和 journal 提供高速的消息持久化
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;7.从设计上保证了高性能的集群,客户端-服务器,点对点
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;8.支持 Ajax
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;9.支持与 Axis 的整合
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;10.可以很容易得调用内嵌 JMS provider,进行测试

&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.分布式消息中间件 Metamorphosis
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Metamorphosis (MetaQ) 是一个高性能、高可用、可扩展的分布式消息中间件，类似于 LinkedIn的 Kafka，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;具有消息存储顺序写、吞吐量大和支持本地和 XA 事务等特性，适用于大吞吐量、顺序消息、广播和日志数据传输等场景，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;在淘宝和支付宝有着广泛的应用，现已开源。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;主要特点：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;生产者、服务器和消费者都可分布
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;消息存储顺序写
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;性能极高,吞吐量大
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息顺序
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持本地和 XA 事务
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;客户端 pull，随机读,利用 sendfile 系统调用，zero-copy ,批量拉数据
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消费端事务
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息广播模式
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持异步发送消息
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持 http 协议
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持消息重试和 recover
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;数据迁移、扩容对用户透明
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;消费状态保存在客户端
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持同步和异步复制两种 HA
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;支持 group commit

&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.分布式消息中间件 RocketMQ
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;能够保证严格的消息顺序
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;提供丰富的消息拉取模式
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;高效的订阅者水平扩展能力
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;实时的消息订阅机制
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;亿级消息堆积能力
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Metaq3.0 版本改名，产品名称改为 RocketMQ

&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.其他 MQ
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;.NET 消息中间件 DotNetMQ
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;基于 HBase 的消息队列 HQueue
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Go 的 MQ 框架 KiteQ
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AMQP 消息服务器 RabbitMQ
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;MemcacheQ 是一个基于 MemcacheDB 的消息队列服务器。</code></pre> 
  <p><br> 3.为什么需要消息队列&nbsp;<br> &nbsp;&nbsp; &nbsp;消息系统的核心作用就是三点：解耦、异步、并行<br> &nbsp;&nbsp; &nbsp;以用户注册的案列来说明消息系统的作用</p> 
  <p>&nbsp;&nbsp; &nbsp;1.用户注册的一般流程</p> 
  <p><img alt="" class="has" height="240" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215800819.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="801"><br> &nbsp;&nbsp; &nbsp;2.用户注册的并行执行</p> 
  <p><img alt="" class="has" height="730" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215804715.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="841"><br> &nbsp;&nbsp; &nbsp;3.用户注册的最终一致</p> 
  <p><img alt="" class="has" height="494" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215809134.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="587"><br> 4.Kafka 核心组件&nbsp;<br> &nbsp;&nbsp; &nbsp;Topic(主题)：消息根据 Topic 进行归类<br> &nbsp;&nbsp; &nbsp;Producer：发送消息者<br> &nbsp;&nbsp; &nbsp;Consumer：消息接受者<br> &nbsp;&nbsp; &nbsp;broker(中间人)：kafka cluster(kafka群)中的 每个 kafka 实例(server)<br> &nbsp;&nbsp; &nbsp;Zookeeper：依赖集群保存 meta 信息。</p> 
  <p><img alt="" class="has" height="271" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215814521.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="940"><br> 5.Kafka 集群部署&nbsp;</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.集群部署的基本流程
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;下载安装包、解压安装包、修改配置文件、分发安装包、启动集群
&nbsp;&nbsp; &nbsp;
&nbsp;&nbsp; &nbsp;2.集群部署的基础环境准备
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.安装前的准备工作（zk 集群已经部署完毕）
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.关闭防火墙：chkconfig iptables off &amp;&amp; setenforce 0
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.创建用户：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;groupadd 组名 &amp;&amp; useradd 用户名 &amp;&amp; usermod -a -G 组名 用户名
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;groupadd realtime &amp;&amp; useradd realtime &amp;&amp; usermod -a -G realtime realtime
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.创建工作目录并赋权
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mkdir /export
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mkdir /export/servers
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;chmod 755 -R /export
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.切换到 realtime 用户下：su realtime

&nbsp;&nbsp; &nbsp;3.Kafka 集群部署
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.下载安装包
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;下载地址：http://kafka.apache.org/downloads.html
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;在 linux 中使用 wget 命令下载安装包：wget http://mirrors.shuosc.org/apache/kafka/1.0.0/kafka_2.11-1.0.0.tgz

</code></pre> 
  <p><img alt="" class="has" height="415" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215823687.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="673"></p> 
  <p><br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.解压安装包<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;tar -zxvf kafka_2.11-1.0.0.tgz -C /export/servers/<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cd /export/servers/<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;mv kafka_2.11-1.0.0 kafka</p> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.修改配置文件</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cp /export/servers/kafka/config/server.properties /export/servers/kafka/config/server.properties.bak
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;vi /export/servers/kafka/config/server.properties
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;输入以下内容：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#broker 的全局唯一编号，不能重复
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=0
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来监听链接的端口，producer 或 consumer 将在此端口建立连接
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;port=9092
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#处理网络请求的线程数量
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.network.threads=3
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来处理磁盘 IO 的线程数量
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.io.threads=8
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#发送套接字的缓冲区大小
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.send.buffer.bytes=102400
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#接收套接字的缓冲区大小
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.receive.buffer.bytes=102400
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#请求套接字的缓冲区大小
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.request.max.bytes=104857600
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#kafka 运行日志存放的路径
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.dirs=/export/servers/logs/kafka
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#topic(主题) 在当前 broker(中间人) 上的分片个数
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.partitions=2
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#用来恢复和清理 data 下数据的线程数量
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.recovery.threads.per.data.dir=1
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#segment 文件保留的最长时间，超时将被删除
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.hours=168
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#滚动生成新的 segment 文件的最大时间
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.roll.hours=168
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#日志文件中每个 segment 的大小，默认为 1G
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.segment.bytes=1073741824
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#周期性检查文件大小的时间
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.check.interval.ms=300000
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#日志清理是否打开
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.cleaner.enable=true
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#broker 需要使用 zookeeper 保存 meta 数据
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connect=192.168.52.106:2181,192.168.52.107:2181,192.168.52.108:2181
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#zookeeper 链接超时时间
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connection.timeout.ms=6000
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#partion buffer 中，消息的条数达到阈值，将触发 flush 到磁盘
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.flush.interval.messages=10000
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#消息 buffer 的时间，达到阈值，将触发 flush 到磁盘
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.flush.interval.ms=3000
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#删除 topic，需要 server.properties 中设置 delete.topic.enable=true，否则只是标记删除
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;delete.topic.enable=true
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;#此处的 host.name 为本机 IP(重要)，如果不改，则客户端会抛出:Producer connection to localhost:9092 unsuccessful 错误!
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;host.name=kafka01</code></pre> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.分发安装包<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.scp -r /export/servers/kafka kafka02:/export/servers<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;然后分别在各机器上创建软连<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;cd /export/servers/</p> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.scp -r /export/servers/kafka kafka03:/export/servers<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;然后分别在各机器上创建软连<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;cd /export/servers/</p> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.再次修改配置文件（重要）<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;依次修改各服务器上配置文件的的 broker.id，分别是 0,1,2 不得重复。&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;</p> 
  <p>&nbsp; &nbsp; &nbsp; &nbsp; 6.启动集群</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.依次在各节点上启动 kafka
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;nohup /export/servers/kafka/bin/kafka-server-start.sh /export/servers/kafka/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.输出错误日志到黑洞
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;command &gt;/dev/null 2&gt;&amp;1 &amp;

</code></pre> 
  <p><br> 6.Kafka 常用操作命令</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.查看当前服务器中的所有 topic
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --list --zookeeper zk01:2181

&nbsp;&nbsp; &nbsp;2.创建 topic
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --create --zookeeper zk01:2181 --replication-factor 1 --partitions 1 --topic test

&nbsp;&nbsp; &nbsp;3.删除 topic
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --delete --zookeeper zk01:2181 --topic test
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;需要 server.properties 中设置 delete.topic.enable=true 否则只是标记删除或者直接重启。

&nbsp;&nbsp; &nbsp;4.通过 shell 命令发送消息
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-console-producer.sh --broker-list kafka01:9092 --topic test

&nbsp;&nbsp; &nbsp;5.通过 shell 消费消息
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-console-consumer.sh --zookeeper zk01:2181 --from-beginning --topic test

&nbsp;&nbsp; &nbsp;6.查看消费位置
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-run-class.sh kafka.tools.ConsumerOffsetChecker --zookeeper zk01:2181 --group testGroup

&nbsp;&nbsp; &nbsp;7.查看某个 Topic 的详情
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --topic test --describe --zookeeper zk01:2181

&nbsp;&nbsp; &nbsp;8.对分区数进行修改
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;bin/kafka-topics.sh --zookeeper zk01 --alter --partitions 2 --topic test</code></pre> 
  <p>7.Kafka JavaAPI</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.Kafka 生产者
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;dependency&gt;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;version&gt;0.11.0.1&lt;/version&gt;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;/dependency&gt;

&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public static void main(String[] args)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//1、准备配置文件
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Properties props = new Properties();
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("bootstrap.servers", "node01:9092");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("acks", "all");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("retries", 0);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("batch.size", 16384);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("linger.ms", 1);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("buffer.memory", 33554432);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//2、创建 Kafka Producer 生产者
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;KafkaProducer&lt;String, String&gt; kafkaProducer = new KafkaProducer&lt;String,String&gt;(props);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;for (int i=0;i&lt;100;i++)
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;//3、发送数据
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafkaProducer.send(new ProducerRecord&lt;String, String&gt;("test","num"+i,"value"+i));
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}</code></pre> 
  <p>&nbsp;&nbsp; &nbsp;2.Kafka 消费者</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;dependency&gt;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;version&gt;0.11.0.1&lt;/version&gt;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&lt;/dependency&gt;

&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public static void main(String[] args)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 1、准备配置文件
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Properties props = new Properties();
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("bootstrap.servers", "node01:9092");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("group.id", "test");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("enable.auto.commit", "true");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("auto.commit.interval.ms", "1000");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 2、创建 Kafka Consumer 消费者
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;String, String&gt;(props);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 3、订阅数据，这里的 topic(主题) 可以是多个，可用List封装
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafkaConsumer.subscribe(Arrays.asList("test"));
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 4、获取数据
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;while (true)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;for (ConsumerRecord&lt;String, String&gt; record : records)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;System.out.printf("topic = %s,offset = %d, key = %s, value = %s%n",&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; record.topic(), record.offset(), record.key(), record.value());
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}</code></pre> 
  <p>8.Kafka 整体结构图</p> 
  <p><img alt="" class="has" height="433" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215840450.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="891"></p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.Producer：消息生产者，就是向 kafka broker(中间人) 发消息的客户端&nbsp;
&nbsp;&nbsp; &nbsp;2.Consumer：消息消费者，向 kafka broker(中间人) 取消息的客户端
&nbsp;&nbsp; &nbsp;3.Topic：主题
&nbsp;&nbsp; &nbsp;4.Consumer Group（CG）消费者组：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;这是 kafka 用来实现一个 topic(主题) 消息的广播（发给所有的 consumer消费者）和 单播（发给任意一个 consumer消费者）的手段。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;一个 topic(主题) 可以有多个 CG消费者组。topic(主题) 的消息会复制（不是真的复制，是概念上的）到所有的 CG消费者组，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;但每个 partion(分区) 只会把消息发给该 CG 中的一个consumer消费者。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;如果需要实现广播，只要每个 consumer消费者 有一个独立的 CG 就可以了。要实现单播只要所有的 consumer 在同一个 CG。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;用 CG消费者组 还可以将 consumer消费者 进行自由的分组，而不需要多次发送消息到不同的 topic(主题)。
&nbsp;&nbsp; &nbsp;5.Broker：一台 kafka 服务器就是一个 broker(中间人)。一个kafka集群(cluster) 由多个 broker(中间人) 组成。一个 broker 可以容纳多个 topic(主题)。
&nbsp;&nbsp; &nbsp;6.Partition(分区)：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;为了实现扩展性，一个非常大的 topic(主题) 可以分布到多个 broker（即服务器）上，一个topic(主题) 可以分为多个 partition(分区)，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 partition(分区) 是一个有序的队列(Queue)。partition(分区) 中的每条消息都会被分配一个有序的 id（offset）。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafka 只保证按一个 partition(分区) 中的顺序 将消息发给 consumer消费者，不保证一个 topic 的整体（多个 partition分区 间）的顺序
&nbsp;&nbsp; &nbsp;7.Offset：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;kafka 的存储文件都是按照 offset.kafka 来命名，用 offset 做名字的好处是方便查找。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;例如你想找位于 2049 的位置，只要找到 2048.kafka 的文件即可。当然 the first offset 就是00000000000.kafka
&nbsp;&nbsp; &nbsp;8.Replication(复制)：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Kafka 支持以 Partition(分区) 为单位对 Message 进行冗余备份，每个 Partition(分区) 都可以配置至少 1 个 Replication(复制)，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当仅只有 1 个 Replication(复制) 时 即仅该 Partition(分区) 本身。
&nbsp;&nbsp; &nbsp;9.Leader：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 Replication(复制) 集合中的 Partition(分区) 都会选出一个唯一的 Leader，所有的 读写请求 都由 Leader 处理。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;其他 Replicas(复数的复制品) 从 Leader 处把数据更新同步到本地，过程类似大家熟悉的 MySQL中的 Binlog 同步。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;每个 Cluster(集群) 当中会选举出一个 Broker(中间人) 来担任 Controller，负责处理 Partition(分区) 的 Leader 选举，协调 Partition(分区) 迁移等工作。

&nbsp;&nbsp; &nbsp;10.ISR(In-Sync Replica)：
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;是 Replicas(复制品) 的一个子集，表示目前 Alive 且与 Leader 能够“Catch-up(追赶)”的 Replicas(复制品) 集合。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;由于读写都是首先落到 Leader 上，所以一般来说通过同步机制从 Leader 上拉取数据的 Replica(复制品) 都会和 Leader 有一些延迟
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;(包括了延迟时间和延迟条数两个维度)，任意一个超过阈值都会把该 Replica(复制品) 踢出 ISR。每个 Partition(分区) 都有它自己独立的 ISR。</code></pre> 
  <p>9.Kafka 配置文件详解</p> 
  <p><img alt="" class="has" height="603" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215854251.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="1200"><br> 10.Consumer消费者 与 topic主题 关系</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.本质上 kafka 只支持 Topic主题&nbsp;
&nbsp;&nbsp; &nbsp;2.每个 group 中可以有多个 consumer消费者，每个 consumer消费者 属于一个 consumer group；
&nbsp;&nbsp; &nbsp; &nbsp;通常情况下，一个 group 中会包含多个 consumer，这样不仅可以提高 topic主题 中消息的并发消费能力，而且还能提高"故障容错"性，
&nbsp;&nbsp; &nbsp; &nbsp;如果 group 中的某个 consumer消费者 失效，那么其消费的 partitions分区 将会有其他 consumer 自动接管。
&nbsp;&nbsp; &nbsp;3.对于 Topic主题 中的一条特定的消息，只会被订阅此 Topic主题 的每个 group 中的其中一个 consumer消费者，此消息不会发送给一个 group 的多个 consumer；
&nbsp;&nbsp; &nbsp; &nbsp;那么一个 group 中所有的 consumer消费者 将会交错的消费整个 Topic主题，每个 group 中 consumer 消息消费 互相独立，我们可以认为一个 group 是一个"订阅"者。
&nbsp;&nbsp; &nbsp;4.在 kafka 中，一个 partition分区 中的消息只会被 group 中的一个 consumer 消费(同一时刻)；
&nbsp;&nbsp; &nbsp; &nbsp;一个 Topic主题 中的每个 partions分区，只会被一个"订阅者"中的一个 consumer 消费，不过一个 consumer 可以同时消费多个 partitions分区 中的消息。
&nbsp;&nbsp; &nbsp;5.kafka 的设计原理决定，对于一个 topic主题， 同一个 group 中不能有多于 partitions分区 个数的 consumer 同时消费，否则将意味着某些 consumer 将无法得到消息。
&nbsp;&nbsp; &nbsp;6.kafka 只能保证一个 partition分区 中的消息被某个 consumer 消费时是顺序的；事实上，从 Topic主题 角度来说，当有多个 partitions分区 时，消息仍不是全局有序的。

</code></pre> 
  <p><br> 11.Kafka 消息的分发</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.Producer 客户端负责消息的分发
&nbsp;&nbsp; &nbsp;2.kafka 集群中的任何一个 broker中间者 都可以向 producer 提供 metadata 信息，这些 metadata 中包含"集群中存活的 servers 列表" / "partitions分区 leader 列表"等信息；
&nbsp;&nbsp; &nbsp;3.当 producer 获取到 metadata 信息之后, producer 将会和 Topic 下所有 partition分区 leader 保持socket 连接；
&nbsp;&nbsp; &nbsp;4.消息由 producer 直接通过 socket 发送到 broker中间者，中间不会经过任何"路由层"，事实上，消息被路由到哪个 partition分区 上由 producer 客户端决定；
&nbsp;&nbsp; &nbsp; &nbsp;比如可以采用"random"、"key-hash"、"轮询"等，如果一个 topic主题 中有多个 partitions分区，那么在 producer 端实现"消息均衡分发"是必要的。
&nbsp;&nbsp; &nbsp;5.在 producer 端的配置文件中，开发者可以指定 partition 路由的方式。
&nbsp;&nbsp; &nbsp;6.Producer 消息发送的应答机制
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;设置发送数据是否需要服务端的反馈，有三个值 0、1、-1
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;0：producer 不会等待 broker中间者 发送 ack(命令正确应答)
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1：当 leader 接收到消息之后发送 ack(命令正确应答)
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;-1：当所有的 follower 都同步消息成功后发送 ack(命令正确应答)
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;request.required.acks=0</code></pre> 
  <p><br> 12.Consumer消费者 的负载均衡</p> 
  <p><img alt="" class="has" height="353" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019050421590053.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="694"></p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;当一个 group 中,有 consumer消费者 加入或者离开时，会触发 partitions分区 均衡。均衡的最终目的，是提升 topic主题 的并发消费能力，步骤如下：
&nbsp;&nbsp; &nbsp;1.假如 topic主题 具有如下 partitions分区：P0、P1、P2、P3
&nbsp;&nbsp; &nbsp;2.加入 group 中，有如下 consumer消费者：C1、C2
&nbsp;&nbsp; &nbsp;3.首先根据 partition分区 索引号对 partitions分区 排序：P0、P1、P2、P3
&nbsp;&nbsp; &nbsp;4.根据 consumer.id 排序：C0、C1
&nbsp;&nbsp; &nbsp;5.计算倍数：M = [P0,P1,P2,P3].size / [C0,C1].size，本例值 M=2(向上取整)
&nbsp;&nbsp; &nbsp;6.然后依次分配 partitions分区：C0 = [P0,P1]，C1 = [P2,P3]，即 Ci = [P(i * M),P((i + 1) * M -1)]

</code></pre> 
  <p><br> 13.Kafka 文件存储机制</p> 
  <pre class="has">
<code>&nbsp;&nbsp;&nbsp;&nbsp;1.Kafka 文件存储基本结构
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.在Kafka文件存储中，同一个 topic主题 下有多个不同 partition分区， 每个 partition分区 为一个目录， partiton分区 命名规则为 topic主题名称 + 有序序号，
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一个 partiton分区 序号从 0 开始，序号最大值为 partitions分区 数量减 1。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.每个 partion分区(目录) 相当于一个巨型文件被平均分配到多个 大小相等 segment(段)数据文件中。&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;但每个段 segment file 消息数量不一定相等，这种特性方便 old segment file 快速被删除。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认保留 7 天的数据。</code></pre> 
  <p><img alt="" class="has" height="240" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215927756.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="524"></p> 
  <pre class="has">
<code>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.每个 partiton分区 只需要支持顺序读写就行了，segment 文件生命周期由服务端配置参数决定。（什么时候创建，什么时候删除）
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：数据有序的讨论？一个 partition分区 的数据是否是有序的？
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：间隔性有序，不连续针对一个 topic主题 里面的数据，只能做到 partition分区 内部有序，不能做到全局有序。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：特别加入消费者的场景后，如何保证消费者 消费的数据 全局有序的？
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：伪命题。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;问：只有一种情况下才能保证全局有序？
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;答：就是只有一个 partition。</code></pre> 
  <p><img alt="" class="has" height="329" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504215932536.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="668"></p> 
  <p>14.Kafka Partition Segment</p> 
  <pre class="has">
<code>&nbsp;&nbsp;&nbsp;&nbsp;1.Segment file 组成：
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由 2 大部分组成，分别为 index file 和 data file，此 2 个文件一一对应，成对出现，后缀".index"和“.log”分别表示为 segment 索引文件、数据文件。</code></pre> 
  <p><img alt="" class="has" height="232" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220002848.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="428"></p> 
  <pre class="has">
<code>&nbsp;&nbsp;&nbsp;&nbsp;2.Segment 文件命名规则：&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;partion分区 全局的第一个 segment 从 0 开始， 后续每个 segment 文件名为上一个 segment 文件最后一条消息的 offset 值。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数值最大为 64 位 long 大小，19 位数字字符长度，没有数字用 0 填充。
&nbsp;&nbsp;&nbsp;&nbsp;3.索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;下述图中索引文件存储大量元数据，数据文件存储大量消息，索引文件中元数据指向对应数据文件中 message 的物理偏移地址。
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message(在全局partiton 表示第 368772 个 message)、以及该消息的物理偏移地址为 497。</code></pre> 
  <p><img alt="" class="has" height="459" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220012278.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="916"></p> 
  <p>&nbsp;&nbsp;&nbsp;&nbsp;4.segment data file 由许多 message 组成，物理结构如下：</p> 
  <p><img alt="" class="has" height="899" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220018658.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="647"></p> 
  <p>15.Kafka 查找 message<br> &nbsp;&nbsp; &nbsp;1.读取 offset=368776 的 message，需要通过下面 2 个步骤查找。<img alt="" class="has" height="208" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220023724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="322"></p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;2.查找 segment file
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000000000.index 表示最开始的文件，起始偏移量(offset)为 0
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000368769.index 的消息量起始偏移量为 368770 = 368769 + 1
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;00000000000000737337.index 的起始偏移量为 737338 = 737337 + 1
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;其他后续文件依次类推。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;以起始偏移量命名并排序这些文件，只要根据 offset **二分查找**文件列表，就可以快速定位到具体文件。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当 offset = 368776 时定位到 00000000000000368769.index 和对应 log 文件。

&nbsp;&nbsp; &nbsp;3.通过 segment file 查找 message
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;当 offset=368776 时，依次定位到 00000000000000368769.index 的元数据物理位置 和 00000000000000368769.log 的物理偏移地址，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;然后再通过 00000000000000368769.log 顺序查找直到 offset=368776 为止。</code></pre> 
  <p><br> 16.Kafka 自定义 Partition<br> &nbsp;&nbsp; &nbsp;如果指定 partition，就用 partition<br> &nbsp;&nbsp; &nbsp;如果指定 key，使用 key 进行 hash 取模。<br> &nbsp;&nbsp; &nbsp;如果没有指定 key，使用轮询的方式。</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;public class DefaultPartitioner implements Partitioner&nbsp;
&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;private final ConcurrentMap&lt;String, AtomicInteger&gt; topicCounterMap = new ConcurrentHashMap&lt;&gt;();
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public void configure(Map&lt;String, ?&gt; configs) {}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;/**
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* 计算给定记录的分区
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param topic 主题名称
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param key 分区上的键（或如果没有键，则为空）
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param keyBytes 序列化的分区键（或如果没有键，则为空）
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param value 分区或无效的值
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param valueBytes 分区 序列化值 或 无效&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;* @param cluster 当前集群 元数据
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*/
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;List&lt;PartitionInfo&gt; partitions = cluster.partitionsForTopic(topic);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int numPartitions = partitions.size();
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (keyBytes == null)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int nextValue = nextValue(topic);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;List&lt;PartitionInfo&gt; availablePartitions = cluster.availablePartitionsForTopic(topic);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (availablePartitions.size() &gt; 0)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;int part = Utils.toPositive(nextValue) % availablePartitions.size();
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return availablePartitions.get(part).partition();
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;else&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 没有分区可用，给出非可用分区
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return Utils.toPositive(nextValue) % numPartitions;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;else&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;// 散列键值以选择分区
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return Utils.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}

&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;private int nextValue(String topic)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AtomicInteger counter = topicCounterMap.get(topic);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (null == counter)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;counter = new AtomicInteger(ThreadLocalRandom.current().nextInt());
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;AtomicInteger currentCounter = topicCounterMap.putIfAbsent(topic, counter);
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;if (currentCounter != null)&nbsp;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;counter = currentCounter;
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;return counter.getAndIncrement();
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;public void close() {}
&nbsp;&nbsp; &nbsp;}</code></pre> 
  <p>17.Kafka 为什么那么快</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.Broker中间者
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.不同于 Redis 和 MemcacheQ 等内存消息队列，Kafka 的设计是把所有的 Message 都要写入速度低容量大的硬盘，以此来换取更强的存储能力。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.实际上，Kafka 使用硬盘并没有带来过多的性能损失，“规规矩矩”的抄了一条“近道”。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;首先，说“规规矩矩”是因为 Kafka 在磁盘上只做 Sequence顺序 I/O，由于消息系统读写的特殊性，这并不存在什么问题。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;关于磁盘 I/O 的性能，引用一组 Kafka 官方给出的测试数据(Raid-5，7200rpm)：Sequence I/O: 600MB/s、Random I/O: 100KB/s。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;所以通过只做 Sequence顺序 I/O 的限制，规避了磁盘访问速度低下对性能可能造成的影响。

&nbsp;&nbsp; &nbsp;2.接下来我们再聊一聊 Kafka 是如何“抄近道的”。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.首先，Kafka 重度依赖底层操作系统提供的 Page Cache页面缓存 功能。当上层有写操作时，操作系统只是将数据写入 Page Cache页面缓存，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同时标记 Page页面 属性为 Dirty脏的。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.当读操作发生时，先从 Page Cache页面缓存 中查找，如果发生 缺页才进行磁盘调度，最终返回需要的数据。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;实际上 Page Cache页面缓存 是把尽可能多的空闲内存 都当做了磁盘缓存来使用。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同时如果有其他进程申请内存，回收 Page Cache页面缓存 的代价又很小，所以现代的 OS 都支持 Page Cache页面缓存。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.使用 Page Cache页面缓存 功能同时可以避免在 JVM 内部缓存数据，JVM 为我们提供了强大的 GC(垃圾回收机制) 能力，同时也引入了一些问题不适用与 Kafka 的设计。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;如果在 Heap堆 内管理缓存，JVM 的 GC(垃圾回收机制) 线程会频繁扫描 Heap堆 空间，带来不必要的开销。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;如果 Heap堆过大，执行一次 Full GC 对系统的可用性来说将是极大的挑战。所有在 JVM 内的对象都不免带有一个 Object Overhead(对象开销)，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;内存的有效空间利用率会因此降低。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.所有的 In-Process Cache进程内缓存 在 OS 中都有一份同样的 Page Cache页面缓存。 所以通过将缓存只放在 Page Cache页面缓存，
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;可以至少让可用缓存空间翻倍。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;5.如果 Kafka 重启，所有的 In-Process Cache进程内缓存 都会失效，而 OS 管理的 Page Cache页面缓存 依然可以继续使用。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;Page Cache页面缓存 还只是第一步，Kafka 为了进一步的优化性能还采用了 Sendfile 技术。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;在解释 Sendfile 之前，首先介绍一下传统的网络 I/O 操作流程，大体上分为以下 4 步。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.OS 从硬盘 把数据读到 内核区的 Page Cache页面缓存。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.用户进程 把 数据 从 内核区 Copy 到 用户区。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.然后 用户进程 再把 数据 写入到 Socket，数据 流入 内核区的 Socket Buffer 上。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.OS 再把 数据从 Buffer 中 Copy 到 网卡的 Buffer 上，这样完成一次发送。


&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;整个过程共经历两次 Context Switch上下文切换，四次 System Call系统调用。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;同一份数据在内核 Buffer 与用户 Buffer 之间重复拷贝，效率低下。
&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; &nbsp;其中 2、3 两步没有必要，完全可以直接在内核区完成数据拷贝。这也正是 Sendfile 所解决的问题，经过 Sendfile 优化后，整个 I/O 过程就变成了下面这个样子。</code></pre> 
  <p><img alt="" class="has" height="427" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220121545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="565">&nbsp;<img alt="" class="has" height="521" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220124579.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="639"></p> 
  <p>18.Kafka 最佳实践</p> 
  <p><img alt="" class="has" height="257" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220130984.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="748"><br> 19.Kafka 监控工具&nbsp;</p> 
  <pre class="has">
<code>&nbsp;&nbsp; &nbsp;1.Kafka Web Console：监控功能较为全面，可以预览消息，监控 Offset、Lag 等信息，但存在 bug，不建议在生产环境中使用。
&nbsp;&nbsp; &nbsp;2.Kafka Manager：偏向 Kafka 集群管理，若操作不当，容易导致集群出现故障。对 Kafka 实时生产和消费消息是通过 JMX 实现的。没有记录 Offset、Lag 等信息。
&nbsp;&nbsp; &nbsp;3.KafkaOffsetMonitor：程序一个 jar 包的形式运行，部署较为方便。只有监控功能，使用起来也较为安全。
&nbsp;&nbsp; &nbsp;4.若只需要监控功能，推荐使用 KafkaOffsetMonito，若偏重 Kafka 集群管理，推荐使用 KafkaManager。
&nbsp;&nbsp; &nbsp; &nbsp;因为都是开源程序，稳定性欠缺。

</code></pre> 
  <p><img alt="" class="has" height="483" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220136217.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="623"><br> 20.配置一键启动脚本</p> 
  <p><img alt="" class="has" height="629" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220141390.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="860"></p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
