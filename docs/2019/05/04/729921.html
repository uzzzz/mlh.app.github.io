<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>大数据系列（一）hadoop生态圈基础知识后续之分布式hadoop环境搭建 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="大数据系列（一）hadoop生态圈基础知识后续之分布式hadoop环境搭建" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="目录 环境介绍须知 前置工作 集群搭建 集群规划 配置HOSTS文件 配置免密码SSH链接 配置hadoop 推荐一些阿里云搭建的博客 环境介绍须知 我们按照3台服务器数量来搭建，1个namenode，2个databode，那么我们需要以下环境： 三台linux系统的服务器，博主使用的是阿里云centos7 jdk8，请大家自行下载，这边博客不在讲述 hadoop3.x的tar包 文中出现的hadoop_home皆为你自己安装的hadoop的路径 前置工作 首先我们创建三台阿里云，当然如果你提前配置好vpc，就可以指定ip（关于基于云服务做网络架构设计，配合应用架构搭建企业级的业务集群，博主后期会更新相关架构文档，有兴趣的小伙伴可以等一等哦），如果没有VPC，那么直接使用ipv4（仅测试或者自己玩的环境） 登陆官网下载hadoop3.x的tar包，传送门：https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz， 直接在服务器上wget即可 jdk下载（不做介绍），请小伙伴自行安装 规划网络与服务器节点 规划数据存储位置 规划各个应用的用户与角色（因为这是非生产，用来学习，博主直接root用户走起来） 集群搭建 集群规划 我们前面说，我们用三台来搭建分布式集群，那么我们对服务器需要提前做些规划，网络划分记得是内网哦。 master服务器，是namenode节点，ip为：10.151.64.57 node1服务器，是datanode1节点，ip为：10.151.64.60 node2服务器，是datanode2节点，ip为：10.151.64.59 接下来，我们创建一些目录，作为临时数据、元数据等数据存储的地方，方便后续观察，因为这是非生产，所以博主 比较随意，直接在根目录下创建了（mkdir tmp hdfs hdfs/data hdfs/name）： 目录/tmp，用来存储临时生成的文件 目录/hdfs，用来存储集群数据 目录hdfs/data，用来存储真正的数据 目录hdfs/name，用来存储文件系统元数据 配置HOSTS文件 为了更方便通信，在各个配置文件中无需写ip，我们直接在namenode节点上配置所有相关节点的host，然后统一覆盖所有节点即可： vi /etc/hosts 10.151.64.57 master 10.151.64.60 node1 10.151.64.59 node2 配置免密码SSH链接 为了让namenode节点可以免密码直接链接各个datanode节点，我们做如下操作： 利用下面命令生成密钥，在生成的过程中一直按回车就可以： ssh-keygen 将密钥加入到可信任列表，可以使用下面命令，也可以直接将id_rsa.pub内容复制在authorized_keys中： cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 将id_rsa.pub拷贝到node1节点的authorized_keys中，这样就默认node1是信任master服务器的 或者你可以使用scp将id_rsa.pub 拷贝在node1节点（需要输入node1连接密码），然后在使用 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys命令添加信任 在master节点上，使用ssh node1命令，如果可以正常登陆node1，则代表免密码配置成功 ssh node1 备注：你可以利用node1做为镜像服务器，如果环境配置好之后，直接打镜像，然后后续在添加服务器，利用这个镜像创建服务器即可，然后通过namenode配置hosts，将所有配置全部发送给所有节点进行覆盖。 配置hadoop 首先我们使用https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz下载下来的tar包进行解压，博主解压在家目录下（/root） tar -zxf hadoop-3.1.2.tar.gz -C /root/ 然后我们开始配置环境变量 vi /etc/profile export JAVA_HOME=/usr/java/default export HADOOP_HOME=/root/hadoop export PATH=/usr/local/mysql/bin:/usr/local/mysql/lib:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 配置完毕之后，记得使用source /etc/profile才生效哦 然后我们使用下面命令查看是否生效，生效会有hadoop的具体信息 hadoop version 接下来我们开始配置hadoop的配置文件，配置文件在/hadoop_home/etc/hadoop下 core-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/root/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; hdfs-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/root/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/root/data&lt;/value&gt; &lt;/property&gt; &lt;!-- 副本系数，代表数据会存储几份,我们这里就设定1份即可 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; mapred-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; yarn-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;!-- 这里使用hadoop classpath查看以下路径，如果这里不配置，可能会报Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster错误 --&gt; &lt;property&gt; &lt;name&gt;yarn.application.classpath&lt;/name&gt; &lt;value&gt;输入刚才返回的Hadoop classpath路径,记得以逗号分割&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 修改slaves(3.x修改为workers): master node1 node2 将修改的文件发送的另外的节点覆盖：rsync -av /root/hadoop/etc/ node2:/root/hadoop/etc/ 如果出现以下错误： [root@master sbin]# ./start-dfs.sh Starting namenodes on [master] ERROR: Attempting to operate on hdfs namenode as root ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation. Starting datanodes ERROR: Attempting to operate on hdfs datanode as root ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation. Starting secondary namenodes [slave1] ERROR: Attempting to operate on hdfs secondarynamenode as root ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation. 在/hadoop/sbin路径下： 将start-dfs.sh，stop-dfs.sh两个文件顶部添加以下参数 #!/usr/bin/env bash HDFS_DATANODE_USER=root HADOOP_SECURE_DN_USER=hdfs HDFS_NAMENODE_USER=root HDFS_SECONDARYNAMENODE_USER=root 还有，start-yarn.sh，stop-yarn.sh顶部也需添加以下： #!/usr/bin/env bash YARN_RESOURCEMANAGER_USER=root HADOOP_SECURE_DN_USER=yarn YARN_NODEMANAGER_USER=root hadoop3.x端口号已经更改，如下： The patch updates the HDFS default HTTP/RPC ports to non-ephemeral ports. The changes are listed below: Namenode ports: 50470 --&gt; 9871, 50070 --&gt; 9870, 8020 --&gt; 9820 Secondary NN ports: 50091 --&gt; 9869, 50090 --&gt; 9868 Datanode ports: 50020 --&gt; 9867, 50010 --&gt; 9866, 50475 --&gt; 9865, 50075 --&gt; 9864 启动之后访问(记得安全组9870与8088端口要开放哦)： http://你的ip:9870 http://你的ip:8088/cluster 推荐一些阿里云搭建的博客 1.https://blog.csdn.net/zhangvalue/article/details/80870160 2.https://blog.csdn.net/bqw18744018044/article/details/79103931 3.:https://blog.csdn.net/a1135497143/article/details/81915489" />
<meta property="og:description" content="目录 环境介绍须知 前置工作 集群搭建 集群规划 配置HOSTS文件 配置免密码SSH链接 配置hadoop 推荐一些阿里云搭建的博客 环境介绍须知 我们按照3台服务器数量来搭建，1个namenode，2个databode，那么我们需要以下环境： 三台linux系统的服务器，博主使用的是阿里云centos7 jdk8，请大家自行下载，这边博客不在讲述 hadoop3.x的tar包 文中出现的hadoop_home皆为你自己安装的hadoop的路径 前置工作 首先我们创建三台阿里云，当然如果你提前配置好vpc，就可以指定ip（关于基于云服务做网络架构设计，配合应用架构搭建企业级的业务集群，博主后期会更新相关架构文档，有兴趣的小伙伴可以等一等哦），如果没有VPC，那么直接使用ipv4（仅测试或者自己玩的环境） 登陆官网下载hadoop3.x的tar包，传送门：https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz， 直接在服务器上wget即可 jdk下载（不做介绍），请小伙伴自行安装 规划网络与服务器节点 规划数据存储位置 规划各个应用的用户与角色（因为这是非生产，用来学习，博主直接root用户走起来） 集群搭建 集群规划 我们前面说，我们用三台来搭建分布式集群，那么我们对服务器需要提前做些规划，网络划分记得是内网哦。 master服务器，是namenode节点，ip为：10.151.64.57 node1服务器，是datanode1节点，ip为：10.151.64.60 node2服务器，是datanode2节点，ip为：10.151.64.59 接下来，我们创建一些目录，作为临时数据、元数据等数据存储的地方，方便后续观察，因为这是非生产，所以博主 比较随意，直接在根目录下创建了（mkdir tmp hdfs hdfs/data hdfs/name）： 目录/tmp，用来存储临时生成的文件 目录/hdfs，用来存储集群数据 目录hdfs/data，用来存储真正的数据 目录hdfs/name，用来存储文件系统元数据 配置HOSTS文件 为了更方便通信，在各个配置文件中无需写ip，我们直接在namenode节点上配置所有相关节点的host，然后统一覆盖所有节点即可： vi /etc/hosts 10.151.64.57 master 10.151.64.60 node1 10.151.64.59 node2 配置免密码SSH链接 为了让namenode节点可以免密码直接链接各个datanode节点，我们做如下操作： 利用下面命令生成密钥，在生成的过程中一直按回车就可以： ssh-keygen 将密钥加入到可信任列表，可以使用下面命令，也可以直接将id_rsa.pub内容复制在authorized_keys中： cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 将id_rsa.pub拷贝到node1节点的authorized_keys中，这样就默认node1是信任master服务器的 或者你可以使用scp将id_rsa.pub 拷贝在node1节点（需要输入node1连接密码），然后在使用 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys命令添加信任 在master节点上，使用ssh node1命令，如果可以正常登陆node1，则代表免密码配置成功 ssh node1 备注：你可以利用node1做为镜像服务器，如果环境配置好之后，直接打镜像，然后后续在添加服务器，利用这个镜像创建服务器即可，然后通过namenode配置hosts，将所有配置全部发送给所有节点进行覆盖。 配置hadoop 首先我们使用https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz下载下来的tar包进行解压，博主解压在家目录下（/root） tar -zxf hadoop-3.1.2.tar.gz -C /root/ 然后我们开始配置环境变量 vi /etc/profile export JAVA_HOME=/usr/java/default export HADOOP_HOME=/root/hadoop export PATH=/usr/local/mysql/bin:/usr/local/mysql/lib:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 配置完毕之后，记得使用source /etc/profile才生效哦 然后我们使用下面命令查看是否生效，生效会有hadoop的具体信息 hadoop version 接下来我们开始配置hadoop的配置文件，配置文件在/hadoop_home/etc/hadoop下 core-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/root/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; hdfs-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/root/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/root/data&lt;/value&gt; &lt;/property&gt; &lt;!-- 副本系数，代表数据会存储几份,我们这里就设定1份即可 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; mapred-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; yarn-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;!-- 这里使用hadoop classpath查看以下路径，如果这里不配置，可能会报Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster错误 --&gt; &lt;property&gt; &lt;name&gt;yarn.application.classpath&lt;/name&gt; &lt;value&gt;输入刚才返回的Hadoop classpath路径,记得以逗号分割&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 修改slaves(3.x修改为workers): master node1 node2 将修改的文件发送的另外的节点覆盖：rsync -av /root/hadoop/etc/ node2:/root/hadoop/etc/ 如果出现以下错误： [root@master sbin]# ./start-dfs.sh Starting namenodes on [master] ERROR: Attempting to operate on hdfs namenode as root ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation. Starting datanodes ERROR: Attempting to operate on hdfs datanode as root ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation. Starting secondary namenodes [slave1] ERROR: Attempting to operate on hdfs secondarynamenode as root ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation. 在/hadoop/sbin路径下： 将start-dfs.sh，stop-dfs.sh两个文件顶部添加以下参数 #!/usr/bin/env bash HDFS_DATANODE_USER=root HADOOP_SECURE_DN_USER=hdfs HDFS_NAMENODE_USER=root HDFS_SECONDARYNAMENODE_USER=root 还有，start-yarn.sh，stop-yarn.sh顶部也需添加以下： #!/usr/bin/env bash YARN_RESOURCEMANAGER_USER=root HADOOP_SECURE_DN_USER=yarn YARN_NODEMANAGER_USER=root hadoop3.x端口号已经更改，如下： The patch updates the HDFS default HTTP/RPC ports to non-ephemeral ports. The changes are listed below: Namenode ports: 50470 --&gt; 9871, 50070 --&gt; 9870, 8020 --&gt; 9820 Secondary NN ports: 50091 --&gt; 9869, 50090 --&gt; 9868 Datanode ports: 50020 --&gt; 9867, 50010 --&gt; 9866, 50475 --&gt; 9865, 50075 --&gt; 9864 启动之后访问(记得安全组9870与8088端口要开放哦)： http://你的ip:9870 http://你的ip:8088/cluster 推荐一些阿里云搭建的博客 1.https://blog.csdn.net/zhangvalue/article/details/80870160 2.https://blog.csdn.net/bqw18744018044/article/details/79103931 3.:https://blog.csdn.net/a1135497143/article/details/81915489" />
<link rel="canonical" href="https://mlh.app/2019/05/04/729921.html" />
<meta property="og:url" content="https://mlh.app/2019/05/04/729921.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-04T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"目录 环境介绍须知 前置工作 集群搭建 集群规划 配置HOSTS文件 配置免密码SSH链接 配置hadoop 推荐一些阿里云搭建的博客 环境介绍须知 我们按照3台服务器数量来搭建，1个namenode，2个databode，那么我们需要以下环境： 三台linux系统的服务器，博主使用的是阿里云centos7 jdk8，请大家自行下载，这边博客不在讲述 hadoop3.x的tar包 文中出现的hadoop_home皆为你自己安装的hadoop的路径 前置工作 首先我们创建三台阿里云，当然如果你提前配置好vpc，就可以指定ip（关于基于云服务做网络架构设计，配合应用架构搭建企业级的业务集群，博主后期会更新相关架构文档，有兴趣的小伙伴可以等一等哦），如果没有VPC，那么直接使用ipv4（仅测试或者自己玩的环境） 登陆官网下载hadoop3.x的tar包，传送门：https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz， 直接在服务器上wget即可 jdk下载（不做介绍），请小伙伴自行安装 规划网络与服务器节点 规划数据存储位置 规划各个应用的用户与角色（因为这是非生产，用来学习，博主直接root用户走起来） 集群搭建 集群规划 我们前面说，我们用三台来搭建分布式集群，那么我们对服务器需要提前做些规划，网络划分记得是内网哦。 master服务器，是namenode节点，ip为：10.151.64.57 node1服务器，是datanode1节点，ip为：10.151.64.60 node2服务器，是datanode2节点，ip为：10.151.64.59 接下来，我们创建一些目录，作为临时数据、元数据等数据存储的地方，方便后续观察，因为这是非生产，所以博主 比较随意，直接在根目录下创建了（mkdir tmp hdfs hdfs/data hdfs/name）： 目录/tmp，用来存储临时生成的文件 目录/hdfs，用来存储集群数据 目录hdfs/data，用来存储真正的数据 目录hdfs/name，用来存储文件系统元数据 配置HOSTS文件 为了更方便通信，在各个配置文件中无需写ip，我们直接在namenode节点上配置所有相关节点的host，然后统一覆盖所有节点即可： vi /etc/hosts 10.151.64.57 master 10.151.64.60 node1 10.151.64.59 node2 配置免密码SSH链接 为了让namenode节点可以免密码直接链接各个datanode节点，我们做如下操作： 利用下面命令生成密钥，在生成的过程中一直按回车就可以： ssh-keygen 将密钥加入到可信任列表，可以使用下面命令，也可以直接将id_rsa.pub内容复制在authorized_keys中： cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 将id_rsa.pub拷贝到node1节点的authorized_keys中，这样就默认node1是信任master服务器的 或者你可以使用scp将id_rsa.pub 拷贝在node1节点（需要输入node1连接密码），然后在使用 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys命令添加信任 在master节点上，使用ssh node1命令，如果可以正常登陆node1，则代表免密码配置成功 ssh node1 备注：你可以利用node1做为镜像服务器，如果环境配置好之后，直接打镜像，然后后续在添加服务器，利用这个镜像创建服务器即可，然后通过namenode配置hosts，将所有配置全部发送给所有节点进行覆盖。 配置hadoop 首先我们使用https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz下载下来的tar包进行解压，博主解压在家目录下（/root） tar -zxf hadoop-3.1.2.tar.gz -C /root/ 然后我们开始配置环境变量 vi /etc/profile export JAVA_HOME=/usr/java/default export HADOOP_HOME=/root/hadoop export PATH=/usr/local/mysql/bin:/usr/local/mysql/lib:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 配置完毕之后，记得使用source /etc/profile才生效哦 然后我们使用下面命令查看是否生效，生效会有hadoop的具体信息 hadoop version 接下来我们开始配置hadoop的配置文件，配置文件在/hadoop_home/etc/hadoop下 core-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;file:/root/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; hdfs-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/root/hdfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:/root/data&lt;/value&gt; &lt;/property&gt; &lt;!-- 副本系数，代表数据会存储几份,我们这里就设定1份即可 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; mapred-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; yarn-site.xml: &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;!-- 这里使用hadoop classpath查看以下路径，如果这里不配置，可能会报Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster错误 --&gt; &lt;property&gt; &lt;name&gt;yarn.application.classpath&lt;/name&gt; &lt;value&gt;输入刚才返回的Hadoop classpath路径,记得以逗号分割&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 修改slaves(3.x修改为workers): master node1 node2 将修改的文件发送的另外的节点覆盖：rsync -av /root/hadoop/etc/ node2:/root/hadoop/etc/ 如果出现以下错误： [root@master sbin]# ./start-dfs.sh Starting namenodes on [master] ERROR: Attempting to operate on hdfs namenode as root ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation. Starting datanodes ERROR: Attempting to operate on hdfs datanode as root ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation. Starting secondary namenodes [slave1] ERROR: Attempting to operate on hdfs secondarynamenode as root ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation. 在/hadoop/sbin路径下： 将start-dfs.sh，stop-dfs.sh两个文件顶部添加以下参数 #!/usr/bin/env bash HDFS_DATANODE_USER=root HADOOP_SECURE_DN_USER=hdfs HDFS_NAMENODE_USER=root HDFS_SECONDARYNAMENODE_USER=root 还有，start-yarn.sh，stop-yarn.sh顶部也需添加以下： #!/usr/bin/env bash YARN_RESOURCEMANAGER_USER=root HADOOP_SECURE_DN_USER=yarn YARN_NODEMANAGER_USER=root hadoop3.x端口号已经更改，如下： The patch updates the HDFS default HTTP/RPC ports to non-ephemeral ports. The changes are listed below: Namenode ports: 50470 --&gt; 9871, 50070 --&gt; 9870, 8020 --&gt; 9820 Secondary NN ports: 50091 --&gt; 9869, 50090 --&gt; 9868 Datanode ports: 50020 --&gt; 9867, 50010 --&gt; 9866, 50475 --&gt; 9865, 50075 --&gt; 9864 启动之后访问(记得安全组9870与8088端口要开放哦)： http://你的ip:9870 http://你的ip:8088/cluster 推荐一些阿里云搭建的博客 1.https://blog.csdn.net/zhangvalue/article/details/80870160 2.https://blog.csdn.net/bqw18744018044/article/details/79103931 3.:https://blog.csdn.net/a1135497143/article/details/81915489","@type":"BlogPosting","url":"https://mlh.app/2019/05/04/729921.html","headline":"大数据系列（一）hadoop生态圈基础知识后续之分布式hadoop环境搭建","dateModified":"2019-05-04T00:00:00+08:00","datePublished":"2019-05-04T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/04/729921.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>大数据系列（一）hadoop生态圈基础知识后续之分布式hadoop环境搭建</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p></p>
  <div class="toc">
   <h3>目录</h3>
   <ul>
    <li><a href="#_1" rel="nofollow">环境介绍须知</a></li>
    <li><a href="#_7" rel="nofollow">前置工作</a></li>
    <li><a href="#_14" rel="nofollow">集群搭建</a></li>
    <ul>
     <li><a href="#_15" rel="nofollow">集群规划</a></li>
     <li><a href="#HOSTS_28" rel="nofollow">配置HOSTS文件</a></li>
     <li><a href="#SSH_40" rel="nofollow">配置免密码SSH链接</a></li>
     <li><a href="#hadoop_59" rel="nofollow">配置hadoop</a></li>
    </ul>
    <li><a href="#_198" rel="nofollow">推荐一些阿里云搭建的博客</a></li>
   </ul>
  </div>
  <p></p> 
  <h1><a id="_1"></a>环境介绍须知</h1> 
  <p>我们按照3台服务器数量来搭建，1个namenode，2个databode，那么我们需要以下环境：</p> 
  <ul> 
   <li>三台linux系统的服务器，博主使用的是阿里云centos7</li> 
   <li>jdk8，请大家自行下载，这边博客不在讲述</li> 
   <li>hadoop3.x的tar包</li> 
   <li><em>文中出现的hadoop_home皆为你自己安装的hadoop的路径</em></li> 
  </ul> 
  <h1><a id="_7"></a>前置工作</h1> 
  <ul> 
   <li>首先我们创建三台阿里云，当然如果你提前配置好vpc，就可以指定ip（关于基于云服务做网络架构设计，配合应用架构搭建企业级的业务集群，博主后期会更新相关架构文档，有兴趣的小伙伴可以等一等哦），如果没有VPC，那么直接使用ipv4（仅测试或者自己玩的环境）</li> 
   <li>登陆官网下载hadoop3.x的tar包，传送门：<a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz%EF%BC%8C" rel="nofollow">https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz，</a> 直接在服务器上wget即可</li> 
   <li>jdk下载（不做介绍），请小伙伴自行安装</li> 
   <li>规划网络与服务器节点</li> 
   <li>规划数据存储位置</li> 
   <li>规划各个应用的用户与角色（因为这是非生产，用来学习，博主直接root用户走起来）</li> 
  </ul> 
  <h1><a id="_14"></a>集群搭建</h1> 
  <h2><a id="_15"></a>集群规划</h2> 
  <p>我们前面说，我们用三台来搭建分布式集群，那么我们对服务器需要提前做些规划，网络划分记得是内网哦。</p> 
  <blockquote> 
   <p>master服务器，是namenode节点，ip为：10.151.64.57<br> node1服务器，是datanode1节点，ip为：10.151.64.60<br> node2服务器，是datanode2节点，ip为：10.151.64.59</p> 
  </blockquote> 
  <p>接下来，我们创建一些目录，作为临时数据、元数据等数据存储的地方，方便后续观察，因为这是非生产，所以博主 比较随意，直接在根目录下创建了（<strong>mkdir tmp hdfs hdfs/data hdfs/name</strong>）：</p> 
  <blockquote> 
   <p>目录/tmp，用来存储临时生成的文件<br> 目录/hdfs，用来存储集群数据<br> 目录hdfs/data，用来存储真正的数据<br> 目录hdfs/name，用来存储文件系统元数据</p> 
  </blockquote> 
  <h2><a id="HOSTS_28"></a>配置HOSTS文件</h2> 
  <p>为了更方便通信，在各个配置文件中无需写ip，我们直接在namenode节点上配置所有相关节点的host，然后统一覆盖所有节点即可：</p> 
  <p><strong>vi /etc/hosts</strong></p> 
  <pre><code>10.151.64.57 master
10.151.64.60 node1
10.151.64.59 node2
</code></pre> 
  <h2><a id="SSH_40"></a>配置免密码SSH链接</h2> 
  <p>为了让namenode节点可以免密码直接链接各个datanode节点，我们做如下操作：</p> 
  <p>利用下面命令生成密钥，在生成的过程中一直按回车就可以：</p> 
  <blockquote> 
   <p>ssh-keygen</p> 
  </blockquote> 
  <p>将密钥加入到可信任列表，可以使用下面命令，也可以直接将id_rsa.pub内容复制在authorized_keys中：</p> 
  <blockquote> 
   <p>cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</p> 
  </blockquote> 
  <p>将id_rsa.pub拷贝到node1节点的authorized_keys中，这样就默认node1是信任master服务器的</p> 
  <blockquote> 
   <p>或者你可以使用scp将id_rsa.pub 拷贝在node1节点（需要输入node1连接密码），然后在使用 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys命令添加信任</p> 
  </blockquote> 
  <p>在master节点上，使用ssh node1命令，如果可以正常登陆node1，则代表免密码配置成功</p> 
  <blockquote> 
   <p>ssh node1</p> 
  </blockquote> 
  <p>备注：你可以利用node1做为镜像服务器，如果环境配置好之后，直接打镜像，然后后续在添加服务器，利用这个镜像创建服务器即可，然后通过namenode配置hosts，将所有配置全部发送给所有节点进行覆盖。</p> 
  <h2><a id="hadoop_59"></a>配置hadoop</h2> 
  <p>首先我们使用https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz下载下来的tar包进行解压，博主解压在家目录下（/root）</p> 
  <pre><code>tar -zxf hadoop-3.1.2.tar.gz -C /root/
</code></pre> 
  <p>然后我们开始配置环境变量</p> 
  <p>vi /etc/profile</p> 
  <pre><code>export JAVA_HOME=/usr/java/default
export HADOOP_HOME=/root/hadoop
export PATH=/usr/local/mysql/bin:/usr/local/mysql/lib:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
</code></pre> 
  <p>配置完毕之后，记得使用<strong>source /etc/profile</strong>才生效哦<br> 然后我们使用下面命令查看是否生效，生效会有hadoop的具体信息</p> 
  <blockquote> 
   <p>hadoop version</p> 
  </blockquote> 
  <p>接下来我们开始配置hadoop的配置文件，配置文件在/hadoop_home/etc/hadoop下</p> 
  <p>core-site.xml:</p> 
  <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://master:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;file:/root/tmp&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
  <p>hdfs-site.xml:</p> 
  <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;file:/root/hdfs/name&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;file:/root/data&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 副本系数，代表数据会存储几份,我们这里就设定1份即可 --&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.permissions&lt;/name&gt;
        &lt;value&gt;false&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
  <p>mapred-site.xml:</p> 
  <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
  <p>yarn-site.xml:</p> 
  <pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
        &lt;value&gt;master&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;
        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;
    &lt;/property&gt;
    &lt;!-- 这里使用hadoop classpath查看以下路径，如果这里不配置，可能会报Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster错误 --&gt;
     &lt;property&gt;
        &lt;name&gt;yarn.application.classpath&lt;/name&gt;
        &lt;value&gt;输入刚才返回的Hadoop classpath路径,记得以逗号分割&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre> 
  <p>修改slaves(3.x修改为workers):</p> 
  <pre><code>master
node1
node2
</code></pre> 
  <p>将修改的文件发送的另外的节点覆盖：<em><strong>rsync -av /root/hadoop/etc/ node2:/root/hadoop/etc/</strong></em></p> 
  <p>如果出现以下错误：</p> 
  <blockquote> 
   <p>[root@master sbin]# ./start-dfs.sh<br> Starting namenodes on [master]<br> ERROR: Attempting to operate on hdfs namenode as root<br> ERROR: but there is no HDFS_NAMENODE_USER defined. Aborting operation.<br> Starting datanodes<br> ERROR: Attempting to operate on hdfs datanode as root<br> ERROR: but there is no HDFS_DATANODE_USER defined. Aborting operation.<br> Starting secondary namenodes [slave1]<br> ERROR: Attempting to operate on hdfs secondarynamenode as root<br> ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined. Aborting operation.</p> 
  </blockquote> 
  <p>在/hadoop/sbin路径下：<br> <a href="http://xn--start-dfs-kj5q.sh" rel="nofollow">将start-dfs.sh</a>，stop-dfs.sh两个文件顶部添加以下参数</p> 
  <pre><code>#!/usr/bin/env bash
HDFS_DATANODE_USER=root
HADOOP_SECURE_DN_USER=hdfs
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
</code></pre> 
  <p>还有，<a href="http://start-yarn.sh" rel="nofollow">start-yarn.sh</a>，stop-yarn.sh顶部也需添加以下：</p> 
  <pre><code>#!/usr/bin/env bash
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root
</code></pre> 
  <p>hadoop3.x端口号已经更改，如下：</p> 
  <blockquote> 
   <p>The patch updates the HDFS default HTTP/RPC ports to non-ephemeral ports. The changes are listed below:<br> Namenode ports: 50470 --&gt; 9871, 50070 --&gt; 9870, 8020 --&gt; 9820<br> Secondary NN ports: 50091 --&gt; 9869, 50090 --&gt; 9868<br> Datanode ports: 50020 --&gt; 9867, 50010 --&gt; 9866, 50475 --&gt; 9865, 50075 --&gt; 9864</p> 
  </blockquote> 
  <p>启动之后访问(记得安全组9870与8088端口要开放哦)：</p> 
  <blockquote> 
   <p><a href="http://xn--ip-0p3cm89l:9870" rel="nofollow">http://你的ip:9870</a><br> <a href="http://xn--ip-0p3cm89l:8088/cluster" rel="nofollow">http://你的ip:8088/cluster</a></p> 
  </blockquote> 
  <h1><a id="_198"></a>推荐一些阿里云搭建的博客</h1> 
  <p>1.<a href="https://blog.csdn.net/zhangvalue/article/details/80870160" rel="nofollow">https://blog.csdn.net/zhangvalue/article/details/80870160</a><br> 2.<a href="https://blog.csdn.net/bqw18744018044/article/details/79103931" rel="nofollow">https://blog.csdn.net/bqw18744018044/article/details/79103931</a><br> 3.:<a href="https://blog.csdn.net/a1135497143/article/details/81915489" rel="nofollow">https://blog.csdn.net/a1135497143/article/details/81915489</a></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?aee162ba0c05d8e682055e28ff964fa2";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
