<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>mmdetection源码阅读笔记（1）–创建网络 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="mmdetection源码阅读笔记（1）–创建网络" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="之前写了mmdetection的模型创建部分，这次以cascade rcnn为例具体看下网络是怎么构建的。 讲网络之前，要先看看配置文件，这里我主要结合官方提供的cascade_mask_rcnn_r50_fpn_1x.py来看具体实现，关于这些配置项具体的含义可以看mmdetection的configs中的各项参数具体解释 创建cascade rcnn网络 先找到cascade rcnn的定义文件mmdet/models/detectors/cascade_rcnn.py 这里我将cascade rcnn网络的创建过程主要分为5个部分。 backbone neck rpn_head bbox_head mask_head backbone cascade rcnn的backb选择的是res50，创建backbone的方式和之前一样，也是将支持的模型注册到registry中，只后再通过builder进行实例化。 resnet的定义文件在mmdet/models/backbones/resnet.py def forward(self, x): x = self.conv1(x) x = self.norm1(x) x = self.relu(x) x = self.maxpool(x) outs = [] for i, layer_name in enumerate(self.res_layers): res_layer = getattr(self, layer_name) x = res_layer(x) if i in self.out_indices: outs.append(x) if len(outs) == 1: return outs[0] else: return tuple(outs) 在forward中outs取的是多stage的输出，先拼成一个list在转成tuple，取哪些stage是根据config中的out_indices。 model = dict( type=&#39;CascadeRCNN&#39;, num_stages=3, pretrained=&#39;modelzoo://resnet50&#39;, backbone=dict( type=&#39;ResNet&#39;, depth=50, num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=1, style=&#39;pytorch&#39;), backbone是4stage,取了所有的stage。 backbone的主要作用就是提取图像特征。 neck 这部分主要是实现FPN,FPN讲解 先看下config文件中与FPN相关的部分 neck=dict( type=&#39;FPN&#39;, in_channels=[256, 512, 1024, 2048], out_channels=256, num_outs=5), in_channels与之前backbone的输出相匹配，out_channels为输出纬度。 FPN定义在mmdet/models/necks/fpn.py,其中__init__.py中 for i in range(self.start_level, self.backbone_end_level): l_conv = ConvModule( in_channels[i], out_channels, 1, normalize=normalize, bias=self.with_bias, activation=self.activation, inplace=False) fpn_conv = ConvModule( out_channels, out_channels, 3, padding=1, normalize=normalize, bias=self.with_bias, activation=self.activation, inplace=False) self.lateral_convs.append(l_conv) self.fpn_convs.append(fpn_conv) 这里的self.start_level为0 self.backbone_end_level为len(in_channels)，也就是说这里定义的lateral_convs和fpn_convs的长度和输入的长度是相等的。 这里可以这样理解，之前backbone的输出是多层的特征图，这里对每层的输出用不同的ConvModule来处理，再统一channel数，就完成了高低层特征的融合。可能比较绕，结合代码就比较好理解了。 下面是forward函数部分代码。 # build laterals laterals = [ lateral_conv(inputs[i + self.start_level]) for i, lateral_conv in enumerate(self.lateral_convs) ] # part 1: from original levels outs = [ self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels) ] 其实这部分也可以看成是在提取特征，到下面RPN部分就真正涉及到目标检测了。 RPN HEAD cascade rcnn的rpn_head乍一看感觉还挺简单的，因为这部分主要就两个网络。主要涉及到两个文件mmdet/models/anchor_head/anchor_head.py和mmdet/models/anchor_head/rpn_head.py后者是前者的子类。 先是config相关项 rpn_head=dict( type=&#39;RPNHead&#39;, in_channels=256, feat_channels=256, anchor_scales=[8], anchor_ratios=[0.5, 1.0, 2.0], anchor_strides=[4, 8, 16, 32, 64], target_means=[.0, .0, .0, .0], target_stds=[1.0, 1.0, 1.0, 1.0], use_sigmoid_cls=True), rpn_head的主要实现如下 #定义网络 def _init_layers(self): self.rpn_conv = nn.Conv2d( self.in_channels, self.feat_channels, 3, padding=1) self.rpn_cls = nn.Conv2d(self.feat_channels, self.num_anchors * self.cls_out_channels, 1) self.rpn_reg = nn.Conv2d(self.feat_channels, self.num_anchors * 4, 1) #forward def forward_single(self, x): x = self.rpn_conv(x) x = F.relu(x, inplace=True) rpn_cls_score = self.rpn_cls(x) rpn_bbox_pred = self.rpn_reg(x) return rpn_cls_score, rpn_bbox_pred 很简单，就只有两个网络，判断是否是前景(rpn_cls)，预测框的修改值(rpn_reg)。并且其中self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)。 但是RPN的目标是得到候选框，所以这里就还要用到anchor_head.py中的另一个函数get_bboxs() def get_bboxes(self, cls_scores, bbox_preds, img_metas, cfg, rescale=False): assert len(cls_scores) == len(bbox_preds) num_levels = len(cls_scores) mlvl_anchors = [ self.anchor_generators[i].grid_anchors(cls_scores[i].size()[-2:], self.anchor_strides[i]) for i in range(num_levels) ] result_list = [] for img_id in range(len(img_metas)): cls_score_list = [ cls_scores[i][img_id].detach() for i in range(num_levels) ] bbox_pred_list = [ bbox_preds[i][img_id].detach() for i in range(num_levels) ] img_shape = img_metas[img_id][&#39;img_shape&#39;] scale_factor = img_metas[img_id][&#39;scale_factor&#39;] proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, mlvl_anchors, img_shape, scale_factor, cfg, rescale) result_list.append(proposals) return result_list 在这里先通过self.anchor_generators[i].grid_anchors()这个函数取到所有的anchor_boxs,再通过self.get_bboxes_single()根据之前rpn的结果获取到候选框(proposal boxs)。 在self.get_bboxes_single()中，先在每个尺度上取2000个anchor出来，concat到一起作为该图像的anchor，对这些anchor boxs作nms(thr=0.7)就得到了所需的候选框。 这部分还有他的loss比较复杂,就放到之后写loss的时候在一起写。 assigners and samplers 上一步rpn输出了一堆候选框，但是在将这些候选框拿去训练之前还需要分为正负样本。assigners就是完成这个工作的。 cascade_rcnn默认使用的是MaxIoUAssigner定义在mmdet/core/bbox/assigners/max_iou_assigner.py主要用到的是assign() def assign(self, bboxes, gt_bboxes, gt_bboxes_ignore=None, gt_labels=None): &quot;&quot;&quot;Assign gt to bboxes. This method assign a gt bbox to every bbox (proposal/anchor), each bbox will be assigned with -1, 0, or a positive number. -1 means don&#39;t care, 0 means negative sample, positive number is the index (1-based) of assigned gt. The assignment is done in following steps, the order matters. 1. assign every bbox to -1 2. assign proposals whose iou with all gts &lt; neg_iou_thr to 0 3. for each bbox, if the iou with its nearest gt &gt;= pos_iou_thr, assign it to that bbox 4. for each gt bbox, assign its nearest proposals (may be more than one) to itself Args: bboxes (Tensor): Bounding boxes to be assigned, shape(n, 4). gt_bboxes (Tensor): Groundtruth boxes, shape (k, 4). gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are labelled as `ignored`, e.g., crowd boxes in COCO. gt_labels (Tensor, optional): Label of gt_bboxes, shape (k, ). Returns: :obj:`AssignResult`: The assign result. &quot;&quot;&quot; if bboxes.shape[0] == 0 or gt_bboxes.shape[0] == 0: raise ValueError(&#39;No gt or bboxes&#39;) bboxes = bboxes[:, :4] overlaps = bbox_overlaps(gt_bboxes, bboxes) if (self.ignore_iof_thr &gt; 0) and (gt_bboxes_ignore is not None) and ( gt_bboxes_ignore.numel() &gt; 0): if self.ignore_wrt_candidates: ignore_overlaps = bbox_overlaps( bboxes, gt_bboxes_ignore, mode=&#39;iof&#39;) ignore_max_overlaps, _ = ignore_overlaps.max(dim=1) else: ignore_overlaps = bbox_overlaps( gt_bboxes_ignore, bboxes, mode=&#39;iof&#39;) ignore_max_overlaps, _ = ignore_overlaps.max(dim=0) overlaps[:, ignore_max_overlaps &gt; self.ignore_iof_thr] = -1 assign_result = self.assign_wrt_overlaps(overlaps, gt_labels) return assign_result 将proposal分为正负样本过后，通过sampler对这些proposal进行采样得到sampler_result进行训练。 cascade_rcnn默认使用的是RandomSampler定义在mmdet/core/bbox/sampler/random_sampler.py @staticmethod def random_choice(gallery, num): &quot;&quot;&quot;Random select some elements from the gallery. It seems that Pytorch&#39;s implementation is slower than numpy so we use numpy to randperm the indices. &quot;&quot;&quot; assert len(gallery) &gt;= num if isinstance(gallery, list): gallery = np.array(gallery) cands = np.arange(len(gallery)) np.random.shuffle(cands) rand_inds = cands[:num] if not isinstance(gallery, np.ndarray): rand_inds = torch.from_numpy(rand_inds).long().to(gallery.device) return gallery[rand_inds] def _sample_pos(self, assign_result, num_expected, **kwargs): &quot;&quot;&quot;Randomly sample some positive samples.&quot;&quot;&quot; pos_inds = torch.nonzero(assign_result.gt_inds &gt; 0) if pos_inds.numel() != 0: pos_inds = pos_inds.squeeze(1) if pos_inds.numel() &lt;= num_expected: return pos_inds else: return self.random_choice(pos_inds, num_expected) def _sample_neg(self, assign_result, num_expected, **kwargs): &quot;&quot;&quot;Randomly sample some negative samples.&quot;&quot;&quot; neg_inds = torch.nonzero(assign_result.gt_inds == 0) if neg_inds.numel() != 0: neg_inds = neg_inds.squeeze(1) if len(neg_inds) &lt;= num_expected: return neg_inds else: return self.random_choice(neg_inds, num_expected) 重写了两个sample函数供父类调用。 主要用到的是其父类mmdet/core/bbox/sampler/base_sampler.py定义的sample def sample(self, assign_result, bboxes, gt_bboxes, gt_labels=None, **kwargs): &quot;&quot;&quot;Sample positive and negative bboxes. This is a simple implementation of bbox sampling given candidates, assigning results and ground truth bboxes. Args: assign_result (:obj:`AssignResult`): Bbox assigning results. bboxes (Tensor): Boxes to be sampled from. gt_bboxes (Tensor): Ground truth bboxes. gt_labels (Tensor, optional): Class labels of ground truth bboxes. Returns: :obj:`SamplingResult`: Sampling result. &quot;&quot;&quot; bboxes = bboxes[:, :4] gt_flags = bboxes.new_zeros((bboxes.shape[0], ), dtype=torch.uint8) if self.add_gt_as_proposals: bboxes = torch.cat([gt_bboxes, bboxes], dim=0) assign_result.add_gt_(gt_labels) gt_ones = bboxes.new_ones(gt_bboxes.shape[0], dtype=torch.uint8) gt_flags = torch.cat([gt_ones, gt_flags]) num_expected_pos = int(self.num * self.pos_fraction) pos_inds = self.pos_sampler._sample_pos( assign_result, num_expected_pos, bboxes=bboxes, **kwargs) # We found that sampled indices have duplicated items occasionally. # (may be a bug of PyTorch) pos_inds = pos_inds.unique() num_sampled_pos = pos_inds.numel() num_expected_neg = self.num - num_sampled_pos if self.neg_pos_ub &gt;= 0: _pos = max(1, num_sampled_pos) neg_upper_bound = int(self.neg_pos_ub * _pos) if num_expected_neg &gt; neg_upper_bound: num_expected_neg = neg_upper_bound neg_inds = self.neg_sampler._sample_neg( assign_result, num_expected_neg, bboxes=bboxes, **kwargs) neg_inds = neg_inds.unique() return SamplingResult(pos_inds, neg_inds, bboxes, gt_bboxes, assign_result, gt_flags) 现在bbox已经处理好了，之后就是将这些框分别送到bbox head和mask head了。 bbox head 当然之前得到的那些框还不能直接送到bbox head,在此之前还要做一次RoI Pooling,将不同大小的框映射成固定大小。 具体定义在mmdet/models/roi_extractors/single_level.py def forward(self, feats, rois): if len(feats) == 1: return self.roi_layers[0](feats[0], rois) out_size = self.roi_layers[0].out_size num_levels = len(feats) target_lvls = self.map_roi_levels(rois, num_levels) roi_feats = torch.cuda.FloatTensor(rois.size()[0], self.out_channels, out_size, out_size).fill_(0) for i in range(num_levels): inds = target_lvls == i if inds.any(): rois_ = rois[inds, :] roi_feats_t = self.roi_layers[i](feats[i], rois_) roi_feats[inds] += roi_feats_t return roi_feats 这里的roi_layers用的是RoIAlign,RoI的结果就可以送到bbox head了。 bbox head部分和之前的rpn部分的操作差不多，主要是针对每个框进行分类和坐标修正。之前rpn分为前景和背景两类，这里分为N+1类(实际类别 + 背景)。具体代码在mmdet/models/bbox_head/convfc_bbox_head.py def forward(self, x): # shared part if self.num_shared_convs &gt; 0: for conv in self.shared_convs: x = conv(x) if self.num_shared_fcs &gt; 0: if self.with_avg_pool: x = self.avg_pool(x) x = x.view(x.size(0), -1) for fc in self.shared_fcs: x = self.relu(fc(x)) # separate branches x_cls = x x_reg = x for conv in self.cls_convs: x_cls = conv(x_cls) if x_cls.dim() &gt; 2: if self.with_avg_pool: x_cls = self.avg_pool(x_cls) x_cls = x_cls.view(x_cls.size(0), -1) for fc in self.cls_fcs: x_cls = self.relu(fc(x_cls)) for conv in self.reg_convs: x_reg = conv(x_reg) if x_reg.dim() &gt; 2: if self.with_avg_pool: x_reg = self.avg_pool(x_reg) x_reg = x_reg.view(x_reg.size(0), -1) for fc in self.reg_fcs: x_reg = self.relu(fc(x_reg)) cls_score = self.fc_cls(x_cls) if self.with_cls else None bbox_pred = self.fc_reg(x_reg) if self.with_reg else None return cls_score, bbox_pred forward的输出就是框的分类score和坐标。 之后再通过这两个结果去计算bbox_loss,这个也放到之后在写。 下面就是与 bbox head平行的另一个分支mask head了。 mask head mask 部分的流程和bbox部分相同，也是先对之前的候选框先做一次RoI Pooling，这里的RoI与之前bbox网络都一样只是部分参数不同。 具体定义在mmdet/models/mask_heads/fcn_mask_head.py def forward(self, x): for conv in self.convs: x = conv(x) if self.upsample is not None: x = self.upsample(x) if self.upsample_method == &#39;deconv&#39;: x = self.relu(x) mask_pred = self.conv_logits(x) return mask_pred forward的输出就是每个像素点的分类值，之后也是通过这个结果去计算mask loss。 在bbox head 和这部分forward的输出结果都不是测试阶段的最终结果，还需要进行其他操作才能得到测试结果。这部分之后写test的时候再写。 小结 这篇主要写了mmdetection中cascade_rcnn的网络创建过程，之前想的是慢慢抠细节，争取把每部分的细节都写了，但是实际看的时候还是觉得太复杂了，就先把整体流程写了一遍，相当于把整体骨架写了。准备之后把loss和测试部分写完了，在慢慢来抠每个部分的细节。" />
<meta property="og:description" content="之前写了mmdetection的模型创建部分，这次以cascade rcnn为例具体看下网络是怎么构建的。 讲网络之前，要先看看配置文件，这里我主要结合官方提供的cascade_mask_rcnn_r50_fpn_1x.py来看具体实现，关于这些配置项具体的含义可以看mmdetection的configs中的各项参数具体解释 创建cascade rcnn网络 先找到cascade rcnn的定义文件mmdet/models/detectors/cascade_rcnn.py 这里我将cascade rcnn网络的创建过程主要分为5个部分。 backbone neck rpn_head bbox_head mask_head backbone cascade rcnn的backb选择的是res50，创建backbone的方式和之前一样，也是将支持的模型注册到registry中，只后再通过builder进行实例化。 resnet的定义文件在mmdet/models/backbones/resnet.py def forward(self, x): x = self.conv1(x) x = self.norm1(x) x = self.relu(x) x = self.maxpool(x) outs = [] for i, layer_name in enumerate(self.res_layers): res_layer = getattr(self, layer_name) x = res_layer(x) if i in self.out_indices: outs.append(x) if len(outs) == 1: return outs[0] else: return tuple(outs) 在forward中outs取的是多stage的输出，先拼成一个list在转成tuple，取哪些stage是根据config中的out_indices。 model = dict( type=&#39;CascadeRCNN&#39;, num_stages=3, pretrained=&#39;modelzoo://resnet50&#39;, backbone=dict( type=&#39;ResNet&#39;, depth=50, num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=1, style=&#39;pytorch&#39;), backbone是4stage,取了所有的stage。 backbone的主要作用就是提取图像特征。 neck 这部分主要是实现FPN,FPN讲解 先看下config文件中与FPN相关的部分 neck=dict( type=&#39;FPN&#39;, in_channels=[256, 512, 1024, 2048], out_channels=256, num_outs=5), in_channels与之前backbone的输出相匹配，out_channels为输出纬度。 FPN定义在mmdet/models/necks/fpn.py,其中__init__.py中 for i in range(self.start_level, self.backbone_end_level): l_conv = ConvModule( in_channels[i], out_channels, 1, normalize=normalize, bias=self.with_bias, activation=self.activation, inplace=False) fpn_conv = ConvModule( out_channels, out_channels, 3, padding=1, normalize=normalize, bias=self.with_bias, activation=self.activation, inplace=False) self.lateral_convs.append(l_conv) self.fpn_convs.append(fpn_conv) 这里的self.start_level为0 self.backbone_end_level为len(in_channels)，也就是说这里定义的lateral_convs和fpn_convs的长度和输入的长度是相等的。 这里可以这样理解，之前backbone的输出是多层的特征图，这里对每层的输出用不同的ConvModule来处理，再统一channel数，就完成了高低层特征的融合。可能比较绕，结合代码就比较好理解了。 下面是forward函数部分代码。 # build laterals laterals = [ lateral_conv(inputs[i + self.start_level]) for i, lateral_conv in enumerate(self.lateral_convs) ] # part 1: from original levels outs = [ self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels) ] 其实这部分也可以看成是在提取特征，到下面RPN部分就真正涉及到目标检测了。 RPN HEAD cascade rcnn的rpn_head乍一看感觉还挺简单的，因为这部分主要就两个网络。主要涉及到两个文件mmdet/models/anchor_head/anchor_head.py和mmdet/models/anchor_head/rpn_head.py后者是前者的子类。 先是config相关项 rpn_head=dict( type=&#39;RPNHead&#39;, in_channels=256, feat_channels=256, anchor_scales=[8], anchor_ratios=[0.5, 1.0, 2.0], anchor_strides=[4, 8, 16, 32, 64], target_means=[.0, .0, .0, .0], target_stds=[1.0, 1.0, 1.0, 1.0], use_sigmoid_cls=True), rpn_head的主要实现如下 #定义网络 def _init_layers(self): self.rpn_conv = nn.Conv2d( self.in_channels, self.feat_channels, 3, padding=1) self.rpn_cls = nn.Conv2d(self.feat_channels, self.num_anchors * self.cls_out_channels, 1) self.rpn_reg = nn.Conv2d(self.feat_channels, self.num_anchors * 4, 1) #forward def forward_single(self, x): x = self.rpn_conv(x) x = F.relu(x, inplace=True) rpn_cls_score = self.rpn_cls(x) rpn_bbox_pred = self.rpn_reg(x) return rpn_cls_score, rpn_bbox_pred 很简单，就只有两个网络，判断是否是前景(rpn_cls)，预测框的修改值(rpn_reg)。并且其中self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)。 但是RPN的目标是得到候选框，所以这里就还要用到anchor_head.py中的另一个函数get_bboxs() def get_bboxes(self, cls_scores, bbox_preds, img_metas, cfg, rescale=False): assert len(cls_scores) == len(bbox_preds) num_levels = len(cls_scores) mlvl_anchors = [ self.anchor_generators[i].grid_anchors(cls_scores[i].size()[-2:], self.anchor_strides[i]) for i in range(num_levels) ] result_list = [] for img_id in range(len(img_metas)): cls_score_list = [ cls_scores[i][img_id].detach() for i in range(num_levels) ] bbox_pred_list = [ bbox_preds[i][img_id].detach() for i in range(num_levels) ] img_shape = img_metas[img_id][&#39;img_shape&#39;] scale_factor = img_metas[img_id][&#39;scale_factor&#39;] proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, mlvl_anchors, img_shape, scale_factor, cfg, rescale) result_list.append(proposals) return result_list 在这里先通过self.anchor_generators[i].grid_anchors()这个函数取到所有的anchor_boxs,再通过self.get_bboxes_single()根据之前rpn的结果获取到候选框(proposal boxs)。 在self.get_bboxes_single()中，先在每个尺度上取2000个anchor出来，concat到一起作为该图像的anchor，对这些anchor boxs作nms(thr=0.7)就得到了所需的候选框。 这部分还有他的loss比较复杂,就放到之后写loss的时候在一起写。 assigners and samplers 上一步rpn输出了一堆候选框，但是在将这些候选框拿去训练之前还需要分为正负样本。assigners就是完成这个工作的。 cascade_rcnn默认使用的是MaxIoUAssigner定义在mmdet/core/bbox/assigners/max_iou_assigner.py主要用到的是assign() def assign(self, bboxes, gt_bboxes, gt_bboxes_ignore=None, gt_labels=None): &quot;&quot;&quot;Assign gt to bboxes. This method assign a gt bbox to every bbox (proposal/anchor), each bbox will be assigned with -1, 0, or a positive number. -1 means don&#39;t care, 0 means negative sample, positive number is the index (1-based) of assigned gt. The assignment is done in following steps, the order matters. 1. assign every bbox to -1 2. assign proposals whose iou with all gts &lt; neg_iou_thr to 0 3. for each bbox, if the iou with its nearest gt &gt;= pos_iou_thr, assign it to that bbox 4. for each gt bbox, assign its nearest proposals (may be more than one) to itself Args: bboxes (Tensor): Bounding boxes to be assigned, shape(n, 4). gt_bboxes (Tensor): Groundtruth boxes, shape (k, 4). gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are labelled as `ignored`, e.g., crowd boxes in COCO. gt_labels (Tensor, optional): Label of gt_bboxes, shape (k, ). Returns: :obj:`AssignResult`: The assign result. &quot;&quot;&quot; if bboxes.shape[0] == 0 or gt_bboxes.shape[0] == 0: raise ValueError(&#39;No gt or bboxes&#39;) bboxes = bboxes[:, :4] overlaps = bbox_overlaps(gt_bboxes, bboxes) if (self.ignore_iof_thr &gt; 0) and (gt_bboxes_ignore is not None) and ( gt_bboxes_ignore.numel() &gt; 0): if self.ignore_wrt_candidates: ignore_overlaps = bbox_overlaps( bboxes, gt_bboxes_ignore, mode=&#39;iof&#39;) ignore_max_overlaps, _ = ignore_overlaps.max(dim=1) else: ignore_overlaps = bbox_overlaps( gt_bboxes_ignore, bboxes, mode=&#39;iof&#39;) ignore_max_overlaps, _ = ignore_overlaps.max(dim=0) overlaps[:, ignore_max_overlaps &gt; self.ignore_iof_thr] = -1 assign_result = self.assign_wrt_overlaps(overlaps, gt_labels) return assign_result 将proposal分为正负样本过后，通过sampler对这些proposal进行采样得到sampler_result进行训练。 cascade_rcnn默认使用的是RandomSampler定义在mmdet/core/bbox/sampler/random_sampler.py @staticmethod def random_choice(gallery, num): &quot;&quot;&quot;Random select some elements from the gallery. It seems that Pytorch&#39;s implementation is slower than numpy so we use numpy to randperm the indices. &quot;&quot;&quot; assert len(gallery) &gt;= num if isinstance(gallery, list): gallery = np.array(gallery) cands = np.arange(len(gallery)) np.random.shuffle(cands) rand_inds = cands[:num] if not isinstance(gallery, np.ndarray): rand_inds = torch.from_numpy(rand_inds).long().to(gallery.device) return gallery[rand_inds] def _sample_pos(self, assign_result, num_expected, **kwargs): &quot;&quot;&quot;Randomly sample some positive samples.&quot;&quot;&quot; pos_inds = torch.nonzero(assign_result.gt_inds &gt; 0) if pos_inds.numel() != 0: pos_inds = pos_inds.squeeze(1) if pos_inds.numel() &lt;= num_expected: return pos_inds else: return self.random_choice(pos_inds, num_expected) def _sample_neg(self, assign_result, num_expected, **kwargs): &quot;&quot;&quot;Randomly sample some negative samples.&quot;&quot;&quot; neg_inds = torch.nonzero(assign_result.gt_inds == 0) if neg_inds.numel() != 0: neg_inds = neg_inds.squeeze(1) if len(neg_inds) &lt;= num_expected: return neg_inds else: return self.random_choice(neg_inds, num_expected) 重写了两个sample函数供父类调用。 主要用到的是其父类mmdet/core/bbox/sampler/base_sampler.py定义的sample def sample(self, assign_result, bboxes, gt_bboxes, gt_labels=None, **kwargs): &quot;&quot;&quot;Sample positive and negative bboxes. This is a simple implementation of bbox sampling given candidates, assigning results and ground truth bboxes. Args: assign_result (:obj:`AssignResult`): Bbox assigning results. bboxes (Tensor): Boxes to be sampled from. gt_bboxes (Tensor): Ground truth bboxes. gt_labels (Tensor, optional): Class labels of ground truth bboxes. Returns: :obj:`SamplingResult`: Sampling result. &quot;&quot;&quot; bboxes = bboxes[:, :4] gt_flags = bboxes.new_zeros((bboxes.shape[0], ), dtype=torch.uint8) if self.add_gt_as_proposals: bboxes = torch.cat([gt_bboxes, bboxes], dim=0) assign_result.add_gt_(gt_labels) gt_ones = bboxes.new_ones(gt_bboxes.shape[0], dtype=torch.uint8) gt_flags = torch.cat([gt_ones, gt_flags]) num_expected_pos = int(self.num * self.pos_fraction) pos_inds = self.pos_sampler._sample_pos( assign_result, num_expected_pos, bboxes=bboxes, **kwargs) # We found that sampled indices have duplicated items occasionally. # (may be a bug of PyTorch) pos_inds = pos_inds.unique() num_sampled_pos = pos_inds.numel() num_expected_neg = self.num - num_sampled_pos if self.neg_pos_ub &gt;= 0: _pos = max(1, num_sampled_pos) neg_upper_bound = int(self.neg_pos_ub * _pos) if num_expected_neg &gt; neg_upper_bound: num_expected_neg = neg_upper_bound neg_inds = self.neg_sampler._sample_neg( assign_result, num_expected_neg, bboxes=bboxes, **kwargs) neg_inds = neg_inds.unique() return SamplingResult(pos_inds, neg_inds, bboxes, gt_bboxes, assign_result, gt_flags) 现在bbox已经处理好了，之后就是将这些框分别送到bbox head和mask head了。 bbox head 当然之前得到的那些框还不能直接送到bbox head,在此之前还要做一次RoI Pooling,将不同大小的框映射成固定大小。 具体定义在mmdet/models/roi_extractors/single_level.py def forward(self, feats, rois): if len(feats) == 1: return self.roi_layers[0](feats[0], rois) out_size = self.roi_layers[0].out_size num_levels = len(feats) target_lvls = self.map_roi_levels(rois, num_levels) roi_feats = torch.cuda.FloatTensor(rois.size()[0], self.out_channels, out_size, out_size).fill_(0) for i in range(num_levels): inds = target_lvls == i if inds.any(): rois_ = rois[inds, :] roi_feats_t = self.roi_layers[i](feats[i], rois_) roi_feats[inds] += roi_feats_t return roi_feats 这里的roi_layers用的是RoIAlign,RoI的结果就可以送到bbox head了。 bbox head部分和之前的rpn部分的操作差不多，主要是针对每个框进行分类和坐标修正。之前rpn分为前景和背景两类，这里分为N+1类(实际类别 + 背景)。具体代码在mmdet/models/bbox_head/convfc_bbox_head.py def forward(self, x): # shared part if self.num_shared_convs &gt; 0: for conv in self.shared_convs: x = conv(x) if self.num_shared_fcs &gt; 0: if self.with_avg_pool: x = self.avg_pool(x) x = x.view(x.size(0), -1) for fc in self.shared_fcs: x = self.relu(fc(x)) # separate branches x_cls = x x_reg = x for conv in self.cls_convs: x_cls = conv(x_cls) if x_cls.dim() &gt; 2: if self.with_avg_pool: x_cls = self.avg_pool(x_cls) x_cls = x_cls.view(x_cls.size(0), -1) for fc in self.cls_fcs: x_cls = self.relu(fc(x_cls)) for conv in self.reg_convs: x_reg = conv(x_reg) if x_reg.dim() &gt; 2: if self.with_avg_pool: x_reg = self.avg_pool(x_reg) x_reg = x_reg.view(x_reg.size(0), -1) for fc in self.reg_fcs: x_reg = self.relu(fc(x_reg)) cls_score = self.fc_cls(x_cls) if self.with_cls else None bbox_pred = self.fc_reg(x_reg) if self.with_reg else None return cls_score, bbox_pred forward的输出就是框的分类score和坐标。 之后再通过这两个结果去计算bbox_loss,这个也放到之后在写。 下面就是与 bbox head平行的另一个分支mask head了。 mask head mask 部分的流程和bbox部分相同，也是先对之前的候选框先做一次RoI Pooling，这里的RoI与之前bbox网络都一样只是部分参数不同。 具体定义在mmdet/models/mask_heads/fcn_mask_head.py def forward(self, x): for conv in self.convs: x = conv(x) if self.upsample is not None: x = self.upsample(x) if self.upsample_method == &#39;deconv&#39;: x = self.relu(x) mask_pred = self.conv_logits(x) return mask_pred forward的输出就是每个像素点的分类值，之后也是通过这个结果去计算mask loss。 在bbox head 和这部分forward的输出结果都不是测试阶段的最终结果，还需要进行其他操作才能得到测试结果。这部分之后写test的时候再写。 小结 这篇主要写了mmdetection中cascade_rcnn的网络创建过程，之前想的是慢慢抠细节，争取把每部分的细节都写了，但是实际看的时候还是觉得太复杂了，就先把整体流程写了一遍，相当于把整体骨架写了。准备之后把loss和测试部分写完了，在慢慢来抠每个部分的细节。" />
<link rel="canonical" href="https://mlh.app/2019/05/04/729589.html" />
<meta property="og:url" content="https://mlh.app/2019/05/04/729589.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-04T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"之前写了mmdetection的模型创建部分，这次以cascade rcnn为例具体看下网络是怎么构建的。 讲网络之前，要先看看配置文件，这里我主要结合官方提供的cascade_mask_rcnn_r50_fpn_1x.py来看具体实现，关于这些配置项具体的含义可以看mmdetection的configs中的各项参数具体解释 创建cascade rcnn网络 先找到cascade rcnn的定义文件mmdet/models/detectors/cascade_rcnn.py 这里我将cascade rcnn网络的创建过程主要分为5个部分。 backbone neck rpn_head bbox_head mask_head backbone cascade rcnn的backb选择的是res50，创建backbone的方式和之前一样，也是将支持的模型注册到registry中，只后再通过builder进行实例化。 resnet的定义文件在mmdet/models/backbones/resnet.py def forward(self, x): x = self.conv1(x) x = self.norm1(x) x = self.relu(x) x = self.maxpool(x) outs = [] for i, layer_name in enumerate(self.res_layers): res_layer = getattr(self, layer_name) x = res_layer(x) if i in self.out_indices: outs.append(x) if len(outs) == 1: return outs[0] else: return tuple(outs) 在forward中outs取的是多stage的输出，先拼成一个list在转成tuple，取哪些stage是根据config中的out_indices。 model = dict( type=&#39;CascadeRCNN&#39;, num_stages=3, pretrained=&#39;modelzoo://resnet50&#39;, backbone=dict( type=&#39;ResNet&#39;, depth=50, num_stages=4, out_indices=(0, 1, 2, 3), frozen_stages=1, style=&#39;pytorch&#39;), backbone是4stage,取了所有的stage。 backbone的主要作用就是提取图像特征。 neck 这部分主要是实现FPN,FPN讲解 先看下config文件中与FPN相关的部分 neck=dict( type=&#39;FPN&#39;, in_channels=[256, 512, 1024, 2048], out_channels=256, num_outs=5), in_channels与之前backbone的输出相匹配，out_channels为输出纬度。 FPN定义在mmdet/models/necks/fpn.py,其中__init__.py中 for i in range(self.start_level, self.backbone_end_level): l_conv = ConvModule( in_channels[i], out_channels, 1, normalize=normalize, bias=self.with_bias, activation=self.activation, inplace=False) fpn_conv = ConvModule( out_channels, out_channels, 3, padding=1, normalize=normalize, bias=self.with_bias, activation=self.activation, inplace=False) self.lateral_convs.append(l_conv) self.fpn_convs.append(fpn_conv) 这里的self.start_level为0 self.backbone_end_level为len(in_channels)，也就是说这里定义的lateral_convs和fpn_convs的长度和输入的长度是相等的。 这里可以这样理解，之前backbone的输出是多层的特征图，这里对每层的输出用不同的ConvModule来处理，再统一channel数，就完成了高低层特征的融合。可能比较绕，结合代码就比较好理解了。 下面是forward函数部分代码。 # build laterals laterals = [ lateral_conv(inputs[i + self.start_level]) for i, lateral_conv in enumerate(self.lateral_convs) ] # part 1: from original levels outs = [ self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels) ] 其实这部分也可以看成是在提取特征，到下面RPN部分就真正涉及到目标检测了。 RPN HEAD cascade rcnn的rpn_head乍一看感觉还挺简单的，因为这部分主要就两个网络。主要涉及到两个文件mmdet/models/anchor_head/anchor_head.py和mmdet/models/anchor_head/rpn_head.py后者是前者的子类。 先是config相关项 rpn_head=dict( type=&#39;RPNHead&#39;, in_channels=256, feat_channels=256, anchor_scales=[8], anchor_ratios=[0.5, 1.0, 2.0], anchor_strides=[4, 8, 16, 32, 64], target_means=[.0, .0, .0, .0], target_stds=[1.0, 1.0, 1.0, 1.0], use_sigmoid_cls=True), rpn_head的主要实现如下 #定义网络 def _init_layers(self): self.rpn_conv = nn.Conv2d( self.in_channels, self.feat_channels, 3, padding=1) self.rpn_cls = nn.Conv2d(self.feat_channels, self.num_anchors * self.cls_out_channels, 1) self.rpn_reg = nn.Conv2d(self.feat_channels, self.num_anchors * 4, 1) #forward def forward_single(self, x): x = self.rpn_conv(x) x = F.relu(x, inplace=True) rpn_cls_score = self.rpn_cls(x) rpn_bbox_pred = self.rpn_reg(x) return rpn_cls_score, rpn_bbox_pred 很简单，就只有两个网络，判断是否是前景(rpn_cls)，预测框的修改值(rpn_reg)。并且其中self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)。 但是RPN的目标是得到候选框，所以这里就还要用到anchor_head.py中的另一个函数get_bboxs() def get_bboxes(self, cls_scores, bbox_preds, img_metas, cfg, rescale=False): assert len(cls_scores) == len(bbox_preds) num_levels = len(cls_scores) mlvl_anchors = [ self.anchor_generators[i].grid_anchors(cls_scores[i].size()[-2:], self.anchor_strides[i]) for i in range(num_levels) ] result_list = [] for img_id in range(len(img_metas)): cls_score_list = [ cls_scores[i][img_id].detach() for i in range(num_levels) ] bbox_pred_list = [ bbox_preds[i][img_id].detach() for i in range(num_levels) ] img_shape = img_metas[img_id][&#39;img_shape&#39;] scale_factor = img_metas[img_id][&#39;scale_factor&#39;] proposals = self.get_bboxes_single(cls_score_list, bbox_pred_list, mlvl_anchors, img_shape, scale_factor, cfg, rescale) result_list.append(proposals) return result_list 在这里先通过self.anchor_generators[i].grid_anchors()这个函数取到所有的anchor_boxs,再通过self.get_bboxes_single()根据之前rpn的结果获取到候选框(proposal boxs)。 在self.get_bboxes_single()中，先在每个尺度上取2000个anchor出来，concat到一起作为该图像的anchor，对这些anchor boxs作nms(thr=0.7)就得到了所需的候选框。 这部分还有他的loss比较复杂,就放到之后写loss的时候在一起写。 assigners and samplers 上一步rpn输出了一堆候选框，但是在将这些候选框拿去训练之前还需要分为正负样本。assigners就是完成这个工作的。 cascade_rcnn默认使用的是MaxIoUAssigner定义在mmdet/core/bbox/assigners/max_iou_assigner.py主要用到的是assign() def assign(self, bboxes, gt_bboxes, gt_bboxes_ignore=None, gt_labels=None): &quot;&quot;&quot;Assign gt to bboxes. This method assign a gt bbox to every bbox (proposal/anchor), each bbox will be assigned with -1, 0, or a positive number. -1 means don&#39;t care, 0 means negative sample, positive number is the index (1-based) of assigned gt. The assignment is done in following steps, the order matters. 1. assign every bbox to -1 2. assign proposals whose iou with all gts &lt; neg_iou_thr to 0 3. for each bbox, if the iou with its nearest gt &gt;= pos_iou_thr, assign it to that bbox 4. for each gt bbox, assign its nearest proposals (may be more than one) to itself Args: bboxes (Tensor): Bounding boxes to be assigned, shape(n, 4). gt_bboxes (Tensor): Groundtruth boxes, shape (k, 4). gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are labelled as `ignored`, e.g., crowd boxes in COCO. gt_labels (Tensor, optional): Label of gt_bboxes, shape (k, ). Returns: :obj:`AssignResult`: The assign result. &quot;&quot;&quot; if bboxes.shape[0] == 0 or gt_bboxes.shape[0] == 0: raise ValueError(&#39;No gt or bboxes&#39;) bboxes = bboxes[:, :4] overlaps = bbox_overlaps(gt_bboxes, bboxes) if (self.ignore_iof_thr &gt; 0) and (gt_bboxes_ignore is not None) and ( gt_bboxes_ignore.numel() &gt; 0): if self.ignore_wrt_candidates: ignore_overlaps = bbox_overlaps( bboxes, gt_bboxes_ignore, mode=&#39;iof&#39;) ignore_max_overlaps, _ = ignore_overlaps.max(dim=1) else: ignore_overlaps = bbox_overlaps( gt_bboxes_ignore, bboxes, mode=&#39;iof&#39;) ignore_max_overlaps, _ = ignore_overlaps.max(dim=0) overlaps[:, ignore_max_overlaps &gt; self.ignore_iof_thr] = -1 assign_result = self.assign_wrt_overlaps(overlaps, gt_labels) return assign_result 将proposal分为正负样本过后，通过sampler对这些proposal进行采样得到sampler_result进行训练。 cascade_rcnn默认使用的是RandomSampler定义在mmdet/core/bbox/sampler/random_sampler.py @staticmethod def random_choice(gallery, num): &quot;&quot;&quot;Random select some elements from the gallery. It seems that Pytorch&#39;s implementation is slower than numpy so we use numpy to randperm the indices. &quot;&quot;&quot; assert len(gallery) &gt;= num if isinstance(gallery, list): gallery = np.array(gallery) cands = np.arange(len(gallery)) np.random.shuffle(cands) rand_inds = cands[:num] if not isinstance(gallery, np.ndarray): rand_inds = torch.from_numpy(rand_inds).long().to(gallery.device) return gallery[rand_inds] def _sample_pos(self, assign_result, num_expected, **kwargs): &quot;&quot;&quot;Randomly sample some positive samples.&quot;&quot;&quot; pos_inds = torch.nonzero(assign_result.gt_inds &gt; 0) if pos_inds.numel() != 0: pos_inds = pos_inds.squeeze(1) if pos_inds.numel() &lt;= num_expected: return pos_inds else: return self.random_choice(pos_inds, num_expected) def _sample_neg(self, assign_result, num_expected, **kwargs): &quot;&quot;&quot;Randomly sample some negative samples.&quot;&quot;&quot; neg_inds = torch.nonzero(assign_result.gt_inds == 0) if neg_inds.numel() != 0: neg_inds = neg_inds.squeeze(1) if len(neg_inds) &lt;= num_expected: return neg_inds else: return self.random_choice(neg_inds, num_expected) 重写了两个sample函数供父类调用。 主要用到的是其父类mmdet/core/bbox/sampler/base_sampler.py定义的sample def sample(self, assign_result, bboxes, gt_bboxes, gt_labels=None, **kwargs): &quot;&quot;&quot;Sample positive and negative bboxes. This is a simple implementation of bbox sampling given candidates, assigning results and ground truth bboxes. Args: assign_result (:obj:`AssignResult`): Bbox assigning results. bboxes (Tensor): Boxes to be sampled from. gt_bboxes (Tensor): Ground truth bboxes. gt_labels (Tensor, optional): Class labels of ground truth bboxes. Returns: :obj:`SamplingResult`: Sampling result. &quot;&quot;&quot; bboxes = bboxes[:, :4] gt_flags = bboxes.new_zeros((bboxes.shape[0], ), dtype=torch.uint8) if self.add_gt_as_proposals: bboxes = torch.cat([gt_bboxes, bboxes], dim=0) assign_result.add_gt_(gt_labels) gt_ones = bboxes.new_ones(gt_bboxes.shape[0], dtype=torch.uint8) gt_flags = torch.cat([gt_ones, gt_flags]) num_expected_pos = int(self.num * self.pos_fraction) pos_inds = self.pos_sampler._sample_pos( assign_result, num_expected_pos, bboxes=bboxes, **kwargs) # We found that sampled indices have duplicated items occasionally. # (may be a bug of PyTorch) pos_inds = pos_inds.unique() num_sampled_pos = pos_inds.numel() num_expected_neg = self.num - num_sampled_pos if self.neg_pos_ub &gt;= 0: _pos = max(1, num_sampled_pos) neg_upper_bound = int(self.neg_pos_ub * _pos) if num_expected_neg &gt; neg_upper_bound: num_expected_neg = neg_upper_bound neg_inds = self.neg_sampler._sample_neg( assign_result, num_expected_neg, bboxes=bboxes, **kwargs) neg_inds = neg_inds.unique() return SamplingResult(pos_inds, neg_inds, bboxes, gt_bboxes, assign_result, gt_flags) 现在bbox已经处理好了，之后就是将这些框分别送到bbox head和mask head了。 bbox head 当然之前得到的那些框还不能直接送到bbox head,在此之前还要做一次RoI Pooling,将不同大小的框映射成固定大小。 具体定义在mmdet/models/roi_extractors/single_level.py def forward(self, feats, rois): if len(feats) == 1: return self.roi_layers[0](feats[0], rois) out_size = self.roi_layers[0].out_size num_levels = len(feats) target_lvls = self.map_roi_levels(rois, num_levels) roi_feats = torch.cuda.FloatTensor(rois.size()[0], self.out_channels, out_size, out_size).fill_(0) for i in range(num_levels): inds = target_lvls == i if inds.any(): rois_ = rois[inds, :] roi_feats_t = self.roi_layers[i](feats[i], rois_) roi_feats[inds] += roi_feats_t return roi_feats 这里的roi_layers用的是RoIAlign,RoI的结果就可以送到bbox head了。 bbox head部分和之前的rpn部分的操作差不多，主要是针对每个框进行分类和坐标修正。之前rpn分为前景和背景两类，这里分为N+1类(实际类别 + 背景)。具体代码在mmdet/models/bbox_head/convfc_bbox_head.py def forward(self, x): # shared part if self.num_shared_convs &gt; 0: for conv in self.shared_convs: x = conv(x) if self.num_shared_fcs &gt; 0: if self.with_avg_pool: x = self.avg_pool(x) x = x.view(x.size(0), -1) for fc in self.shared_fcs: x = self.relu(fc(x)) # separate branches x_cls = x x_reg = x for conv in self.cls_convs: x_cls = conv(x_cls) if x_cls.dim() &gt; 2: if self.with_avg_pool: x_cls = self.avg_pool(x_cls) x_cls = x_cls.view(x_cls.size(0), -1) for fc in self.cls_fcs: x_cls = self.relu(fc(x_cls)) for conv in self.reg_convs: x_reg = conv(x_reg) if x_reg.dim() &gt; 2: if self.with_avg_pool: x_reg = self.avg_pool(x_reg) x_reg = x_reg.view(x_reg.size(0), -1) for fc in self.reg_fcs: x_reg = self.relu(fc(x_reg)) cls_score = self.fc_cls(x_cls) if self.with_cls else None bbox_pred = self.fc_reg(x_reg) if self.with_reg else None return cls_score, bbox_pred forward的输出就是框的分类score和坐标。 之后再通过这两个结果去计算bbox_loss,这个也放到之后在写。 下面就是与 bbox head平行的另一个分支mask head了。 mask head mask 部分的流程和bbox部分相同，也是先对之前的候选框先做一次RoI Pooling，这里的RoI与之前bbox网络都一样只是部分参数不同。 具体定义在mmdet/models/mask_heads/fcn_mask_head.py def forward(self, x): for conv in self.convs: x = conv(x) if self.upsample is not None: x = self.upsample(x) if self.upsample_method == &#39;deconv&#39;: x = self.relu(x) mask_pred = self.conv_logits(x) return mask_pred forward的输出就是每个像素点的分类值，之后也是通过这个结果去计算mask loss。 在bbox head 和这部分forward的输出结果都不是测试阶段的最终结果，还需要进行其他操作才能得到测试结果。这部分之后写test的时候再写。 小结 这篇主要写了mmdetection中cascade_rcnn的网络创建过程，之前想的是慢慢抠细节，争取把每部分的细节都写了，但是实际看的时候还是觉得太复杂了，就先把整体流程写了一遍，相当于把整体骨架写了。准备之后把loss和测试部分写完了，在慢慢来抠每个部分的细节。","@type":"BlogPosting","url":"https://mlh.app/2019/05/04/729589.html","headline":"mmdetection源码阅读笔记（1）–创建网络","dateModified":"2019-05-04T00:00:00+08:00","datePublished":"2019-05-04T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/04/729589.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>mmdetection源码阅读笔记（1）--创建网络</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <blockquote> 
   <p>之前写了mmdetection的模型创建部分，这次以cascade rcnn为例具体看下网络是怎么构建的。</p> 
  </blockquote> 
  <p>讲网络之前，要先看看配置文件，这里我主要结合官方提供的<code>cascade_mask_rcnn_r50_fpn_1x.py</code>来看具体实现，关于这些配置项具体的含义可以看<a href="https://blog.csdn.net/hajlyx/article/details/85991400" rel="nofollow">mmdetection的configs中的各项参数具体解释</a></p> 
  <h1><a id="cascade_rcnn_4"></a>创建cascade rcnn网络</h1> 
  <p>先找到cascade rcnn的定义文件<code>mmdet/models/detectors/cascade_rcnn.py</code><br> 这里我将cascade rcnn网络的创建过程主要分为5个部分。</p> 
  <ul> 
   <li>backbone</li> 
   <li>neck</li> 
   <li>rpn_head</li> 
   <li>bbox_head</li> 
   <li>mask_head</li> 
  </ul> 
  <h1><a id="backbone_14"></a>backbone</h1> 
  <p>cascade rcnn的backb选择的是<code>res50</code>，创建backbone的方式和之前一样，也是将支持的模型注册到<code>registry</code>中，只后再通过<code>builder</code>进行实例化。<br> <code>resnet</code>的定义文件在<code>mmdet/models/backbones/resnet.py</code></p> 
  <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>conv1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>norm1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>maxpool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        outs <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> i<span class="token punctuation">,</span> layer_name <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>res_layers<span class="token punctuation">)</span><span class="token punctuation">:</span>
            res_layer <span class="token operator">=</span> <span class="token builtin">getattr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> layer_name<span class="token punctuation">)</span>
            x <span class="token operator">=</span> res_layer<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">if</span> i <span class="token keyword">in</span> self<span class="token punctuation">.</span>out_indices<span class="token punctuation">:</span>
                outs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>outs<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> outs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> <span class="token builtin">tuple</span><span class="token punctuation">(</span>outs<span class="token punctuation">)</span>
</code></pre> 
  <p>在<code>forward</code>中outs取的是多stage的输出，先拼成一个list在转成tuple，取哪些stage是根据config中的<code>out_indices</code>。</p> 
  <pre><code class="prism language-python">model <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>
    <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'CascadeRCNN'</span><span class="token punctuation">,</span>
    num_stages<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span>
    pretrained<span class="token operator">=</span><span class="token string">'modelzoo://resnet50'</span><span class="token punctuation">,</span>
    backbone<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'ResNet'</span><span class="token punctuation">,</span>
        depth<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span>
        num_stages<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span>
        out_indices<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        frozen_stages<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
        style<span class="token operator">=</span><span class="token string">'pytorch'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</code></pre> 
  <p>backbone是4stage,取了所有的stage。<br> backbone的主要作用就是提取图像特征。</p> 
  <hr> 
  <h1><a id="neck_53"></a>neck</h1> 
  <p>这部分主要是实现<code>FPN</code>,<a href="https://blog.csdn.net/u014380165/article/details/72890275/" rel="nofollow">FPN讲解</a><br> 先看下config文件中与FPN相关的部分</p> 
  <pre><code class="prism language-python">neck<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'FPN'</span><span class="token punctuation">,</span>
        in_channels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">2048</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        out_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>
        num_outs<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</code></pre> 
  <p><code>in_channels</code>与之前<code>backbone</code>的输出相匹配，<code>out_channels</code>为输出纬度。<br> <code>FPN</code>定义在<code>mmdet/models/necks/fpn.py</code>,其中<code>__init__.py</code>中</p> 
  <pre><code class="prism language-python">        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>start_level<span class="token punctuation">,</span> self<span class="token punctuation">.</span>backbone_end_level<span class="token punctuation">)</span><span class="token punctuation">:</span>
            l_conv <span class="token operator">=</span> ConvModule<span class="token punctuation">(</span>
                in_channels<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>
                out_channels<span class="token punctuation">,</span>
                <span class="token number">1</span><span class="token punctuation">,</span>
                normalize<span class="token operator">=</span>normalize<span class="token punctuation">,</span>
                bias<span class="token operator">=</span>self<span class="token punctuation">.</span>with_bias<span class="token punctuation">,</span>
                activation<span class="token operator">=</span>self<span class="token punctuation">.</span>activation<span class="token punctuation">,</span>
                inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            fpn_conv <span class="token operator">=</span> ConvModule<span class="token punctuation">(</span>
                out_channels<span class="token punctuation">,</span>
                out_channels<span class="token punctuation">,</span>
                <span class="token number">3</span><span class="token punctuation">,</span>
                padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>
                normalize<span class="token operator">=</span>normalize<span class="token punctuation">,</span>
                bias<span class="token operator">=</span>self<span class="token punctuation">.</span>with_bias<span class="token punctuation">,</span>
                activation<span class="token operator">=</span>self<span class="token punctuation">.</span>activation<span class="token punctuation">,</span>
                inplace<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>

            self<span class="token punctuation">.</span>lateral_convs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>l_conv<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>fpn_convs<span class="token punctuation">.</span>append<span class="token punctuation">(</span>fpn_conv<span class="token punctuation">)</span>
</code></pre> 
  <p>这里的<code>self.start_level</code>为0 <code>self.backbone_end_level</code>为<code>len(in_channels)</code>，也就是说这里定义的<code>lateral_convs</code>和<code>fpn_convs</code>的长度和输入的长度是相等的。<br> 这里可以这样理解，之前backbone的输出是多层的特征图，这里对每层的输出用不同的<code>ConvModule</code>来处理，再统一<code>channel</code>数，就完成了高低层特征的融合。可能比较绕，结合代码就比较好理解了。<br> 下面是<code>forward</code>函数部分代码。</p> 
  <pre><code class="prism language-python"><span class="token comment"># build laterals</span>
        laterals <span class="token operator">=</span> <span class="token punctuation">[</span>
            lateral_conv<span class="token punctuation">(</span>inputs<span class="token punctuation">[</span>i <span class="token operator">+</span> self<span class="token punctuation">.</span>start_level<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> i<span class="token punctuation">,</span> lateral_conv <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>lateral_convs<span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
<span class="token comment"># part 1: from original levels</span>
        outs <span class="token operator">=</span> <span class="token punctuation">[</span>
            self<span class="token punctuation">.</span>fpn_convs<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>laterals<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>used_backbone_levels<span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
</code></pre> 
  <p>其实这部分也可以看成是在提取特征，到下面RPN部分就真正涉及到目标检测了。</p> 
  <hr> 
  <h1><a id="RPN_HEAD_107"></a>RPN HEAD</h1> 
  <p><code>cascade rcnn</code>的<code>rpn_head</code>乍一看感觉还挺简单的，因为这部分主要就两个网络。主要涉及到两个文件<code>mmdet/models/anchor_head/anchor_head.py</code>和<code>mmdet/models/anchor_head/rpn_head.py</code>后者是前者的子类。<br> 先是config相关项</p> 
  <pre><code class="prism language-python">rpn_head<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>
        <span class="token builtin">type</span><span class="token operator">=</span><span class="token string">'RPNHead'</span><span class="token punctuation">,</span>
        in_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>
        feat_channels<span class="token operator">=</span><span class="token number">256</span><span class="token punctuation">,</span>
        anchor_scales<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">8</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        anchor_ratios<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">0.5</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">2.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        anchor_strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        target_means<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">.0</span><span class="token punctuation">,</span> <span class="token number">.0</span><span class="token punctuation">,</span> <span class="token number">.0</span><span class="token punctuation">,</span> <span class="token number">.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        target_stds<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        use_sigmoid_cls<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
</code></pre> 
  <p><code>rpn_head</code>的主要实现如下</p> 
  <pre><code class="prism language-python">    <span class="token comment">#定义网络</span>
    <span class="token keyword">def</span> <span class="token function">_init_layers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>rpn_conv <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>in_channels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>feat_channels<span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rpn_cls <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>feat_channels<span class="token punctuation">,</span>
                                 self<span class="token punctuation">.</span>num_anchors <span class="token operator">*</span> self<span class="token punctuation">.</span>cls_out_channels<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rpn_reg <span class="token operator">=</span> nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span>self<span class="token punctuation">.</span>feat_channels<span class="token punctuation">,</span> self<span class="token punctuation">.</span>num_anchors <span class="token operator">*</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token comment">#forward</span>
    <span class="token keyword">def</span> <span class="token function">forward_single</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>rpn_conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        rpn_cls_score <span class="token operator">=</span> self<span class="token punctuation">.</span>rpn_cls<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        rpn_bbox_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>rpn_reg<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> rpn_cls_score<span class="token punctuation">,</span> rpn_bbox_pred
</code></pre> 
  <p>很简单，就只有两个网络，判断是否是前景(rpn_cls)，预测框的修改值(rpn_reg)。并且其中<code>self.num_anchors = len(self.anchor_ratios) * len(self.anchor_scales)</code>。<br> 但是RPN的目标是得到候选框，所以这里就还要用到<code>anchor_head.py</code>中的另一个函数<code>get_bboxs()</code></p> 
  <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">get_bboxes</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> cls_scores<span class="token punctuation">,</span> bbox_preds<span class="token punctuation">,</span> img_metas<span class="token punctuation">,</span> cfg<span class="token punctuation">,</span>
                   rescale<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>cls_scores<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span>bbox_preds<span class="token punctuation">)</span>
        num_levels <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>cls_scores<span class="token punctuation">)</span>

        mlvl_anchors <span class="token operator">=</span> <span class="token punctuation">[</span>
            self<span class="token punctuation">.</span>anchor_generators<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>grid_anchors<span class="token punctuation">(</span>cls_scores<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>anchor_strides<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_levels<span class="token punctuation">)</span>
        <span class="token punctuation">]</span>
        result_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> img_id <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>img_metas<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            cls_score_list <span class="token operator">=</span> <span class="token punctuation">[</span>
                cls_scores<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>img_id<span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_levels<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
            bbox_pred_list <span class="token operator">=</span> <span class="token punctuation">[</span>
                bbox_preds<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">[</span>img_id<span class="token punctuation">]</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_levels<span class="token punctuation">)</span>
            <span class="token punctuation">]</span>
            img_shape <span class="token operator">=</span> img_metas<span class="token punctuation">[</span>img_id<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'img_shape'</span><span class="token punctuation">]</span>
            scale_factor <span class="token operator">=</span> img_metas<span class="token punctuation">[</span>img_id<span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'scale_factor'</span><span class="token punctuation">]</span>
            proposals <span class="token operator">=</span> self<span class="token punctuation">.</span>get_bboxes_single<span class="token punctuation">(</span>cls_score_list<span class="token punctuation">,</span> bbox_pred_list<span class="token punctuation">,</span>
                                               mlvl_anchors<span class="token punctuation">,</span> img_shape<span class="token punctuation">,</span>
                                               scale_factor<span class="token punctuation">,</span> cfg<span class="token punctuation">,</span> rescale<span class="token punctuation">)</span>
            result_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>proposals<span class="token punctuation">)</span>
        <span class="token keyword">return</span> result_list
</code></pre> 
  <p>在这里先通过<code>self.anchor_generators[i].grid_anchors()</code>这个函数取到所有的<code>anchor_boxs</code>,再通过<code>self.get_bboxes_single()</code>根据之前rpn的结果获取到候选框(proposal boxs)。<br> 在<code>self.get_bboxes_single()</code>中，先在每个尺度上取2000个<code>anchor</code>出来，<code>concat</code>到一起作为该图像的anchor，对这些<code>anchor boxs</code>作<code>nms(thr=0.7)</code>就得到了所需的候选框。</p> 
  <p>这部分还有他的<code>loss</code>比较复杂,就放到之后写<code>loss</code>的时候在一起写。</p> 
  <hr> 
  <h1><a id="assigners_and_samplers_175"></a>assigners and samplers</h1> 
  <p>上一步<code>rpn</code>输出了一堆候选框，但是在将这些候选框拿去训练之前还需要分为正负样本。<code>assigners</code>就是完成这个工作的。<br> <code>cascade_rcnn</code>默认使用的是<code>MaxIoUAssigner</code>定义在<code>mmdet/core/bbox/assigners/max_iou_assigner.py</code>主要用到的是<code>assign()</code></p> 
  <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">assign</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> bboxes<span class="token punctuation">,</span> gt_bboxes<span class="token punctuation">,</span> gt_bboxes_ignore<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> gt_labels<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Assign gt to bboxes. This method assign a gt bbox to every bbox (proposal/anchor), each bbox will be assigned with -1, 0, or a positive number. -1 means don't care, 0 means negative sample, positive number is the index (1-based) of assigned gt. The assignment is done in following steps, the order matters. 1. assign every bbox to -1 2. assign proposals whose iou with all gts &lt; neg_iou_thr to 0 3. for each bbox, if the iou with its nearest gt &gt;= pos_iou_thr, assign it to that bbox 4. for each gt bbox, assign its nearest proposals (may be more than one) to itself Args: bboxes (Tensor): Bounding boxes to be assigned, shape(n, 4). gt_bboxes (Tensor): Groundtruth boxes, shape (k, 4). gt_bboxes_ignore (Tensor, optional): Ground truth bboxes that are labelled as `ignored`, e.g., crowd boxes in COCO. gt_labels (Tensor, optional): Label of gt_bboxes, shape (k, ). Returns: :obj:`AssignResult`: The assign result. """</span>
        <span class="token keyword">if</span> bboxes<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span> <span class="token operator">or</span> gt_bboxes<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">raise</span> ValueError<span class="token punctuation">(</span><span class="token string">'No gt or bboxes'</span><span class="token punctuation">)</span>
        bboxes <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>
        overlaps <span class="token operator">=</span> bbox_overlaps<span class="token punctuation">(</span>gt_bboxes<span class="token punctuation">,</span> bboxes<span class="token punctuation">)</span>

        <span class="token keyword">if</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>ignore_iof_thr <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">and</span> <span class="token punctuation">(</span>gt_bboxes_ignore <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">)</span> <span class="token operator">and</span> <span class="token punctuation">(</span>
                gt_bboxes_ignore<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>ignore_wrt_candidates<span class="token punctuation">:</span>
                ignore_overlaps <span class="token operator">=</span> bbox_overlaps<span class="token punctuation">(</span>
                    bboxes<span class="token punctuation">,</span> gt_bboxes_ignore<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'iof'</span><span class="token punctuation">)</span>
                ignore_max_overlaps<span class="token punctuation">,</span> _ <span class="token operator">=</span> ignore_overlaps<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                ignore_overlaps <span class="token operator">=</span> bbox_overlaps<span class="token punctuation">(</span>
                    gt_bboxes_ignore<span class="token punctuation">,</span> bboxes<span class="token punctuation">,</span> mode<span class="token operator">=</span><span class="token string">'iof'</span><span class="token punctuation">)</span>
                ignore_max_overlaps<span class="token punctuation">,</span> _ <span class="token operator">=</span> ignore_overlaps<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            overlaps<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> ignore_max_overlaps <span class="token operator">&gt;</span> self<span class="token punctuation">.</span>ignore_iof_thr<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token operator">-</span><span class="token number">1</span>

        assign_result <span class="token operator">=</span> self<span class="token punctuation">.</span>assign_wrt_overlaps<span class="token punctuation">(</span>overlaps<span class="token punctuation">,</span> gt_labels<span class="token punctuation">)</span>
        <span class="token keyword">return</span> assign_result
</code></pre> 
  <p>将<code>proposal</code>分为正负样本过后，通过<code>sampler</code>对这些<code>proposal</code>进行采样得到<code>sampler_result</code>进行训练。<br> <code>cascade_rcnn</code>默认使用的是<code>RandomSampler</code>定义在<code>mmdet/core/bbox/sampler/random_sampler.py</code></p> 
  <pre><code class="prism language-python">    @<span class="token builtin">staticmethod</span>
    <span class="token keyword">def</span> <span class="token function">random_choice</span><span class="token punctuation">(</span>gallery<span class="token punctuation">,</span> num<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Random select some elements from the gallery. It seems that Pytorch's implementation is slower than numpy so we use numpy to randperm the indices. """</span>
        <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>gallery<span class="token punctuation">)</span> <span class="token operator">&gt;=</span> num
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>gallery<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            gallery <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>gallery<span class="token punctuation">)</span>
        cands <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>gallery<span class="token punctuation">)</span><span class="token punctuation">)</span>
        np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>cands<span class="token punctuation">)</span>
        rand_inds <span class="token operator">=</span> cands<span class="token punctuation">[</span><span class="token punctuation">:</span>num<span class="token punctuation">]</span>
        <span class="token keyword">if</span> <span class="token operator">not</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>gallery<span class="token punctuation">,</span> np<span class="token punctuation">.</span>ndarray<span class="token punctuation">)</span><span class="token punctuation">:</span>
            rand_inds <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>rand_inds<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>gallery<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        <span class="token keyword">return</span> gallery<span class="token punctuation">[</span>rand_inds<span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">_sample_pos</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> assign_result<span class="token punctuation">,</span> num_expected<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Randomly sample some positive samples."""</span>
        pos_inds <span class="token operator">=</span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>assign_result<span class="token punctuation">.</span>gt_inds <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> pos_inds<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            pos_inds <span class="token operator">=</span> pos_inds<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> pos_inds<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;=</span> num_expected<span class="token punctuation">:</span>
            <span class="token keyword">return</span> pos_inds
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>random_choice<span class="token punctuation">(</span>pos_inds<span class="token punctuation">,</span> num_expected<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_sample_neg</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> assign_result<span class="token punctuation">,</span> num_expected<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Randomly sample some negative samples."""</span>
        neg_inds <span class="token operator">=</span> torch<span class="token punctuation">.</span>nonzero<span class="token punctuation">(</span>assign_result<span class="token punctuation">.</span>gt_inds <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> neg_inds<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            neg_inds <span class="token operator">=</span> neg_inds<span class="token punctuation">.</span>squeeze<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>neg_inds<span class="token punctuation">)</span> <span class="token operator">&lt;=</span> num_expected<span class="token punctuation">:</span>
            <span class="token keyword">return</span> neg_inds
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>random_choice<span class="token punctuation">(</span>neg_inds<span class="token punctuation">,</span> num_expected<span class="token punctuation">)</span>
</code></pre> 
  <p>重写了两个sample函数供父类调用。<br> 主要用到的是其父类<code>mmdet/core/bbox/sampler/base_sampler.py</code>定义的<code>sample</code></p> 
  <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">sample</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>
               assign_result<span class="token punctuation">,</span>
               bboxes<span class="token punctuation">,</span>
               gt_bboxes<span class="token punctuation">,</span>
               gt_labels<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
               <span class="token operator">**</span>kwargs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Sample positive and negative bboxes. This is a simple implementation of bbox sampling given candidates, assigning results and ground truth bboxes. Args: assign_result (:obj:`AssignResult`): Bbox assigning results. bboxes (Tensor): Boxes to be sampled from. gt_bboxes (Tensor): Ground truth bboxes. gt_labels (Tensor, optional): Class labels of ground truth bboxes. Returns: :obj:`SamplingResult`: Sampling result. """</span>
        bboxes <span class="token operator">=</span> bboxes<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token number">4</span><span class="token punctuation">]</span>

        gt_flags <span class="token operator">=</span> bboxes<span class="token punctuation">.</span>new_zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>bboxes<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>add_gt_as_proposals<span class="token punctuation">:</span>
            bboxes <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>gt_bboxes<span class="token punctuation">,</span> bboxes<span class="token punctuation">]</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            assign_result<span class="token punctuation">.</span>add_gt_<span class="token punctuation">(</span>gt_labels<span class="token punctuation">)</span>
            gt_ones <span class="token operator">=</span> bboxes<span class="token punctuation">.</span>new_ones<span class="token punctuation">(</span>gt_bboxes<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
            gt_flags <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">[</span>gt_ones<span class="token punctuation">,</span> gt_flags<span class="token punctuation">]</span><span class="token punctuation">)</span>

        num_expected_pos <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num <span class="token operator">*</span> self<span class="token punctuation">.</span>pos_fraction<span class="token punctuation">)</span>
        pos_inds <span class="token operator">=</span> self<span class="token punctuation">.</span>pos_sampler<span class="token punctuation">.</span>_sample_pos<span class="token punctuation">(</span>
            assign_result<span class="token punctuation">,</span> num_expected_pos<span class="token punctuation">,</span> bboxes<span class="token operator">=</span>bboxes<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        <span class="token comment"># We found that sampled indices have duplicated items occasionally.</span>
        <span class="token comment"># (may be a bug of PyTorch)</span>
        pos_inds <span class="token operator">=</span> pos_inds<span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span>
        num_sampled_pos <span class="token operator">=</span> pos_inds<span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span>
        num_expected_neg <span class="token operator">=</span> self<span class="token punctuation">.</span>num <span class="token operator">-</span> num_sampled_pos
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>neg_pos_ub <span class="token operator">&gt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>
            _pos <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> num_sampled_pos<span class="token punctuation">)</span>
            neg_upper_bound <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>neg_pos_ub <span class="token operator">*</span> _pos<span class="token punctuation">)</span>
            <span class="token keyword">if</span> num_expected_neg <span class="token operator">&gt;</span> neg_upper_bound<span class="token punctuation">:</span>
                num_expected_neg <span class="token operator">=</span> neg_upper_bound
        neg_inds <span class="token operator">=</span> self<span class="token punctuation">.</span>neg_sampler<span class="token punctuation">.</span>_sample_neg<span class="token punctuation">(</span>
            assign_result<span class="token punctuation">,</span> num_expected_neg<span class="token punctuation">,</span> bboxes<span class="token operator">=</span>bboxes<span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">)</span>
        neg_inds <span class="token operator">=</span> neg_inds<span class="token punctuation">.</span>unique<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">return</span> SamplingResult<span class="token punctuation">(</span>pos_inds<span class="token punctuation">,</span> neg_inds<span class="token punctuation">,</span> bboxes<span class="token punctuation">,</span> gt_bboxes<span class="token punctuation">,</span>
                              assign_result<span class="token punctuation">,</span> gt_flags<span class="token punctuation">)</span>
</code></pre> 
  <p>现在bbox已经处理好了，之后就是将这些框分别送到<code>bbox head</code>和<code>mask head</code>了。</p> 
  <hr> 
  <h1><a id="bbox_head_321"></a>bbox head</h1> 
  <p>当然之前得到的那些框还不能直接送到<code>bbox head</code>,在此之前还要做一次<code>RoI Pooling</code>,将不同大小的框映射成固定大小。<br> 具体定义在<code>mmdet/models/roi_extractors/single_level.py</code></p> 
  <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> feats<span class="token punctuation">,</span> rois<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>feats<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            <span class="token keyword">return</span> self<span class="token punctuation">.</span>roi_layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">(</span>feats<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> rois<span class="token punctuation">)</span>

        out_size <span class="token operator">=</span> self<span class="token punctuation">.</span>roi_layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>out_size
        num_levels <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>feats<span class="token punctuation">)</span>
        target_lvls <span class="token operator">=</span> self<span class="token punctuation">.</span>map_roi_levels<span class="token punctuation">(</span>rois<span class="token punctuation">,</span> num_levels<span class="token punctuation">)</span>
        roi_feats <span class="token operator">=</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">(</span>rois<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> self<span class="token punctuation">.</span>out_channels<span class="token punctuation">,</span>
                                           out_size<span class="token punctuation">,</span> out_size<span class="token punctuation">)</span><span class="token punctuation">.</span>fill_<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_levels<span class="token punctuation">)</span><span class="token punctuation">:</span>
            inds <span class="token operator">=</span> target_lvls <span class="token operator">==</span> i
            <span class="token keyword">if</span> inds<span class="token punctuation">.</span><span class="token builtin">any</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                rois_ <span class="token operator">=</span> rois<span class="token punctuation">[</span>inds<span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
                roi_feats_t <span class="token operator">=</span> self<span class="token punctuation">.</span>roi_layers<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">(</span>feats<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> rois_<span class="token punctuation">)</span>
                roi_feats<span class="token punctuation">[</span>inds<span class="token punctuation">]</span> <span class="token operator">+=</span> roi_feats_t
        <span class="token keyword">return</span> roi_feats
</code></pre> 
  <p>这里的<code>roi_layers</code>用的是<code>RoIAlign</code>,RoI的结果就可以送到<code>bbox head</code>了。<br> <code>bbox head</code>部分和之前的<code>rpn</code>部分的操作差不多，主要是针对每个框进行分类和坐标修正。之前<code>rpn</code>分为前景和背景两类，这里分为<code>N+1</code>类(实际类别 + 背景)。具体代码在<code>mmdet/models/bbox_head/convfc_bbox_head.py</code></p> 
  <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># shared part</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>num_shared_convs <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>shared_convs<span class="token punctuation">:</span>
                x <span class="token operator">=</span> conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>num_shared_fcs <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_avg_pool<span class="token punctuation">:</span>
                x <span class="token operator">=</span> self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">for</span> fc <span class="token keyword">in</span> self<span class="token punctuation">.</span>shared_fcs<span class="token punctuation">:</span>
                x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># separate branches</span>
        x_cls <span class="token operator">=</span> x
        x_reg <span class="token operator">=</span> x

        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>cls_convs<span class="token punctuation">:</span>
            x_cls <span class="token operator">=</span> conv<span class="token punctuation">(</span>x_cls<span class="token punctuation">)</span>
        <span class="token keyword">if</span> x_cls<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">2</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_avg_pool<span class="token punctuation">:</span>
                x_cls <span class="token operator">=</span> self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>x_cls<span class="token punctuation">)</span>
            x_cls <span class="token operator">=</span> x_cls<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x_cls<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> fc <span class="token keyword">in</span> self<span class="token punctuation">.</span>cls_fcs<span class="token punctuation">:</span>
            x_cls <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>fc<span class="token punctuation">(</span>x_cls<span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>reg_convs<span class="token punctuation">:</span>
            x_reg <span class="token operator">=</span> conv<span class="token punctuation">(</span>x_reg<span class="token punctuation">)</span>
        <span class="token keyword">if</span> x_reg<span class="token punctuation">.</span>dim<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">2</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_avg_pool<span class="token punctuation">:</span>
                x_reg <span class="token operator">=</span> self<span class="token punctuation">.</span>avg_pool<span class="token punctuation">(</span>x_reg<span class="token punctuation">)</span>
            x_reg <span class="token operator">=</span> x_reg<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x_reg<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> fc <span class="token keyword">in</span> self<span class="token punctuation">.</span>reg_fcs<span class="token punctuation">:</span>
            x_reg <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>fc<span class="token punctuation">(</span>x_reg<span class="token punctuation">)</span><span class="token punctuation">)</span>

        cls_score <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_cls<span class="token punctuation">(</span>x_cls<span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_cls <span class="token keyword">else</span> <span class="token boolean">None</span>
        bbox_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>fc_reg<span class="token punctuation">(</span>x_reg<span class="token punctuation">)</span> <span class="token keyword">if</span> self<span class="token punctuation">.</span>with_reg <span class="token keyword">else</span> <span class="token boolean">None</span>
        <span class="token keyword">return</span> cls_score<span class="token punctuation">,</span> bbox_pred
</code></pre> 
  <p><code>forward</code>的输出就是框的分类score和坐标。<br> 之后再通过这两个结果去计算<code>bbox_loss</code>,这个也放到之后在写。<br> 下面就是与 <code>bbox head</code>平行的另一个分支<code>mask head</code>了。</p> 
  <hr> 
  <h1><a id="mask_head_390"></a>mask head</h1> 
  <p><code>mask</code> 部分的流程和<code>bbox</code>部分相同，也是先对之前的候选框先做一次<code>RoI Pooling</code>，这里的<code>RoI</code>与之前<code>bbox</code>网络都一样只是部分参数不同。<br> 具体定义在<code>mmdet/models/mask_heads/fcn_mask_head.py</code></p> 
  <pre><code class="prism language-python">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> conv <span class="token keyword">in</span> self<span class="token punctuation">.</span>convs<span class="token punctuation">:</span>
            x <span class="token operator">=</span> conv<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>upsample <span class="token keyword">is</span> <span class="token operator">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            x <span class="token operator">=</span> self<span class="token punctuation">.</span>upsample<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>upsample_method <span class="token operator">==</span> <span class="token string">'deconv'</span><span class="token punctuation">:</span>
                x <span class="token operator">=</span> self<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        mask_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>conv_logits<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> mask_pred
</code></pre> 
  <p><code>forward</code>的输出就是每个像素点的分类值，之后也是通过这个结果去计算<code>mask loss</code>。<br> 在<code>bbox head</code> 和这部分<code>forward</code>的输出结果都不是测试阶段的最终结果，还需要进行其他操作才能得到测试结果。这部分之后写<code>test</code>的时候再写。</p> 
  <hr> 
  <h1><a id="_409"></a>小结</h1> 
  <p>这篇主要写了<code>mmdetection</code>中<code>cascade_rcnn</code>的网络创建过程，之前想的是慢慢抠细节，争取把每部分的细节都写了，但是实际看的时候还是觉得太复杂了，就先把整体流程写了一遍，相当于把整体骨架写了。准备之后把<code>loss</code>和测试部分写完了，在慢慢来抠每个部分的细节。</p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
