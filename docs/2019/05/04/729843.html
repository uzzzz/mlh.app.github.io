<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>基于深度学习的3D pose estimation总结（包括几篇2D pose estimation） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="基于深度学习的3D pose estimation总结（包括几篇2D pose estimation）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="声明：此文章是作者自己学习过程中的简单总结，也是作者第一次上传，仅供各位同行参考，也请对文中错误和不足多多指教，敬请指正，谢谢！ 一、任务描述 给定一幅图或者是一段视频，人体姿态估计就是恢复出其中的人体关节点位置的过程。 二、挑战和难点 1.人体肢体运动较为灵活； 2. 视角的变化； 3.附着物的变化（比如遮挡，衣物等）； 4.3D pose &nbsp;estimation缺乏数据集； 三、评价指标 主要分为以下两种： 1. PCK&nbsp; PCK的评价指标多出现在单人的姿态估计上； 定义：&nbsp;Percentage of Correct Keypoints (PCK)，reports the percentage of keypoint detection falling within a normalized distance of the ground truth. 2. mAP 主要用于多人姿态估计评价； 在物体检测中，我们是用IoU(intersection over union)来评价预测与真实标注之间的差异；在人体骨骼关键点的检测任务中，使用OKS(object keypoint similarity)代替IoU,对预测的人体骨骼关键点位置与真实标注之间的相似性进行评分； 3.OKS 四、数据集 对于以下数据集，1-4应用较多，其余应用较少： 1. Human3.6M （2D+3D） http://vision.imar.ro/human3.6m/description.php 2. MPI-INF-3DHP (3D) http://human-pose.mpi-inf.mpg.de/ 3. SURREAL (3D) https://www.di.ens.fr/willow/research/surreal/ 4. Unite the People dataset(UP) &nbsp; (2D + 3D) http://files.is.tuebingen.mpg.de/classner/up/ 5. LSP (2D) 单人数据集http://sam.johnson.io/research/lsp.html 6.FILC (2D) 单人数据集https://bensapp.github.io/flic-dataset.html 7.MPII （2D） 单人/多人数据集&nbsp;http://human-pose.mpi-inf.mpg.de/ 8. HumanEva （3D） http://humaneva.is.tue.mpg.de/ 五、应用 基于姿态估计的可能的应用方向如下： 基础性研究： 行为识别，动作分类，异常行为检测，人物追踪，步态识别； 产业应用： &nbsp; 智能视频监控，病人监护系统，虚拟现实，人机交互，游戏，动画，衣物识别， &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;运动员辅助训练，自动驾驶。 六、已有工作 1.Convolutional Pose Machines， CVPR2016 文中将convolutional nnetwork 应用到pose machine中，用于学习图像特征以及图像的空间模型；在articulated pose estimation任务的结构化预测方面，隐式的建立不同结构之间的空间依赖关系模型；如文中多述，网络分为多个阶段，在每个阶段网络中加入intermediate supervision，以用来缓解端到端网络使用BP训练中出现的梯度消失的问题（有待验证）。 利用卷积网络先从局部特征入手，确定了一个或者是多个关节点，这样就可以借助已知的关节点来对其他身体部位进行定位。 数据集： MPII,LSP, and FLIC datasets 文中不足： 对于密集的多人估计效果是很差的； &nbsp; 2. Stacked Hourglass Networks for Human&nbsp;Pose Estimation,2016 一种沙漏型的网络结构，首先进行卷积处理并进行下采样处理，获得一些分辨率较低的特征，来降低计算的复杂度；紧接着又采用上采样操作来提升图像特征的分辨率，同时也使得网络更有能力预测物体的精确位置；而且这种沙漏结构具有可堆叠性。在此工作中，也在不同阶段采用intermediate supervision方法。 此方法相比于CMPs，在精度和速度上都略胜一筹。 数据集：FLIC and MPII 此方法也对密集多人姿态估计进行了测试，表现效果相比CMPs有很大提升。 &nbsp; 3. 3D Human Pose Estimation in the Wild by Adversarial Learning，CVPR2018 本文工作采用对抗学习框架，从有完全注释的数据集中学习3D pose，然后应用到只有2D 标注数据的野外图像中；设计可以了一个multi-source 的判别器，来识别预测到的3D pose 是否为GT. &nbsp; 4. End-to-end Recovery of Human Shape and Pose；2018 本文工作使用端到端的框架，直接从单张彩色图片中恢复出3D 人体网格（包括人体形状和关节角度），不需要依赖中间任务（如2D估计）。 文中使用两个数据集，一个是带有2D标注信息的实况数据集，另一个是人体3D模型数据集。获得一幅图时，先获取其3D mseh参数，然后推断出其3D joint，再映射到2D，与原图的2D joint匹配，即一个2D-3D-2D过程，把无3D标注的2D当成训练集使用。在参数预测上则采用了iterative regression with feedback的方法。另外，为了使生成的模型符合真实的人体结构，使用GAN的网络结构，把生成模型的参数输入到一个Discriminator中，Discriminator在训练中学习每个joint之间的角度限制，由Discriminator来判断模型是否真实。 优点：直接从图像中推断其三维网格参数，训练省事不易丢失图片信息；而且不需要有paired 2D-3D数据集，为从大量2D数据学习3D提供可能性。 5. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose&nbsp;and Shape Estimation；2018 文章中使用基于2D的区域表示，将人体分为12个部分，作为映射到3D的一个中间步骤； 文中提出一种新的方法-Neural Body Fitting(NBF)，结合CNN使用这一种statistical body model，利用bottom-up semantic body part segmentation and top-down body model constraints，采用端到端的训练方式。 NBF用一个standard semantic CNN 将人体分为12个部位，然后encoding CNN 直接从RGB image或者是semantic segmentation of image中预测模型参数，再通过SMPL产生3D mesh；最后再将3D mesh的关节点重投影到2D，reprojection loss采用BP方法，来训练整个网络。 除此之外，文章中对很多工作做了分析，比如什么样的输入更好，loss function怎么设置，3D annotation数据量对结果影响，以及分割效果对于效果的影响等等。 文章中仅仅使用百分之二十的3D标注训练集就可以取得和使得全部3D标注训练集相似的结果。 未来工作：密集的多人姿态估计。 &nbsp; 6. Learning to Estimate 3D Human Pose and Shape from a Single Color Image，2018 文中工作把SMPL模型嵌入端到端的框架，从单个彩色图像中估计人体的姿势和形状；提出一种基于卷积网络的高效的直接预测方法，其优于迭代优化的方法。 首先训练一个卷及网络human2D，其产生两个输出，轮廓（包括人体和背景两个）和热图（输出关键点）； 接下来，训练两个网络，一个是poseprior，使用2D关键点作为输入，检测置信度并估计姿态系数theta，另一个是shapeprior，使用轮廓作为输入，并估计其形状系数beta，最后进行参数size转换，对应于SMPL模型的系数theta和beta。最后将生成的3D人体模型实例投影到图像平面，并计算其轮廓与2D关键点位置的已生成训练输入输出对。 网络优点：参数少，有利于直接进行预测；训练生成3D网格，并对其表面光滑度进行优化。 &nbsp; 7. RepNet: Weakly Supervised Training of an Adversarial Reprojection Network&nbsp;for 3D Human Pose Estimation ; CVPR2019 本文是一种从2D 学习3D的方法； 利用神经网络类直接估计3D pose的工作大多都忽略了 &nbsp;最终的估计应该满足重投影误差，而且目前神经网络的方法很容易导致过拟合；本文工作忽略2D和3D之间的一致性而解决过拟合问题，并且避免网络对训练数据产生一定的记忆，允许弱监督训练。 文中运用对抗网络的思想，网络主要分为两个部分，一个部分是reprojection network，其使用对抗训练的方法学习2D pose 到3D pose分布的map；另一部分网络estimate camera，这能够使得预测得到的3D pose重投影回2D ，从而计算reprojection loss function。 实验结果优于其他的弱监督方法，同时解决一定数据量的过拟合问题；优于部分监督学习模型。 文中指出： 在Human3.6M数据集上训练的网络用于预测MPI-INF-3DHP（unseen data）数据，相比其他方法有很大提升。 &nbsp; 8. DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a Single Color Image；2019 提出一种端到端的方法，直接从单个彩色图片中得到3D 人体网格；该研究训练一个编码器-解码器网格，无需使用任何中间任务，如2D 估计等。 之前的研究通常使用SMPL 这样的可变型模型来表示3D 人体结构，但是本文利用UV位置映射图来表示3D人体几何结构（UV是一个2D表示图，如上图所示），用UV映射图来储存整个人体表面的三维位置信息。 &nbsp; 七、总结 1. 问题难点 （1）数据： 缺少足够量的带有ground truth 3D annotation的in-the-wild图像，目前已有的带有标注的图像大多数是在特定实验环境中获取的，并不足以反映真实环境下可能出现的情况； （2）2D与3D之间映射存在一定的模糊性，因为缺少一些深度信息（或者其他的辅助性信息），许多的三维模型可以映射为同一个2D模型，但是反之，从二维映射到三维时，未必能真正反映人体结构。 2.基于深度学习的方法 关于3D pose estimation的方法主要可以分为两类，简言之，就是一阶段法和二阶段法，以下会讲解两种方法的大概流程： 2.1. 一阶段法 直接从图片中获取3D 关节点位置，然后reproject 到2D，与有ground truth 2D annotation数据集对比，进而优化网络。 优点：不易丢失图片信息。 2.2. 二阶段法 （1）用2D pose检测，预测2D关节点位置； （2）通过回归分析或者model fitting的方式，从2D中预测3D关节点位置；这种方法有一个共性，就是会利用一个预测3D 模型的框架，主要是SMPL； 注：对于这样的一种方法，为了约束2D-to-3D固有的这种模糊性，会利用一些先验知识：假定四肢长度或者是比例； 缺点：但是这样的方法或过度依赖2D关节点的位置信息，有可能会丢掉图片中的其他信息。 &nbsp; 八、参考文献 1.Convolutional Pose Machines； 2. Stacked Hourglass Networks for Human&nbsp;Pose Estimation； 3. 3D Human Pose Estimation in the Wild by Adversarial Learning； 4. End-to-end Recovery of Human Shape and Pose； 5. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose&nbsp;and Shape Estimation； 6. Learning to Estimate 3D Human Pose and Shape from a Single Color Image； 7. RepNet: Weakly Supervised Training of an Adversarial Reprojection Network&nbsp;for 3D Human Pose Estimation&nbsp;； 8. DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a&nbsp;Single Color Image；" />
<meta property="og:description" content="声明：此文章是作者自己学习过程中的简单总结，也是作者第一次上传，仅供各位同行参考，也请对文中错误和不足多多指教，敬请指正，谢谢！ 一、任务描述 给定一幅图或者是一段视频，人体姿态估计就是恢复出其中的人体关节点位置的过程。 二、挑战和难点 1.人体肢体运动较为灵活； 2. 视角的变化； 3.附着物的变化（比如遮挡，衣物等）； 4.3D pose &nbsp;estimation缺乏数据集； 三、评价指标 主要分为以下两种： 1. PCK&nbsp; PCK的评价指标多出现在单人的姿态估计上； 定义：&nbsp;Percentage of Correct Keypoints (PCK)，reports the percentage of keypoint detection falling within a normalized distance of the ground truth. 2. mAP 主要用于多人姿态估计评价； 在物体检测中，我们是用IoU(intersection over union)来评价预测与真实标注之间的差异；在人体骨骼关键点的检测任务中，使用OKS(object keypoint similarity)代替IoU,对预测的人体骨骼关键点位置与真实标注之间的相似性进行评分； 3.OKS 四、数据集 对于以下数据集，1-4应用较多，其余应用较少： 1. Human3.6M （2D+3D） http://vision.imar.ro/human3.6m/description.php 2. MPI-INF-3DHP (3D) http://human-pose.mpi-inf.mpg.de/ 3. SURREAL (3D) https://www.di.ens.fr/willow/research/surreal/ 4. Unite the People dataset(UP) &nbsp; (2D + 3D) http://files.is.tuebingen.mpg.de/classner/up/ 5. LSP (2D) 单人数据集http://sam.johnson.io/research/lsp.html 6.FILC (2D) 单人数据集https://bensapp.github.io/flic-dataset.html 7.MPII （2D） 单人/多人数据集&nbsp;http://human-pose.mpi-inf.mpg.de/ 8. HumanEva （3D） http://humaneva.is.tue.mpg.de/ 五、应用 基于姿态估计的可能的应用方向如下： 基础性研究： 行为识别，动作分类，异常行为检测，人物追踪，步态识别； 产业应用： &nbsp; 智能视频监控，病人监护系统，虚拟现实，人机交互，游戏，动画，衣物识别， &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;运动员辅助训练，自动驾驶。 六、已有工作 1.Convolutional Pose Machines， CVPR2016 文中将convolutional nnetwork 应用到pose machine中，用于学习图像特征以及图像的空间模型；在articulated pose estimation任务的结构化预测方面，隐式的建立不同结构之间的空间依赖关系模型；如文中多述，网络分为多个阶段，在每个阶段网络中加入intermediate supervision，以用来缓解端到端网络使用BP训练中出现的梯度消失的问题（有待验证）。 利用卷积网络先从局部特征入手，确定了一个或者是多个关节点，这样就可以借助已知的关节点来对其他身体部位进行定位。 数据集： MPII,LSP, and FLIC datasets 文中不足： 对于密集的多人估计效果是很差的； &nbsp; 2. Stacked Hourglass Networks for Human&nbsp;Pose Estimation,2016 一种沙漏型的网络结构，首先进行卷积处理并进行下采样处理，获得一些分辨率较低的特征，来降低计算的复杂度；紧接着又采用上采样操作来提升图像特征的分辨率，同时也使得网络更有能力预测物体的精确位置；而且这种沙漏结构具有可堆叠性。在此工作中，也在不同阶段采用intermediate supervision方法。 此方法相比于CMPs，在精度和速度上都略胜一筹。 数据集：FLIC and MPII 此方法也对密集多人姿态估计进行了测试，表现效果相比CMPs有很大提升。 &nbsp; 3. 3D Human Pose Estimation in the Wild by Adversarial Learning，CVPR2018 本文工作采用对抗学习框架，从有完全注释的数据集中学习3D pose，然后应用到只有2D 标注数据的野外图像中；设计可以了一个multi-source 的判别器，来识别预测到的3D pose 是否为GT. &nbsp; 4. End-to-end Recovery of Human Shape and Pose；2018 本文工作使用端到端的框架，直接从单张彩色图片中恢复出3D 人体网格（包括人体形状和关节角度），不需要依赖中间任务（如2D估计）。 文中使用两个数据集，一个是带有2D标注信息的实况数据集，另一个是人体3D模型数据集。获得一幅图时，先获取其3D mseh参数，然后推断出其3D joint，再映射到2D，与原图的2D joint匹配，即一个2D-3D-2D过程，把无3D标注的2D当成训练集使用。在参数预测上则采用了iterative regression with feedback的方法。另外，为了使生成的模型符合真实的人体结构，使用GAN的网络结构，把生成模型的参数输入到一个Discriminator中，Discriminator在训练中学习每个joint之间的角度限制，由Discriminator来判断模型是否真实。 优点：直接从图像中推断其三维网格参数，训练省事不易丢失图片信息；而且不需要有paired 2D-3D数据集，为从大量2D数据学习3D提供可能性。 5. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose&nbsp;and Shape Estimation；2018 文章中使用基于2D的区域表示，将人体分为12个部分，作为映射到3D的一个中间步骤； 文中提出一种新的方法-Neural Body Fitting(NBF)，结合CNN使用这一种statistical body model，利用bottom-up semantic body part segmentation and top-down body model constraints，采用端到端的训练方式。 NBF用一个standard semantic CNN 将人体分为12个部位，然后encoding CNN 直接从RGB image或者是semantic segmentation of image中预测模型参数，再通过SMPL产生3D mesh；最后再将3D mesh的关节点重投影到2D，reprojection loss采用BP方法，来训练整个网络。 除此之外，文章中对很多工作做了分析，比如什么样的输入更好，loss function怎么设置，3D annotation数据量对结果影响，以及分割效果对于效果的影响等等。 文章中仅仅使用百分之二十的3D标注训练集就可以取得和使得全部3D标注训练集相似的结果。 未来工作：密集的多人姿态估计。 &nbsp; 6. Learning to Estimate 3D Human Pose and Shape from a Single Color Image，2018 文中工作把SMPL模型嵌入端到端的框架，从单个彩色图像中估计人体的姿势和形状；提出一种基于卷积网络的高效的直接预测方法，其优于迭代优化的方法。 首先训练一个卷及网络human2D，其产生两个输出，轮廓（包括人体和背景两个）和热图（输出关键点）； 接下来，训练两个网络，一个是poseprior，使用2D关键点作为输入，检测置信度并估计姿态系数theta，另一个是shapeprior，使用轮廓作为输入，并估计其形状系数beta，最后进行参数size转换，对应于SMPL模型的系数theta和beta。最后将生成的3D人体模型实例投影到图像平面，并计算其轮廓与2D关键点位置的已生成训练输入输出对。 网络优点：参数少，有利于直接进行预测；训练生成3D网格，并对其表面光滑度进行优化。 &nbsp; 7. RepNet: Weakly Supervised Training of an Adversarial Reprojection Network&nbsp;for 3D Human Pose Estimation ; CVPR2019 本文是一种从2D 学习3D的方法； 利用神经网络类直接估计3D pose的工作大多都忽略了 &nbsp;最终的估计应该满足重投影误差，而且目前神经网络的方法很容易导致过拟合；本文工作忽略2D和3D之间的一致性而解决过拟合问题，并且避免网络对训练数据产生一定的记忆，允许弱监督训练。 文中运用对抗网络的思想，网络主要分为两个部分，一个部分是reprojection network，其使用对抗训练的方法学习2D pose 到3D pose分布的map；另一部分网络estimate camera，这能够使得预测得到的3D pose重投影回2D ，从而计算reprojection loss function。 实验结果优于其他的弱监督方法，同时解决一定数据量的过拟合问题；优于部分监督学习模型。 文中指出： 在Human3.6M数据集上训练的网络用于预测MPI-INF-3DHP（unseen data）数据，相比其他方法有很大提升。 &nbsp; 8. DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a Single Color Image；2019 提出一种端到端的方法，直接从单个彩色图片中得到3D 人体网格；该研究训练一个编码器-解码器网格，无需使用任何中间任务，如2D 估计等。 之前的研究通常使用SMPL 这样的可变型模型来表示3D 人体结构，但是本文利用UV位置映射图来表示3D人体几何结构（UV是一个2D表示图，如上图所示），用UV映射图来储存整个人体表面的三维位置信息。 &nbsp; 七、总结 1. 问题难点 （1）数据： 缺少足够量的带有ground truth 3D annotation的in-the-wild图像，目前已有的带有标注的图像大多数是在特定实验环境中获取的，并不足以反映真实环境下可能出现的情况； （2）2D与3D之间映射存在一定的模糊性，因为缺少一些深度信息（或者其他的辅助性信息），许多的三维模型可以映射为同一个2D模型，但是反之，从二维映射到三维时，未必能真正反映人体结构。 2.基于深度学习的方法 关于3D pose estimation的方法主要可以分为两类，简言之，就是一阶段法和二阶段法，以下会讲解两种方法的大概流程： 2.1. 一阶段法 直接从图片中获取3D 关节点位置，然后reproject 到2D，与有ground truth 2D annotation数据集对比，进而优化网络。 优点：不易丢失图片信息。 2.2. 二阶段法 （1）用2D pose检测，预测2D关节点位置； （2）通过回归分析或者model fitting的方式，从2D中预测3D关节点位置；这种方法有一个共性，就是会利用一个预测3D 模型的框架，主要是SMPL； 注：对于这样的一种方法，为了约束2D-to-3D固有的这种模糊性，会利用一些先验知识：假定四肢长度或者是比例； 缺点：但是这样的方法或过度依赖2D关节点的位置信息，有可能会丢掉图片中的其他信息。 &nbsp; 八、参考文献 1.Convolutional Pose Machines； 2. Stacked Hourglass Networks for Human&nbsp;Pose Estimation； 3. 3D Human Pose Estimation in the Wild by Adversarial Learning； 4. End-to-end Recovery of Human Shape and Pose； 5. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose&nbsp;and Shape Estimation； 6. Learning to Estimate 3D Human Pose and Shape from a Single Color Image； 7. RepNet: Weakly Supervised Training of an Adversarial Reprojection Network&nbsp;for 3D Human Pose Estimation&nbsp;； 8. DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a&nbsp;Single Color Image；" />
<link rel="canonical" href="https://mlh.app/2019/05/04/729843.html" />
<meta property="og:url" content="https://mlh.app/2019/05/04/729843.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-04T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"声明：此文章是作者自己学习过程中的简单总结，也是作者第一次上传，仅供各位同行参考，也请对文中错误和不足多多指教，敬请指正，谢谢！ 一、任务描述 给定一幅图或者是一段视频，人体姿态估计就是恢复出其中的人体关节点位置的过程。 二、挑战和难点 1.人体肢体运动较为灵活； 2. 视角的变化； 3.附着物的变化（比如遮挡，衣物等）； 4.3D pose &nbsp;estimation缺乏数据集； 三、评价指标 主要分为以下两种： 1. PCK&nbsp; PCK的评价指标多出现在单人的姿态估计上； 定义：&nbsp;Percentage of Correct Keypoints (PCK)，reports the percentage of keypoint detection falling within a normalized distance of the ground truth. 2. mAP 主要用于多人姿态估计评价； 在物体检测中，我们是用IoU(intersection over union)来评价预测与真实标注之间的差异；在人体骨骼关键点的检测任务中，使用OKS(object keypoint similarity)代替IoU,对预测的人体骨骼关键点位置与真实标注之间的相似性进行评分； 3.OKS 四、数据集 对于以下数据集，1-4应用较多，其余应用较少： 1. Human3.6M （2D+3D） http://vision.imar.ro/human3.6m/description.php 2. MPI-INF-3DHP (3D) http://human-pose.mpi-inf.mpg.de/ 3. SURREAL (3D) https://www.di.ens.fr/willow/research/surreal/ 4. Unite the People dataset(UP) &nbsp; (2D + 3D) http://files.is.tuebingen.mpg.de/classner/up/ 5. LSP (2D) 单人数据集http://sam.johnson.io/research/lsp.html 6.FILC (2D) 单人数据集https://bensapp.github.io/flic-dataset.html 7.MPII （2D） 单人/多人数据集&nbsp;http://human-pose.mpi-inf.mpg.de/ 8. HumanEva （3D） http://humaneva.is.tue.mpg.de/ 五、应用 基于姿态估计的可能的应用方向如下： 基础性研究： 行为识别，动作分类，异常行为检测，人物追踪，步态识别； 产业应用： &nbsp; 智能视频监控，病人监护系统，虚拟现实，人机交互，游戏，动画，衣物识别， &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;运动员辅助训练，自动驾驶。 六、已有工作 1.Convolutional Pose Machines， CVPR2016 文中将convolutional nnetwork 应用到pose machine中，用于学习图像特征以及图像的空间模型；在articulated pose estimation任务的结构化预测方面，隐式的建立不同结构之间的空间依赖关系模型；如文中多述，网络分为多个阶段，在每个阶段网络中加入intermediate supervision，以用来缓解端到端网络使用BP训练中出现的梯度消失的问题（有待验证）。 利用卷积网络先从局部特征入手，确定了一个或者是多个关节点，这样就可以借助已知的关节点来对其他身体部位进行定位。 数据集： MPII,LSP, and FLIC datasets 文中不足： 对于密集的多人估计效果是很差的； &nbsp; 2. Stacked Hourglass Networks for Human&nbsp;Pose Estimation,2016 一种沙漏型的网络结构，首先进行卷积处理并进行下采样处理，获得一些分辨率较低的特征，来降低计算的复杂度；紧接着又采用上采样操作来提升图像特征的分辨率，同时也使得网络更有能力预测物体的精确位置；而且这种沙漏结构具有可堆叠性。在此工作中，也在不同阶段采用intermediate supervision方法。 此方法相比于CMPs，在精度和速度上都略胜一筹。 数据集：FLIC and MPII 此方法也对密集多人姿态估计进行了测试，表现效果相比CMPs有很大提升。 &nbsp; 3. 3D Human Pose Estimation in the Wild by Adversarial Learning，CVPR2018 本文工作采用对抗学习框架，从有完全注释的数据集中学习3D pose，然后应用到只有2D 标注数据的野外图像中；设计可以了一个multi-source 的判别器，来识别预测到的3D pose 是否为GT. &nbsp; 4. End-to-end Recovery of Human Shape and Pose；2018 本文工作使用端到端的框架，直接从单张彩色图片中恢复出3D 人体网格（包括人体形状和关节角度），不需要依赖中间任务（如2D估计）。 文中使用两个数据集，一个是带有2D标注信息的实况数据集，另一个是人体3D模型数据集。获得一幅图时，先获取其3D mseh参数，然后推断出其3D joint，再映射到2D，与原图的2D joint匹配，即一个2D-3D-2D过程，把无3D标注的2D当成训练集使用。在参数预测上则采用了iterative regression with feedback的方法。另外，为了使生成的模型符合真实的人体结构，使用GAN的网络结构，把生成模型的参数输入到一个Discriminator中，Discriminator在训练中学习每个joint之间的角度限制，由Discriminator来判断模型是否真实。 优点：直接从图像中推断其三维网格参数，训练省事不易丢失图片信息；而且不需要有paired 2D-3D数据集，为从大量2D数据学习3D提供可能性。 5. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose&nbsp;and Shape Estimation；2018 文章中使用基于2D的区域表示，将人体分为12个部分，作为映射到3D的一个中间步骤； 文中提出一种新的方法-Neural Body Fitting(NBF)，结合CNN使用这一种statistical body model，利用bottom-up semantic body part segmentation and top-down body model constraints，采用端到端的训练方式。 NBF用一个standard semantic CNN 将人体分为12个部位，然后encoding CNN 直接从RGB image或者是semantic segmentation of image中预测模型参数，再通过SMPL产生3D mesh；最后再将3D mesh的关节点重投影到2D，reprojection loss采用BP方法，来训练整个网络。 除此之外，文章中对很多工作做了分析，比如什么样的输入更好，loss function怎么设置，3D annotation数据量对结果影响，以及分割效果对于效果的影响等等。 文章中仅仅使用百分之二十的3D标注训练集就可以取得和使得全部3D标注训练集相似的结果。 未来工作：密集的多人姿态估计。 &nbsp; 6. Learning to Estimate 3D Human Pose and Shape from a Single Color Image，2018 文中工作把SMPL模型嵌入端到端的框架，从单个彩色图像中估计人体的姿势和形状；提出一种基于卷积网络的高效的直接预测方法，其优于迭代优化的方法。 首先训练一个卷及网络human2D，其产生两个输出，轮廓（包括人体和背景两个）和热图（输出关键点）； 接下来，训练两个网络，一个是poseprior，使用2D关键点作为输入，检测置信度并估计姿态系数theta，另一个是shapeprior，使用轮廓作为输入，并估计其形状系数beta，最后进行参数size转换，对应于SMPL模型的系数theta和beta。最后将生成的3D人体模型实例投影到图像平面，并计算其轮廓与2D关键点位置的已生成训练输入输出对。 网络优点：参数少，有利于直接进行预测；训练生成3D网格，并对其表面光滑度进行优化。 &nbsp; 7. RepNet: Weakly Supervised Training of an Adversarial Reprojection Network&nbsp;for 3D Human Pose Estimation ; CVPR2019 本文是一种从2D 学习3D的方法； 利用神经网络类直接估计3D pose的工作大多都忽略了 &nbsp;最终的估计应该满足重投影误差，而且目前神经网络的方法很容易导致过拟合；本文工作忽略2D和3D之间的一致性而解决过拟合问题，并且避免网络对训练数据产生一定的记忆，允许弱监督训练。 文中运用对抗网络的思想，网络主要分为两个部分，一个部分是reprojection network，其使用对抗训练的方法学习2D pose 到3D pose分布的map；另一部分网络estimate camera，这能够使得预测得到的3D pose重投影回2D ，从而计算reprojection loss function。 实验结果优于其他的弱监督方法，同时解决一定数据量的过拟合问题；优于部分监督学习模型。 文中指出： 在Human3.6M数据集上训练的网络用于预测MPI-INF-3DHP（unseen data）数据，相比其他方法有很大提升。 &nbsp; 8. DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a Single Color Image；2019 提出一种端到端的方法，直接从单个彩色图片中得到3D 人体网格；该研究训练一个编码器-解码器网格，无需使用任何中间任务，如2D 估计等。 之前的研究通常使用SMPL 这样的可变型模型来表示3D 人体结构，但是本文利用UV位置映射图来表示3D人体几何结构（UV是一个2D表示图，如上图所示），用UV映射图来储存整个人体表面的三维位置信息。 &nbsp; 七、总结 1. 问题难点 （1）数据： 缺少足够量的带有ground truth 3D annotation的in-the-wild图像，目前已有的带有标注的图像大多数是在特定实验环境中获取的，并不足以反映真实环境下可能出现的情况； （2）2D与3D之间映射存在一定的模糊性，因为缺少一些深度信息（或者其他的辅助性信息），许多的三维模型可以映射为同一个2D模型，但是反之，从二维映射到三维时，未必能真正反映人体结构。 2.基于深度学习的方法 关于3D pose estimation的方法主要可以分为两类，简言之，就是一阶段法和二阶段法，以下会讲解两种方法的大概流程： 2.1. 一阶段法 直接从图片中获取3D 关节点位置，然后reproject 到2D，与有ground truth 2D annotation数据集对比，进而优化网络。 优点：不易丢失图片信息。 2.2. 二阶段法 （1）用2D pose检测，预测2D关节点位置； （2）通过回归分析或者model fitting的方式，从2D中预测3D关节点位置；这种方法有一个共性，就是会利用一个预测3D 模型的框架，主要是SMPL； 注：对于这样的一种方法，为了约束2D-to-3D固有的这种模糊性，会利用一些先验知识：假定四肢长度或者是比例； 缺点：但是这样的方法或过度依赖2D关节点的位置信息，有可能会丢掉图片中的其他信息。 &nbsp; 八、参考文献 1.Convolutional Pose Machines； 2. Stacked Hourglass Networks for Human&nbsp;Pose Estimation； 3. 3D Human Pose Estimation in the Wild by Adversarial Learning； 4. End-to-end Recovery of Human Shape and Pose； 5. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose&nbsp;and Shape Estimation； 6. Learning to Estimate 3D Human Pose and Shape from a Single Color Image； 7. RepNet: Weakly Supervised Training of an Adversarial Reprojection Network&nbsp;for 3D Human Pose Estimation&nbsp;； 8. DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a&nbsp;Single Color Image；","@type":"BlogPosting","url":"https://mlh.app/2019/05/04/729843.html","headline":"基于深度学习的3D pose estimation总结（包括几篇2D pose estimation）","dateModified":"2019-05-04T00:00:00+08:00","datePublished":"2019-05-04T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/04/729843.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>基于深度学习的3D pose estimation总结（包括几篇2D pose estimation）</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p style="margin-left:0px;">声明：此文章是作者自己学习过程中的简单总结，也是作者第一次上传，仅供各位同行参考，也请对文中错误和不足多多指教，敬请指正，谢谢！</p> 
  <h1 style="margin-left:0px;"><strong><span style="color:#000000;">一、任务描述</span></strong></h1> 
  <p><span style="color:#000000;">给定一幅图或者是一段视频，人体姿态估计就是恢复出其中的人体关节点位置的过程。</span></p> 
  <h1 style="margin-left:0px;"><strong><span style="color:#000000;">二、挑战和难点</span></strong></h1> 
  <p><span style="color:#000000;">1.人体肢体运动较为灵活；</span></p> 
  <p><span style="color:#000000;">2. 视角的变化；</span></p> 
  <p><span style="color:#000000;">3.附着物的变化（比如遮挡，衣物等）；</span></p> 
  <p><span style="color:#000000;">4.3D pose &nbsp;estimation缺乏数据集；</span></p> 
  <h1 style="margin-left:0px;"><strong><span style="color:#000000;">三、评价指标</span></strong></h1> 
  <p><span style="color:#000000;">主要分为以下两种：</span></p> 
  <p><span style="color:#000000;">1. PCK&nbsp;</span></p> 
  <p><span style="color:#000000;">PCK的评价指标多出现在单人的姿态估计上；</span></p> 
  <p><span style="color:#000000;">定义：&nbsp;<span style="color:#4f4f4f;"><span style="color:#000000;">Percentage of Correct Keypoints (PCK)，reports the percentage of keypoint detection falling within a normalized distance of the ground truth.</span></span></span></p> 
  <p><span style="color:#000000;"><span style="color:#4f4f4f;"><span style="color:#000000;">2. mAP</span></span></span></p> 
  <p><span style="color:#000000;">主要用于多人姿态估计评价；</span></p> 
  <p><span style="color:#000000;">在物体检测中，我们是用IoU(intersection over union)来评价预测与真实标注之间的差异；在人体骨骼关键点的检测任务中，使用OKS(object keypoint similarity)代替IoU,对预测的人体骨骼关键点位置与真实标注之间的相似性进行评分；</span></p> 
  <p><span style="color:#000000;">3.OKS</span></p> 
  <h1 style="margin-left:0px;"><strong><span style="color:#000000;">四、数据集</span></strong></h1> 
  <p><span style="color:#000000;">对于以下数据集，1-4应用较多，其余应用较少：</span></p> 
  <p><span style="color:#000000;">1. Human3.6M （2D+3D）</span></p> 
  <p><span style="color:#000000;"><a href="http://vision.imar.ro/human3.6m/description.php" rel="nofollow">http://vision.imar.ro/human3.6m/description.php</a></span></p> 
  <p><span style="color:#000000;">2. MPI-INF-3DHP (3D)</span></p> 
  <p><span style="color:#000000;"><a href="http://human-pose.mpi-inf.mpg.de/" rel="nofollow">http://human-pose.mpi-inf.mpg.de/</a></span></p> 
  <p><span style="color:#000000;">3. SURREAL (3D)</span></p> 
  <p><span style="color:#000000;"><a href="https://www.di.ens.fr/willow/research/surreal/" rel="nofollow">https://www.di.ens.fr/willow/research/surreal/</a></span></p> 
  <p><span style="color:#000000;">4. Unite the People dataset(UP) &nbsp; (2D + 3D)</span></p> 
  <p><span style="color:#000000;"><a href="http://files.is.tuebingen.mpg.de/classner/up/" rel="nofollow">http://files.is.tuebingen.mpg.de/classner/up/</a></span></p> 
  <p><span style="color:#000000;">5. LSP (2D)</span></p> 
  <p><span style="color:#000000;">单人数据集<a href="http://sam.johnson.io/research/lsp.html" rel="nofollow">http://sam.johnson.io/research/lsp.html</a></span></p> 
  <p><span style="color:#000000;">6.FILC (2D)</span></p> 
  <p><span style="color:#000000;">单人数据集<a href="https://bensapp.github.io/flic-dataset.html" rel="nofollow">https://bensapp.github.io/flic-dataset.html</a></span></p> 
  <p><span style="color:#000000;">7.MPII （2D）</span></p> 
  <p><span style="color:#000000;">单人/多人数据集&nbsp;<a href="http://human-pose.mpi-inf.mpg.de/" rel="nofollow">http://human-pose.mpi-inf.mpg.de/</a></span></p> 
  <p><span style="color:#000000;">8. HumanEva （3D）</span></p> 
  <p><span style="color:#000000;"><a href="http://humaneva.is.tue.mpg.de/" rel="nofollow">http://humaneva.is.tue.mpg.de/</a></span></p> 
  <h1 style="margin-left:0px;"><strong><span style="color:#000000;">五、应用</span></strong></h1> 
  <p><span style="color:#000000;">基于姿态估计的可能的应用方向如下：</span></p> 
  <p><span style="color:#000000;">基础性研究： 行为识别，动作分类，异常行为检测，人物追踪，步态识别；</span></p> 
  <p><span style="color:#000000;">产业应用： &nbsp; 智能视频监控，病人监护系统，虚拟现实，人机交互，游戏，动画，衣物识别， &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;运动员辅助训练，自动驾驶。</span></p> 
  <h1 style="margin-left:0px;"><strong><span style="color:#000000;">六、已有工作</span></strong></h1> 
  <p><span style="color:#000000;">1.Convolutional Pose Machines， CVPR2016</span></p> 
  <p><img alt="" class="has" height="908" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504203806635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><span style="color:#000000;">文中将convolutional nnetwork 应用到pose machine中，用于学习图像特征以及图像的空间模型；在articulated pose estimation任务的结构化预测方面，隐式的建立不同结构之间的空间依赖关系模型；如文中多述，网络分为多个阶段，在每个阶段网络中加入intermediate supervision，以用来缓解端到端网络使用BP训练中出现的梯度消失的问题（有待验证）。</span></p> 
  <p><span style="color:#000000;">利用卷积网络先从局部特征入手，确定了一个或者是多个关节点，这样就可以借助已知的关节点来对其他身体部位进行定位。</span></p> 
  <p><span style="color:#000000;">数据集： MPII,LSP, and FLIC datasets</span></p> 
  <p><span style="color:#000000;">文中不足： 对于密集的多人估计效果是很差的；</span></p> 
  <p>&nbsp;</p> 
  <p><span style="color:#000000;">2. Stacked Hourglass Networks for Human&nbsp;Pose Estimation,2016</span></p> 
  <p><img alt="" class="has" height="538" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504203919354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><img alt="" class="has" height="660" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504203910350.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><span style="color:#000000;"></span></p> 
  <p><span style="color:#000000;">一种沙漏型的网络结构，首先进行卷积处理并进行下采样处理，获得一些分辨率较低的特征，来降低计算的复杂度；紧接着又采用上采样操作来提升图像特征的分辨率，同时也使得网络更有能力预测物体的精确位置；而且这种沙漏结构具有可堆叠性。在此工作中，也在不同阶段采用intermediate supervision方法。</span></p> 
  <p><span style="color:#000000;">此方法相比于CMPs，在精度和速度上都略胜一筹。</span></p> 
  <p><span style="color:#000000;">数据集：FLIC and MPII</span></p> 
  <p><span style="color:#000000;">此方法也对密集多人姿态估计进行了测试，表现效果相比CMPs有很大提升。</span></p> 
  <p>&nbsp;</p> 
  <p><span style="color:#000000;">3. 3D Human Pose Estimation in the Wild by Adversarial Learning，CVPR2018</span></p> 
  <p><img alt="" class="has" height="813" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504203941801.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="743"></p> 
  <p><span style="color:#000000;"></span></p> 
  <p><span style="color:#000000;">本文工作采用对抗学习框架，从有完全注释的数据集中学习3D pose，然后应用到只有2D 标注数据的野外图像中；设计可以了一个multi-source 的判别器，来识别预测到的3D pose 是否为GT.</span></p> 
  <p>&nbsp;</p> 
  <p><span style="color:#000000;">4. End-to-end Recovery of Human Shape and Pose；2018</span></p> 
  <p><img alt="" class="has" height="804" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504203954645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><span style="color:#000000;"></span></p> 
  <p><span style="color:#000000;">本文工作使用端到端的框架，直接从单张彩色图片中恢复出3D 人体网格（包括人体形状和关节角度），不需要依赖中间任务（如2D估计）。</span></p> 
  <p><span style="color:#000000;">文中使用两个数据集，一个是带有2D标注信息的实况数据集，另一个是人体3D模型数据集。获得一幅图时，先获取其3D mseh参数，然后推断出其3D joint，再映射到2D，与原图的2D joint匹配，即一个2D-3D-2D过程，把无3D标注的2D当成训练集使用。在参数预测上则采用了iterative regression with feedback的方法。另外，为了使生成的模型符合真实的人体结构，使用GAN的网络结构，把生成模型的参数输入到一个Discriminator中，Discriminator在训练中学习每个joint之间的角度限制，由Discriminator来判断模型是否真实。</span></p> 
  <p><span style="color:#000000;">优点：直接从图像中推断其三维网格参数，训练省事不易丢失图片信息；而且不需要有paired 2D-3D数据集，为从大量2D数据学习3D提供可能性。</span></p> 
  <p><span style="color:#000000;">5. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose&nbsp;and Shape Estimation；2018</span></p> 
  <p><img alt="" class="has" height="725" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504204003927.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><span style="color:#000000;"></span></p> 
  <p><span style="color:#000000;">文章中使用基于2D的区域表示，将人体分为12个部分，作为映射到3D的一个中间步骤；</span></p> 
  <p><span style="color:#000000;">文中提出一种新的方法-Neural Body Fitting(NBF)，结合CNN使用这一种statistical body model，利用bottom-up semantic body part segmentation and top-down body model constraints，采用端到端的训练方式。</span></p> 
  <p><span style="color:#000000;">NBF用一个standard semantic CNN 将人体分为12个部位，然后encoding CNN 直接从RGB image或者是semantic segmentation of image中预测模型参数，再通过SMPL产生3D mesh；最后再将3D mesh的关节点重投影到2D，reprojection loss采用BP方法，来训练整个网络。</span></p> 
  <p><span style="color:#000000;">除此之外，文章中对很多工作做了分析，比如什么样的输入更好，loss function怎么设置，3D annotation数据量对结果影响，以及分割效果对于效果的影响等等。</span></p> 
  <p><span style="color:#000000;">文章中仅仅使用百分之二十的3D标注训练集就可以取得和使得全部3D标注训练集相似的结果。</span></p> 
  <p><span style="color:#000000;">未来工作：密集的多人姿态估计。</span></p> 
  <p>&nbsp;</p> 
  <p><span style="color:#000000;">6. Learning to Estimate 3D Human Pose and Shape from a Single Color Image，2018</span></p> 
  <p><img alt="" class="has" height="836" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504204011723.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><span style="color:#000000;"></span></p> 
  <p><span style="color:#000000;">文中工作把SMPL模型嵌入端到端的框架，从单个彩色图像中估计人体的姿势和形状；提出一种基于卷积网络的高效的直接预测方法，其优于迭代优化的方法。</span></p> 
  <p><span style="color:#000000;">首先训练一个卷及网络human2D，其产生两个输出，轮廓（包括人体和背景两个）和热图（输出关键点）； 接下来，训练两个网络，一个是poseprior，使用2D关键点作为输入，检测置信度并估计姿态系数theta，另一个是shapeprior，使用轮廓作为输入，并估计其形状系数beta，最后进行参数size转换，对应于SMPL模型的系数theta和beta。最后将生成的3D人体模型实例投影到图像平面，并计算其轮廓与2D关键点位置的已生成训练输入输出对。</span></p> 
  <p><span style="color:#000000;">网络优点：参数少，有利于直接进行预测；训练生成3D网格，并对其表面光滑度进行优化。</span></p> 
  <p>&nbsp;</p> 
  <p><span style="color:#000000;">7. RepNet: Weakly Supervised Training of an Adversarial Reprojection Network&nbsp;for 3D Human Pose Estimation ; CVPR2019</span></p> 
  <p><img alt="" class="has" height="337" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504204021944.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="767"></p> 
  <p><span style="color:#000000;"></span></p> 
  <p><span style="color:#000000;">本文是一种从2D 学习3D的方法；</span></p> 
  <p><span style="color:#000000;">利用神经网络类直接估计3D pose的工作大多都忽略了 &nbsp;最终的估计应该满足重投影误差，而且目前神经网络的方法很容易导致过拟合；本文工作忽略2D和3D之间的一致性而解决过拟合问题，并且避免网络对训练数据产生一定的记忆，允许弱监督训练。</span></p> 
  <p><span style="color:#000000;">文中运用对抗网络的思想，网络主要分为两个部分，一个部分是reprojection network，其使用对抗训练的方法学习2D pose 到3D pose分布的map；另一部分网络estimate camera，这能够使得预测得到的3D pose重投影回2D ，从而计算reprojection loss function。</span></p> 
  <p><span style="color:#000000;">实验结果优于其他的弱监督方法，同时解决一定数据量的过拟合问题；优于部分监督学习模型。</span></p> 
  <p><span style="color:#000000;">文中指出： 在Human3.6M数据集上训练的网络用于预测MPI-INF-3DHP（unseen data）数据，相比其他方法有很大提升。</span></p> 
  <p>&nbsp;</p> 
  <p><span style="color:#000000;">8. DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a</span></p> 
  <p><span style="color:#000000;">Single Color Image；2019</span></p> 
  <p><img alt="" class="has" height="474" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504204030493.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQwMDQ1MzA5,size_16,color_FFFFFF,t_70" width="1200"></p> 
  <p><span style="color:#000000;"></span></p> 
  <p><span style="color:#000000;">提出一种端到端的方法，直接从单个彩色图片中得到3D 人体网格；该研究训练一个编码器-解码器网格，无需使用任何中间任务，如2D 估计等。</span></p> 
  <p><span style="color:#000000;">之前的研究通常使用SMPL 这样的可变型模型来表示3D 人体结构，但是本文利用UV位置映射图来表示3D人体几何结构（UV是一个2D表示图，如上图所示），用UV映射图来储存整个人体表面的三维位置信息。</span></p> 
  <p>&nbsp;</p> 
  <h1 style="margin-left:0px;"><strong><span style="color:#000000;">七、总结</span></strong></h1> 
  <h2 style="margin-left:0px;"><strong><span style="color:#000000;">1. 问题难点</span></strong></h2> 
  <p><span style="color:#000000;">（1）数据： 缺少足够量的带有ground truth 3D annotation的in-the-wild图像，目前已有的带有标注的图像大多数是在特定实验环境中获取的，并不足以反映真实环境下可能出现的情况；</span></p> 
  <p><span style="color:#000000;">（2）2D与3D之间映射存在一定的模糊性，因为缺少一些深度信息（或者其他的辅助性信息），许多的三维模型可以映射为同一个2D模型，但是反之，从二维映射到三维时，未必能真正反映人体结构。</span></p> 
  <h2 style="margin-left:0px;"><strong><span style="color:#000000;">2.基于深度学习的方法</span></strong></h2> 
  <p><span style="color:#000000;">关于3D pose estimation的方法主要可以分为两类，简言之，就是一阶段法和二阶段法，以下会讲解两种方法的大概流程：</span></p> 
  <h3 style="margin-left:0px;"><strong><span style="color:#000000;">2.1. 一阶段法</span></strong></h3> 
  <p><span style="color:#000000;">直接从图片中获取3D 关节点位置，然后reproject 到2D，与有ground truth 2D annotation数据集对比，进而优化网络。</span></p> 
  <p><span style="color:#000000;">优点：不易丢失图片信息。</span></p> 
  <h3 style="margin-left:0px;"><strong><span style="color:#000000;">2.2. 二阶段法</span></strong></h3> 
  <p><span style="color:#000000;">（1）用2D pose检测，预测2D关节点位置；</span></p> 
  <p><span style="color:#000000;">（2）通过回归分析或者model fitting的方式，从2D中预测3D关节点位置；这种方法有一个共性，就是会利用一个预测3D 模型的框架，主要是SMPL；</span></p> 
  <p><span style="color:#000000;">注：对于这样的一种方法，为了约束2D-to-3D固有的这种模糊性，会利用一些先验知识：假定四肢长度或者是比例；</span></p> 
  <p><span style="color:#000000;">缺点：但是这样的方法或过度依赖2D关节点的位置信息，有可能会丢掉图片中的其他信息。</span></p> 
  <p>&nbsp;</p> 
  <h1 style="margin-left:0px;"><strong><span style="color:#000000;">八、参考文献</span></strong></h1> 
  <p><span style="color:#000000;">1.Convolutional Pose Machines；</span></p> 
  <p><span style="color:#000000;">2. Stacked Hourglass Networks for Human&nbsp;Pose Estimation；</span></p> 
  <p><span style="color:#000000;">3. 3D Human Pose Estimation in the Wild by Adversarial Learning；</span></p> 
  <p><span style="color:#000000;">4. End-to-end Recovery of Human Shape and Pose；</span></p> 
  <p><span style="color:#000000;">5. Neural Body Fitting: Unifying Deep Learning and Model Based Human Pose&nbsp;and Shape Estimation；</span></p> 
  <p><span style="color:#000000;">6. Learning to Estimate 3D Human Pose and Shape from a Single Color Image；</span></p> 
  <p><span style="color:#000000;">7. RepNet: Weakly Supervised Training of an Adversarial Reprojection Network&nbsp;for 3D Human Pose Estimation&nbsp;；</span></p> 
  <p><span style="color:#000000;">8. DenseBody: Directly Regressing Dense 3D Human Pose and Shape From a&nbsp;Single Color Image；</span></p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
