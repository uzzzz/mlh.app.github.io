<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>kafka 安装（非CDH） | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="kafka 安装（非CDH）" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="大数据组件安装(非CDH) 总文章 &nbsp; 1.安装准备 &nbsp;&nbsp; &nbsp;1.安装jdk、安装zookeeper &nbsp;&nbsp; &nbsp;2.安装目录 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;数据目录：mkdir -p /root/kafkaData&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;日志目录：mkdir -p /root/kafkaLogs &nbsp;&nbsp; &nbsp;3.tar -zxvf kafka_2.11-1.0.0.tgz -C &nbsp; &nbsp;&nbsp; &nbsp;4.mv kafka_2.11-1.0.0 kafka &nbsp;&nbsp; &nbsp;5.启动zookeeper 都必须执行 时间同步命令：ntpdate ntp6.aliyun.com &nbsp;&nbsp; &nbsp; &nbsp;kafka安装前，最好配置一下定时脚本(时间同步)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;crontab &nbsp;-e &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*/1 * * * * /usr/sbin/ntpdate cn.pool.ntp.org; 2.修改配置文件 &nbsp;&nbsp; &nbsp;vim /root/kafka/config/server.properties 修改三个地方 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.borker中间者的id(唯一标识符id 标识 kafka集群中的 每一台kafka服务器) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# broker.id 标识了“kafka集群中一个kafka服务器中的”唯一的broker。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.network.threads=3 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.io.threads=8 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.send.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.receive.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.request.max.bytes=104857600 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.数据存放的目录，注意目录如果不存在，需要新建下。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# 存放生产者生产的数据 数据一般以topic的方式存放 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# 创建一个数据存放目录，可以使用 mkdir -p 先创建出来 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.dirs=/root/kafkaData &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.partitions=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.recovery.threads.per.data.dir=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;offsets.topic.replication.factor=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;transaction.state.log.replication.factor=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;transaction.state.log.min.isr=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.segment.bytes=1073741824 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.check.interval.ms=300000 &nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.zookeeper的地址信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# zk的信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connect=NODE1:2181,NODE2:2181,NODE3:2181 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connection.timeout.ms=6000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;group.initial.rebalance.delay.ms=0 &nbsp;&nbsp; &nbsp; 3.分发配置文件到NODE2和NODE3&nbsp; &nbsp;&nbsp; &nbsp;scp -r /root/kafka NODE2:/root &nbsp;&nbsp; &nbsp;scp -r /root/kafka NODE3:/root 4.分别修改NODE2、NODE3上的broker.id，并且在每个linux下创建数据存放目录&nbsp; &nbsp;&nbsp; &nbsp;1.vi /root/kafka/config/server.properties &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# borker中间者的id(唯一标识符id 标识 kafka集群中的 每一台kafka服务器) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# broker.id 标识了“kafka集群中一个kafka服务器中的”唯一的broker。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=数字 &nbsp;&nbsp; &nbsp; &nbsp;修改如下： &nbsp;&nbsp; &nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE2：broker.id=1 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;NODE3：broker.id=2 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;2.每个linux下创建数据存放目录：mkdir -p /root/kafkaData 5.每台机器都启动zookeeper（启动zookeeper 都必须执行 时间同步命令：ntpdate ntp6.aliyun.com） &nbsp;&nbsp; &nbsp;cd /root/zookeeper/bin/ &nbsp;&nbsp; &nbsp;zkServer.sh start &nbsp; 查看集群状态、主从信息： &nbsp;&nbsp; &nbsp;1.cd /root/zookeeper/bin/ &nbsp;&nbsp; &nbsp;2../zkServer.sh status # 查看状态：一个leader，两个follower &nbsp;&nbsp; &nbsp;3.“follower跟随者”的打印结果： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMX enabled by default &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Using config: /root/zookeeper/bin/../conf/zoo.cfg &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Mode: follower &nbsp;&nbsp; &nbsp;4.“leader领导者”的打印结果： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMX enabled by default &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Using config: /root/zookeeper/bin/../conf/zoo.cfg &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Mode: leader 6.配置环境变量 &nbsp;&nbsp; &nbsp;1.vim /etc/profile 配置kafka路径 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;export KAFKA_HOME=/root/kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;export PATH=$PATH:$KAFKA_HOME/bin &nbsp;&nbsp;&nbsp; &nbsp;2.分发配置文件到NODE2和NODE3&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;scp -r /etc/profile NODE2:/etc &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;scp -r /etc/profile NODE3:/etc &nbsp;&nbsp; &nbsp;3.source /etc/profile 7.每台机器都启动kafka进行kafka集群 &nbsp;&nbsp; &nbsp;cd /root/kafka/bin &nbsp;&nbsp; &nbsp;chmod 777 kafka-server-start.sh &nbsp;&nbsp; &nbsp;chmod 777 /root/kafka/bin/kafka-run-class.sh &nbsp;&nbsp; &nbsp;./kafka-server-start.sh /root/kafka/config/server.properties 8.Kafka集群一键启动脚本、一键关闭脚本 &nbsp;&nbsp; &nbsp;一键启动：cd /root/kafkaSH &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; chmod 777 startkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; ./startkafka.sh &nbsp;&nbsp; &nbsp;一键关闭：cd /root/kafkaSH &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; chmod 777 stopkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; ./stopkafka.sh &nbsp;&nbsp; &nbsp;1.首先需要创建一个slave文件中配置集群中的各个主机名，用于给一键启动脚本读取该文件中的集群中的各个主机名 &nbsp;&nbsp; &nbsp; &nbsp;注意：此处要在第四行给一个空行，那么脚本才能顺利加载到第三行信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE2 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE3 &nbsp;&nbsp; &nbsp;2.一键启动脚本startkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cat /root/kafkaSH/slave | while read line &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;do &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;echo $line &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ssh $line &quot;source /etc/profile;nohup kafka-server-start.sh /root/kafka/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp;&quot; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;wait &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;done&nbsp; &nbsp;&nbsp; &nbsp;3.一键关闭脚本stopkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cat /root/kafkaSH/slave | while read line &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;do &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;echo $line &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ssh $line &quot;source /etc/profile;jps |grep Kafka |cut -c 1-4 |xargs kill -s 9 &quot; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;wait &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;done&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.每个linux执行jps命令查看，表示成功启动 9.查看Kafka集群信息工具：ZooInspector &nbsp;&nbsp; &nbsp;由于kafka集群并没有UI界面可以查看。需要借助外部工具ZooInspector，来查看kafka集群。这个工具是一个java程序ZooInspector，必须要安装好JDK。 &nbsp; 10.kafkaManager监控工具的安装与使用 &nbsp;&nbsp; &nbsp;1.yum install unzip&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;unzip kafka-manager-1.3.3.7.zip &nbsp;&nbsp; &nbsp; &nbsp;mv kafka-manager-1.3.3.7 kafka-manager&nbsp; &nbsp;&nbsp; &nbsp;2.修改application.conf配置里面的zk连接地址： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;vim /root/kafka-manager/conf/application.conf：kafka-manager.zkhosts=&quot;NODE1:2181,NODE2:2181,NODE3:2181&quot; &nbsp;&nbsp; &nbsp;3.nohup 后台启动kafkaManager &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cd /root/kafka-manager/bin &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;nohup ./kafka-manager &nbsp;-Dconfig.file=/root/kafka-manager/conf/application.conf -Dhttp.port=8070 &nbsp;&gt;/dev/null 2&gt;&amp;1 &amp; &nbsp;&nbsp; &nbsp;4.jps命令查看是否启动成功 &nbsp;&nbsp; &nbsp;5.webUI页面访问：192.168.25.100:8070&nbsp; &nbsp;" />
<meta property="og:description" content="大数据组件安装(非CDH) 总文章 &nbsp; 1.安装准备 &nbsp;&nbsp; &nbsp;1.安装jdk、安装zookeeper &nbsp;&nbsp; &nbsp;2.安装目录 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;数据目录：mkdir -p /root/kafkaData&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;日志目录：mkdir -p /root/kafkaLogs &nbsp;&nbsp; &nbsp;3.tar -zxvf kafka_2.11-1.0.0.tgz -C &nbsp; &nbsp;&nbsp; &nbsp;4.mv kafka_2.11-1.0.0 kafka &nbsp;&nbsp; &nbsp;5.启动zookeeper 都必须执行 时间同步命令：ntpdate ntp6.aliyun.com &nbsp;&nbsp; &nbsp; &nbsp;kafka安装前，最好配置一下定时脚本(时间同步)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;crontab &nbsp;-e &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*/1 * * * * /usr/sbin/ntpdate cn.pool.ntp.org; 2.修改配置文件 &nbsp;&nbsp; &nbsp;vim /root/kafka/config/server.properties 修改三个地方 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.borker中间者的id(唯一标识符id 标识 kafka集群中的 每一台kafka服务器) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# broker.id 标识了“kafka集群中一个kafka服务器中的”唯一的broker。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.network.threads=3 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.io.threads=8 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.send.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.receive.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.request.max.bytes=104857600 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.数据存放的目录，注意目录如果不存在，需要新建下。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# 存放生产者生产的数据 数据一般以topic的方式存放 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# 创建一个数据存放目录，可以使用 mkdir -p 先创建出来 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.dirs=/root/kafkaData &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.partitions=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.recovery.threads.per.data.dir=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;offsets.topic.replication.factor=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;transaction.state.log.replication.factor=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;transaction.state.log.min.isr=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.segment.bytes=1073741824 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.check.interval.ms=300000 &nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.zookeeper的地址信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# zk的信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connect=NODE1:2181,NODE2:2181,NODE3:2181 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connection.timeout.ms=6000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;group.initial.rebalance.delay.ms=0 &nbsp;&nbsp; &nbsp; 3.分发配置文件到NODE2和NODE3&nbsp; &nbsp;&nbsp; &nbsp;scp -r /root/kafka NODE2:/root &nbsp;&nbsp; &nbsp;scp -r /root/kafka NODE3:/root 4.分别修改NODE2、NODE3上的broker.id，并且在每个linux下创建数据存放目录&nbsp; &nbsp;&nbsp; &nbsp;1.vi /root/kafka/config/server.properties &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# borker中间者的id(唯一标识符id 标识 kafka集群中的 每一台kafka服务器) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# broker.id 标识了“kafka集群中一个kafka服务器中的”唯一的broker。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=数字 &nbsp;&nbsp; &nbsp; &nbsp;修改如下： &nbsp;&nbsp; &nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE2：broker.id=1 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;NODE3：broker.id=2 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;2.每个linux下创建数据存放目录：mkdir -p /root/kafkaData 5.每台机器都启动zookeeper（启动zookeeper 都必须执行 时间同步命令：ntpdate ntp6.aliyun.com） &nbsp;&nbsp; &nbsp;cd /root/zookeeper/bin/ &nbsp;&nbsp; &nbsp;zkServer.sh start &nbsp; 查看集群状态、主从信息： &nbsp;&nbsp; &nbsp;1.cd /root/zookeeper/bin/ &nbsp;&nbsp; &nbsp;2../zkServer.sh status # 查看状态：一个leader，两个follower &nbsp;&nbsp; &nbsp;3.“follower跟随者”的打印结果： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMX enabled by default &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Using config: /root/zookeeper/bin/../conf/zoo.cfg &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Mode: follower &nbsp;&nbsp; &nbsp;4.“leader领导者”的打印结果： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMX enabled by default &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Using config: /root/zookeeper/bin/../conf/zoo.cfg &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Mode: leader 6.配置环境变量 &nbsp;&nbsp; &nbsp;1.vim /etc/profile 配置kafka路径 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;export KAFKA_HOME=/root/kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;export PATH=$PATH:$KAFKA_HOME/bin &nbsp;&nbsp;&nbsp; &nbsp;2.分发配置文件到NODE2和NODE3&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;scp -r /etc/profile NODE2:/etc &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;scp -r /etc/profile NODE3:/etc &nbsp;&nbsp; &nbsp;3.source /etc/profile 7.每台机器都启动kafka进行kafka集群 &nbsp;&nbsp; &nbsp;cd /root/kafka/bin &nbsp;&nbsp; &nbsp;chmod 777 kafka-server-start.sh &nbsp;&nbsp; &nbsp;chmod 777 /root/kafka/bin/kafka-run-class.sh &nbsp;&nbsp; &nbsp;./kafka-server-start.sh /root/kafka/config/server.properties 8.Kafka集群一键启动脚本、一键关闭脚本 &nbsp;&nbsp; &nbsp;一键启动：cd /root/kafkaSH &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; chmod 777 startkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; ./startkafka.sh &nbsp;&nbsp; &nbsp;一键关闭：cd /root/kafkaSH &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; chmod 777 stopkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; ./stopkafka.sh &nbsp;&nbsp; &nbsp;1.首先需要创建一个slave文件中配置集群中的各个主机名，用于给一键启动脚本读取该文件中的集群中的各个主机名 &nbsp;&nbsp; &nbsp; &nbsp;注意：此处要在第四行给一个空行，那么脚本才能顺利加载到第三行信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE2 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE3 &nbsp;&nbsp; &nbsp;2.一键启动脚本startkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cat /root/kafkaSH/slave | while read line &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;do &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;echo $line &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ssh $line &quot;source /etc/profile;nohup kafka-server-start.sh /root/kafka/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp;&quot; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;wait &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;done&nbsp; &nbsp;&nbsp; &nbsp;3.一键关闭脚本stopkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cat /root/kafkaSH/slave | while read line &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;do &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;echo $line &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ssh $line &quot;source /etc/profile;jps |grep Kafka |cut -c 1-4 |xargs kill -s 9 &quot; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;wait &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;done&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.每个linux执行jps命令查看，表示成功启动 9.查看Kafka集群信息工具：ZooInspector &nbsp;&nbsp; &nbsp;由于kafka集群并没有UI界面可以查看。需要借助外部工具ZooInspector，来查看kafka集群。这个工具是一个java程序ZooInspector，必须要安装好JDK。 &nbsp; 10.kafkaManager监控工具的安装与使用 &nbsp;&nbsp; &nbsp;1.yum install unzip&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;unzip kafka-manager-1.3.3.7.zip &nbsp;&nbsp; &nbsp; &nbsp;mv kafka-manager-1.3.3.7 kafka-manager&nbsp; &nbsp;&nbsp; &nbsp;2.修改application.conf配置里面的zk连接地址： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;vim /root/kafka-manager/conf/application.conf：kafka-manager.zkhosts=&quot;NODE1:2181,NODE2:2181,NODE3:2181&quot; &nbsp;&nbsp; &nbsp;3.nohup 后台启动kafkaManager &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cd /root/kafka-manager/bin &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;nohup ./kafka-manager &nbsp;-Dconfig.file=/root/kafka-manager/conf/application.conf -Dhttp.port=8070 &nbsp;&gt;/dev/null 2&gt;&amp;1 &amp; &nbsp;&nbsp; &nbsp;4.jps命令查看是否启动成功 &nbsp;&nbsp; &nbsp;5.webUI页面访问：192.168.25.100:8070&nbsp; &nbsp;" />
<link rel="canonical" href="https://mlh.app/2019/05/04/729862.html" />
<meta property="og:url" content="https://mlh.app/2019/05/04/729862.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-04T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"大数据组件安装(非CDH) 总文章 &nbsp; 1.安装准备 &nbsp;&nbsp; &nbsp;1.安装jdk、安装zookeeper &nbsp;&nbsp; &nbsp;2.安装目录 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;数据目录：mkdir -p /root/kafkaData&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;日志目录：mkdir -p /root/kafkaLogs &nbsp;&nbsp; &nbsp;3.tar -zxvf kafka_2.11-1.0.0.tgz -C &nbsp; &nbsp;&nbsp; &nbsp;4.mv kafka_2.11-1.0.0 kafka &nbsp;&nbsp; &nbsp;5.启动zookeeper 都必须执行 时间同步命令：ntpdate ntp6.aliyun.com &nbsp;&nbsp; &nbsp; &nbsp;kafka安装前，最好配置一下定时脚本(时间同步)： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;crontab &nbsp;-e &nbsp;&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*/1 * * * * /usr/sbin/ntpdate cn.pool.ntp.org; 2.修改配置文件 &nbsp;&nbsp; &nbsp;vim /root/kafka/config/server.properties 修改三个地方 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.borker中间者的id(唯一标识符id 标识 kafka集群中的 每一台kafka服务器) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# broker.id 标识了“kafka集群中一个kafka服务器中的”唯一的broker。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=0 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.network.threads=3 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.io.threads=8 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.send.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.receive.buffer.bytes=102400 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.request.max.bytes=104857600 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.数据存放的目录，注意目录如果不存在，需要新建下。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# 存放生产者生产的数据 数据一般以topic的方式存放 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# 创建一个数据存放目录，可以使用 mkdir -p 先创建出来 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.dirs=/root/kafkaData &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.partitions=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.recovery.threads.per.data.dir=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;offsets.topic.replication.factor=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;transaction.state.log.replication.factor=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;transaction.state.log.min.isr=1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.hours=168 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.segment.bytes=1073741824 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.check.interval.ms=300000 &nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.zookeeper的地址信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# zk的信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connect=NODE1:2181,NODE2:2181,NODE3:2181 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connection.timeout.ms=6000 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;group.initial.rebalance.delay.ms=0 &nbsp;&nbsp; &nbsp; 3.分发配置文件到NODE2和NODE3&nbsp; &nbsp;&nbsp; &nbsp;scp -r /root/kafka NODE2:/root &nbsp;&nbsp; &nbsp;scp -r /root/kafka NODE3:/root 4.分别修改NODE2、NODE3上的broker.id，并且在每个linux下创建数据存放目录&nbsp; &nbsp;&nbsp; &nbsp;1.vi /root/kafka/config/server.properties &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# borker中间者的id(唯一标识符id 标识 kafka集群中的 每一台kafka服务器) &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# broker.id 标识了“kafka集群中一个kafka服务器中的”唯一的broker。 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=数字 &nbsp;&nbsp; &nbsp; &nbsp;修改如下： &nbsp;&nbsp; &nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE2：broker.id=1 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;NODE3：broker.id=2 &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;2.每个linux下创建数据存放目录：mkdir -p /root/kafkaData 5.每台机器都启动zookeeper（启动zookeeper 都必须执行 时间同步命令：ntpdate ntp6.aliyun.com） &nbsp;&nbsp; &nbsp;cd /root/zookeeper/bin/ &nbsp;&nbsp; &nbsp;zkServer.sh start &nbsp; 查看集群状态、主从信息： &nbsp;&nbsp; &nbsp;1.cd /root/zookeeper/bin/ &nbsp;&nbsp; &nbsp;2../zkServer.sh status # 查看状态：一个leader，两个follower &nbsp;&nbsp; &nbsp;3.“follower跟随者”的打印结果： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMX enabled by default &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Using config: /root/zookeeper/bin/../conf/zoo.cfg &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Mode: follower &nbsp;&nbsp; &nbsp;4.“leader领导者”的打印结果： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMX enabled by default &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Using config: /root/zookeeper/bin/../conf/zoo.cfg &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Mode: leader 6.配置环境变量 &nbsp;&nbsp; &nbsp;1.vim /etc/profile 配置kafka路径 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;export KAFKA_HOME=/root/kafka &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;export PATH=$PATH:$KAFKA_HOME/bin &nbsp;&nbsp;&nbsp; &nbsp;2.分发配置文件到NODE2和NODE3&nbsp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;scp -r /etc/profile NODE2:/etc &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;scp -r /etc/profile NODE3:/etc &nbsp;&nbsp; &nbsp;3.source /etc/profile 7.每台机器都启动kafka进行kafka集群 &nbsp;&nbsp; &nbsp;cd /root/kafka/bin &nbsp;&nbsp; &nbsp;chmod 777 kafka-server-start.sh &nbsp;&nbsp; &nbsp;chmod 777 /root/kafka/bin/kafka-run-class.sh &nbsp;&nbsp; &nbsp;./kafka-server-start.sh /root/kafka/config/server.properties 8.Kafka集群一键启动脚本、一键关闭脚本 &nbsp;&nbsp; &nbsp;一键启动：cd /root/kafkaSH &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; chmod 777 startkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; ./startkafka.sh &nbsp;&nbsp; &nbsp;一键关闭：cd /root/kafkaSH &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; chmod 777 stopkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; ./stopkafka.sh &nbsp;&nbsp; &nbsp;1.首先需要创建一个slave文件中配置集群中的各个主机名，用于给一键启动脚本读取该文件中的集群中的各个主机名 &nbsp;&nbsp; &nbsp; &nbsp;注意：此处要在第四行给一个空行，那么脚本才能顺利加载到第三行信息 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE1 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE2 &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE3 &nbsp;&nbsp; &nbsp;2.一键启动脚本startkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cat /root/kafkaSH/slave | while read line &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;do &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;echo $line &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ssh $line &quot;source /etc/profile;nohup kafka-server-start.sh /root/kafka/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp;&quot; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;wait &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;done&nbsp; &nbsp;&nbsp; &nbsp;3.一键关闭脚本stopkafka.sh &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cat /root/kafkaSH/slave | while read line &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;do &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{ &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;echo $line &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ssh $line &quot;source /etc/profile;jps |grep Kafka |cut -c 1-4 |xargs kill -s 9 &quot; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&amp; &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;wait &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;done&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;4.每个linux执行jps命令查看，表示成功启动 9.查看Kafka集群信息工具：ZooInspector &nbsp;&nbsp; &nbsp;由于kafka集群并没有UI界面可以查看。需要借助外部工具ZooInspector，来查看kafka集群。这个工具是一个java程序ZooInspector，必须要安装好JDK。 &nbsp; 10.kafkaManager监控工具的安装与使用 &nbsp;&nbsp; &nbsp;1.yum install unzip&nbsp; &nbsp;&nbsp; &nbsp; &nbsp;unzip kafka-manager-1.3.3.7.zip &nbsp;&nbsp; &nbsp; &nbsp;mv kafka-manager-1.3.3.7 kafka-manager&nbsp; &nbsp;&nbsp; &nbsp;2.修改application.conf配置里面的zk连接地址： &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;vim /root/kafka-manager/conf/application.conf：kafka-manager.zkhosts=&quot;NODE1:2181,NODE2:2181,NODE3:2181&quot; &nbsp;&nbsp; &nbsp;3.nohup 后台启动kafkaManager &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cd /root/kafka-manager/bin &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;nohup ./kafka-manager &nbsp;-Dconfig.file=/root/kafka-manager/conf/application.conf -Dhttp.port=8070 &nbsp;&gt;/dev/null 2&gt;&amp;1 &amp; &nbsp;&nbsp; &nbsp;4.jps命令查看是否启动成功 &nbsp;&nbsp; &nbsp;5.webUI页面访问：192.168.25.100:8070&nbsp; &nbsp;","@type":"BlogPosting","url":"https://mlh.app/2019/05/04/729862.html","headline":"kafka 安装（非CDH）","dateModified":"2019-05-04T00:00:00+08:00","datePublished":"2019-05-04T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/04/729862.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>kafka 安装（非CDH）</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post">  
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <h1><u><strong><a href="https://blog.csdn.net/zimiao552147572/article/details/88602425" rel="nofollow"><span style="color:#f33b45;">大数据组件安装(非CDH) 总文章</span></a></strong></u></h1> 
  <p>&nbsp;</p> 
  <p>1.安装准备<br> &nbsp;&nbsp; &nbsp;1.安装jdk、安装zookeeper<br> &nbsp;&nbsp; &nbsp;2.安装目录<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;数据目录：mkdir -p /root/kafkaData&nbsp;<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;日志目录：mkdir -p /root/kafkaLogs<br> &nbsp;&nbsp; &nbsp;3.tar -zxvf kafka_2.11-1.0.0.tgz -C &nbsp;<br> &nbsp;&nbsp; &nbsp;4.mv kafka_2.11-1.0.0 kafka<br> &nbsp;&nbsp; &nbsp;5.启动zookeeper 都必须执行 时间同步命令：ntpdate ntp6.aliyun.com<br> &nbsp;&nbsp; &nbsp; &nbsp;kafka安装前，最好配置一下定时脚本(时间同步)：<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;crontab &nbsp;-e &nbsp;&nbsp;<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;*/1 * * * * /usr/sbin/ntpdate cn.pool.ntp.org;</p> 
  <p>2.修改配置文件<br> &nbsp;&nbsp; &nbsp;vim /root/kafka/config/server.properties 修改三个地方<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;1.borker中间者的id(唯一标识符id 标识 kafka集群中的 每一台kafka服务器)<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# broker.id 标识了“kafka集群中一个kafka服务器中的”唯一的broker。<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=0<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.network.threads=3<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.io.threads=8<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.send.buffer.bytes=102400<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.receive.buffer.bytes=102400<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;socket.request.max.bytes=104857600</p> 
  <p>&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;2.数据存放的目录，注意目录如果不存在，需要新建下。<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# 存放生产者生产的数据 数据一般以topic的方式存放<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# 创建一个数据存放目录，可以使用 mkdir -p 先创建出来<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.dirs=/root/kafkaData<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.partitions=1<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;num.recovery.threads.per.data.dir=1<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;offsets.topic.replication.factor=1<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;transaction.state.log.replication.factor=1<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;transaction.state.log.min.isr=1<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.hours=168<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.segment.bytes=1073741824<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;log.retention.check.interval.ms=300000<br> &nbsp;<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;3.zookeeper的地址信息<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# zk的信息<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connect=NODE1:2181,NODE2:2181,NODE3:2181<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;zookeeper.connection.timeout.ms=6000<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;group.initial.rebalance.delay.ms=0<br> &nbsp;&nbsp; &nbsp;</p> 
  <p>3.分发配置文件到NODE2和NODE3&nbsp;<br> &nbsp;&nbsp; &nbsp;scp -r /root/kafka NODE2:/root<br> &nbsp;&nbsp; &nbsp;scp -r /root/kafka NODE3:/root</p> 
  <p>4.分别修改NODE2、NODE3上的broker.id，并且在每个linux下创建数据存放目录&nbsp;<br> &nbsp;&nbsp; &nbsp;1.vi /root/kafka/config/server.properties<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# borker中间者的id(唯一标识符id 标识 kafka集群中的 每一台kafka服务器)<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;# broker.id 标识了“kafka集群中一个kafka服务器中的”唯一的broker。<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;broker.id=数字<br> &nbsp;&nbsp; &nbsp; &nbsp;修改如下：<br> &nbsp;&nbsp; &nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE2：broker.id=1<br> &nbsp;&nbsp; &nbsp; &nbsp;&nbsp; &nbsp;NODE3：broker.id=2<br> &nbsp;&nbsp; &nbsp;<br> &nbsp;&nbsp; &nbsp;2.每个linux下创建数据存放目录：mkdir -p /root/kafkaData</p> 
  <p>5.每台机器都启动zookeeper（启动zookeeper 都必须执行 时间同步命令：ntpdate ntp6.aliyun.com）<br> &nbsp;&nbsp; &nbsp;cd /root/zookeeper/bin/<br> &nbsp;&nbsp; &nbsp;zkServer.sh start</p> 
  <p>&nbsp; 查看集群状态、主从信息：<br> &nbsp;&nbsp; &nbsp;1.cd /root/zookeeper/bin/<br> &nbsp;&nbsp; &nbsp;2../zkServer.sh status # 查看状态：一个leader，两个follower<br> &nbsp;&nbsp; &nbsp;3.“follower跟随者”的打印结果：<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMX enabled by default<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Using config: /root/zookeeper/bin/../conf/zoo.cfg<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Mode: follower<br> &nbsp;&nbsp; &nbsp;4.“leader领导者”的打印结果：<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;JMX enabled by default<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Using config: /root/zookeeper/bin/../conf/zoo.cfg<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;Mode: leader</p> 
  <p>6.配置环境变量<br> &nbsp;&nbsp; &nbsp;1.vim /etc/profile 配置kafka路径<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;export KAFKA_HOME=/root/kafka<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;export PATH=$PATH:$KAFKA_HOME/bin<br> &nbsp;&nbsp;&nbsp; &nbsp;2.分发配置文件到NODE2和NODE3&nbsp;<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;scp -r /etc/profile NODE2:/etc<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;scp -r /etc/profile NODE3:/etc<br> &nbsp;&nbsp; &nbsp;3.source /etc/profile</p> 
  <p>7.每台机器都启动kafka进行kafka集群<br> &nbsp;&nbsp; &nbsp;cd /root/kafka/bin<br> &nbsp;&nbsp; &nbsp;chmod 777 kafka-server-start.sh<br> &nbsp;&nbsp; &nbsp;chmod 777 /root/kafka/bin/kafka-run-class.sh<br> &nbsp;&nbsp; &nbsp;./kafka-server-start.sh /root/kafka/config/server.properties</p> 
  <p>8.Kafka集群一键启动脚本、一键关闭脚本<br> &nbsp;&nbsp; &nbsp;一键启动：cd /root/kafkaSH<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; chmod 777 startkafka.sh<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; ./startkafka.sh<br> &nbsp;&nbsp; &nbsp;一键关闭：cd /root/kafkaSH<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; chmod 777 stopkafka.sh<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp; ./stopkafka.sh</p> 
  <p>&nbsp;&nbsp; &nbsp;1.首先需要创建一个slave文件中配置集群中的各个主机名，用于给一键启动脚本读取该文件中的集群中的各个主机名<br> &nbsp;&nbsp; &nbsp; &nbsp;注意：此处要在第四行给一个空行，那么脚本才能顺利加载到第三行信息<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE1<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE2<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;NODE3</p> 
  <p>&nbsp;&nbsp; &nbsp;2.一键启动脚本startkafka.sh<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cat /root/kafkaSH/slave | while read line<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;do<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{<br> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;echo $line<br> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ssh $line "source /etc/profile;nohup kafka-server-start.sh /root/kafka/config/server.properties &gt;/dev/null 2&gt;&amp;1 &amp;"<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&amp;<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;wait<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;done&nbsp;<br> &nbsp;&nbsp; &nbsp;3.一键关闭脚本stopkafka.sh<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cat /root/kafkaSH/slave | while read line<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;do<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;{<br> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;echo $line<br> &nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;ssh $line "source /etc/profile;jps |grep Kafka |cut -c 1-4 |xargs kill -s 9 "<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;}&amp;<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;wait<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;done&nbsp;</p> 
  <p>&nbsp;&nbsp;&nbsp; &nbsp;4.每个linux执行jps命令查看，表示成功启动</p> 
  <p><img alt="" class="has" height="75" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220359583.png" width="201"></p> 
  <p>9.查看Kafka集群信息工具：ZooInspector<br> &nbsp;&nbsp; &nbsp;由于kafka集群并没有UI界面可以查看。需要借助外部工具ZooInspector，来查看kafka集群。这个工具是一个java程序ZooInspector，必须要安装好JDK。</p> 
  <p><img alt="" class="has" height="547" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220355195.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3ppbWlhbzU1MjE0NzU3Mg==,size_16,color_FFFFFF,t_70" width="1200"><br> &nbsp;<br> 10.kafkaManager监控工具的安装与使用<br> &nbsp;&nbsp; &nbsp;1.yum install unzip&nbsp;<br> &nbsp;&nbsp; &nbsp; &nbsp;unzip kafka-manager-1.3.3.7.zip<br> &nbsp;&nbsp; &nbsp; &nbsp;mv kafka-manager-1.3.3.7 kafka-manager&nbsp;<br> &nbsp;&nbsp; &nbsp;2.修改application.conf配置里面的zk连接地址：<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;vim /root/kafka-manager/conf/application.conf：kafka-manager.zkhosts="NODE1:2181,NODE2:2181,NODE3:2181"<br> &nbsp;&nbsp; &nbsp;3.nohup 后台启动kafkaManager<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;cd /root/kafka-manager/bin<br> &nbsp;&nbsp; &nbsp;&nbsp;&nbsp; &nbsp;nohup ./kafka-manager &nbsp;-Dconfig.file=/root/kafka-manager/conf/application.conf -Dhttp.port=8070 &nbsp;&gt;/dev/null 2&gt;&amp;1 &amp;</p> 
  <p>&nbsp;&nbsp; &nbsp;4.jps命令查看是否启动成功</p> 
  <p><img alt="" class="has" height="95" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504220343810.png" width="221"></p> 
  <p>&nbsp;&nbsp; &nbsp;5.webUI页面访问：192.168.25.100:8070&nbsp;<br> &nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
