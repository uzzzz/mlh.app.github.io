<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>卷积神经网络第一章 卷积神经网络 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="卷积神经网络第一章 卷积神经网络" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="1.1 计算机视觉 一般的CV问题包括以下三类： 图片分类已经见过。 目标检测中首先要计算出图中有哪些物体，再将他们模拟成一个个盒子，以便你的车可以避开他们。 风格转换是用神经网络把你的照片和一张风格照片融合到一起，描绘出一张新的照片，整体轮廓来自左边，风格来自右边。 使用传统神经网络处理计算机视觉的一个主要问题是输入层维度很大，解决方法是用CNN。 1.2 了解卷积：边缘检测示例 我们之前讲过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（如眼睛、鼻子等）、整体面部轮廓。 这一小节讲如何检测图片边缘。最常检测的图片边缘有两类：一是垂直边缘，二是水平边缘。 原始图片的尺寸是66，滤波器filter的尺寸是33，通过卷积运算得到尺寸为44的图片。 数学中卷积用表示，python中用conv-forward()表示，TensorFlow中用tf.nn.conv2d()表示,keras中用Conv2D()表示。 1.3 更多边缘检测内容 由亮向暗还是由暗向亮过度，滤波器可以帮我们区分这两种的区别： 水平边缘检测的滤波器算子就是吧垂直边缘检测的滤波器翻转90度： 还有一些filter，可能更robust；同时filter的数值可以作为参数通过训练得到，类似于标准神经网络中的权重W通过梯度下降迭代得到，也可以检测到图片的各种边缘特征。CNN的主要目的就是计算出这些filter的数值。确定得到了这些filter后，CNN浅层网络也就实现了对图片所有边缘特征的检测。 1.4 Padding 按照上面的卷积方式，原始图片为nn, filter为ff, 则卷积后图片尺寸为(n-f+1)*(n-f+1), 这会带来图片尺寸缩小问题，而且可以看出来原始图片边缘信息对输出贡献小，输出图片丢失边缘信息。 为了解决这两个问题，可以使用padding方法，即把原始图片尺寸拓展，拓展区域补0，用p来表示每个方向拓展的宽度。 经过padding，原始图片尺寸为(n+2p) x (n+2p)，filter尺寸为f x f，则卷积后的图片尺寸为(n+2p-f+1) x (n+2p-f+1)。“Same convolutions’使卷积前后图片尺寸不变，即p为（f-1)/2。(f基本都是奇数) “valid convolution”就是p为0。 1.5 卷积步长 stride步长表示filter在原图片中水平和垂直方向每次的步进长度。图片尺寸为：(除不尽的时候向下取整) 实际上，我们的操作在数学上是相关系数cross-correlations不是卷积convolution，但是深度学习论文中常常默认叫卷积因为忽略镜面翻转可以提高CNN速度而不影响模型性能。真正的卷积是要先把filter镜面翻转，真正的卷积也有结合律。 1.6 卷积为何有效 对于3通道的RGB图片，其对应的滤波器算子也需要是3通道的。例如一个图片是663，分别表示height、width、channel通道数。 卷积运算方法类似，对应数字相乘相加，得到输出图片的一个像素值。 不同通道的滤波算子可以不同，不同的filter检测不同的特征。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。 维度：输入图片nnnc(通道数），filter为ffnc(有nc’个), 输出图片(n-f+1)*(n-f+1) *nc’。 1.7 单层卷积网络 卷积神经网络一层的结构： 计算一下参数的数目：每个滤波器有W：333=27个，一个b,一共28个；两个滤波器就有28*2=56个。可以看到参数的数目和输入图片的尺寸无关，就不存在由于图片尺寸过大造成参数过多的情况。例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，参数数目只由滤波器组决定，数目相对来说要少得多，这是CNN的优势之一。 符号总结： A[l]是m个a[l]，即在前面乘以m。 weights就是nc[l]个each filter is的组合，即维度又乘以nc[l]。 记忆方法：nc[l-1]是通道数，nc[l]是滤波器个数。 1.8 简单卷积网络示例 一个简单的CNN网络模型： 把这几层最终得到的7740个特征（即a[3]），即1960，作为一列把这个长向量填充到逻辑回归或softmax回归函数中,得到最后的输出y hat。 可以看到，随着CNN层数增加，nH[l]和nW[l]逐渐减小，nc[l]通道数逐渐增加。 关于超参数的选择以后的视频会给一些指导。 一个典型的卷积神经网络通常有三层，卷积层、池化层、全连接层。 1.9 池化层 pooling layers是CNN中用来减小尺寸的，提高运算速度的，同样能减小noise影响，让各特征更robust。 pooling layers的做法比convolution layers简单许多，没有卷积运算，只是在滤波器算子滑动区域取最大值，即max pooling。 max pooling的好处是只保留区域内的最大值（特征），忽略其他值，减低噪声影响，提高模型健壮性。而且max pooling需要的超参数仅为滤波器尺寸f和步长s, 没有其他参数，不需要训练，计算量小。 如果有多个通道，就对每个通道单独进行max pooling，所以通道数不变。 在神经网络中，最大池比平均池用的多。 一般都不需要加padding。 1.10 卷积神经网络示例 识别0到9的10个数字的神经网络例子： CON层后面紧接一个POOL层，CONV1和POOL1构成第一层；CONV2和POOL2构成第二层；FC3和FC4为全连接层FC，它跟标准的神经网络结构一致；最后的输出层softmax由10个神经元构成。 池化层没有参数，卷积层参数少，全连接层参数多；激活元的尺寸在快速变小。 1.11 为什么使用卷积？ 比用普通神经网络少了很多参数呀。 原因一是输入图片的不同区域在使用同样的参数，即参数共享。二是稀疏连接，输出图片的每个数字只与输入图片的9个数字（特征）相关，与其他数字（特征）不相关。 由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上减少了过拟合。 而且CNN比较擅长捕捉区域位置偏移，也就是CNN进行物体检测时，不太受物体所处的位置影响，增加检测的准确性和系统的健壮性。" />
<meta property="og:description" content="1.1 计算机视觉 一般的CV问题包括以下三类： 图片分类已经见过。 目标检测中首先要计算出图中有哪些物体，再将他们模拟成一个个盒子，以便你的车可以避开他们。 风格转换是用神经网络把你的照片和一张风格照片融合到一起，描绘出一张新的照片，整体轮廓来自左边，风格来自右边。 使用传统神经网络处理计算机视觉的一个主要问题是输入层维度很大，解决方法是用CNN。 1.2 了解卷积：边缘检测示例 我们之前讲过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（如眼睛、鼻子等）、整体面部轮廓。 这一小节讲如何检测图片边缘。最常检测的图片边缘有两类：一是垂直边缘，二是水平边缘。 原始图片的尺寸是66，滤波器filter的尺寸是33，通过卷积运算得到尺寸为44的图片。 数学中卷积用表示，python中用conv-forward()表示，TensorFlow中用tf.nn.conv2d()表示,keras中用Conv2D()表示。 1.3 更多边缘检测内容 由亮向暗还是由暗向亮过度，滤波器可以帮我们区分这两种的区别： 水平边缘检测的滤波器算子就是吧垂直边缘检测的滤波器翻转90度： 还有一些filter，可能更robust；同时filter的数值可以作为参数通过训练得到，类似于标准神经网络中的权重W通过梯度下降迭代得到，也可以检测到图片的各种边缘特征。CNN的主要目的就是计算出这些filter的数值。确定得到了这些filter后，CNN浅层网络也就实现了对图片所有边缘特征的检测。 1.4 Padding 按照上面的卷积方式，原始图片为nn, filter为ff, 则卷积后图片尺寸为(n-f+1)*(n-f+1), 这会带来图片尺寸缩小问题，而且可以看出来原始图片边缘信息对输出贡献小，输出图片丢失边缘信息。 为了解决这两个问题，可以使用padding方法，即把原始图片尺寸拓展，拓展区域补0，用p来表示每个方向拓展的宽度。 经过padding，原始图片尺寸为(n+2p) x (n+2p)，filter尺寸为f x f，则卷积后的图片尺寸为(n+2p-f+1) x (n+2p-f+1)。“Same convolutions’使卷积前后图片尺寸不变，即p为（f-1)/2。(f基本都是奇数) “valid convolution”就是p为0。 1.5 卷积步长 stride步长表示filter在原图片中水平和垂直方向每次的步进长度。图片尺寸为：(除不尽的时候向下取整) 实际上，我们的操作在数学上是相关系数cross-correlations不是卷积convolution，但是深度学习论文中常常默认叫卷积因为忽略镜面翻转可以提高CNN速度而不影响模型性能。真正的卷积是要先把filter镜面翻转，真正的卷积也有结合律。 1.6 卷积为何有效 对于3通道的RGB图片，其对应的滤波器算子也需要是3通道的。例如一个图片是663，分别表示height、width、channel通道数。 卷积运算方法类似，对应数字相乘相加，得到输出图片的一个像素值。 不同通道的滤波算子可以不同，不同的filter检测不同的特征。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。 维度：输入图片nnnc(通道数），filter为ffnc(有nc’个), 输出图片(n-f+1)*(n-f+1) *nc’。 1.7 单层卷积网络 卷积神经网络一层的结构： 计算一下参数的数目：每个滤波器有W：333=27个，一个b,一共28个；两个滤波器就有28*2=56个。可以看到参数的数目和输入图片的尺寸无关，就不存在由于图片尺寸过大造成参数过多的情况。例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，参数数目只由滤波器组决定，数目相对来说要少得多，这是CNN的优势之一。 符号总结： A[l]是m个a[l]，即在前面乘以m。 weights就是nc[l]个each filter is的组合，即维度又乘以nc[l]。 记忆方法：nc[l-1]是通道数，nc[l]是滤波器个数。 1.8 简单卷积网络示例 一个简单的CNN网络模型： 把这几层最终得到的7740个特征（即a[3]），即1960，作为一列把这个长向量填充到逻辑回归或softmax回归函数中,得到最后的输出y hat。 可以看到，随着CNN层数增加，nH[l]和nW[l]逐渐减小，nc[l]通道数逐渐增加。 关于超参数的选择以后的视频会给一些指导。 一个典型的卷积神经网络通常有三层，卷积层、池化层、全连接层。 1.9 池化层 pooling layers是CNN中用来减小尺寸的，提高运算速度的，同样能减小noise影响，让各特征更robust。 pooling layers的做法比convolution layers简单许多，没有卷积运算，只是在滤波器算子滑动区域取最大值，即max pooling。 max pooling的好处是只保留区域内的最大值（特征），忽略其他值，减低噪声影响，提高模型健壮性。而且max pooling需要的超参数仅为滤波器尺寸f和步长s, 没有其他参数，不需要训练，计算量小。 如果有多个通道，就对每个通道单独进行max pooling，所以通道数不变。 在神经网络中，最大池比平均池用的多。 一般都不需要加padding。 1.10 卷积神经网络示例 识别0到9的10个数字的神经网络例子： CON层后面紧接一个POOL层，CONV1和POOL1构成第一层；CONV2和POOL2构成第二层；FC3和FC4为全连接层FC，它跟标准的神经网络结构一致；最后的输出层softmax由10个神经元构成。 池化层没有参数，卷积层参数少，全连接层参数多；激活元的尺寸在快速变小。 1.11 为什么使用卷积？ 比用普通神经网络少了很多参数呀。 原因一是输入图片的不同区域在使用同样的参数，即参数共享。二是稀疏连接，输出图片的每个数字只与输入图片的9个数字（特征）相关，与其他数字（特征）不相关。 由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上减少了过拟合。 而且CNN比较擅长捕捉区域位置偏移，也就是CNN进行物体检测时，不太受物体所处的位置影响，增加检测的准确性和系统的健壮性。" />
<link rel="canonical" href="https://mlh.app/2019/05/05/729846.html" />
<meta property="og:url" content="https://mlh.app/2019/05/05/729846.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-05T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"1.1 计算机视觉 一般的CV问题包括以下三类： 图片分类已经见过。 目标检测中首先要计算出图中有哪些物体，再将他们模拟成一个个盒子，以便你的车可以避开他们。 风格转换是用神经网络把你的照片和一张风格照片融合到一起，描绘出一张新的照片，整体轮廓来自左边，风格来自右边。 使用传统神经网络处理计算机视觉的一个主要问题是输入层维度很大，解决方法是用CNN。 1.2 了解卷积：边缘检测示例 我们之前讲过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（如眼睛、鼻子等）、整体面部轮廓。 这一小节讲如何检测图片边缘。最常检测的图片边缘有两类：一是垂直边缘，二是水平边缘。 原始图片的尺寸是66，滤波器filter的尺寸是33，通过卷积运算得到尺寸为44的图片。 数学中卷积用表示，python中用conv-forward()表示，TensorFlow中用tf.nn.conv2d()表示,keras中用Conv2D()表示。 1.3 更多边缘检测内容 由亮向暗还是由暗向亮过度，滤波器可以帮我们区分这两种的区别： 水平边缘检测的滤波器算子就是吧垂直边缘检测的滤波器翻转90度： 还有一些filter，可能更robust；同时filter的数值可以作为参数通过训练得到，类似于标准神经网络中的权重W通过梯度下降迭代得到，也可以检测到图片的各种边缘特征。CNN的主要目的就是计算出这些filter的数值。确定得到了这些filter后，CNN浅层网络也就实现了对图片所有边缘特征的检测。 1.4 Padding 按照上面的卷积方式，原始图片为nn, filter为ff, 则卷积后图片尺寸为(n-f+1)*(n-f+1), 这会带来图片尺寸缩小问题，而且可以看出来原始图片边缘信息对输出贡献小，输出图片丢失边缘信息。 为了解决这两个问题，可以使用padding方法，即把原始图片尺寸拓展，拓展区域补0，用p来表示每个方向拓展的宽度。 经过padding，原始图片尺寸为(n+2p) x (n+2p)，filter尺寸为f x f，则卷积后的图片尺寸为(n+2p-f+1) x (n+2p-f+1)。“Same convolutions’使卷积前后图片尺寸不变，即p为（f-1)/2。(f基本都是奇数) “valid convolution”就是p为0。 1.5 卷积步长 stride步长表示filter在原图片中水平和垂直方向每次的步进长度。图片尺寸为：(除不尽的时候向下取整) 实际上，我们的操作在数学上是相关系数cross-correlations不是卷积convolution，但是深度学习论文中常常默认叫卷积因为忽略镜面翻转可以提高CNN速度而不影响模型性能。真正的卷积是要先把filter镜面翻转，真正的卷积也有结合律。 1.6 卷积为何有效 对于3通道的RGB图片，其对应的滤波器算子也需要是3通道的。例如一个图片是663，分别表示height、width、channel通道数。 卷积运算方法类似，对应数字相乘相加，得到输出图片的一个像素值。 不同通道的滤波算子可以不同，不同的filter检测不同的特征。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。 维度：输入图片nnnc(通道数），filter为ffnc(有nc’个), 输出图片(n-f+1)*(n-f+1) *nc’。 1.7 单层卷积网络 卷积神经网络一层的结构： 计算一下参数的数目：每个滤波器有W：333=27个，一个b,一共28个；两个滤波器就有28*2=56个。可以看到参数的数目和输入图片的尺寸无关，就不存在由于图片尺寸过大造成参数过多的情况。例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，参数数目只由滤波器组决定，数目相对来说要少得多，这是CNN的优势之一。 符号总结： A[l]是m个a[l]，即在前面乘以m。 weights就是nc[l]个each filter is的组合，即维度又乘以nc[l]。 记忆方法：nc[l-1]是通道数，nc[l]是滤波器个数。 1.8 简单卷积网络示例 一个简单的CNN网络模型： 把这几层最终得到的7740个特征（即a[3]），即1960，作为一列把这个长向量填充到逻辑回归或softmax回归函数中,得到最后的输出y hat。 可以看到，随着CNN层数增加，nH[l]和nW[l]逐渐减小，nc[l]通道数逐渐增加。 关于超参数的选择以后的视频会给一些指导。 一个典型的卷积神经网络通常有三层，卷积层、池化层、全连接层。 1.9 池化层 pooling layers是CNN中用来减小尺寸的，提高运算速度的，同样能减小noise影响，让各特征更robust。 pooling layers的做法比convolution layers简单许多，没有卷积运算，只是在滤波器算子滑动区域取最大值，即max pooling。 max pooling的好处是只保留区域内的最大值（特征），忽略其他值，减低噪声影响，提高模型健壮性。而且max pooling需要的超参数仅为滤波器尺寸f和步长s, 没有其他参数，不需要训练，计算量小。 如果有多个通道，就对每个通道单独进行max pooling，所以通道数不变。 在神经网络中，最大池比平均池用的多。 一般都不需要加padding。 1.10 卷积神经网络示例 识别0到9的10个数字的神经网络例子： CON层后面紧接一个POOL层，CONV1和POOL1构成第一层；CONV2和POOL2构成第二层；FC3和FC4为全连接层FC，它跟标准的神经网络结构一致；最后的输出层softmax由10个神经元构成。 池化层没有参数，卷积层参数少，全连接层参数多；激活元的尺寸在快速变小。 1.11 为什么使用卷积？ 比用普通神经网络少了很多参数呀。 原因一是输入图片的不同区域在使用同样的参数，即参数共享。二是稀疏连接，输出图片的每个数字只与输入图片的9个数字（特征）相关，与其他数字（特征）不相关。 由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上减少了过拟合。 而且CNN比较擅长捕捉区域位置偏移，也就是CNN进行物体检测时，不太受物体所处的位置影响，增加检测的准确性和系统的健壮性。","@type":"BlogPosting","url":"https://mlh.app/2019/05/05/729846.html","headline":"卷积神经网络第一章 卷积神经网络","dateModified":"2019-05-05T00:00:00+08:00","datePublished":"2019-05-05T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/05/729846.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>卷积神经网络第一章 卷积神经网络</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div id="content_views" class="markdown_views prism-atom-one-dark"> 
  <!-- flowchart 箭头图标 勿删 --> 
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> 
  <p><strong>1.1 计算机视觉</strong><br> 一般的CV问题包括以下三类：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504154956256.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 图片分类已经见过。<br> 目标检测中首先要计算出图中有哪些物体，再将他们模拟成一个个盒子，以便你的车可以避开他们。<br> 风格转换是用神经网络把你的照片和一张风格照片融合到一起，描绘出一张新的照片，整体轮廓来自左边，风格来自右边。</p> 
  <p>使用传统神经网络处理计算机视觉的一个主要问题是输入层维度很大，解决方法是用CNN。</p> 
  <p><strong>1.2 了解卷积：边缘检测示例</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019050416012444.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 我们之前讲过，神经网络由浅层到深层，分别可以检测出图片的边缘特征、局部特征（如眼睛、鼻子等）、整体面部轮廓。<br> 这一小节讲如何检测图片边缘。最常检测的图片边缘有两类：一是垂直边缘，二是水平边缘。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504161203255.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 原始图片的尺寸是6<em>6，滤波器filter的尺寸是3</em>3，通过卷积运算得到尺寸为4<em>4的图片。<br> 数学中卷积用</em>表示，python中用conv-forward()表示，TensorFlow中用tf.nn.conv2d()表示,keras中用Conv2D()表示。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504160143853.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p><strong>1.3 更多边缘检测内容</strong><br> 由亮向暗还是由暗向亮过度，滤波器可以帮我们区分这两种的区别：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504162535562.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 水平边缘检测的滤波器算子就是吧垂直边缘检测的滤波器翻转90度：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504162554131.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 还有一些filter，可能更robust；同时filter的数值可以作为参数通过训练得到，类似于标准神经网络中的权重W通过梯度下降迭代得到，也可以检测到图片的各种边缘特征。CNN的主要目的就是计算出这些filter的数值。确定得到了这些filter后，CNN浅层网络也就实现了对图片所有边缘特征的检测。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504162603128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
  <p><strong>1.4 Padding</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504174713489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 按照上面的卷积方式，原始图片为n<em>n, filter为f</em>f, 则卷积后图片尺寸为(n-f+1)*(n-f+1), 这会带来图片尺寸缩小问题，而且可以看出来原始图片边缘信息对输出贡献小，输出图片丢失边缘信息。<br> 为了解决这两个问题，可以使用padding方法，即把原始图片尺寸拓展，拓展区域补0，用p来表示每个方向拓展的宽度。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504174725312.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 经过padding，原始图片尺寸为(n+2p) x (n+2p)，filter尺寸为f x f，则卷积后的图片尺寸为(n+2p-f+1) x (n+2p-f+1)。“Same convolutions’使卷积前后图片尺寸不变，即p为（f-1)/2。(f基本都是奇数)<br> “valid convolution”就是p为0。</p> 
  <p><strong>1.5 卷积步长</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504175952643.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> stride步长表示filter在原图片中水平和垂直方向每次的步进长度。图片尺寸为：(除不尽的时候向下取整)<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504180001423.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019050418001728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 实际上，我们的操作在数学上是相关系数cross-correlations不是卷积convolution，但是深度学习论文中常常默认叫卷积因为忽略镜面翻转可以提高CNN速度而不影响模型性能。真正的卷积是要先把filter镜面翻转，真正的卷积也有结合律。</p> 
  <p><strong>1.6 卷积为何有效</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504195203868.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 对于3通道的RGB图片，其对应的滤波器算子也需要是3通道的。例如一个图片是6<em>6</em>3，分别表示height、width、channel通道数。<br> 卷积运算方法类似，对应数字相乘相加，得到输出图片的一个像素值。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504195216229.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 不同通道的滤波算子可以不同，不同的filter检测不同的特征。例如R通道filter实现垂直边缘检测，G和B通道不进行边缘检测，全部置零，或者将R，G，B三通道filter全部设置为水平边缘检测。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504195227629.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 为了进行多个卷积运算，实现更多边缘检测，可以增加更多的滤波器组。例如设置第一个滤波器组实现垂直边缘检测，第二个滤波器组实现水平边缘检测。这样，不同滤波器组卷积得到不同的输出，个数由滤波器组决定。<br> 维度：输入图片n<em>n</em>nc(通道数），filter为f<em>f</em>nc(有nc’个), 输出图片(n-f+1)*(n-f+1) *nc’。</p> 
  <p><strong>1.7 单层卷积网络</strong><br> 卷积神经网络一层的结构：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504202716126.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504204545763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 计算一下参数的数目：每个滤波器有W：3<em>3</em>3=27个，一个b,一共28个；两个滤波器就有28*2=56个。可以看到参数的数目和输入图片的尺寸无关，就不存在由于图片尺寸过大造成参数过多的情况。例如一张1000x1000x3的图片，标准神经网络输入层的维度将达到3百万，而在CNN中，参数数目只由滤波器组决定，数目相对来说要少得多，这是CNN的优势之一。<br> 符号总结：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504204042344.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> A[l]是m个a[l]，即在前面乘以m。<br> weights就是nc[l]个each filter is的组合，即维度又乘以nc[l]。<br> 记忆方法：nc[l-1]是通道数，nc[l]是滤波器个数。</p> 
  <p><strong>1.8 简单卷积网络示例</strong><br> 一个简单的CNN网络模型：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019050421025922.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 把这几层最终得到的7<em>7</em>40个特征（即a[3]），即1960，作为一列把这个长向量填充到逻辑回归或softmax回归函数中,得到最后的输出y hat。<br> 可以看到，随着CNN层数增加，nH[l]和nW[l]逐渐减小，nc[l]通道数逐渐增加。<br> 关于超参数的选择以后的视频会给一些指导。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504210311106.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 一个典型的卷积神经网络通常有三层，卷积层、池化层、全连接层。</p> 
  <p><strong>1.9 池化层</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504212326249.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> pooling layers是CNN中用来减小尺寸的，提高运算速度的，同样能减小noise影响，让各特征更robust。<br> pooling layers的做法比convolution layers简单许多，没有卷积运算，只是在滤波器算子滑动区域取最大值，即max pooling。<br> max pooling的好处是只保留区域内的最大值（特征），忽略其他值，减低噪声影响，提高模型健壮性。而且max pooling需要的超参数仅为滤波器尺寸f和步长s, <em>没有其他参数，不需要训练</em>，计算量小。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504212009532.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 如果有多个通道，就对每个通道单独进行max pooling，所以通道数不变。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504212017336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt=""><br> 在神经网络中，最大池比平均池用的多。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019050421203691.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 一般都不需要加padding。</p> 
  <p><strong>1.10 卷积神经网络示例</strong><br> 识别0到9的10个数字的神经网络例子：<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190504214030121.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> CON层后面紧接一个POOL层，CONV1和POOL1构成第一层；CONV2和POOL2构成第二层；FC3和FC4为全连接层FC，它跟标准的神经网络结构一致；最后的输出层softmax由10个神经元构成。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505104727206.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 池化层没有参数，卷积层参数少，全连接层参数多；激活元的尺寸在快速变小。</p> 
  <p><strong>1.11 为什么使用卷积？</strong><br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505105316903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 比用普通神经网络少了很多参数呀。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019050510543427.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br> 原因一是输入图片的不同区域在使用同样的参数，即参数共享。二是稀疏连接，输出图片的每个数字只与输入图片的9个数字（特征）相关，与其他数字（特征）不相关。<br> 由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上减少了过拟合。<br> 而且CNN比较擅长捕捉区域位置偏移，也就是CNN进行物体检测时，不太受物体所处的位置影响，增加检测的准确性和系统的健壮性。<br> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505105443718.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjIzNDc2OQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p> 
 </div> 
 <link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-258a4616f7.css" rel="stylesheet"> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
