<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>【机器学习实践】泰坦尼克号乘客获救预测 | 有组织在！</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="【机器学习实践】泰坦尼克号乘客获救预测" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="目录 &nbsp; &nbsp; 目的： 数据读取： 数据处理： 线性回归： &nbsp; 目的： 利用所给数据的特征来判断哪些人能够获救。 &nbsp; 数据读取： titanic_train.csv: 训练集，共计891条数据 titanic_test.csv: 测试集，共计418条数据 我们使用pandas库来读取CSV数据。 这里使用read_csv所得到的是&nbsp;&nbsp;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&nbsp; 类型的数据， 关于DataFrame 的一些具体操作可以参考pandas的document。《&nbsp; http://pandas.pydata.org/pandas-docs/stable/&nbsp;》 我们可以直接使用print 来输出完整的data_train。 当然也可使用&nbsp;&nbsp;print(data_train.head(10))&nbsp; 来输出前十条信息。 &nbsp; 我们还可以使用info&nbsp; 和&nbsp; discribe方法来对数据进行一个总览。 首先来看一下discribe方法的输出。 &nbsp; 我们可以看到关于我们这一组数据的一些统计信息。 &nbsp; 下面是info&nbsp; 方法。 从info的输出中我们可以看到，可以看出我们的数据共891行，11列 并且有三个属性是出现了缺失的，分别是Age,Cabin和Embarked， 其中，Age列缺失117条数据；Cabin列缺失687条数据；Embarked列缺失2条数据。 &nbsp; &nbsp; &nbsp; 数据处理： &nbsp; 我们从info的结果中得知了信息缺失，我们则有必要针对这部分缺失的信息做出一定的人为处理。 对于不同种类的数据缺失采取不同的方法： 1.&nbsp; &nbsp;对于Age，因为对结果的预测很重要，采取中位数填充的方法 2.&nbsp; &nbsp;cabin对结果的影响不大，并且缺失很多，盲目填充会产生一定的副作用，所以采取删除的方法 3.&nbsp; &nbsp;&nbsp;Embarke 对结果无关，我们这里也是选择删除 综上，我们要做的也就是对于age的填充操作，选定了使用中位数进行填充后，我们具体的实现如下： data_train[&quot;Age&quot;] = data_train[&#39;Age&#39;].fillna(data_train[&#39;Age&#39;].median()) http://pandas.pydata.org/pandas-docs/stable/reference/frame.html 从pandas 官方的API当中可以找到对于 DataFrame 类型数据的一些对应方法。 fillna方法是属于Missing data handling中的一种。它的作用是Fill NA/NaN values using the specified method. 他的一些具体参数如下： return 的还是&nbsp;DataFrame 类型的数据。 这其中的median() 函数的返回值是给定数据的中位数。&nbsp; the median of the values for the requested axis. 这样一来也就实现了中位数填充的目的。 &nbsp; 线性回归： #线性回归 from sklearn.linear_model import LinearRegression #训练集交叉验证，得到平均值 from sklearn.model_selection import KFold #选取简单的可用输入特征 predictors = [&quot;Pclass&quot;,&quot;Age&quot;,&quot;SibSp&quot;,&quot;Parch&quot;,&quot;Fare&quot;] #初始化现行回归算法 alg = LinearRegression() #样本平均分成3份，3折交叉验证 kf = KFold(n_splits=3,shuffle=False,random_state=1) # 最终的预测结果（hypothesis） predictions = [] 准备工作完成，开始导入我们准备的数据， sklearn的相关API当中有关于使用KFold 初始化的kf 的一些相应方法。 我们可以看到在循环当中使用的split就是将输出的dataset 切分为 train 和 test 的函数&nbsp; for train,test in kf.split(data_train): #这里的train_predictors所代表的是选取的特征 train_predictors = (data_train[predictors].iloc[train,:]) train_label = data_train[&quot;Survived&quot;].iloc[train] alg.fit(train_predictors,train_label) # 得到hypothesis test_predictions = alg.predict(data_train[predictors].iloc[test,:]) predictions.append(test_predictions) 循环里的五行代码我们分别来看。 第一行中的iloc函数是用来实现对于行或者列的选取；下面给出了一些实际应用； 逗号是分隔符， 如果不加以说明则默认为整行或者是整列的选取 data_test1=data.iloc[:,:8] &nbsp;#选取位置为[0,8)列的整列数据 data_test2=data.iloc[0:2,8] &nbsp;#选取位置为8的列的[0,2)行的数据 data_test3=data.loc[0:2,&#39;工龄&#39;] &nbsp;#选取列名为‘工龄’的[0,2]行的数据 关于alg 也是就线性回归的初始化算法，其所有的方法如下 使用fit 方法就是开始执行线性回归这个分类器了。（这里并没有返回值，我不是很理解） hypothesis （参数名为test_predictions）的获得方法原理是相同的。 最后将得到的hypothesis 使用list的append方法添加到&nbsp; predictions&nbsp; 当中去。 因为我们使用的是K = 3 的 3折验证，所以会产生三组预测结果，这三组结果分别存储在三个list当中。 我们将它合并成为一个numpy的ndarray类型数组，然后再进行后续的概率计算。 predictions = np.concatenate(predictions,axis=0) #Map predictions to outcomes(only possible outcomes are 1 and 0) predictions[predictions&gt;.5] = 1 predictions[predictions&lt;=.5] = 0 accuracy = sum(predictions == data_train[&quot;Survived&quot;]) / len(predictions) print (&quot;准确率为: &quot;, accuracy) 运行后得到我们最终的结果， &nbsp; &nbsp;" />
<meta property="og:description" content="目录 &nbsp; &nbsp; 目的： 数据读取： 数据处理： 线性回归： &nbsp; 目的： 利用所给数据的特征来判断哪些人能够获救。 &nbsp; 数据读取： titanic_train.csv: 训练集，共计891条数据 titanic_test.csv: 测试集，共计418条数据 我们使用pandas库来读取CSV数据。 这里使用read_csv所得到的是&nbsp;&nbsp;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&nbsp; 类型的数据， 关于DataFrame 的一些具体操作可以参考pandas的document。《&nbsp; http://pandas.pydata.org/pandas-docs/stable/&nbsp;》 我们可以直接使用print 来输出完整的data_train。 当然也可使用&nbsp;&nbsp;print(data_train.head(10))&nbsp; 来输出前十条信息。 &nbsp; 我们还可以使用info&nbsp; 和&nbsp; discribe方法来对数据进行一个总览。 首先来看一下discribe方法的输出。 &nbsp; 我们可以看到关于我们这一组数据的一些统计信息。 &nbsp; 下面是info&nbsp; 方法。 从info的输出中我们可以看到，可以看出我们的数据共891行，11列 并且有三个属性是出现了缺失的，分别是Age,Cabin和Embarked， 其中，Age列缺失117条数据；Cabin列缺失687条数据；Embarked列缺失2条数据。 &nbsp; &nbsp; &nbsp; 数据处理： &nbsp; 我们从info的结果中得知了信息缺失，我们则有必要针对这部分缺失的信息做出一定的人为处理。 对于不同种类的数据缺失采取不同的方法： 1.&nbsp; &nbsp;对于Age，因为对结果的预测很重要，采取中位数填充的方法 2.&nbsp; &nbsp;cabin对结果的影响不大，并且缺失很多，盲目填充会产生一定的副作用，所以采取删除的方法 3.&nbsp; &nbsp;&nbsp;Embarke 对结果无关，我们这里也是选择删除 综上，我们要做的也就是对于age的填充操作，选定了使用中位数进行填充后，我们具体的实现如下： data_train[&quot;Age&quot;] = data_train[&#39;Age&#39;].fillna(data_train[&#39;Age&#39;].median()) http://pandas.pydata.org/pandas-docs/stable/reference/frame.html 从pandas 官方的API当中可以找到对于 DataFrame 类型数据的一些对应方法。 fillna方法是属于Missing data handling中的一种。它的作用是Fill NA/NaN values using the specified method. 他的一些具体参数如下： return 的还是&nbsp;DataFrame 类型的数据。 这其中的median() 函数的返回值是给定数据的中位数。&nbsp; the median of the values for the requested axis. 这样一来也就实现了中位数填充的目的。 &nbsp; 线性回归： #线性回归 from sklearn.linear_model import LinearRegression #训练集交叉验证，得到平均值 from sklearn.model_selection import KFold #选取简单的可用输入特征 predictors = [&quot;Pclass&quot;,&quot;Age&quot;,&quot;SibSp&quot;,&quot;Parch&quot;,&quot;Fare&quot;] #初始化现行回归算法 alg = LinearRegression() #样本平均分成3份，3折交叉验证 kf = KFold(n_splits=3,shuffle=False,random_state=1) # 最终的预测结果（hypothesis） predictions = [] 准备工作完成，开始导入我们准备的数据， sklearn的相关API当中有关于使用KFold 初始化的kf 的一些相应方法。 我们可以看到在循环当中使用的split就是将输出的dataset 切分为 train 和 test 的函数&nbsp; for train,test in kf.split(data_train): #这里的train_predictors所代表的是选取的特征 train_predictors = (data_train[predictors].iloc[train,:]) train_label = data_train[&quot;Survived&quot;].iloc[train] alg.fit(train_predictors,train_label) # 得到hypothesis test_predictions = alg.predict(data_train[predictors].iloc[test,:]) predictions.append(test_predictions) 循环里的五行代码我们分别来看。 第一行中的iloc函数是用来实现对于行或者列的选取；下面给出了一些实际应用； 逗号是分隔符， 如果不加以说明则默认为整行或者是整列的选取 data_test1=data.iloc[:,:8] &nbsp;#选取位置为[0,8)列的整列数据 data_test2=data.iloc[0:2,8] &nbsp;#选取位置为8的列的[0,2)行的数据 data_test3=data.loc[0:2,&#39;工龄&#39;] &nbsp;#选取列名为‘工龄’的[0,2]行的数据 关于alg 也是就线性回归的初始化算法，其所有的方法如下 使用fit 方法就是开始执行线性回归这个分类器了。（这里并没有返回值，我不是很理解） hypothesis （参数名为test_predictions）的获得方法原理是相同的。 最后将得到的hypothesis 使用list的append方法添加到&nbsp; predictions&nbsp; 当中去。 因为我们使用的是K = 3 的 3折验证，所以会产生三组预测结果，这三组结果分别存储在三个list当中。 我们将它合并成为一个numpy的ndarray类型数组，然后再进行后续的概率计算。 predictions = np.concatenate(predictions,axis=0) #Map predictions to outcomes(only possible outcomes are 1 and 0) predictions[predictions&gt;.5] = 1 predictions[predictions&lt;=.5] = 0 accuracy = sum(predictions == data_train[&quot;Survived&quot;]) / len(predictions) print (&quot;准确率为: &quot;, accuracy) 运行后得到我们最终的结果， &nbsp; &nbsp;" />
<link rel="canonical" href="https://mlh.app/2019/05/05/729913.html" />
<meta property="og:url" content="https://mlh.app/2019/05/05/729913.html" />
<meta property="og:site_name" content="有组织在！" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-05T00:00:00+08:00" />
<script type="application/ld+json">
{"description":"目录 &nbsp; &nbsp; 目的： 数据读取： 数据处理： 线性回归： &nbsp; 目的： 利用所给数据的特征来判断哪些人能够获救。 &nbsp; 数据读取： titanic_train.csv: 训练集，共计891条数据 titanic_test.csv: 测试集，共计418条数据 我们使用pandas库来读取CSV数据。 这里使用read_csv所得到的是&nbsp;&nbsp;&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;&nbsp; 类型的数据， 关于DataFrame 的一些具体操作可以参考pandas的document。《&nbsp; http://pandas.pydata.org/pandas-docs/stable/&nbsp;》 我们可以直接使用print 来输出完整的data_train。 当然也可使用&nbsp;&nbsp;print(data_train.head(10))&nbsp; 来输出前十条信息。 &nbsp; 我们还可以使用info&nbsp; 和&nbsp; discribe方法来对数据进行一个总览。 首先来看一下discribe方法的输出。 &nbsp; 我们可以看到关于我们这一组数据的一些统计信息。 &nbsp; 下面是info&nbsp; 方法。 从info的输出中我们可以看到，可以看出我们的数据共891行，11列 并且有三个属性是出现了缺失的，分别是Age,Cabin和Embarked， 其中，Age列缺失117条数据；Cabin列缺失687条数据；Embarked列缺失2条数据。 &nbsp; &nbsp; &nbsp; 数据处理： &nbsp; 我们从info的结果中得知了信息缺失，我们则有必要针对这部分缺失的信息做出一定的人为处理。 对于不同种类的数据缺失采取不同的方法： 1.&nbsp; &nbsp;对于Age，因为对结果的预测很重要，采取中位数填充的方法 2.&nbsp; &nbsp;cabin对结果的影响不大，并且缺失很多，盲目填充会产生一定的副作用，所以采取删除的方法 3.&nbsp; &nbsp;&nbsp;Embarke 对结果无关，我们这里也是选择删除 综上，我们要做的也就是对于age的填充操作，选定了使用中位数进行填充后，我们具体的实现如下： data_train[&quot;Age&quot;] = data_train[&#39;Age&#39;].fillna(data_train[&#39;Age&#39;].median()) http://pandas.pydata.org/pandas-docs/stable/reference/frame.html 从pandas 官方的API当中可以找到对于 DataFrame 类型数据的一些对应方法。 fillna方法是属于Missing data handling中的一种。它的作用是Fill NA/NaN values using the specified method. 他的一些具体参数如下： return 的还是&nbsp;DataFrame 类型的数据。 这其中的median() 函数的返回值是给定数据的中位数。&nbsp; the median of the values for the requested axis. 这样一来也就实现了中位数填充的目的。 &nbsp; 线性回归： #线性回归 from sklearn.linear_model import LinearRegression #训练集交叉验证，得到平均值 from sklearn.model_selection import KFold #选取简单的可用输入特征 predictors = [&quot;Pclass&quot;,&quot;Age&quot;,&quot;SibSp&quot;,&quot;Parch&quot;,&quot;Fare&quot;] #初始化现行回归算法 alg = LinearRegression() #样本平均分成3份，3折交叉验证 kf = KFold(n_splits=3,shuffle=False,random_state=1) # 最终的预测结果（hypothesis） predictions = [] 准备工作完成，开始导入我们准备的数据， sklearn的相关API当中有关于使用KFold 初始化的kf 的一些相应方法。 我们可以看到在循环当中使用的split就是将输出的dataset 切分为 train 和 test 的函数&nbsp; for train,test in kf.split(data_train): #这里的train_predictors所代表的是选取的特征 train_predictors = (data_train[predictors].iloc[train,:]) train_label = data_train[&quot;Survived&quot;].iloc[train] alg.fit(train_predictors,train_label) # 得到hypothesis test_predictions = alg.predict(data_train[predictors].iloc[test,:]) predictions.append(test_predictions) 循环里的五行代码我们分别来看。 第一行中的iloc函数是用来实现对于行或者列的选取；下面给出了一些实际应用； 逗号是分隔符， 如果不加以说明则默认为整行或者是整列的选取 data_test1=data.iloc[:,:8] &nbsp;#选取位置为[0,8)列的整列数据 data_test2=data.iloc[0:2,8] &nbsp;#选取位置为8的列的[0,2)行的数据 data_test3=data.loc[0:2,&#39;工龄&#39;] &nbsp;#选取列名为‘工龄’的[0,2]行的数据 关于alg 也是就线性回归的初始化算法，其所有的方法如下 使用fit 方法就是开始执行线性回归这个分类器了。（这里并没有返回值，我不是很理解） hypothesis （参数名为test_predictions）的获得方法原理是相同的。 最后将得到的hypothesis 使用list的append方法添加到&nbsp; predictions&nbsp; 当中去。 因为我们使用的是K = 3 的 3折验证，所以会产生三组预测结果，这三组结果分别存储在三个list当中。 我们将它合并成为一个numpy的ndarray类型数组，然后再进行后续的概率计算。 predictions = np.concatenate(predictions,axis=0) #Map predictions to outcomes(only possible outcomes are 1 and 0) predictions[predictions&gt;.5] = 1 predictions[predictions&lt;=.5] = 0 accuracy = sum(predictions == data_train[&quot;Survived&quot;]) / len(predictions) print (&quot;准确率为: &quot;, accuracy) 运行后得到我们最终的结果， &nbsp; &nbsp;","@type":"BlogPosting","url":"https://mlh.app/2019/05/05/729913.html","headline":"【机器学习实践】泰坦尼克号乘客获救预测","dateModified":"2019-05-05T00:00:00+08:00","datePublished":"2019-05-05T00:00:00+08:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://mlh.app/2019/05/05/729913.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->


    <link rel="stylesheet" href="/assets/css/style.css?v=">
    <script src="/assets/js/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-123344652-3"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-123344652-3');
    </script>
    
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-8889449066804352",
        enable_page_level_ads: true
      });
    </script>
    
    <script async custom-element="amp-auto-ads"
        src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
    
    <style>
      @media screen and (max-width:760px){
        .sm-hidden{display:none; }
      }
    </style>

  </head>
  <body>
    
        <amp-auto-ads type="adsense"
              data-ad-client="ca-pub-8889449066804352">
        </amp-auto-ads>
    
    <div class="wrapper">
      <header  class="without-description" >
        <h1>【机器学习实践】泰坦尼克号乘客获救预测</h1>
        
        
        <ul>
            <li><a href="https://uzshare.com/" style="line-height: unset;" target="_blank"><strong>柚子社区</strong></a></li>
        </ul>
        
        
        
      </header>
      <section>

<div style="margin:0 0 8px 0;">
<style>
table.gsc-input {
    margin: 0;
}
.cse .gsc-control-cse, .gsc-control-cse {
    padding: 0;
    width: auto;
}
.gsc-search-box td {
    border-bottom: none;
}
</style>
<script>
  (function() {
    var cx = '004431708863642777669:qan2_6ugotw';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:search></gcse:search>
</div>
	

        <div id="article_content" class="article_content clearfix csdn-tracking-statistics" data-pid="blog" data-mod="popu_307" data-dsm="post"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-f57960eb32.css"> 
 <div class="htmledit_views" id="content_views"> 
  <p id="main-toc"><strong>目录</strong></p> 
  <p id="-toc" style="margin-left:0px;">&nbsp;</p> 
  <p style="margin-left:0px;">&nbsp;</p> 
  <p id="%E7%9B%AE%E7%9A%84%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E7%9B%AE%E7%9A%84%EF%BC%9A" rel="nofollow">目的：</a></p> 
  <p id="%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%EF%BC%9A" rel="nofollow">数据读取：</a></p> 
  <p id="%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%9A" rel="nofollow">数据处理：</a></p> 
  <p id="%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%9A" rel="nofollow">线性回归：</a></p> 
  <hr id="hr-toc">
  <h1>&nbsp;</h1> 
  <h1 id="%E7%9B%AE%E7%9A%84%EF%BC%9A"><span style="color:#f33b45;">目的：</span></h1> 
  <p>利用所给数据的特征来判断哪些人能够获救。</p> 
  <p>&nbsp;</p> 
  <h1 id="%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%8F%96%EF%BC%9A"><span style="color:#f33b45;">数据读取：</span></h1> 
  <p>titanic_train.csv: 训练集，共计891条数据</p> 
  <p>titanic_test.csv: 测试集，共计418条数据</p> 
  <p><img alt="" class="has" height="141" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505184823830.png" width="751"></p> 
  <p>我们使用pandas库来读取CSV数据。</p> 
  <p>这里使用read_csv所得到的是&nbsp;&nbsp;&lt;class 'pandas.core.frame.DataFrame'&gt;&nbsp; 类型的数据，</p> 
  <p>关于DataFrame 的一些具体操作可以参考pandas的document。《&nbsp; <a href="http://pandas.pydata.org/pandas-docs/stable/" rel="nofollow">http://pandas.pydata.org/pandas-docs/stable/</a>&nbsp;》</p> 
  <p>我们可以直接使用print 来输出完整的data_train。</p> 
  <p>当然也可使用&nbsp;&nbsp;print(data_train.head(10))&nbsp; 来输出前十条信息。</p> 
  <p>&nbsp;</p> 
  <p>我们还可以使用info&nbsp; 和&nbsp; discribe方法来对数据进行一个总览。</p> 
  <p>首先来看一下discribe方法的输出。</p> 
  <pre>

<code class="language-html hljs">&nbsp;</code></pre> 
  <p>我们可以看到关于我们这一组数据的一些统计信息。</p> 
  <p>&nbsp;</p> 
  <p>下面是info&nbsp; 方法。</p> 
  <p><img alt="" class="has" height="746" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505185721763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BpZXJjZV9LSw==,size_16,color_FFFFFF,t_70" width="639"></p> 
  <p>从info的输出中我们可以看到，可以看出我们的数据共891行，11列</p> 
  <p>并且有三个属性是出现了缺失的，分别是Age,Cabin和Embarked，</p> 
  <p>其中，Age列缺失117条数据；Cabin列缺失687条数据；Embarked列缺失2条数据。</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
  <h1 id="%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%9A"><span style="color:#f33b45;">数据处理：</span></h1> 
  <p>&nbsp;</p> 
  <p>我们从info的结果中得知了信息缺失，我们则有必要针对这部分缺失的信息做出一定的人为处理。</p> 
  <p>对于不同种类的数据缺失采取不同的方法：</p> 
  <p>1.&nbsp; &nbsp;对于Age，因为对结果的预测很重要，采取中位数填充的方法</p> 
  <p>2.&nbsp; &nbsp;cabin对结果的影响不大，并且缺失很多，盲目填充会产生一定的副作用，所以采取删除的方法</p> 
  <p>3.&nbsp; &nbsp;&nbsp;Embarke 对结果无关，我们这里也是选择删除</p> 
  <p>综上，我们要做的也就是对于age的填充操作，选定了使用中位数进行填充后，我们具体的实现如下：</p> 
  <pre class="has">
<code>data_train["Age"] = data_train['Age'].fillna(data_train['Age'].median())</code></pre> 
  <p><a href="http://pandas.pydata.org/pandas-docs/stable/reference/frame.html" rel="nofollow">http://pandas.pydata.org/pandas-docs/stable/reference/frame.html</a></p> 
  <p>从pandas 官方的API当中可以找到对于 DataFrame 类型数据的一些对应方法。</p> 
  <p>fillna方法是属于Missing data handling中的一种。它的作用是Fill NA/NaN values using the specified method.</p> 
  <p>他的一些具体参数如下：</p> 
  <p><img alt="" class="has" height="597" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505191556689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1BpZXJjZV9LSw==,size_16,color_FFFFFF,t_70" width="674"></p> 
  <p>return 的还是&nbsp;DataFrame 类型的数据。</p> 
  <p>这其中的median() 函数的返回值是给定数据的中位数。&nbsp; the median of the values for the requested axis.</p> 
  <p>这样一来也就实现了中位数填充的目的。</p> 
  <p>&nbsp;</p> 
  <h1 id="%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%EF%BC%9A"><span style="color:#f33b45;">线性回归：</span></h1> 
  <pre class="has">
<code>#线性回归
from sklearn.linear_model import LinearRegression   

#训练集交叉验证，得到平均值
from sklearn.model_selection import KFold
 
#选取简单的可用输入特征
predictors = ["Pclass","Age","SibSp","Parch","Fare"]     
 
#初始化现行回归算法
alg = LinearRegression()

#样本平均分成3份，3折交叉验证
kf = KFold(n_splits=3,shuffle=False,random_state=1) 

# 最终的预测结果（hypothesis）
predictions = []</code></pre> 
  <p>准备工作完成，开始导入我们准备的数据，</p> 
  <p>sklearn的相关API当中有关于使用KFold 初始化的kf 的一些相应方法。</p> 
  <p><img alt="" class="has" height="93" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505194304991.png" width="780"></p> 
  <p>我们可以看到在循环当中使用的split就是将输出的dataset 切分为 train 和 test 的函数&nbsp;</p> 
  <pre class="has">
<code>for train,test in kf.split(data_train):
	
    #这里的train_predictors所代表的是选取的特征
	train_predictors = (data_train[predictors].iloc[train,:])
	
	train_label = data_train["Survived"].iloc[train]
	
	alg.fit(train_predictors,train_label)
	
    #  得到hypothesis 
	test_predictions = alg.predict(data_train[predictors].iloc[test,:])

	predictions.append(test_predictions)</code></pre> 
  <p>循环里的五行代码我们分别来看。</p> 
  <p>第一行中的iloc函数是用来实现对于行或者列的选取；下面给出了一些实际应用；</p> 
  <pre class="has">
<code>逗号是分隔符， 如果不加以说明则默认为整行或者是整列的选取

data_test1=data.iloc[:,:8] &nbsp;#选取位置为[0,8)列的整列数据
data_test2=data.iloc[0:2,8] &nbsp;#选取位置为8的列的[0,2)行的数据
data_test3=data.loc[0:2,'工龄'] &nbsp;#选取列名为‘工龄’的[0,2]行的数据
</code></pre> 
  <p>关于alg 也是就线性回归的初始化算法，其所有的方法如下</p> 
  <p><img alt="" class="has" height="163" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505194656269.png" width="784"></p> 
  <p>使用fit 方法就是开始执行线性回归这个分类器了。（这里并没有返回值，我不是很理解）</p> 
  <p>hypothesis （参数名为test_predictions）的获得方法原理是相同的。</p> 
  <p>最后将得到的hypothesis 使用list的append方法添加到&nbsp; predictions&nbsp; 当中去。</p> 
  <p>因为我们使用的是K = 3 的 3折验证，所以会产生三组预测结果，这三组结果分别存储在三个list当中。</p> 
  <p>我们将它合并成为一个numpy的ndarray类型数组，然后再进行后续的概率计算。</p> 
  <pre class="has">
<code>predictions = np.concatenate(predictions,axis=0)
 
#Map predictions to outcomes(only possible outcomes are 1 and 0)
predictions[predictions&gt;.5] = 1
predictions[predictions&lt;=.5] = 0
accuracy = sum(predictions == data_train["Survived"]) / len(predictions)
print ("准确率为: ", accuracy)</code></pre> 
  <p>运行后得到我们最终的结果，</p> 
  <p><img alt="" class="has" height="133" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190505195438788.png" width="483"></p> 
  <p>&nbsp;</p> 
  <p>&nbsp;</p> 
 </div> 
</div>

	<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
	<!-- 自定义广告 -->
	<ins class="adsbygoogle"
	     style="display:block"
	     data-ad-client="ca-pub-8889449066804352"
	     data-ad-slot="1494696990"
	     data-ad-format="auto"
	     data-full-width-responsive="true"></ins>
	<script>
		(adsbygoogle = window.adsbygoogle || []).push({});
	</script>


        <br />
        <a href="https://uzshare.com/">更多精彩内容</a>
      </section>
      
      <header style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
        <ul style="display: block;">
          <li><a href="/" style="line-height: 40px;padding-top:0px;">回首页</a></li>
        </ul>
      </header>
      <header class="sm-hidden" style="right: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/imgqcode.png" style="width:160px;" />
      </header>
      
      <header class="sm-hidden" style="left: 0;position: fixed;bottom: 60px;z-index: 100;background: none;border-bottom:none;">
          <img src="https://uzzz.org.cn/hou_imgqcode.png" style="width:160px;">
      </header>
    </div>
    
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->

    <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?0d1dbe5a3e5863242418b768d1601633";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script>

  </body>
</html>
